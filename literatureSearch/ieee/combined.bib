@INPROCEEDINGS{9012140,
author={Raj, Vinay and Ravichandra, S.},
booktitle={2018 3rd IEEE International Conference on Recent Trends in Electronics, Information Communication Technology (RTEICT)}, title={Microservices: A perfect SOA based solution for Enterprise Applications compared to Web Services},
year={2018},
volume={},
number={},
pages={1531-1536},
abstract={The Software Engineering community has defined different types of architectures to build applications. One among them is Service Oriented Architecture(SOA) which has created significant impact the way software applications are built. There are many implementations of SOA like Web Services, REST services etc. But Web Services and REST services do not fully follow all the principles of SOA. Microservices as an architectural style recently emerged from SOA by which we can develop business requirements with loosely coupled, self deploying and scalable services. Microservices have gained more popularity in application development as they are easy to understand, scale and deploy. In this paper we discuss principles of SOA, major drawbacks of web services and benefits of Microservices over SOA based web services. We have highlighted the importance of Microservices in software development. This paper gives information for architects as to why choose Microservices architecture over web services. We have also discussed metrics used for calculating Coupling between services and we evaluated by considering a smart payment application for ecommerce which is built using both the styles. We observed that Microservices architectural style has less coupling between services compared to Web Service style based on the metric values of the application.},
keywords={Service-oriented architecture;Couplings;Measurement;Computer architecture;Business;Service Oriented Architecture(SOA);Web Services;Microservices;Coupling;Metrics},
doi={10.1109/RTEICT42901.2018.9012140},
ISSN={},
month={May},}
@INPROCEEDINGS{9095617,
author={Rosa, Thatiane de Oliveira and Goldman, Alfredo and Guerra, Eduardo Martins},
booktitle={2020 IEEE International Conference on Software Architecture Companion (ICSA-C)}, title={How ‘micro’ are your services?},
year={2020},
volume={},
number={},
pages={75-78},
abstract={Microservice is an architectural style that proposes that a complex system should be developed from small and independent services that work together. There is not a welldefined boundary about when a software architecture can be considered based on microservices or not. Because of that, defining microservices context and infrastructure is challenging, especially to characterize aspects related to microservice size, data consistency, and microservices coupling. Thus, it is crucial to understand the microservices-based software characteristics, to comprehend the impact of some evolutions on architecture, and evaluate how much a particular architecture fits the microservices architectural style. Therefore, based on bibliographic research and case studies conducted in academical and industrial environments, we aim to propose a model to characterize the architecture structure based on the main guidelines of the microservice architectural style. This model introduces dimensions that measure characteristics based on modules size, coupling to data sources, and service collaboration. This study should facilitate the mapping, measurement, and monitoring of different impacts generated in the software architecture from increments and refactoring performed. This work is on the initial development stage and as a result, we expected that the model supports architectural decisions that consider different quality attributes to achieve the right balance between service independence and collaboration for a given system.},
keywords={Measurement;Databases;Couplings;Complexity theory;Software;Computer architecture;Software architecture;software architecture;microservices;characterization model},
doi={10.1109/ICSA-C50368.2020.00023},
ISSN={},
month={March},}
@INPROCEEDINGS{9101318,
author={Santos, Nuno and Rito Silva, António},
booktitle={2020 IEEE International Conference on Software Architecture (ICSA)}, title={A Complexity Metric for Microservices Architecture Migration},
year={2020},
volume={},
number={},
pages={169-178},
abstract={Monolith applications tend to be difficult to deploy, upgrade, maintain, and understand. Microservices, on the other hand, have the advantages of being independently developed, tested, deployed, scaled and, more importantly, easier to change and maintain. This paper addresses the problem of migrating a monolith to a microservices architecture. Therefore, we address two research questions: (1) Can we define the cost of decomposition in terms of the effort to redesign a functionality, which is implemented in the monolith as an ACID transaction, into several distributed transactions? (2) Considering several similarity measures between domain entities, which provide a better decomposition when they are compared using the proposed complexity metric? To answer the first research question, we propose a complexity metric, for each functionality of the monolith application, that measures the impact of relaxing the functionality consistency on the architecture redesign and implementation. Regarding the second research question, we experiment with four similarity measures, each based on a different type of information collected from monolith functionality implementation. We evaluated our approach with three monolith systems and compared our complexity metric against industry metrics of cohesion and coupling. We also evaluated the different similarity measures in terms of the complexity of the decomposition they produce. We were able to correctly correlate the complexity metric with other metrics of cohesion and coupling defined in other research and we conclude that no single combination of similarity measures outperforms the other, which is confirmed by the existing research. Additionally, we conclude that the approach can help on an incremental migration to microservices, which, actually, is the strategy proposed by the industry experts.},
keywords={Measurement;Complexity theory;Business;Computer architecture;Tools;Industries;Couplings;Monolith applications, Microservices, Complexity metrics, Architecture migration, Architecture evolution},
doi={10.1109/ICSA47634.2020.00024},
ISSN={},
month={March},}
@INPROCEEDINGS{9095641,
author={Avritzer, Alberto},
booktitle={2020 IEEE International Conference on Software Architecture Companion (ICSA-C)}, title={Challenges and Approaches for the Assessment of Micro-Service Architecture Deployment Alternatives in DevOps : A tutorial presented at ICSA 2020},
year={2020},
volume={},
number={},
pages={1-2},
abstract={The goal of this tutorial is to provide an overview of challenges and approaches for architecture/dependability assessment in the context of DevOps and microservices. Specifically, we present approaches that employ operational data obtained from production-level application performance management (APM) tools, giving access to operational workload profiles, architectural information, failure models, and security intrusions. We use this data to automatically create and conFigure architecture assessments based on models, load tests, and resilience benchmarks. The focus of this tutorial is on approaches that employ production usage, because these approaches provide more accurate recommendations for microservice architecture dependability assessment than approaches that do not consider production usage. We present an overview of (1) the state-of-the-art approaches for obtaining operational data from production systems using APM tools, (2) the challenges of dependability for DevOps and microservices, (3) selected approaches based on operational data to assess dependability. The architecture assessment focus of this tutorial is on scalability, resilience, survivability, and security. Particularly, we present a demo of the automated approach for the evaluation of a domain-based scalability and security metric assessment that is based on the microservice architecture ability to satisfy the performance requirement under load and/or intrusions. We illustrate the approach by presenting experimental results using a benchmark microservice architecture.},
keywords={Tutorials;Computer architecture;Scalability;Security;Tools;Data models;Production;micro-service architectures;operational profile;security intrusions},
doi={10.1109/ICSA-C50368.2020.00007},
ISSN={},
month={March},}
@INPROCEEDINGS{7829777,
author={Parimala, N. and Kohar, Rachna},
booktitle={2016 Eleventh International Conference on Digital Information Management (ICDIM)}, title={A quality metric for BPEL process under evolution},
year={2016},
volume={},
number={},
pages={197-202},
abstract={In Service-Oriented Architecture (SOA), behaviour of a business process is specified using Business Process Execution Language (BPEL) which is a XML based language. In today's competitive market, enterprises change their business processes frequently. Changes in BPEL process may affect the quality of BPEL process for the consumer. It is desirable to measure and evaluate the BPEL process quality when changes occur. Metrics are vastly used to provide a quantitative measure for the quality. In this paper, BPEL Process Usefulness Metric under Evolution (BUME) is proposed to measure quality of a BPEL process when it evolves. The applicability of the metric is demonstrated using simulated data for different versions of a BPEL process.},
keywords={Measurement;Business;Complexity theory;Documentation;Service-oriented architecture;Context;Business Process;BPEL;Change;Metric;Quality;Usefulness},
doi={10.1109/ICDIM.2016.7829777},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{7562758,
author={Honamore, Suhas and Kumar, Lov and Rath, Santanu Ku.},
booktitle={2016 International Conference on Internet of Things and Applications (IOTA)}, title={Analysis of control flow complexity metrics for web service composition},
year={2016},
volume={},
number={},
pages={389-394},
abstract={In service oriented computing, web services are combined to meet the interoperability demands in different heterogeneous and distributed applications. However, incisively measuring the control flow complexity of Web Service Composition (WSC) is not an easy task due to characteristics of distributed, loose-coupling, and heterogeneity. In Service Oriented Architecture (SOA), Business Process Execution Language (BPEL) is used to describe the combination of web services. This paper mainly focuses on the complexity measurement of web service composition from BPEL. Petri-net is one of the models to represent the work flow. The BPEL of WSC is converted into Petri-net based model and by extracting the information of places, transitions, and their interrelationship; the complexity is measured for that Petri-net model. Two metric sets are considered for analysis of the WSC's complexity, which are identified by studying the workflow's execution dependency relations. The first metric set describes the static features, and second metric set describes about the dynamic complexity of business process.},
keywords={Complexity theory;Business;Service-oriented architecture;Atmospheric modeling;Weight measurement;Service oriented architecture;BPEL;WSC;Petri-net;Complexity metrics},
doi={10.1109/IOTA.2016.7562758},
ISSN={},
month={Jan},}
@INPROCEEDINGS{8614791,
author={Parekh, Nikunj and Kurunji, Swathi and Beck, Alan},
booktitle={2018 IEEE 9th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON)}, title={Monitoring Resources of Machine Learning Engine In Microservices Architecture},
year={2018},
volume={},
number={},
pages={486-492},
abstract={Microservices architecture facilitates building distributed scalable software products, usually deployed in a cloud environment. Monitoring microservices deployed in a Kubernetes orchestrated distributed advanced analytics machine learning engines is at the heart of many cloud resource management solutions. In addition, measuring resource utilization at more granular level such as per query or sub-query basis in an MPP Machine Learning Engine (MLE) is key to resource planning and is also the focus of our work. In this paper we propose two mechanisms to measure resource utilization in Teradata Machine Learning Engine (MLE). First mechanism is the Cluster Resource Monitoring (CRM). CRM is a high-level resource measuring mechanism for IT administrators and analytics users to visualize, plot, generates alerts and perform live and historical-analytics on overall cluster usage statistics. Second mechanism is the Query Resource Monitoring (QRM). QRM enables IT administrators and MLE users to measure compute resource utilization per individual query and its sub-queries. When query takes long time, QRM provides insights. This is useful to identify expensive phases within a query that tax certain resources more and skew the work distribution. We show the results of proposed mechanisms and highlight use-cases.},
keywords={Monitoring;Resource management;Engines;Containers;Machine learning;Maximum likelihood estimation;Customer relationship management;Big Data;Data Analytics;Machine Learning;Docker;Linux Containers (LXC);Massively Parallel Processing (MPP);MapReduce;Kubernetes;Monitoring;and Workload Skew},
doi={10.1109/IEMCON.2018.8614791},
ISSN={},
month={Nov},}
@INPROCEEDINGS{7153891,
author={Abid, Kashif Sohail and Abid, Asif Sohail and Ansari, M. Mohsen},
booktitle={2015 IEEE International Conference on Multimedia Big Data}, title={A Better Approach for Conceptual Readability of WSDL},
year={2015},
volume={},
number={},
pages={260-263},
abstract={Issues that concerns with the inter-operability on a heterogeneous environment can easily be address using the flexible platform of Service Oriented Architecture (SOA). Web service is an implementation and modeling of Service Oriented Architecture (SOA). Web service description language (WSDL)is a standard describing a web service in XML form. This Description can be categorized in two parts i.e. Structural and non-structural. The readability of a web service helps the consumer to understand it easily, it is suggested to provide sufficient details about functionality scope and limitation of scope in WSDL, so that it can easily be understandable. Readability depends upon interaction of two variables i.e. Text and reader. The maximum details about a web service could lead to it's reproduction by business competitor, and it may helps in maximizing vulnerabilities in it. This paper focuses on a technique for computing readability index by a detail analysis of WSDL document. This readability index obtain using this approach helps the producer of a web service to adjust readability, so that it can easily be understandable by consumer. The better readability index can also leads the provider to a better service discovery. To calculate Readability Index, extraction of WSDL file components was performed. After extraction of key concepts, they were mapped with the Domain Ontology. The words that were not mapped in the ontology, synonyms are employed by consulting the Word Net. Final readability was obtained using Simplified Dale Chall readability index (DaCw). The Web Service Readability can be measure more precisely by considering words that were not found in the mapping process.},
keywords={Indexes;Ontologies;Mathematical model;Service-oriented architecture;Web sites;XML;Web Services;Readability;WSDL},
doi={10.1109/BigMM.2015.52},
ISSN={},
month={April},}
@INPROCEEDINGS{8940402,
author={Fernandes Mioto de Oliveira dos Santos, Eduardo and Lima Werner, Claudia Maria},
booktitle={2019 International Conference on Information Systems and Software Technologies (ICI2ST)}, title={A Survey on Microservices Criticality Attributes on Established Architectures},
year={2019},
volume={},
number={},
pages={149-155},
abstract={The microservice oriented software architecture considers the delegation of responsibilities by separate components, thus creating a set of interconnected but independent services. Information about the most critical microservices is relevant to software architects and other decision-makers, thus guiding the maintenance and evolution of architecture in a more assertive and guided way. This paper aims to observe the need for a method to measure criticality in a microservice oriented architecture, motivated by this purpose, during August 2019, a survey with twenty experienced participants from the industry and academia was conducted, where the lack of a grounded method to measure the criticality on established architectures was observed.},
keywords={Computer architecture;ISO Standards;Atmospheric measurements;Particle measurements;Service-oriented architecture;Computational modeling;Microservices;Criticality;Attributes;Established Architectures;Survey},
doi={10.1109/ICI2ST.2019.00028},
ISSN={},
month={Nov},}
@INPROCEEDINGS{6917306,
author={Zhang, Lili and Yu, Shusong and Ding, Xiangqian and Wang, Xiaodong},
booktitle={2014 Sixth International Conference on Intelligent Human-Machine Systems and Cybernetics}, title={Research on IOT RESTful Web Service Asynchronous Composition Based on BPEL},
year={2014},
volume={1},
number={},
pages={62-65},
abstract={In recent years, The Internet of Things(IOT) is one of the hottest research topics. It was originally defined as connected all the things through the sensing devices to the Internet. In addition, Service-Oriented methodology has gradually drawn people's attention. Therefore, integrated The IOT with Service-Oriented methodology is very important. But now IOT service composition is mostly synchronous and service model is more complex. RESTful web services have been widely recognized and used because of their lightweight and succinct. RESTful web services introduce a new kind of abstraction, the resource, so that they are hard to compose using the Business Process Execution Language (BPEL). In order to compose asynchronous RESTful web services and make use of various IOT services, this paper proposes an asynchronous RESTful web service recursive measure, which is based on the BPEL extention. First, design the architecture of IOT RESTful web services, the architecture is divided into six layers so that it can integrate The IOT and RESTful web services effectively. Second, we show how to invoke the RESTful web services from the IOT and publish a BPEL process as a RESTful web service by extending BPEL. Finally, through an experiment to verify the correctness and validity of the proposed method in this paper.},
keywords={Service-oriented architecture;Computer architecture;Drugs;Servers;Security;Educational institutions;Internet of Things;RESTful Web Service;BPEL;Service Asynchronous Composition;IOT Architecture},
doi={10.1109/IHMSC.2014.23},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8987957,
author={Kumar, T Sathis and Latha, K},
booktitle={2019 International Conference on Smart Systems and Inventive Technology (ICSSIT)}, title={Interoperability Performance in Adaptive Middleware for Enterprise Business Applications},
year={2019},
volume={},
number={},
pages={652-656},
abstract={To improve the presentation of B2B (Business to Business) and B2C (Business to Consumer) regarding venture wide Service Oriented Architecture (SOA), we need middleware interoperability particularly with agent building to be specific CORBA (Common Object Request Broker Architecture) proposed by Object Management Group ORB programming named ORBeline. Unmistakable models for client server correspondences have just been created and executed specifically Handle Driven ORB (H-ORB), Forwarding ORB (F-ORB), and the Adaptive ORB (A- ORB). This paper concentrates how to improve the presentation of the interoperability in Adaptive ORB (A-ORB) as for client server collaboration in N-level engineering alongside multithreading condition. We have presented a strategy called linear discriminant interoperable support learning method and how it will in general be used for improving the presentation of interoperability is examined. The outcome gives the framework conduct especially the impact of message measure, between hub deferrals; torpidity and flexibility of solicitation/reaction administration times for the A-ORB engineering are broke down.},
keywords={Interoperability;Multithreading;Threshold;Object Request Broker},
doi={10.1109/ICSSIT46314.2019.8987957},
ISSN={},
month={Nov},}
@ARTICLE{9463396,
author={Chen, Jeng-Chung and Chen, Chun-Chih and Shen, Chih-Hsiung and Chen, Ho-Wen},
journal={IEEE Internet of Things Journal}, title={User Integration in Two IoT Sustainable Services by Evaluation Grid Method},
year={2021},
volume={},
number={},
pages={1-1},
abstract={To meet the need for sustainable development, Taiwan has been spreading a network of micro-monitoring stations to measure the environmental quality in rivers and air to protect people from environmental pollution. As a result, more and more information technology companies develop Internet of Things (IoT) services for this job. However, most IoT services are screened out of the market because lacking design thinking. Therefore, including users’ desires in IoT products and services is a critical determinant for their survival in this permanently changing market. Thus, this study proposed a systematic framework to identify the users’ desires from different stakeholders to determine technological development. For this, we use the Evaluation Grid Method (EGM) to explore the users’ desires by a series of in-depth interviews and visualize the user’s response as a hierarchical evaluation map of attraction. After that, an IoT prototype is built and used to capture the insightful feedback of respondents. Meanwhile, we adopt the minimum viable product (MVP) design principles to develop two prototypes that manage a wastewater treatment plant and household environment. Overall, this study proposes an applicable user integration procedure to help IT engineers develop the IoT for sustainable service. This study also confirms that the MVP method can help to accelerate user integration. We propose a service-oriented IoT architecture in technology development and develop a decision-making service of human dispatch in operating environmental facilities and a context-awareness service for environmental control.},
keywords={Internet of Things;Ventilation;Water pollution;Wastewater treatment;Interviews;Companies;Air pollution;User integration;sustainable development;IoT;minimum viable product (MVP);evaluation grid method (EGM).},
doi={10.1109/JIOT.2021.3091688},
ISSN={2327-4662},
month={},}
@INPROCEEDINGS{8082679,
author={Chaudhari, Nikhil and Bhadoria, Robin Singh and Prasad, Siddharth},
booktitle={2016 8th International Conference on Computational Intelligence and Communication Networks (CICN)}, title={Information Handling and Processing Using Enterprise Service Bus in Service-Oriented Architecture System},
year={2016},
volume={},
number={},
pages={418-421},
abstract={Information is key factor in delivering service across networks. Messaging is important aspect in handing information using Enterprise Service Bus (ESB) in Service Oriented Architecture (SOA). Such information is generally passes and used as interaction parameters upon communication between two parties that could be carried out amongst multiple services. Integration between multiple application services could be strengthened by adopting this methodology which is important to handle web services over networks. ESB is messaging middleware framework that helps in designing and developing web services through which software intermediary could be possible. It is a kind of depletion layer that efficiently handles various overheads during communication and interaction between multiple application services. This paper details about issues related to application services with message handling and control. Testing and simulation has been carried out on - AdroitLogic UltraESB, WSO2 ESB and Red Hat JBoss Fuse ESBs. Several parameters like total and average message counts, overall bytes measure, overall message received and sent, processing time of messages, and memory allocation.},
keywords={Service-oriented architecture;Time factors;Message systems;Business;Fuses;Concurrent computing;Service-Oriented Architecture (SOA);Enterprise Service Bus (ESB);Message Handling;Middleware},
doi={10.1109/CICN.2016.88},
ISSN={2472-7555},
month={Dec},}
@ARTICLE{9222262,
author={Wang, Chen and Ma, Hui and Chen, Gang and Hartmann, Sven and Branke, Jürgen},
journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, title={Robustness Estimation and Optimisation for Semantic Web Service Composition With Stochastic Service Failures},
year={2020},
volume={},
number={},
pages={1-16},
abstract={Service-oriented architecture (SOA) is a widely adopted software engineering paradigm that encourages modular and reusable applications. One popular application of SOA is web service composition, which aims to loosely couple web services to accommodate complex goals not achievable through any individual web service. Many approaches have been proposed to construct composite services with optimized Quality of Service (QoS), assuming that QoS of web services never changes. However, the constructed composite services may not perform well and may not be executable later due to its component services' failure. Therefore, it is important to build composite services that are robust to stochastic service failures. Two challenges of building robust composite services are to efficiently generate service composition with near-optimal quality in a large search space of available services and to accurately measure the robustness of composite services considering all possible failure scenarios. This article proposes a novel two-stage GA-based approach to robust web service composition with an adaptive evolutionary control and an efficient robustness measurement. This approach can generate robust composite service at the design phase, which can cope with stochastic service failures and maintain high quality at the time of execution. We have conducted experiments with benchmark datasets to evaluate the performance of our proposed approach. Our experiments show that our method can produce highly robust composite services, achieving outstanding performance consistently in the event of stochastic service failures, on service repositories with varying sizes.},
keywords={Quality of service;Robustness;Web services;Estimation;Optimization;Approximation methods;Genetic algorithms;Combinatorial optimisation;genetic algorithm;robust optimisation;web service composition},
doi={10.1109/TETCI.2020.3027870},
ISSN={2471-285X},
month={},}
@INPROCEEDINGS{9441601,
author={Sun, Yu and Mao, Shaojie and Huang, Songhua and Mao, Xiaobin},
booktitle={2021 2nd Information Communication Technologies Conference (ICTC)}, title={Load Balancing Method for Service Scheduling of Command Information System},
year={2021},
volume={},
number={},
pages={297-301},
abstract={In order to satisfy the capability generation requirement of command information system, a load balancing method for service scheduling is studied. Considering that a work which will be finished by command information system based on service-oriented architecture is composed of several jobs, the paper analyzes the work completion process in detail. Then, a method to measure the load on a service which is scheduled to participate in a work is designed. On that basis, a load balancing mathematical model for service scheduling is established and a model solving algorithm that is based on greedy strategy and has polynomial time is put forward. Simulated experimental results show that the method proposed in this paper can allocate load to the services of command information system in a balanced way.},
keywords={Atmospheric measurements;Load management;Particle measurements;Scheduling;Communications technology;Service-oriented architecture;Mathematical model;command information system;service oriented architecture;service scheduling;load balancing;greedy strategy},
doi={10.1109/ICTC51749.2021.9441601},
ISSN={},
month={May},}
@INPROCEEDINGS{8536110,
author={Langermeier, Melanie and Bauer, Bernhard},
booktitle={2018 IEEE 22nd International Enterprise Distributed Object Computing Workshop (EDOCW)}, title={A Model-Based Method for the Evaluation of Project Proposal Compliance within EA Planning},
year={2018},
volume={},
number={},
pages={97-106},
abstract={The business model and IT infrastructure of organizations is continually changing. Trends like microservices and digital transformation demand an adaption of the business models and IT infrastructure in order to stay competitive. It is important to ensure the compliance of these new projects with the current goals and principles. The discipline of Enterprise Architecture Planning provides methods for the structured development of the business and IT of an organization. In this paper we propose a tool-supported method for EA planning to evaluate to the project compliance based on established models. Different analyses are used to support the architect during project planning. Gap and impact analysis are used to ensure the change consistency. The compliance with the current strategy is finally evaluated with view generation and metric calculation. Foundation of the method is a generic generic analysis architecture execution environment (A2E), that provides us with the required flexibility to adapt to different needs and meta models. The method and the proposed analyses are evaluated within a case study from a medium-sized software product company.},
keywords={Planning;Computer architecture;Proposals;Adaptation models;Organizations;Analytical models;Architecture Analysis, Architecture Evaluation, Enterprise Architecture, Enterprise Architecture Planning},
doi={10.1109/EDOCW.2018.00024},
ISSN={2325-6605},
month={Oct},}
@INPROCEEDINGS{8585730,
author={OULMAHDI, Mohamed and CHASSOT, Christophe and VAN WAMBEKE, Nicolas},
booktitle={2018 International Conference on Smart Communications in Network Technologies (SaCoNeT)}, title={Extensible and Adaptive Architecture for an Evolutive Transport Layer},
year={2018},
volume={},
number={},
pages={102-107},
abstract={The world of communications and networking knows and important evolution over the years. While this evolution is concretized by a deployment of many modern protocols at most of protocol layers, the Transport one continues to use old TCP and UDP protocols. This despite that an important number of modern protocols and mechanisms have been proposed. In this context, we study in this paper the obstacle of the deployment of new transport protocols and propose a new architecture to support the deployment and the adaptation of new Transport solutions. This was achieved by adding extensibility and adaptability capabilities using service-oriented and component-based paradigms. The architecture performances are studied at the end to measure the impact and the benefits of the new architecture comparing to classical Transport protocol.},
keywords={Transport protocols;Internet;Reliability;Aerodynamics;Semantics;Telecommunications;Transport layer;service-oriented;component-based;TCP;Aeronautical Telecommunications Network (ATN).},
doi={10.1109/SaCoNeT.2018.8585730},
ISSN={},
month={Oct},}
@INPROCEEDINGS{7509323,
author={Pulparambil, Supriya and Baghdadi, Youcef},
booktitle={2016 IEEE Students' Conference on Electrical, Electronics and Computer Science (SCEECS)}, title={SOA maturity model a frame of reference},
year={2016},
volume={},
number={},
pages={1-6},
abstract={Service Oriented Architecture (SOA) is an architectural style that supports service orientation. In reality, SOA is much more than architecture. SOA adoption is prerequisite for organization to excel their service deliveries, as the delivery platforms are shifting to mobile, cloud and social media. A maturity model is a tool to accelerate enterprise SOA adoption, however it depends on how it should be applied. This paper presents a literature review of existing maturity models and proposes 5 major aspects that a maturity model has to address to improve SOA practices of an enterprise. A maturity model can be used as: (i) a roadmap for SOA adoption, (ii) a reference guide for SOA adoption, (iii) a tool to gauge maturity of process execution, (iv) a tool to measure the effectiveness of SOA motivations, and (v) a review tool for governance framework. This paper also sheds light on how SOA maturity assessment can be modeled. A model for SOA process execution maturity and perspective maturity assessment has been proposed along with a framework to include SOA scope of adoption.},
keywords={Service-oriented architecture;Semiconductor optical amplifiers;Capability maturity model;Organizations;Standards organizations;Industries;SOA maturity model;assessment;execution maturity;perspective maturity;scope;framework},
doi={10.1109/SCEECS.2016.7509323},
ISSN={},
month={March},}
@INPROCEEDINGS{9307705,
author={Camilli, Matteo and Colarusso, Carmine and Russo, Barbara and Zimeo, Eugenio},
booktitle={2020 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)}, title={Domain Metric Driven Decomposition of Data-Intensive Applications},
year={2020},
volume={},
number={},
pages={189-196},
abstract={The microservices architectural style is picking up more and more momentum in IT industry for the development of systems as loosely coupled, collaborating services. Companies that undergo the migration of their own applications have aspirations such as increasing maintainability and the scale of operation. Such a process is worthwhile but not easy, since it should ensure atomic improvements to the overall architecture for each migration step. Furthermore, the systematic evaluation of migration steps becomes cumbersome without sensible optimization metrics that take into account performance and scalability under expected operational conditions. Recent lines of research recognize this task as challenging, especially in data-intensive applications where known approaches based, for instance, on Domain Driven Design may not be adequate. In this paper, we introduce an approach to evaluate a migration in an iterative way and recognize whether it represents an improvement in terms of performance and scalability. The approach leverages a Domain Metric-based analysis to quantitatively evaluate alternative architectures. We exemplified the envisioned approach on a data-intensive application case study in the domain of smart mobility. Preliminary results from our controlled experiments show the effectiveness of our approach to support systematic and automated evaluation of migration processes.},
keywords={Scalability;Testing;Measurement;Computer architecture;Roads;Business;Servers;Microservices;Decomposition;Performance Analysis;Scalability Analysis;Domain Metric},
doi={10.1109/ISSREW51248.2020.00071},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8786277,
author={Delgado, Andrea},
booktitle={2018 XLIV Latin American Computer Conference (CLEI)}, title={Monitoring and Analyzing Service Execution from Business Processes: An AXIS Extension},
year={2018},
volume={},
number={},
pages={582-589},
abstract={Implementing Business Processes (BPs) with services (and microservices) is nowadays the main way to support the execution of automated activities in processes, both within the organization itself, and externally interacting with customers, suppliers and other participants. In order to do so, it is important not only to model and implement services but also to define Quality of Service (QoS) characteristics for services, to monitor and evaluate their execution. Although there are many proposals for services monitoring and evaluation from the services point of view, there are not many from the BPs perspective. In this paper we present a reference architecture for service monitoring tools, along with a prototype implementation as an extension of the web services execution environment AXIS2. We show that existing service measures and new ones can be defined into the monitor to collect execution data and relate this data with BPs execution, to measure BPs and service execution in an integrated manner.},
keywords={Monitoring;Computer architecture;Tools;Quality of service;Service-oriented architecture;Time measurement;Business processes;measuring business processes and services;Quality of Service (QoS);service monitoring},
doi={10.1109/CLEI.2018.00075},
ISSN={},
month={Oct},}
@INPROCEEDINGS{6986002,
author={Nik Daud, Nik Marsyahariani and Wan Kadir, Wan M. N.},
booktitle={2014 8th. Malaysian Software Engineering Conference (MySEC)}, title={Static and dynamic classifications for SOA structural attributes metrics},
year={2014},
volume={},
number={},
pages={130-135},
abstract={Evaluating qualities of software based on software structural attributes such as coupling and cohesion are frequently done in practice as these attributes directly have impacts on value of higher level quality. Concerning oneself with structural attributes values early on helps developers to predict quality attributes level in the software. Service-Oriented Architecture (SOA) is an architectural concept where services are used as building blocks in developing new software. Lots of structural attributes metrics related to SOA had been proposed these recent years, which triggered an investigation to classify these metrics based on specific criteria. In this paper, we introduce classifications for SOA based structural attributes metrics, where the metrics are restricted to coupling, cohesion and complexity metrics. These metrics are classified based on software static and dynamic aspects with some brief introduction for each metric. By classifying these SOA based structural attributes metrics, it will allow user to avoid redundancy in proposing similar metrics thus increases the reusability of existing metrics.},
keywords={Couplings;Service-oriented architecture;Complexity theory;Software measurement;Semiconductor optical amplifiers;Structural attributes metric;Service Oriented Architecture;metrics classification},
doi={10.1109/MySec.2014.6986002},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9407977,
author={Tummalapalli, Sahithi and Kumar, Lov and Neti, Lalita Bhanu Murthy and Krishna, Aneesh},
booktitle={2020 IEEE 22nd International Conference on High Performance Computing and Communications; IEEE 18th International Conference on Smart City; IEEE 6th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, title={An Empirical Analysis on the Role of WSDL Metrics in Web Service Anti-Pattern Prediction},
year={2020},
volume={},
number={},
pages={559-564},
abstract={Service-Oriented Architecture (SOA) is one of the most well-known models for designing web systems. SOA system evolution and maintenance is challenging because of its distributive nature and secondly due to the demand of designing high-quality, stable interfaces. This evolution leads to a problem called Anti-patterns in web services. It is observed that these anti-patterns negatively impact the evolution and maintenance of software systems, making the early detection and correction of them a primary concern for the software developers. The primary motivation of this work is to investigate the relationship between the Web Service Description Language(WSDL) metrics and anti-patterns in web services. This research aims to develop an automatic method for the detection of web service anti-patterns. The core idea of the methodology defined is to identify the most crucial WSDL metrics with the association of various feature selection techniques for the prediction of anti-patterns. Experimental results show that the model developed by using all the WSDL quantity metrics(AM) shows a bit high performance compared to the models developed with the other metric sets. Experimental results also showed that the performance of the models generated using Decision Tree(DT) and Major Voting Ensemble(MVE) is high compared to the models generated using other classifier techniques.},
keywords={Measurement;Computational modeling;High performance computing;Conferences;Maintenance engineering;Software systems;Feature extraction;Anti-patterns;Web Services;WSDL metrics;Neural Networks;Feature Selection;Data Sampling;Machine Learning},
doi={10.1109/HPCC-SmartCity-DSS50907.2020.00070},
ISSN={},
month={Dec},}
@INPROCEEDINGS{7521492,
author={Gomes, Luiza Barcelos Gualberto and Farias, Pedro Porfírio Muniz and Bessa Albuquerque, Adriano and Herden, Adriana},
booktitle={2016 11th Iberian Conference on Information Systems and Technologies (CISTI)}, title={Software measure based on BPMN activity points},
year={2016},
volume={},
number={},
pages={1-6},
abstract={BPMN usage has been extended beyond the workflow systems and service-oriented architecture. Development methodologies have been proposed using BPMN to describe use cases, to specify the activities flow that forms each scenario of general purpose systems and business process execution with web services. This article proposes a metric to estimate software size, called BPMN Activity Points based on activities counting from three different perspectives, in which these scores are increasingly detailed and refined.},
keywords={Unified modeling language;Logic gates;Business;Software measurement;Service-oriented architecture;Context;BPMN;metric to estimate;software size},
doi={10.1109/CISTI.2016.7521492},
ISSN={},
month={June},}
@INPROCEEDINGS{7558028,
author={Li, Zhinan and Yang, Xiaodong},
booktitle={2016 IEEE International Conference on Web Services (ICWS)}, title={A Reliability-Oriented Web Service Discovery Scheme with Cross-Layer Design in MANET},
year={2016},
volume={},
number={},
pages={404-411},
abstract={Web service technologies are playing an increasingly important role in service-oriented architecture design and application convergence over Mobile ad hoc networks (MANET). Due to the decentralized administration and dynamic wireless connectivity problems, accomplishing reliable service discovery in MANET faces a large number of challenges. In order to relieve the communication inefficiency among service providers and clients caused mainly by the unpredictable node mobility, this paper proposes a cross-layer service discovery scheme which enables improved network efficiency and reduced resource consumption. Firstly a network-layer based underlay framework is presented. It specifically establishes a reliability-oriented source routing mechanism which is equipped with a novel reliability-maximized path selection metric and a backup path support fast route recovery strategy. The cross-layer design is prudentially realized by piggybacking service discovery procedures on the reliability enhanced underlay routing mechanism. Simulation analysis verifies that the proposed scheme improves service discovery reliability by achieving low rediscovery frequency, and guarantees high network efficiency by providing reduced service discovery delay and control overhead.},
keywords={Reliability;Routing;Correlation;Routing protocols;Mobile ad hoc networks;Nickel;Web services;path reliability;web service;service discovery;backup path;cross-layer},
doi={10.1109/ICWS.2016.59},
ISSN={},
month={June},}
@INPROCEEDINGS{7062707,
author={Nuraini, Aminah and Widyani, Yani},
booktitle={2014 International Conference on Data and Software Engineering (ICODSE)}, title={Software with service oriented architecture quality assessment},
year={2014},
volume={},
number={},
pages={1-6},
abstract={Service Oriented Architecture (SOA) is becoming popular since its flexibility fulfill the need of rapidly changing enterprise requirement. Therefore, expectation of a good quality software with SOA is getting higher. To address this need, this paper presents a guideline to conduct quality assessment using an existing tool. The quality assessment model is designed by selecting the relevant quality factors, choosing an appropriate quality to metric mapping method, identifying the relevant metrics, and mapping each quality factor to the metrics. Using the model, the quality assessment process is prepared by identifying data and selecting the appropriate tools. The chosen tool may require some modification. The proposed quality assessment guideline can help the software quality assurance team to assess quality of their software with SOA. The proposed guideline has been used to assess the quality of an existing sofware with SOA (Bonita BPM). The result is considered as promising, although several improvement are still needed.},
keywords={Measurement;Quality assessment;Service-oriented architecture;Q-factor;Guidelines;Semiconductor optical amplifiers;SOA;software quality assessment;quality factor;quality metrics},
doi={10.1109/ICODSE.2014.7062707},
ISSN={},
month={Nov},}
@INPROCEEDINGS{7013150,
author={Wijayanto, Arie Wahyu and Suhardi},
booktitle={2014 International Conference on ICT For Smart Society (ICISS)}, title={Service oriented architecture design using SOMA for optimizing public satisfaction in government agency: Case study: BPN - National Land Authority of Indonesia},
year={2014},
volume={},
number={},
pages={49-55},
abstract={Service oriented architecture (SOA) enables organizations to easily integrate systems, data, and business processes. Implementation of SOA solution in private sector is widely used and successfully proven to increase their profit. But there are different challenge in public sector which is not profit oriented and has different business model. In public sector, user satisfaction on government agencies is one of common indicator to measure quality of public service. This paper presents SOA solution for public sector using SOMA to conduct a service integration for optimizing public satisfaction. We also combined SWOT and Porter's Value Chain to support business modelling analysis. The result shows that there is a simplicity and feasibility for users to access the service after SOA integration, which improves user satisfaction.},
keywords={Service-oriented architecture;Unified modeling language;Government;Analytical models;Computer architecture;Service Engineering;SOMA;Service Design;Service Oriented Architecture;Public Sector},
doi={10.1109/ICTSS.2014.7013150},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{6901158,
author={Mcheick, Hamid and Mohammad, Atif Farid},
booktitle={2014 IEEE 27th Canadian Conference on Electrical and Computer Engineering (CCECE)}, title={The evident use of evidence theory in big data analytics using cloud computing},
year={2014},
volume={},
number={},
pages={1-6},
abstract={We live in the world of evidence. This research survey comprises of several research works and has an example implying dempster-shafer theory of evidence. We have witnessed several advances in computational performance, which have brought us the design and development of high-performance computing simulation tools. It is a fact that we have to account for uncertainty, while generating such high-performance systems using such simulation tools can fail in service performance predictions. We have seen that evidence theory is utilized to measure uncertainty in terms of the uncertain measures of belief and plausibility. It is also witnessed in computing community that Cloud computing has provided a flexible and scalable infrastructures to grow beyond contemporary borders to the organizations as wells the users everyday use of services. It also has increased availability of high-performance computing applications to small/ medium-sized businesses as well as academic users to work with. This paper also sheds light on Cloud computing and Service-Oriented Architecture.},
keywords={Abstracts;Forgery;Computational modeling;Data models;Personnel;Cloud Computing;Evidence Theory;High-Performance Computing;Simulation},
doi={10.1109/CCECE.2014.6901158},
ISSN={0840-7789},
month={May},}
@INPROCEEDINGS{8560743,
author={Marmsoler, Diego},
booktitle={2018 International Symposium on Theoretical Aspects of Software Engineering (TASE)}, title={On Syntactic and Semantic Dependencies in Service-Oriented Architectures},
year={2018},
volume={},
number={},
pages={132-137},
abstract={In service oriented architectures, components provide services on their output ports and consume services from other components on their input ports. Thereby, a component is said to depend on another component if the former consumes a service provided by the latter. This notion of dependency (which we call syntactic dependency) is used by many architecture analysis tools as a measure for system maintainability. With this paper, we introduce a weaker notion of dependency, still sufficient, however, to guarantee semantic independence between components. Thereby, we discover the concepts of weak and strong semantic dependency and prove that strong semantic dependency indeed implies syntactic dependency. Our alternative notion of dependency paves the way to more precise dependency analysis tools. Moreover, our results about the different types of dependencies can be used for the verification of semantic independence.},
keywords={Syntactic Dependency;Semantic Dependency;Service Oriented Architectures},
doi={10.1109/TASE.2018.00025},
ISSN={},
month={Aug},}
@ARTICLE{8936375,
author={Sun, Chang-Ai and Dai, Hepeng and Wang, Guan and Towey, Dave and Chen, Tsong Yueh and Cai, Kai-Yuan},
journal={IEEE Transactions on Services Computing}, title={Dynamic Random Testing of Web Services: A Methodology and Evaluation},
year={2019},
volume={},
number={},
pages={1-1},
abstract={In recent years, Service Oriented Architecture (SOA) has been increasingly adopted to develop distributed applications in the context of the Internet. To develop reliable SOA-based applications, an important issue is how to ensure the quality of web services. In this paper, we propose a dynamic random testing (DRT) technique for web services, which is an improvement over the widely-practiced random testing (RT) and partition testing (PT). We examine key issues when adapting DRT to the context of SOA, including a framework, guidelines for parameter settings, and a prototype for such an adaptation. Empirical studies are reported where DRT is used to test three real-life web services, and mutation analysis is employed to measure the effectiveness. Our experimental results show that, compared with the three baseline techniques, RT, Adaptive Testing (AT) and Random Partition Testing (RPT), DRT demonstrates higher fault-detection effectiveness with a lower test case selection overhead. Furthermore, the theoretical guidelines of parameter setting for DRT are confirmed to be effective. The proposed DRT and the prototype provide an effective and efficient approach for testing web services.},
keywords={Testing;Service-oriented architecture;Guidelines;Reliability;Prototypes;Software Testing;Random Testing;Dynamic Random Testing;Web Service;Service Oriented Architecture},
doi={10.1109/TSC.2019.2960496},
ISSN={1939-1374},
month={},}
@INPROCEEDINGS{8599786,
author={Johnsen, Frank T. and Landmark, Lars and Hauge, Mariann and Larsen, Erlend and Kure, Øivind},
booktitle={MILCOM 2018 - 2018 IEEE Military Communications Conference (MILCOM)}, title={Publish/Subscribe Versus a Content-Based Approach for Information Dissemination},
year={2018},
volume={},
number={},
pages={1-9},
abstract={NATO has identified the WS-Notification standard from OASIS to support event-driven communication in the NATO enterprise and when building coalition networks. Using this standard promotes interoperability. However, there is significant overhead associated with WS-Notification since it is built on SOAP Web services (WS). Overhead can be problematic in networks with scarce resources. In this paper we perform a small-scale comparative evaluation of overhead of WS-Notification with another publish/subscribe standard: Message Queuing Telemetry Transport (MQTT). We also measure how these standards compare to the novel approach of content-based networking under the same networking conditions. We use the Named Data Networking (NDN) flavor of content-based networking for our experiment. Though fundamentally different, these approaches can be used to realize the Service-Oriented Architecture (SOA) paradigm. The drawback of standard publish/subscribe approaches is that they usually rely on a broker, which constitutes a single point of failure. NDN, on the other hand, has no broker which makes it interesting to consider for tactical networks. We use NATO Friendly Force Information (NFFI), which is much used for friendly force tracking, as the data format for the payload in all our tests. In the paper we focus on the respective approaches' network resource consumption. Based on the results we argue that the content-based approach seems promising and should be investigated further.},
keywords={Standards;Service-oriented architecture;Protocols;IP networks;Buildings;Force;Simple object access protocol},
doi={10.1109/MILCOM.2018.8599786},
ISSN={2155-7586},
month={Oct},}
@ARTICLE{8288619,
author={Akbar, Adnan and Kousiouris, George and Pervaiz, Haris and Sancho, Juan and Ta-Shma, Paula and Carrez, Francois and Moessner, Klaus},
journal={IEEE Access}, title={Real-Time Probabilistic Data Fusion for Large-Scale IoT Applications},
year={2018},
volume={6},
number={},
pages={10015-10027},
abstract={Internet of Things (IoT) data analytics is underpinning numerous applications, however, the task is still challenging predominantly due to heterogeneous IoT data streams, unreliable networks, and ever increasing size of the data. In this context, we propose a two-layer architecture for analyzing IoT data. The first layer provides a generic interface using a service oriented gateway to ingest data from multiple interfaces and IoT systems, store it in a scalable manner and analyze it in real-time to extract high-level events; whereas second layer is responsible for probabilistic fusion of these high-level events. In the second layer, we extend state-of-the-art event processing using Bayesian networks in order to take uncertainty into account while detecting complex events. We implement our proposed solution using open source components optimized for large-scale applications. We demonstrate our solution on real-world use-case in the domain of intelligent transportation system where we analyzed traffic, weather, and social media data streams from Madrid city in order to predict probability of congestion in real-time. The performance of the system is evaluated qualitatively using a web-interface where traffic administrators can provide the feedback about the quality of predictions and quantitatively using F-measure with an accuracy of over 80%.},
keywords={Real-time systems;Probabilistic logic;Uncertainty;Data mining;Meteorology;Bayes methods;Data analysis;Complex event processing;data analysis;internet of things;real-time systems;intelligent transportation systems},
doi={10.1109/ACCESS.2018.2804623},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{7133511,
author={Harrer, Simon and Geiger, Matthias and Preißinger, Christian R. and Bimamisa, David and Schuberth, Stephan J.A. and Wirtz, Guido},
booktitle={2015 IEEE Symposium on Service-Oriented System Engineering}, title={Improving the Static Analysis Conformance of BPEL Engines with BPELlint},
year={2015},
volume={},
number={},
pages={31-39},
abstract={Today, process-aware systems are ubiquitous. They are built by leveraging process languages for both business and implementation perspectives. In the typical context of a Web Services-based Service-oriented Architecture, the obvious choice to implement service orchestrations is still the Business Process Execution Language (BPEL). For BPEL, a variety of open source and commercial engines have emerged. Although the BPEL standard document defines a set of static analysis rules which should be checked by engines prior to deployment to be standard conformant, previous work revealed that most engines are not capable of revealing all violations of these constraints, resulting in costly runtime errors later on. In this paper, we aim to improve the static analysis conformance of BPEL engines. We implement the tool BPELlint that validates 71 static analysis rules of the BPEL specification, show that the tool can be easily integrated into the deployment process of existing engines, and evaluate its performance to measure the effect on the time to deploy. The results demonstrate that BPELlint can improve the static analysis conformance of BPEL engines with an acceptable performance overhead.},
keywords={Engines;XML;Load modeling;Standards;Semantics;Business;Analytical models;Static analysis;Standard conformance;BPEL},
doi={10.1109/SOSE.2015.21},
ISSN={},
month={March},}
@INPROCEEDINGS{8986987,
author={Tripathi, Manish K and Chaubisa, Divyanshu and Kumar, Lov and Murthy Neti, Lalita Bhanu},
booktitle={2018 15th IEEE India Council International Conference (INDICON)}, title={Prediction of Quality of Service Parameters Using Aggregate Software Metrics and Machine Learning Techniques},
year={2018},
volume={},
number={},
pages={1-6},
abstract={In todays Service-Oriented Architecture (SOA) world, software systems are built by composing web services offered by Service Providers (SPs). There are different SPs offering services for the same set of functional requirements. Service providers are expected to be highly competitive in their offerings to enhance their market. The quality of web services is an important factor that differentiates one service provider from another. Twelve parameters are identified by which quality of service can be measured. The prediction of these twelve QoS parameters help SPs to enhance the quality of their service. Each web service is realized by several programming files. CK and object oriented metrics of the underlying Java files of the web services are important features for predicting QoS parameters of the web service. The aggregated measure, mean, is chosen to be a feature in predicting the QoS parameters in earlier studies. We propose to build prediction models using 16 aggregate measures and show that there is significant difference between these aggregate measures. We find best feature subset using six feature selection techniques and build prediction models using Extreme Learning Machines with different kernels. We show that feature selection techniques might not enhance prediction accuracies and the ensemble algorithm out performs other learning algorithms.},
keywords={Measurement;Quality of service;Web services;Object oriented modeling;Predictive models;Aggregates;Feature extraction;PCA: Principal Component Analysis;ELM: Extreme Learning Machine;RBF: Radial Basis Function;Feature selection;Aggregation Metrics},
doi={10.1109/INDICON45594.2018.8986987},
ISSN={2325-9418},
month={Dec},}
@INPROCEEDINGS{8776974,
author={Barnwal, Anil and Jangade, Rajesh and Pugla, Satyakam},
booktitle={2019 9th International Conference on Cloud Computing, Data Science Engineering (Confluence)}, title={Analyzing and Predicting the Allocation and Utilization of Resources in Cloud Computing System},
year={2019},
volume={},
number={},
pages={56-62},
abstract={The increasing use of cloud computing, constructed on good research in utility computing, networking, virtualization and web services provides some important benefits such as flexibility, cost reduction and easy availability for people using the system. These advantages are expected to increase the demand for more cloud services which further increase the installation of more clouds and its customer base. These demands lead to many technical issues such as applications of internet services, service oriented architecture including high scalability and availability, fault tolerance. So the core issue is to develop techniques for balancing of load effectively. It is clear from the fact that the measure and complexity makes these systems infeasible for assignment of centralized jobs to specific servers. So there is need of productive distributed solutions. In the current paper three proposed load balancing solutions for distributed environment is investigated. They are biased Random Sampling, Honeybee Foraging and Active Clustering.},
keywords={Cloud computing;Servers;Load management;Workstations;Task analysis;Resource management;Complexity theory;Cloud Computing; Cloud Services;SaaS;PaaS;IaaS;Active Clustering;Random Sampling;Honeybee Foraging},
doi={10.1109/CONFLUENCE.2019.8776974},
ISSN={},
month={Jan},}
@ARTICLE{7153530,
author={Zhao, Feng and Nian, Guodong and Jin, Hai and Yang, Laurence T. and Zhu, Yajun},
journal={IEEE Systems Journal}, title={A Hybrid eBusiness Software Metrics Framework for Decision Making in Cloud Computing Environment},
year={2017},
volume={11},
number={2},
pages={1049-1059},
abstract={Developing high-quality software is essential for eBusiness organizations to cope with drastic market competition. With the development of cloud computing technologies, eBusiness systems and applications pay more attention to open endedness. In a cloud computing environment, eBusiness systems have the ability to provide information technology resources on demand. Traditional software metric methods in distributed systems and applications are technical and project driven, making the market demand and internal practical operation not perfectly balanced within a cloud-computing-based eBusiness corporation. To address this issue, this paper presents a hybrid framework based on the goal/question/metric paradigm to evaluate the quality and efficiency of previous software products, projects, and development organizations in a cloud computing environment. In our approach, to support decision making at the project and organization levels, three angular metrics are used, i.e., project metrics, product metrics, and organization metrics. Furthermore, an improved radial-basis-function-based model is also provided to manage existing projects and design new projects. Experimental results on a well-known eBusiness organization show that the proposed framework is effective, efficient, and operational. Moreover, using the described decision-making algorithm, the predicted data are very close to actual results on the software cost, the fault rate, the development workload, etc., which are greatly helpful in achieving high-quality software.},
keywords={Computational modeling;Organizations;Software metrics;Cloud computing;Data models;Cloud computing;decision making;eBusiness;prediction;radial basis function (RBF);software metrics},
doi={10.1109/JSYST.2015.2443049},
ISSN={1937-9234},
month={June},}
@INPROCEEDINGS{8477227,
author={Li, Keqin},
booktitle={2018 IEEE 16th International Conference on Software Engineering Research, Management and Applications (SERA)}, title={Quantitative Modeling and Analytical Calculation of Elasticity in Cloud Computing},
year={2018},
volume={},
number={},
pages={3-3},
abstract={Elasticity is a fundamental feature of cloud computing and can be considered as a great advantage and a key benefit of cloud computing. Our research makes the following significant contributions. First, we present a new, quantitative, and formal definition of elasticity in cloud computing, i.e., the probability that the computing resources provided by a cloud platform match the current workload. Our definition is applicable to any cloud platform and can be easily measured and monitored. Furthermore, we develop an analytical model to study elasticity by treating a cloud platform as a queueing system, and use a continuous-time Markov chain (CTMC) model to precisely calculate the elasticity value of a cloud platform by using an analytical and numerical method based on just a few parameters, namely, the task arrival rate, the service rate, the virtual machine start-up and shut-down rates. In addition, we formally define auto-scaling schemes and point out that our model and method can be easily extended to handle arbitrarily sophisticated scaling schemes. Second, we apply our model and method to predict many other important properties of an elastic cloud computing system, such as average task response time, throughput, quality of service, average number of VMs, average number of busy VMs, utilization, cost, cost-performance ratio, productivity, and scalability. In fact, from a cloud consumer's point of view, these performance and cost metrics are even more important than the elasticity metric. Ourperformance and cost guarantee using the results developed in this talk. On the other hand, a cloud service provider can optimize its elastic scaling scheme to deliver the best cost-performance ratio. study in this talk has two significance. On one hand, a cloud service provider can predict its To the best of our knowledge, this is the first work that analytically and comprehensively studies elasticity, performance, and cost in cloud computing. Our model and method significantly contribute to the understanding of cloud elasticity and management of elastic cloud computing systems.},
keywords={Cloud computing;Elasticity;Computational modeling;Analytical models;Computer science;Numerical models;Task analysis},
doi={10.1109/SERA.2018.8477227},
ISSN={},
month={June},}
@INPROCEEDINGS{8477218,
author={Li, Keqin},
booktitle={2018 IEEE 16th International Conference on Software Engineering Research, Management and Applications (SERA)}, title={Quantitative Modeling and Analytical Calculation of Elasticity in Cloud Computing},
year={2018},
volume={},
number={},
pages={3-3},
abstract={Elasticity is a fundamental feature of cloud computing and can be considered as a great advantage and a key benefit of cloud computing. Our research makes the following significant contributions. First, we present a new, quantitative, and formal definition of elasticity in cloud computing, i.e., the probability that the computing resources provided by a cloud platform match the current workload. Our definition is applicable to any cloud platform and can be easily measured and monitored. Furthermore, we develop an analytical model to study elasticity by treating a cloud platform as a queueing system, and use a continuous-time Markov chain (CTMC) model to precisely calculate the elasticity value of a cloud platform by using an analytical and numerical method based on just a few parameters, namely, the task arrival rate, the service rate, the virtual machine start-up and shut-down rates. In addition, we formally define auto-scaling schemes and point out that our model and method can be easily extended to handle arbitrarily sophisticated scaling schemes. Second, we apply our model and method to predict many other important properties of an elastic cloud computing system, such as average task response time, throughput, quality of service, average number of VMs, average number of busy VMs, utilization, cost, cost-performance ratio, productivity, and scalability. In fact, from a cloud consumer's point of view, these performance and cost metrics are even more important than the elasticity metric. Ourperformance and cost guarantee using the results developed in this talk. On the other hand, a cloud service provider can optimize its elastic scaling scheme to deliver the best cost-performance ratio. study in this talk has two significance. On one hand, a cloud service provider can predict its To the best of our knowledge, this is the first work that analytically and comprehensively studies elasticity, performance, and cost in cloud computing. Our model and method significantly contribute to the understanding of cloud elasticity and management of elastic cloud computing systems.},
keywords={Cloud computing;Elasticity;Computational modeling;Analytical models;Computer science;Numerical models;Task analysis},
doi={10.1109/SERA.2018.8477218},
ISSN={},
month={June},}
@ARTICLE{9178326,
author={Ahamed Ahanger, Tariq and Tariq, Usman and Ibrahim, Atef and Ullah, Imdad and Bouteraa, Yassine},
journal={IEEE Access}, title={ANFIS-Inspired Smart Framework for Education Quality Assessment},
year={2020},
volume={8},
number={},
pages={175306-175318},
abstract={In the education sector, the Internet of Things (IoT) technology, integrated with fog-cloud computing, has offered productive services. Motivated by this, the smart recommender system offers the facility to the students to opt for the course and college based on the education quality. This research provides an IoT-fog-cloud paradigm for evaluating the academic environment with a perspective to enhance quality education. Specifically, IoT technology is incorporated to gather data about the academic environment that directly and indirectly influence the quality of education. Using the Bayesian Modeling Technique, the data collected is analyzed utilizing a fog-cloud computing framework to quantify the measure of the probability of education quality (PoEQ). Moreover, the Education Quality Assurance Index (EQAI) is calculated to analyze the quality assessment over a temporal scale. Furthermore, predictive decision-making is performed for quality estimation using the Adaptive Neuro-Fuzzy Inference System (ANFIS). The experimental simulation on 4 challenging datasets namely C1 (2124 instances), C2 (2112), C3 (2139), and C4 (2109) shows the effectiveness of the proposed framework. Simulation findings are compared with state-of-the-art techniques to measure the overall performance enhancement of the proposed system. Also, the mathematical analysis was carried out to assess the analytical performance of the proposed framework.},
keywords={Education;Quality assessment;Internet of Things;Analytical models;Decision making;Real-time systems;Recommender systems;Adaptive neuro-fuzzy inference system;smart recommender system;Internet of Things (IoT);fog-cloud computing},
doi={10.1109/ACCESS.2020.3019682},
ISSN={2169-3536},
month={},}
@ARTICLE{8391708,
author={Xu, Han and Qiu, Xiwei and Sheng, Yongpan and Luo, Liang and Xiang, Yanping},
journal={IEEE Access}, title={A Qos-Driven Approach to the Cloud Service Addressing Attributes of Security},
year={2018},
volume={6},
number={},
pages={34477-34487},
abstract={Recently, cloud computing has been widely used by relying on its powerful resource integration and computing abilities. In the cloud computing system (CCS), the quality of service (QoS) is an important service evaluation criterion from provider and client perspectives, which directly affects the client experience and profit of the cloud providers. Thus, a precise evaluation of the QoS can help the cloud provider develop reasonable resource allocation strategies for improving the client experience. The performance metric is usually adopted to quantify QoS. Many approaches and methods for evaluating performance have been widely studied. However, another important metric, i.e., security, does not receive adequate attention in the evaluation of QoS. More importantly, security also has serious effects on the performance metric, that is, complex security-performance (S-P) correlations. To address these issues, this paper first builds a Markov model to analyze and assess the security of the CCS that captures two critical security factors, i.e., malicious attacks and the security protection mechanism. Then, a hierarchical modeling approach is presented to flexibly build the connection between security and the service performance. Finally, we propose a correlation metric to quantify random service performance. This correlation metric comprehensively considers the effect of the security factors and thus becomes more realistic and precise. The experimental results reveal the dynamic change of performance caused by the security factors and demonstrate the important S-P correlation. Therefore, security cannot be ignored in the modeling and evaluation of the QoS metric.},
keywords={Security;Cloud computing;Quality of service;Measurement;Correlation;Servers;Computational modeling;Cloud service;quality of service;security modeling;performance modeling},
doi={10.1109/ACCESS.2018.2849594},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8251864,
author={Gustamas, R. Gargista and Shidik, Guruh Fajar},
booktitle={2017 International Seminar on Application for Technology of Information and Communication (iSemantic)}, title={Analysis of network infrastructure performance on cloud computing},
year={2017},
volume={},
number={},
pages={169-174},
abstract={Cloud Computing offers more convenience than conventional that provide custom Virtual Machine (VM) for any computation requirements. Network connectivity is closely related to the quality of cloud infrastructure itself. This paper focus in preliminary study to test the performance of cloud infrastructure with two type test. First test to measure Network performance and the second to measure cloud computation performance. OpenStack was used as cloud computing software infrastructure. We perform simple cloud infrastructure topology which is divided into three zones, there are Internal Zone, External Zone and Outside Cloud Infrastructure Zone. The parameter tested in this research are quality of bandwidth, latency, jitter and also Processing time during rendering process. The results show VM from simple topology cloud computing which is used to render video, able to perform processing time that slightly longer than using personal computer (PC) with same specification. The network side has been considering as a key of degradation render performance in cloud computing.},
keywords={Cloud computing;Rendering (computer graphics);Servers;Topology;Network topology;Bandwidth;Jitter;Cloud Computing;Network Performance;IAAS;Rendering},
doi={10.1109/ISEMANTIC.2017.8251864},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8073634,
author={Muralitharan, D. Boobala and Reebha, S. Arockia Babi and Saravanan, D.},
booktitle={2017 International Conference on IoT and Application (ICIOT)}, title={Optimization of performance and scheduling of HPC applications in cloud using cloudsim and scheduling approach},
year={2017},
volume={},
number={},
pages={1-6},
abstract={Cloud computing is emerging as a promising alternative to supercomputers for some High-Performance Computing (HPC) applications. Cloud computing is an essential component of the back bone of the Internet of Things (IoT). Clouds are needed to support huge numbers of interactions with varying quality requirements. Hence, Service quality will be a vital differentiator among cloud providers. In order to differentiate themselves from their competitors, cloud providers should offer best services that meet customers' expectations. A quality model can be used to represent, measure and compare the quality of the providers, such that a mutual understanding can be established among clouds take holders. With cloud as an additional deployment option, HPC users and providers faces the challenges of dealing with highly heterogeneous resources, where the variability spans across a wide range of processor configurations, interconnects, virtualization environments, and pricing models. HPC applications are increasingly being used in academia and laboratories for scientific research and in industries for business and analytics. Cloud computing offers the benefits of virtualization, elasticity of resources and elimination of cluster setup cost and time to HPC applications users. Effort was taken for holistic viewpoint to answer the questions - why and who should choose cloud for HPC, for what applications and how the cloud can be used for HPC? Comprehensive performance and cost evaluation and analysis of running a set of HPC applications on a range of platforms, varying from supercomputers to clouds was carried out. Further, performance of HPC applications is improved in cloud by optimizing HPC applications' characteristics for cloud and cloud virtualization mechanisms for HPC. In this paper, a novel heuristics for online application-aware job scheduling in multi-platform environments is presented. Experimental results and Simulations using CloudSim show that current clouds cannot substitute supercomputers but can effectively complement them.},
keywords={Cloud computing;Virtualization;Supercomputers;Computational modeling;Servers;Processor scheduling;Resource management;Cloud computing;High-Performance Computing (HPC);Job scheduling;CloudSim},
doi={10.1109/ICIOTA.2017.8073634},
ISSN={},
month={May},}
@ARTICLE{7845614,
author={Li, Keqin},
journal={IEEE Transactions on Cloud Computing}, title={Quantitative Modeling and Analytical Calculation of Elasticity in Cloud Computing},
year={2020},
volume={8},
number={4},
pages={1135-1148},
abstract={Elasticity is a fundamental feature of cloud computing and can be considered as a great advantage and a key benefit of cloud computing. One key challenge in cloud elasticity is lack of consensus on a quantifiable, measurable, observable, and calculable definition of elasticity and systematic approaches to modeling, quantifying, analyzing, and predicting elasticity. Another key challenge in cloud computing is lack of effective ways for prediction and optimization of performance and cost in an elastic cloud platform. The present paper makes the following significant contributions. First, we present a new, quantitative, and formal definition of elasticity in cloud computing, i.e., the probability that the computing resources provided by a cloud platform match the current workload. Our definition is applicable to any cloud platform and can be easily measured and monitored. Furthermore, we develop an analytical model to study elasticity by treating a cloud platform as a queueing system, and use a continuous-time Markov chain (CTMC) model to precisely calculate the elasticity value of a cloud platform by using an analytical and numerical method based on just a few parameters, namely, the task arrival rate, the service rate, the virtual machine start-up and shut-down rates. In addition, we formally define auto-scaling schemes and point out that our model and method can be easily extended to handle arbitrarily sophisticated scaling schemes. Second, we apply our model and method to predict many other important properties of an elastic cloud computing system, such as average task response time, throughput, quality of service, average number of VMs, average number of busy VMs, utilization, cost, cost-performance ratio, productivity, and scalability. In fact, from a cloud consumer's point of view, these performance and cost metrics are even more important than the elasticity metric. Our study in this paper has two significance. On one hand, a cloud service provider can predict its performance and cost guarantee using the results developed in this paper. On the other hand, a cloud service provider can optimize its elastic scaling scheme to deliver the best cost-performance ratio. To the best of our knowledge, this is the first paper that analytically and comprehensively studies elasticity, performance, and cost in cloud computing. Our model and method significantly contribute to the understanding of cloud elasticity and management of elastic cloud computing systems.},
keywords={Cloud computing;Markov processes;Computational modeling;Analytical models;Pricing;Quality of service;Optimization;Queueing analysis;Cloud computing;continuous-time Markov chain;cost-performance ratio;elasticity;queueing model},
doi={10.1109/TCC.2017.2665549},
ISSN={2168-7161},
month={Oct},}
@INPROCEEDINGS{7450805,
author={Lehrig, Sebastian and Eikerling, Hendrik and Becker, Steffen},
booktitle={2015 11th International ACM SIGSOFT Conference on Quality of Software Architectures (QoSA)}, title={Scalability, elasticity, and efficiency in cloud computing: A systematic literature review of definitions and metrics},
year={2015},
volume={},
number={},
pages={83-92},
abstract={Context In cloud computing, there is a multitude of definitions and metrics for scalability, elasticity, and efficiency. However, stakeholders have little guidance for choosing fitting definitions and metrics for these quality properties, thus leading to potential misunderstandings. For example, cloud consumers and providers cannot negotiate reliable and quantitative service level objectives directly understood by each stakeholder. Objectives Therefore, we examine existing definitions and metrics for these quality properties from the viewpoint of cloud consumers, cloud providers, and software architects with regard to commonly used concepts. Methods We execute a systematic literature review (SLR), reproducibly collecting common concepts in definitions and metrics for scalability, elasticity, and efficiency. As quality selection criteria, we assess whether existing literature differentiates the three properties, exemplifies metrics, and considers typical cloud characteristics and cloud roles. Results Our SLR yields 418 initial results from which we select 20 for in-depth evaluation based on our quality selection criteria. In our evaluation, we recommend concepts, definitions, and metrics for each property. Conclusions Software architects can use our recommendations to analyze the quality of cloud computing applications. Cloud providers and cloud consumers can specify service level objectives based on our metric suggestions.},
keywords={Cloud computing;Measurement;Elasticity;Scalability;Protocols;NIST;Systematic Literature Review;Definitions;Metrics;Cloud},
doi={10.1145/2737182.2737185},
ISSN={},
month={May},}
@ARTICLE{9139920,
author={Guerron, Ximena and Abrahão, Silvia and Insfran, Emilio and Fernández-Diego, Marta and González-Ladrón-De-Guevara, Fernando},
journal={IEEE Access}, title={A Taxonomy of Quality Metrics for Cloud Services},
year={2020},
volume={8},
number={},
pages={131461-131498},
abstract={A large number of metrics with which to assess the quality of cloud services have been proposed over the last years. However, this knowledge is still dispersed, and stakeholders have little or no guidance when choosing metrics that will be suitable to evaluate their cloud services. The objective of this paper is, therefore, to systematically identify, taxonomically classify, and compare existing quality of service (QoS) metrics in the cloud computing domain. We conducted a systematic literature review of 84 studies selected from a set of 4333 studies that were published from 2006 to November 2018. We specifically identified 470 metric operationalizations that were then classified using a taxonomy, which is also introduced in this paper. The data extracted from the metrics were subsequently analyzed using thematic analysis. The findings indicated that most metrics evaluate quality attributes related to performance efficiency (64%) and that there is a need for metrics that evaluate other characteristics, such as security and compatibility. The majority of the metrics are used during the Operation phase of the cloud services and are applied to the running service. Our results also revealed that metrics for cloud services are still in the early stages of maturity - only 10% of the metrics had been empirically validated. The proposed taxonomy can be used by practitioners as a guideline when specifying service level objectives or deciding which metric is best suited to the evaluation of their cloud services, and by researchers as a comprehensive quality framework in which to evaluate their approaches.},
keywords={Measurement;Cloud computing;Taxonomy;Quality of service;Systematics;NIST;Elasticity;Software quality;metrics;cloud services;systematic literature review},
doi={10.1109/ACCESS.2020.3009079},
ISSN={2169-3536},
month={},}
@ARTICLE{6740846,
author={Zheng, Xianrong and Martin, Patrick and Brohman, Kathryn and Xu, Li Da},
journal={IEEE Transactions on Industrial Informatics}, title={CLOUDQUAL: A Quality Model for Cloud Services},
year={2014},
volume={10},
number={2},
pages={1527-1536},
abstract={Cloud computing is an important component of the backbone of the Internet of Things (IoT). Clouds will be required to support large numbers of interactions with varying quality requirements. Service quality will therefore be an important differentiator among cloud providers. In order to distinguish themselves from their competitors, cloud providers should offer superior services that meet customers' expectations. A quality model can be used to represent, measure, and compare the quality of the providers, such that a mutual understanding can be established among cloud stakeholders. In this paper, we take a service perspective and initiate a quality model named CLOUDQUAL for cloud services. It is a model with quality dimensions and metrics that targets general cloud services. CLOUDQUAL contains six quality dimensions, i.e., usability, availability, reliability, responsiveness, security, and elasticity, of which usability is subjective, whereas the others are objective. To demonstrate the effectiveness of CLOUDQUAL, we conduct empirical case studies on three storage clouds. Results show that CLOUDQUAL can evaluate their quality. To demonstrate its soundness, we validate CLOUDQUAL with standard criteria and show that it can differentiate service quality.},
keywords={Cloud computing;Security;Availability;Quality of service;Measurement;Cloud computing;Internet of Things (IoT);quality model;validity criteria},
doi={10.1109/TII.2014.2306329},
ISSN={1941-0050},
month={May},}
@INPROCEEDINGS{7207386,
author={Cedillo, Priscila and Jimenez-Gomez, Javier and Abrahao, Silvia and Insfran, Emilio},
booktitle={2015 IEEE International Conference on Services Computing}, title={Towards a Monitoring Middleware for Cloud Services},
year={2015},
volume={},
number={},
pages={451-458},
abstract={Cloud Computing represents a new trend in the development and use of software. Many organizations are currently adopting the use of services that are hosted in the cloud by employing the Software as a Service (SaaS) model. Services are typically accompanied by a Service Level Agreement (SLA), which defines the quality terms that a provider offers to its customers. Many monitoring tools have been proposed to report compliance with the SLA. However, they have some limitations when changes to monitoring requirements must be made and because of the complexity involved in capturing low-level raw data from services at runtime. In this paper, we propose the design of a platform-independent monitoring middleware for cloud services, which supports the monitoring of SLA compliance and provides a report containing SLA violations that may help stakeholders to make decisions regarding how to improve the quality of cloud services. Moreover, our middleware definition is based on the use of models@run.time, which allows the dynamic change of quality requirements and/or the dynamic selection of different metric operationalizations (i.e., Calculation formulas) with which to measure the quality of services. In order to demonstrate the feasibility of our approach, we show the instantiation of the proposed middleware that can be used to monitor services when deployed on the Microsoft Azure© platform.},
keywords={Monitoring;Middleware;Measurement;Radiation detectors;Engines;Runtime;Software as a service;Cloud Computing;Software as a Service;Monitoring;Middleware;Quality of Service;Models@run.time},
doi={10.1109/SCC.2015.68},
ISSN={},
month={June},}
@INPROCEEDINGS{8509050,
author={Kumar Koditala, Nikhil and Shekar Pandey, Purnendu},
booktitle={2018 International Conference on Research in Intelligent and Computing in Engineering (RICE)}, title={Water Quality Monitoring System Using IoT and Machine Learning},
year={2018},
volume={},
number={},
pages={1-5},
abstract={World Economic Forum ranked drinking water crisis as one of the global risk, due to which around 200 children are dying per day. Drinking unsafe water alone causes around 3.4 million deaths per year. Despite the advancements in technology, sufficient quality measures are not present to measure the quality of drinking water. By focusing on the above issue, this paper proposes a low cost water quality monitoring system using emerging technologies such as IoT, Machine Learning and Cloud Computing which can replace traditional way of quality monitoring. This helps in saving people of rural areas from various dangerous diseases such as fluorosis, bone deformities etc. The proposed model also has a capacity to control temperature of water and adjusts it so as to suit environment temperature. Based on our model we have achieved R-squared score of 0.933.},
keywords={Temperature sensors;Monitoring;Temperature measurement;Cloud computing;Sensor systems;Electronic mail;Water quality monitoring;Internet of Things;Machine learning;Cloud Computing;MQTT;Rural Development},
doi={10.1109/RICE.2018.8509050},
ISSN={},
month={Aug},}
@INPROCEEDINGS{7852595,
author={Rodziah binti Atan},
booktitle={2016 2nd International Conference on Science in Information Technology (ICSITech)}, title={Enhancing service quality through Service Level Agreement (SLA) full implementation},
year={2016},
volume={},
number={},
pages={1-1},
abstract={Various SLA monitoring systems are proposed by different features and abilities to evaluate the agreed SLA. The current SLA monitoring systems in cloud computing for its structural, behavioral characteristics and situation are also in place. The systematic reviews of a well-known methods and approaches shows a significant numbers of researches been done in this area. Based on the number of effort and researches, the quality of services should proportionately increase alongside them. We look this matter from the perspectives of enforcement, that evident the stand of quality of services. Service Level Agreement (SLA) enforcement impact measures is a potential research area to be explored. Assumptions that this study is making are, SLA management will become better by a firm enforcement, where every customers are responsible to launch report of bugs or mischief of services such as unsatisfactory quality or service unavailability to a collection pool, and the provider will react immediately to the complaints so that the total downtime not exceeding the SLA value, with efficient enforcement. This study establishes fundamental theory to measure enforcement impact to SLA monitoring and management. We proposed eight activity phases from formulating until analyzing and decision formation. Descriptive statistics is utilized to analyze the extracted data. The SLA validation detection is the most frequent purpose of SLA monitoring systems in cloud by 58% and throughput is checked as an attribute target by 28%. The self-monitoring SLA, self-healing system, hierarchical structure are recognized points of SLA monitoring systems which need improvement before the enforcement could be based upon.},
keywords={Service Level Agreement;enforcement;monitoring;cloud computing;quality of service},
doi={10.1109/ICSITech.2016.7852595},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8350688,
author={Indrawati and Puspita, Fitri Maya and Erlita, Sri and Nadeak, Inosensius and Arisha, Bella},
booktitle={2018 International Conference on Information and Communications Technology (ICOIACT)}, title={LINGO-based optimization problem of cloud computing of bandwidth consumption in the Internet},
year={2018},
volume={},
number={},
pages={436-441},
abstract={Optimization problem is an important issue in the network Internet. With the dynamic approach in modeling networks, we can strengthen network performance and ensure that the cost will be minimized and profit of provider can be maximized. This research aims to study, analyze the scheme for cloud networking and formulate a plan of new models of dynamic networks and can work under a cloud of wireless networks. Mixed Integer Non Linear Programming (MINLP) is an integer linear programming model to optimize a particular purpose. In MINLP process, the objective function is determined beforehand. The optimal solution of MINLP lies in the majority of decision variables that can be an integer, Boolean or fractions. Model Cloud computing is one of the areas that is most discussed and promising in modern computer science. Cloud computing is a computing model in which resources such as processors, storage, network and software information that can be accessed by customers via the Internet. In the cloud computing implementation, we require a good traffic for performance and reliability of the system is maintained. QoS (Quality of Services) refers to the distribution of bandwidth. QoS is used as a measure of whether or not the characteristics of the network to meet the needs of different services that use the same infrastructure. Tests carried out on the quality of service parameters, namely, delay, packet loss, throughput and bandwidth. To formulate and solve optimization problems used LINGO software applications. The results show that by designing the optimization problem, the cost of consumption of the demand of the internet can be reduced; the maximum profit for the provider can be increased.},
keywords={Cloud computing;Bandwidth;Servers;Optimization;Mathematical model;Web and internet services;Pricing;MINLP;cloud computing;QoS;LINGO;optimal solution},
doi={10.1109/ICOIACT.2018.8350688},
ISSN={},
month={March},}
@INPROCEEDINGS{7536961,
author={Chaemin Seong and Minsoo Jang and Kyungshik Lim},
booktitle={2016 Eighth International Conference on Ubiquitous and Future Networks (ICUFN)}, title={Context-aware HTTP Adaptive Streaming in mobile cloud environments},
year={2016},
volume={},
number={},
pages={1062-1067},
abstract={With advances of cloud computing, seamless video streaming from video server to cloud client has been one of technical challenges for multimedia cloud applications. Especially in case that Desktop-as-a-Service (DaaS) as a major cloud application is deployed via wireless networks, it could raise a new set of issues to be addressed. To solve the problem, we propose a Cloud-based Context-aware HTTP Adaptive Streaming (C2HAS) agent located at cloud server. The goal of the agent is to maximize the video quality of seamless streaming perceived by cloud client, given a dynamically changing network context. From network context we derive a major metric for adapting and maximizing the video quality perceived by cloud clients, which is the throughput ratio of backbone networks and access networks. Based on the metric, we can provide a maximal quality of seamless video streaming to cloud users who might be connected via distant and/or lossy wireless links. The experimental performance analysis shows that the C2HAS agent could be a viable solution for cloud-based multimedia applications.},
keywords={Streaming media;Cloud computing;Servers;Context;Mobile communication;Video recording;Quality assessment;context awareness;HTTP adaptive streaming;virtual desktop infrastructure;mobile cloud computing component},
doi={10.1109/ICUFN.2016.7536961},
ISSN={2165-8536},
month={July},}
@INPROCEEDINGS{7498925,
author={Karadimce, Aleksandar and Davcev, Danco},
booktitle={2016 Eighth International Conference on Quality of Multimedia Experience (QoMEX)}, title={Perception of quality in cloud computing based services},
year={2016},
volume={},
number={},
pages={1-6},
abstract={Cloud computing consists of hardware and software resources, available on the Internet as a set of services for users. This technology aims to provide stable, reliable and encapsulated dynamic information and communication environment for end users to be able to simultaneously access shared resources that are available anywhere and at any time. The major benefit of cloud computing is used to improve the perception of quality for the client requests. Commonly in the communications industry, the term Quality of Experience (QoE) is used as a measure for the user perception of service from the user's point of view. In this research, we propose a classification of cloud-based services based on objective and subjective characteristics for perception of quality. The main contribution in this paper is a novel approach based on Bayesian modeling for efficient assessment of QoE perception for cloud-based services considering the level of interactivity, service complexity, usage domain, and multimedia-intensity.},
keywords={Cloud computing;Quality of service;Multimedia communication;Mobile communication;Mobile handsets;Computational modeling;Bayes methods;cloud services;perception of quality;QoE;bayesian network},
doi={10.1109/QoMEX.2016.7498925},
ISSN={},
month={June},}
@ARTICLE{7501820,
author={Chen, Yunliang and Wang, Lizhe and Chen, Xiaodao and Ranjan, Rajiv and Zomaya, Albert Y. and Zhou, Yuchen and Hu, Shiyan},
journal={IEEE Transactions on Cloud Computing}, title={Stochastic Workload Scheduling for Uncoordinated Datacenter Clouds with Multiple QoS Constraints},
year={2020},
volume={8},
number={4},
pages={1284-1295},
abstract={Cloud computing is now a well-adopted computing paradigm. With unprecedented scalability and flexibility, the computational cloud is able to carry out large scale computing tasks in parallel. The datacenter cloud is a new cloud computing model that uses multi-datacenter architectures for large scale massive data processing or computing. In datacenter cloud computing, the overall efficiency of the cloud depends largely on the workload scheduler, which allocates clients' tasks to different Cloud datacenters. Developing high performance workload scheduling techniques in Cloud computing imposes a great challenge which has been extensively studied. Most previous works aim only at minimizing the completion time of all tasks. However, timeliness is not the only concern, reliability and security are also very important. In this work, a comprehensive Quality of Service (QoS) model is proposed to measure the overall performance of datacenter clouds. An advanced Cross-Entropy based stochastic scheduling (CESS) algorithm is developed to optimize the accumulative QoS and sojourn time of all tasks. Experimental results show that our algorithm improves accumulative QoS and sojourn time by up to 56.1 and 25.4 percent respectively compared to the baseline algorithm. The runtime of our algorithm grows only linearly with the number of Cloud datacenters and tasks. Given the same arrival rate and service rate ratio, our algorithm steadily generates scheduling solutions with satisfactory QoS without sacrificing sojourn time.},
keywords={Cloud computing;Quality of service;Processor scheduling;Computational modeling;Scheduling;Data centers;Resource management;Cloud computing;datacenter clouds;quality of service;workload scheduling},
doi={10.1109/TCC.2016.2586048},
ISSN={2168-7161},
month={Oct},}
@INPROCEEDINGS{8422956,
author={Skourletopoulos, Georgios and Mavromoustakis, Constandinos X. and Mastorakis, George and Batalla, Jordi Mongay and Song, Houbing and Sahalos, John N. and Pallis, Evangelos},
booktitle={2018 IEEE International Conference on Communications (ICC)}, title={Elasticity Debt Analytics Exploitation for Green Mobile Cloud Computing: An Equilibrium Model},
year={2018},
volume={},
number={},
pages={1-6},
abstract={Mobile cloud computing is being accepted as the model for mobile users to ubiquitously access a shared pool of cloud computing resources, data and services on-demand. In this context, elasticity debt analytics can be harnessed as a measure for efficient scheduling of cloud resources and guarantee of quality of service requirements. This paper proposes a novel green-driven, game theoretic approach to minimizing the elasticity debt on mobile cloud-based service level, investigating the case when a task is offloaded, scheduled and executed on a mobile cloud computing system. The decision to offload a mobile device user's task on cloud affects the level of elasticity debt minimization for the provided services. The research problem is formulated as an elasticity debt quantification game, elaborating on an incentive mechanism to: (a) predict elasticity debt and mitigate the risk of service overutilization, (b) achieve scalability as the number of mobile device user requests for cloud resources increases or decreases accordingly, and (c) optimize cloud resource provisioning, parameterizing the current pool of active users per service. The experimental results prove the effectiveness of the equilibrium model, which allocates the mobile device user requests to high elasticity debt-level services and facilitate elasticity debt minimization for greener mobile cloud computing environments.},
keywords={Elasticity;Cloud computing;Mobile handsets;Games;Computational modeling;Minimization;Green products},
doi={10.1109/ICC.2018.8422956},
ISSN={1938-1883},
month={May},}
@INPROCEEDINGS{8251862,
author={Tirta, Manggiardi B.W. and Shidik, Guruh Fajar},
booktitle={2017 International Seminar on Application for Technology of Information and Communication (iSemantic)}, title={Evaluation performance of cloud computing with network attached storage for video render},
year={2017},
volume={},
number={},
pages={157-163},
abstract={One of the benefits of Cloud Computing is the use of virtual machines for efficiency and resource utilization. The study utilizes a virtual machine on cloud computing technology for video rendering needs and is integrated with Network Attached Storage (NAS) storage methods, a centralized storage method that uses network media to connect storage media with users. The rendering process is then analyzed using several metering tools to measure the rendering time frame, VM Utilization, network performance, and NAS Network Performance. The results show that rendering takes longer, then CPU Utilization shows a maximum of 77%, Memory Utilization 55%, and Network Utilization 10%. The bandwidth available between NAS and VM storage in a cloud computing system only generates a maximum of 295.1 Mbps, which should reach 1 Gbps. The quality of video rendering in VM cloud computing shows similar results with rendering on physical computers, the results obtained from testing between frames using mean-square error algorithm.},
keywords={Rendering (computer graphics);Cloud computing;Testing;Servers;Process control;Virtual machining;Central Processing Unit;cloud computing;video render;network attached storage},
doi={10.1109/ISEMANTIC.2017.8251862},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9091376,
author={Zhang, Ziyi and Guo, Caishan and Sun, Yuyan and Hu, Kaiqiang and Wang, Qinghai and Wu, Yuzhao and Cai, Zexiang},
booktitle={2019 IEEE International Conference on Smart Cloud (SmartCloud)}, title={Cloud Computing Placement Optimization Under Ubiquitous Power Internet of Things Background},
year={2019},
volume={},
number={},
pages={13-18},
abstract={With the development of power system and the introduction of the Energy Internet, the implementation of Ubiquitous Power Internet of Things (UPIoT) is necessary for power utilities to meet the demands of Integrated Energy Applications. Massive heterogeneous data from various devices surge into power system via UPIoT, which puts heavy burden on data processing capabilities of power system. Cloud computing is an effective measure to provide big data processing capabilities and the establishment of cloud computing for power system is of great significance. Firstly, the architecture of UPIoT and the cloud computing system based on UPIoT background are analyzed. Considering the characteristics of power system, a distributed cloud computing architecture for power system is proposed. A coordinated placement optimization strategy based on minimum cost and satisfaction of quality of service for the proposed architecture is formulated. Based on a given case, the placement optimization simulations are studied. The simulation results prove that the proposed architecture is cost-efficient and the proposed optimization strategy is effective and efficient.},
keywords={Cloud computing;Power systems;Computer architecture;Power generation;Data centers;Optimization;Quality of service;cloud computing;edge computing;ubiquitous power internet of things;placement optimization;cost;quality of service},
doi={10.1109/SmartCloud.2019.00012},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9242798,
author={Abdulwahid, Ali Hadi},
booktitle={2020 9th International Conference on Renewable Energy Research and Application (ICRERA)}, title={IoT Based Water Quality Monitoring System for Rural Areas},
year={2020},
volume={},
number={},
pages={279-282},
abstract={To ensure that safety is guaranteed, it is essential to implement monitoring in real-time for the quality of potable water. This work is about the use of Internet of Things (IoT) technology to develop an affordable system to control water quality in real-time. Several sensors are integrated into the system to measure various chemical and physical water properties, such as conductivity, pH, turbidity, and temperature. The core controller, which can also be the microprocessor, manages the processing of data captured by the sensor. The visualization of data can be accomplished on cloud computing via the Internet.},
keywords={Sensors;Temperature sensors;Temperature measurement;Water quality;Monitoring;Sensor systems;Internet of Things;water quality monitoring;Internet of Things;Arduino;cloud computing},
doi={10.1109/ICRERA49962.2020.9242798},
ISSN={2572-6013},
month={Sep.},}
@ARTICLE{8758137,
author={Azadi, Majid and Emrouznejad, Ali and Ramezani, Fahimeh and Hussain, Farookh K.},
journal={IEEE Transactions on Cloud Computing}, title={Efficiency measurement of cloud service providers using network data envelopment analysis},
year={2019},
volume={},
number={},
pages={1-1},
abstract={An increasing number of organizations and businesses around the world use cloud computing services to improve their performance in the competitive marketplace. However, one of the biggest challenges in using cloud computing services is performance measurement and the selection of the best cloud service providers (CSPs) based on quality of service (QoS) requirements (Duan, 2017). To address this shortcoming in this article we propose a network data envelopment analysis (DEA) method in measuring the efficiency of CSPs. When network dimensions are taken into consideration, a more comprehensive analysis is enabled where divisional efficiency is reflected in overall efficiency estimates. This helps managers and decision makers in organizations to make accurate decisions in selecting cloud services. In the current study, variable returns to scale (VRS), the non-oriented network slacks-based measure (SBM) model and input-oriented and output-oriented SBM models are applied to measure the performance of 18 CSPs. The obtained results show the superiority of the network DEA model and they also demonstrate that the proposed model can evaluate and rank CSPs much better than compared to traditional DEA models.},
keywords={Cloud computing;Quality of service;Measurement;Analytical models;Computational modeling;Data envelopment analysis;Information technology;Cloud service providers (CSPs);Performance measures;Efficiency measurement;Data Envelopment Analysis;Network slacks-based measure (SBM) model},
doi={10.1109/TCC.2019.2927340},
ISSN={2168-7161},
month={},}
@INPROCEEDINGS{9302797,
author={Flinck Lindström, Sebastian and Wetterberg, Markus and Carlsson, Niklas},
booktitle={2020 IEEE/ACM 13th International Conference on Utility and Cloud Computing (UCC)}, title={Cloud Gaming: A QoE Study of Fast-paced Single-player and Multiplayer Gaming},
year={2020},
volume={},
number={},
pages={34-45},
abstract={Cloud computing offers an attractive solution for modern computer games. By moving the increasingly demanding graphical calculations (e.g., generation of real-time video streams) to the cloud, consumers can play games using small, cheap devices. While cloud gaming has many advantages and is increasingly deployed, not much work has been done to understand the underlying factors impacting players' user experience when moving the processing to the cloud. In this paper, we study the impact of the quality of service (QoS) factors most affecting the players' quality of experience (QoE) and in-game performance. In particular, these relationships are studied from multiple perspectives using complementing analysis methods applied on the data collected via instrumented user tests. During the tests, we manipulated the players' network conditions and collected low-level QoS metrics and in-game performance, and after each game, the users answered questions capturing their QoE. New insights are provided using different correlation/auto-correlation/cross-correlation statistics, regression models, and a thorough breakdown of the QoS metric most strongly correlated with the users' QoE. We find that the frame age is the most important QoS metric for predicting in-game performance and QoE, and that spikes in the frame age caused by large frame transfers can have extended negative impact as they can cause processing backlogs. The study emphasizes the need to carefully consider and optimize the parts making up the frame age, including dependencies between the processing steps. By lowering the frame age, more enjoyable gaming experiences can be provided.},
keywords={Games;Quality of experience;Measurement;Quality of service;Servers;Packet loss;Cloud gaming;Cloud computing;cloud gaming;QoE;frame age;single-player;multiplayer;gaming;fast-paced;performance},
doi={10.1109/UCC48980.2020.00023},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8883458,
author={Biondi, Katalina and Al-Masri, Eyhab and Baiocchi, Orlando and Jeyaraman, Suganya and Pospisil, Eric and Boyer, Graham and de Souza, Cleonilson Protasio},
booktitle={2019 International Conference in Engineering Applications (ICEA)}, title={Air Pollution Detection System using Edge Computing},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Existing solutions to measuring air quality can be expensive and potentially mutes high air pollution events. The IoT Pollution Project is exploring how IoT concepts can be applied with smart systems to detect pollution in real-time. Using a network of Raspberry Pi prototypes, the project aims to measure heavily populated areas around the City of Tacoma, while building a real-time interface measuring current air quality. The project also explores the use of edge computing as an alternative to cloud computing. The vast expansion of IoT devices poses threats to the infrastructure of cloud computing as more devices process and store data to the cloud. The project demonstrates how edge devices can alleviate the work done on the cloud by calculating rolling averages over a time interval on the edge device and then deploying the data to the cloud. The project uses Microsoft Azure Framework, IoT concepts and edge computing concepts to build the project architecture.},
keywords={Cloud computing;Air pollution;Edge computing;Atmospheric measurements;Pollution measurement;Internet of Things;Raspberry Pi;Microsoft Azure;LoRa;Pollution Detection;Environmental Monitoring;Real-Time Data;IoT;Edge Computing;Cloud Computing;Air Quality},
doi={10.1109/CEAP.2019.8883458},
ISSN={},
month={July},}
@INPROCEEDINGS{7312289,
author={Zhang, Xiaodong and Dechen, Zhan and Nie, Lanshun and Zhao, Tianqi and Xiong, Xiao},
booktitle={2014 International Conference on Service Sciences}, title={An Optimal Service-Selection Model Based on Capability and Quality of Resource Service},
year={2014},
volume={},
number={},
pages={47-52},
abstract={Most of the researches on optimal service selection are based on the assumption that the capabilities of the services fully meet the requirements. Their limitation is the ignorance of the resources which is the basic factor supporting the implementation of services and it may cause a waste of resources. In cloud computing environment which benefits from its large-scale, there are a large number of resources. Therefore, the waste of resources in it would be a big problem. This paper introduces 'service equivalent' as the basic metric to measure the capabilities of service resources and proposes an optimal service selection model based on capability and quality of service resources and algorithm, in order to solve the issues about the matching capability of service resource and the optimal selection of service resource based on quality. Finally it proves that the model can effectively reduce the waste of resources by the test, which achieves the expected goal.},
keywords={Quality of service;Optimization;Heuristic algorithms;Business;Vehicles;Algorithm design and analysis;Load modeling;service capability matching;service equivalent;service capability model;QoS model},
doi={10.1109/ICSS.2014.39},
ISSN={2165-3836},
month={May},}
@INPROCEEDINGS{8005362,
author={Brataas, Grunnar and Herbst, Nikolas and Ivansek, Simon and Polutnik, Jure},
booktitle={2017 IEEE International Conference on Autonomic Computing (ICAC)}, title={Scalability Analysis of Cloud Software Services},
year={2017},
volume={},
number={},
pages={285-292},
abstract={Cloud computing theoretically offers its customers unlimited cloud resources. However, the scalability of software services is often limited by their underlying architecture. In contrast to current scalability analysis approaches, we make work parameters, quality thresholds, as well as the resource space explicit in a conceptually consistent set of equations. We propose two scalability metric functions based on these equations. The resource scalability metric function describes the relation between the capacity of the multi-tier cloud software service and its use of cloud resources, whereas the cost scalability metric function replaces cloud resources with cost. We validate using the Cloud-Store application. CloudStore follows the TPC-W specification, representing an online book store. We have experimented with 21 different public Amazon Web Service configurations and two private OpenStack configurations.},
keywords={Measurement;Scalability;Cloud computing;Computer architecture;Aerospace electronics;cloud;service;scalability;metric;measurement;cost},
doi={10.1109/ICAC.2017.34},
ISSN={2474-0756},
month={July},}
@INPROCEEDINGS{8364051,
author={Ramos da Paixão, Ermínio Augusto and Vieira, Rafael Fogarolli and Araújo, Welton Vasconcelos and Cardoso, Diego Lisboa},
booktitle={2018 Third International Conference on Fog and Mobile Edge Computing (FMEC)}, title={Optimized load balancing by dynamic BBU-RRH mapping in C-RAN architecture},
year={2018},
volume={},
number={},
pages={100-104},
abstract={Cloud Radio Access Network (C-RAN) is one of the key architectures for the next generation of mobile networks (5G) that aim at centralized processing and management, collaborative radios and cloud computing in real time. These features enable the architectures to make a rational adjustment to the connection between remote radio heads (RRHs) and baseband units (BBUs) dynamically. This is important since if this feature is neglected, it can cause difficulties such as blocked calls and low-quality connections. This study investigates this area and proposes an optimized mapping model for RRH-BBU that seeks a more equitable and effective balancing. The Key Performance Indicator (KPI) of blocked calls was used for this to measure the quality of service (QoS). A particle Swarm algorithm (PSO) was created to minimize the number of blocked calls and additionally balancing the processing load between the BBUs. Scenario from literature was employed that consists of 19 RRHs distributed in a geographic area, which can be mapped in a BBU pool that manages two BBUs with three sectors each. The initial configuration on average, led to 80 blocked calls. The results obtained by the PSO show that there was a reduction of up to 100% of blocked calls, as well as a more equitable load distribution between the BBUs. Additionally, realistic scenarios with different user profiles were also included, since they demonstrate that these factors have a direct impact on the load generated in the BBUs and hence, affect their balance.},
keywords={Computer architecture;Resource management;Quality of service;Load modeling;Edge computing;Radio access networks;Mathematical model;C-RAN;RRHs;BBUs;PSO;balance},
doi={10.1109/FMEC.2018.8364051},
ISSN={},
month={April},}
@ARTICLE{7066939,
author={Lillo-Castellano, J. M. and Mora-Jiménez, I. and Santiago-Mozos, R. and Chavarría-Asso, F. and Cano-González, A. and García-Alberola, A. and Rojo-Álvarez, J. L.},
journal={IEEE Journal of Biomedical and Health Informatics}, title={Symmetrical Compression Distance for Arrhythmia Discrimination in Cloud-Based Big-Data Services},
year={2015},
volume={19},
number={4},
pages={1253-1263},
abstract={The current development of cloud computing is completely changing the paradigm of data knowledge extraction in huge databases. An example of this technology in the cardiac arrhythmia field is the SCOOP platform, a national-level scientific cloud-based big data service for implantable cardioverter defibrillators. In this scenario, we here propose a new methodology for automatic classification of intracardiac electrograms (EGMs) in a cloud computing system, designed for minimal signal preprocessing. A new compression-based similarity measure (CSM) is created for low computational burden, so-called weighted fast compression distance, which provides better performance when compared with other CSMs in the literature. Using simple machine learning techniques, a set of 6848 EGMs extracted from SCOOP platform were classified into seven cardiac arrhythmia classes and one noise class, reaching near to 90% accuracy when previous patient arrhythmia information was available and 63% otherwise, hence overcoming in all cases the classification provided by the majority class. Results show that this methodology can be used as a high-quality service of cloud computing, providing support to physicians for improving the knowledge on patient diagnosis.},
keywords={Dictionaries;Informatics;Databases;Biomedical measurement;Heart beat;Hospitals;Complexity theory;Cardiac Arrhythmia Classification;Implantable Defibrillator;Intracardiac Electrogram;Weighted Fast Compression Distance;Big Data Analytics.;Big data analytics;cardiac arrhythmia classification;implantable defibrillator;intracardiac electrogram;weighted fast compression distance},
doi={10.1109/JBHI.2015.2412175},
ISSN={2168-2208},
month={July},}
@ARTICLE{8130579,
author={Kumar, Neeraj and Chilamkurti, Naveen and Zeadally, Sherali and Jeong, Young-Sik},
journal={The Computer Journal}, title={Achieving Quality of Service (QoS) Using Resource Allocation and Adaptive Scheduling in Cloud Computing with Grid Support},
year={2014},
volume={57},
number={2},
pages={281-290},
abstract={In the past few years, cloud computing has emerged as a new reliable, scalable and flexible virtual computing environment (VCE). In this new VCE, users can use the available resources as a service by paying for that service according to the time for which these resources are used. It remains a significant challenge to achieve quality of service (QoS) in a VCE with the available resources. The main goal is to schedule the available resources so that the overall QoS delivered by the VCE can be improved. Resources are assumed to be located both at local and global sites. We propose a three-step scheme: resource selection, scheduling of users requests with shared resources and a new Resource Allocation and Adaptive Job Scheduling algorithm, which improves the QoS delivered by the cloud. For job scheduling, we define a new weight metric that is used to efficiently schedule jobs competing for available resources. Our proposed strategy increases the reliability of resource availability for a job and reduces the job completion time, which in turn increases the QoS delivered to end-users. We evaluate our proposed scheme using well-known heuristics. The results obtained show that our proposed scheme considerably reduces the job execution time, and increases the reliability of resource availability for job execution and throughput.},
keywords={cloud computing;job scheduling;quality of service;grid;performance},
doi={10.1093/comjnl/bxt024},
ISSN={1460-2067},
month={Feb},}
@ARTICLE{6671599,
author={Shen, Haiying and Lin, Yuhua and Li, Ting},
journal={IEEE Transactions on Computers}, title={Combining Efficiency, Fidelity, and Flexibility in Resource Information Services},
year={2015},
volume={64},
number={2},
pages={353-367},
abstract={A large-scale resource sharing system (e.g., collaborative cloud computing and grid computing) creates a virtual supercomputer by providing an infrastructure for sharing tremendous amounts of resources (e.g., computing, storage, and data) distributed over the Internet. A resource information service, which collects resource data and provides resource search functionality for locating desired resources, is a crucial component of the resource sharing system. In addition to resource discovery speed and cost (i.e., efficiency), the ability to accurately locate all satisfying resources (i.e., fidelity) is also an important metric for evaluating service quality. Previously, a number of resource information service systems have been proposed based on Distributed Hash Tables (DHTs) that offer scalable key-based lookup functions. However, these systems either achieve high fidelity at low efficiency, or high efficiency at low fidelity. Moreover, some systems have limited flexibility by only providing exact-matching services or by describing a resource using a pre-defined list of attributes. This paper presents a resource information service that offers high efficiency and fidelity without restricting resource expressiveness, while also providing a similar-matching service. Extensive simulation and PlanetLab experimental results show that the proposed service outperforms other services in terms of efficiency, fidelity, and flexibility; it dramatically reduces overhead and yields significant enhancements in efficiency and fidelity.},
keywords={Information services;Vectors;Resource management;Transforms;Central Processing Unit;Cloud computing;Aerospace electronics;Resource sharing systems;collaborative cloud computing (CCC);grid computing;resource information service;resource discovery;distributed hash table (DHT)},
doi={10.1109/TC.2013.222},
ISSN={1557-9956},
month={Feb},}
@INPROCEEDINGS{9292150,
author={Gavra, Vlad-Dacian and Pop, Ovidiu Aurel},
booktitle={2020 IEEE 26th International Symposium for Design and Technology in Electronic Packaging (SIITME)}, title={Usage of ZigBee and LoRa wireless technologies in IoT systems},
year={2020},
volume={},
number={},
pages={221-224},
abstract={IoT systems are based sensors and actuators to enable ubiquitous sensing to measure environment parameters from delicate ecologies and natural environments to urban environments. By connecting these sensors and actuators to a big network, like internet, an automatization can be performed, and repetitive actions can be done in background by the IoT ecosystem and save a lot of time. IoT can do such things in Home Automation, Smart Cities and even in Air Quality analysis. IoT solution are dependent on the way sensors are transmitting data to cloud or up to the internet. This paper will present the benefits of using Zig Bee instead of using traditional Wi-Fi sensor and present some of the characteristics of LoRa sensors. Cloud computing contributed to the expansion of the IoT systems by offloading local IoT devices of computation intensive tasks. Fog computing brings Cloud closer to the sensors and by doing this minimize communication latencies.},
keywords={Zigbee;Sensors;Protocols;Edge computing;Internet of Things;Wireless sensor networks;Wireless communication;IoT;ZigBEE;LoRa},
doi={10.1109/SIITME50350.2020.9292150},
ISSN={2642-7036},
month={Oct},}
@INPROCEEDINGS{7335004,
author={Dai, Yangyang and Lou, Yuansheng and Lu, Xin},
booktitle={2015 7th International Conference on Intelligent Human-Machine Systems and Cybernetics}, title={A Task Scheduling Algorithm Based on Genetic Algorithm and Ant Colony Optimization Algorithm with Multi-QoS Constraints in Cloud Computing},
year={2015},
volume={2},
number={},
pages={428-431},
abstract={Task scheduling problem in cloud computing environment is NP-hard problem, which is difficult to obtain exact optimal solution and is suitable for using intelligent optimization algorithms to approximate the optimal solution. Meanwhile, quality of service (QoS) is an important indicator to measure the performance of task scheduling. In this paper, a novel task scheduling algorithm MQoS-GAAC with multi-QoS constraints is proposed, considering the time-consuming, expenditure, security and reliability in the scheduling process. The algorithm integrates ant colony optimization algorithm (ACO) with genetic algorithm (GA). To generate the initial pheromone efficiently for ACO, GA is invoked. With the designed fitness function, 4-dimensional QoS objectives are evaluated. Then, ACO is utilized to seek out the optimum resource. The experiment indicates that the proposed algorithm has preferable performance both in balancing resources and guaranteeing QoS.},
keywords={Genetic algorithms;Quality of service;Cloud computing;Algorithm design and analysis;Scheduling algorithms;Ant colony optimization;task scheduling;cloud computing;genetic algorithm;ant colony optimization algorithm;QoS},
doi={10.1109/IHMSC.2015.186},
ISSN={},
month={Aug},}
@INPROCEEDINGS{7976761,
author={Bashar, Abul},
booktitle={2017 IEEE 7th International Advance Computing Conference (IACC)}, title={BN-Based Approach for Predictive Admission Control of Cloud Services},
year={2017},
volume={},
number={},
pages={59-64},
abstract={A phenomenal growth in the demand for Cloud Computing services by the cloud consumers has necessitated the efficient and proactive management of the data center hosted services having varied characteristics. One of the major issues concerning both the cloud service providers and consumers is the provisioning of highest level of Quality of Service (QoS) under unpredictable service demands, while maintaining required revenue targets. Traditional Admission Control (AC) approaches which are usually mathematical or analytical in nature, have limited performance levels in the situations where service types, QoS parameters and user demands become highly unpredictable. To this end, an opportunity exists to utilize the self-learning capabilities of Machine Learning (ML) approaches to incorporate predictive and adaptive Admission Control of service requests without violating the Service Level Agreements (SLA) and simultaneously ensuring targeted revenue to the providers. This paper proposes, implements and evaluates a Bayesian Networks based predictive modeling framework (termed as BNSAC) to provide an autonomic Admission Control of cloud service requests. In summary, the BN-based model learns the historical behavior of the system involving various performance metrics (indicators) and predicts the desired unknown metric (e.g. SLA parameter) for making admission control decisions. It presents simulated experimental results involving various service demand scenarios which provide insights into the feasibility and applicability of the proposed approach for improving the QoS in the cloud computing setup.},
keywords={Cloud computing;Admission control;Predictive models;Measurement;Time factors;Bayes methods;Cloud Services;Admission Control;Bayesian Networks;Predictive Control},
doi={10.1109/IACC.2017.0027},
ISSN={2473-3571},
month={Jan},}
@INPROCEEDINGS{6903503,
author={Lim, Erbin and Thiran, Philippe},
booktitle={2014 IEEE International Conference on Cloud Engineering}, title={Communication of Technical QoS among Cloud Brokers},
year={2014},
volume={},
number={},
pages={403-409},
abstract={Service brokers are commonly used in the cloud computing paradigm to represent service requesters to select a service provider. They act as an intermediary between the two parties. One model of the cloud computing paradigm involves 3 layers, the user, the SaaS provider and the Cloud provider. The selection of service requesters is challenging due to the different levels of Quality of Service that each service provider can provide. In this paper we propose a unique mechanism that allows communication between service brokers in different layers in order to further improve this selection. In addition, we introduce a metric, efficiency, which service brokers can use to deterministically compare service providers with each other.},
keywords={Quality of service;Monitoring;Measurement;Cloud computing;Availability;Computer architecture},
doi={10.1109/IC2E.2014.92},
ISSN={},
month={March},}
@INPROCEEDINGS{7564810,
author={Chatterjee, Subarna and Misra, Sudip},
booktitle={2016 IEEE Wireless Communications and Networking Conference}, title={QoS estimation and selection of CSP in oligopoly environment for Internet of Things},
year={2016},
volume={},
number={},
pages={1-6},
abstract={This work focuses on an automated selection of Cloud Service Provider (CSP) for a naive end-user in an IoT scenario. In traditional cloud computing model, the end-users are knowledgeable about the Virtual Machines (VMs) and are technically aware of their requirements in terms of the computing cores, processing abilities, and storage requirements. In case of IoT, the users are envisioned to be widespread from naive, unsophisticated people to even objects or things who are devoid of the required knowledge and expertise. Further, in IoT technology, multiple Cloud Service Providers (CSPs) may possess the potential of serving an IoT application. Therefore, it is required for the end-user to judiciously select a single CSP based on the maximum obtainable Quality of Service (QoS) from a CSP. This work proposes an algorithm QoS based Automated Selection of CSP (QASeC) for automated selection of a CSP from a set of nominated CSPs based on the maximum achievable QoS. The work identifies and models the QoS parameters for every CSP and defines a QoS utility metric for each CSP. Based on the metric, the work proposes an optimization for selection of the appropriate CSP and the cloud gateway associated with it. From the obtained results, we infer the suitability of QASeC in real-life IoT scenarios.},
keywords={Internet of things;Quality of service;Delays;Cloud computing;Logic gates;Nickel;Uplink;Wireless Sensor Networks;Cloud Service Provider;Oligopoly;Internet of Things;Quality of Service},
doi={10.1109/WCNC.2016.7564810},
ISSN={1558-2612},
month={April},}
@INPROCEEDINGS{6785362,
author={Yao Lu and Liu, Yao and Dey, Sujit},
booktitle={2014 International Conference on Computing, Networking and Communications (ICNC)}, title={Enhancing Cloud Mobile 3D display gaming user experience by asymmetric graphics rendering},
year={2014},
volume={},
number={},
pages={368-374},
abstract={With the arrival of auto-stereoscopic 3D displays for mobile devices, and emergence of more 3D content, there is much anticipation for 3D mobile multimedia experiences, including 3D display gaming. Simultaneously, with the emergence of cloud computing, more mobile applications are being developed to take advantage of the elastic cloud resources. In this paper, we explore the possibility of developing Cloud-based 3D Mobile Gaming, where the 3D video rendering and encoding is performed on cloud servers, with the resulting 3D video streamed over wireless networks to mobile devices with 3D displays for a true 3D mobile gaming experience. However, with the significantly higher bit rate requirement for 3D video, ensuring user experience may be a challenge, both in terms of 3D video quality and network delay (response time), considering the bandwidth constraints and fluctuations of wireless networks. In this paper, we propose a new asymmetric graphics rendering approach which can significantly reduce the video encoding bit rate needed for a certain video quality, thereby making it easier to transmit the video over wireless network. However, since asymmetric rendering may also impair the graphics quality, we need to be able to understand and measure its impact. We conduct subjective tests to study and model the impairments due to asymmetric rendering and network delay, thereby developing a user experience model for cloud based mobile 3D display gaming. By conducting subsequent subjective tests, we prove the correctness of the impairment functions and the resulting user experience model. We also conduct experiments using real 4G-LTE network profile. Experimental results show that by making use of the user experience model, it is possible to set appropriate graphics rendering parameters according to network constraints, such that the user experience can be maintained to a high level.},
keywords={Three-dimensional displays;Rendering (computer graphics);Delays;Games;Mobile communication;Streaming media},
doi={10.1109/ICCNC.2014.6785362},
ISSN={},
month={Feb},}
@ARTICLE{7018938,
author={Lu, Yao and Liu, Yao and Dey, Sujit},
journal={IEEE Journal of Selected Topics in Signal Processing}, title={Cloud Mobile 3D Display Gaming User Experience Modeling and Optimization by Asymmetric Graphics Rendering},
year={2015},
volume={9},
number={3},
pages={517-532},
abstract={With the arrival of auto-stereoscopic 3D displays for mobile devices, and emergence of more 3D content, there is much anticipation for 3D mobile multimedia experiences, including 3D display gaming. Simultaneously, with the emergence of cloud computing, more mobile applications are being developed to take advantage of the elastic cloud resources. In this paper, we explore the possibility of developing Cloud Mobile 3D Display Gaming, where the 3D video rendering and encoding is performed on cloud servers, with the resulting 3D video streamed over wireless networks to mobile devices with 3D displays for a true 3D mobile gaming experience. However, with the significantly higher bitrate requirement for 3D video, ensuring user experience may be a challenge, both in terms of 3D video quality and network delay (response time), considering the bandwidth constraints and fluctuations of wireless networks. In this paper, we propose a new asymmetric graphics rendering approach which can significantly reduce the video encoding bitrate needed for a certain video quality, thereby making it easier to transmit the video over wireless network. However, since asymmetric graphics rendering may also impair the graphics quality, we need to be able to understand and measure its impact. We conduct subjective tests to study and model the impairments due to asymmetric graphics rendering and network delay, thereby developing a user experience model for cloud based mobile 3D display gaming. By conducting subsequent subjective tests, we prove the correctness of the impairment functions and the resulting user experience model. Furthermore, given any network condition, we propose to solve the problem of selecting the optimal graphics rendering factors for the left and right views so as to maximize user experience of cloud mobile 3D display gaming. In order to solve this problem, we first develop a model to estimate the resulting video bitrate of the rendered 3D video when certain graphics rendering factors are used. Next, we derive a model to predict the delay given the available network bandwidth and the video bitrate of the rendered 3D video. We use the above two models together with a branch and bound algorithm to solve the optimization problem and determine the optimal values for the left and right view rendering factors. Experiments conducted using real 4G-LTE network profiles on commercial cloud service demonstrate the feasibility of significant improvement in user experience when the proposed optimization algorithm is used to dynamically select optimal rendering factors according to changing network conditions.},
keywords={Three-dimensional displays;Rendering (computer graphics);Games;Streaming media;Mobile communication;Delays;3D;asymmetric graphics rendering;branch and bound;cloud Mobile Gaming;subjective testing;user experience},
doi={10.1109/JSTSP.2015.2396475},
ISSN={1941-0484},
month={April},}
@INPROCEEDINGS{8053360,
author={Fang, Dongfeng and Ye, Feng and Qian, Yi and Sharif, Hamid},
booktitle={2017 IEEE International Conference on Electro Information Technology (EIT)}, title={An efficient incentive mechanism for cloud-based mobile sensor network},
year={2017},
volume={},
number={},
pages={229-234},
abstract={Mobile sensor networks (MSNs) enable extensive applications of data collection, such as accident report in transportation and health prediction in public health. Incentive mechanism (IM) is applied for sensing user (SU) recruitment. However, the IM used in traditional MSN is not efficient due to limited information of SU used for recruitment. With the development of cloud computing technology, cloud-based MSN is the trend to use more information of SUs for IM design to improve its efficiency. In this paper, a novel cloud-based MSN model is presented. Three parties are considered, including data request party, cloud-based platform and SUs. A data quality model is proposed to measure the credit level of SUs. In addition, with consideration of social connections of SUs, a SU recruitment strategy is presented. SUs are divided into first and second degrees based on how they join the sensing task. The utility functions of first degree SUs and cloud-based platform are presented, respectively. At last, an efficient IM is proposed by formulating a Stackelberg game. The performance of the proposed IM on data quality and SU recruitment time comparing with other method are presented and discussed. The simulation results illustrate that the proposed IM ensures data quality for data request party and recruits SUs more efficiently.},
keywords={Sensors;Recruitment;Data models;Cloud computing;Computational modeling;Games},
doi={10.1109/EIT.2017.8053360},
ISSN={2154-0373},
month={May},}
@INPROCEEDINGS{8230340,
author={Laghari, Asif Ali and He, Hui and Shafiq, Muhammad and Khan, Asiya},
booktitle={2017 IEEE 9th International Conference on Communication Software and Networks (ICCSN)}, title={Impact of storage of mobile on quality of experience (QoE) at user level accessing cloud},
year={2017},
volume={},
number={},
pages={1402-1409},
abstract={Quality of Experience (QoE) is referred as level of user's satisfaction, enjoyment, learning and evaluation about the services or products. Recently quality of experience is used for improvement in product development life cycle after getting feedback from end users and service providers also use QoE to measure quality of services (QoS) of their services. Cloud computing provides services such as storage, web hosting, operating system environment, application development platform and CPU resources pay per use. End users are accessing cloud services via mobile apps, but enormous amount of temporary/cache data is generated by apps, so internal storage of mobile devices are filled quickly. Mobile device without any space in internal storage has huge impact on the performance when accessing the cloud services, which degrade the QoE of end users for particular cloud app and services. This paper presents the results of experiments conducted using two mobile devices HTC and Samsung to analyze the impact on end user's QoE during accessing cloud, when internal storage of HTC mobile device is filled and Samsung having 10 GB free space. Finally, on the basis of experimental results future changes in cloud apps are suggested for service provider to improve end user's QoE.},
keywords={Cloud computing;Random access memory;Mobile handsets;Mobile communication;Memory management;Loading;qaulity of experience (QoE);performance;cloud service providers;mobile app;internal storage;WeChat},
doi={10.1109/ICCSN.2017.8230340},
ISSN={2472-8489},
month={May},}
@ARTICLE{7807337,
author={Singh, Sukhpal and Chana, Inderveer and Buyya, Rajkumar},
journal={IEEE Transactions on Cloud Computing}, title={STAR: SLA-aware Autonomic Management of Cloud Resources},
year={2020},
volume={8},
number={4},
pages={1040-1053},
abstract={Cloud computing has recently emerged as an important service to manage applications efficiently over the Internet. Various cloud providers offer pay per use cloud services that requires Quality of Service (QoS) management to efficiently monitor and measure the delivered services through Internet of Things (IoT) and thus needs to follow Service Level Agreements (SLAs). However, providing dedicated cloud services that ensure user's dynamic QoS requirements by avoiding SLA violations is a big challenge in cloud computing. As dynamism, heterogeneity and complexity of cloud environment is increasing rapidly, it makes cloud systems insecure and unmanageable. To overcome these problems, cloud systems require self-management of services. Therefore, there is a need to develop a resource management technique that automatically manages QoS requirements of cloud users thus helping the cloud providers in achieving the SLAs and avoiding SLA violations. In this paper, we present SLA-aware autonomic resource management technique called STAR which mainly focuses on reducing SLA violation rate for the efficient delivery of cloud services. The performance of the proposed technique has been evaluated through cloud environment. The experimental results demonstrate that STAR is efficient in reducing SLA violation rate and in optimizing other QoS parameters which effect efficient cloud service delivery.},
keywords={Cloud computing;Quality of service;Resource management;Monitoring;Reliability;Service level agreements;Software as a service;Autonomic cloud;resource provisioning;cloud computing;resource scheduling;quality of service;service level agreement},
doi={10.1109/TCC.2017.2648788},
ISSN={2168-7161},
month={Oct},}
@INPROCEEDINGS{9148980,
author={Ma, Kun and Bagula, Antoine and Ajayi, Olasupo and Nyirenda, Clement},
booktitle={ICC 2020 - 2020 IEEE International Conference on Communications (ICC)}, title={Aiming at QoS: A Modified DE Algorithm for Task Allocation in Cloud Computing},
year={2020},
volume={},
number={},
pages={1-7},
abstract={The Cloud computing system is characterized by large scale servers being utilized by an even larger number of users. It is a system where there is the need to frequently and efficiently schedule and manage different application tasks, with varied service requirements. One of the challenges of Cloud computing is managing the quality of service (QoS) rendered to users, specifically scheduling tasks between users and Cloud resources in a timely manner. Cloud users usually have widely diverse QoS requirements and meeting these simultaneously is also a challenge. In this paper, in order to improve on Cloud resource allocation and specifically to tailor it towards meeting varied QoS requirements of users, we proposed a new algorithm which combines Differential Evolution with the Shapley Value economic mode. This combination allows us measure the contribution of each virtual machine (VM), so as to improve the probability of obtaining a better tasks-to-resource allocation thereby improving user satisfaction. From results of conducted experiments, when compared with the traditional DE (Differential Evolution) algorithm and the conventional task-VM binding policy in CloudSim, both for allocations where special QoS requirements are required and in instances of multiple QoS requirements; the modified Shapley value based DE algorithm (SVBDA) shows significant improvement.},
keywords={Quality of service;Task analysis;Cloud computing;Resource management;Games;Bandwidth;Processor scheduling;Cloud computing;Differential evolution algorithm;Execution time/cost minimizing;NP hard problem;Quality of service (QoS);Shapley value;Tasks scheduling;Virtual machine},
doi={10.1109/ICC40277.2020.9148980},
ISSN={1938-1883},
month={June},}
@ARTICLE{7517217,
author={Lyu, Xinchen and Tian, Hui and Sengul, Cigdem and Zhang, Ping},
journal={IEEE Transactions on Vehicular Technology}, title={Multiuser Joint Task Offloading and Resource Optimization in Proximate Clouds},
year={2017},
volume={66},
number={4},
pages={3435-3447},
abstract={Proximate cloud computing enables computationally intensive applications on mobile devices, providing a rich user experience. However, remote resource bottlenecks limit the scalability of offloading, requiring optimization of the offloading decision and resource utilization. To this end, in this paper, we leverage the variability in capabilities of mobile devices and user preferences. Our system utility metric is a measure of quality of experience (QoE) based on task completion time and energy consumption of a mobile device. We propose a heuristic offloading decision algorithm (HODA), which is semidistributed and jointly optimizes the offloading decision, and communication and computation resources to maximize system utility. Our main contribution is to reduce the problem to a submodular maximization problem and prove its NP-hardness by decomposing it into two subproblems: 1) optimization of communication and computation resources solved by quasiconvex and convex optimization and 2) offloading decision solved by submodular set function optimization. HODA reduces the complexity of finding the local optimum to O(K3), where K is the number of mobile users. Simulation results show that HODA performs within 5% of the optimal on average. Compared with other solutions, HODA's performance is significantly superior as the number of users increases.},
keywords={Mobile communication;Cloud computing;Mobile handsets;Optimization;Base stations;Uplink;Energy consumption;Mobile cloud computing;multiuser offloading;proximate cloud;resource optimization},
doi={10.1109/TVT.2016.2593486},
ISSN={1939-9359},
month={April},}
@INPROCEEDINGS{7207388,
author={Zhou, Nianjun and Mohindra, Ajay},
booktitle={2015 IEEE International Conference on Services Computing}, title={Causality-Driven Performance Monitoring and Scaling Automation for Managed Solutions},
year={2015},
volume={},
number={},
pages={467-474},
abstract={A key feature of Cloud computing is its agility and flexibility to support the scalability needs of business solutions. Currently, the agility is only limited to the scalability of the compute, memory and storage. To improve an application's agility, we need to monitor & measure solution level metrics and associate the performance of the metrics to the business agility needs of the solution by making real-time scalability or change decisions. In this paper, we illustrate a scaling decision mechanism utilizing the monitoring data from infrastructure, middleware, and business level metrics. We use these performance metrics as input to a causality analysis model to make architecture changes or scalability decisions. Mathematically, we define the causality as a graph to link the changes in the measured metric values to the action of the solution change. The causality analysis follows scalability principles as best practices. They are a) the principle of performance scalability b) principle of contribution margin for scalability, and c) principle of the least cost of SLA compliance. We define these scalability principles as the rules to ensure that the business stakeholder of the solution can maintain or improve their business quality or profit margins as the computing capability scales up or down. To implement those principles, we need to establish the linkages of the business metrics to the decision of changes. To make such linkage, we first utilize causality analysis to identify feasible scaling actions, and then associate those actions with the system, application, and business performance metrics. With the help of causality analysis, we implement a performance monitoring and scaling automation framework for managed solutions using an Open Source Monitoring system.},
keywords={Scalability;Measurement;Monitoring;Business;Computer architecture;Media;Servers;Scalability;Business Monitoring;Performance Metrics;Service Level Agreements;Decision;Trade-Off},
doi={10.1109/SCC.2015.70},
ISSN={},
month={June},}
@ARTICLE{9395576,
author={Cedillo, Priscila and Insfran, Emilio and Abrahão, Silvia and Vanderdonckt, Jean},
journal={IEEE Access}, title={Empirical Evaluation of a Method for Monitoring Cloud Services Based on Models at Runtime},
year={2021},
volume={9},
number={},
pages={55898-55919},
abstract={Cloud computing is being adopted by commercial and governmental organizations driven by the need to reduce the operational cost of their information technology resources and search for a scalable and flexible way to provide and release their software services. In this computing model, the Quality of Services (QoS) is agreed between service providers and their customers through Service Level Agreements (SLA). There is thus a need for systematic approaches with which to assess the quality of cloud services and their compliance with the SLA. In previous work, we introduced a generic method for Monitoring cloud Services using models at RunTime (MoS@RT), which allows the monitoring requirements or the metric operationalizations of these requirements to be changed at runtime without the modification of the underlying infrastructure. In this paper, we present the design of a monitoring infrastructure that supports the proposed method with its instantiation to a specific platform and reports the results of an experiment carried out to evaluate the perceived efficacy of 58 undergraduate students when using the infrastructure to configure the monitoring of cloud services deployed on the Microsoft Azure platform. The results show that the participants perceived MoS@RT to be easy to use, useful, and they also expressed their intention to use the method in the future. Although further experiments must be carried out to strengthen these results, MoS@RT has proved to be a promising monitoring method for cloud services.},
keywords={Monitoring;Cloud computing;Tools;Runtime;Quality of service;Measurement;Service level agreements;Cloud computing;models@runtime;quality of service (QoS);services monitoring;software as a service (SaaS)},
doi={10.1109/ACCESS.2021.3071417},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9284567,
author={Zhang, Yilei and Zhang, Xiao and Zhang, Peiyun and Luo, Jun},
booktitle={2020 IEEE International Conference on Services Computing (SCC)}, title={Credible and Online QoS Prediction for Services in Unreliable Cloud Environment},
year={2020},
volume={},
number={},
pages={272-279},
abstract={With the widespread adoption of cloud computing, Service-Orientated Architecture (SOA) facilitates the deployment of large-scale online applications in many key areas where quality and reliability are critical. In order to ensure the performance of cloud applications, Quality of Service (QoS) is widely used as a key metric to enable QoS-driven service selection, composition, adaption, etc. Since QoS data observed by users is sparse due to technical constraints, previous studies have proposed prediction approaches to solve this problem. However, the dynamic nature of the cloud environment requires timely prediction of time-varying QoS values. In addition, unreliable QoS data from untrustworthy users may significantly affect the prediction accuracy. In this paper, we propose a credible online QoS prediction approach to address these challenges. We evaluate user credibility through a reputation mechanism and employ online learning techniques to provide QoS prediction results at runtime. The proposed approach is evaluated on a large-scale real-world QoS dataset, and the experimental results demonstrate its effectiveness and efficiency in unreliable cloud environment.},
keywords={Cloud computing;Runtime;Service computing;Quality of service;Real-time systems;Service-oriented architecture;Reliability;QoS Prediction;Cloud Services;Collaborative Filtering;Reputation;Online Learning},
doi={10.1109/SCC49832.2020.00043},
ISSN={2474-2473},
month={Nov},}
@INPROCEEDINGS{7847681,
author={Pendlebury, John and Emeakaroha, Vincent C. and O'Shea, David and Cafferkey, Neil and Morrison, John P. and Lynn, Theo},
booktitle={2016 2nd International Conference on Cloud Computing Technologies and Applications (CloudTech)}, title={SOMBA - automated anomaly detection for Cloud quality of service},
year={2016},
volume={},
number={},
pages={71-79},
abstract={Cloud computing has transformed the standard model of service provisioning, allowing the delivery of on-demand services over the Internet. With its inherent requirements for elastic scalability and a pay-as-you-go pricing model, an additional level of complexity is added to its Quality of Service (QoS) management. This has made service provisioning more prone to performance anomalies due to the large-scale and evolving nature of Clouds. Existing methods for anomaly detection based on QoS monitoring in the Cloud rely on probabilistic methods, which are not computationally easy and are often valid for very short times before system dynamics change. We posit that more minimalistic approaches including automated techniques are needed for effective anomaly detection to support QoS enforcement in Clouds. In this paper, we present an automated anomaly detection scheme that recognises and adapts to changes in Clouds for efficient multi-metric performance anomaly detection to guarantee service quality. It includes a monitoring tool for collating performance data in real time for analysis and an anomaly detection technique based on an unsupervised machine learning strategy. Based on a Cloud service provisioning use case scenario, we evaluate our anomaly detection technique and compare it against two statistical anomaly detection approaches to demonstrate its efficiency.},
keywords={Monitoring;Quality of service;Cloud computing;Visualization;Resource management},
doi={10.1109/CloudTech.2016.7847681},
ISSN={},
month={May},}
@ARTICLE{9097181,
author={Belgaum, Mohammad Riyaz and Musa, Shahrulniza and Alam, Muhammad Mansoor and Su’ud, Mazliham Mohd},
journal={IEEE Access}, title={A Systematic Review of Load Balancing Techniques in Software-Defined Networking},
year={2020},
volume={8},
number={},
pages={98612-98636},
abstract={The traditional networks are facing difficulties in managing the services offered by cloud computing, big data, and the Internet of Things as the users have become more dependent on their services. Software-Defined Networking (SDN) has pulled enthusiasm in the integration process of technologies and function as per the user's requirements for both academia and industry, and it has begun to be embraced in actual framework usage. The emergence of SDN has given another idea to empower the focal programmability of the system. Because of the increasing demand and the scarcity of resources, the load balancing issue needs to be addressed efficiently to manage the incoming traffic and resources and to improve network performance. One of the most critical issues is the role of the controller in SDN to balance the load for having a better Quality of Service (QoS). Though there are few survey articles written on load balancing, there is no detail and systematic review conducted in load balancing in SDN. Hence, this paper extends and reviews the discussion with a taxonomy of current emerging load balancing techniques in SDN systematically by categorizing the techniques as conventional and artificial intelligence-based techniques to improve the service quality. The review also includes the study of metrics and parameters which have been used to measure the performance. This review would allow gaining more information on load balancing approaches in SDN and enables the researchers to fill the current research gaps.},
keywords={Load management;Quality of service;Switches;Systematics;Measurement;Software;Artificial intelligence;conventional;load balancing;review;SDN;software-defined networking;systematic},
doi={10.1109/ACCESS.2020.2995849},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8718133,
author={Wong, Tong-Sheng and Chan, Gaik-Yee and Chua, Fang-Fang},
booktitle={2019 International Conference on Information Networking (ICOIN)}, title={Adaptive Preventive and Remedial Measures in Resolving Cloud Quality of Service Violation},
year={2019},
volume={},
number={},
pages={473-479},
abstract={Cloud Computing acts as a paradigm to support on-demand computing services, from applications to storage, manage and processing capabilities. One of the major challenges in delivering and accessing cloud applications is the management of Quality of Service (QoS) and cloud service providers are mandated to adhere to Service Level Agreement (SLA) in providing quality cloud services to the users. The agreement matching is important for both parties to ensure satisfaction and expectation level. This proposed work aims to resolve cloud QoS violation with the implementation of adaptive preventive and remedial mechanisms. Preventive measure such as horizontal scaling is used to optimize the performance of a running cloud service in order to prevent the cloud service to downgrade to QoS violation condition. Remedial action on the other hand, is to provide fault tolerance using replication for faulty cloud service to recover from failure incidents or already violation condition. Experimental results have demonstrated the feasibility and effectiveness of applying horizontal scaling in preventing and replication in rectifying cloud QoS violations based on response time and throughput.},
keywords={Cloud computing;Quality of service;Fault tolerance;Fault tolerant systems;Time factors;Scalability;Throughput;Cloud Computing;Fault Tolerance;Quality of Service Violation;Replication;Scalability},
doi={10.1109/ICOIN.2019.8718133},
ISSN={1976-7684},
month={Jan},}
@ARTICLE{8737926,
author={Liu, Ying and Wang, Ke and Ge, Liang and Ye, Lei and Cheng, Jingde},
journal={IEEE Access}, title={Adaptive Evaluation of Virtual Machine Placement and Migration Scheduling Algorithms Using Stochastic Petri Nets},
year={2019},
volume={7},
number={},
pages={79810-79824},
abstract={More and more mobile applications rely on the combination of both mobile and cloud computing technology to bring out their full potential. The cloud is usually used for providing additional computing resources that cannot be handled efficiently by the mobile devices. Cloud usage, however, results in several challenges related to the management of virtualized resources. A large number of scheduling algorithms are proposed to balance between performance and cost of data center. Due to huge cost and time consuming of measure-based and simulation method, this paper proposes an adaptive method to evaluate scheduling algorithms. In this method, the virtual machine placement and migration process are modeled by using Stochastic Reward Nets. Different scheduling methods are described as reward functions to perform the adaptive evaluation. Two types of performance metrics are also discussed: one is about quality of service, such as system availability, mean waiting time, and mean service time, and the other is the cost of runtime, such as energy consumption and cost of migration. Compared to a simulation method, the analysis model in this paper only modifies the reward function for different scheduling algorithms and does not need to reconstruct the process. The numeric results suggest that it also has a good accuracy and can quantify the influence of scheduling algorithms on both quality of service and cost of runtime.},
keywords={Scheduling algorithms;Cloud computing;Servers;Adaptation models;Stochastic processes;Virtual machining;Quality of service;Adaptive evaluation;virtual machine placement and migration;scheduling algorithms;stochastic reward net},
doi={10.1109/ACCESS.2019.2923592},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9178684,
author={Wang, Chengrong and Zhang, Xiaodong and Chu, Dianhui},
booktitle={2020 5th International Conference on Computational Intelligence and Applications (ICCIA)}, title={Research on Service Composition Optimization Method Based on Composite Services QoS},
year={2020},
volume={},
number={},
pages={206-210},
abstract={With the development of Cloud Computing, Internet of Things, and the advent of the era of Big Data, the types and scale of services are getting larger and larger, and the problem space of service composition is exploding. In order to measure the composite services quality of different combination schemes, this paper shows the calculation method of composite services QoS (Quality of Service), and improves the Ant Colony Algorithm by introducing Skyline calculation to further improve the efficiency of service composition and respond to user quickly. Finally, it is verified on the real QoS data set, and the feasibility and effectiveness of the method are proved through experiments.},
keywords={Quality of service;Throughput;Task analysis;Time factors;Genetic algorithms;Computer science;Electronic mail;QoS;ant colony algorithm;service composition;skyline},
doi={10.1109/ICCIA49625.2020.00046},
ISSN={},
month={June},}
@ARTICLE{7445250,
author={Shi, Lei and Shi, Yi and Wei, Xing and Ding, Xu and Wei, Zhenchun},
journal={IEEE Transactions on Parallel and Distributed Systems}, title={Cost Minimization Algorithms for Data Center Management},
year={2017},
volume={28},
number={1},
pages={60-71},
abstract={Due to the increasing usage of cloud computing applications, it is important to minimize energy cost consumed by a data center, and simultaneously, to improve quality of service via data center management. One promising approach is to switch some servers in a data center to the idle mode for saving energy while to keep a suitable number of servers in the active mode for providing timely service. In this paper, we design both online and offline algorithms for this problem. For the offline algorithm, we formulate data center management as a cost minimization problem by considering energy cost, delay cost (to measure service quality), and switching cost (to change servers's active/idle mode). Then, we analyze certain properties of an optimal solution which lead to a dynamic programming based algorithm. Moreover, by revising the solution procedure, we successfully eliminate the recursive procedure and achieve an optimal offline algorithm with a polynomial complexity. For the online algorithm, We design it by considering the worst case scenario for future workload. In simulation, we show this online algorithm can always provide near-optimal solutions.},
keywords={Servers;Algorithm design and analysis;Switches;Heuristic algorithms;Optimization;Minimization;Delays;Data center management;offline algorithm;dynamic programming;online algorithm},
doi={10.1109/TPDS.2016.2549016},
ISSN={1558-2183},
month={Jan},}
@ARTICLE{9046283,
author={Zhu, Zongwei and Han, Guangjie and Jia, Gangyong and Shu, Lei},
journal={IEEE Internet of Things Journal}, title={Modified DenseNet for Automatic Fabric Defect Detection With Edge Computing for Minimizing Latency},
year={2020},
volume={7},
number={10},
pages={9623-9636},
abstract={As an essential step in quality control, fabric defect detection plays an important role in the textile manufacturing industry. The traditional manual detection method is inaccurate and incurs a high cost; as a result, it is gradually being replaced by deep learning algorithms based on cloud computing. However, a high data transmission latency between end devices and the cloud has a significant impact on textile production efficiency. In contrast, edge computing, which provides services near end devices by deploying network, computing and storage facilities at the edge of the Internet, can effectively solve the above-mentioned problem. In this article, we propose a deep-learning-based fabric defect detection method for edge computing scenarios. First, this article modifies the structure of DenseNet to better suit a resource-constrained edge computing scenario. To better assess the proposed model, an optimized cross-entropy loss function is also formulated. Afterward, six feasible expansion schemes are utilized to enhance the data set according to the characteristics of various defects in fabric samples. To balance the distribution of samples, proportions of various defect types are used to determine the number of enhancements. Finally, a fabric defect detection system is established to test the performance of the optimized model used on edge devices in a real-world textile industry scenario. Experimental results demonstrate that compared with the conventional convolutional neural network (CNN), the proposed optimized model attains an average improvement of 18% in the area under the curve (AUC) metric for 11 defects. Data transmission is reduced by approximately 50% and latency is reduced by 32% in the Cambricon 1H8 platform compared with a cloud platform.},
keywords={Fabrics;Production;Computational modeling;Edge computing;Cloud computing;Image edge detection;Adaptation models;Convolutional neural network (CNN);edge computing;fabric defect detection;image processing},
doi={10.1109/JIOT.2020.2983050},
ISSN={2327-4662},
month={Oct},}
@INPROCEEDINGS{8458040,
author={Ma, Kun and Bagula, Antoine and Mauwa, Hope and Celesti, Antonio},
booktitle={2018 IEEE 6th International Conference on Future Internet of Things and Cloud (FiCloud)}, title={Modelling Cloud Federation: A Fair Profit Distribution Strategy Using the Shapley Value},
year={2018},
volume={},
number={},
pages={393-398},
abstract={Cloud computing provides software (Software as a Service), platform (Platform as a Service) and infrastructure (Infrastructure as a Service) services to its users by integrating IT resources into a large-scale and scalable resource pool through the virtualisation technology. However, the single cloud resource provider model currently implemented by many providers may fail short to meet the dynamic nature of cloud users' requirements. Cloud federation can mitigate this issue by optimising cloud resource allocation through sharing and re-usability of available resources. This paper revisit the problem of cloud engineering by tackling the key issue of the fair distribution of profit between cloud resource providers, which, to the best of our knowledge, has only been scarcely addressed by the research and practitioners' community. We propose a method that enables the cloud federation to map the contribution of resources of the participants to the federations into a quality of service metric used to achieve a cloud federation. Building upon a federation game implementation, we reveal the possibilities and benefits of different federation compositions using the Shapley value of each resource provider as a way of implementing a fair profit sharing strategy. Using extensions of the CloudSim package, we present simulation results that demonstrate the fairness of our proposed method and strategy.},
keywords={Cloud computing;Quality of service;Task analysis;Resource management;Games;Reliability;Security;cloud computing, federation, game theory, tasks scheduling, fair profit distribution, resource allocation, quality of service (QoS)},
doi={10.1109/FiCloud.2018.00063},
ISSN={},
month={Aug},}
@ARTICLE{9140398,
author={Fantacci, Romano and Picano, Benedetta},
journal={IEEE Transactions on Vehicular Technology}, title={Performance Analysis of a Delay Constrained Data Offloading Scheme in an Integrated Cloud-Fog-Edge Computing System},
year={2020},
volume={69},
number={10},
pages={12004-12014},
abstract={The recent growth in intensive services and applications demand has triggered the functional integration of cloud computing with edge computing capabilities. One of the main goals is to allow a fast processing to tasks with strict real time constraints in order to lower the task dropping probability due to expiration of the associated deadlines. This paper deals with the performance evaluation and optimization of a three layers cloud-fog-edge computing infrastructure by resorting to the use of queueing theory results. In particular, a Markov queueing system model with reneging is proposed for the cloud subsystem, in order to consider the premature computation requests departure due to their deadline expiration. Furthermore, a computational resources allocation method is proposed with the aim at maximizing the social welfare metric, constrained to specific quality of service requirements. Finally, the proposed queueing theory analysis as well as of the computational resources allocation approach is validated by comparing the obtained analytical predictions with simulation results.},
keywords={Cloud computing;Computational modeling;Optimization;Queueing analysis;Delays;Servers;Edge computing;Mobile computing;offloading;queueing theory;performance optimization},
doi={10.1109/TVT.2020.3008926},
ISSN={1939-9359},
month={Oct},}
@INPROCEEDINGS{7063421,
author={Ran, Yongyi and Shi, Youkang and Yang, Enzhong and Chen, Shuangwu and Yang, Jian},
booktitle={2014 IEEE Globecom Workshops (GC Wkshps)}, title={Dynamic resource allocation for video transcoding with QoS guaranteeing in cloud-based DASH system},
year={2014},
volume={},
number={},
pages={144-149},
abstract={Due to diverse network conditions and heterogeneous devices, there may be various video demands with different video qualities and formats from the client side. Compared to keeping all necessary copies for the same video, video transcoding in real-time should be an essential solution. The complex nature of video transcoding enables cloud computing to be uniquely suitable for dynamically providing transcoding resource. However, due to the fluctuation and uncertainty of the future transcoding demand, it is still a challenge to dynamically determine the optimal resource allocation to save cost while guaranteeing the Quality of Service (QoS). Overload may result in the transcoding jitter and increase the lateness which directly affects video freezes while over-provisioning naturally increases the cost. To address this problem, in this paper, by defining the transcoding jitter probability as a metric of QoS, we proposed a dynamic resource allocation algorithm based on the large deviation principle, which is capable of proactive calculating the optimal number of transcoding nodes for the upcoming transcoding demand subject to the transcoding jitter probability below a desired threshold. Finally, the experiments are performed on a cloud-based prototype system to show the attainable performance of the proposed resource allocation algorithm and verify that the proposed algorithm can make a good tradeoff between cost saving and QoS guaranteeing.},
keywords={Transcoding;Streaming media;Jitter;Quality of service;Bit rate;Heuristic algorithms;Dynamic scheduling;Dynamic resource allocation;video transcoding;cloud computing;quality of service;cost saving},
doi={10.1109/GLOCOMW.2014.7063421},
ISSN={2166-0077},
month={Dec},}
@INPROCEEDINGS{7116128,
author={Al-Jawad, Ahmed and Trestian, Ramona and Shah, Purav and Gemikonakli, Orhan},
booktitle={Proceedings of the 2015 1st IEEE Conference on Network Softwarization (NetSoft)}, title={BaProbSDN: A probabilistic-based QoS routing mechanism for Software Defined Networks},
year={2015},
volume={},
number={},
pages={1-5},
abstract={Over the past decade there has been an exponential increase in the Internet traffic especially with the proliferation of cloud computing and other distributed data services. This explosion of data traffic with its dynamically changing traffic patterns and flows might result in degradation of the network performance. In this context, there is a need for an intelligent and efficient network management system that delivers guaranteed services. To this extent, this paper proposes BaProbSDN, a probabilistic Quality of Service (QoS) routing mechanism for Software Defined Networks (SDN). The QoS routing algorithm employs the bandwidth availability metric as a QoS routing constraint for unicast data delivery. BaProbSDN makes use of Bayes' theorem and Bayesian network model to determine the link probability in order to select the route that satisfies the given bandwidth constraint. The performance of the proposed probabilistic QoS routing algorithm was tested in a simulation-based environment and compared against the widest-shortest path routing (WSR) algorithm. The results demonstrate that BaProbSDN can achieve up to 8.02% decrease in the bandwidth blocking rate when compared to WSR in the presence of link update inaccuracies of threshold and time delay.},
keywords={Bandwidth;Quality of service;Routing;Measurement;Control systems;Probabilistic logic;Bayes methods;Software Defined Networks;OpenFlow;Quality of Service Routing;Bayesian Network},
doi={10.1109/NETSOFT.2015.7116128},
ISSN={},
month={April},}
@INPROCEEDINGS{6969013,
author={Tchernykh, Andrei and Lozano, Luz and Schwiegelshohn, Uwe and Bouvry, Pascal and Pecero, Johnatan E. and Nesmachnow, Sergio},
booktitle={2014 IEEE 3rd International Conference on Cloud Networking (CloudNet)}, title={Bi-objective online scheduling with quality of service for IaaS clouds},
year={2014},
volume={},
number={},
pages={307-312},
abstract={This paper focuses on the bi-objective experimental analysis of online scheduling in the Infrastructure as a Service model of Cloud computing. In this model, customer have the choice between different service levels. Each service level is associated with a price per unit of job execution time and a slack factor that determines the maximal time span to deliver the requested amount of computing resources. It is responsibility of the system and its scheduling algorithm to guarantee the corresponding quality of service for all accepted jobs. We do not consider any optimistic scheduling approach, that is, a job cannot be accepted if its service guarantee will not be observed assuming that all accepted jobs receive the requested resources. We analyze several scheduling algorithms with different cloud configurations and workloads and use the maximization of the provider income and minimization of the total power consumption of a schedule as additional objectives. Therefore, we cannot expect finding a unique solution to a given problem but a set of nondominated solutions also known as Pareto optima. Then we assess the performance of different scheduling algorithms by using a set coverage metric to compare them in terms of Pareto dominance. Based on the presented case study, we claim that a simple algorithm can provide the best energy and income trade-offs. This scheduling algorithm performs well in different scenarios with a variety of workloads and cloud configurations.},
keywords={Power demand;Degradation;Measurement;Processor scheduling;Educational institutions;Energy efficiency;Resource management;Cloud computing;Service Level Agreement;Energy Efficiency;Scheduling},
doi={10.1109/CloudNet.2014.6969013},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9407931,
author={Hussain, Razin Farhan and Pakravan, Alireza and Salehi, Mohsen Amini},
booktitle={2020 IEEE 22nd International Conference on High Performance Computing and Communications; IEEE 18th International Conference on Smart City; IEEE 6th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, title={Analyzing the Performance of Smart Industry 4.0 Applications on Cloud Computing Systems},
year={2020},
volume={},
number={},
pages={11-18},
abstract={Cloud-based Deep Neural Network (DNN) applications that make latency-sensitive inference are becoming an indispensable part of Industry 4.0. Due to the multi-tenancy and resource heterogeneity, both inherent to the cloud computing environments, the inference time of DNN-based applications are stochastic. Such stochasticity, if not captured, can potentially lead to low Quality of Service (QoS) or even a disaster in critical sectors, such as Oil and Gas industry. To make Industry 4.0 robust, solution architects and researchers need to understand the behavior of DNN-based applications and capture the stochasticity exists in their inference times. Accordingly, in this study, we provide a descriptive analysis of the inference time from two perspectives. First, we perform an application-centric analysis and statistically model the execution time of four categorically different DNN applications on both Amazon and Chameleon clouds. Second, we take a resource-centric approach and analyze a rate-based metric in form of Million Instruction Per Second (MIPS) for heterogeneous machines in the cloud. This non-parametric modeling, achieved via Jackknife and Bootstrap re-sampling methods, provides the confidence interval of MIPS for heterogeneous cloud machines. The findings of this research can be helpful for researchers and cloud solution architects to develop solutions that are robust against the stochastic nature of the inference time of DNN applications in the cloud and can offer a higher QoS to their users and avoid unintended outcomes.},
keywords={Measurement;Cloud computing;Analytical models;Oils;High performance computing;Conferences;Neural networks;Deep Neural Network Applications;Industry 4.0;Cloud Platform;Heterogeneous Machines;Inference Time},
doi={10.1109/HPCC-SmartCity-DSS50907.2020.00003},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8613297,
author={Al-Said Ahmad, Amro and Andras, Peter},
booktitle={2018 Fifth International Symposium on Innovation in Information and Communication Technology (ISIICT)}, title={Measuring and Testing the Scalability of Cloud-based Software Services},
year={2018},
volume={},
number={},
pages={1-8},
abstract={Performance and scalability testing and measurements of cloud-based software services are critically important in the context of rapid growth of cloud computing and supporting the delivery of these services. Cloud-based software services performance aspects are interrelated, both elasticity and efficiency are depending on the delivery of a sufficient level of scalability performance. In this work, we focused on testing and measuring the scalability of cloud-based software services in technical terms. This paper uses technical scalability metrics that address both volume and quality scaling, that inspired by earlier technical metrics of elasticity. We show how our technical scalability metrics can be integrated into an earlier utility oriented metric of scalability. We demonstrate the application of the metrics using a practical example and discuss the importance of them.},
keywords={Scalability;Software;Elasticity;Software measurement;Testing;Cloud computing;Measurement;Performance;Testing;Scalability;Software-as-a-Service (SaaS);Metrics},
doi={10.1109/ISIICT.2018.8613297},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8646562,
author={Zhu, Hongbin and Wang, Haifeng and Luo, Xiliang and Qian, Hua},
booktitle={2018 IEEE Global Conference on Signal and Information Processing (GlobalSIP)}, title={AN ONLINE LEARNING APPROACH TO WIRELESS COMPUTATION OFFLOADING},
year={2018},
volume={},
number={},
pages={678-682},
abstract={Fog computing extends cloud computing and services to the edge of networks, bringing advantages of the cloud closer to where data is created and acted upon. To support real time applications, latency performance is a crucial metric in fog computing. In this paper, we consider a sequential decision-making problem for computation offloading with unknown dynamics in which a mobile user offloads its arrival tasks to associated fog nodes (FNs) at each time slot. The queue of arrival tasks at each FN is modeled as a Markov chain. In order to provide satisfactory quality of experience, the network latency, which is directly associated with the queue condition, needs to be minimized. Taking advantage of reinforcement learning, the sequential decision-making problem is formulated as a restless multi-armed bandit problem. We construct a policy with interleaved exploration and exploitation stages, which achieves a regret with sub-linear order. Both analytical and simulation results validate the effectiveness of the proposed method in dealing with sequential decision-making problem.},
keywords={Task analysis;Markov processes;Edge computing;Cloud computing;Quality of experience;Decision making;Optimization;Fog computing;quality of experience (QoE);restless multi-armed bandit (RMAB);Markov chain},
doi={10.1109/GlobalSIP.2018.8646562},
ISSN={},
month={Nov},}
@INPROCEEDINGS{6883661,
author={Si, Pengbo and Yu, F. Richard and Zhang, Yanhua},
booktitle={2014 IEEE International Conference on Communications (ICC)}, title={Joint cloud and radio resource management for video transmissions in mobile cloud computing networks},
year={2014},
volume={},
number={},
pages={2270-2275},
abstract={In mobile cloud computing (MCC) systems, the resource in both the cloud and the mobile network should be carefully managed. Cloud resource management and radio resource management have traditionally been addressed separately in previous works. In this paper, we propose to jointly study dynamic cloud and radio resource management so as to improve end-to-end performance of adaptive video transmissions in MCC systems. Video application quality of service performance, distortion, is adopted as the performance measure. An important video application layer parameter, intra-refreshing rate, is optimized to improve the video distortion performance. We formulate the problem as a stochastic restless bandits optimization problem, which facilitates the distributed MCC architecture and simplifies the computation and implementation due to its “indexibility” property. Simulation results are presented to show the effectivenes of the proposed scheme.},
keywords={Servers;Mobile communication;Mobile computing;Resource management;Cloud computing;Bandwidth;Wireless communication},
doi={10.1109/ICC.2014.6883661},
ISSN={1938-1883},
month={June},}
@INPROCEEDINGS{8057143,
author={Toka, Lászlíó and Lajtha, Balázs and Hosszu, Éva and Formanek, Bence and Géhberger, Dániel and Tapolcai, János},
booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications}, title={A resource-aware and time-critical IoT framework},
year={2017},
volume={},
number={},
pages={1-9},
abstract={Internet of Things (IoT) systems produce great amount of data, but usually have insufficient resources to process them in the edge. Several time-critical IoT scenarios have emerged and created a challenge of supporting low latency applications. At the same time cloud computing became a success in delivering computing as a service at affordable price with great scalability and high reliability. We propose an intelligent resource allocation system that optimally selects the important IoT data streams to transfer to the cloud for processing. The optimization runs on utility functions computed by predictor algorithms that forecast future events with some probabilistic confidence based on a dynamically recalculated data model. We investigate ways of reducing specifically the upload bandwidth of IoT video streams and propose techniques to compute the corresponding utility functions. We built a prototype for a smart squash court and simulated multiple courts to measure the efficiency of dynamic allocation of network and cloud resources for event detection during squash games. By continuously adapting to the observed system state and maximizing the expected quality of detection within the resource constraints our system can save up to 70% of the resources compared to the naive solution.},
keywords={Cloud computing;Bandwidth;Streaming media;Cameras;Quality of service;Uplink;Resource management;Internet of Things;cloud computing;cloud control;resource provisioning;adaptive;dynamic;QoS;QoE},
doi={10.1109/INFOCOM.2017.8057143},
ISSN={},
month={May},}
@INPROCEEDINGS{7037229,
author={Mazza, Daniela and Tarchi, Daniele and Corazza, Giovanni E.},
booktitle={2014 IEEE Global Communications Conference}, title={A user-satisfaction based offloading technique for smart city applications},
year={2014},
volume={},
number={},
pages={2783-2788},
abstract={The Smart cities applications are gaining an increasing interest among administrations, citizens and technologists for their suitability in managing the everyday life. One of the major challenges is regarding the possibility of managing in an efficient way the presence of multiple applications in a Wireless Heterogeneous Network (HetNet) environment, alongside the presence of a Mobile Cloud Computing (MCC) infrastructure. In this context we propose a utility function model derived from the economic world aiming to measure the Quality of Service (QoS), in order to choose the best access point in a HetNet to offload part of an application on the MCC, aiming to save energy for the Smart Mobile Devices (SMDs) and to reduce computational time. We distinguish three different types of application, considering different offloading percentage of computation and analyzing how the cell association algorithm allows energy saving and shortens computation time. The results show that when the network is overloaded, the proposed utility function allows to respect the target values by achieving higher throughput values, and reducing the energy consumption and the computational time.},
keywords={Throughput;Quality of service;Mobile communication;Servers;Mobile computing;Mobile handsets;Energy consumption},
doi={10.1109/GLOCOM.2014.7037229},
ISSN={1930-529X},
month={Dec},}
@ARTICLE{9354861,
author={Sacco, Alessio and Flocco, Matteo and Esposito, Flavio and Marchetto, Guido},
journal={IEEE Transactions on Network and Service Management}, title={Supporting Sustainable Virtual Network Mutations With Mystique},
year={2021},
volume={18},
number={3},
pages={2714-2727},
abstract={The abiding attempt of automation has also permeated the networks, with the ability to measure, analyze, and control themselves in an automated manner, by reacting to changes in the environment (e.g., demand). When provided with these features, networks are often labeled as “self-driving” or “autonomous”. In this regard, the provision and orchestration of physical or virtual resources are crucial for both Quality of Service (QoS) guarantees and cost management in the edge/cloud computing environment. To effectively manage the lifecycle of these resources, an auto-scaling mechanism is essential. However, traditional threshold-based and recent Machine Learning (ML)-based policies are often unable to address the soaring complexity of networks due to their centralized approach. By relying on multi-agent reinforcement learning, we propose Mystique, a solution that learns from the load on links to establish the minimal set of active network resources. As traffic demands ebb and flow, our adaptive and self-driving solution can scale up and down and also react to failures in a fully automated, flexible, and efficient manner. Our results demonstrate that the presented solution can reduce network energy consumption while providing an adequate service level, outperforming other benchmark auto-scaling approaches.},
keywords={Reinforcement learning;Quality of experience;Load modeling;Topology;Routing;Monitoring;Complexity theory;SDN;reinforcement learning;auto-scaling;network management},
doi={10.1109/TNSM.2021.3059647},
ISSN={1932-4537},
month={Sep.},}
@INPROCEEDINGS{9183589,
author={Winzinger, Stefan and Wirtz, Guido},
booktitle={2020 IEEE International Conference on Service Oriented Systems Engineering (SOSE)}, title={Applicability of Coverage Criteria for Serverless Applications},
year={2020},
volume={},
number={},
pages={49-56},
abstract={Serverless computing is a popular trend in cloud computing based on serverless functions. These functions are stateless which can be utilized by the cloud platform provider to scale functions dynamically. While these small functions are easy to test in isolation, integrating them with other resources provided by the cloud platform provider or third parties creates a complex system whose emerging behavior is hard to test. Integration tests help test the interaction of the serverless functions with other resources and their environment. However, it is hard to decide if a test case is adequate and focuses on the critical parts of the system. Therefore, coverage criteria can be used to measure the coverage of the relevant software components and help assess the quality of the test suite. In this paper, we identified serverless applications based on serverless functions on GitHub and used them to investigate which coverage criteria can be used to capture the interaction of serverless functions with other resources. Furthermore, we show a general approach to implement the measurement of the coverage on FaaS platforms. Thus, developers have means to test the adequacy of their applications on any FaaS platform.},
keywords={Memory;FAA;Cloud computing;Logic gates;Biological system modeling;Data models;Focusing;Serverless Computing;FaaS;Integration Testing;Coverage Criteria},
doi={10.1109/SOSE49046.2020.00013},
ISSN={2642-6587},
month={Aug},}
@INPROCEEDINGS{7983102,
author={Ekanayake, Wijaya and Amarasinghe, Heli and Karmouch, Ahmed},
booktitle={2017 14th IEEE Annual Consumer Communications Networking Conference (CCNC)}, title={SDN-based IaaS for mobile computing},
year={2017},
volume={},
number={},
pages={179-184},
abstract={Mobile Cloud Computing enables resource limited mobile devices to support rich application services. Among three types of cloud services, Infrastructure-as-a-Service (IaaS) clouds provides compute infrastructure for mobile applications on demand. In IaaS-based mobile clouds, latency and bandwidth requirements can considered as critical factors impacting Quality of Service (QoS). Opposed to centralized clouds, geographically distributed clouds realize higher QoS benefiting the proximity to the end user. In this paper, we propose an IaaS framework with regional datacenters for mobile clouds. With the benefits of software-defined networking (SDN), we address impacts on QoS during mobility by serving mobile user via the optimum datacenter. A test-bed was developed to measure the performance of service allocation and relocation in proposed framework.},
keywords={Cloud computing;Mobile communication;Quality of service;IP networks;Mobile computing;Mobile handsets;Resource management;Cloud Computing;Mobile Clouds;Infrastructure-as-a-Service;Software-defined-networking},
doi={10.1109/CCNC.2017.7983102},
ISSN={2331-9860},
month={Jan},}
@ARTICLE{8489955,
author={Nguyen, Tien-Dung and Huh, Eui-Nam and Jo, Minho},
journal={IEEE Internet of Things Journal}, title={Decentralized and Revised Content-Centric Networking-Based Service Deployment and Discovery Platform in Mobile Edge Computing for IoT Devices},
year={2019},
volume={6},
number={3},
pages={4162-4175},
abstract={Mobile edge computing (MEC) is used to offload services (tasks) from cloud computing in order to deliver those services to mobile Internet of Things (IoT) devices near mobile edge nodes. However, even though there are advantages to MEC, we face many significant problems, such as how a service provider (SP) deploys requested services efficiently on a destination MEC node, and how to discover existing services in neighboring MEC nodes to save edge resources. In this paper, we present a decentralized and revised content-centric networking (CCN)-based MEC service deployment/discovery protocol and platform. We organized a gateway in every area according to a three-tiered hierarchical MEC network topology to reduce computing overhead at the centralized controller. We revised CCN to introduce a protocol to help SP deploy their service on MEC node and assist MEC node discover services in neighboring nodes. By using our proposed protocol, MEC nodes can deploy or discover the requested service instances in the proximity of IoT devices to reduce transmission delay. We also present a mathematical model to calculate the round trip time to guarantee quality of service. Numerical experiments measure the performance of our proposed method with various mobile IoT device services. The results show that the proposed service deployment protocol and platform reduce the average service delay by up to 50% compared to legacy cloud. In addition, the proposed method outperforms the legacy protocol of the MEC environment in service discovery time.},
keywords={Cloud computing;Protocols;Edge computing;Internet of Things;Quality of service;Delays;5G mobile communication;Cloud;fog;Internet of Things (IoT);mobile edge computing (MEC);offloading;service deployment;service discovery},
doi={10.1109/JIOT.2018.2875489},
ISSN={2327-4662},
month={June},}
@ARTICLE{7972945,
author={He, Jianhua and Wei, Jian and Chen, Kai and Tang, Zuoyin and Zhou, Yi and Zhang, Yan},
journal={IEEE Internet of Things Journal}, title={Multitier Fog Computing With Large-Scale IoT Data Analytics for Smart Cities},
year={2018},
volume={5},
number={2},
pages={677-686},
abstract={Analysis of Internet of Things (IoT) sensor data is a key for achieving city smartness. In this paper a multitier fog computing model with large-scale data analytics service is proposed for smart cities applications. The multitier fog is consisted of ad-hoc fogs and dedicated fogs with opportunistic and dedicated computing resources, respectively. The proposed new fog computing model with clear functional modules is able to mitigate the potential problems of dedicated computing infrastructure and slow response in cloud computing. We run analytics benchmark experiments over fogs formed by Rapsberry Pi computers with a distributed computing engine to measure computing performance of various analytics tasks, and create easy-to-use workload models. Quality of services (QoS) aware admission control, offloading, and resource allocation schemes are designed to support data analytics services, and maximize analytics service utilities. Availability and cost models of networking and computing resources are taken into account in QoS scheme design. A scalable system level simulator is developed to evaluate the fog-based analytics service and the QoS management schemes. Experiment results demonstrate the efficiency of analytics services over multitier fogs and the effectiveness of the proposed QoS schemes. Fogs can largely improve the performance of smart city analytics services than cloud only model in terms of job blocking probability and service utility.},
keywords={Edge computing;Computational modeling;Cloud computing;Smart cities;Quality of service;Data analysis;Analytical models;Data analytics;fog computing;Internet of Things (IoT);quality of services (QoS);Raspberry Pi;smart cities;Spark},
doi={10.1109/JIOT.2017.2724845},
ISSN={2327-4662},
month={April},}
@INBOOK{9116755,
author={Wu, Chu‐ge and Wang, Ling},
booktitle={Fog Computing: Theory and Practice}, title={An Estimation of Distribution Algorithm to Optimize the Utility of Task Scheduling Under Fog Computing Systems},
year={2020},
volume={},
number={},
pages={371-384},
abstract={The Internet of Things (IoT) is realized initially today. A large amount of data is produced and a range of IoT services are settled down. Based on it, a range of responsive IoT applications arise. To satisfy the quality of experience (QoE) of users, the applications are needed to be processed in a timely manner. Compared with traditional cloud computing systems, fog computing is one of the promising solutions to processing the huge amount of local data and decreasing the end‐to‐end latency. Different time‐dependent functions are adopted to measure the utility of different tasks and in this work, the resource allocation and task scheduling problem under the fog system is considered to maximize the sum of the utility of tasks. And an estimation of distributed algorithm to maximum the task utility (uEDA) with a repair procedure and local search is adopted to determine the task processing order and computing node allocation. The comparative results show that the performance of our algorithm exceeds significantly the heuristic method on the utility metrics.},
keywords={Task analysis;Internet of Things;Edge computing;Computational modeling;Processor scheduling;Scheduling;Optimization},
doi={10.1002/9781119551713.ch14},
ISSN={},
publisher={Wiley},
isbn={9781119551768},
url={https://ieeexplore.ieee.org/document/9116755},}
@ARTICLE{7090976,
author={Candeia, David and Santos, Ricardo Araújo and Lopes, Raquel},
journal={IEEE Transactions on Cloud Computing}, title={Business-Driven Long-Term Capacity Planning for SaaS Applications},
year={2015},
volume={3},
number={3},
pages={290-303},
abstract={Capacity Planning is one of the activities developed by Information Technology departments over the years, it aims at estimating the amount of resources needed to offer a computing service. This activity contributes to achieving high Quality of Service levels and also to pursuing better economic results for companies. In the Cloud Computing context, one plausible scenario is to have Software-as-a-Service (SaaS) providers that build their IT infrastructure acquiring resources from Infrastructure-as-a-Service (IaaS) providers. SaaS providers can reduce operational costs and complexity by buying instances from a reservation market, but then need to predict the number of instances needed in the long-term. This work investigates how important is the capacity planning in this context and how simple business-driven heuristics for long-term capacity planning impact on the profit achieved by SaaS providers. Simulation experiments were performed using synthetic e-commerce workloads. Our analysis show that proposed heuristics increase SaaS provider profit, on average, at 9.6501 percent per year. Analysing such results we demonstrate that capacity planning is still an important activity, contributing to the increase of SaaS providers profit. Besides, a good capacity planning may also avoid bad reputation due to unacceptable performance, which is a gain very hard to measure.},
keywords={Capacity planning;Cloud computing;Measurement;Contracts;Quality of service;Planning;Capacity Planning;Cloud Computing;Software-as-a-Service;Capacity planning;cloud computing;software-as-a-service},
doi={10.1109/TCC.2015.2424877},
ISSN={2168-7161},
month={July},}
@ARTICLE{8207422,
author={Noormohammadpour, Mohammad and Raghavendra, Cauligi S.},
journal={IEEE Communications Surveys Tutorials}, title={Datacenter Traffic Control: Understanding Techniques and Tradeoffs},
year={2018},
volume={20},
number={2},
pages={1492-1525},
abstract={Datacenters provide cost-effective and flexible access to scalable compute and storage resources necessary for today's cloud computing needs. A typical datacenter is made up of thousands of servers connected with a large network and usually managed by one operator. To provide quality access to the variety of applications and services hosted on datacenters and maximize performance, it deems necessary to use datacenter networks effectively and efficiently. Datacenter traffic is often a mix of several classes with different priorities and requirements. This includes user-generated interactive traffic, traffic with deadlines, and long-running traffic. To this end, custom transport protocols and traffic management techniques have been developed to improve datacenter network performance. In this tutorial paper, we review the general architecture of datacenter networks, various topologies proposed for them, their traffic properties, general traffic control challenges in datacenters and general traffic control objectives. The purpose of this paper is to bring out the important characteristics of traffic control in datacenters and not to survey all existing solutions (as it is virtually impossible due to massive body of existing research). We hope to provide readers with a wide range of options and factors while considering a variety of traffic control mechanisms. We discuss various characteristics of datacenter traffic control, including management schemes, transmission control, traffic shaping, prioritization, load balancing, multipathing, and traffic scheduling. Next, we point to several open challenges as well as new and interesting networking paradigms. At the end of this paper, we briefly review inter-datacenter networks that connect geographically dispersed datacenters, which have been receiving increasing attention recently and pose interesting and novel research problems. To measure the performance of datacenter networks, different performance metrics have been used, such as flow completion times, deadline miss rate, throughput, and fairness. Depending on the application and user requirements, some metrics may need more attention. While investigating different traffic control techniques, we point out the tradeoffs involved in terms of costs, complexity, and performance. We find that a combination of different traffic control techniques may be necessary at particular entities and layers in the network to improve the variety of performance metrics. We also find that despite significant research efforts, there are still open problems that demand further attention from the research community.},
keywords={Network topology;Topology;Servers;Bandwidth;Tutorials;Optical switches;Datacenters;traffic control;tradeoffs;management schemes;transmission control;traffic shaping;load balancing;flow prioritization;multipath routing;traffic scheduling},
doi={10.1109/COMST.2017.2782753},
ISSN={1553-877X},
month={Secondquarter},}
@ARTICLE{8762170,
author={AbdelBaky, Moustafa and Parashar, Manish},
journal={IEEE Transactions on Services Computing}, title={A General Performance and QoS Model for Distributed Software-Defined Environments},
year={2019},
volume={},
number={},
pages={1-1},
abstract={The landscape for cloud services and cyberinfrastructure offerings has increased drastically over the past few years. Initially, users moved their applications to the cloud to take advantage of a pay-per-usage model and on-demand access. However, as more cloud providers joined the market, users shifted their goals for using cloud computing from cost reduction to resilience, agility, and optimization. These goals can be achieved by dynamically combining services from multiple providers, for example, to avoid data center or cloud zone outages or to take advantage of extensive offerings with different price points. However, to efficiently support application deployment in this dynamic environment, new models and tools that can measure the application performance and the Quality of Service (QoS) of different configurations are required. The goal of this work is to evaluate the application performance and the QoS of a distributed Software-Defined Environment as well as calculate the QoS of alternative configurations from the underlying pool of services. In particular, we present a mathematical model and a tool for evaluating the performance and QoS of batch application workflows in a distributed environment. We experimentally evaluate the proposed model using a bioinformatics workflow running on infrastructure services from multiple cloud providers.},
keywords={Cloud computing;Quality of service;Computational modeling;Data models;Optimization;Mathematical model;Tools;QoS modeling;performance modeling;multi-cloud;software-define environments},
doi={10.1109/TSC.2019.2928300},
ISSN={1939-1374},
month={},}
@ARTICLE{9489314,
author={Cheikhrouhou, Omar and Mahmud, Redowan and Zouari, Ramzi and Ibrahim, Muhammad and Zaguia, Atef and Gia, Tuan Nguyen},
journal={IEEE Access}, title={One-Dimensional CNN Approach for ECG Arrhythmia Analysis in Fog-Cloud Environments},
year={2021},
volume={9},
number={},
pages={103513-103523},
abstract={Cardiovascular diseases are considered the number one cause of death across the globe which can be primarily identified by the abnormal heart rhythms of the patients. By generating electrocardiogram (ECG) signals, wearable Internet of Things (IoT) devices can consistently track the patient’s heart rhythms. Although Cloud-based approaches for ECG analysis can achieve some levels of accuracy, they still have some limitations, such as high latency. Conversely, the Fog computing infrastructure is more powerful than edge devices but less capable than Cloud computing for executing compositionally intensive data analytic software. The Fog infrastructure can consist of Fog-based gateways directly connected with the wearable devices to offer many advanced benefits, including low latency and high quality of services. To address these issues, a modular one-dimensional convolution neural network (1D-CNN) approach is proposed in this work. The inference module of the proposed approach is deployable over the Fog infrastructure for analysing the ECG signals and initiating the emergency countermeasures within a minimum delay, whereas its training module is executable on the computationally enriched Cloud data centers. The proposed approach achieves the F1-measure score ≈1 on the MIT-BIH Arrhythmia database when applying GridSearch algorithm with the cross-validation method. This approach has also been implemented on a single-board computer and Google Colab-based hybrid Fog-Cloud infrastructure and embodied to a remote patient monitoring system that shows 25% improvement in the overall response time.},
keywords={Electrocardiography;Cloud computing;Logic gates;Feature extraction;Security;Edge computing;Wearable computers;Internet of Things;ECG analysis;1D-CNN;fog computing;hybrid fog-cloud;heart disease},
doi={10.1109/ACCESS.2021.3097751},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8366932,
author={Zhou, Peipei and Ruan, Zhenyuan and Fang, Zhenman and Shand, Megan and Roazen, David and Cong, Jason},
booktitle={2018 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)}, title={Doppio: I/O-Aware Performance Analysis, Modeling and Optimization for In-memory Computing Framework},
year={2018},
volume={},
number={},
pages={22-32},
abstract={In conventional Hadoop MapReduce applications, I/O used to play a heavy role in the overall system performance. More recently, a study from the Apache Spark community- state-of-the-art in-memory cluster computing framework- reports that I/O is no longer the bottleneck and has a marginal performance impact on applications like SQL processing. However, we observe that simply replacing HDDs with SSDs in a Spark cluster can have over 10x performance improvement for certain stages in large-scale production-quality genome processing. Therefore, one key question arises: How does I/O quanti- tatively impact the performance of today's big data applications developed using in-memory cluster computing frameworks like Apache Spark? In this paper we select an important yet complex application- the Spark-based Genome Analysis ToolKit (GATK4)-to guide our modeling. We first use different combinations of HDDs and SSDs to measure the I/O impact on GATK4 and change the CPU core number to discover the relation between computation and I/O access. By combining with Spark's underlying implementations, we further analyze the inherent cause of the above observations and build our model based on the analysis. Although we are building upon GATK4, our model maintains generality to other applications. Experimental results show that we can achieve a performance prediction error rate within 10% for typical Spark applications of both iterative and shuffle-heavy algorithms. Finally, we further extend our model to a broader area-that of optimal configuration selection in the public cloud. In Google Cloud, our model enables us to save 38% to 57% of cost for genome sequencing compared with its recommended default configurations. Currently, more and more companies are adopting cloud computing for specific workloads. Our proposed model can have a huge impact on their choices, while also enabling them to significantly reduce their costs.},
keywords={Sparks;Genomics;Bioinformatics;Computational modeling;Analytical models;Cloud computing;Performance Modeling;Apache Spark;I/O Aware;Computational Genomics;Cost Optimization;Genome Analysis Toolkit;GATK4},
doi={10.1109/ISPASS.2018.00011},
ISSN={},
month={April},}
@INPROCEEDINGS{9443978,
author={Yu, Zhixing and He, Kejing and Chen, Chao and Wang, Jian},
booktitle={2020 IEEE Intl Conf on Parallel Distributed Processing with Applications, Big Data Cloud Computing, Sustainable Computing Communications, Social Computing Networking (ISPA/BDCloud/SocialCom/SustainCom)}, title={Live Container Migration via Pre-restore and Random Access Memory},
year={2020},
volume={},
number={},
pages={102-109},
abstract={Container technology is increasingly being used for virtualization due to its ability to isolate the operating environment of the program. In cloud computing environment, we need to migrate containers between different hosts for load balancing or downtime maintenance. However, during the migration process, the container will be temporarily shut down, and the service will be unavailable. Therefore, the time cost is an essential indicator to measure the quality of the migration process. To achieve live container migration, we propose a pre-restore method and a complete random access memory (RAM) based method to migrate containers. Extensive experiments validate the effectiveness of our methods in reducing downtime and improving the efficiency of container migration.},
keywords={Cloud computing;Random access memory;Containers;Maintenance engineering;Load management;Time measurement;Virtualization;Container;Live migration;Downtime;Pre-restore;RAM},
doi={10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00039},
ISSN={},
month={Dec},}
@INPROCEEDINGS{7391921,
author={Sudipta Singha Roy and Tamjid Haque Sarker and Hashem, M. M. A.},
booktitle={2015 2nd International Conference on Electrical Information and Communication Technologies (EICT)}, title={A novel trust measurement system for cloud-based marketplace},
year={2015},
volume={},
number={},
pages={49-54},
abstract={Cloud Computing is an enormously growing phenomenon in the present days enabling IT related services to run in a more dynamic and scalable way than the previous days and cloud marketplace is becoming more competitive with the entrance of new cloud service providers (CSP) offering similar functionalities. The basic obstacles in the way of success of cloud marketplace are the numerous shortcomings in reliable monitoring and identifying reliable cloud service provider based on consumers' preferred services. In this paper, a multi-faceted Entrusted Trust Management (ETM) system architecture is introduced that can support the customers in reliably choosing the trustworthy cloud service provider (CSP) as well as properly weight the information sources that provide feedbacks about the quality of services (QoS) of the CSPs. This ETM system works on several issues to measure the trust value of the providers on specific domain and overall trust value. Firstly, measurement of the trust value of the specific domain of provider on the basis of certainty and uncertainty. Secondly, measurement of overall trust value of the provider from these domain specific trust values. Thirdly, measurement of “Degree of Conflict” between the rating/feedback of consumers and experts. And finally, measurement of trustworthiness of the information sources which provide the rating of the provider on the basis of the SLA between the provider and the consumer. At last, our proposed system is experimented using real datasets.},
keywords={Cloud computing;Cloud Service Provider;Trust Models;Trust Management;CAIQ;Self-Assessment},
doi={10.1109/EICT.2015.7391921},
ISSN={},
month={Dec},}
@ARTICLE{9165739,
author={Gao, Zihan and Hao, Wanming and Han, Zhuo and Yang, Shouyi},
journal={IEEE Access}, title={Q-Learning-Based Task Offloading and Resources Optimization for a Collaborative Computing System},
year={2020},
volume={8},
number={},
pages={149011-149024},
abstract={Mobile edge computing (MEC) can effectively overcome the shortcomings of high-latency in mobile cloud computing (MCC) by deploying the cloud resources, e.g., storage and computational capability, to the edge. However, the limited computation capability of the MEC restricts the scalability of offloading. Therefore, the basic requirements of the MEC system are to explore effective offloading decisions and resource allocation methods. To address it, we develop a collaborative computing system composed of local computing (mobile device), MEC (edge cloud) and MCC (central cloud). Based on the proposed collaborative computing system, we design a novel Q-learning based computation offloading (QLCOF) policy to achieve the optimal resource allocation and offloading scheme by prescheduling the computation side for each task from a global perspective. Specifically, we first model the offloading decision process as a Markov decision process (MDP) and design a state loss function (STLF) to measure the quality of experience (QoE). After that, we define the cumulation of STLFs as the system loss function (SYLF) and formulate an SYLF minimization problem. Due to the difficulty to directly solve the formulated problem, we decompose it into multiple subproblems and preferentially optimize the transmission power and computation frequency of the edge cloud by the quasi-convex bisection and polynomial analysis method, respectively. Based on the precalculated offline transmission power and edge cloud computation frequency, we develop a Q-learning based offloading (QLOF) scheme to minimize the SYLF by optimizing offloading decisions. Finally, the numeral results show that the proposed QLOF scheme effectively reduces the SYLF under different parameters.},
keywords={Cloud computing;Task analysis;Collaboration;Mobile handsets;Computational modeling;Resource management;Loss measurement;Mobile edge computing (MEC);mobile cloud computing (MCC);offloading;resources allocation;MDP;Q-learning},
doi={10.1109/ACCESS.2020.3015993},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9210369,
author={Rico-Bautista, Dewar and Maestre-Gongora, Gina and Guerrero, Cesar D.},
booktitle={2020 Fourth World Conference on Smart Trends in Systems, Security and Sustainability (WorldS4)}, title={Smart University:IoT adoption model},
year={2020},
volume={},
number={},
pages={821-826},
abstract={Higher education organizations see in new technologies an opportunity to improve the quality of their academic and administrative processes. However, the existence and application of new technologies in this type of institutions does not imply that it really has the expected impact on their processes, so many adoption initiatives fail generating losses and discouragement towards change. This happens mainly because more work is done on technology than on the realities of the institutions. One way to prevent this type of problem and redirect efforts is to align the adoption process itself. As artificial intelligence, cloud computing, IoT (Internet of Things) and Big Data technologies become stronger, it is necessary to have tools at hand that have the capacity to measure the level of adoption by institutions. The objective of measuring adoption by the processes and realities of higher education institutions, with a focus on their users. Many models have been proposed to understand why users accept or use technologies. Among those that have emerged for the study of technology adoption are TAM, UTAUT, UTAUT2, DOI, TPB, TRA, among others. This characterization allows us to conclude about the need for alignment and integration of technology with the organization's processes, calling for greater interaction with senior management.},
keywords={Organizations;Internet of Things;Information technology;Computational modeling;Education;Big Data;Cloud computing;Adopting smart technology;Characterization;Process;IoT;Smart university},
doi={10.1109/WorldS450073.2020.9210369},
ISSN={},
month={July},}
@INPROCEEDINGS{7410295,
author={Abtahizadeh, S. Amirhossein and Khomh, Foutse and Guéhéneuc, Yann-Gaël},
booktitle={2015 IEEE 34th International Performance Computing and Communications Conference (IPCCC)}, title={How green are cloud patterns?},
year={2015},
volume={},
number={},
pages={1-8},
abstract={Cloud Patterns are abstract solutions to recurrent design problems in the cloud. Previous work has shown that these patterns can improve the Quality of Service (QoS) of cloud applications but their impact on energy consumption is still unknown. Yet, energy consumption is the biggest challenge that cloud computing systems (the backbone of today's high-tech economy) face today. In fact, 10% of the world's electricity is now being consumed by servers, laptops, tablets and smartphones. Energy consumption has complex dependencies on the hardware platform, and the multiple software layers. The hardware, its firmware, the operating system, and the various software components used by a cloud application, all contribute to determining the energy footprint. Hence, even though increasing a data center efficiency will eventually improve energy efficiency, the internal design of cloud-based applications can be improved to lower energy consumption. In this paper, we conduct an empirical study on a RESTful multi-threaded application deployed in the cloud, to investigate the individual and the combined impact of three cloud patterns (e.g., Local Database proxy, Local Sharding Based Router and Priority Queue) on the energy consumption of cloud based applications. We measure the energy consumption using Power-API; an application programming interface (API) written in Java to monitor the energy consumed at the process-level. Results show that cloud patterns can effectively reduce the energy consumption of a cloud application, but not in all cases. In general, there appear to be a trade-off between an improved response time of the application and the energy consumption. Developers and software architects can make use of these results to guide their design decisions.},
keywords={Cloud computing;Energy consumption;Databases;Energy measurement;Servers;Quality of service;Cloud Patterns;Energy Consumption;Energy Efficiency;Sharding;Priority Message Queue},
doi={10.1109/PCCC.2015.7410295},
ISSN={2374-9628},
month={Dec},}
@ARTICLE{7343819,
author={Liu, Jiangchuan and Zhu, Wenwu and Ebrahimi, Touradj and Apostolopoulos, John and Hua, Xian-Sheng and Wu, Chuan},
journal={IEEE Transactions on Circuits and Systems for Video Technology}, title={Introduction to the Special Section on Visual Computing in the Cloud: Fundamentals and Applications},
year={2015},
volume={25},
number={12},
pages={1885-1887},
abstract={Cloud computing involves a large number of terminals connected through a real-time high-speed network (such as the Internet). The adoption rates for private and hybrid cloud services increased to 40% in 2013, with computing shifting from on-premise infrastructure to the cloud. To keep pace with the ever-accelerating rate of innovation, companies are moving to the cloud. However, visual computing in the cloud brings great challenges, such as how to measure and then improve the quality of experience in cloud computing. This Special Section provides the image/video community a forum to present new academic research and industrial development in running visual computing services in the cloud. This Special Section aims to address fundamental and practical aspects of visual computing in the cloud, such as how to build cloud platforms that can cope with seemingly unlimited supply of content coming from traditional media sources as well as new media uploaded to the Internet (YouTube, Facebook, etc.); how to leverage cloud technology to build high-quality image/video browsing and delivery experiences for a global audience; how to ingest, encode, process, adapt, as well as protect contents and privacy of users; how to provide both on-demand and live-streaming capabilities; how to tag image/video and allow consumers to access the image/video contents with high availability; how to support image/video services in mobile devices; and how to perform real-time image/video analytics in the cloud, to mention a few among a diverse range of challenges.},
keywords={Special issues and sections;Cloud computing;Social network services;Streaming media;Transcoding},
doi={10.1109/TCSVT.2015.2472955},
ISSN={1558-2205},
month={Dec},}
