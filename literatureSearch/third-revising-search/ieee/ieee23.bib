@INPROCEEDINGS{6903296,
  author={Cao, Fei and Zhu, Michelle M. and Wu, Chase Q.},
  booktitle={2014 IEEE World Congress on Services}, 
  title={Energy-Efficient Resource Management for Scientific Workflows in Clouds}, 
  year={2014},
  volume={},
  number={},
  pages={402-409},
  abstract={The elastic resource provision, non-interfering resource sharing and flexible customized configuration provided by the Cloud infrastructure has shed light on efficient execution of many scientific applications. Due to the increasing deployment of data centers and computer servers around the globe escalated by the higher electricity price, the energy cost on running the computing, communication and cooling together with the amount of CO2 emissions have skyrocketed. In order to maintain sustainable Cloud computing facing with ever-increasing problem complexity and big data size in the next decades, we design and develop energy-aware scientific workflow scheduling algorithm to minimize energy consumption and CO2 emission while still satisfying certain Quality of Service (QoS) such as response time specified in Service Level Agreement (SLA). We also apply Dynamic Voltage and Frequency Scaling (DVFS) and DNS scheme to further reduce energy consumption within acceptable performance bounds. Our multiple-step resource provision and allocation algorithm achieves the response time requirement in the step of forwarding task scheduling and minimizes the VM overhead for reduced energy consumption and higher resource utilization rate in the backward task scheduling step. The effectiveness of our algorithm is evaluated under various performance metrics and experimental scenarios using software adapted from open source CloudSim simulator.},
  keywords={},
  doi={10.1109/SERVICES.2014.76},
  ISSN={2378-3818},
  month={June},}@INPROCEEDINGS{6930517,
  author={Yaqub, Edwin and Yahyapour, Ramin and Wieder, Philipp and Kotsokalis, Constantinos and Lu, Kuan and Jehangiri, Ali Imran},
  booktitle={2014 IEEE International Conference on Services Computing}, 
  title={Optimal Negotiation of Service Level Agreements for Cloud-Based Services through Autonomous Agents}, 
  year={2014},
  volume={},
  number={},
  pages={59-66},
  abstract={Cloud-based services have become a cornerstone of today's IT. The self-service feature inherent in Cloud systems allows customers to play a greater role in service procurement. However, this restricts the value propositions and Service Level Agreements (SLAs) that Cloud providers offer because Quality of Service (QoS) and Non Functional Property (NFP) requirements vary from customer to customer. In feature-rich SLA templates, the contract space gets large, objectives are confidential and preferences over QoS and NFP often conflict between providers and customers. Hence, an SLA-gap exists between the two and contemporary providers bind their offerings to the inflexible take-it-or-leave-it SLAs. In this work, we address this problem by presenting a robust and computationally inexpensive negotiation strategy, using which agents can efficiently create near-optimal SLAs under time constraints. Experimental evaluations validate that our strategy performs at par with state of the art learning and non-learning strategies against a variety of metrics including utility, social welfare, social utility and the Pareto-optimal bids. This enables a dynamic SLA negotiation mechanism on top of our OpenShift (PaaS) based Cloud system designed using Service Oriented Cloud Computing Infrastructure (SOCCI) architecture. Negotiated procurement of services is shown to improve satisfaction of participants and reducing the SLA-gap.},
  keywords={},
  doi={10.1109/SCC.2014.17},
  ISSN={},
  month={June},}@ARTICLE{8641327,
  author={Zhou, Xijia and Li, Kenli and Liu, Chubo and Li, Keqin},
  journal={IEEE Access}, 
  title={An Experience-Based Scheme for Energy-SLA Balance in Cloud Data Centers}, 
  year={2019},
  volume={7},
  number={},
  pages={23500-23513},
  abstract={The proliferation of cloud computing has resulted in the establishment of large-scale data centers containing thousands of computing nodes and consuming enormous amounts of electrical energy. However, the low-cost and high-efficiency slogans are getting louder and louder, and the IT industry is also striving for this pursuit. Therefore, it is vital to minimizing the energy consumption for cloud providers while ensuring the quality of service for cloud users. In this paper, we propose several heuristic strategies to optimize these two metrics based on a two-level management model under a heterogeneous cloud environment. First, to detect whether a physical node is continuously overloaded, we propose an empirical forecast algorithm, which predicts the future state of the host by statistically analyzing the historical utilization data of the host. Second, we propose a weighted priority virtual machine (VM) selection algorithm. For each VM on the overloaded host, we weight several utilization factors and calculate its migration priority. Then, we simulate the proposed approach and compare it with the existing overloaded hosts detection algorithms with different VM selection policies under different workloads.},
  keywords={},
  doi={10.1109/ACCESS.2019.2899101},
  ISSN={2169-3536},
  month={},}@ARTICLE{9178309,
  author={He, Xingqiu and Wang, Sheng},
  journal={IEEE Internet of Things Journal}, 
  title={Peer Offloading in Mobile-Edge Computing With Worst Case Response Time Guarantees}, 
  year={2021},
  volume={8},
  number={4},
  pages={2722-2735},
  abstract={Mobile-edge computing (MEC) is a new paradigm that provides cloud computing services at the edge of networks. To achieve better performance with limited computing resources, peer offloading between cooperative edge servers (e.g., MEC-enabled base stations) has been proposed as an effective technique to handle bursty and spatially imbalanced arrival of computation tasks. While various performance metrics of peer offloading policies have been considered in the literature, the worst case response time, a common quality of service (QoS) requirement in real-time applications, yet receives much less attention. To fill the gap, we formulate the peer offloading problem based on a stochastic arrival model and propose two online algorithms for cases with and without prior knowledge of task arrival rate. Our goal is to maximize the utility function of time-average throughput under constraints of energy consumption and worst case response time. Both theoretical analysis and numerical results show that our algorithms are able to produce close to optimal performance.},
  keywords={},
  doi={10.1109/JIOT.2020.3019492},
  ISSN={2327-4662},
  month={Feb},}@INPROCEEDINGS{8514452,
  author={Alqahtani, Awatif and Li, Yinhao and Patel, Pankesh and Solaiman, Ellis and Ranjan, Rajiv},
  booktitle={2018 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={End-to-End Service Level Agreement Specification for IoT Applications}, 
  year={2018},
  volume={},
  number={},
  pages={926-935},
  abstract={The Internet of Things (IoT) promises to help solve a wide range of issues that relate to our wellbeing within applicaÂ¬tion domains that include smart cities, healthcare monitoring, and environmental monitoring. IoT is bringing new wireless sensor use cases by taking advantage of the computing power and flexibility provided by Edge and Cloud Computing. However, the software and hardware resources used within such applications must perform correctly and optimally. Especially in applications where a failure of resources can be critical. Service Level Agreements (SLA) where the performance requirements of such applications are defined, need to be specified in a standard way that reflects the end-to-end nature of IoT application domains, accounting for the Quality of Service (QoS) metrics within every layer including the Edge, Network Gateways, and Cloud. In this paper, we propose a conceptual model that captures the key entities of an SLA and their relationships, as a prior step for end-to-end SLA specification and composition. Service level objective (SLO) terms are also considered to express the QoS constraints. Moreover, we propose a new SLA grammar which considers workflow activities and the multi-layered nature of IoT applications. Accordingly, we develop a tool for SLA specification and composition that can be used as a template to generate SLAs in a machine-readable format. We demonstrate the effectiveness of the proposed specification language through a literature survey that includes an SLA language comparison analysis, and via reflecting the user satisfaction results of a usability study.},
  keywords={},
  doi={10.1109/HPCS.2018.00147},
  ISSN={},
  month={July},}@INPROCEEDINGS{8969716,
  author={Maliszewski, Anderson M. and Vogel, Adriano and Griebler, Dalvan and Roloff, Eduardo and Fernandes, Luiz G. and Philippe O. A., Navaux},
  booktitle={2019 IEEE Symposium on Computers and Communications (ISCC)}, 
  title={Minimizing Communication Overheads in Container-based Clouds for HPC Applications}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={Although the industry has embraced the cloud computing model, there are still significant challenges to be addressed concerning the quality of cloud services. Network-intensive applications may not scale in the cloud due to the sharing of the network infrastructure. In the literature, performance evaluation studies are showing that the network tends to limit the scalability and performance of HPC applications. Therefore, we proposed the aggregation of Network Interface Cards (NICs) in a ready-to-use integration with the OpenNebula cloud manager using Linux containers. We perform a set of experiments using a network microbenchmark to get specific network performance metrics and NAS parallel benchmarks to analyze the performance impact on HPC applications. Our results highlight that the implementation of NIC aggregation improves network performance in terms of throughput and latency. Moreover, HPC applications have different patterns of behavior when using our approach, which depends on communication and the amount of data transferring. While network-intensive applications increased the performance up to 38%, other applications with aggregated NICs maintained the same performance or presented slightly worse performance.},
  keywords={},
  doi={10.1109/ISCC47284.2019.8969716},
  ISSN={2642-7389},
  month={June},}@INPROCEEDINGS{7214120,
  author={Bruneo, Dario and Longo, Francesco and Ghosh, Rahul and Scarpa, Marco and Puliafito, Antonio and Trivedi, Kishor S.},
  booktitle={2015 IEEE 8th International Conference on Cloud Computing}, 
  title={Analytical Modeling of Reactive Autonomic Management Techniques in IaaS Clouds}, 
  year={2015},
  volume={},
  number={},
  pages={797-804},
  abstract={Cloud computing infrastructures provide services to a wide number of users whose behavior can deeply change at the occurrence of particular events. To correctly handle such situations a cloud infrastructure have to be reconfigured in a way that does not cause degradation in the overall performance. Otherwise, the quality of service specified in the service level agreement could be violated. To prevent such situations, the infrastructure could be organized as an autonomic system where self-adaptation and self-configuration techniques are implemented. Appropriate design choices become important in order not to fail in this goal. We propose a technique, based on a Petri net model and a specific analytical analysis approach, to represent Infrastructure-as-a-Service (IaaS) systems in the case in which the load conditions can suddenly change and reactive autonomic management techniques are applied to mitigate the consequences of the change. The model we propose is able to appropriately evaluate performance metrics in such critical situations making it suitable as a design tool for IaaS cloud systems.},
  keywords={},
  doi={10.1109/CLOUD.2015.110},
  ISSN={2159-6190},
  month={June},}@INPROCEEDINGS{6969013,
  author={Tchernykh, Andrei and Lozano, Luz and Schwiegelshohn, Uwe and Bouvry, Pascal and Pecero, Johnatan E. and Nesmachnow, Sergio},
  booktitle={2014 IEEE 3rd International Conference on Cloud Networking (CloudNet)}, 
  title={Bi-objective online scheduling with quality of service for IaaS clouds}, 
  year={2014},
  volume={},
  number={},
  pages={307-312},
  abstract={This paper focuses on the bi-objective experimental analysis of online scheduling in the Infrastructure as a Service model of Cloud computing. In this model, customer have the choice between different service levels. Each service level is associated with a price per unit of job execution time and a slack factor that determines the maximal time span to deliver the requested amount of computing resources. It is responsibility of the system and its scheduling algorithm to guarantee the corresponding quality of service for all accepted jobs. We do not consider any optimistic scheduling approach, that is, a job cannot be accepted if its service guarantee will not be observed assuming that all accepted jobs receive the requested resources. We analyze several scheduling algorithms with different cloud configurations and workloads and use the maximization of the provider income and minimization of the total power consumption of a schedule as additional objectives. Therefore, we cannot expect finding a unique solution to a given problem but a set of nondominated solutions also known as Pareto optima. Then we assess the performance of different scheduling algorithms by using a set coverage metric to compare them in terms of Pareto dominance. Based on the presented case study, we claim that a simple algorithm can provide the best energy and income trade-offs. This scheduling algorithm performs well in different scenarios with a variety of workloads and cloud configurations.},
  keywords={},
  doi={10.1109/CloudNet.2014.6969013},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9092335,
  author={Meyer, VinÃ­cius and Kirchoff, DionatrÃ£ F. and da Silva, Matheus L. and De Rose, CÃ©sar A.F.},
  booktitle={2020 28th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)}, 
  title={An Interference-Aware Application Classifier Based on Machine Learning to Improve Scheduling in Clouds}, 
  year={2020},
  volume={},
  number={},
  pages={80-87},
  abstract={To maximize resource utilization and system throughput in cloud platforms, hardware resources are often shared across multiple virtualized services or applications. In such a consolidated scenario, performance of applications running concurrently in the same physical host can be negatively affected due to interference caused by resource contention. This should be taken into account for efficient scheduling of such applications and performance prediction at user level. Nevertheless, resource scheduling in cloud computing is usually based solely on resource capacity, implemented by heuristics such as bin-packing. Our previous work has introduced an interference-aware scheduling model for web-applications considering their resource utilization profile, and to classify applications we applied fixed interference intervals based on common utilization patters. Although this resulted in placements with better overall results, we observed that some applications with more dynamic workload patterns were wrongly classified with intervals. In this paper, we propose an alternative to the use of intervals and present an interference-aware application classifier for cloud-based applications that deals better with dynamic workloads. Our classifier defines automatically interference levels ranges combining two well-known machine learning techniques: Support Vector Machines and K-Means. Preliminary experiments evaluated the applied machine learning techniques in three quality metrics: Accuracy, F1-Score and Rand Index, observing rates over 80%. The proposed solution creates a workload-aware fine-grained classification that was compared with previous work over different workload scenarios. The results demonstrate that our classification approach improves the placement efficiency by 23% on average.},
  keywords={},
  doi={10.1109/PDP50117.2020.00019},
  ISSN={2377-5750},
  month={March},}@INPROCEEDINGS{8458040,
  author={Ma, Kun and Bagula, Antoine and Mauwa, Hope and Celesti, Antonio},
  booktitle={2018 IEEE 6th International Conference on Future Internet of Things and Cloud (FiCloud)}, 
  title={Modelling Cloud Federation: A Fair Profit Distribution Strategy Using the Shapley Value}, 
  year={2018},
  volume={},
  number={},
  pages={393-398},
  abstract={Cloud computing provides software (Software as a Service), platform (Platform as a Service) and infrastructure (Infrastructure as a Service) services to its users by integrating IT resources into a large-scale and scalable resource pool through the virtualisation technology. However, the single cloud resource provider model currently implemented by many providers may fail short to meet the dynamic nature of cloud users' requirements. Cloud federation can mitigate this issue by optimising cloud resource allocation through sharing and re-usability of available resources. This paper revisit the problem of cloud engineering by tackling the key issue of the fair distribution of profit between cloud resource providers, which, to the best of our knowledge, has only been scarcely addressed by the research and practitioners' community. We propose a method that enables the cloud federation to map the contribution of resources of the participants to the federations into a quality of service metric used to achieve a cloud federation. Building upon a federation game implementation, we reveal the possibilities and benefits of different federation compositions using the Shapley value of each resource provider as a way of implementing a fair profit sharing strategy. Using extensions of the CloudSim package, we present simulation results that demonstrate the fairness of our proposed method and strategy.},
  keywords={},
  doi={10.1109/FiCloud.2018.00063},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9207151,
  author={Wang, Binyang and Li, Huifang and Lin, Zhiwei and Xia, Yuanqing},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Temporal Fusion Pointer network-based Reinforcement Learning algorithm for Multi-Objective Workflow Scheduling in the cloud}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={Cloud computing is emerging as a deployment promising environment for hosting exponentially increasing scientific and social media applications, but how to manage and execute these applications efficiently depends mainly on workflow scheduling. However, scheduling workflows in the cloud is an NP-hard problem and its existing solutions have certain limitations when applied to real-world scenarios. In this paper, a Temporal Fusion Pointer network-based Reinforcement Learning algorithm for multi-objective workflow scheduling (TFP-RL) is proposed. Through adopting reinforcement learning, our algorithm can discover its heuristics over time by continuous learning according to the rewards resulting from good scheduling solutions. To make more comprehensive scheduling decisions as the influence of historical actions, a novel temporal fusion pointer network (TFP) is designed for the reinforcement learning agent, which can improve the quality of our resulting solutions and the ability of our algorithm in dealing with versatile workflow applications. To decrease convergence time, we train the proposed TFP-RL model independently by the Asynchronous Advantage Actor-Critic method and use its resulting model for scheduling workflows. Finally, under a multi-agent reinforcement learning framework, a Pareto dominance-oriented criterion for reasonable action selection is established for a multi-objective optimization scenario. We first train our TFP-RL model by taking randomly generated workflows as inputs to validate its effectiveness in scheduling, then compare our trained model with other existing scheduling approaches through practical compute- and data-intensive workflows. Experimental results demonstrate that our proposed algorithm outperforms the benchmarking ones in terms of different metrics.},
  keywords={},
  doi={10.1109/IJCNN48605.2020.9207151},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{9149347,
  author={Alam, A B M Bodrul and Halabi, Talal and Haque, Anwar and Zulkernine, Mohammad},
  booktitle={ICC 2020 - 2020 IEEE International Conference on Communications (ICC)}, 
  title={Multi-Objective Interdependent VM Placement Model based on Cloud Reliability Evaluation}, 
  year={2020},
  volume={},
  number={},
  pages={1-7},
  abstract={Virtual Machine (VM) placement is considered as one of the crucial problems in Cloud Computing environments. From the perspective of Cloud Service Providers (CSPs), finding the optimal VM placement strategy is often related to optimal resource utilization, revenue maximization, and energy efficiency. However, to ensure the continuity of customer services, CSPs should also consider the reliability of deployed applications when placing VMs on their infrastructures. Existing research in this area either do not focus on the Cloud reliability evaluation aspect or do not account for the trade-off between reliability and performance in the VM placement process. In this paper, we propose a multi-objective placement model for interdependent VMs in the Cloud that considers both reliability and workload. Reliability in our model is quantitatively evaluated through a set of metrics that we propose. The model involves an Integer Linear Programming problem that aims at maximizing the reliability of the Cloud while minimizing network delay. A multi-objective genetic algorithm is then used to solve the problem heuristically. The proposed model introduces a level of flexibility and its parameters could be adjusted depending on the requirements of the infrastructure and services. The results show that our model achieves high Cloud reliability and allows to effectively control the trade-off between reliability and Quality of Service.},
  keywords={},
  doi={10.1109/ICC40277.2020.9149347},
  ISSN={1938-1883},
  month={June},}@INPROCEEDINGS{9407931,
  author={Hussain, Razin Farhan and Pakravan, Alireza and Salehi, Mohsen Amini},
  booktitle={2020 IEEE 22nd International Conference on High Performance Computing and Communications; IEEE 18th International Conference on Smart City; IEEE 6th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, 
  title={Analyzing the Performance of Smart Industry 4.0 Applications on Cloud Computing Systems}, 
  year={2020},
  volume={},
  number={},
  pages={11-18},
  abstract={Cloud-based Deep Neural Network (DNN) applications that make latency-sensitive inference are becoming an indispensable part of Industry 4.0. Due to the multi-tenancy and resource heterogeneity, both inherent to the cloud computing environments, the inference time of DNN-based applications are stochastic. Such stochasticity, if not captured, can potentially lead to low Quality of Service (QoS) or even a disaster in critical sectors, such as Oil and Gas industry. To make Industry 4.0 robust, solution architects and researchers need to understand the behavior of DNN-based applications and capture the stochasticity exists in their inference times. Accordingly, in this study, we provide a descriptive analysis of the inference time from two perspectives. First, we perform an application-centric analysis and statistically model the execution time of four categorically different DNN applications on both Amazon and Chameleon clouds. Second, we take a resource-centric approach and analyze a rate-based metric in form of Million Instruction Per Second (MIPS) for heterogeneous machines in the cloud. This non-parametric modeling, achieved via Jackknife and Bootstrap re-sampling methods, provides the confidence interval of MIPS for heterogeneous cloud machines. The findings of this research can be helpful for researchers and cloud solution architects to develop solutions that are robust against the stochastic nature of the inference time of DNN applications in the cloud and can offer a higher QoS to their users and avoid unintended outcomes.},
  keywords={},
  doi={10.1109/HPCC-SmartCity-DSS50907.2020.00003},
  ISSN={},
  month={Dec},}@ARTICLE{6671599,
  author={Shen, Haiying and Lin, Yuhua and Li, Ting},
  journal={IEEE Transactions on Computers}, 
  title={Combining Efficiency, Fidelity, and Flexibility in Resource Information Services}, 
  year={2015},
  volume={64},
  number={2},
  pages={353-367},
  abstract={A large-scale resource sharing system (e.g., collaborative cloud computing and grid computing) creates a virtual supercomputer by providing an infrastructure for sharing tremendous amounts of resources (e.g., computing, storage, and data) distributed over the Internet. A resource information service, which collects resource data and provides resource search functionality for locating desired resources, is a crucial component of the resource sharing system. In addition to resource discovery speed and cost (i.e., efficiency), the ability to accurately locate all satisfying resources (i.e., fidelity) is also an important metric for evaluating service quality. Previously, a number of resource information service systems have been proposed based on Distributed Hash Tables (DHTs) that offer scalable key-based lookup functions. However, these systems either achieve high fidelity at low efficiency, or high efficiency at low fidelity. Moreover, some systems have limited flexibility by only providing exact-matching services or by describing a resource using a pre-defined list of attributes. This paper presents a resource information service that offers high efficiency and fidelity without restricting resource expressiveness, while also providing a similar-matching service. Extensive simulation and PlanetLab experimental results show that the proposed service outperforms other services in terms of efficiency, fidelity, and flexibility; it dramatically reduces overhead and yields significant enhancements in efficiency and fidelity.},
  keywords={},
  doi={10.1109/TC.2013.222},
  ISSN={1557-9956},
  month={Feb},}@INPROCEEDINGS{9659505,
  author={Klinaku, Floriment and Hakamian, Alireza and Becker, Steffen},
  booktitle={2021 IEEE International Conference on Autonomic Computing and Self-Organizing Systems (ACSOS)}, 
  title={Architecture-based Evaluation of Scaling Policies for Cloud Applications}, 
  year={2021},
  volume={},
  number={},
  pages={151-157},
  abstract={The cloud computing model enables organizations to employ policies for the automated provisioning of computing resources. The impact on the quality, such as performance or cost, of such policies is often unknown for complex, large, and highly distributed cloud applications. Software architects lack a feasible approach to evaluate scaling policies for their cloud application quantitatively. While approaches exist in the literature, they are costly and require a high effort. We propose an approach that utilizes modeling and terminating simulations to evaluate alternative styles and configurations for cloud scaling policies. The approach aids the architect in understanding and explaining their dynamic behavior and the existing trade-offs. Third, we conduct simulation experiments on a representative case study model to show the approach&#x0027;s feasibility. We evaluate the performance, cost, efficiency, and complexity of three scaling policies of different styles (e.g., centralized vs. decentralized) on a model. Results show that the policies improve the performance for the selected scenario. However, no significant difference among them exists in terms of performance. Other metrics highlight the present trade-offs across policies. All in all, the case shows that the approach helps architects refine the style and find an appropriate policy for their context.},
  keywords={},
  doi={10.1109/ACSOS52086.2021.00035},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9563355,
  author={Li, Dian and Wang, Weidong and Kang, Yujian},
  booktitle={2021 IEEE International Conference on Electronic Technology, Communication and Information (ICETCI)}, 
  title={A Hierarchical Approach for QoS-Aware Edge Service Scheduling and Composition}, 
  year={2021},
  volume={},
  number={},
  pages={677-681},
  abstract={Edge computing is a new computing paradigm after cloud computing. Edge service scheduling and composition (ESC) has been well recognized as a convenient and flexible way of services sharing and integrating in industrial application fields. The ESC aims at selecting a set of existing edge service candidates with different Quality of Service (QoS) attributes (e.g., price), then compositing them to accomplish a complex task to meet users' QoS requirements, where each edge service may have multiple functionally equivalent, but different QoS metrics. A grand research challenge of the ESC based on QoS is to select proper service candidates to maximize QoS of the composited edge service and meanwhile meet the global QoS requirements. In this article, we focus on this challenge and propose a hierarchical solution for ESC. Specifically, we classify service candidates into specified grades based on their QoS attributes, and use hierarchical model to address service selection problem. Furthermore, in order to expand the flexibility of our approach, we design a near-optimal solution by decomposing the global end-to-end QoS constraints into local QoS constraints and adopting local service selecting and updating strategy based on the hierarchical model. The results of simulation-based experiments are conducted to show our approach is more efficient and valid compared to other existing approaches.},
  keywords={},
  doi={10.1109/ICETCI53161.2021.9563355},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8614209,
  author={Wangsom, Peerasak and Bouvry, Pascal and Lavangnananda, Kittichai},
  booktitle={2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)}, 
  title={Extreme Solutions NSGA-III (E-NSGA-III) for Scientific Workflow Scheduling on Cloud}, 
  year={2018},
  volume={},
  number={},
  pages={1139-1146},
  abstract={The execution of scientific workflows on dynamic environments such as cloud computing has become multi-objective scheduling in order to satisfy user demands from several perspectives. Among these objectives, Cost and Makespan are probably the most common. This research also includes Data Movement as an additional objective as it has significant effect to network utilization and energy consumption in network equipment in cloud data center. This paper proposes a multi-objective scheduling, Extreme Nondominated Sorting Genetic Algorithm (E-NSGA-III). It is an extension of the Nondominated Sorting Genetic Algorithm (NSGA-III). E-NSGA-III utilizes extreme solutions in the population generation module in order improve quality of solutions. Five well-known scientific workflows are selected as testbeds. Hypervolume and the Pareto front are chosen as the performance metrics. E-NSGA-III is evaluated by comparing its performance against the two previous versions (NSGA-II and NSGA-III). The comparison reveals that E-NSGA-III yields the best performance among them in multi-objective scheduling of the five scientific workflows.},
  keywords={},
  doi={10.1109/ICMLA.2018.00184},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9678460,
  author={Noureddine, Staifi and Meriem, Belguidoum},
  booktitle={2021 International Conference on Information Systems and Advanced Technologies (ICISAT)}, 
  title={ML-SLA-IoT: an SLA Specification and Monitoring Framework for IoT applications}, 
  year={2021},
  volume={},
  number={},
  pages={1-12},
  abstract={Service level agreement (SLA) is a formal contract between a service provider and a service consumer to guarantee the Quality of service (QoS) expectations, it is used in all areas of information technology, such as Cloud Computing, Internet of Things (IoT), networks and Web services. For IoT applications, the main challenges are: (1) how to describe the SLA terms, such as QoS properties, service levels, penalties in SLA violation, (2) how to monitor these terms, and (3) how to integrate an SLA into all the IoT application layers. Therefore, in this paper, we propose ML-SLA-IoT, a framework for SLA specification and monitoring. It covers the entire layers of an IoT application. It describes precisely QoS levels, provided services, and obligations. It differs from other SLA specification languages in the specification of user preferences, the use of microservices (for reusability, dynamism and ease of integration) and ML-SLA (multi-level metrics and QoS according to existing constraints and user preferences). Furthermore, ML-SLA-IoT monitors SLA terms in an automatic and decentralised manner using smart contracts and blockchain technologies without the intervention of the third-party. Finally, we present a comparative study and experiments with existing solutions regarding to some criteria for SLA specification and monitoring. Our results show that ML-SLA-IoT gives better performance in terms of dynamic pricing, obligation combination, and SLA monitoring.},
  keywords={},
  doi={10.1109/ICISAT54145.2021.9678460},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8260045,
  author={Afify, Yasmine M. and Badr, Nagwa L. and Moawad, Ibrahim F. and Tolba, Mohamed F.},
  booktitle={2017 Eighth International Conference on Intelligent Computing and Information Systems (ICICIS)}, 
  title={Evaluation of cloud service ontologies}, 
  year={2017},
  volume={},
  number={},
  pages={144-153},
  abstract={It is the cloud computing era. Substantial number of Cloud Services (CS) have emerged. The automation of the cloud services life cycle can be enhanced using domain ontologies in the cloud environment. Ontologies allow more efficient CS publication, discovery, selection, composition and recommendations. However, no broad cloud ontology for this purpose has dominated yet. This paper presents an in-depth analysis of existing cloud taxonomies and service ontologies. We present a comparison of the cloud service ontologies implementation features. Moreover, a semiotic metrics suite of ontology quality is used for the assessment process.},
  keywords={},
  doi={10.1109/INTELCIS.2017.8260045},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9719678,
  author={Gong, Yanqi and Hao, Fei and Sun, Yifei and Guo, Longjiang},
  booktitle={2021 20th International Conference on Ubiquitous Computing and Communications (IUCC/CIT/DSCI/SmartCNS)}, 
  title={Joint Optimization of Latency and Reward for Offloading Dependent Tasks in Mobile Edge Computing}, 
  year={2021},
  volume={},
  number={},
  pages={68-75},
  abstract={In the 5G era with the explosive growth of data, offloading tasks to edge servers that are executed closer to it becomes one of the most popular computational paradigms. Different from cloud computing, mobile edge computing (MEC) significantly addresses the problem of latency-sensitive applications execution, such as online gaming and VR/AR applications. In order to improve the quality of experience of end-users, those applications are often divided into multiple tasks with dependencies. Regarding the problem of offloading tasks with dependencies, the existing researches focus on either latency or reward optimization that leads to the practical difficulty of this problem. Towards this end, this paper first introduces a novel metric reward per unit time which integrates the latency and reward for better optimization of tasks offloading strategy. Then, the reward per unit time is viewed as the objective function, and further addressing the above problem is equivalent to finding the optimal offloading strategy to maximize the value of the objective function. The simulation experiments are conducted for demonstrating that the proposed offloading strategy is feasible and effective.},
  keywords={},
  doi={10.1109/IUCC-CIT-DSCI-SmartCNS55181.2021.00025},
  ISSN={},
  month={Dec},}@ARTICLE{7437245,
  author={Maia, Delano Jose Holanda and Moreira, Leonardo Oliveira and Coutinho, Emanuel Ferreira and Gomes, Danielo Goncalves},
  journal={IEEE Latin America Transactions}, 
  title={MILENA: a model for implementing distributed multiplayer games in computing clouds}, 
  year={2016},
  volume={14},
  number={2},
  pages={951-957},
  abstract={Cloud computing environments are characteristically composed of distributed infrastructure, heterogeneous and virtualized resources, besides serving concurrently a wide range of customers whose service level agreements may require different levels of Quality of Service (QoS). Distributed multiplayer games, in turn, are collaborative distributed applications that must have an acceptable level of QoS to maintain justice among its players. This article proposes MILENA, a model for implementing distributed multiplayer games on computer clouds. The proposed model meets the requirements of QoS, fault tolerance and scalability. As a case study for verification and validation of the proposal, we have developed a game and evaluated its performance by SLA violations and response time of requests metrics. The results show that the MILENA scales up to 100 players without QoS loss, thus improving justice in distributed multiplayer games.},
  keywords={},
  doi={10.1109/TLA.2016.7437245},
  ISSN={1548-0992},
  month={Feb},}@ARTICLE{7972945,
  author={He, Jianhua and Wei, Jian and Chen, Kai and Tang, Zuoyin and Zhou, Yi and Zhang, Yan},
  journal={IEEE Internet of Things Journal}, 
  title={Multitier Fog Computing With Large-Scale IoT Data Analytics for Smart Cities}, 
  year={2018},
  volume={5},
  number={2},
  pages={677-686},
  abstract={Analysis of Internet of Things (IoT) sensor data is a key for achieving city smartness. In this paper a multitier fog computing model with large-scale data analytics service is proposed for smart cities applications. The multitier fog is consisted of ad-hoc fogs and dedicated fogs with opportunistic and dedicated computing resources, respectively. The proposed new fog computing model with clear functional modules is able to mitigate the potential problems of dedicated computing infrastructure and slow response in cloud computing. We run analytics benchmark experiments over fogs formed by Rapsberry Pi computers with a distributed computing engine to measure computing performance of various analytics tasks, and create easy-to-use workload models. Quality of services (QoS) aware admission control, offloading, and resource allocation schemes are designed to support data analytics services, and maximize analytics service utilities. Availability and cost models of networking and computing resources are taken into account in QoS scheme design. A scalable system level simulator is developed to evaluate the fog-based analytics service and the QoS management schemes. Experiment results demonstrate the efficiency of analytics services over multitier fogs and the effectiveness of the proposed QoS schemes. Fogs can largely improve the performance of smart city analytics services than cloud only model in terms of job blocking probability and service utility.},
  keywords={},
  doi={10.1109/JIOT.2017.2724845},
  ISSN={2327-4662},
  month={April},}@ARTICLE{8489955,
  author={Nguyen, Tien-Dung and Huh, Eui-Nam and Jo, Minho},
  journal={IEEE Internet of Things Journal}, 
  title={Decentralized and Revised Content-Centric Networking-Based Service Deployment and Discovery Platform in Mobile Edge Computing for IoT Devices}, 
  year={2019},
  volume={6},
  number={3},
  pages={4162-4175},
  abstract={Mobile edge computing (MEC) is used to offload services (tasks) from cloud computing in order to deliver those services to mobile Internet of Things (IoT) devices near mobile edge nodes. However, even though there are advantages to MEC, we face many significant problems, such as how a service provider (SP) deploys requested services efficiently on a destination MEC node, and how to discover existing services in neighboring MEC nodes to save edge resources. In this paper, we present a decentralized and revised content-centric networking (CCN)-based MEC service deployment/discovery protocol and platform. We organized a gateway in every area according to a three-tiered hierarchical MEC network topology to reduce computing overhead at the centralized controller. We revised CCN to introduce a protocol to help SP deploy their service on MEC node and assist MEC node discover services in neighboring nodes. By using our proposed protocol, MEC nodes can deploy or discover the requested service instances in the proximity of IoT devices to reduce transmission delay. We also present a mathematical model to calculate the round trip time to guarantee quality of service. Numerical experiments measure the performance of our proposed method with various mobile IoT device services. The results show that the proposed service deployment protocol and platform reduce the average service delay by up to 50% compared to legacy cloud. In addition, the proposed method outperforms the legacy protocol of the MEC environment in service discovery time.},
  keywords={},
  doi={10.1109/JIOT.2018.2875489},
  ISSN={2327-4662},
  month={June},}@ARTICLE{9489314,
  author={Cheikhrouhou, Omar and Mahmud, Redowan and Zouari, Ramzi and Ibrahim, Muhammad and Zaguia, Atef and Gia, Tuan Nguyen},
  journal={IEEE Access}, 
  title={One-Dimensional CNN Approach for ECG Arrhythmia Analysis in Fog-Cloud Environments}, 
  year={2021},
  volume={9},
  number={},
  pages={103513-103523},
  abstract={Cardiovascular diseases are considered the number one cause of death across the globe which can be primarily identified by the abnormal heart rhythms of the patients. By generating electrocardiogram (ECG) signals, wearable Internet of Things (IoT) devices can consistently track the patient's heart rhythms. Although Cloud-based approaches for ECG analysis can achieve some levels of accuracy, they still have some limitations, such as high latency. Conversely, the Fog computing infrastructure is more powerful than edge devices but less capable than Cloud computing for executing compositionally intensive data analytic software. The Fog infrastructure can consist of Fog-based gateways directly connected with the wearable devices to offer many advanced benefits, including low latency and high quality of services. To address these issues, a modular one-dimensional convolution neural network (1D-CNN) approach is proposed in this work. The inference module of the proposed approach is deployable over the Fog infrastructure for analysing the ECG signals and initiating the emergency countermeasures within a minimum delay, whereas its training module is executable on the computationally enriched Cloud data centers. The proposed approach achieves the F1-measure score â1 on the MIT-BIH Arrhythmia database when applying GridSearch algorithm with the cross-validation method. This approach has also been implemented on a single-board computer and Google Colab-based hybrid Fog-Cloud infrastructure and embodied to a remote patient monitoring system that shows 25% improvement in the overall response time.},
  keywords={},
  doi={10.1109/ACCESS.2021.3097751},
  ISSN={2169-3536},
  month={},}@ARTICLE{7090976,
  author={Candeia, David and Santos, Ricardo AraÃºjo and Lopes, Raquel},
  journal={IEEE Transactions on Cloud Computing}, 
  title={Business-Driven Long-Term Capacity Planning for SaaS Applications}, 
  year={2015},
  volume={3},
  number={3},
  pages={290-303},
  abstract={Capacity Planning is one of the activities developed by Information Technology departments over the years, it aims at estimating the amount of resources needed to offer a computing service. This activity contributes to achieving high Quality of Service levels and also to pursuing better economic results for companies. In the Cloud Computing context, one plausible scenario is to have Software-as-a-Service (SaaS) providers that build their IT infrastructure acquiring resources from Infrastructure-as-a-Service (IaaS) providers. SaaS providers can reduce operational costs and complexity by buying instances from a reservation market, but then need to predict the number of instances needed in the long-term. This work investigates how important is the capacity planning in this context and how simple business-driven heuristics for long-term capacity planning impact on the profit achieved by SaaS providers. Simulation experiments were performed using synthetic e-commerce workloads. Our analysis show that proposed heuristics increase SaaS provider profit, on average, at 9.6501 percent per year. Analysing such results we demonstrate that capacity planning is still an important activity, contributing to the increase of SaaS providers profit. Besides, a good capacity planning may also avoid bad reputation due to unacceptable performance, which is a gain very hard to measure.},
  keywords={},
  doi={10.1109/TCC.2015.2424877},
  ISSN={2168-7161},
  month={July},}@ARTICLE{9165739,
  author={Gao, Zihan and Hao, Wanming and Han, Zhuo and Yang, Shouyi},
  journal={IEEE Access}, 
  title={Q-Learning-Based Task Offloading and Resources Optimization for a Collaborative Computing System}, 
  year={2020},
  volume={8},
  number={},
  pages={149011-149024},
  abstract={Mobile edge computing (MEC) can effectively overcome the shortcomings of high-latency in mobile cloud computing (MCC) by deploying the cloud resources, e.g., storage and computational capability, to the edge. However, the limited computation capability of the MEC restricts the scalability of offloading. Therefore, the basic requirements of the MEC system are to explore effective offloading decisions and resource allocation methods. To address it, we develop a collaborative computing system composed of local computing (mobile device), MEC (edge cloud) and MCC (central cloud). Based on the proposed collaborative computing system, we design a novel Q-learning based computation offloading (QLCOF) policy to achieve the optimal resource allocation and offloading scheme by prescheduling the computation side for each task from a global perspective. Specifically, we first model the offloading decision process as a Markov decision process (MDP) and design a state loss function (STLF) to measure the quality of experience (QoE). After that, we define the cumulation of STLFs as the system loss function (SYLF) and formulate an SYLF minimization problem. Due to the difficulty to directly solve the formulated problem, we decompose it into multiple subproblems and preferentially optimize the transmission power and computation frequency of the edge cloud by the quasi-convex bisection and polynomial analysis method, respectively. Based on the precalculated offline transmission power and edge cloud computation frequency, we develop a Q-learning based offloading (QLOF) scheme to minimize the SYLF by optimizing offloading decisions. Finally, the numeral results show that the proposed QLOF scheme effectively reduces the SYLF under different parameters.},
  keywords={},
  doi={10.1109/ACCESS.2020.3015993},
  ISSN={2169-3536},
  month={},}@ARTICLE{9097295,
  author={Rahman, Sabidur and Ahmed, Tanjila and Huynh, Minh and Tornatore, Massimo and Mukherjee, Biswanath},
  journal={IEEE Transactions on Network and Service Management}, 
  title={Auto-Scaling Network Service Chains Using Machine Learning and Negotiation Game}, 
  year={2020},
  volume={17},
  number={3},
  pages={1322-1336},
  abstract={Network Function Virtualization (NFV) enables Network Operators (NOs) to efficiently respond to the increasing dynamicity of network services. Virtual Network Functions (VNFs) running on commercial off-the-shelf servers are easy to deploy, update, monitor, and manage. Such virtualized services are often deployed as Service Chains (SCs), which require in-sequence placement of computing and memory resources as well as routing of traffic flows. Due to the ongoing migration towards cloudification of networks, the concept of auto-scaling which originated in Cloud Computing, is now receiving attention from networks professionals too. Prior studies on auto-scaling use measured load to dynamically react to traffic changes. Moreover, they often focus on only one of the resources (e.g., compute only, or network capacity only). In this study, we consider three different resource types: compute, memory, and network bandwidth. In prior studies, NO takes auto-scaling decisions, assuming tenants are always willing to auto-scale, and Quality of Service (QoS) requirements are homogeneous. Our study proposes a negotiation-game-based auto-scaling method where tenants and NO both engage in the auto-scaling decision, based on their willingness to participate, heterogeneous QoS requirements, and financial gain (e.g., cost savings). In addition, we propose a proactive Machine Learning (ML) based prediction method to perform SC auto-scaling in dynamic traffic scenario. Numerical examples show that our proposed SC auto-scaling methods powered by ML present a win-win situation for both NO and tenants (in terms of cost savings).},
  keywords={},
  doi={10.1109/TNSM.2020.2995900},
  ISSN={1932-4537},
  month={Sep.},}@INPROCEEDINGS{8366932,
  author={Zhou, Peipei and Ruan, Zhenyuan and Fang, Zhenman and Shand, Megan and Roazen, David and Cong, Jason},
  booktitle={2018 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)}, 
  title={Doppio: I/O-Aware Performance Analysis, Modeling and Optimization for In-memory Computing Framework}, 
  year={2018},
  volume={},
  number={},
  pages={22-32},
  abstract={In conventional Hadoop MapReduce applications, I/O used to play a heavy role in the overall system performance. More recently, a study from the Apache Spark community- state-of-the-art in-memory cluster computing framework- reports that I/O is no longer the bottleneck and has a marginal performance impact on applications like SQL processing. However, we observe that simply replacing HDDs with SSDs in a Spark cluster can have over 10x performance improvement for certain stages in large-scale production-quality genome processing. Therefore, one key question arises: How does I/O quanti- tatively impact the performance of today's big data applications developed using in-memory cluster computing frameworks like Apache Spark? In this paper we select an important yet complex application- the Spark-based Genome Analysis ToolKit (GATK4)-to guide our modeling. We first use different combinations of HDDs and SSDs to measure the I/O impact on GATK4 and change the CPU core number to discover the relation between computation and I/O access. By combining with Spark's underlying implementations, we further analyze the inherent cause of the above observations and build our model based on the analysis. Although we are building upon GATK4, our model maintains generality to other applications. Experimental results show that we can achieve a performance prediction error rate within 10% for typical Spark applications of both iterative and shuffle-heavy algorithms. Finally, we further extend our model to a broader area-that of optimal configuration selection in the public cloud. In Google Cloud, our model enables us to save 38% to 57% of cost for genome sequencing compared with its recommended default configurations. Currently, more and more companies are adopting cloud computing for specific workloads. Our proposed model can have a huge impact on their choices, while also enabling them to significantly reduce their costs.},
  keywords={},
  doi={10.1109/ISPASS.2018.00011},
  ISSN={},
  month={April},}@INPROCEEDINGS{8057143,
  author={Toka, LÃ¡szlÃ­Ã³ and Lajtha, BalÃ¡zs and Hosszu, Ãva and Formanek, Bence and GÃ©hberger, DÃ¡niel and Tapolcai, JÃ¡nos},
  booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications}, 
  title={A resource-aware and time-critical IoT framework}, 
  year={2017},
  volume={},
  number={},
  pages={1-9},
  abstract={Internet of Things (IoT) systems produce great amount of data, but usually have insufficient resources to process them in the edge. Several time-critical IoT scenarios have emerged and created a challenge of supporting low latency applications. At the same time cloud computing became a success in delivering computing as a service at affordable price with great scalability and high reliability. We propose an intelligent resource allocation system that optimally selects the important IoT data streams to transfer to the cloud for processing. The optimization runs on utility functions computed by predictor algorithms that forecast future events with some probabilistic confidence based on a dynamically recalculated data model. We investigate ways of reducing specifically the upload bandwidth of IoT video streams and propose techniques to compute the corresponding utility functions. We built a prototype for a smart squash court and simulated multiple courts to measure the efficiency of dynamic allocation of network and cloud resources for event detection during squash games. By continuously adapting to the observed system state and maximizing the expected quality of detection within the resource constraints our system can save up to 70% of the resources compared to the naive solution.},
  keywords={},
  doi={10.1109/INFOCOM.2017.8057143},
  ISSN={},
  month={May},}@ARTICLE{9458258,
  author={Liu, Li and Lu, Caiwu and Xiao, Fengjun and Liu, Ruimin and Xiong, Neal Naixue},
  journal={IEEE Access}, 
  title={A Practical, Integrated Multi-Criteria Decision-Making Scheme for Choosing Cloud Services in Cloud Systems}, 
  year={2021},
  volume={9},
  number={},
  pages={88391-88404},
  abstract={Currently, with the rapid development and broad application of cloud computing technology, companies tend to use cloud services to build their applications or business systems. Selecting a trustworthy cloud service is a challenging multi-criteria decision-making (MCDM) problem. Moreover, decision makers are more inclined to use linguistic descriptions to assess the quality of service (QoS) for cloud services due to the limitation of the decision makers' knowledge and the vagueness of criteria information. Therefore, we propose a practical, integrated MCDM scheme for cloud service evaluation and selection of cloud systems, allowing decision makers to compare cloud services based on QoS criteria. First, to more accurately and effectively express the uncertainty of qualitative concepts, the cloud model is used as a conversion tool for qualitative and quantitative information to quantify linguistic terms. Second, given the shortcomings of traditional differentiating measures between cloud models, a more comprehensive distance measurement algorithm using cloud droplet distribution is proposed for the cloud model. The new distance measurement algorithm is applied to the calculation of cloud model similarity and the gray correlation coefficient. The dynamic expertise weights are determined by calculating the similarity between the expert evaluation cloud model and the arithmetic mean cloud model. Then, we propose a technique for order preference by similarity to an ideal solution (TOPSIS) improved by the grey relational analysis (GRA) to calculate the relative closeness of alternatives to the positive and negative ideal solutions and establish a multi-objective optimization model that maximizes the relative closeness of all alternatives to determine the weights of the criteria. Finally, we reconstructed the QoS evaluation criteria for cloud services from both application and service perspectives, and the classical TOPSIS is applied to generate alternative rankings. The practicability and robustness of the scheme were tested through the cloud service selection problem experienced by a real mining company's scheduling platform, which can provide practical references with the theoretical basis for the selection and evaluation of cloud services.},
  keywords={},
  doi={10.1109/ACCESS.2021.3089991},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9058016,
  author={Bhardwaj, Tushar and Upadhyay, Himanshu and Sharma, Subhash Chander},
  booktitle={2020 10th International Conference on Cloud Computing, Data Science & Engineering (Confluence)}, 
  title={Framework for Quality Ranking of Components in Cloud Computing: Regressive Rank}, 
  year={2020},
  volume={},
  number={},
  pages={598-604},
  abstract={As the popularity of cloud computing is increasing there is an urgent requirement of developing highly efficient and highly qualitative cloud applications (CA). Hence, it be-comes a big research problem. A recommender system recommends the suitable item to the user and almost all the systems provide a rating score for preference. Traditionally, algorithms predicts the ratings that a user should give to the unrated components to queue the item in recommended list. To select an optimal candidate from a set of function-ally equivalent candidates is crucial through approaches that follow a framework for component quality ranking. More-over, such framework helps in detecting the poor performing candidates from a highly distributed cloud applications. In this paper a novel technique is proposed to provide personalized component ranking for designers by employing the past usage of components by different users. In this approach the similarity between the users is measured based on their rankings for functionally equivalent components set instead of their rating values. In this approach no additional invocation of cloud component is required. Experimental results on real world web-service invocations data set shows that the proposed approach outperforms the previous approaches.},
  keywords={},
  doi={10.1109/Confluence47617.2020.9058016},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{6883911,
  author={Liu, Meng and Dou, Wanchun and Yu, Shui and Zhang, Zhensheng},
  booktitle={2014 IEEE International Conference on Communications (ICC)}, 
  title={A clusterized firewall framework for cloud computing}, 
  year={2014},
  volume={},
  number={},
  pages={3788-3793},
  abstract={Cloud computing is becoming popular as the next infrastructure of computing platform. However, with data and business applications outsourced to a third party, how to protect cloud data centers from numerous attacks has become a critical concern. In this paper, we propose a clusterized framework of cloud firewall, which characters performance and cost evaluation. To provide quantitative performance analysis of the cloud firewall, a novel M/Geo/1 analytical model is established. The model allows cloud defenders to extract key system measures such as request response time, and determine how many resources are needed to guarantee quality of service (QoS). Moreover, we give an insight into financial cost of the proposed cloud firewall. Finally, our analytical results are verified by simulation experiments.},
  keywords={},
  doi={10.1109/ICC.2014.6883911},
  ISSN={1938-1883},
  month={June},}@ARTICLE{9354861,
  author={Sacco, Alessio and Flocco, Matteo and Esposito, Flavio and Marchetto, Guido},
  journal={IEEE Transactions on Network and Service Management}, 
  title={Supporting Sustainable Virtual Network Mutations With Mystique}, 
  year={2021},
  volume={18},
  number={3},
  pages={2714-2727},
  abstract={The abiding attempt of automation has also permeated the networks, with the ability to measure, analyze, and control themselves in an automated manner, by reacting to changes in the environment (e.g., demand). When provided with these features, networks are often labeled as âself-drivingâ or âautonomousâ. In this regard, the provision and orchestration of physical or virtual resources are crucial for both Quality of Service (QoS) guarantees and cost management in the edge/cloud computing environment. To effectively manage the lifecycle of these resources, an auto-scaling mechanism is essential. However, traditional threshold-based and recent Machine Learning (ML)-based policies are often unable to address the soaring complexity of networks due to their centralized approach. By relying on multi-agent reinforcement learning, we propose Mystique, a solution that learns from the load on links to establish the minimal set of active network resources. As traffic demands ebb and flow, our adaptive and self-driving solution can scale up and down and also react to failures in a fully automated, flexible, and efficient manner. Our results demonstrate that the presented solution can reduce network energy consumption while providing an adequate service level, outperforming other benchmark auto-scaling approaches.},
  keywords={},
  doi={10.1109/TNSM.2021.3059647},
  ISSN={1932-4537},
  month={Sep.},}@INPROCEEDINGS{7396178,
  author={Rahulamathavan, Yogachandran and Rajarajan, Muttukrishnan and Rana, Omer F. and Awan, Malik S. and Burnap, Pete and Das, Sajal K.},
  booktitle={2015 IEEE 7th International Conference on Cloud Computing Technology and Science (CloudCom)}, 
  title={Assessing Data Breach Risk in Cloud Systems}, 
  year={2015},
  volume={},
  number={},
  pages={363-370},
  abstract={The emerging cloud market introduces a multitude of cloud service providers, making it difficult for consumers to select providers who are likely to be a low risk from a security perspective. Recently, significant emphasis has arisen on the need to specify Service Level Agreements that address security concerns of consumers (referred to as SecSLAs) -- these are intended to clarify security support in addition to Quality of Service characteristics associated with services. It has been found that such SecSLAs are not consistent among providers, even though they offer services with similar functionality. However, measuring security service levels and the associated risk plays an important role when choosing a cloud provider. Data breaches have been identified as a high priority threat influencing the adoption of cloud computing. This paper proposes a general analysis framework which can compute risk associated with data breaches based on pre-agreed SecSLAs for different cloud providers. The framework exploits a tree based structure to identify possible attack scenarios that can lead to data breaches in the cloud and a means of assessing the use of potential mitigation strategies to reduce such breaches.},
  keywords={},
  doi={10.1109/CloudCom.2015.58},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{6883661,
  author={Si, Pengbo and Yu, F. Richard and Zhang, Yanhua},
  booktitle={2014 IEEE International Conference on Communications (ICC)}, 
  title={Joint cloud and radio resource management for video transmissions in mobile cloud computing networks}, 
  year={2014},
  volume={},
  number={},
  pages={2270-2275},
  abstract={In mobile cloud computing (MCC) systems, the resource in both the cloud and the mobile network should be carefully managed. Cloud resource management and radio resource management have traditionally been addressed separately in previous works. In this paper, we propose to jointly study dynamic cloud and radio resource management so as to improve end-to-end performance of adaptive video transmissions in MCC systems. Video application quality of service performance, distortion, is adopted as the performance measure. An important video application layer parameter, intra-refreshing rate, is optimized to improve the video distortion performance. We formulate the problem as a stochastic restless bandits optimization problem, which facilitates the distributed MCC architecture and simplifies the computation and implementation due to its âindexibilityâ property. Simulation results are presented to show the effectivenes of the proposed scheme.},
  keywords={},
  doi={10.1109/ICC.2014.6883661},
  ISSN={1938-1883},
  month={June},}@INPROCEEDINGS{9183589,
  author={Winzinger, Stefan and Wirtz, Guido},
  booktitle={2020 IEEE International Conference on Service Oriented Systems Engineering (SOSE)}, 
  title={Applicability of Coverage Criteria for Serverless Applications}, 
  year={2020},
  volume={},
  number={},
  pages={49-56},
  abstract={Serverless computing is a popular trend in cloud computing based on serverless functions. These functions are stateless which can be utilized by the cloud platform provider to scale functions dynamically. While these small functions are easy to test in isolation, integrating them with other resources provided by the cloud platform provider or third parties creates a complex system whose emerging behavior is hard to test. Integration tests help test the interaction of the serverless functions with other resources and their environment. However, it is hard to decide if a test case is adequate and focuses on the critical parts of the system. Therefore, coverage criteria can be used to measure the coverage of the relevant software components and help assess the quality of the test suite. In this paper, we identified serverless applications based on serverless functions on GitHub and used them to investigate which coverage criteria can be used to capture the interaction of serverless functions with other resources. Furthermore, we show a general approach to implement the measurement of the coverage on FaaS platforms. Thus, developers have means to test the adequacy of their applications on any FaaS platform.},
  keywords={},
  doi={10.1109/SOSE49046.2020.00013},
  ISSN={2642-6587},
  month={Aug},}@INPROCEEDINGS{7288394,
  author={Xie, Xiongwei and Wang, Weichao and Qin, Tuanfa},
  booktitle={2015 24th International Conference on Computer Communication and Networks (ICCCN)}, 
  title={Detection of Service Level Agreement (SLA) Violation in Memory Management in Virtual Machines}, 
  year={2015},
  volume={},
  number={},
  pages={1-8},
  abstract={In cloud computing, quality of services is often enforced through Service Level Agreement (SLA) between end users and cloud providers. While SLAs on hardware resources such as CPU cycles or bandwidth can be monitored by low layer sensors, the enforcement of security SLAs stays a very challenging problem. Several high level architectures for security SLAs have been proposed. However, details still need to be filled before they can be deployed. In this paper, we propose to design mechanisms to detect violations of security SLAs. Specifically, we focus on unauthorized accesses to memory pages of a virtual machine and violation of the memory deduplication policies. Through measuring the accumulated memory access latency, we try to derive out whether or not the memory pages have been swapped out and the order of accesses to them. These events will then be compared to access commands issued by the local VM. In this way, unauthorized memory accesses or violation of deduplication policies can be detected. Compared to existing approaches, our mechanisms do not need explicit help from the hypervisor or third parties. Therefore, it can detect SLA violations even when they are initiated by the hypervisor. We implement our approaches under VMWare with Windows virtual machines. Our experiment results show that the VM can effectively detect the violations with small increases in overhead.},
  keywords={},
  doi={10.1109/ICCCN.2015.7288394},
  ISSN={1095-2055},
  month={Aug},}@INPROCEEDINGS{7435462,
  author={Chen, Wei and Chen, Jiming and Tang, Jine and Wang, Liangmin},
  booktitle={2015 Third International Conference on Advanced Cloud and Big Data}, 
  title={A QoS Guarantee Framework for Cloud Services Based on Bayesian Prediction}, 
  year={2015},
  volume={},
  number={},
  pages={117-124},
  abstract={With the quality of service (QoS) of cloud services becoming increasingly concerned, how to ensure that the QoS of cloud services can meet the users' QoS requirement has become a focus of the study on cloud computing. However, the QoS of cloud services is dynamic regularly, we propose a QoS guarantee framework for cloud services and the Bayesian prediction method is used to predict QoS of cloud service. In our framework, cloud system can monitor and predict the QoS of cloud services in real-time, not only during the selection of cloud services, but also during the execution of cloud services. Once QoS prediction results show that some QoS violations will occur, cloud system will take measures to avoid the occurrence of QoS violations. We use the cloud simulation software called CloudSim for the experiment and the results demonstrate that compared with ARIMA and other prediction methods, our Bayesian prediction method has higher accuracy. Moreover, our QoS guarantee framework can greatly reduce the probability of QoS violation.},
  keywords={},
  doi={10.1109/CBD.2015.28},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{7410295,
  author={Abtahizadeh, S. Amirhossein and Khomh, Foutse and GuÃ©hÃ©neuc, Yann-GaÃ«l},
  booktitle={2015 IEEE 34th International Performance Computing and Communications Conference (IPCCC)}, 
  title={How green are cloud patterns?}, 
  year={2015},
  volume={},
  number={},
  pages={1-8},
  abstract={Cloud Patterns are abstract solutions to recurrent design problems in the cloud. Previous work has shown that these patterns can improve the Quality of Service (QoS) of cloud applications but their impact on energy consumption is still unknown. Yet, energy consumption is the biggest challenge that cloud computing systems (the backbone of today's high-tech economy) face today. In fact, 10% of the world's electricity is now being consumed by servers, laptops, tablets and smartphones. Energy consumption has complex dependencies on the hardware platform, and the multiple software layers. The hardware, its firmware, the operating system, and the various software components used by a cloud application, all contribute to determining the energy footprint. Hence, even though increasing a data center efficiency will eventually improve energy efficiency, the internal design of cloud-based applications can be improved to lower energy consumption. In this paper, we conduct an empirical study on a RESTful multi-threaded application deployed in the cloud, to investigate the individual and the combined impact of three cloud patterns (e.g., Local Database proxy, Local Sharding Based Router and Priority Queue) on the energy consumption of cloud based applications. We measure the energy consumption using Power-API; an application programming interface (API) written in Java to monitor the energy consumed at the process-level. Results show that cloud patterns can effectively reduce the energy consumption of a cloud application, but not in all cases. In general, there appear to be a trade-off between an improved response time of the application and the energy consumption. Developers and software architects can make use of these results to guide their design decisions.},
  keywords={},
  doi={10.1109/PCCC.2015.7410295},
  ISSN={2374-9628},
  month={Dec},}@INPROCEEDINGS{9084760,
  author={Shan, Nanliang and Cui, Xiaolong and Gao, Zhiqiang and Li, Yu},
  booktitle={2020 IEEE 4th Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)}, 
  title={Multi-User Multi-Server Multi-Channel Computation Offloading Strategy for Mobile Edge Computing}, 
  year={2020},
  volume={1},
  number={},
  pages={1389-1400},
  abstract={Mobile edge computing is a new computing paradigm that can extend cloud computing capabilities to the edge network, supporting computation-intensive applications such as face recognition, natural language processing, augmented reality. Notably, computation offloading is a key technology of mobile edge computing to improve mobile devices performance and user experience by offloading local tasks to edge servers. In this paper, we study the problem of computation offloading under multi-user, multi-server, and multi-channel scenarios, and propose a computation offloading strategy considering the quality of service (QoS) of users, server resources, and channel interference. This strategy consists of three stages: (1) In offloading decision stage, the offloading decision is made based on the beneficial degree of computation offloading, which is measured by the total cost of local computing of mobile device in comparison with the edge-side server. (2) In the server selection stage, the candidate is comprehensively evaluated and selected by a multi-objective decision based on Cov-AHP for computation offloading. (3) In the channel selection stage, a multi-user and multi-channel distributed computation offloading model based on potential game is proposed by considering the influence of channel interference on the user's overall overhead. The corresponding multi-user and multi-channel task scheduling algorithm is designed to maximize the overall benefit by finding the Nash equilibrium point of the potential game. Amounts of experimental results show that the proposed method can greatly increase the number of beneficial computation offloading users, and effectively reduce the energy consumption and time delay.},
  keywords={},
  doi={10.1109/ITNEC48623.2020.9084760},
  ISSN={},
  month={June},}@ARTICLE{6740925,
  author={Nam, Yunyoung and Park, Hyung Ju and Cho, Chae Ho and Park, Jong Hyuk},
  journal={IEEE Systems Journal}, 
  title={An Interactive IPTV System With Community Participation in Cloud Computing Environments}, 
  year={2014},
  volume={8},
  number={1},
  pages={174-183},
  abstract={This paper presents a video communication system that provides real-time participating services to audiences using Internet Protocol television (IPTV) and mobile devices on cloud computing environments. High-quality video processing and bidirectional multimedia communication technologies are combined for videoconferencing and interactive user participation. The P-module has been developed to encode and decode 1080i high-definition video data on a system simultaneously. A video communication protocol is applied to exchanging information between distributed and heterogeneous devices. The developed system has been deployed in a public service center in Seoul, Korea. In the experiments, we will show the implemented system using IPTV and a mobile phone, as well as the experiment results of the measured CPU overhead and mixing time in our system.},
  keywords={},
  doi={10.1109/JSYST.2013.2258745},
  ISSN={1937-9234},
  month={March},}@INPROCEEDINGS{8418099,
  author={Kyriazis, Dimosthenis},
  booktitle={2018 32nd International Conference on Advanced Information Networking and Applications Workshops (WAINA)}, 
  title={BYOS: Bring Your Own Security in Clouds and Service Oriented Infrastructures}, 
  year={2018},
  volume={},
  number={},
  pages={374-379},
  abstract={Cloud computing is widely being used by users, tenants and enterprises. However, the major concern and barrier for its adoption are the security and privacy concerns of end users. To this end, in this paper an approach is presented that proposes the use of security mechanisms, as plugins that are custom / tailored and potentially developed by the end users themselves. The latter is proposed as a means to overcome users concerns about the quality of security offered by the providers through their deployed security and privacy measures. As a concept, it builds on top of the well-established Bring Your Own Device (BYOD) paradigm and adopts it in the context of security and privacy. The potential challenges and an architecture with the corresponding key building blocks that address these challenges are presented.},
  keywords={},
  doi={10.1109/WAINA.2018.00114},
  ISSN={},
  month={May},}@INPROCEEDINGS{7391921,
  author={Sudipta Singha Roy and Tamjid Haque Sarker and Hashem, M. M. A.},
  booktitle={2015 2nd International Conference on Electrical Information and Communication Technologies (EICT)}, 
  title={A novel trust measurement system for cloud-based marketplace}, 
  year={2015},
  volume={},
  number={},
  pages={49-54},
  abstract={Cloud Computing is an enormously growing phenomenon in the present days enabling IT related services to run in a more dynamic and scalable way than the previous days and cloud marketplace is becoming more competitive with the entrance of new cloud service providers (CSP) offering similar functionalities. The basic obstacles in the way of success of cloud marketplace are the numerous shortcomings in reliable monitoring and identifying reliable cloud service provider based on consumers' preferred services. In this paper, a multi-faceted Entrusted Trust Management (ETM) system architecture is introduced that can support the customers in reliably choosing the trustworthy cloud service provider (CSP) as well as properly weight the information sources that provide feedbacks about the quality of services (QoS) of the CSPs. This ETM system works on several issues to measure the trust value of the providers on specific domain and overall trust value. Firstly, measurement of the trust value of the specific domain of provider on the basis of certainty and uncertainty. Secondly, measurement of overall trust value of the provider from these domain specific trust values. Thirdly, measurement of âDegree of Conflictâ between the rating/feedback of consumers and experts. And finally, measurement of trustworthiness of the information sources which provide the rating of the provider on the basis of the SLA between the provider and the consumer. At last, our proposed system is experimented using real datasets.},
  keywords={},
  doi={10.1109/EICT.2015.7391921},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9569577,
  author={Li, Guo and Liu, Ling and Liang, Zhengping and Ma, Xiaoliang and Zhu, Zexuan},
  booktitle={2021 IEEE 32nd Annual International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC)}, 
  title={Memetic Algorithm Based on Community Detection for Energy-Efficient Service Migration Optimization in 5G Mobile Edge Computing}, 
  year={2021},
  volume={},
  number={},
  pages={1-7},
  abstract={Mobile edge computing (MEC) can supplement cloud computing by helping to overcome the limitations of long physical transmission distances and accelerating the responsiveness of edge computing servers. In 5G (fifth generation) cellular networks, adopting MEC can guarantee ultralow latency. To enhance the MEC quality, optimization of the user service profile migration according to the user mobility is essential. However, this optimization establishes an NP-hard problem. Moreover, high-speed 5G base stations with MEC servers often experience high energy consumption. As conventional service migration algorithms such as those based on profile tracking and game theory tend to fall in local optima and neglect energy consumption constraints, we propose a memetic algorithm based on community detection local search (MA-CDLS) to continuously optimize the service migration in 5G MEC scenarios. During busy periods or in crowded areas, MA-CDLS adopts a single-objective optimization of user-perceived latency to achieve high-performance 5G services. During light-load periods or in uncrowded areas, MA-CDLS uses two measures, namely the user-perceived latency and energy consumption, to realize energy-efficient 5G services. MA-CDLS effectively reduces the search space and speeds up the elite selection in the meme operator. Experiments in simulated scenarios show that MA-CDLS achieves a lower user-perceived latency and energy consumption, than the traditional profile tracking and game theory methods, especially during congestion.},
  keywords={},
  doi={10.1109/PIMRC50174.2021.9569577},
  ISSN={2166-9589},
  month={Sep.},}@INPROCEEDINGS{7983102,
  author={Ekanayake, Wijaya and Amarasinghe, Heli and Karmouch, Ahmed},
  booktitle={2017 14th IEEE Annual Consumer Communications & Networking Conference (CCNC)}, 
  title={SDN-based IaaS for mobile computing}, 
  year={2017},
  volume={},
  number={},
  pages={179-184},
  abstract={Mobile Cloud Computing enables resource limited mobile devices to support rich application services. Among three types of cloud services, Infrastructure-as-a-Service (IaaS) clouds provides compute infrastructure for mobile applications on demand. In IaaS-based mobile clouds, latency and bandwidth requirements can considered as critical factors impacting Quality of Service (QoS). Opposed to centralized clouds, geographically distributed clouds realize higher QoS benefiting the proximity to the end user. In this paper, we propose an IaaS framework with regional datacenters for mobile clouds. With the benefits of software-defined networking (SDN), we address impacts on QoS during mobility by serving mobile user via the optimum datacenter. A test-bed was developed to measure the performance of service allocation and relocation in proposed framework.},
  keywords={},
  doi={10.1109/CCNC.2017.7983102},
  ISSN={2331-9860},
  month={Jan},}@INPROCEEDINGS{7816920,
  author={Falasi, Asma Al and Serhani, Mohamed Adel},
  booktitle={2016 Intl IEEE Conferences on Ubiquitous Intelligence & Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People, and Smart World Congress (UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld)}, 
  title={SLA Specification and Negotiation Model for a Network of Federated Clouds: CloudLend}, 
  year={2016},
  volume={},
  number={},
  pages={772-779},
  abstract={The Cloud computing paradigm is remarkably evolving. Cloud customers have become more conscious about the QoS expectation from Cloud providers' services. Accordingly, Cloud providers are required to be responsive to customers' demands, be open to establishing federations with other providers in order to retain their shares in the competitive Cloud market. Cloud customers are always searching for optimized services, irrespective of which providers are taking part in a federation to deliver these services. They seek federated Cloud services to attain the maximum satisfaction level, which is measured by the degree of adherence to customers' quality of service (QoS). Such federations of Cloud services are typically governed by service level agreements (SLAs) that are negotiated between the Cloud customer, provider prior to service provisioning. This paper tackles the challenges related to SLA specification, negotiation in a federated network of Clouds, CloudLend. We first propose a weighted SLA specification model that captures customers' QoS, manages multi-level SLAs specification. We then introduce an autonomous SLA negotiation model that adopts an enhanced fair division game. The model enables federated Cloud services to examine SLAs, react to SLA offers, eventually sign an SLA contract. It autonomously detects changes in Clouds federations, revises SLA specifications accordingly. The proposed model is evaluated using a CloudLend simulator, which we developed for this purpose. Several test cases were executed,, the results we have achieved verified the fairness, efficiency of our proposed SLA specification, negotiation models in CloudLend.},
  keywords={},
  doi={10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0124},
  ISSN={},
  month={July},}@INPROCEEDINGS{9443978,
  author={Yu, Zhixing and He, Kejing and Chen, Chao and Wang, Jian},
  booktitle={2020 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)}, 
  title={Live Container Migration via Pre-restore and Random Access Memory}, 
  year={2020},
  volume={},
  number={},
  pages={102-109},
  abstract={Container technology is increasingly being used for virtualization due to its ability to isolate the operating environment of the program. In cloud computing environment, we need to migrate containers between different hosts for load balancing or downtime maintenance. However, during the migration process, the container will be temporarily shut down, and the service will be unavailable. Therefore, the time cost is an essential indicator to measure the quality of the migration process. To achieve live container migration, we propose a pre-restore method and a complete random access memory (RAM) based method to migrate containers. Extensive experiments validate the effectiveness of our methods in reducing downtime and improving the efficiency of container migration.},
  keywords={},
  doi={10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00039},
  ISSN={},
  month={Dec},}@ARTICLE{7343819,
  author={Liu, Jiangchuan and Zhu, Wenwu and Ebrahimi, Touradj and Apostolopoulos, John and Hua, Xian-Sheng and Wu, Chuan},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Introduction to the Special Section on Visual Computing in the Cloud: Fundamentals and Applications}, 
  year={2015},
  volume={25},
  number={12},
  pages={1885-1887},
  abstract={Cloud computing involves a large number of terminals connected through a real-time high-speed network (such as the Internet). The adoption rates for private and hybrid cloud services increased to 40% in 2013, with computing shifting from on-premise infrastructure to the cloud. To keep pace with the ever-accelerating rate of innovation, companies are moving to the cloud. However, visual computing in the cloud brings great challenges, such as how to measure and then improve the quality of experience in cloud computing. This Special Section provides the image/video community a forum to present new academic research and industrial development in running visual computing services in the cloud. This Special Section aims to address fundamental and practical aspects of visual computing in the cloud, such as how to build cloud platforms that can cope with seemingly unlimited supply of content coming from traditional media sources as well as new media uploaded to the Internet (YouTube, Facebook, etc.); how to leverage cloud technology to build high-quality image/video browsing and delivery experiences for a global audience; how to ingest, encode, process, adapt, as well as protect contents and privacy of users; how to provide both on-demand and live-streaming capabilities; how to tag image/video and allow consumers to access the image/video contents with high availability; how to support image/video services in mobile devices; and how to perform real-time image/video analytics in the cloud, to mention a few among a diverse range of challenges.},
  keywords={},
  doi={10.1109/TCSVT.2015.2472955},
  ISSN={1558-2205},
  month={Dec},}
