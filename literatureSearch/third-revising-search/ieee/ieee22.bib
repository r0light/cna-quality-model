@INPROCEEDINGS{7173479,
  author={Techio, Leila Regina and Misaghi, Mehran},
  booktitle={Fifth International Conference on the Innovative Computing Technology (INTECH 2015)}, 
  title={EMSCLOUD – an evaluative model of cloud services cloud service management}, 
  year={2015},
  volume={},
  number={},
  pages={100-105},
  abstract={Cloud computing is considered a paradigm both technology and business. Its widespread adoption is an increasingly effective trend. However, the lack of quality metrics and audit of services offered in the cloud slows its use, and it stimulates the increase in focused discussions with the adaptation of existing standards in management services for cloud services offered. This article describes the EMSCloud, that is an Evaluative Model of Cloud Services following interoperability standards, risk management and audit of cloud IT services. Aims to present that is possible to assess the life cycle of services offered in the cloud in the technical dimensions of usability, good practices and economic viability.},
  keywords={},
  doi={10.1109/INTECH.2015.7173479},
  ISSN={},
  month={May},}@INPROCEEDINGS{8080065,
  author={Gabi, Danlami and Ismail, Abdul Samad and Zainal, Anazida and Zakaria, Zalmiyah and Al-Khasawneh, Ahmad},
  booktitle={2017 8th International Conference on Information Technology (ICIT)}, 
  title={Cloud scalable multi-objective task scheduling algorithm for cloud computing using cat swarm optimization and simulated annealing}, 
  year={2017},
  volume={},
  number={},
  pages={599-604},
  abstract={In cloud computing, customers-desired Quality of Service (QoS) expectations are quite superficial due to lack of scalable task scheduling solutions that can adjust to long-time changes. Researchers in the literature have put forward several task scheduling algorithms to account for customers' QoS expectations. Unfortunately, most of these algorithms need improvements to ensure the provisioning of better consumers' QoS expectation. In this study, a Multi-Objective QoS model to address customers profit based on execution time and execution cost criteria is presented. A Cloud Scalable Multi-Objective Cat Swarm Optimization (CSO) based Simulated Annealing (SA) (CSM-CSOSA) algorithm is then proposed to solve the model. In this method, the Taguchi Orthogonal approach is used to enhanced the SA and incorporated into the local search of the proposed algorithm for enhancing it exploration capability. Implementation of the algorithm is carried out on CloudSim tool and evaluated using one dataset (Normal distributed) and one Parallel Workload (High-Performance Computing Center North(HPC2N)). Quantitative analysis of the algorithm performance is taken based on metrics of execution time, execution cost, QoS and percentage improvement. Result obtained is compared with that of Multi-Objective Genetic Algorithm (MOGA), Multi-Objective Ant Colony (MOSACO) and Multi-Objective Particle Swarm Optimization (MOPSO), where proposed method is able to returned substantial performance with improved QoS.},
  keywords={},
  doi={10.1109/ICITECH.2017.8080065},
  ISSN={},
  month={May},}@INPROCEEDINGS{8109266,
  author={Gonçalves, Charles Ferreira},
  booktitle={2017 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)}, 
  title={Benchmarking the Security of Virtualization Infrastructures: Motivation and Approach}, 
  year={2017},
  volume={},
  number={},
  pages={100-103},
  abstract={With the growing adoption of cloud computing for business systems, the efforts to keep those environments secure are also increasing. Virtualization infrastructures are key to support such systems, but engineers lack means to help them in selecting the best solutions according to their security requirements. The goal of this work is to define and develop a benchmarking approach to assess and compare the security of virtualization infrastructures. The approach allows the benchmark user to define his usage scenario, which will influence the assessment metrics and quality model. Well established performance benchmarks will be used as workload. The evaluation procedure comprises two key phases: i) security qualification to make sure that detectable/known vulnerabilities are not present; ii) trustworthiness assessment to gather further evidences of the system security. We believe this approach will allow assessing and comparing systems in terms of security, thus helping IaaS providers to select the best infrastructure for their specific needs.},
  keywords={},
  doi={10.1109/ISSREW.2017.70},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9269114,
  author={Papakonstantinou, Ioannis and Kalafatidis, Sarantis and Mamatas, Lefteris},
  booktitle={2020 16th International Conference on Network and Service Management (CNSM)}, 
  title={A Techno-Economic Assessment of Microservices}, 
  year={2020},
  volume={},
  number={},
  pages={1-5},
  abstract={The microservices design paradigm enables applications, usually based on containers, exploiting the flexibility of cloud computing and bringing unique scalability, fault-tolerance and resource-allocation benefits. A number of orchestration facilities, including Kubernetes, target the efficient deployment and operation of containers and are mainly focusing on the maintenance of server resource allocation under predefined thresholds, i.e., through scaling up or down containers to mitigate dynamic changes in the workload. In this work, we highlight the technical capabilities and cost-saving impact of microservices in contrast to traditional monolithic applications, based on a techno-economic analysis. We also investigate the service performance vs resource allocation trade-off, uncovering interesting dynamics when elasticity is driven from service quality metrics. This approach allows the Service Providers (SPs) to balance their profit margins with the customer satisfaction, i.e., reducing the infrastructure cost while keeping the service performance at an acceptable level.},
  keywords={},
  doi={10.23919/CNSM50824.2020.9269114},
  ISSN={2165-963X},
  month={Nov},}@INPROCEEDINGS{7018544,
  author={Nodehi, Tahereh and Ghimire, Sudeep and Jardim-Gonçalves, Ricardo},
  booktitle={2014 2nd International Conference on Model-Driven Engineering and Software Development (MODELSWARD)}, 
  title={Toward a unified intercloud interoperability conceptual model for IaaS cloud service}, 
  year={2014},
  volume={},
  number={},
  pages={673-681},
  abstract={The concept of interoperation between cloud providers is a recent research challenging objective. Current cloud systems have been developed without concerns of seamless cloud interconnection, and actually they do not support intercloud interoperability. The paper proposes a conceptual model for Intercloud Interoperability, to enable schedule dynamic operation for Infrastructure as a Service (IaaS) between different clouds. The paper is providing a better understanding of elaborates on the cloud computing architecture, appropriate metrics for Service Level Agreements (SLA) and Quality of Service (QoS) models that are required for seamless integration and interoperability between cloud environments. Then, a conceptual model for the Intercloud Interoperability Framework for Workload Migration is proposed. The novel component of the framework that provides interoperability is the Transformation Engine that maps workload between heterogeneous cloud providers, whilst Model Driven Architecture (MDA) is adopted as an applicable method for developing the Transformation Engine module.},
  keywords={},
  doi={},
  ISSN={},
  month={Jan},}@ARTICLE{7403967,
  author={Wang, Lujia and Liu, Ming and Meng, Max Q.-H.},
  journal={IEEE Transactions on Cybernetics}, 
  title={A Hierarchical Auction-Based Mechanism for Real-Time Resource Allocation in Cloud Robotic Systems}, 
  year={2017},
  volume={47},
  number={2},
  pages={473-484},
  abstract={Cloud computing enables users to share computing resources on-demand. The cloud computing framework cannot be directly mapped to cloud robotic systems with ad hoc networks since cloud robotic systems have additional constraints such as limited bandwidth and dynamic structure. However, most multirobotic applications with cooperative control adopt this decentralized approach to avoid a single point of failure. Robots need to continuously update intensive data to execute tasks in a coordinated manner, which implies real-time requirements. Thus, a resource allocation strategy is required, especially in such resource-constrained environments. This paper proposes a hierarchical auction-based mechanism, namely link quality matrix (LQM) auction, which is suitable for ad hoc networks by introducing a link quality indicator. The proposed algorithm produces a fast and robust method that is accurate and scalable. It reduces both global communication and unnecessary repeated computation. The proposed method is designed for firm real-time resource retrieval for physical multirobot systems. A joint surveillance scenario empirically validates the proposed mechanism by assessing several practical metrics. The results show that the proposed LQM auction outperforms state-of-the-art algorithms for resource allocation.},
  keywords={},
  doi={10.1109/TCYB.2016.2519525},
  ISSN={2168-2275},
  month={Feb},}@INPROCEEDINGS{9504780,
  author={Saemi, Behzad and Sadeghilalimi, Mehdi and Rahmani Hosseinabadi, Ali Asghar and Mouhoub, Malek and Sadaoui, Samira},
  booktitle={2021 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={A New Optimization Approach for Task Scheduling Problem Using Water Cycle Algorithm in Mobile Cloud Computing}, 
  year={2021},
  volume={},
  number={},
  pages={530-539},
  abstract={Mobile devices are used by numerous applications that continuously need computing power to grow. Due to limited resources for complex computing, offloading, a service offered for mobile devices, is commonly used in cloud computing. In Mobile Cloud Computing (MCC), offloading decides where to execute the tasks to efficiently maximize the benefits. Hence, we represent offloading as a Task Scheduling Problem (TSP). This latter is a Multi-Objective Optimization (MOO) problem where the goal is to find the best schedule for processing mobile source tasks, while minimizing both the average processor energy consumption and the average task processing time. Owing to the combinatorial nature of the problem, the TSP in MCC is known as NP-hard. To overcome this difficulty in practice, we adopt meta-heuristic search techniques as they offer a good trade-off between solution quality and scalability. More precisely, we introduce a new optimization approach, that we call Multi-objective Discrete Water Cycle Algorithm (MDWCA), to schedule tasks from mobile source nodes to processor resources in a hybrid MCC architecture, including public cloud, cloudlets, and mobile devices. To evaluate the performance of our proposed approach, we conducted several comparative experiments on many generated TSP instances in MCC. The simulation results show that MDWCA outperforms the state-of-the-art optimization algorithms for several quality metrics.},
  keywords={},
  doi={10.1109/CEC45853.2021.9504780},
  ISSN={},
  month={June},}@INPROCEEDINGS{9171079,
  author={Hans, Manoj and Jagtap, Nilesh and Deokate, Jivan Balasaheb and Jogi, Vivek Kant},
  booktitle={2020 Fourth International Conference on Inventive Systems and Control (ICISC)}, 
  title={Peak Load Management in Smart Grid – Integration of Rescheduling & Cloud Computing}, 
  year={2020},
  volume={},
  number={},
  pages={861-865},
  abstract={Ever-increasing demand for power has motivated researchers to come up with methodologies for meeting the demand. A smart grid is one of the solutions to minimizing the issue. A smart grid has become a proven way to optimize the load flow, hence the balance between the demand and supply of power is maintained. Though the problem of demand and supply is resolved to some extent still problems persist. The efficiency of the system i.e. end to end must be high. The quality of power must be intact. Considering above mentioned factors there can be checkpoints at three different levels. Remedial measures can be at the utility or the consumer end. As much can’t be done at the utility side due to several constraints hence there is a need for implementation of remedial measures on the consumer end, also known as the Demand Side Management (DSM). The demand-side management must be given emphasis because of several advantages it serves to the consumer as well as to the utility. DSM has been implemented at the Institute premises with the application of cloud computing. Communication of data between the cloud and the microgrid at the institute has been monitored and analyzed in the experimentation. Through analysis has been presented in the paper.},
  keywords={},
  doi={10.1109/ICISC47916.2020.9171079},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{9684637,
  author={Udomsripaiboon, Thana and Chaewsuwan, Chutiphan and Chumpoowang, Thanatip and Saetoen, Natthachai and Rojanavasu, Pornthep and Chaewsuwan, Thitirath},
  booktitle={2021 25th International Computer Science and Engineering Conference (ICSEC)}, 
  title={The Atmospheric Ozone Monitoring System by using Internet of Things Technology for Nanosatellites (3U CubeSat)}, 
  year={2021},
  volume={},
  number={},
  pages={325-329},
  abstract={This paper presents the system for monitoring the condition of the earth's ozone layer using Internet of Things (IoT) technology. The proposed system deploys a 3U CubeSat satellite to measure ultraviolet intensity to compare the intensity value of ultraviolet radiation at each terrestrial base station through the web application. The measured data is computed and classified by cloud computing into five levels of the regional ozone layer's quality: excellent, good, average, fair, and poor. These data can also be gathered as statistics and retrieved on a daily, monthly and annual basis. Consequently, by this information, campaigning for people to reduce the destructive behaviours of the ozone layer in each area would be incredibly advantageous. In addition, each base station can be built for less than $150 using commonly available electronics and sensors, allowing the proposed system to be implemented and deployed globally. As a result, this project would be of great benefit to humanity to have information on the health of the ozone layer in each region around the world. This paper could be better inform monitoring strategies to reduce the greenhouse effect that brings unfamiliar and unpredictable impacts of climate change to the world.},
  keywords={},
  doi={10.1109/ICSEC53205.2021.9684637},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{7498925,
  author={Karadimce, Aleksandar and Davcev, Danco},
  booktitle={2016 Eighth International Conference on Quality of Multimedia Experience (QoMEX)}, 
  title={Perception of quality in cloud computing based services}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={Cloud computing consists of hardware and software resources, available on the Internet as a set of services for users. This technology aims to provide stable, reliable and encapsulated dynamic information and communication environment for end users to be able to simultaneously access shared resources that are available anywhere and at any time. The major benefit of cloud computing is used to improve the perception of quality for the client requests. Commonly in the communications industry, the term Quality of Experience (QoE) is used as a measure for the user perception of service from the user's point of view. In this research, we propose a classification of cloud-based services based on objective and subjective characteristics for perception of quality. The main contribution in this paper is a novel approach based on Bayesian modeling for efficient assessment of QoE perception for cloud-based services considering the level of interactivity, service complexity, usage domain, and multimedia-intensity.},
  keywords={},
  doi={10.1109/QoMEX.2016.7498925},
  ISSN={},
  month={June},}@ARTICLE{7501820,
  author={Chen, Yunliang and Wang, Lizhe and Chen, Xiaodao and Ranjan, Rajiv and Zomaya, Albert Y. and Zhou, Yuchen and Hu, Shiyan},
  journal={IEEE Transactions on Cloud Computing}, 
  title={Stochastic Workload Scheduling for Uncoordinated Datacenter Clouds with Multiple QoS Constraints}, 
  year={2020},
  volume={8},
  number={4},
  pages={1284-1295},
  abstract={Cloud computing is now a well-adopted computing paradigm. With unprecedented scalability and flexibility, the computational cloud is able to carry out large scale computing tasks in parallel. The datacenter cloud is a new cloud computing model that uses multi-datacenter architectures for large scale massive data processing or computing. In datacenter cloud computing, the overall efficiency of the cloud depends largely on the workload scheduler, which allocates clients' tasks to different Cloud datacenters. Developing high performance workload scheduling techniques in Cloud computing imposes a great challenge which has been extensively studied. Most previous works aim only at minimizing the completion time of all tasks. However, timeliness is not the only concern, reliability and security are also very important. In this work, a comprehensive Quality of Service (QoS) model is proposed to measure the overall performance of datacenter clouds. An advanced Cross-Entropy based stochastic scheduling (CESS) algorithm is developed to optimize the accumulative QoS and sojourn time of all tasks. Experimental results show that our algorithm improves accumulative QoS and sojourn time by up to 56.1 and 25.4 percent respectively compared to the baseline algorithm. The runtime of our algorithm grows only linearly with the number of Cloud datacenters and tasks. Given the same arrival rate and service rate ratio, our algorithm steadily generates scheduling solutions with satisfactory QoS without sacrificing sojourn time.},
  keywords={},
  doi={10.1109/TCC.2016.2586048},
  ISSN={2168-7161},
  month={Oct},}@INPROCEEDINGS{9091376,
  author={Zhang, Ziyi and Guo, Caishan and Sun, Yuyan and Hu, Kaiqiang and Wang, Qinghai and Wu, Yuzhao and Cai, Zexiang},
  booktitle={2019 IEEE International Conference on Smart Cloud (SmartCloud)}, 
  title={Cloud Computing Placement Optimization Under Ubiquitous Power Internet of Things Background}, 
  year={2019},
  volume={},
  number={},
  pages={13-18},
  abstract={With the development of power system and the introduction of the Energy Internet, the implementation of Ubiquitous Power Internet of Things (UPIoT) is necessary for power utilities to meet the demands of Integrated Energy Applications. Massive heterogeneous data from various devices surge into power system via UPIoT, which puts heavy burden on data processing capabilities of power system. Cloud computing is an effective measure to provide big data processing capabilities and the establishment of cloud computing for power system is of great significance. Firstly, the architecture of UPIoT and the cloud computing system based on UPIoT background are analyzed. Considering the characteristics of power system, a distributed cloud computing architecture for power system is proposed. A coordinated placement optimization strategy based on minimum cost and satisfaction of quality of service for the proposed architecture is formulated. Based on a given case, the placement optimization simulations are studied. The simulation results prove that the proposed architecture is cost-efficient and the proposed optimization strategy is effective and efficient.},
  keywords={},
  doi={10.1109/SmartCloud.2019.00012},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8422956,
  author={Skourletopoulos, Georgios and Mavromoustakis, Constandinos X. and Mastorakis, George and Batalla, Jordi Mongay and Song, Houbing and Sahalos, John N. and Pallis, Evangelos},
  booktitle={2018 IEEE International Conference on Communications (ICC)}, 
  title={Elasticity Debt Analytics Exploitation for Green Mobile Cloud Computing: An Equilibrium Model}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={Mobile cloud computing is being accepted as the model for mobile users to ubiquitously access a shared pool of cloud computing resources, data and services on-demand. In this context, elasticity debt analytics can be harnessed as a measure for efficient scheduling of cloud resources and guarantee of quality of service requirements. This paper proposes a novel green-driven, game theoretic approach to minimizing the elasticity debt on mobile cloud-based service level, investigating the case when a task is offloaded, scheduled and executed on a mobile cloud computing system. The decision to offload a mobile device user's task on cloud affects the level of elasticity debt minimization for the provided services. The research problem is formulated as an elasticity debt quantification game, elaborating on an incentive mechanism to: (a) predict elasticity debt and mitigate the risk of service overutilization, (b) achieve scalability as the number of mobile device user requests for cloud resources increases or decreases accordingly, and (c) optimize cloud resource provisioning, parameterizing the current pool of active users per service. The experimental results prove the effectiveness of the equilibrium model, which allocates the mobile device user requests to high elasticity debt-level services and facilitate elasticity debt minimization for greener mobile cloud computing environments.},
  keywords={},
  doi={10.1109/ICC.2018.8422956},
  ISSN={1938-1883},
  month={May},}@ARTICLE{8752013,
  author={Yang, Xiao and Pavelsky, Tamlin M. and Allen, George H. and Donchyts, Gennadii},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={RivWidthCloud: An Automated Google Earth Engine Algorithm for River Width Extraction From Remotely Sensed Imagery}, 
  year={2020},
  volume={17},
  number={2},
  pages={217-221},
  abstract={The wetted width of a river is one of the most important hydraulic parameters that can be readily measured using remote sensing. Remotely sensed river widths are used to estimate key attributes of river systems, including changes in their surface area, channel storage, and discharge. Although several published algorithms automate river network and width extraction from remote sensing images, they are limited by only being able to run on local computers and do not automatically manage cloudy images as input. Here we present RivWidthCloud, a river width software package developed on the Google Earth Engine cloud computing platform. RivWidthCloud automatically extracts river centerline and widths from optical satellite images with the ability to flag observations that are obstructed by features like clouds, cloud shadows, and snow based on existing quality band classification. Because RivWidthCloud is built on a popular cloud computing platform, it allows users to easily apply the algorithm to the platform's vast archive of remote sensing images, thereby reducing the users' overhead for computing hardware and data storage. By comparing RivWidthCloud-derived widths from Landsat images to in situ widths from the U.S. and Canada, we show that RivWidthCloud can estimate widths with high accuracy (root mean square error: 99 m; mean absolute error: 43 m; mean bias: -21 m). By making RivWidthCloud publicly available, we anticipate that it will be used to address both river science questions and operational applications of water resource management.},
  keywords={},
  doi={10.1109/LGRS.2019.2920225},
  ISSN={1558-0571},
  month={Feb},}@INPROCEEDINGS{7328126,
  author={Al-Shammari, Shaymaa and Al-Yasiri, Adil},
  booktitle={2015 IEEE 9th International Symposium on the Maintenance and Evolution of Service-Oriented and Cloud-Based Environments (MESOCA)}, 
  title={MonSLAR: a middleware for monitoring SLA for RESTFUL services in cloud computing}, 
  year={2015},
  volume={},
  number={},
  pages={46-50},
  abstract={Measuring the quality of cloud computing provision from the client's point of view is important in order to ensure that the service conforms to the level specified in the service level agreement (SLA). With a view to avoid SLA violation, the main parameters should be determined in the agreement and then used to evaluate the fulfillment of the SLA terms at the client's side. Current studies in cloud monitoring only handle monitoring the provider resources with little or no consideration to the client's side. This paper presents MonSLAR, a User-centric middleware for Monitoring SLA for Restful services in SaaS cloud computing environments. MonSLAR uses a distributed architecture that allows SLA parameters and the monitored data to be embedded in the requests and responses of the REST protocol.},
  keywords={},
  doi={10.1109/MESOCA.2015.7328126},
  ISSN={2326-6937},
  month={Oct},}@INPROCEEDINGS{8279168,
  author={Shibu, Sini and Naik, Archana},
  booktitle={2017 International Conference on Information, Communication, Instrumentation and Control (ICICIC)}, 
  title={An approach to increase the awareness of e-governance initiatives based on cloud computing}, 
  year={2017},
  volume={},
  number={},
  pages={1-4},
  abstract={E-governance is being adopted by the governments of every country for its operations through the ICT (Information and Communication Technology) i.e. incorporating its operations through IT model so that the schemes can be reached to the masses. In India too, as of now, nearly every state government has its own e-Governance model. Cloud computing is now being widely used in e-governance. With the help of the features of Cloud computing, e-Governance operations can be built up as cost effective technology solutions and can be geographically distributed to heterogeneous resources thereby increasing the quality of service to the users. In fact, G-cloud (Governance on Cloud) is designed for using Government services. It is not merely enough to set up e-governance models but its awareness amongst masses is equally important. This paper analyses the cloud based model of e-governance and suggests measures to increase awareness among people regarding the various e-governance initiatives taken by the Government of Madhya Pradesh.},
  keywords={},
  doi={10.1109/ICOMICON.2017.8279168},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{7453380,
  author={Singh, Sarbjeet and Sidhu, Jagpreet},
  booktitle={2015 2nd International Conference on Recent Advances in Engineering & Computational Sciences (RAECS)}, 
  title={A collaborative trust calculation scheme for cloud computing systems}, 
  year={2015},
  volume={},
  number={},
  pages={1-5},
  abstract={One of the major hurdles in the widespread use of cloud computing systems is the lack of trust between consumer and service provider. Lack of trust can put consumer's sensitive data and applications at risk. Consumers need assurance that service providers will provide services as per agreement and will not deviate from agreed terms and conditions. Though trust is a subjective term, it can be measured objectively also. In this paper we present the design and simulation of a collaborative trust calculation scheme in which trust on a service provider is build by participants in a collaborative way. Each collaborator shares its experience of service provider with the coordinator and then shared experiences are aggregated by coordinator to compute final trust value which represents the trustworthiness of service provider. The scheme makes use of fuzzy logic to aggregate responses and to handle uncertain and imprecise information. Collaborative trust calculation scheme makes it difficult for untrustworthy service provider to build its reputation in the system by providing quality services only to a selected set of participants. A service provider has to provide agreed services to all participants uniformly in order to build reputation in the environment. Simulation has been done using MATLAB toolkit. Simulation results show that the scheme is workable and can be adopted for use in collaborative cloud computing systems to determine trustworthiness of service providers.},
  keywords={},
  doi={10.1109/RAECS.2015.7453380},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8666838,
  author={Mengge, YUAN and Rui, LI and Ning, ZHAO},
  booktitle={2018 International Conference on Information Systems and Computer Aided Education (ICISCAE)}, 
  title={Optimization of the Number of Servers in Cloud Computing Centers}, 
  year={2018},
  volume={},
  number={},
  pages={269-273},
  abstract={To improve the service quality and save the system cost of the cloud computing center, this paper studies the joint optimization problem of energy consumption and performance of cloud computing centers with a batch Markovian arrival process. The system has multiple parallel processors and the processing time of each processor follows phase type distribution. The system has finite buffer. We construct the system as a BMAP/PH/N/M queueing system and analyze the performance of the system based on queuing theory. An optimization model is established by combing the energy consumption and system performance measures. The optimal number of servers is analyzed. Some managerial insights are given by numerical analysis.},
  keywords={},
  doi={10.1109/ICISCAE.2018.8666838},
  ISSN={},
  month={July},}@INPROCEEDINGS{9084987,
  author={Chen, Zhijia and Di, Yanqiang and Yuan, Hongli and Feng, Shaochong},
  booktitle={2020 IEEE 4th Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)}, 
  title={Intelligent Cloud Training System based on Edge Computing and Cloud Computing}, 
  year={2020},
  volume={1},
  number={},
  pages={1550-1553},
  abstract={Equipment simulation training based on cloud computing is emerging. However, the latency between cloud center and client is long, and the energy consumption management is difficult, which are influencing the development of cloud training. Intelligent cloud training system based on edge computing and cloud computing is introduced in this paper. Intelligent gateway is introduced, through which the task and resources are scheduled and managed together. The popularity of training resources is analyzed. The management of servers in cloud center and edge is intelligently switched between timing sleep and task-activation. Intelligent training service provisioning is achieved through above measures. The simulation results show that the system and management methods are effective on improving training service quality and lower the energy consumption.},
  keywords={},
  doi={10.1109/ITNEC48623.2020.9084987},
  ISSN={},
  month={June},}@ARTICLE{8852632,
  author={Ala’anzy, Mohammed and Othman, Mohamed},
  journal={IEEE Access}, 
  title={Load Balancing and Server Consolidation in Cloud Computing Environments: A Meta-Study}, 
  year={2019},
  volume={7},
  number={},
  pages={141868-141887},
  abstract={The data-center is considered the heart of cloud computing. Recently, the growing demand for cloud computing services has caused a growing load on data centers. In terms of system behavior and workload, patterns of cloud computing are very dynamic; and that might serve to imbalance the load among data center resources. Eventually, some data-center resources could come to be over-loaded/under-loaded, which leads to an increase in energy consumption in addition to decreased functioning and wastage of resources. Just considering energy-efficiency (that can be attained efficiently by consolidate the servers) may not be enough for real applications because it may cause problems such as unbalanced load for each Physical Machine (PM). Therefore, this paper surveys published load balancing algorithms that achieved by server consolidation via a meta-analysis. Load balancing with server consolidation enriches the exploitation of resource utilization and can enhance Quality of Service (QoS) metrics, since data-centers and their applications are increasing exponentially. This meta-study, reviews the literature on load balancing and server consolidation and presents a ready reference taxonomy on the most efficient algorithms that achieve load balancing and server consolidation. This work attempts to present a taxonomy with a new classification for load balancing and server consolidation, such as migration overhead, hardware threshold, network traffic, and reliability.},
  keywords={},
  doi={10.1109/ACCESS.2019.2944420},
  ISSN={2169-3536},
  month={},}@ARTICLE{9261243,
  author={Bui, Khiet Thanh and Van Vo, Len and Nguyen, Canh Minh and Pham, Tran Vu and Tran, Hung Cong},
  journal={Journal of Communications and Networks}, 
  title={A fault detection and diagnosis approach for multi-tier application in cloud computing}, 
  year={2020},
  volume={22},
  number={5},
  pages={399-414},
  abstract={Ensuring the availability of cloud computing services always concerns both service providers and end users. Therefore, the system always needs precautions for unexpected cases. Accordingly, cloud computing services must be capable of identifying faults and behaving appropriately when it is abnormal to ensure the smoothness as well as the service quality. In this study, we propose a fault detection method for multi-tier web application in cloud computing deployment environment based on the Fuzzy One-class support vector machine and Exponentially Weighted Moving Average method. And then, the suspicious metrics are located by using feature selection method which based on Random Forest algorithm. To evaluate our approach, a multi-tier application is deployed by a transnational web e-Commerce benchmark by using TPC-W (TPC Benchmark™ W, simulates the activities of a business oriented transaction web server in a controlled internet commerce environment) in private cloud and then it is injected typical faults. The effectiveness of the fault detection and diagnosis are demonstrated in experiment results.},
  keywords={},
  doi={10.1109/JCN.2020.000023},
  ISSN={1976-5541},
  month={Oct},}@INPROCEEDINGS{8422909,
  author={Kong, Cuiyu and Rimal, Bhaskar Prasad and Bhattarai, Bishnu P. and Devetsikiotis, Michael},
  booktitle={2018 IEEE International Conference on Communications (ICC)}, 
  title={Cloud-Based Charging Management of Electric Vehicles in a Network of Charging Stations}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={A large scale of electric vehicles (EVs) and the operation of smart grid requires the support of a reliable and robust communication infrastructure. Cloud computing has gained popularity in smart grid for reducing computational and communication complexity. Based on cloud computing services, this paper considers the issues of high charging demand in fast charging stations (FCSs) during peak hours and communication among a large-scale of EVs, a network of FCSs, and system operator (SO). More specifically, we propose a novel cloud-based hierarchical charging management model of EVs, whereby two levels of cloud computing infrastructures are considered to meet different latency requirements of customers in highway exits and parking lots. Considering the quality of service (QoS) metrics (average waiting time in the queue, and blocking probability), the model is composed of: server planning in the cloud, capacity planning in FCSs, and profit maximization. Meanwhile, a price incentive mechanism is applied to shift the heavy load from peak hours to off-peak hours. Numerical results demonstrate the effectiveness of the proposed method, which can guarantee QoS and system profit, thereby more customers can satisfy their charging demand.},
  keywords={},
  doi={10.1109/ICC.2018.8422909},
  ISSN={1938-1883},
  month={May},}@INPROCEEDINGS{8229905,
  author={Baghel, Dinesh Kumar and Singh, Arun and Deka, Pratyush Kumar},
  booktitle={2017 International Conference on Computing, Communication and Automation (ICCCA)}, 
  title={Agricultural management using cloud computing in India}, 
  year={2017},
  volume={},
  number={},
  pages={801-806},
  abstract={Although agriculture now accounts for only 14 percent of Gross Domestic Product (GDP), rapid growth of agriculture in India is critical for inclusiveness. Information Communication and Technology (ICT) provides greater role in offering greater expertise to producers regarding pricing, good quality seed information, fertilizers, disease detail, sharing new discoveries of scientists working at various Agricultural Institutes. An effective implementation of cloud computing in agricultural sector is encouraging and required for overall development of agricultural sector of India. There are potential risks in cloud computing which if properly addressed can be a potent ICT tool in agricultural sector in India. Considering the benefits of cloud computing, a design is proposed for Indian agricultural sector and two performance metrics are discussed which can be used to assess any cloud based application.},
  keywords={},
  doi={10.1109/CCAA.2017.8229905},
  ISSN={},
  month={May},}@INPROCEEDINGS{8390054,
  author={Gopavanitha, K. and Nagaraju, S.},
  booktitle={2017 International Conference on Energy, Communication, Data Analytics and Soft Computing (ICECDS)}, 
  title={A low cost system for real time water quality monitoring and controlling using IoT}, 
  year={2017},
  volume={},
  number={},
  pages={3227-3229},
  abstract={Water is a prerequisite element required for humans and therefore there must be mechanisms put in place to vigorously test the quality of drinking water in real time. This paper proposes a low cost system for real time water quality monitoring and controlling using IoT. The system consist of physiochemical sensors which can measures the physical and chemical parameters of the water such as Temperature, Turbidity, Conductivity, pH and Flow. By these sensors, water contaminants are detected. The sensor values processed by Raspberry pi and send to the cloud. Finally the sensed data is visible on the cloud using cloud computing and the flow of the water in the pipeline is controlled through IoT.},
  keywords={},
  doi={10.1109/ICECDS.2017.8390054},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{7974607,
  author={Li, Suyou and Guo, Zhigang and Shou, Guochu and Hu, Yihong and Li, Hongxing},
  booktitle={2016 IEEE International Conference on Network Infrastructure and Digital Content (IC-NIDC)}, 
  title={QoE analysis of NFV-based mobile edge computing video application}, 
  year={2016},
  volume={},
  number={},
  pages={411-415},
  abstract={Mobile Edge Computing (MEC) provides mobile and cloud computing capabilities within the access network. Network Functions Virtualization (NFV) leverages standard IT Virtualization technology to decouple the network functions from the underlying physical infrastructure. Basing on the ICT demand, MEC can be consolidated into NFV, as a network element within access network. This paper presents an architecture of NFV-based MEC platform and analyzes its Quality of Service (QoS) compared with the remote servers (Shenzhen and Qingdao). Then, this paper measures the Quality of Experience (QoE) of HTTP videos deployed in the servers. The result shows MEC can offer a service environment with higher bandwidth, which supports 10-fold gains, and ultra-low latency, jitter and packet loss rate. Moreover, along with the higher resolution and bitrates, the range of the video QoE improvement on this platform rises compared with the remote servers. In a word, the NFV-based MEC can achieve better performance than the remote servers.},
  keywords={},
  doi={10.1109/ICNIDC.2016.7974607},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9242798,
  author={Abdulwahid, Ali Hadi},
  booktitle={2020 9th International Conference on Renewable Energy Research and Application (ICRERA)}, 
  title={IoT Based Water Quality Monitoring System for Rural Areas}, 
  year={2020},
  volume={},
  number={},
  pages={279-282},
  abstract={To ensure that safety is guaranteed, it is essential to implement monitoring in real-time for the quality of potable water. This work is about the use of Internet of Things (IoT) technology to develop an affordable system to control water quality in real-time. Several sensors are integrated into the system to measure various chemical and physical water properties, such as conductivity, pH, turbidity, and temperature. The core controller, which can also be the microprocessor, manages the processing of data captured by the sensor. The visualization of data can be accomplished on cloud computing via the Internet.},
  keywords={},
  doi={10.1109/ICRERA49962.2020.9242798},
  ISSN={2572-6013},
  month={Sep.},}@INPROCEEDINGS{8310143,
  author={Puteaux, Pauline and Puech, William},
  booktitle={2017 Seventh International Conference on Image Processing Theory, Tools and Applications (IPTA)}, 
  title={Reversible data hiding in encrypted images based on adaptive local entropy analysis}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={With the development of cloud computing, the growth in information technology has led to serious security issues. For this reason, a lot of multimedia files are stored in encrypted forms. Methods of reversible data hiding in encrypted images (RDHEI) have been designed to provide authentication and integrity in the encrypted domain. The original image is firstly encrypted to ensure confidentiality, by making the content unreadable. A secret message is then embedded in the encrypted image, without the need of the encryption key or any access to the clear content. The challenge lies in finding the best trade-off between embedding capacity and quality of the reconstructed image. In 2008, Puech et al. suggested using the AES algorithm to encrypt an original image and to embed one bit in each block of 16 pixels (payload = 0.0625 bpp) [12]. During the decryption phase, the original image is reconstructed by measuring the standard deviation into each block. In this paper, we propose an improvement to this method, by performing an adaptive local entropy measurement. We can achieve a larger payload without altering the recovered image quality. Our obtained results are very good and better than most of the modern state-of-the-art methods, whilst offering an improved security level with the use of the AES algorithm, defined as the encryption standard by the NIST.},
  keywords={},
  doi={10.1109/IPTA.2017.8310143},
  ISSN={2154-512X},
  month={Nov},}@INPROCEEDINGS{8364051,
  author={Ramos da Paixão, Ermínio Augusto and Vieira, Rafael Fogarolli and Araújo, Welton Vasconcelos and Cardoso, Diego Lisboa},
  booktitle={2018 Third International Conference on Fog and Mobile Edge Computing (FMEC)}, 
  title={Optimized load balancing by dynamic BBU-RRH mapping in C-RAN architecture}, 
  year={2018},
  volume={},
  number={},
  pages={100-104},
  abstract={Cloud Radio Access Network (C-RAN) is one of the key architectures for the next generation of mobile networks (5G) that aim at centralized processing and management, collaborative radios and cloud computing in real time. These features enable the architectures to make a rational adjustment to the connection between remote radio heads (RRHs) and baseband units (BBUs) dynamically. This is important since if this feature is neglected, it can cause difficulties such as blocked calls and low-quality connections. This study investigates this area and proposes an optimized mapping model for RRH-BBU that seeks a more equitable and effective balancing. The Key Performance Indicator (KPI) of blocked calls was used for this to measure the quality of service (QoS). A particle Swarm algorithm (PSO) was created to minimize the number of blocked calls and additionally balancing the processing load between the BBUs. Scenario from literature was employed that consists of 19 RRHs distributed in a geographic area, which can be mapped in a BBU pool that manages two BBUs with three sectors each. The initial configuration on average, led to 80 blocked calls. The results obtained by the PSO show that there was a reduction of up to 100% of blocked calls, as well as a more equitable load distribution between the BBUs. Additionally, realistic scenarios with different user profiles were also included, since they demonstrate that these factors have a direct impact on the load generated in the BBUs and hence, affect their balance.},
  keywords={},
  doi={10.1109/FMEC.2018.8364051},
  ISSN={},
  month={April},}@INPROCEEDINGS{9178684,
  author={Wang, Chengrong and Zhang, Xiaodong and Chu, Dianhui},
  booktitle={2020 5th International Conference on Computational Intelligence and Applications (ICCIA)}, 
  title={Research on Service Composition Optimization Method Based on Composite Services QoS}, 
  year={2020},
  volume={},
  number={},
  pages={206-210},
  abstract={With the development of Cloud Computing, Internet of Things, and the advent of the era of Big Data, the types and scale of services are getting larger and larger, and the problem space of service composition is exploding. In order to measure the composite services quality of different combination schemes, this paper shows the calculation method of composite services QoS (Quality of Service), and improves the Ant Colony Algorithm by introducing Skyline calculation to further improve the efficiency of service composition and respond to user quickly. Finally, it is verified on the real QoS data set, and the feasibility and effectiveness of the method are proved through experiments.},
  keywords={},
  doi={10.1109/ICCIA49625.2020.00046},
  ISSN={},
  month={June},}@ARTICLE{7517217,
  author={Lyu, Xinchen and Tian, Hui and Sengul, Cigdem and Zhang, Ping},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={Multiuser Joint Task Offloading and Resource Optimization in Proximate Clouds}, 
  year={2017},
  volume={66},
  number={4},
  pages={3435-3447},
  abstract={Proximate cloud computing enables computationally intensive applications on mobile devices, providing a rich user experience. However, remote resource bottlenecks limit the scalability of offloading, requiring optimization of the offloading decision and resource utilization. To this end, in this paper, we leverage the variability in capabilities of mobile devices and user preferences. Our system utility metric is a measure of quality of experience (QoE) based on task completion time and energy consumption of a mobile device. We propose a heuristic offloading decision algorithm (HODA), which is semidistributed and jointly optimizes the offloading decision, and communication and computation resources to maximize system utility. Our main contribution is to reduce the problem to a submodular maximization problem and prove its NP-hardness by decomposing it into two subproblems: 1) optimization of communication and computation resources solved by quasiconvex and convex optimization and 2) offloading decision solved by submodular set function optimization. HODA reduces the complexity of finding the local optimum to O(K3), where K is the number of mobile users. Simulation results show that HODA performs within 5% of the optimal on average. Compared with other solutions, HODA's performance is significantly superior as the number of users increases.},
  keywords={},
  doi={10.1109/TVT.2016.2593486},
  ISSN={1939-9359},
  month={April},}@ARTICLE{8082532,
  author={Abdul-Rahman, Omar Arif and Aida, Kento},
  journal={IEEE Transactions on Cloud Computing}, 
  title={Google Users as Sequences: A Robust Hierarchical Cluster Analysis Study}, 
  year={2020},
  volume={8},
  number={1},
  pages={167-179},
  abstract={In this era of cloud computing, users encounter the challenging task of effectively composing and running their applications on the cloud. By understanding user behavior in constructing applications and interacting with typical cloud infrastructures, cloud managers can develop better systems that improve the users' experience. In this paper, we analyze a large dataset of a Google cluster to characterize the users into distinct groups of similar usage behavior. We used a wide range of measured metrics to model user behavior in composing applications from the perspective of actions around application architecting, capacity planning, and workload type planning and to model user interaction behavior around the session view. The trajectories of users' actions are represented as sequences using categorical and proportional encoding schemes. We used techniques from the sequence analysis paradigm to quantify dissimilarity among users. We employed a robust cluster analysis procedure based on the agglomerative hierarchical methods to optimally classify users into 12 classes. We used a variety of formal indices and visual aids to confirm the quality and stability of the outcomes. By visual inspection, we regrouped the obtained clusters into 5 main groups that reveal interesting insights about the characteristics which underline different groups' utilization behavior.},
  keywords={},
  doi={10.1109/TCC.2017.2766227},
  ISSN={2168-7161},
  month={Jan},}@INPROCEEDINGS{7152489,
  author={Kuang, Wei and Brown, Laura E. and Wang, Zhenlin},
  booktitle={2015 15th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing}, 
  title={Modeling Cross-Architecture Co-Tenancy Performance Interference}, 
  year={2015},
  volume={},
  number={},
  pages={231-240},
  abstract={Cloud computing has become a dominant computing paradigm to provide elastic, affordable computing resources to end users. Due to the increased computing power of modern machines powered by multi/many-core computing, data centers often co-locate multiple virtual machines (VMs) into one physical machine, resulting in co-tenancy, and resource sharing and competition. Applications or VMs co-locating in one physical machine can interfere with each other despite of the promise of performance isolation through virtualization. Modelling and predicting co-run interference therefore becomes critical for data center job scheduling and QoS (Quality of Service) assurance. Co-run interference can be categorized into two metrics, sensitivity and pressure, where the former denotes how an application's performance is affected by its co-run applications, and the latter measures how it impacts the performance of its co-run applications. This paper shows that sensitivity and pressure are both application-and architecture dependent. Further, we propose a regression model that predicts an application's sensitivity and pressure across architectures with high accuracy. This regression model enables a data center scheduler to guarantee the QoS of a VM/application when it is scheduled to co-locate with another VMs/applications.},
  keywords={},
  doi={10.1109/CCGrid.2015.152},
  ISSN={},
  month={May},}@INPROCEEDINGS{7744161,
  author={He, Fei-Long and Chen, Wei-Neng and Hu, Xiao-Min},
  booktitle={2016 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Differential evolution with double-level archives for bi-objective cloud task scheduling}, 
  year={2016},
  volume={},
  number={},
  pages={2942-2949},
  abstract={In cloud computing, scheduling plays a critical role for quality of service (QoS) and provider efficiency which are generally measured by several metrics and make the scheduling a multiobjective problem (MOP). In this paper, we propose a differential evolution algorithm with double-level archives (DE-DLA) for bi-objective cloud task scheduling. The proposed algorithm is based on the newly-developed framework, multiobjective evolutionary algorithm with double-level archives (MOEA-DLA), and uses differential evolution to implement this framework. Global Archive is used to save Pareto-optimal individuals for the whole problem and Sub-archive is used to save several comparatively good individuals for the corresponding sub-problem formed by decomposition. So the algorithm takes advantages of both whole multiobjective problem optimization and decomposition based optimization. Precedence constraint in user's application is considered in the scheduling model of this paper. To minimize cost and makespan simultaneously, the proposed algorithm tries to find optimal resource allocation and optimal order of task executing. In the experiment, compared with two other algorithms, DE-DLA has shown competitive advantages.},
  keywords={},
  doi={10.1109/CEC.2016.7744161},
  ISSN={},
  month={July},}@ARTICLE{6856153,
  author={Shuja, Junaid and Bilal, Kashif and Madani, Sajjad A. and Othman, Mazliza and Ranjan, Rajiv and Balaji, Pavan and Khan, Samee U.},
  journal={IEEE Systems Journal}, 
  title={Survey of Techniques and Architectures for Designing Energy-Efficient Data Centers}, 
  year={2016},
  volume={10},
  number={2},
  pages={507-519},
  abstract={Cloud computing has emerged as the leading paradigm for information technology businesses. Cloud computing provides a platform to manage and deliver computing services around the world over the Internet. Cloud services have helped businesses utilize computing services on demand with no upfront investments. The cloud computing paradigm has sustained its growth, which has led to increase in size and number of data centers. Data centers with thousands of computing devices are deployed as back end to provide cloud services. Computing devices are deployed redundantly in data centers to ensure 24/7 availability. However, many studies have pointed out that data centers consume large amount of electricity, thus calling for energy-efficiency measures. In this survey, we discuss research issues related to conflicting requirements of maximizing quality of services (QoSs) (availability, reliability, etc.) delivered by the cloud services while minimizing energy consumption of the data center resources. In this paper, we present the concept of inception of data center energy-efficiency controller that can consolidate data center resources with minimal effect on QoS requirements. We discuss software- and hardware-based techniques and architectures for data center resources such as server, memory, and network devices that can be manipulated by the data center controller to achieve energy efficiency.},
  keywords={},
  doi={10.1109/JSYST.2014.2315823},
  ISSN={1937-9234},
  month={June},}@ARTICLE{8683979,
  author={Gamal, Marwa and Rizk, Rawya and Mahdi, Hani and Elnaghi, Basem E.},
  journal={IEEE Access}, 
  title={Osmotic Bio-Inspired Load Balancing Algorithm in Cloud Computing}, 
  year={2019},
  volume={7},
  number={},
  pages={42735-42744},
  abstract={Cloud computing is increasing rapidly as a successful paradigm presenting on-demand infrastructure, platform, and software services to clients. Load balancing is one of the important issues in cloud computing to distribute the dynamic workload equally among all the nodes to avoid the status that some nodes are overloaded while others are underloaded. Many algorithms have been suggested to perform this task. Recently, worldview is turning into a new paradigm for optimization search by applying the osmosis theory from chemistry science to form osmotic computing. Osmotic computing is aimed to achieve balance in highly distributed environments. The main goal of this paper is to propose a hybrid metaheuristics technique which combines the osmotic behavior with bio-inspired load balancing algorithms. The osmotic behavior enables the automatic deployment of virtual machines (VMs) that are migrated through cloud infrastructures. Since the hybrid artificial bee colony and ant colony optimization proved its efficiency in the dynamic environment in cloud computing, the paper then exploits the advantages of these bio-inspired algorithms to form an osmotic hybrid artificial bee and ant colony (OH_BAC) optimization load balancing algorithm. It overcomes the drawbacks of the existing bio-inspired algorithms in achieving load balancing between physical machines. The simulation results show that OH_BAC decreases energy consumption, the number of VMs migrations and the number of shutdown hosts compared to existing algorithms. In addition, it enhances the quality of services (QoSs) which is measured by service level agreement violation (SLAV) and performance degradation due to migrations (PDMs).},
  keywords={},
  doi={10.1109/ACCESS.2019.2907615},
  ISSN={2169-3536},
  month={},}@ARTICLE{7066939,
  author={Lillo-Castellano, J. M. and Mora-Jiménez, I. and Santiago-Mozos, R. and Chavarría-Asso, F. and Cano-González, A. and García-Alberola, A. and Rojo-Álvarez, J. L.},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Symmetrical Compression Distance for Arrhythmia Discrimination in Cloud-Based Big-Data Services}, 
  year={2015},
  volume={19},
  number={4},
  pages={1253-1263},
  abstract={The current development of cloud computing is completely changing the paradigm of data knowledge extraction in huge databases. An example of this technology in the cardiac arrhythmia field is the SCOOP platform, a national-level scientific cloud-based big data service for implantable cardioverter defibrillators. In this scenario, we here propose a new methodology for automatic classification of intracardiac electrograms (EGMs) in a cloud computing system, designed for minimal signal preprocessing. A new compression-based similarity measure (CSM) is created for low computational burden, so-called weighted fast compression distance, which provides better performance when compared with other CSMs in the literature. Using simple machine learning techniques, a set of 6848 EGMs extracted from SCOOP platform were classified into seven cardiac arrhythmia classes and one noise class, reaching near to 90% accuracy when previous patient arrhythmia information was available and 63% otherwise, hence overcoming in all cases the classification provided by the majority class. Results show that this methodology can be used as a high-quality service of cloud computing, providing support to physicians for improving the knowledge on patient diagnosis.},
  keywords={},
  doi={10.1109/JBHI.2015.2412175},
  ISSN={2168-2208},
  month={July},}@INPROCEEDINGS{8046685,
  author={Wang, Paul and Takizawa, Shigeyuki and He, David and Ge, Fred and Wang, Orson and Ye, Fred and Liang, Park and Tan, KG},
  booktitle={2017 18th International Conference on Electronic Packaging Technology (ICEPT)}, 
  title={DDR4 dual-contact interconnect methodology, component, and board level reliability}, 
  year={2017},
  volume={},
  number={},
  pages={1337-1344},
  abstract={This article is a series of study on new generation of electronic contact challenges and component interconnects technology for high-end computing products. These products include server and data storage for cloud computing applications at the data center as well as core routers for service providers, edge and branch routers for enterprise networking companies, and small switch and wireless router for commercial and small and home office. All these cloud computing products require high data speed in terabytes per second and high signal integrity for the massive mobile users and loT application whenever and wherever they connected To achieve such mobility and signal integrity the major focus is the electrical interconnections between the CPUlGPU and component in the system. Due to the large number of edge-card connections such as DIMM, PCle, etc. in modern computer systems and due to their relatively low reliability, in previous Part 2 of the study a test vehicle with daisy chain was used to assess the contact interconnect failure related to factors such as soldering flux residue, plating quality, contact interface cleaning and doubt insertion, and particulate control and management. As concluded in Part 2, the heavy flux residue and vibration preconditioning have medium effect on contact failure, however contact interface cleaning and particulate control show no significant contribution and not able to eliminate the last thousands DPPM of DIMM contact failure. The purpose of current study is to look into a new generation of dual-contact interconnect methodology and assess component level contact configuration and interconnect reliability. First, the contact pin configuration and plating morphology such as homogeneity and thickness are carefully examined to ensure contact integrity between DDR4 connect and DIMM module can be achieved. Then normal force of dual-pin and individual first and second contact were measured to benchmark to existing conventional single-contacts. Furthermore the JEDEC Raptor test vehicle was adapted to assess characteristic impedance and four signal integrity tests, RL (return loss), IL (insertion loss), NEXT (near-end cross talk), and FEXT (far-end cross talk) to ensure signal integrity requirements are fulfilled. Finally, board level reliability test is proposed for Raptor test board and trial run on real product. The overall goal of Part 3 of the study is to ensure a smooth migration from conventional single-contact to a new interconnect mechanism with robust board and system reliability for high signal integrity requirement in cloud computing and loT application.},
  keywords={},
  doi={10.1109/ICEPT.2017.8046685},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9667831,
  author={Ishak, Md and Rahman, Raiyan and Mahmud, Tahasin},
  booktitle={2021 5th International Conference on Electrical Engineering and Information Communication Technology (ICEEICT)}, 
  title={Integrating Cloud Computing in E-healthcare: System Design, Implementation and Significance in Context of Developing Countries}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Cloud computing in the medical sector refers to the method of storing, maintaining, and processing electronic health records and relevant services on cloud servers that are accessible over the internet. The flexibility of cloud computing makes it a practical approach for enhancing the quality, dependability, and efficiency of medical services, as well as increasing patient-doctor interaction and safeguarding patient anonymity if proper measures are taken. Furthermore, cloud strategies facilitate healthcare technologies such as computerized healthcare records, remote appointments, mobile applications, patient portals, IoT devices, and big data analytics, enabling trouble-free scalable solutions. Integrating cloud computing technologies can especially be beneficial in increasing the efficiency of healthcare services in developing counties where physical health infrastructure is usually limited. As such, the objective of this work is to explore the feasibility of incorporating cloud and distributed computing in e-healthcare through an extensive requirement analysis and user study. Then, the smart healthcare system will be compared with traditional database-centric healthcare systems and a prototype system will be designed and implemented based on the findings. Finally, we focus on finding the usability and user acceptance of such systems and challenges that lie with integrating cloud services to e-healthcare systems for the general user demographic of developing countries through extensive usability evaluation.},
  keywords={},
  doi={10.1109/ICEEICT53905.2021.9667831},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{7335004,
  author={Dai, Yangyang and Lou, Yuansheng and Lu, Xin},
  booktitle={2015 7th International Conference on Intelligent Human-Machine Systems and Cybernetics}, 
  title={A Task Scheduling Algorithm Based on Genetic Algorithm and Ant Colony Optimization Algorithm with Multi-QoS Constraints in Cloud Computing}, 
  year={2015},
  volume={2},
  number={},
  pages={428-431},
  abstract={Task scheduling problem in cloud computing environment is NP-hard problem, which is difficult to obtain exact optimal solution and is suitable for using intelligent optimization algorithms to approximate the optimal solution. Meanwhile, quality of service (QoS) is an important indicator to measure the performance of task scheduling. In this paper, a novel task scheduling algorithm MQoS-GAAC with multi-QoS constraints is proposed, considering the time-consuming, expenditure, security and reliability in the scheduling process. The algorithm integrates ant colony optimization algorithm (ACO) with genetic algorithm (GA). To generate the initial pheromone efficiently for ACO, GA is invoked. With the designed fitness function, 4-dimensional QoS objectives are evaluated. Then, ACO is utilized to seek out the optimum resource. The experiment indicates that the proposed algorithm has preferable performance both in balancing resources and guaranteeing QoS.},
  keywords={},
  doi={10.1109/IHMSC.2015.186},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{6958835,
  author={Wen, Zi-Yi and Hsiao, Hsu-Feng},
  booktitle={2014 IEEE 16th International Workshop on Multimedia Signal Processing (MMSP)}, 
  title={QoE-driven performance analysis of cloud gaming services}, 
  year={2014},
  volume={},
  number={},
  pages={1-6},
  abstract={With the popularity of cloud computing services and the endorsement from the video game industry, cloud gaming services have emerged promisingly. In a cloud gaming service, the contents of games can be delivered to the clients through either video streaming or file streaming. Due to the strict constraint on the end-to-end latency for real-time interaction in a game, there are still challenges in designing a successful cloud gaming system, which needs to deliver satisfying quality of experience to the customers. In this paper, the methodology for subjective and objective evaluation as well as the analysis of cloud gaming services was developed. The methodology is based on a nonintrusive approach, and therefore, it can be used on different kinds of cloud gaming systems. There are challenges in such objective measurements of important QoS factors, due to the fact that most of the commercial cloud gaming systems are proprietary and closed. In addition, satisfactory QoE is one of the crucial ingredients in the success of cloud gaming services. By combining subjective and objective evaluation results, cloud gaming system developers can infer possible results of QoE levels based on the measured QoS factors. It can also be used in an expert system for choosing the list of games that customers can appreciate at a given environment, as well as for deciding the upper bound of the number of users in a system.},
  keywords={},
  doi={10.1109/MMSP.2014.6958835},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{7037229,
  author={Mazza, Daniela and Tarchi, Daniele and Corazza, Giovanni E.},
  booktitle={2014 IEEE Global Communications Conference}, 
  title={A user-satisfaction based offloading technique for smart city applications}, 
  year={2014},
  volume={},
  number={},
  pages={2783-2788},
  abstract={The Smart cities applications are gaining an increasing interest among administrations, citizens and technologists for their suitability in managing the everyday life. One of the major challenges is regarding the possibility of managing in an efficient way the presence of multiple applications in a Wireless Heterogeneous Network (HetNet) environment, alongside the presence of a Mobile Cloud Computing (MCC) infrastructure. In this context we propose a utility function model derived from the economic world aiming to measure the Quality of Service (QoS), in order to choose the best access point in a HetNet to offload part of an application on the MCC, aiming to save energy for the Smart Mobile Devices (SMDs) and to reduce computational time. We distinguish three different types of application, considering different offloading percentage of computation and analyzing how the cell association algorithm allows energy saving and shortens computation time. The results show that when the network is overloaded, the proposed utility function allows to respect the target values by achieving higher throughput values, and reducing the energy consumption and the computational time.},
  keywords={},
  doi={10.1109/GLOCOM.2014.7037229},
  ISSN={1930-529X},
  month={Dec},}@INPROCEEDINGS{9306518,
  author={Forcan, M. and Maksimović, M. and Forcan, J. and Jokić, S.},
  booktitle={2020 28th Telecommunications Forum (TELFOR)}, 
  title={5G and Cloudification to Enhance Real-Time Electricity Consumption Measuring in Smart Grid}, 
  year={2020},
  volume={},
  number={},
  pages={1-4},
  abstract={The number of smart devices in Smart Grid (SG) increases continuously and the presence of big data demands more efficient communication architectures. It is anticipated that the full potential of the SG vision in terms of better performances, reliability, and quality of service, can be achieved by incorporating the fifth generation of cellular network technology (5G) and Cloudification into the SG. In order to demonstrate their potential in SG, this paper presents the enhancement of real-time electricity consumption measuring with the help of 5G and Cloud computing. 5G-based communication model supporting Advanced Metering Infrastructure (AMI) in SG is built and validated on the example of real-time communication between the SM model and Cloud platform ThingSpeak.},
  keywords={},
  doi={10.1109/TELFOR51502.2020.9306518},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9004389,
  author={Anita, J. Mary and Raina, Roma},
  booktitle={2019 International Conference on Computational Intelligence and Knowledge Economy (ICCIKE)}, 
  title={Review on Smart Grid Communication Technologies}, 
  year={2019},
  volume={},
  number={},
  pages={215-220},
  abstract={Smart grid (SG) has given a better vision for electricity infrastructure. The quality, quantity of power transmitted and the usage of available data from smart sensing, metering and communication has dramatically increased with the introduction of smart grid to power systems. SG also has empowered customer participation by managing their load pattern to take advantage of choosing their supply and pricing options. The heart of the SG lies on the communication between the consumers and the grid operators. Grids operators need the real time customer meter data to schedule their supply and pricing policies and the consumers need the same to manage their loads. The Wireless Sensor Network (WSN) uses Aggregation Protocol with Error Detection (APED) to improve the security of data. The SG with SCADA is facilitated by data acquisitions which includes the meter reading, system conditions, etc. that are monitored and transmitted at regular intervals in real time. The security of data transfer is assured by the introduction of improvised Ciphertext Policy_ Attribute Based Encryption (CP-ABE) is used to achieve the security parameters like confidentiality, integrity, and availability in cloud computing. Block chain-based systems combine distributed register and cryptographic security measures. Introduction of block chain in SG has revolutionized the functioning of SG with smart contracts, and transaction of huge amount of data in a fully decentralized market platform.This paper reviews the modern technologies used in smart grid communication based on IEEE 802.15.4 standard to the SG and how it is modified to ensure effective, efficient and economical and secured communication of the huge real time data from the smart meters.},
  keywords={},
  doi={10.1109/ICCIKE47802.2019.9004389},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9292150,
  author={Gavra, Vlad-Dacian and Pop, Ovidiu Aurel},
  booktitle={2020 IEEE 26th International Symposium for Design and Technology in Electronic Packaging (SIITME)}, 
  title={Usage of ZigBee and LoRa wireless technologies in IoT systems}, 
  year={2020},
  volume={},
  number={},
  pages={221-224},
  abstract={IoT systems are based sensors and actuators to enable ubiquitous sensing to measure environment parameters from delicate ecologies and natural environments to urban environments. By connecting these sensors and actuators to a big network, like internet, an automatization can be performed, and repetitive actions can be done in background by the IoT ecosystem and save a lot of time. IoT can do such things in Home Automation, Smart Cities and even in Air Quality analysis. IoT solution are dependent on the way sensors are transmitting data to cloud or up to the internet. This paper will present the benefits of using Zig Bee instead of using traditional Wi-Fi sensor and present some of the characteristics of LoRa sensors. Cloud computing contributed to the expansion of the IoT systems by offloading local IoT devices of computation intensive tasks. Fog computing brings Cloud closer to the sensors and by doing this minimize communication latencies.},
  keywords={},
  doi={10.1109/SIITME50350.2020.9292150},
  ISSN={2642-7036},
  month={Oct},}@INPROCEEDINGS{7979932,
  author={Lin, Cho-Chin and Kuo, Yuan-Han and Xie, Dong-Ye and Goh, Wei-Ping and Wu, Shyi-Tsong},
  booktitle={2016 7th International Conference on Cloud Computing and Big Data (CCBD)}, 
  title={A Practical Model for Analyzing Push-Based Virtual Machine Live Migration}, 
  year={2016},
  volume={},
  number={},
  pages={347-352},
  abstract={Virtual Technology has been employed by cloud computing to satisfy service requests from the customers. Virtual machine live migration provides non-stop services while an unexpected event impacts the service quality of the host. The cost of performing live migration is measured by the total number of transferred pages and the service suspension time. In this paper, a practical model for analysing push-based live migration is proposed. The model abstracts live migration strategy into trend and sanction functions. Based on the model, the patterns on the numbers of transferred memory frames in the iterations have been analysed for various dirty frequencies and push rules. Furthermore, it is useful for developing a formal method for conducting complex analysis.},
  keywords={},
  doi={10.1109/CCBD.2016.074},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8892932,
  author={Tri, Nguyen Minh and Nagata, Syunya and Tsuru, Masato},
  booktitle={2019 20th Asia-Pacific Network Operations and Management Symposium (APNOMS)}, 
  title={Locating Delay Fluctuation-Prone Links by Packet Arrival Intervals in OpenFlow Networks}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={In cloud computing and content delivery networking, OpenFlow-based centrally managed networks to connect distributed servers are becoming popular these days. To maintain service quality and availability in such networks by flexible and dynamic traffic engineering, detecting and locating deteriorated (e.g., congested) links in an efficient manner is essential. Following our previous study that actively monitors packet loss rate to find deteriorated links, in this paper, we actively estimate packet delay variance on each link (note both up and down directions of each full-duplex link are distinguished) in an OpenFlow network. A notable feature is that packet delay variance is estimated based on monitoring arrival time intervals of probe packets without directly measuring packet delay time over a link. In the proposed scheme, a series of probe packets is launched from a measurement host and traverses each direction of each link once and only once by multicasting, while arrival time intervals of those packets at each input port of OpenFlow switches are monitored. Then the OpenFlow controller collects the arrival time interval statistics from those switches to locate delay fluctuation-prone links, i.e., links with a high packet delay variance, which are likely congested or physically unstable. In addition, to minimize the necessary number of accesses to switch ports, an appropriate order of collecting statistics from switches is dynamically controlled. The results of numerical simulation on large-scale network topologies demonstrate the effectiveness of our proposed scheme. A prototype implementation which requires an extension of OpenFlow is also presented on Mininet.},
  keywords={},
  doi={10.23919/APNOMS.2019.8892932},
  ISSN={2576-8565},
  month={Sep.},}@INPROCEEDINGS{8494151,
  author={Prathibha, K and Hegde, Pawan},
  booktitle={2018 9th International Conference on Computing, Communication and Networking Technologies (ICCCNT)}, 
  title={A Real-Time System for Environmental Study Based on Cloud Computing}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={Following the ecological parameters variation is important keeping in mind the end goal to decide on the nature of our environment. This paper aims at detecting and detailing the changes in the environmental parameters. Environmental monitoring applications based on cloud computing makes use of sensors to help in protecting environmental conditions by checking parameters like temperature, air quality, earthquake and so on. The utilization of present day advances such as the single-board computers can encourage and give much more functionalities to cloud. The significant areas that cover the above said applications are home, industries, buildings and so forth. This is the way toward observing some of the modules of environment and thus providing the features to the admins and clients. It causes the specialists to screen the states of the work in an organization or industry from remote areas and to take prompt measures.},
  keywords={},
  doi={10.1109/ICCCNT.2018.8494151},
  ISSN={},
  month={July},}@INPROCEEDINGS{8998716,
  author={Munadi, Rendy and Irawan, Arif Indra and Romiadi, Yuman Fariz},
  booktitle={2019 International Conference on Mechatronics, Robotics and Systems Engineering (MoRSE)}, 
  title={Security System ATM Machine with One-Time Passcode on M-Banking Application}, 
  year={2019},
  volume={},
  number={},
  pages={92-96},
  abstract={Automated Teller Machine (ATM) security system currently still uses magnetic cards and static PIN as its security system, which create many security holes. This security hole in many cases caused many bank customers to lose money mysteriously. In this paper a two-factor authentication system which uses ATM card and dynamic PIN is proposed to overcome this security hole. In this paper, a prototype of an ATM and m-banking application were built. The ATM prototype uses several components such as the Raspberry Pi 3B, smart card, smart card reader / writer, keypad number and LCD monitor. Dynamic PINs are generated using the CSPRNG-SHA1-MWC random number generator. In developing the prototypes, the framework used in this study is based on mobile applications and cloud computing. To evaluate the quality of the prototype, we performed qualitative and quantitative tests. Qualitatively we tested the prototype using a questionnaire using 165 sample respondents to provide an opinion about the safety and comfort of our prototype and quantitatively we measured the prototype to find out the level of randomness of the generated PIN and the QoS of the designed prototype.},
  keywords={},
  doi={10.1109/MoRSE48060.2019.8998716},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8976772,
  author={Rana, Prateek and Sharma, Monika},
  booktitle={2019 2nd International Conference on Power Energy, Environment and Intelligent Control (PEEIC)}, 
  title={Less Energy Consumption Framework for Fog Computing With IoT}, 
  year={2019},
  volume={},
  number={},
  pages={41-46},
  abstract={IOT applications nowadays have quickly expanded and the basic standard centralized models of cloud computing have faced numerous challenging situations which has excessiveness in latency; have low capacity and the failure of network, less capacity of storing and excessive use of power. Fog computing has brought the cloud nearer to the devices of IOT, which deals with the challenges. The services being provided by the fog have quicker response moreover more better quality, in comparison to the cloud. The choices which are best, allow the IOT to offer services which are efficient and secured for most of the users of IOT, that is being measured by the fog computing. In this paper, we are focusing on the fog computing furthermore the incorporation of fog computing with the IOT by specially focusing on the implementation of the challenges is being presented. We have proposed architecture for the less consumption of energy and power.},
  keywords={},
  doi={10.1109/PEEIC47157.2019.8976772},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9355356,
  author={Yang, Yi},
  booktitle={2020 International Conference on Advance in Ambient Computing and Intelligence (ICAACI)}, 
  title={Simulation Analysis of Standardized Management Measures of Enterprise Accounting Based on Cloud Computing}, 
  year={2020},
  volume={},
  number={},
  pages={143-146},
  abstract={In the current corporate governance, accounting management is an indispensable part, in which the quality of accounting directly affects the prosperity of enterprises. Accounting is a basic work in the related work of enterprise accounting, which is the accounting of economic activities of enterprises under the constraints of relevant laws and regulations, and is a summary of previous economic activities. Accounting, as a basic function and the core content of enterprise accounting work, has always been in a very important position. Accounting information feeds back the problems existing in the production and operation of enterprises, so that relevant personnel can continuously optimize their work, and ultimately enhance the competitiveness of products or services provided by enterprises in the market. This paper discusses the connotation and importance of enterprise accounting standardization management, analyzes the problems existing in the process of enterprise accounting standardization management, and puts forward specific measures of enterprise accounting standardization management based on cloud computing.},
  keywords={},
  doi={10.1109/ICAACI50733.2020.00036},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9602504,
  author={Li, Xu and Gao, Guanbin and Na, Jing and Chen, Xin},
  booktitle={2021 33rd Chinese Control and Decision Conference (CCDC)}, 
  title={Design of an Automatic T-beam Erection System Based on NB-IoT for Bridge-Erecting Cranes}, 
  year={2021},
  volume={},
  number={},
  pages={684-689},
  abstract={Bridge-erecting cranes are often used for beam erection in the construction of expressways. To improve the speed and quality of T-beam erection and ensure the safety of bridge-erecting cranes, an automatic T-beam erection system based on the Internet of Things (IoT) is designed in this paper. Narrow Band Internet of Things (NB-IoT) communication technology is used to integrate laser-ranging sensors, batteries, and communication modules into base station subsystems, which are installed in specific locations of the bridge-erecting crane. The position of the T-beam can be measured in real-time by the laser ranging sensors, with which a closed-loop control system is constructed for the T-beam erection system. The information of the running state including the position of the T-beam, the installation progress, and the position of the bridge-erecting crane is transferred to the cloud computing platform by NB-IoT, which can be viewed by mobile terminals. The experimental tests show that the distance measurement range of the system is 0.045m~30m, and the measurement accuracy is 2mm. Compared with the manual operation, the automatic T-beam erection system can reduce the risk of the T-beam erection and improve efficiency.},
  keywords={},
  doi={10.1109/CCDC52312.2021.9602504},
  ISSN={1948-9447},
  month={May},}@INPROCEEDINGS{9556059,
  author={Jin, Xuan and Xie, Yunlong and Yin, Yitao},
  booktitle={2021 13th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC)}, 
  title={BotCatcher:A Complementary Advantages and Deep Learning Based Scheme for Intrusion Detection}, 
  year={2021},
  volume={},
  number={},
  pages={95-98},
  abstract={In today’s society, computer network is one of the most important and advanced infrastructures. The emerging technologies, represented by cloud computing, have brought many new situations and challenges to network security. This paper presents a novel scheme, called BotCatcher, which is based on the fusion and optimization of two different types of existing methods for intrusion detection. There are two models in the scheme: 1) The high-speed mode based on complementary advantages improves the F-Measure by about 0.06 without reducing the detection rate and 2) The high-quality mode based on deep learning combines the historical behavior of hosts and optimizes the detection index for greater performance improvement.},
  keywords={},
  doi={10.1109/IHMSC52134.2021.00030},
  ISSN={},
  month={Aug},}@ARTICLE{9129768,
  author={Azizi, Sadoon and Shojafar, Mohammad and Abawajy, Jemal and Buyya, Rajkumar},
  journal={IEEE Systems Journal}, 
  title={GRVMP: A Greedy Randomized Algorithm for Virtual Machine Placement in Cloud Data Centers}, 
  year={2021},
  volume={15},
  number={2},
  pages={2571-2582},
  abstract={Cloud computing efficiency greatly depends on the efficiency of the virtual machines (VMs) placement strategy used. However, VM placement has remained one of the major challenging issues in cloud computing mainly because of the heterogeneity in both virtual and physical machines (PMs), the multidimensionality of the resources, and the increasing scale of the cloud data centers (CDCs). An inefficiency in VM placement strategy has a significant influence on the quality of service provided, the amount of energy consumed, and the running costs of the CDCs. To address these issues, in this article, we propose a greedy randomized VM placement (GRVMP) algorithm in a large-scale CDC with heterogeneous and multidimensional resources. GRVMP inspires the “power of two choices” model and places VMs on the more power-efficient PMs to jointly optimize CDC energy usage and resource utilization. The performance of GRVMP is evaluated using synthetic and real-world production scenarios (Amazon EC2) with several performance matrices. The results of the experiment confirm that GRVMP jointly optimizes power usage and the overall wastage of resource utilization. The results also show that GRVMP significantly outperforms the baseline schemes in terms of the performance metrics used.},
  keywords={},
  doi={10.1109/JSYST.2020.3002721},
  ISSN={1937-9234},
  month={June},}@INPROCEEDINGS{6903503,
  author={Lim, Erbin and Thiran, Philippe},
  booktitle={2014 IEEE International Conference on Cloud Engineering}, 
  title={Communication of Technical QoS among Cloud Brokers}, 
  year={2014},
  volume={},
  number={},
  pages={403-409},
  abstract={Service brokers are commonly used in the cloud computing paradigm to represent service requesters to select a service provider. They act as an intermediary between the two parties. One model of the cloud computing paradigm involves 3 layers, the user, the SaaS provider and the Cloud provider. The selection of service requesters is challenging due to the different levels of Quality of Service that each service provider can provide. In this paper we propose a unique mechanism that allows communication between service brokers in different layers in order to further improve this selection. In addition, we introduce a metric, efficiency, which service brokers can use to deterministically compare service providers with each other.},
  keywords={},
  doi={10.1109/IC2E.2014.92},
  ISSN={},
  month={March},}@INPROCEEDINGS{6927759,
  author={Sang-Ho Na and Eui-Nam Huh},
  booktitle={Fourth edition of the International Conference on the Innovative Computing Technology (INTECH 2014)}, 
  title={A methodology of assessing security risk of cloud computing in user perspective for security-service-level agreements}, 
  year={2014},
  volume={},
  number={},
  pages={87-92},
  abstract={underlying cloud computing feature, outsourcing of resources, makes the Service Level Agreement (SLA) is a critical factor for Quality of Service (QoS), and many researchers have addressed the question of how a SLA can be evaluated. Lately, security-SLAs have also received much attention with the Security-as-a-Service mode in cloud computing. The quantitative measurement of security metrics is a considerably difficult problem and might be considered the multi-dimensional aspects of security threats and user requirements. To address these issues, we provide a novel a methodology of security risk assessment for security-service-level agreements in the cloud service based on a multi-dimensional approach depending on services type, probabilities of threats, and network environments to reach a security-SLA evaluation.},
  keywords={},
  doi={10.1109/INTECH.2014.6927759},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9537262,
  author={Reddy, Gangireddy Narendra Kumar and Manikandan, M. Sabarimalai and Murty, N. V. L. Narasimha},
  booktitle={2021 IEEE International Conference on Health, Instrumentation & Measurement, and Natural Sciences (InHeNce)}, 
  title={Lightweight Compressed Sensing (CS) and Partial DCT Based Compression Schemes for Energy-Efficient Wearable PPG Monitoring Devices}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Most wearable medical devices are designed to continuously acquire photoplethysmography (PPG) for measuring vital signs and transmitting acquired PPG data wirelessly to edge-computing device or cloud-computing server. These devices are constrained with limited battery power and data-rate capacity. Therefore, in this paper, we present a lightweight effective data-reduction method by investigating the performance of compressed sensing (CS)-based and and partial discrete cosine transform (DCT)-based compression methods with major objectives of achieving higher compression ratio (CR) with minimal waveform distortion with low reconstruction time. By using both normal and abnormal PPG signals, the performance of the CS-based and DCT-based compression methods is evaluated in terms of CR, global and local distortion measures and processing time. Evaluation results showed that CR values of the partial-DCT based method are 3 times higher (CR ranging from 7.50 to 9.38) without distorting fiducial points and shapes of the PPG signal (percentage root-mean-square difference (PRD) ranging from 1% to 2%) as compared to the CS-based data method (CR from 2.50 to 3.13 for PRD from 2% of 4%). The higher data reduction with acceptable level of reconstruction quality demonstrates that the partial DCT-based method can lead to provide better overall energy consumption reduction solution for resource-constrained wearable devices.},
  keywords={},
  doi={10.1109/InHeNce52833.2021.9537262},
  ISSN={},
  month={July},}@ARTICLE{7226862,
  author={Peng, Kuan-Li and Huang, Chin-Yu},
  journal={IEEE Transactions on Services Computing}, 
  title={Reliability Analysis of On-Demand Service-Based Software Systems Considering Failure Dependencies}, 
  year={2017},
  volume={10},
  number={3},
  pages={423-435},
  abstract={Service-based software systems (SBSSs) are widely deployed due to the growing trend of distributed computing and cloud computing. It is important to ensure high quality of an SBSS, especially in a strongly competitive market. Existing works on SBSS reliability usually assumed independence of service failures. However, the fact that resource sharing exists in different levels of SBSS operations invalidates this assumption. Ignorance of failure dependencies have been discussed as potentially affecting system reliability predictions and lowering the benefits of design diversity, as typically seen in high-reliability systems. In this paper, we propose a reliability framework that incorporates failure dependence modeling, system reliability modeling, as well as reliability analysis for individual services and for failure sources. The framework is also capable of analyzing the internal structures of popular software fault tolerant (FT) schemes. The proposed method is applied to a travel agency system based upon a real-world practice for verifying its accuracy of reliability modeling and effectiveness of varied reliability measures. The results show that failure dependence of the services is an essential factor for analyzing any valuable SBSS system. Further, a set of reliability measures with different capabilities and complexities are available for assisting SBSS engineers with system improvements.},
  keywords={},
  doi={10.1109/TSC.2015.2473843},
  ISSN={1939-1374},
  month={May},}@INPROCEEDINGS{9210369,
  author={Rico-Bautista, Dewar and Maestre-Gongora, Gina and Guerrero, Cesar D.},
  booktitle={2020 Fourth World Conference on Smart Trends in Systems, Security and Sustainability (WorldS4)}, 
  title={Smart University:IoT adoption model}, 
  year={2020},
  volume={},
  number={},
  pages={821-826},
  abstract={Higher education organizations see in new technologies an opportunity to improve the quality of their academic and administrative processes. However, the existence and application of new technologies in this type of institutions does not imply that it really has the expected impact on their processes, so many adoption initiatives fail generating losses and discouragement towards change. This happens mainly because more work is done on technology than on the realities of the institutions. One way to prevent this type of problem and redirect efforts is to align the adoption process itself. As artificial intelligence, cloud computing, IoT (Internet of Things) and Big Data technologies become stronger, it is necessary to have tools at hand that have the capacity to measure the level of adoption by institutions. The objective of measuring adoption by the processes and realities of higher education institutions, with a focus on their users. Many models have been proposed to understand why users accept or use technologies. Among those that have emerged for the study of technology adoption are TAM, UTAUT, UTAUT2, DOI, TPB, TRA, among others. This characterization allows us to conclude about the need for alignment and integration of technology with the organization's processes, calling for greater interaction with senior management.},
  keywords={},
  doi={10.1109/WorldS450073.2020.9210369},
  ISSN={},
  month={July},}@INPROCEEDINGS{8711239,
  author={Navamani, Beaulah A and Yue, Chuan and Zhou, Xiaobo},
  booktitle={2018 IEEE 37th International Performance Computing and Communications Conference (IPCCC)}, 
  title={Discover and Secure (DaS): An Automated Virtual Machine Security Management Framework}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={Cloud computing is very appealing for its convenient central management, the elasticity of resource provisioning and its economic benefits. Undoubtedly, the non-transparent nature of the Cloud infrastructure introduces significant security concerns. Naively, Virtual Machine (VM) migration can weaken or even nullify the security protection on a VM. Attackers compromise such vulnerable hosts and can either take control over their resources or use them as a channel for future attacks. To overcome the hidden security risk, this paper proposes Discover and Secure (DaS) framework for automated VM security management. This framework accomplishes two qualities: 1) to discover whether the VM is an inadvertent security victim 2) to secure the VM and the mission-critical applications running inside them. Modules in this framework detect, extract and measures the new identifiers assigned to the VM. Comparing the new identifiers to the reference table containing the old measured identifier values, verifies the identifier/s status. Transformed identifiers are perceived and replaced with new valid ones, hence, restoring the nullified security. This framework is implemented as VM-Internal security, self-supplied by the user and VM-introspection security, host-supplied by the cloud provider. Experimental results show that DaS framework can armor the VM from obscured security problems and seal the hidden door against attackers.},
  keywords={},
  doi={10.1109/PCCC.2018.8711239},
  ISSN={2374-9628},
  month={Nov},}@INPROCEEDINGS{9732730,
  author={Shrivastava, Ritu and Tiwary, Abhigyan and Yadav, Pranay},
  booktitle={2021 International Conference on Advances in Technology, Management & Education (ICATME)}, 
  title={Challenges Block Chain Technology Using IOT for Improving Personal and Physical Safety - Review}, 
  year={2021},
  volume={},
  number={},
  pages={238-243},
  abstract={Web of Things (IoT) is an interconnection of clever actual articles called things and People. IoT permits each “Thing” to associate and impart in this manner creating and sending a colossal measure of Data like a monster Information System. Because of the immense measure of Data dealing with by IoT gadgets it got fundamental to incorporate Cloud Computing, Machine Learning and Information Modelling into The IoT stage. The enormous development in the field of IoT is causing increment in Information and Communication Technology (ICT) business too. It is anticipated that before the finish of 2020 95% of the new items will have IoT as its canter. As can be seen there will be an expanding presence of IoT objects and thus their perceivability from the Internet and lawful admittance to assets is a subject of grave concern. IoT gives and empowers the formation of creative applications that improved the physical and individual existence of an individual, yet the absence of security and weakness of individuals may prompt basic issues like the wellbeing of our homes might be undermined, and Centralized organizations utilizing delicate information are consistently at a danger hacking. Block-chain innovation is increasing a ton of consideration from different associations and parcel of examination is being done as it gives extraordinary answers for the issues related with the traditional incorporated design of IoT. Since, there are so numerous IoT gadgets which are on the lookout for the upgrade of an individual's physical, mental development and improving the personal satisfaction by and large, a conveyed trust innovation, guaranteeing versatility, security, and unwavering quality, is the need of great importance for the development of IoT conditions. The joining of IoT and BC represents a ton of difficulties. The Objective of this exploration paper is to build up an incorporated IOT and Block-chain Application Environment to upgrade the individual and Physical existence of a being. Consequently, our center will be to build up a safe and safe climate for a Smart home. Our proposed design depends on progressive structure and disseminated foundation of Block-chain to keep up security and protection and make it appropriate for explicit prerequisites of IoT. Subsequently we have coordinated the mechanization of the home alongside the actual soundness of an individual in this manner guaranteeing wellbeing, accommodation and strength of an individual.},
  keywords={},
  doi={10.1109/ICATME50232.2021.9732730},
  ISSN={},
  month={Jan},}@ARTICLE{9153148,
  author={Abdel-Basset, Mohamed and El-Shahat, Doaa and Elhoseny, Mohamed and Song, Houbing},
  journal={IEEE Internet of Things Journal}, 
  title={Energy-Aware Metaheuristic Algorithm for Industrial-Internet-of-Things Task Scheduling Problems in Fog Computing Applications}, 
  year={2021},
  volume={8},
  number={16},
  pages={12638-12649},
  abstract={In Industrial-Internet-of-Things (IIoT) applications, fog computing (FC) has soared as a means to improve the Quality of Services (QoSs) provided to users through cloud computing, which has become overwhelmed by the massive flow of data. Transmitting all these amounts of data to the cloud and coming back with a response can cause high latency and requires high network bandwidth. The availability of sustainable energy sources for FC servers is one of the difficulties that the service providers can face in IIoT applications. The most important factor contributing to energy consumption on fog servers is task scheduling. In this article, we suggest an energy-aware metaheuristic algorithm based on a Harris Hawks optimization algorithm based on a local search strategy (HHOLS) for task scheduling in FC (TSFC) to improve the QoSs provided to the users in IIoT applications. First, we describe the high virtualized layered FC model taking into account its heterogeneous architecture. The normalization and scaling phase aids the standard Harris hawks algorithm to solve the TSFC, which is discrete. Moreover, the swap mutation ameliorates the quality of the solutions due to its ability to balance the workloads among all virtual machines. For further improvements, a local search strategy is integrated with HHOLS. We compare HHOLS with other metaheuristics using various performance metrics, such as energy consumption, makespan, cost, flow time, and emission rate of carbon dioxide. The proposed algorithm gives superior results in comparison with other algorithms.},
  keywords={},
  doi={10.1109/JIOT.2020.3012617},
  ISSN={2327-4662},
  month={Aug},}@INPROCEEDINGS{7063421,
  author={Ran, Yongyi and Shi, Youkang and Yang, Enzhong and Chen, Shuangwu and Yang, Jian},
  booktitle={2014 IEEE Globecom Workshops (GC Wkshps)}, 
  title={Dynamic resource allocation for video transcoding with QoS guaranteeing in cloud-based DASH system}, 
  year={2014},
  volume={},
  number={},
  pages={144-149},
  abstract={Due to diverse network conditions and heterogeneous devices, there may be various video demands with different video qualities and formats from the client side. Compared to keeping all necessary copies for the same video, video transcoding in real-time should be an essential solution. The complex nature of video transcoding enables cloud computing to be uniquely suitable for dynamically providing transcoding resource. However, due to the fluctuation and uncertainty of the future transcoding demand, it is still a challenge to dynamically determine the optimal resource allocation to save cost while guaranteeing the Quality of Service (QoS). Overload may result in the transcoding jitter and increase the lateness which directly affects video freezes while over-provisioning naturally increases the cost. To address this problem, in this paper, by defining the transcoding jitter probability as a metric of QoS, we proposed a dynamic resource allocation algorithm based on the large deviation principle, which is capable of proactive calculating the optimal number of transcoding nodes for the upcoming transcoding demand subject to the transcoding jitter probability below a desired threshold. Finally, the experiments are performed on a cloud-based prototype system to show the attainable performance of the proposed resource allocation algorithm and verify that the proposed algorithm can make a good tradeoff between cost saving and QoS guaranteeing.},
  keywords={},
  doi={10.1109/GLOCOMW.2014.7063421},
  ISSN={2166-0077},
  month={Dec},}@INPROCEEDINGS{7027516,
  author={Keller, Matthias and Robbert, Christoph and Karl, Holger},
  booktitle={2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing}, 
  title={Template Embedding: Using Application Architecture to Allocate Resources in Distributed Clouds}, 
  year={2014},
  volume={},
  number={},
  pages={387-395},
  abstract={In distributed cloud computing, application deployment across multiple sites can improve quality of service. Recent research developed algorithms to find optimal locations for virtual machines. However, those algorithms assume to have either single-tier applications or a fixed number of virtual machines -- a strong simplification of reality. This paper investigates the placement and scaling of complex application architectures. An application is dynamically scaled to fit both the current demand situation and the currently available infrastructure resources. We compare two approaches: The first one is based on virtual network embedding. The second approach is a novel method called Template Embedding. It is based on a hierarchical 1-allocation hub flow problem and combines application scaling and embedding in one step. Extensive experiments on 43200 network configurations showed that Template Embedding outperforms virtual network embedding in all cases in three metrics: success rate, solution quality, and runtime. This positive result shows that template embedding is a promising approach for distributed cloud resource allocation.},
  keywords={},
  doi={10.1109/UCC.2014.49},
  ISSN={},
  month={Dec},}@ARTICLE{9395576,
  author={Cedillo, Priscila and Insfran, Emilio and Abrahão, Silvia and Vanderdonckt, Jean},
  journal={IEEE Access}, 
  title={Empirical Evaluation of a Method for Monitoring Cloud Services Based on Models at Runtime}, 
  year={2021},
  volume={9},
  number={},
  pages={55898-55919},
  abstract={Cloud computing is being adopted by commercial and governmental organizations driven by the need to reduce the operational cost of their information technology resources and search for a scalable and flexible way to provide and release their software services. In this computing model, the Quality of Services (QoS) is agreed between service providers and their customers through Service Level Agreements (SLA). There is thus a need for systematic approaches with which to assess the quality of cloud services and their compliance with the SLA. In previous work, we introduced a generic method for Monitoring cloud Services using models at RunTime (MoS@RT), which allows the monitoring requirements or the metric operationalizations of these requirements to be changed at runtime without the modification of the underlying infrastructure. In this paper, we present the design of a monitoring infrastructure that supports the proposed method with its instantiation to a specific platform and reports the results of an experiment carried out to evaluate the perceived efficacy of 58 undergraduate students when using the infrastructure to configure the monitoring of cloud services deployed on the Microsoft Azure platform. The results show that the participants perceived MoS@RT to be easy to use, useful, and they also expressed their intention to use the method in the future. Although further experiments must be carried out to strengthen these results, MoS@RT has proved to be a promising monitoring method for cloud services.},
  keywords={},
  doi={10.1109/ACCESS.2021.3071417},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9242580,
  author={Albur, Nageshwar and Handigol, Sonal and Naik, Sonali and Mulla, Mohammed Moin and Narayan, D. G.},
  booktitle={2020 12th International Conference on Computational Intelligence and Communication Networks (CICN)}, 
  title={QoS-aware Flow Management in Software Defined Network}, 
  year={2020},
  volume={},
  number={},
  pages={215-220},
  abstract={Software Defined Networking is a developing pattern in a computer network that authorize a controller to control and keep track of the entire network state of a system. Traditional networks are not compatible for business ventures since they are manually configured (static) and are inflexible. To solve the problems related to traditional network framework, SDN is considered as an effective solution because SDN is dynamic and easily manageable. Quality-of-Service (QoS) is a list of network requirements that is mentioned in Service Level Agreement (SLA) and this requirements has to be satisfied when a packet is being streamed from one node to another node in a network. QoS metrics provide a sophisticated way to prioritise the network traffic over a network to guarantee better performance. QoS assures that the priorities of routing does not change because change-in prioritise may lead to jitter, packet loss and delay. With rapid development in the cloud computing environment for hosting various virtual applications, Quality Of Service (QoS) has to be maintained while delivering the services that were specified in the Software Level Agreement (SLA). Network Traffic Management helps the administrator to reduce the congestion, packet loss, latency, and also ensures smooth network operations with the help of traffic monitoring tools and techniques. The proposed work presents the QoS aware routing using the OpenDayLight controller. To implement the routing algorithm the bandwidth and the delay parameters are considered. These help to manage the resources of the network by prioritizing specific types of packets on the network. Packet switching not only forwards the data packets but also focuses on selecting the optimal path available for routing of these packets based on certain parameters.},
  keywords={},
  doi={10.1109/CICN49253.2020.9242580},
  ISSN={2472-7555},
  month={Sep.},}@INPROCEEDINGS{9284567,
  author={Zhang, Yilei and Zhang, Xiao and Zhang, Peiyun and Luo, Jun},
  booktitle={2020 IEEE International Conference on Services Computing (SCC)}, 
  title={Credible and Online QoS Prediction for Services in Unreliable Cloud Environment}, 
  year={2020},
  volume={},
  number={},
  pages={272-279},
  abstract={With the widespread adoption of cloud computing, Service-Orientated Architecture (SOA) facilitates the deployment of large-scale online applications in many key areas where quality and reliability are critical. In order to ensure the performance of cloud applications, Quality of Service (QoS) is widely used as a key metric to enable QoS-driven service selection, composition, adaption, etc. Since QoS data observed by users is sparse due to technical constraints, previous studies have proposed prediction approaches to solve this problem. However, the dynamic nature of the cloud environment requires timely prediction of time-varying QoS values. In addition, unreliable QoS data from untrustworthy users may significantly affect the prediction accuracy. In this paper, we propose a credible online QoS prediction approach to address these challenges. We evaluate user credibility through a reputation mechanism and employ online learning techniques to provide QoS prediction results at runtime. The proposed approach is evaluated on a large-scale real-world QoS dataset, and the experimental results demonstrate its effectiveness and efficiency in unreliable cloud environment.},
  keywords={},
  doi={10.1109/SCC49832.2020.00043},
  ISSN={2474-2473},
  month={Nov},}@INPROCEEDINGS{7761131,
  author={O'Donncha, Fearghal and Venugopal, Srikumar and James, Scott C. and Ragnoli, Emanuele},
  booktitle={OCEANS 2016 MTS/IEEE Monterey}, 
  title={Deploying and optimizing performance of a 3D hydrodynamic model on cloud}, 
  year={2016},
  volume={},
  number={},
  pages={1-7},
  abstract={Container-based cloud computing, as standardised and popularised by the open-source docker project has many potential opportunities for scientific application in highperformance computing. It promises highly flexible and available compute capabilities via cloud, without the resource overheads of traditional virtual machines. Further, productivity gains can be made by easy repackaging of images with additional developments, automated deployments, and version-control integrations. Nevertheless, the impact of container overhead and overlay network implementation and performance are areas that requires detailed study to allow for well-defined quality of service for typical HPC applications. This papers presents details on deploying the Environmental Fluid Dynamics Code (EFDC) on a container-based cloud environment. Results are compared to a bare metal deployment. Application-specific benchmarking tests are complemented by detailed network tests that evaluate isolated MPI communication protocols both at intra-node and inter-node level with varying degrees of self-contention. Cloud-based simulations report significant performance loss in mean run-times. A containerised environment increases simulation time by up to 50%. More detailed analysis demonstrates that much of this performance penalty is a result of large variance in MPI communciation times. This manifests as simulation runtime variance on container cloud that hinders both simulation run-time and collection of well-defined quality-of-service metrics.},
  keywords={},
  doi={10.1109/OCEANS.2016.7761131},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8390400,
  author={Silva, Helber and Barbalho, Felipe and Neto, Augusto},
  booktitle={2018 International Conference on Computing, Networking and Communications (ICNC)}, 
  title={Cross-layer Multiuser Session Control for Improved SDN Cloud Communications}, 
  year={2018},
  volume={},
  number={},
  pages={377-382},
  abstract={The integration of Cloud Computing and Internet of Things (IoT) is foreseen as an enabler to suit a plethora of novel latency critical applications (e.g, e-health, intelligent transportation, safety, energy, smart cities, and many others). These applications require multimedia (mainly video) flows to be handled by the underlying network in an efficient and scalable way, as they expect to consume a massive data produced by billions of things. In view of this, we propose a dynamic multiuser session control plane which leverages 5G's support of Software-Defined Networking (SDN) substrate to advance beyond todays limited, per-flow IP-based communication systems. We handle such limitations by proposing CLASSICO, a Cross-LAyer Sdn SessIon COntrol architecture that exploits SDN to offload the flow streaming computation operations from the IoT cloud platform to the network edge, affording high timeliness and scalability for the IoT-cloudified system. CLASSICO dynamically builds Application Layer multiuser data sessions and maps them into enhanced group-enabled data paths featuring SDN replication at branching nodes. We applied our solution to multimedia-alike use case, and results show that CLASSICO outperforms typical SDN-enabled IoT systems in terms to Quality of Service (QoS) and Quality of Experience (QoE) video metrics.},
  keywords={},
  doi={10.1109/ICCNC.2018.8390400},
  ISSN={},
  month={March},}@INPROCEEDINGS{7847681,
  author={Pendlebury, John and Emeakaroha, Vincent C. and O'Shea, David and Cafferkey, Neil and Morrison, John P. and Lynn, Theo},
  booktitle={2016 2nd International Conference on Cloud Computing Technologies and Applications (CloudTech)}, 
  title={SOMBA - automated anomaly detection for Cloud quality of service}, 
  year={2016},
  volume={},
  number={},
  pages={71-79},
  abstract={Cloud computing has transformed the standard model of service provisioning, allowing the delivery of on-demand services over the Internet. With its inherent requirements for elastic scalability and a pay-as-you-go pricing model, an additional level of complexity is added to its Quality of Service (QoS) management. This has made service provisioning more prone to performance anomalies due to the large-scale and evolving nature of Clouds. Existing methods for anomaly detection based on QoS monitoring in the Cloud rely on probabilistic methods, which are not computationally easy and are often valid for very short times before system dynamics change. We posit that more minimalistic approaches including automated techniques are needed for effective anomaly detection to support QoS enforcement in Clouds. In this paper, we present an automated anomaly detection scheme that recognises and adapts to changes in Clouds for efficient multi-metric performance anomaly detection to guarantee service quality. It includes a monitoring tool for collating performance data in real time for analysis and an anomaly detection technique based on an unsupervised machine learning strategy. Based on a Cloud service provisioning use case scenario, we evaluate our anomaly detection technique and compare it against two statistical anomaly detection approaches to demonstrate its efficiency.},
  keywords={},
  doi={10.1109/CloudTech.2016.7847681},
  ISSN={},
  month={May},}@INPROCEEDINGS{9454002,
  author={Estrela, Vania V. and Andreopoulos, Nikolaos and Sroufer, Robert and de Jesus, Maria A. and Mamani, Wilma Dora Huacasi and Peixoto, Aruquia},
  booktitle={2021 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Transmedia Ecosystems, Quality of Experience and Quality of Service in Fog Computing for Comfortable Learning}, 
  year={2021},
  volume={},
  number={},
  pages={1003-1009},
  abstract={This paper looks at the concepts of Quality of Service (QoS) and Quality of Experience (QoE) for the valuation of Transmedia Ecosystems (TEs) services in fog networking. Fog computing (FC) has delivered new services that cloud computing (CC) cannot make available, particularly those calling for QoE warranties. The suggested model is advantageous in an FC that comprises cloud-like services to sustain users with low latency response necessities. This TE model for QoE/QoS relies on objective and subjective QoE metrics. These assessment mechanisms will capture evidence automatically employing agent technology with user feedback. This proposed structure observes, investigates, yields reports and policy alterations without administrators' intervention.},
  keywords={},
  doi={10.1109/EDUCON46332.2021.9454002},
  ISSN={2165-9567},
  month={April},}@ARTICLE{7018938,
  author={Lu, Yao and Liu, Yao and Dey, Sujit},
  journal={IEEE Journal of Selected Topics in Signal Processing}, 
  title={Cloud Mobile 3D Display Gaming User Experience Modeling and Optimization by Asymmetric Graphics Rendering}, 
  year={2015},
  volume={9},
  number={3},
  pages={517-532},
  abstract={With the arrival of auto-stereoscopic 3D displays for mobile devices, and emergence of more 3D content, there is much anticipation for 3D mobile multimedia experiences, including 3D display gaming. Simultaneously, with the emergence of cloud computing, more mobile applications are being developed to take advantage of the elastic cloud resources. In this paper, we explore the possibility of developing Cloud Mobile 3D Display Gaming, where the 3D video rendering and encoding is performed on cloud servers, with the resulting 3D video streamed over wireless networks to mobile devices with 3D displays for a true 3D mobile gaming experience. However, with the significantly higher bitrate requirement for 3D video, ensuring user experience may be a challenge, both in terms of 3D video quality and network delay (response time), considering the bandwidth constraints and fluctuations of wireless networks. In this paper, we propose a new asymmetric graphics rendering approach which can significantly reduce the video encoding bitrate needed for a certain video quality, thereby making it easier to transmit the video over wireless network. However, since asymmetric graphics rendering may also impair the graphics quality, we need to be able to understand and measure its impact. We conduct subjective tests to study and model the impairments due to asymmetric graphics rendering and network delay, thereby developing a user experience model for cloud based mobile 3D display gaming. By conducting subsequent subjective tests, we prove the correctness of the impairment functions and the resulting user experience model. Furthermore, given any network condition, we propose to solve the problem of selecting the optimal graphics rendering factors for the left and right views so as to maximize user experience of cloud mobile 3D display gaming. In order to solve this problem, we first develop a model to estimate the resulting video bitrate of the rendered 3D video when certain graphics rendering factors are used. Next, we derive a model to predict the delay given the available network bandwidth and the video bitrate of the rendered 3D video. We use the above two models together with a branch and bound algorithm to solve the optimization problem and determine the optimal values for the left and right view rendering factors. Experiments conducted using real 4G-LTE network profiles on commercial cloud service demonstrate the feasibility of significant improvement in user experience when the proposed optimization algorithm is used to dynamically select optimal rendering factors according to changing network conditions.},
  keywords={},
  doi={10.1109/JSTSP.2015.2396475},
  ISSN={1941-0484},
  month={April},}@INPROCEEDINGS{8230340,
  author={Laghari, Asif Ali and He, Hui and Shafiq, Muhammad and Khan, Asiya},
  booktitle={2017 IEEE 9th International Conference on Communication Software and Networks (ICCSN)}, 
  title={Impact of storage of mobile on quality of experience (QoE) at user level accessing cloud}, 
  year={2017},
  volume={},
  number={},
  pages={1402-1409},
  abstract={Quality of Experience (QoE) is referred as level of user's satisfaction, enjoyment, learning and evaluation about the services or products. Recently quality of experience is used for improvement in product development life cycle after getting feedback from end users and service providers also use QoE to measure quality of services (QoS) of their services. Cloud computing provides services such as storage, web hosting, operating system environment, application development platform and CPU resources pay per use. End users are accessing cloud services via mobile apps, but enormous amount of temporary/cache data is generated by apps, so internal storage of mobile devices are filled quickly. Mobile device without any space in internal storage has huge impact on the performance when accessing the cloud services, which degrade the QoE of end users for particular cloud app and services. This paper presents the results of experiments conducted using two mobile devices HTC and Samsung to analyze the impact on end user's QoE during accessing cloud, when internal storage of HTC mobile device is filled and Samsung having 10 GB free space. Finally, on the basis of experimental results future changes in cloud apps are suggested for service provider to improve end user's QoE.},
  keywords={},
  doi={10.1109/ICCSN.2017.8230340},
  ISSN={2472-8489},
  month={May},}@INPROCEEDINGS{9415574,
  author={Younis, Ayman and Qiu, Brian and Pompili, Dario},
  booktitle={2021 16th Annual Conference on Wireless On-demand Network Systems and Services Conference (WONS)}, 
  title={QLRan: Latency-Quality Tradeoffs and Task Offloading in Multi-node Next Generation RANs}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  abstract={Next-Generation Radio Access Network (NG-RAN) is an emerging paradigm that provides flexible distribution of cloud computing and radio capabilities at the edge of the wireless Radio Access Points (RAPs). Computation at the edge bridges the gap for roaming end users, enabling access to rich services and applications. In this paper, we propose a multi-edge node task offloading system, i.e., QLRan, a novel optimization solution for latency and quality tradeoff task allocation in NG-RANs. Considering constraints on service latency, quality loss, and edge capacity, the problem of joint task offloading, latency, and Quality Loss of Result (QLR) is formulated in order to minimize the User Equipment (UEs) task offloading utility, which is measured by a weighted sum of reductions in task completion time and QLR cost. The QLRan optimization problem is proved as a Mixed Integer Nonlinear Program (MINLP) problem, which is a NP-hard problem. To efficiently solve the QLRan optimization problem, we utilize Linear Programming (LP)-based approach that can be later solved by using convex optimization techniques. Additionally, a programmable NG-RAN testbed is presented where the Central Unit (CU), Distributed Unit (DU), and UE are virtualized using the OpenAirInterface (OAI) software platform to characterize the performance in terms of data input, memory usage, and average processing time with respect to QLR levels. Simulation results show that our algorithm performs significantly improves the network latency over different conflgurations.},
  keywords={},
  doi={10.23919/WONS51326.2021.9415574},
  ISSN={},
  month={March},}@INPROCEEDINGS{8545546,
  author={Štofová, Lenka and Szaryszova, Petra and Bosák, Martin and Tarča, Alexander and Hajduová, Zuzana},
  booktitle={2018 XIV International Scientific-Technical Conference on Actual Problems of Electronics Instrument Engineering (APEIE)}, 
  title={Ambient Intelligence for Increasing Innovation Performance of Enterprises}, 
  year={2018},
  volume={},
  number={},
  pages={452-458},
  abstract={The new development of the changing global environment brings to the attention of ideas in the form of trends that show the future environment very differently from the current state. Technical experts are discussing the growing presence of internet of things and technologies, the involvement of all devices, and the prediction of how to create ambient intelligence. This type of intelligence refers to an electronic environment that is sensitive and responsive to the presence of users. Within these ambient systems, we can identify what the user needs and at the same time obtain it without asking for it. Ambient intelligence is a combination of neural networking, smart technologies, cloud computing, big data, websites, bearers, and user interface to services that can automate processes and make recommendations to improve the quality of users' lives. On a wider scale, there are modern high-tech possibilities to closely monitor the impact on the quality and safety of the current market environment by ambient intelligence and sensory management solutions. The aim of the paper is to highlight the selected trends of ambient intelligence system applications as an innovative paradigm to support smart innovation that will further enhance the quality of the automotive industry's technological solution in Slovak republic with advancing developments inspired by other successful companies' results acting in this sector. The reliability of their most important measures were obtained by correlation analysis and multiple linear regression.},
  keywords={},
  doi={10.1109/APEIE.2018.8545546},
  ISSN={2473-8573},
  month={Oct},}@INPROCEEDINGS{6785362,
  author={Yao Lu and Liu, Yao and Dey, Sujit},
  booktitle={2014 International Conference on Computing, Networking and Communications (ICNC)}, 
  title={Enhancing Cloud Mobile 3D display gaming user experience by asymmetric graphics rendering}, 
  year={2014},
  volume={},
  number={},
  pages={368-374},
  abstract={With the arrival of auto-stereoscopic 3D displays for mobile devices, and emergence of more 3D content, there is much anticipation for 3D mobile multimedia experiences, including 3D display gaming. Simultaneously, with the emergence of cloud computing, more mobile applications are being developed to take advantage of the elastic cloud resources. In this paper, we explore the possibility of developing Cloud-based 3D Mobile Gaming, where the 3D video rendering and encoding is performed on cloud servers, with the resulting 3D video streamed over wireless networks to mobile devices with 3D displays for a true 3D mobile gaming experience. However, with the significantly higher bit rate requirement for 3D video, ensuring user experience may be a challenge, both in terms of 3D video quality and network delay (response time), considering the bandwidth constraints and fluctuations of wireless networks. In this paper, we propose a new asymmetric graphics rendering approach which can significantly reduce the video encoding bit rate needed for a certain video quality, thereby making it easier to transmit the video over wireless network. However, since asymmetric rendering may also impair the graphics quality, we need to be able to understand and measure its impact. We conduct subjective tests to study and model the impairments due to asymmetric rendering and network delay, thereby developing a user experience model for cloud based mobile 3D display gaming. By conducting subsequent subjective tests, we prove the correctness of the impairment functions and the resulting user experience model. We also conduct experiments using real 4G-LTE network profile. Experimental results show that by making use of the user experience model, it is possible to set appropriate graphics rendering parameters according to network constraints, such that the user experience can be maintained to a high level.},
  keywords={},
  doi={10.1109/ICCNC.2014.6785362},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{8053360,
  author={Fang, Dongfeng and Ye, Feng and Qian, Yi and Sharif, Hamid},
  booktitle={2017 IEEE International Conference on Electro Information Technology (EIT)}, 
  title={An efficient incentive mechanism for cloud-based mobile sensor network}, 
  year={2017},
  volume={},
  number={},
  pages={229-234},
  abstract={Mobile sensor networks (MSNs) enable extensive applications of data collection, such as accident report in transportation and health prediction in public health. Incentive mechanism (IM) is applied for sensing user (SU) recruitment. However, the IM used in traditional MSN is not efficient due to limited information of SU used for recruitment. With the development of cloud computing technology, cloud-based MSN is the trend to use more information of SUs for IM design to improve its efficiency. In this paper, a novel cloud-based MSN model is presented. Three parties are considered, including data request party, cloud-based platform and SUs. A data quality model is proposed to measure the credit level of SUs. In addition, with consideration of social connections of SUs, a SU recruitment strategy is presented. SUs are divided into first and second degrees based on how they join the sensing task. The utility functions of first degree SUs and cloud-based platform are presented, respectively. At last, an efficient IM is proposed by formulating a Stackelberg game. The performance of the proposed IM on data quality and SU recruitment time comparing with other method are presented and discussed. The simulation results illustrate that the proposed IM ensures data quality for data request party and recruits SUs more efficiently.},
  keywords={},
  doi={10.1109/EIT.2017.8053360},
  ISSN={2154-0373},
  month={May},}@INPROCEEDINGS{7396225,
  author={Heidari, Parisa and Boucheneb, Hanifa and Shami, Abdallah},
  booktitle={2015 IEEE 7th International Conference on Cloud Computing Technology and Science (CloudCom)}, 
  title={A Formal Approach for QoS Assurance in the Cloud}, 
  year={2015},
  volume={},
  number={},
  pages={629-634},
  abstract={Cloud computing is an attractive business model offering cost-efficiency and business agility. Recently, the trend is that small and large businesses are moving their services to cloud environments. The quality of service is always negotiated between the cloud users and the cloud providers and documented in the service level agreement (SLA). Yet assuring -- or even measuring -- the quality of the provided service can be challenging. This paper proposes a formal approach for quantifying the quality of service in the cloud systems as promised in the SLA. The proposed approach uses controller synthesis to find a system configuration that meets the SLA requirement. The formal approach suggested in this paper is based on, but not limited to, %the controller synthesis of Time Petri Nets (TPN). As a case study, we focus on service availability as a key performance indicator in the SLA and for a sample set of resources providing a service, we determine the system configuration satisfying the SLA.},
  keywords={},
  doi={10.1109/CloudCom.2015.36},
  ISSN={},
  month={Nov},}@ARTICLE{7807337,
  author={Singh, Sukhpal and Chana, Inderveer and Buyya, Rajkumar},
  journal={IEEE Transactions on Cloud Computing}, 
  title={STAR: SLA-aware Autonomic Management of Cloud Resources}, 
  year={2020},
  volume={8},
  number={4},
  pages={1040-1053},
  abstract={Cloud computing has recently emerged as an important service to manage applications efficiently over the Internet. Various cloud providers offer pay per use cloud services that requires Quality of Service (QoS) management to efficiently monitor and measure the delivered services through Internet of Things (IoT) and thus needs to follow Service Level Agreements (SLAs). However, providing dedicated cloud services that ensure user's dynamic QoS requirements by avoiding SLA violations is a big challenge in cloud computing. As dynamism, heterogeneity and complexity of cloud environment is increasing rapidly, it makes cloud systems insecure and unmanageable. To overcome these problems, cloud systems require self-management of services. Therefore, there is a need to develop a resource management technique that automatically manages QoS requirements of cloud users thus helping the cloud providers in achieving the SLAs and avoiding SLA violations. In this paper, we present SLA-aware autonomic resource management technique called STAR which mainly focuses on reducing SLA violation rate for the efficient delivery of cloud services. The performance of the proposed technique has been evaluated through cloud environment. The experimental results demonstrate that STAR is efficient in reducing SLA violation rate and in optimizing other QoS parameters which effect efficient cloud service delivery.},
  keywords={},
  doi={10.1109/TCC.2017.2648788},
  ISSN={2168-7161},
  month={Oct},}@ARTICLE{7852434,
  author={Mei, Jing and Li, Kenli and Li, Keqin},
  journal={IEEE Transactions on Sustainable Computing}, 
  title={Customer-Satisfaction-Aware Optimal Multiserver Configuration for Profit Maximization in Cloud Computing}, 
  year={2017},
  volume={2},
  number={1},
  pages={17-29},
  abstract={Along with the development of cloud computing, an increasing number of enterprises start to adopt cloud service, which promotes the emergence of many cloud service providers. For cloud service providers, how to configure their cloud service platforms to obtain the maximum profit becomes increasingly the focus that they pay attention to. In this paper, we take customer satisfaction into consideration to address this problem. Customer satisfaction affects the profit of cloud service providers in two ways. On one hand, the cloud configuration affects the quality of service which is an important factor affecting customer satisfaction. On the other hand, the customer satisfaction affects the request arrival rate of a cloud service provider. However, few existing works take customer satisfaction into consideration in solving profit maximization problem, or the existing works considering customer satisfaction do not give a proper formalized definition for it. Hence, we first refer to the definition of customer satisfaction in economics and develop a formula for measuring customer satisfaction in cloud computing. And then, an analysis is given in detail on how the customer satisfaction affects the profit. Lastly, taking into consideration customer satisfaction, service-level agreement, renting price, energy consumption, and so forth, a profit maximization problem is formulated and solved to get the optimal configuration such that the profit is maximized.},
  keywords={},
  doi={10.1109/TSUSC.2017.2667706},
  ISSN={2377-3782},
  month={Jan},}@ARTICLE{8412190,
  author={El Kassabi, Hadeel T. and Serhani, Mohamed Adel and Dssouli, Rachida and Benatallah, Boualem},
  journal={IEEE Access}, 
  title={A Multi-Dimensional Trust Model for Processing Big Data Over Competing Clouds}, 
  year={2018},
  volume={6},
  number={},
  pages={39989-40007},
  abstract={Cloud computing has emerged as a powerful paradigm for delivering data-intensive services over the Internet. Cloud computing has enabled the implementation and success of big data, a recent phenomenon handling huge data being generated from different sources. Competing clouds have made it challenging to select a cloud provider that guarantees quality of cloud service (QoCS). Also, cloud providers' claims of guaranteeing QoCS are exaggerated for marketing purposes; hence, they cannot often be trusted. Therefore, a comprehensive trust model is necessary to evaluate the QoCS prior to making any selection decision. In this paper, we propose a multi-dimensional trust model for big data workflow processing over different clouds. It evaluates the trustworthiness of cloud providers based on: the most up-to-date cloud resource capabilities, the reputation evidence measured by neighboring users, and a recorded personal history of experiences with the cloud provider. The ultimate goal is to ensure an efficient selection of trustworthiness cloud provider who eventually will guarantee high QoCS and fulfills key big data workflow requirements. Various experiments were conducted to validate our proposed model. The results show that our model captures the different components of trust, ensures high QoCS, and effectively adapts to the dynamic nature of the cloud.},
  keywords={},
  doi={10.1109/ACCESS.2018.2856623},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9148980,
  author={Ma, Kun and Bagula, Antoine and Ajayi, Olasupo and Nyirenda, Clement},
  booktitle={ICC 2020 - 2020 IEEE International Conference on Communications (ICC)}, 
  title={Aiming at QoS: A Modified DE Algorithm for Task Allocation in Cloud Computing}, 
  year={2020},
  volume={},
  number={},
  pages={1-7},
  abstract={The Cloud computing system is characterized by large scale servers being utilized by an even larger number of users. It is a system where there is the need to frequently and efficiently schedule and manage different application tasks, with varied service requirements. One of the challenges of Cloud computing is managing the quality of service (QoS) rendered to users, specifically scheduling tasks between users and Cloud resources in a timely manner. Cloud users usually have widely diverse QoS requirements and meeting these simultaneously is also a challenge. In this paper, in order to improve on Cloud resource allocation and specifically to tailor it towards meeting varied QoS requirements of users, we proposed a new algorithm which combines Differential Evolution with the Shapley Value economic mode. This combination allows us measure the contribution of each virtual machine (VM), so as to improve the probability of obtaining a better tasks-to-resource allocation thereby improving user satisfaction. From results of conducted experiments, when compared with the traditional DE (Differential Evolution) algorithm and the conventional task-VM binding policy in CloudSim, both for allocations where special QoS requirements are required and in instances of multiple QoS requirements; the modified Shapley value based DE algorithm (SVBDA) shows significant improvement.},
  keywords={},
  doi={10.1109/ICC40277.2020.9148980},
  ISSN={1938-1883},
  month={June},}@INPROCEEDINGS{9568289,
  author={Weerasinghe, L. D. S. B. and Perera, Indika},
  booktitle={2021 International Research Conference on Smart Computing and Systems Engineering (SCSE)}, 
  title={An exploratory evaluation of replacing ESB with microservices in service-oriented architecture}, 
  year={2021},
  volume={4},
  number={},
  pages={137-144},
  abstract={With the continuous progress in technology during the past few decades, cloud computing has become a fast-growing technology in the world, making computerized systems widespread. The emergence of Cloud Computing has evolved towards microservice concepts, which are highly demanded by corporates for enterprise application level. Most enterprise applications have moved away from traditional unified models of software programs like monolithic architecture and traditional SOA architecture to microservice architecture to ensure better scalability, lesser investment in hardware, and high performance. The monolithic architecture is designed in a manner that all the components and the modules are packed together and deployed on a single binary. However, in the microservice architecture, components are developed as small services so that horizontally and vertically scaling is made easier in comparison to monolith or SOA architecture. SOA and monolithic architecture are at a disadvantage compared to Microservice architecture, as they require colossal hardware specifications to scale the software. In general terms, the system performance of these architectures can be measured considering different aspects such as system capacity, throughput, and latency. This research focuses on how scalability and performance software quality attributes behave when converting the SOA system to microservice architecture. Experimental results have shown that microservice architecture can bring more scalability with a minimum cost generation. Nevertheless, specific gaps in performance are identified in the perspective of the final user experiences due to the interservice communication in the microservice architecture in a distributed environment.},
  keywords={},
  doi={10.1109/SCSE53661.2021.9568289},
  ISSN={2613-8662},
  month={Sep.},}@INPROCEEDINGS{7904283,
  author={Bruschi, Gustavo C. and Spolon, Roberta and Pauro, Leandro L. and Lobato, Renata S. and Manacero, Aleardo and Cavenaghi, Marcos A.},
  booktitle={2016 15th International Symposium on Parallel and Distributed Computing (ISPDC)}, 
  title={StackAct: Performance Evaluation in an IaaS Cloud Multilayer}, 
  year={2016},
  volume={},
  number={},
  pages={149-156},
  abstract={Cloud Computing has become synonymous of quality, efficiency, and return of investment in Information Technology, creating new challenges for processing and data integrations. This paper presents the StackAct, a mechanism that allows performing monitoring and obtaining data on the consumption of computing resources of a solution in three layers using orchestrator IaaS Apache CloudStack, XenServer hypervisor and data storage on the NAS OpenFiler system. Performance tests were conducted using three different instances profile in a private cloud computing, allowing measuring CPU consumption, I/O disk and memory in three layers with different service offerings. The tests resulted in a comparison between the layers, it is possible to note the high consumption of disk in the data storage layer, in particular I/O data recording and the high memory consumption on the hypervisor layer, which is justified by the hypervisor itself to allocation of VMs being created and used in the process.},
  keywords={},
  doi={10.1109/ISPDC.2016.27},
  ISSN={},
  month={July},}@INPROCEEDINGS{9463991,
  author={Toka, Laszlo and Dobreff, Gergely and Haja, David and Szalay, Mark},
  booktitle={2021 IFIP/IEEE International Symposium on Integrated Network Management (IM)}, 
  title={Predicting cloud-native application failures based on monitoring data of cloud infrastructure}, 
  year={2021},
  volume={},
  number={},
  pages={842-847},
  abstract={The quality of service provided by cloud-deployed online applications is often affected by faults in the underlying cloud platform and infrastructure. In order to discover the cause and effect at application failures, a cloud monitoring system must be in place. The sheer amount of the produced monitoring data calls for smart and automatic handling in order to find the patterns that can be used for fault management. In this paper we present an open source, cloud-native, lightweight cloud monitoring system, and a data analytics pipeline that efficiently processes the gathered data and is able to discover useful inference between infrastructure-, and application-level metrics. We apply time series clustering steps within the pipeline to compress the collected data for fast and lightweight data mining. We show the capabilities of our proposed system in a reactive and a proactive use case. The results prove that the proposed system brings precious insights for root-cause analysis and proactive fault management frameworks of cloud applications.},
  keywords={},
  doi={},
  ISSN={1573-0077},
  month={May},}@INPROCEEDINGS{7565173,
  author={Mushtaq, M. Sajid and Fowler, Scott and Augustin, Brice and Mellouk, Abdelhamid},
  booktitle={2016 IEEE Wireless Communications and Networking Conference}, 
  title={QoE in 5G cloud networks using multimedia services}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={The 4G standard Long Term Evolution-Advanced (LTE-A) has been deployed in many countries. Now, technology is evolving towards the 5G standard since it is expecting to start its service in 2020. The 5G cellular networks will mainly contain in cloud computing and primarily Quality of Service (QoS) parameters (e.g. delay, loss rate, etc.) influence the cloud network performance. The impact of user perceived Quality of Experience (QoE) using multimedia services, and application significantly relies on the QoS parameters. The key challenge of 5G technology is to reduce the delay less than one millisecond. In this paper, we have described a method that minimizes the overall network delay for multimedia services; which are constant bit rate (VoIP) and variable bit rate (video) traffic model. We also proposed a method that measures the user's QoE for video streaming traffic using the network QoS parameters, i.e. delay and packet loss rate. The performance of proposed QoE method is compared with QoV method, and our proposed QoE method performs best by carefully handle the impact of QoS parameters. The results show that our described method successfully reduces the overall network delays, which result to maximize the user's QoE.},
  keywords={},
  doi={10.1109/WCNC.2016.7565173},
  ISSN={1558-2612},
  month={April},}@ARTICLE{7445250,
  author={Shi, Lei and Shi, Yi and Wei, Xing and Ding, Xu and Wei, Zhenchun},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Cost Minimization Algorithms for Data Center Management}, 
  year={2017},
  volume={28},
  number={1},
  pages={60-71},
  abstract={Due to the increasing usage of cloud computing applications, it is important to minimize energy cost consumed by a data center, and simultaneously, to improve quality of service via data center management. One promising approach is to switch some servers in a data center to the idle mode for saving energy while to keep a suitable number of servers in the active mode for providing timely service. In this paper, we design both online and offline algorithms for this problem. For the offline algorithm, we formulate data center management as a cost minimization problem by considering energy cost, delay cost (to measure service quality), and switching cost (to change servers's active/idle mode). Then, we analyze certain properties of an optimal solution which lead to a dynamic programming based algorithm. Moreover, by revising the solution procedure, we successfully eliminate the recursive procedure and achieve an optimal offline algorithm with a polynomial complexity. For the online algorithm, We design it by considering the worst case scenario for future workload. In simulation, we show this online algorithm can always provide near-optimal solutions.},
  keywords={},
  doi={10.1109/TPDS.2016.2549016},
  ISSN={1558-2183},
  month={Jan},}@ARTICLE{9144208,
  author={Vatalaro, Francesco and Ciccarella, Gianfranco},
  journal={IEEE Access}, 
  title={A Network Paradigm for Very High Capacity Mobile and Fixed Telecommunications Ecosystem Sustainable Evolution}, 
  year={2020},
  volume={8},
  number={},
  pages={135075-135090},
  abstract={The main objective for Very High Capacity (VHC) fixed and mobile networks is improving end-user Quality of Experience (QoE), i.e., meeting the Key Performance Indicators (KPIs) - throughput, download time, round trip time, and video delay - required by the applications. KPIs depend on the end-to-end connection between the server and the end-user device. Not only Telco operators must provide the quality needed for the different applications, but also they must address economic sustainability objectives for VHC networks. Today, both goals are often not met, mainly due to the push to increase the access networks bitrate without considering the end-to-end applications KPIs. This paper's main contribution deals with the definition of a VHC network deployment framework able to address performance and cost issues. We show that three are the interventions on which it is necessary to focus: i) the reduction of bit-rate through video compression, ii) the reduction of packet loss rate through artificial intelligence algorithms for access lines stabilization, and iii) the reduction of latency (i.e., the round-trip time) with edge-cloud computing and content delivery platforms, including transparent caching. The concerted and properly phased action of these three measures can allow a Telco to get out of the Ultra Broad Band access network “trap”as defined in the paper. We propose to work on the end-to-end optimization of the bandwidth utilization ratio (i.e., the ratio between the throughput and the bit-rate that any application can use). It leads to better performance experienced by the end-user, enables new business models and revenue streams, and provides a sustainable cost for the Telco operators. To make such a perspective more precise, the case of MoVAR (Mobile Virtual and Augmented Reality), one of the most challenging future services, is finally described.},
  keywords={},
  doi={10.1109/ACCESS.2020.3010348},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8766409,
  author={Brunschwiler, T. and Weiss, J. and Paredes, S. and Sridhar, A. and Pluntke, U. and Chau, S. Mai and Gerke, S. and Barroso, J. and Loertscher, E. and Temiz, Y. and Ruch, P. and Michel, B. and Zafar, S. and van Kessel, T.},
  booktitle={2019 Global IoT Summit (GIoTS)}, 
  title={Internet of the Body - Wearable Monitoring and Coaching}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={Wearables that acquire relevant vital and contextual parameters improve work safety as well as quality of life of elderly citizens or patients with chronic diseases. A scalable architecture connects wearables via a hub to the cloud and combines edge with cloud computing to provide optimal user interaction and allow analytics on multi-stream data. The functionality was expanded to enable demonstrations of physiological and psychological stress classification in firemen and mobile health interventions in patients with lung diseases. Following an initial table-top edge demonstrator a hemi-spherical display improves emotional contact to users. A first use case tested an integrated acquisition and inference system that was trained to differentiate physical and emotional stress. The system measured stress in firemen during training in a cage maze and in hot training locations and provided functions to acquire expert labels. A second use case focused on mobile-health intervention for patients suffering from Chronic-Obstructive-Pulmonary-Disease (COPD), to improve their quality-of-life. Patient-physician conversations are extended through a communication channel and a virtual assistant provides disease related information, reminders, and alerts.},
  keywords={},
  doi={10.1109/GIOTS.2019.8766409},
  ISSN={},
  month={June},}@INPROCEEDINGS{8718133,
  author={Wong, Tong-Sheng and Chan, Gaik-Yee and Chua, Fang-Fang},
  booktitle={2019 International Conference on Information Networking (ICOIN)}, 
  title={Adaptive Preventive and Remedial Measures in Resolving Cloud Quality of Service Violation}, 
  year={2019},
  volume={},
  number={},
  pages={473-479},
  abstract={Cloud Computing acts as a paradigm to support on-demand computing services, from applications to storage, manage and processing capabilities. One of the major challenges in delivering and accessing cloud applications is the management of Quality of Service (QoS) and cloud service providers are mandated to adhere to Service Level Agreement (SLA) in providing quality cloud services to the users. The agreement matching is important for both parties to ensure satisfaction and expectation level. This proposed work aims to resolve cloud QoS violation with the implementation of adaptive preventive and remedial mechanisms. Preventive measure such as horizontal scaling is used to optimize the performance of a running cloud service in order to prevent the cloud service to downgrade to QoS violation condition. Remedial action on the other hand, is to provide fault tolerance using replication for faulty cloud service to recover from failure incidents or already violation condition. Experimental results have demonstrated the feasibility and effectiveness of applying horizontal scaling in preventing and replication in rectifying cloud QoS violations based on response time and throughput.},
  keywords={},
  doi={10.1109/ICOIN.2019.8718133},
  ISSN={1976-7684},
  month={Jan},}@INPROCEEDINGS{7175787,
  author={Hong Shen and Jinglei Meng and Licheng Yu and Xuefeng Fang and Tianzhou Chen and Hui Yan and Honglun Hou},
  booktitle={2014 IEEE 3rd International Conference on Cloud Computing and Intelligence Systems}, 
  title={A quantitative quality control method of big data in cancer patients using artificial neural network}, 
  year={2014},
  volume={},
  number={},
  pages={499-504},
  abstract={Nonstandard treatments for cancer patients are commonly seen in hospitals of developing countries like China. So it is crucial to standardize the treatments for cancer with technological means in order to supervise the process of treatments. Widespread of electronic health records (EHRs) has generated massive data sets which are far beyond the capability of traditional computing model. Although there are process and measures about quality control, but automatic computerized Quantitative Control (QC) and quantization methods are still lack. In this paper, we propose a quantitative quality control method of radiotherapy and chemotherapy based on artificial neural network to automatically analysis and rate the compliance with standard treatment process. The quantitative QC items are established and the artificial neural network is constructed accordingly. Then the selected cases are evaluated by experts for corresponding QC grades to train the artificial neural network. After that, the trained artificial neural network can be used to grade new cases for their QC score. To meet the high requirement of computation and accommodate massive data sets, we adopt our proposal in the cloud. With massive data distributed on computing nodes in the cloud, computing capability of nodes are dynamically allocated to homogenization and ANN computing, each node work both homogenization medical records and ANN computing according to system load balance resulting the quantitative QC process perform in high parallelism.},
  keywords={},
  doi={10.1109/CCIS.2014.7175787},
  ISSN={2376-595X},
  month={Nov},}@ARTICLE{6473795,
  author={Bruneo, Dario},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={A Stochastic Model to Investigate Data Center Performance and QoS in IaaS Cloud Computing Systems}, 
  year={2014},
  volume={25},
  number={3},
  pages={560-569},
  abstract={Cloud data center management is a key problem due to the numerous and heterogeneous strategies that can be applied, ranging from the VM placement to the federation with other clouds. Performance evaluation of cloud computing infrastructures is required to predict and quantify the cost-benefit of a strategy portfolio and the corresponding quality of service (QoS) experienced by users. Such analyses are not feasible by simulation or on-the-field experimentation, due to the great number of parameters that have to be investigated. In this paper, we present an analytical model, based on stochastic reward nets (SRNs), that is both scalable to model systems composed of thousands of resources and flexible to represent different policies and cloud-specific strategies. Several performance metrics are defined and evaluated to analyze the behavior of a cloud data center: utilization, availability, waiting time, and responsiveness. A resiliency analysis is also provided to take into account load bursts. Finally, a general approach is presented that, starting from the concept of system capacity, can help system managers to opportunely set the data center parameters under different working conditions.},
  keywords={},
  doi={10.1109/TPDS.2013.67},
  ISSN={1558-2183},
  month={March},}@INPROCEEDINGS{8029803,
  author={Mazlami, Genc and Cito, Jürgen and Leitner, Philipp},
  booktitle={2017 IEEE International Conference on Web Services (ICWS)}, 
  title={Extraction of Microservices from Monolithic Software Architectures}, 
  year={2017},
  volume={},
  number={},
  pages={524-531},
  abstract={Driven by developments such as mobile computing, cloud computing infrastructure, DevOps and elastic computing, the microservice architectural style has emerged as a new alternative to the monolithic style for designing large software systems. Monolithic legacy applications in industry undergo a migration to microservice-oriented architectures. A key challenge in this context is the extraction of microservices from existing monolithic code bases. While informal migration patterns and techniques exist, there is a lack of formal models and automated support tools in that area. This paper tackles that challenge by presenting a formal microservice extraction model to allow algorithmic recommendation of microservice candidates in a refactoring and migration scenario. The formal model is implemented in a web-based prototype. A performance evaluation demonstrates that the presented approach provides adequate performance. The recommendation quality is evaluated quantitatively by custom microservice-specific metrics. The results show that the produced microservice candidates lower the average development team size down to half of the original size or lower. Furthermore, the size of recommended microservice conforms with microservice sizing reported by empirical surveys and the domain-specific redundancy among different microservices is kept at a low rate.},
  keywords={},
  doi={10.1109/ICWS.2017.61},
  ISSN={},
  month={June},}@ARTICLE{8306964,
  author={Neghabi, Ali Akbar and Jafari Navimipour, Nima and Hosseinzadeh, Mehdi and Rezaee, Ali},
  journal={IEEE Access}, 
  title={Load Balancing Mechanisms in the Software Defined Networks: A Systematic and Comprehensive Review of the Literature}, 
  year={2018},
  volume={6},
  number={},
  pages={14159-14178},
  abstract={With the expansion of the network and increasing their users, as well as emerging new technologies, such as cloud computing and big data, managing traditional networks is difficult. Therefore, it is necessary to change the traditional network architecture. Lately, to address this issue, a notion named software-defined network (SDN) has been proposed, which makes network management more conformable. Due to limited network resources and to meet the requirements of quality of service, one of the points that must be considered is load balancing issue that serves to distribute data traffic among multiple resources in order to maximize the efficiency and reliability of network resources. Load balancing is established based on the local information of the network in the conventional network. Hence, it is not very precise. However, SDN controllers have a global view of the network and can produce more optimized load balances. Although load balancing mechanisms are important in the SDN, to the best of our knowledge, there exists no precise and systematic review or survey on investigating these issues. Hence, this paper reviews the load balancing mechanisms which have been used in the SDN systematically based on two categories, deterministic and non-deterministic. Also, this paper represents benefits and some weakness regarded of the selected load balancing algorithms and investigates the metrics of their algorithms. In addition, the important challenges of these algorithms have been reviewed, so better load balancing techniques can be applied by the researchers in the future.},
  keywords={},
  doi={10.1109/ACCESS.2018.2805842},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8030623,
  author={Al-Dhuraibi, Yahya and Paraiso, Fawaz and Djarallah, Nabil and Merle, Philippe},
  booktitle={2017 IEEE 10th International Conference on Cloud Computing (CLOUD)}, 
  title={Autonomic Vertical Elasticity of Docker Containers with ELASTICDOCKER}, 
  year={2017},
  volume={},
  number={},
  pages={472-479},
  abstract={Elasticity is the key feature of cloud computing to scale computing resources according to application workloads timely. In the literature as well as in industrial products, much attention was given to the elasticity of virtual machines, but much less to the elasticity of containers. However, containers are the new trend for packaging and deploying microservices-based applications. Moreover, most of approaches focus on horizontal elasticity, fewer works address vertical elasticity. In this paper, we propose ELASTICDOCKER, the first system powering vertical elasticity of Docker containers autonomously. Based on the well-known IBM's autonomic computing MAPE-K principles, ELASTICDOCKER scales up and down both CPU and memory assigned to each container according to the application workload. As vertical elasticity is limited to the host machine capacity, ELASTICDOCKER does container live migration when there is no enough resources on the hosting machine. Our experiments show that ELASTICDOCKER helps to reduce expenses for container customers, make better resource utilization for container providers, and improve Quality of Experience for application end-users. In addition, based on the observed migration performance metrics, the experiments reveal a high efficient live migration technique. As compared to horizontal elasticity, ELASTICDOCKER outperforms Kubernetes elasticity by 37.63%.},
  keywords={},
  doi={10.1109/CLOUD.2017.67},
  ISSN={2159-6190},
  month={June},}@ARTICLE{7045510,
  author={Xia, YunNi and Zhou, MengChu and Luo, Xin and Pang, ShanChen and Zhu, QingSheng},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Stochastic Modeling and Performance Analysis of Migration-Enabled and Error-Prone Clouds}, 
  year={2015},
  volume={11},
  number={2},
  pages={495-504},
  abstract={Cloud computing is a promising paradigm capable of rationalizing the use of computational resources by means of outsourcing and virtualization. Virtualization allows to instantiate virtual machines (VMs) on top of fewer physical systems managed by a VM manager. Performance evaluation of clouds is required to evaluate and quantify the cost-benefit of a strategy portfolio and the quality of service (QoS) experienced by end-users. Such evaluation is not feasible by means of simulation or on-the-field measurement, due to the great scale of parameter spaces that have to be traversed. In this study, we present a stochastic-queuing-network-based approach to performance analysis of migration-enabled clouds in error-prone environment. Several performance metrics are defined and evaluated: utilization, expected task completion time, and task rejection rate under different load conditions and error intensities. To validate the proposed approach, we obtain experimental performance data through a real-world cloud and conduct a confidence-interval analysis. The analysis results suggest the perfect coverage of theoretical performance results by corresponding experimental confidence intervals.},
  keywords={},
  doi={10.1109/TII.2015.2405792},
  ISSN={1941-0050},
  month={April},}@ARTICLE{9046283,
  author={Zhu, Zongwei and Han, Guangjie and Jia, Gangyong and Shu, Lei},
  journal={IEEE Internet of Things Journal}, 
  title={Modified DenseNet for Automatic Fabric Defect Detection With Edge Computing for Minimizing Latency}, 
  year={2020},
  volume={7},
  number={10},
  pages={9623-9636},
  abstract={As an essential step in quality control, fabric defect detection plays an important role in the textile manufacturing industry. The traditional manual detection method is inaccurate and incurs a high cost; as a result, it is gradually being replaced by deep learning algorithms based on cloud computing. However, a high data transmission latency between end devices and the cloud has a significant impact on textile production efficiency. In contrast, edge computing, which provides services near end devices by deploying network, computing and storage facilities at the edge of the Internet, can effectively solve the above-mentioned problem. In this article, we propose a deep-learning-based fabric defect detection method for edge computing scenarios. First, this article modifies the structure of DenseNet to better suit a resource-constrained edge computing scenario. To better assess the proposed model, an optimized cross-entropy loss function is also formulated. Afterward, six feasible expansion schemes are utilized to enhance the data set according to the characteristics of various defects in fabric samples. To balance the distribution of samples, proportions of various defect types are used to determine the number of enhancements. Finally, a fabric defect detection system is established to test the performance of the optimized model used on edge devices in a real-world textile industry scenario. Experimental results demonstrate that compared with the conventional convolutional neural network (CNN), the proposed optimized model attains an average improvement of 18% in the area under the curve (AUC) metric for 11 defects. Data transmission is reduced by approximately 50% and latency is reduced by 32% in the Cambricon 1H8 platform compared with a cloud platform.},
  keywords={},
  doi={10.1109/JIOT.2020.2983050},
  ISSN={2327-4662},
  month={Oct},}@ARTICLE{8976136,
  author={Farid, Mazen and Latip, Rohaya and Hussin, Masnida and Abdul Hamid, Nor Asilah Wati},
  journal={IEEE Access}, 
  title={Scheduling Scientific Workflow Using Multi-Objective Algorithm With Fuzzy Resource Utilization in Multi-Cloud Environment}, 
  year={2020},
  volume={8},
  number={},
  pages={24309-24322},
  abstract={The provision of resources and services for scientific workflow applications using a multi-cloud architecture and a pay-per-use rule has recently gained popularity within the cloud computing research domain. This is because workflow applications are computation intensive. Most of the existing studies on workflow scheduling in the cloud mainly focus on finding an ideal makespan or cost. Nevertheless, there are other important quality of service metrics that are of critical concern in workflow scheduling such as reliability and resource utilization. In this respect, this paper proposes a new multi-objective scheduling algorithm with Fuzzy resource utilization (FR-MOS) for scheduling scientific workflow based on particle swarm optimization (PSO) method. The algorithm minimizes cost and makespan while considering reliability constraint. The coding scheme jointly considers task execution location and data transportation order. Simulation experiments reveal that FR-MOS outperforms the basic MOS over the PSO algorithm.},
  keywords={},
  doi={10.1109/ACCESS.2020.2970475},
  ISSN={2169-3536},
  month={},}@ARTICLE{7010388,
  author={Nesmachnow, Sergio and Iturriaga, Santiago and Dorronsoro, Bernabe},
  journal={IEEE Computational Intelligence Magazine}, 
  title={Efficient Heuristics for Profit Optimization of Virtual Cloud Brokers}, 
  year={2015},
  volume={10},
  number={1},
  pages={33-43},
  abstract={This article introduces a new kind of broker for cloud computing, whose business relies on outsourcing virtual machines (VMs) to its customers. More specifically, the broker owns a number of reserved instances of different VMs from several cloud providers and offers them to its customers in an on-demand basis, at cheaper prices than those of the cloud providers. The essence of the business resides in the large difference in price between on-demand and reserved VMs. We define the Virtual Machine Planning Problem, an optimization problem to maximize the profit of the broker. We also propose a number of efficient smart heuristics (seven two-phase list scheduling heuristics and a reordering local search) to allocate a set of VM requests from customers into the available pre-booked ones, that maximize the broker earnings. We perform experimental evaluation to analyze the profit and quality of service metrics for the resulting planning, including a set of 400 problem instances that account for realistic workloads and scenarios using real data from cloud providers.},
  keywords={},
  doi={10.1109/MCI.2014.2369893},
  ISSN={1556-6048},
  month={Feb},}@ARTICLE{9140398,
  author={Fantacci, Romano and Picano, Benedetta},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={Performance Analysis of a Delay Constrained Data Offloading Scheme in an Integrated Cloud-Fog-Edge Computing System}, 
  year={2020},
  volume={69},
  number={10},
  pages={12004-12014},
  abstract={The recent growth in intensive services and applications demand has triggered the functional integration of cloud computing with edge computing capabilities. One of the main goals is to allow a fast processing to tasks with strict real time constraints in order to lower the task dropping probability due to expiration of the associated deadlines. This paper deals with the performance evaluation and optimization of a three layers cloud-fog-edge computing infrastructure by resorting to the use of queueing theory results. In particular, a Markov queueing system model with reneging is proposed for the cloud subsystem, in order to consider the premature computation requests departure due to their deadline expiration. Furthermore, a computational resources allocation method is proposed with the aim at maximizing the social welfare metric, constrained to specific quality of service requirements. Finally, the proposed queueing theory analysis as well as of the computational resources allocation approach is validated by comparing the obtained analytical predictions with simulation results.},
  keywords={},
  doi={10.1109/TVT.2020.3008926},
  ISSN={1939-9359},
  month={Oct},}@ARTICLE{7042798,
  author={Ayoubi, Sara and Assi, Chadi and Shaban, Khaled and Narayanan, Lata},
  journal={IEEE Transactions on Communications}, 
  title={MINTED: Multicast VIrtual NeTwork Embedding in Cloud Data Centers With Delay Constraints}, 
  year={2015},
  volume={63},
  number={4},
  pages={1291-1305},
  abstract={Network virtualization is regarded as the pillar of cloud computing, enabling the multi-tenancy concept where multiple Virtual Networks (VNs) can cohabit the same substrate network. With network virtualization, the problem of allocating resources to the various tenants, commonly known as the Virtual Network Embedding problem, emerges as a challenge. Its NP-Hard nature has drawn a lot of attention from the research community, many of which however overlooked the type of communication that a given VN may exhibit, assuming that they all exhibit a one-to-one (unicast) communication only. In this paper, we motivate the importance of characterizing the mode of communication in VN requests, and we focus our attention on the problem of embedding VNs with a one-to-many (multicast) communication mode. Throughout this paper, we highlight the unique properties of multicast VNs and its distinct Quality of Service (QoS) requirements, most notably the end-delay and delay-variation constraints for delay-sensitive multicast services. Further, we showcase the limitations of handling a multicast VN as unicast. To this extent, we formally define the VNE problem for Multicast VNs (MVNs) and prove its NP-Hard nature. We propose two novel approach to solve the Multicast VNE (MVNE) problem with end-delay and delay variation constraints: A 3-Step MVNE technique, and a Tabu-Search algorithm. We motivate the intuition behind our proposed embedding techniques, and provide a competitive analysis of our suggested approaches over multiple metrics and against other embedding heuristics.},
  keywords={},
  doi={10.1109/TCOMM.2015.2404440},
  ISSN={1558-0857},
  month={April},}
