@INPROCEEDINGS{8477218,
  author={Li, Keqin},
  booktitle={2018 IEEE 16th International Conference on Software Engineering Research, Management and Applications (SERA)}, 
  title={Quantitative Modeling and Analytical Calculation of Elasticity in Cloud Computing}, 
  year={2018},
  volume={},
  number={},
  pages={3-3},
  abstract={Elasticity is a fundamental feature of cloud computing and can be considered as a great advantage and a key benefit of cloud computing. Our research makes the following significant contributions. First, we present a new, quantitative, and formal definition of elasticity in cloud computing, i.e., the probability that the computing resources provided by a cloud platform match the current workload. Our definition is applicable to any cloud platform and can be easily measured and monitored. Furthermore, we develop an analytical model to study elasticity by treating a cloud platform as a queueing system, and use a continuous-time Markov chain (CTMC) model to precisely calculate the elasticity value of a cloud platform by using an analytical and numerical method based on just a few parameters, namely, the task arrival rate, the service rate, the virtual machine start-up and shut-down rates. In addition, we formally define auto-scaling schemes and point out that our model and method can be easily extended to handle arbitrarily sophisticated scaling schemes. Second, we apply our model and method to predict many other important properties of an elastic cloud computing system, such as average task response time, throughput, quality of service, average number of VMs, average number of busy VMs, utilization, cost, cost-performance ratio, productivity, and scalability. In fact, from a cloud consumer's point of view, these performance and cost metrics are even more important than the elasticity metric. Ourperformance and cost guarantee using the results developed in this talk. On the other hand, a cloud service provider can optimize its elastic scaling scheme to deliver the best cost-performance ratio. study in this talk has two significance. On one hand, a cloud service provider can predict its To the best of our knowledge, this is the first work that analytically and comprehensively studies elasticity, performance, and cost in cloud computing. Our model and method significantly contribute to the understanding of cloud elasticity and management of elastic cloud computing systems.},
  keywords={},
  doi={10.1109/SERA.2018.8477218},
  ISSN={},
  month={June},}@INPROCEEDINGS{8477227,
  author={Li, Keqin},
  booktitle={2018 IEEE 16th International Conference on Software Engineering Research, Management and Applications (SERA)}, 
  title={Quantitative Modeling and Analytical Calculation of Elasticity in Cloud Computing}, 
  year={2018},
  volume={},
  number={},
  pages={3-3},
  abstract={Elasticity is a fundamental feature of cloud computing and can be considered as a great advantage and a key benefit of cloud computing. Our research makes the following significant contributions. First, we present a new, quantitative, and formal definition of elasticity in cloud computing, i.e., the probability that the computing resources provided by a cloud platform match the current workload. Our definition is applicable to any cloud platform and can be easily measured and monitored. Furthermore, we develop an analytical model to study elasticity by treating a cloud platform as a queueing system, and use a continuous-time Markov chain (CTMC) model to precisely calculate the elasticity value of a cloud platform by using an analytical and numerical method based on just a few parameters, namely, the task arrival rate, the service rate, the virtual machine start-up and shut-down rates. In addition, we formally define auto-scaling schemes and point out that our model and method can be easily extended to handle arbitrarily sophisticated scaling schemes. Second, we apply our model and method to predict many other important properties of an elastic cloud computing system, such as average task response time, throughput, quality of service, average number of VMs, average number of busy VMs, utilization, cost, cost-performance ratio, productivity, and scalability. In fact, from a cloud consumer's point of view, these performance and cost metrics are even more important than the elasticity metric. Ourperformance and cost guarantee using the results developed in this talk. On the other hand, a cloud service provider can optimize its elastic scaling scheme to deliver the best cost-performance ratio. study in this talk has two significance. On one hand, a cloud service provider can predict its To the best of our knowledge, this is the first work that analytically and comprehensively studies elasticity, performance, and cost in cloud computing. Our model and method significantly contribute to the understanding of cloud elasticity and management of elastic cloud computing systems.},
  keywords={},
  doi={10.1109/SERA.2018.8477227},
  ISSN={},
  month={June},}@INPROCEEDINGS{7450805,
  author={Lehrig, Sebastian and Eikerling, Hendrik and Becker, Steffen},
  booktitle={2015 11th International ACM SIGSOFT Conference on Quality of Software Architectures (QoSA)}, 
  title={Scalability, elasticity, and efficiency in cloud computing: A systematic literature review of definitions and metrics}, 
  year={2015},
  volume={},
  number={},
  pages={83-92},
  abstract={Context In cloud computing, there is a multitude of definitions and metrics for scalability, elasticity, and efficiency. However, stakeholders have little guidance for choosing fitting definitions and metrics for these quality properties, thus leading to potential misunderstandings. For example, cloud consumers and providers cannot negotiate reliable and quantitative service level objectives directly understood by each stakeholder. Objectives Therefore, we examine existing definitions and metrics for these quality properties from the viewpoint of cloud consumers, cloud providers, and software architects with regard to commonly used concepts. Methods We execute a systematic literature review (SLR), reproducibly collecting common concepts in definitions and metrics for scalability, elasticity, and efficiency. As quality selection criteria, we assess whether existing literature differentiates the three properties, exemplifies metrics, and considers typical cloud characteristics and cloud roles. Results Our SLR yields 418 initial results from which we select 20 for in-depth evaluation based on our quality selection criteria. In our evaluation, we recommend concepts, definitions, and metrics for each property. Conclusions Software architects can use our recommendations to analyze the quality of cloud computing applications. Cloud providers and cloud consumers can specify service level objectives based on our metric suggestions.},
  keywords={},
  doi={10.1145/2737182.2737185},
  ISSN={},
  month={May},}@INPROCEEDINGS{7207388,
  author={Zhou, Nianjun and Mohindra, Ajay},
  booktitle={2015 IEEE International Conference on Services Computing}, 
  title={Causality-Driven Performance Monitoring and Scaling Automation for Managed Solutions}, 
  year={2015},
  volume={},
  number={},
  pages={467-474},
  abstract={A key feature of Cloud computing is its agility and flexibility to support the scalability needs of business solutions. Currently, the agility is only limited to the scalability of the compute, memory and storage. To improve an application's agility, we need to monitor & measure solution level metrics and associate the performance of the metrics to the business agility needs of the solution by making real-time scalability or change decisions. In this paper, we illustrate a scaling decision mechanism utilizing the monitoring data from infrastructure, middleware, and business level metrics. We use these performance metrics as input to a causality analysis model to make architecture changes or scalability decisions. Mathematically, we define the causality as a graph to link the changes in the measured metric values to the action of the solution change. The causality analysis follows scalability principles as best practices. They are a) the principle of performance scalability b) principle of contribution margin for scalability, and c) principle of the least cost of SLA compliance. We define these scalability principles as the rules to ensure that the business stakeholder of the solution can maintain or improve their business quality or profit margins as the computing capability scales up or down. To implement those principles, we need to establish the linkages of the business metrics to the decision of changes. To make such linkage, we first utilize causality analysis to identify feasible scaling actions, and then associate those actions with the system, application, and business performance metrics. With the help of causality analysis, we implement a performance monitoring and scaling automation framework for managed solutions using an Open Source Monitoring system.},
  keywords={},
  doi={10.1109/SCC.2015.70},
  ISSN={},
  month={June},}@ARTICLE{9139920,
  author={Guerron, Ximena and Abrahão, Silvia and Insfran, Emilio and Fernández-Diego, Marta and González-Ladrón-De-Guevara, Fernando},
  journal={IEEE Access}, 
  title={A Taxonomy of Quality Metrics for Cloud Services}, 
  year={2020},
  volume={8},
  number={},
  pages={131461-131498},
  abstract={A large number of metrics with which to assess the quality of cloud services have been proposed over the last years. However, this knowledge is still dispersed, and stakeholders have little or no guidance when choosing metrics that will be suitable to evaluate their cloud services. The objective of this paper is, therefore, to systematically identify, taxonomically classify, and compare existing quality of service (QoS) metrics in the cloud computing domain. We conducted a systematic literature review of 84 studies selected from a set of 4333 studies that were published from 2006 to November 2018. We specifically identified 470 metric operationalizations that were then classified using a taxonomy, which is also introduced in this paper. The data extracted from the metrics were subsequently analyzed using thematic analysis. The findings indicated that most metrics evaluate quality attributes related to performance efficiency (64%) and that there is a need for metrics that evaluate other characteristics, such as security and compatibility. The majority of the metrics are used during the Operation phase of the cloud services and are applied to the running service. Our results also revealed that metrics for cloud services are still in the early stages of maturity - only 10% of the metrics had been empirically validated. The proposed taxonomy can be used by practitioners as a guideline when specifying service level objectives or deciding which metric is best suited to the evaluation of their cloud services, and by researchers as a comprehensive quality framework in which to evaluate their approaches.},
  keywords={},
  doi={10.1109/ACCESS.2020.3009079},
  ISSN={2169-3536},
  month={},}@ARTICLE{7153530,
  author={Zhao, Feng and Nian, Guodong and Jin, Hai and Yang, Laurence T. and Zhu, Yajun},
  journal={IEEE Systems Journal}, 
  title={A Hybrid eBusiness Software Metrics Framework for Decision Making in Cloud Computing Environment}, 
  year={2017},
  volume={11},
  number={2},
  pages={1049-1059},
  abstract={Developing high-quality software is essential for eBusiness organizations to cope with drastic market competition. With the development of cloud computing technologies, eBusiness systems and applications pay more attention to open endedness. In a cloud computing environment, eBusiness systems have the ability to provide information technology resources on demand. Traditional software metric methods in distributed systems and applications are technical and project driven, making the market demand and internal practical operation not perfectly balanced within a cloud-computing-based eBusiness corporation. To address this issue, this paper presents a hybrid framework based on the goal/question/metric paradigm to evaluate the quality and efficiency of previous software products, projects, and development organizations in a cloud computing environment. In our approach, to support decision making at the project and organization levels, three angular metrics are used, i.e., project metrics, product metrics, and organization metrics. Furthermore, an improved radial-basis-function-based model is also provided to manage existing projects and design new projects. Experimental results on a well-known eBusiness organization show that the proposed framework is effective, efficient, and operational. Moreover, using the described decision-making algorithm, the predicted data are very close to actual results on the software cost, the fault rate, the development workload, etc., which are greatly helpful in achieving high-quality software.},
  keywords={},
  doi={10.1109/JSYST.2015.2443049},
  ISSN={1937-9234},
  month={June},}@ARTICLE{7845614,
  author={Li, Keqin},
  journal={IEEE Transactions on Cloud Computing}, 
  title={Quantitative Modeling and Analytical Calculation of Elasticity in Cloud Computing}, 
  year={2020},
  volume={8},
  number={4},
  pages={1135-1148},
  abstract={Elasticity is a fundamental feature of cloud computing and can be considered as a great advantage and a key benefit of cloud computing. One key challenge in cloud elasticity is lack of consensus on a quantifiable, measurable, observable, and calculable definition of elasticity and systematic approaches to modeling, quantifying, analyzing, and predicting elasticity. Another key challenge in cloud computing is lack of effective ways for prediction and optimization of performance and cost in an elastic cloud platform. The present paper makes the following significant contributions. First, we present a new, quantitative, and formal definition of elasticity in cloud computing, i.e., the probability that the computing resources provided by a cloud platform match the current workload. Our definition is applicable to any cloud platform and can be easily measured and monitored. Furthermore, we develop an analytical model to study elasticity by treating a cloud platform as a queueing system, and use a continuous-time Markov chain (CTMC) model to precisely calculate the elasticity value of a cloud platform by using an analytical and numerical method based on just a few parameters, namely, the task arrival rate, the service rate, the virtual machine start-up and shut-down rates. In addition, we formally define auto-scaling schemes and point out that our model and method can be easily extended to handle arbitrarily sophisticated scaling schemes. Second, we apply our model and method to predict many other important properties of an elastic cloud computing system, such as average task response time, throughput, quality of service, average number of VMs, average number of busy VMs, utilization, cost, cost-performance ratio, productivity, and scalability. In fact, from a cloud consumer's point of view, these performance and cost metrics are even more important than the elasticity metric. Our study in this paper has two significance. On one hand, a cloud service provider can predict its performance and cost guarantee using the results developed in this paper. On the other hand, a cloud service provider can optimize its elastic scaling scheme to deliver the best cost-performance ratio. To the best of our knowledge, this is the first paper that analytically and comprehensively studies elasticity, performance, and cost in cloud computing. Our model and method significantly contribute to the understanding of cloud elasticity and management of elastic cloud computing systems.},
  keywords={},
  doi={10.1109/TCC.2017.2665549},
  ISSN={2168-7161},
  month={Oct},}@INPROCEEDINGS{8613297,
  author={Al-Said Ahmad, Amro and Andras, Peter},
  booktitle={2018 Fifth International Symposium on Innovation in Information and Communication Technology (ISIICT)}, 
  title={Measuring and Testing the Scalability of Cloud-based Software Services}, 
  year={2018},
  volume={},
  number={},
  pages={1-8},
  abstract={Performance and scalability testing and measurements of cloud-based software services are critically important in the context of rapid growth of cloud computing and supporting the delivery of these services. Cloud-based software services performance aspects are interrelated, both elasticity and efficiency are depending on the delivery of a sufficient level of scalability performance. In this work, we focused on testing and measuring the scalability of cloud-based software services in technical terms. This paper uses technical scalability metrics that address both volume and quality scaling, that inspired by earlier technical metrics of elasticity. We show how our technical scalability metrics can be integrated into an earlier utility oriented metric of scalability. We demonstrate the application of the metrics using a practical example and discuss the importance of them.},
  keywords={},
  doi={10.1109/ISIICT.2018.8613297},
  ISSN={},
  month={Oct},}@ARTICLE{8391708,
  author={Xu, Han and Qiu, Xiwei and Sheng, Yongpan and Luo, Liang and Xiang, Yanping},
  journal={IEEE Access}, 
  title={A Qos-Driven Approach to the Cloud Service Addressing Attributes of Security}, 
  year={2018},
  volume={6},
  number={},
  pages={34477-34487},
  abstract={Recently, cloud computing has been widely used by relying on its powerful resource integration and computing abilities. In the cloud computing system (CCS), the quality of service (QoS) is an important service evaluation criterion from provider and client perspectives, which directly affects the client experience and profit of the cloud providers. Thus, a precise evaluation of the QoS can help the cloud provider develop reasonable resource allocation strategies for improving the client experience. The performance metric is usually adopted to quantify QoS. Many approaches and methods for evaluating performance have been widely studied. However, another important metric, i.e., security, does not receive adequate attention in the evaluation of QoS. More importantly, security also has serious effects on the performance metric, that is, complex security-performance (S-P) correlations. To address these issues, this paper first builds a Markov model to analyze and assess the security of the CCS that captures two critical security factors, i.e., malicious attacks and the security protection mechanism. Then, a hierarchical modeling approach is presented to flexibly build the connection between security and the service performance. Finally, we propose a correlation metric to quantify random service performance. This correlation metric comprehensively considers the effect of the security factors and thus becomes more realistic and precise. The experimental results reveal the dynamic change of performance caused by the security factors and demonstrate the important S-P correlation. Therefore, security cannot be ignored in the modeling and evaluation of the QoS metric.},
  keywords={},
  doi={10.1109/ACCESS.2018.2849594},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{6968746,
  author={Poggi, Nicolas and Carrera, David and Ayguadé, Eduard and Torres, Jordi},
  booktitle={2014 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={POSTER: Profit-aware cloud resource provisioner for ecommerce}, 
  year={2014},
  volume={},
  number={},
  pages={274-275},
  abstract={In recent years, the Cloud Computing paradigm has proven effective in scaling dynamically the number of servers according to simple performance metrics and the incoming workload. However while some applications are able to scale-out, as current scaling metrics do not relate system performance to sales, hosting costs and profits are not optimized completely. The following article proposes a novel technique for dynamic resource provisioning based on revenue and cost metrics, to optimize profits for online retailers in the Cloud. The proposal relies on user behavior models that relate Quality-of-Service (QoS) to service capacity, and to the intention of users to buy a product on an Ecommerce site. We show how such metrics can enable profit-aware resource management by setting an optimal number of servers at each time of the day. Experiments are performed on custom, real-life datasets from an Ecommerce retailer contain over two years of access, performance, and sales data from popular travelWeb applications.},
  keywords={},
  doi={10.1109/CLUSTER.2014.6968746},
  ISSN={2168-9253},
  month={Sep.},}@INPROCEEDINGS{9719517,
  author={Nayak, Samaleswari Prasad and Rout, Suchismita and Das, Surajit and Patra, Sudhansu Shekhar},
  booktitle={2021 19th OITS International Conference on Information Technology (OCIT)}, 
  title={Error rate reduction of Air Quality Parameters in Health Care Industry using SD-IoT Environment}, 
  year={2021},
  volume={},
  number={},
  pages={454-459},
  abstract={The air quality index has a major impact on the health of a person. This parameter must be carefully monitored to take all the necessary arrangements to improve the environmental conditions. The error rate must be minimized for accurate data collection and processing. In this paper, an IoT -based air quality platform is designed with the name ‘'IAQM (Industry Air Quality Monitoring)”. This platform relies on IoT, SDN, and Cloud computing technology to monitor the air quality of the health care industry. Apart from the health care sector, this system can be used anywhere and anytime. We measure its performance metrics with existing AQMS. IAQM gives better performance than the existing approach as per the resultant graphs.},
  keywords={},
  doi={10.1109/OCIT53463.2021.00094},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8343082,
  author={Ibrahim, Abdallah A. Z. A. and Varrette, Sebastien and Bouvry, Pascal},
  booktitle={2018 International Conference on Information Networking (ICOIN)}, 
  title={PRESENCE: Toward a novel approach for performance evaluation of mobile cloud SaaS Web Services}, 
  year={2018},
  volume={},
  number={},
  pages={50-55},
  abstract={Cloud Services Providers (CSPs) deliver cloud services to cloud customers on a pay-per-use model. The quality of the provided services are defined using Service Level Agreements (SLAs). The recent developments around edge computing and the advent of mobile cloud computing platforms contribute to the success of this approach and the multiplication of offers. Unfortunately, despite the projections foreseeing a growing market for the coming years, there is no standard mechanism which exists to verify and assure that delivered services satisfy the signed SLA agreement. Accurate measures of the provided Quality of Service (QoS) is also missing most of time. In this context, we aim at offering an automatic framework named PRESENCE, to evaluate the QoS and SLA compliance of Web Services (WSs) offered across several CSPs. PRESENCE aims at quantifying in a fair and by stealth way the performance and scalability of the delivered WS. By stealthiness, we refer to the capacity of evaluating a given Cloud service by orchestrating multiple workload patterns that making them indistinguishable from a regular user traffic from the provider point of view. PRESENCE defines a set of Common performance metrics handled by a set of agents within a customized client (called the Auditor) for measuring the behaviour of cloud applications on top of a given CSP. This position paper offers a description of the PRESENCE framework, and the way each modules are foreseen to be designed. This opens novel perspectives for assessing the SLA compliance of Cloud providers using the PRESENCE framework.},
  keywords={},
  doi={10.1109/ICOIN.2018.8343082},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{7913123,
  author={Khurana, Ravi and Bawa, Rajesh Kumar},
  booktitle={2016 Fourth International Conference on Parallel, Distributed and Grid Computing (PDGC)}, 
  title={Quality based cloud simulators: State-of-the-art & road ahead}, 
  year={2016},
  volume={},
  number={},
  pages={101-106},
  abstract={Cloud Computing is an emerging technology nowadays. It has been used by many leading organisations. They deploy their critical information onto the cloud. Several challenges are associated with it like quality issues, security, energy consumption etc. Continuous research is going on to cater these issues. It is not easy to setup a cloud for any researcher or group of researchers, it needs huge investment. Big organisations having huge budgets can only afford that. To address these issues cloud simulators are really helpful. Cloud simulator is a simulating environment through which one can realize actual cloud environment. Data centers, virtual machines, hosts and networks can be setup virtually. Numbers of cloud simulators are there in the literature each offering different scenario. Cloudsim, a well known cloud simulator calculates start time, finish time and total time for execution of cloudlet. Another cloud simulator GreenCloud calculates energy consumption by data centers, hosts, switches and other network equipments. In the present paper, we focus on quality metrics addressed by cloud simulators. With each simulator, we will enlist quality metrics discussed by them. At the end, we conclude that there is a need to develop simulator which will address relevant quality metrics.},
  keywords={},
  doi={10.1109/PDGC.2016.7913123},
  ISSN={},
  month={Dec},}@ARTICLE{9220139,
  author={Feng, Jie Xu and Si, Guannan and Zhou, Fengyu},
  journal={IEEE Access}, 
  title={Overview and Framework of Quality Service Metrics for Cloud-Based Robotics Platforms}, 
  year={2020},
  volume={8},
  number={},
  pages={185885-185898},
  abstract={With the rapid development of big data, cloud computing and other technologies, Cloud-based robotic has become one of the key research directions for service robot, such as used in hospitals. A framework and set of metrics for evaluating the quality of service (QOS) of a cloud robotic platform would be greatly facilitate research into and actual practice of service robots. In this paper, a QOS metrics framework of cloud robotic computing is summarized and the research of components and metrics of a cloud robotic platform is reviewed. QOS metrics are organized into software, network, and robotic services. By summarizing and analyzing the above three groups of metrics, a QOS framework or index system is proposed. Finally, future research towards open source and standardization of components of robotic cloud platform is discussed.},
  keywords={},
  doi={10.1109/ACCESS.2020.3030069},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8058324,
  author={Upadhyaya, Jolly and Ahuja, Neelu Jyoti},
  booktitle={2017 International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)}, 
  title={Quality of service in cloud computing in higher education: A critical survey and innovative model}, 
  year={2017},
  volume={},
  number={},
  pages={137-140},
  abstract={Cloud Computing, an emerging trend, in the e-learning sector has attracted number of service providers to the market in very less time, providing users with several applications at their disposal. However, while providing such service, not sufficient importance is given to the quality of the service, especially from the user's point of view. Hence it becomes necessary to monitor, track and quantify the QoS of the cloud computing e-learning applications in order to provide the right information to both the customers and the service providers. This information would help both the parties in terms of the comparison between the expectations and the capacity to meet them, but in this sector there is no standard model which defines the QoS parameters from the user's point of view. Thus, the need arises for developing a metrics model for enhancing the quality of service in cloud computing e-learning applications for higher education sector. In the current work, Quality of Service models are studied and comprehensive review of work done in this field is presented. Additionally an innovative QoS model for resolving this issue has been suggested.},
  keywords={},
  doi={10.1109/I-SMAC.2017.8058324},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{8389549,
  author={Geetha, P. and Robin, C.R. Rene},
  booktitle={2017 International Conference on Energy, Communication, Data Analytics and Soft Computing (ICECDS)}, 
  title={A comparative-study of load-cloud balancing algorithms in cloud environments}, 
  year={2017},
  volume={},
  number={},
  pages={806-810},
  abstract={The enrichment knowledge of Cloud Computing is Green Cloud Computing. The term of Cloud Computing is a globally inter — connected networks of Computing Resources( Servers, Networks, Applications, Hardwares, Softwares). The Green Computing is an Environmental Benefits of eco-friendly usage of Computing Resources. The combination of Green Computing and Cloud computing is Green Cloud Computing. GCC performs both performance and efficiency. The combination of Mobile Computing and Cloud Computing is known as Mobile Cloud Computing. Now, the Computational science is changing to be data-intensive. So, Load balancing is a technique to distribute the load across a given Green Cloud Network Vs Mobile Cloud Network. In this proposed system, the in-depth analysis of Load Balancing Algorithms. The Load of Cloud Balancing is a process of reassigning the total load to the individual nodes in a given network. Then the Comparative study of load balancing algorithms with its quality metrics are summarized.},
  keywords={},
  doi={10.1109/ICECDS.2017.8389549},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8467224,
  author={Dhirani, Lubna Luxmi and Newe, Thomas and Nizamani, Shahzad},
  booktitle={2018 5th International Multi-Topic ICT Conference (IMTIC)}, 
  title={Hybrid Cloud Computing QoS Glitches}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={The Hybrid Cloud Computing model has been growing extensively due to its Infrastructure as a Service (IaaS) architecture, customisation and cost benefits. The hybrid cloud services are measured based on the Quality of Service parameters defined by the public cloud vendors. These parameters (i.e. availability, scalability, latency etc.) vary from vendor-to-vendor, developing complexity and confusion on the grounds of methods of service assessments. A Cloud Service Level Agreement (SLA) lists the QoS provisions to be provided to the tenant, the objectives, and exclusions. Regardless of vendors promised uptimes and service metrics, the tenants are susceptible to the following threats: data governance, Denial of Services, multi-tenancy, etc. Cloud computing has often been compared as a utility, but the basic different between a utility and the cloud is the amount of risk involved with data protection, provisioning and control. Few cloud standards have been developed for standardizing the hybrid cloud model but since each public cloud vendor provides different applications and services, these standards do not resolve the existing cloud QoS issue. Since each enterprise implementing the cloud and vendor supplying the services is diverse, a customized Trio (Cloud-IT-Business) QoS model is required to resolve the business need. The authors have designed a model to resolve this existing cloud QoS issue, the abstraction of the model is detailed in this paper.},
  keywords={},
  doi={10.1109/IMTIC.2018.8467224},
  ISSN={},
  month={April},}@INPROCEEDINGS{8611562,
  author={Shin, Young-Rok and Son, A-Young and Jo, Hyeok Kyun and Huh, Eui-Nam},
  booktitle={2018 Second World Conference on Smart Trends in Systems, Security and Sustainability (WorldS4)}, 
  title={Cloud Service Broker Based Quality Metrics Integration Model for Mobile Environment}, 
  year={2018},
  volume={},
  number={},
  pages={254-259},
  abstract={Mobile cloud computing is high technology that extends existing IT capabilities and requirements. And it can also access to shareable remote computing resources pool through the network. As the concept of mobile cloud, many providers have served the mobile cloud services using their own service policies. In other words, there is no formal definition of quality criteria for mobile cloud service evaluation. To solve this problem, some quality models are proposed for cloud service evaluation. However, those did not include many metrics to evaluate the services. Even if the model included a number of criteria, it is difficult to identify whether the metrics are proper or not. Furthermore, most existing models were not concerned about mobile characteristics. Therefore, we propose a cloud service integration model to solve the problem as we mentioned above. First, we select additional metrics to satisfy the mobile characteristics. Second, we present an extended SLA model for modeling complex service-dependencies in mobile cloud services. Third, we describe a method of discovering relations between the metrics of service belonging to mobile cloud services and then using these relations for establishing newly generated SLA.},
  keywords={},
  doi={10.1109/WorldS4.2018.8611562},
  ISSN={},
  month={Oct},}@ARTICLE{9178326,
  author={Ahamed Ahanger, Tariq and Tariq, Usman and Ibrahim, Atef and Ullah, Imdad and Bouteraa, Yassine},
  journal={IEEE Access}, 
  title={ANFIS-Inspired Smart Framework for Education Quality Assessment}, 
  year={2020},
  volume={8},
  number={},
  pages={175306-175318},
  abstract={In the education sector, the Internet of Things (IoT) technology, integrated with fog-cloud computing, has offered productive services. Motivated by this, the smart recommender system offers the facility to the students to opt for the course and college based on the education quality. This research provides an IoT-fog-cloud paradigm for evaluating the academic environment with a perspective to enhance quality education. Specifically, IoT technology is incorporated to gather data about the academic environment that directly and indirectly influence the quality of education. Using the Bayesian Modeling Technique, the data collected is analyzed utilizing a fog-cloud computing framework to quantify the measure of the probability of education quality (PoEQ). Moreover, the Education Quality Assurance Index (EQAI) is calculated to analyze the quality assessment over a temporal scale. Furthermore, predictive decision-making is performed for quality estimation using the Adaptive Neuro-Fuzzy Inference System (ANFIS). The experimental simulation on 4 challenging datasets namely C1 (2124 instances), C2 (2112), C3 (2139), and C4 (2109) shows the effectiveness of the proposed framework. Simulation findings are compared with state-of-the-art techniques to measure the overall performance enhancement of the proposed system. Also, the mathematical analysis was carried out to assess the analytical performance of the proposed framework.},
  keywords={},
  doi={10.1109/ACCESS.2020.3019682},
  ISSN={2169-3536},
  month={},}@ARTICLE{8207422,
  author={Noormohammadpour, Mohammad and Raghavendra, Cauligi S.},
  journal={IEEE Communications Surveys & Tutorials}, 
  title={Datacenter Traffic Control: Understanding Techniques and Tradeoffs}, 
  year={2018},
  volume={20},
  number={2},
  pages={1492-1525},
  abstract={Datacenters provide cost-effective and flexible access to scalable compute and storage resources necessary for today's cloud computing needs. A typical datacenter is made up of thousands of servers connected with a large network and usually managed by one operator. To provide quality access to the variety of applications and services hosted on datacenters and maximize performance, it deems necessary to use datacenter networks effectively and efficiently. Datacenter traffic is often a mix of several classes with different priorities and requirements. This includes user-generated interactive traffic, traffic with deadlines, and long-running traffic. To this end, custom transport protocols and traffic management techniques have been developed to improve datacenter network performance. In this tutorial paper, we review the general architecture of datacenter networks, various topologies proposed for them, their traffic properties, general traffic control challenges in datacenters and general traffic control objectives. The purpose of this paper is to bring out the important characteristics of traffic control in datacenters and not to survey all existing solutions (as it is virtually impossible due to massive body of existing research). We hope to provide readers with a wide range of options and factors while considering a variety of traffic control mechanisms. We discuss various characteristics of datacenter traffic control, including management schemes, transmission control, traffic shaping, prioritization, load balancing, multipathing, and traffic scheduling. Next, we point to several open challenges as well as new and interesting networking paradigms. At the end of this paper, we briefly review inter-datacenter networks that connect geographically dispersed datacenters, which have been receiving increasing attention recently and pose interesting and novel research problems. To measure the performance of datacenter networks, different performance metrics have been used, such as flow completion times, deadline miss rate, throughput, and fairness. Depending on the application and user requirements, some metrics may need more attention. While investigating different traffic control techniques, we point out the tradeoffs involved in terms of costs, complexity, and performance. We find that a combination of different traffic control techniques may be necessary at particular entities and layers in the network to improve the variety of performance metrics. We also find that despite significant research efforts, there are still open problems that demand further attention from the research community.},
  keywords={},
  doi={10.1109/COMST.2017.2782753},
  ISSN={1553-877X},
  month={Secondquarter},}@INPROCEEDINGS{7336367,
  author={Zhou, Ping and Wang, Zhipeng and Li, Wenjing and Jiang, Ning},
  booktitle={2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems}, 
  title={Quality Model of Cloud Service}, 
  year={2015},
  volume={},
  number={},
  pages={1418-1423},
  abstract={In recent years, services based on cloud computing have been used more and more widely. Stakeholders have paid more and more attention on the quality of cloud service. But most of them don't know how to evaluate the quality of cloud service. This paper proposes a comprehensive, structurized, and hierarchical quality model of cloud service, which concerned not only the IT features but also the service features of cloud service. The quality model was constructed by 6 characteristics, i.e., usability, security, reliability, tangibility, responsiveness, and empathy. We divided each characteristic into several subcharacteristics. In order to apply the cloud service model better, and to evaluate the service quality systematically, we provide a metrics framework for those subcharacteristics, which was made up of objective and subjective metrics. We give a brief intro to the methodology on evaluating the cloud service quality. We also illustrate the evaluation process with a case study.},
  keywords={},
  doi={10.1109/HPCC-CSS-ICESS.2015.134},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9711797,
  author={Padma, P. and Akshaya, RS. and Akshaya, H. and Harini, R.},
  booktitle={2021 4th International Conference on Computing and Communications Technologies (ICCCT)}, 
  title={Perlustrate Study on Cloud Security and Vulnerabilities}, 
  year={2021},
  volume={},
  number={},
  pages={293-296},
  abstract={In this modern technology,cloud computing plays an integral role which is also the fastest emerging technology. Cloud computing refers to manipulating,configuring and accessing the applications online. It offers online data storage,infrastructure and application. It is both a combination of software and hardware based computing resources delivered as a network service. High Quality services with improved performance and with reduced cost made the cloud computing a popular paradigm. Cloud computing has numerous advantages to the customer, like its ability to scale and recover from various problems agility and flexibility. As every technology emerges with its own pros and cons cloud computing is vulnerable to certain threats regarding security issues which makes the clients a lack of confidence to adopt cloud technologies. The main reason why companies are leaving the cloud is due to security concerns. Cloud security measures are often inadequate to protect sensitive data. This work aims at presenting a survey of various security issues faced by clients and the necessary measures to counter these threats.},
  keywords={},
  doi={10.1109/ICCCT53315.2021.9711797},
  ISSN={},
  month={Dec},}@ARTICLE{6740846,
  author={Zheng, Xianrong and Martin, Patrick and Brohman, Kathryn and Xu, Li Da},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={CLOUDQUAL: A Quality Model for Cloud Services}, 
  year={2014},
  volume={10},
  number={2},
  pages={1527-1536},
  abstract={Cloud computing is an important component of the backbone of the Internet of Things (IoT). Clouds will be required to support large numbers of interactions with varying quality requirements. Service quality will therefore be an important differentiator among cloud providers. In order to distinguish themselves from their competitors, cloud providers should offer superior services that meet customers' expectations. A quality model can be used to represent, measure, and compare the quality of the providers, such that a mutual understanding can be established among cloud stakeholders. In this paper, we take a service perspective and initiate a quality model named CLOUDQUAL for cloud services. It is a model with quality dimensions and metrics that targets general cloud services. CLOUDQUAL contains six quality dimensions, i.e., usability, availability, reliability, responsiveness, security, and elasticity, of which usability is subjective, whereas the others are objective. To demonstrate the effectiveness of CLOUDQUAL, we conduct empirical case studies on three storage clouds. Results show that CLOUDQUAL can evaluate their quality. To demonstrate its soundness, we validate CLOUDQUAL with standard criteria and show that it can differentiate service quality.},
  keywords={},
  doi={10.1109/TII.2014.2306329},
  ISSN={1941-0050},
  month={May},}@INPROCEEDINGS{7427071,
  author={Khan, Hassan Mahmood and Chan, Gaik-Yee and Chua, Fang-Fang},
  booktitle={2016 International Conference on Information Networking (ICOIN)}, 
  title={An adaptive monitoring framework for ensuring accountability and quality of services in cloud computing}, 
  year={2016},
  volume={},
  number={},
  pages={249-253},
  abstract={Cloud computing platform has gained popularity among service providers and consumers to perform business operations due to the ease of communication and transaction convenience in terms of accessibility and availability. However, due to the vulnerability of this dynamic open environment, it is crucial to have a binding agreement between all the service parties for ensuring trust while fulfilling the expected Quality of Services (QoS). There is a need to improve on the current Service Level Agreements (SLAs) practice which does not focus on the QoS and accountability assurance. In this paper, we propose an adaptive monitoring framework to dynamically monitor QoS metrics and performance measures to verify compliances to the respective SLAs. The framework is validated with scenarios on response time and availability which shown to provide adaptive remedy action to rectify violation situation. Besides, any service party which establishes non-compliance to SLAs shall be penalized in monetary terms.},
  keywords={},
  doi={10.1109/ICOIN.2016.7427071},
  ISSN={},
  month={Jan},}@INBOOK{9116755,
  author={Wu, Chu‐ge and Wang, Ling},
  booktitle={Fog Computing: Theory and Practice: Theory and Practice}, 
  title={An Estimation of Distribution Algorithm to Optimize the Utility of Task Scheduling Under Fog Computing Systems}, 
  year={2020},
  volume={},
  number={},
  pages={371-384},
  abstract={The Internet of Things (IoT) is realized initially today. A large amount of data is produced and a range of IoT services are settled down. Based on it, a range of responsive IoT applications arise. To satisfy the quality of experience (QoE) of users, the applications are needed to be processed in a timely manner. Compared with traditional cloud computing systems, fog computing is one of the promising solutions to processing the huge amount of local data and decreasing the end‐to‐end latency. Different time‐dependent functions are adopted to measure the utility of different tasks and in this work, the resource allocation and task scheduling problem under the fog system is considered to maximize the sum of the utility of tasks. And an estimation of distributed algorithm to maximum the task utility (uEDA) with a repair procedure and local search is adopted to determine the task processing order and computing node allocation. The comparative results show that the performance of our algorithm exceeds significantly the heuristic method on the utility metrics.},
  keywords={},
  doi={10.1002/9781119551713.ch14},
  ISSN={},
  publisher={Wiley},
  isbn={},
  url={https://ieeexplore.ieee.org/document/9116755},}@INPROCEEDINGS{6974100,
  author={Brilhante, Jonathan and Silva, Bruno and Maciel, Paulo and Zimmermann, Armin},
  booktitle={2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={Dependability models for Eucalyptus infrastructure clouds considering VM life-cycle}, 
  year={2014},
  volume={},
  number={},
  pages={1336-1341},
  abstract={Managing a cloud computing provider is a difficult task, which involves the control and maintenance of several components, such as computers, network infrastructures and software components. In these environments, availability, security and low costs are important requirements to achieve high quality of service. Therefore, the evaluation of these systems is important to find a configuration that meets the constraints of users and provider. A widely adopted strategy to evaluate cloud computing systems consists by the utilization of stochastic models (e.g., stochastic Petri nets - SPN) to assess the concern metrics. In this context, Eucalyptus is an open source private cloud software for building private and hybrid clouds. This work presents dependability models for evaluation on Eucalyptus clouds. These models focus on the user point of view metrics (e.g., number of running virtual machines) to assess the dependability metrics. In order to demonstrate the feasibility of the proposed models, we evaluate a real world environment and validate the presented models by using Eucabomber tool version 2.0.},
  keywords={},
  doi={10.1109/SMC.2014.6974100},
  ISSN={1062-922X},
  month={Oct},}@ARTICLE{8131852,
  author={Hussain, Omar Khadeer and Rahman, Zia-ur- and Hussain, Farookh Khadeer and Singh, Jaipal and Janjua, Naeem Khalid and Chang, Elizabeth},
  journal={The Computer Journal}, 
  title={A User-Based Early Warning Service Management Framework in Cloud Computing}, 
  year={2015},
  volume={58},
  number={3},
  pages={472-496},
  abstract={Cloud computing is a very attractive option for service users and service providers for their businesses because of the benefits it provides. A major concern among service users regarding cloud adoption, however, is the unpredictability of performance in relation to the services provided. Even though guarantees in the form of service-level agreements are provided to users by service providers, real-time service-level degradability remains a critical concern; hence, there is a need for an approach that assists users to manage a service before it fails. The approaches proposed in the literature assess and evaluate the performance of the cloud infrastructure of providers, but this does not guarantee that a given service instance will meet the desired quality level because there may be factors other than the provider's infrastructure that will affect the level of quality of the service instance. In this paper, we present an approach that measures the quality of a service instance in real time and provides important analysis for service users as to whether they will achieve their desired objectives. This analysis also constitutes an important input for service users in the assessment and management of a service to avoid the failure to achieve objectives.},
  keywords={},
  doi={10.1093/comjnl/bxu064},
  ISSN={1460-2067},
  month={March},}@INPROCEEDINGS{8251864,
  author={Gustamas, R. Gargista and Shidik, Guruh Fajar},
  booktitle={2017 International Seminar on Application for Technology of Information and Communication (iSemantic)}, 
  title={Analysis of network infrastructure performance on cloud computing}, 
  year={2017},
  volume={},
  number={},
  pages={169-174},
  abstract={Cloud Computing offers more convenience than conventional that provide custom Virtual Machine (VM) for any computation requirements. Network connectivity is closely related to the quality of cloud infrastructure itself. This paper focus in preliminary study to test the performance of cloud infrastructure with two type test. First test to measure Network performance and the second to measure cloud computation performance. OpenStack was used as cloud computing software infrastructure. We perform simple cloud infrastructure topology which is divided into three zones, there are Internal Zone, External Zone and Outside Cloud Infrastructure Zone. The parameter tested in this research are quality of bandwidth, latency, jitter and also Processing time during rendering process. The results show VM from simple topology cloud computing which is used to render video, able to perform processing time that slightly longer than using personal computer (PC) with same specification. The network side has been considering as a key of degradation render performance in cloud computing.},
  keywords={},
  doi={10.1109/ISEMANTIC.2017.8251864},
  ISSN={},
  month={Oct},}@ARTICLE{9070142,
  author={Xu, Jianwen and Ota, Kaoru and Dong, Mianxiong},
  journal={China Communications}, 
  title={A real plug-and-play fog: Implementation of service placement in wireless multimedia networks}, 
  year={2019},
  volume={16},
  number={10},
  pages={191-201},
  abstract={Initially as an extension of cloud computing, fog computing has been inspiring new ideas about moving computing tasks to the edge of networks. In fog, we often repeat the procedure of placing services because of the geographical distribution of mobile users. We may not expect a fixed demand and supply relationship between users and service providers since users always prefer nearby service with less time delay and transmission consumption. That is, a plug-and-play service mode is what we need in fog. In this paper, we put forward a dynamic placement strategy for fog service to guarantee the normal service provision and optimize the Quality of Service (QoS). The simulation results show that our strategy can achieve better performance under metrics including energy consumption and end-to-end latency. Moreover, we design a real Plug-and-Play Fog (PnPF) based on Raspberry Pi and OpenWrt to provide fog services for wireless multimedia networks.},
  keywords={},
  doi={10.23919/JCC.2019.10.012},
  ISSN={1673-5447},
  month={Oct},}@ARTICLE{8130579,
  author={Kumar, Neeraj and Chilamkurti, Naveen and Zeadally, Sherali and Jeong, Young-Sik},
  journal={The Computer Journal}, 
  title={Achieving Quality of Service (QoS) Using Resource Allocation and Adaptive Scheduling in Cloud Computing with Grid Support}, 
  year={2014},
  volume={57},
  number={2},
  pages={281-290},
  abstract={In the past few years, cloud computing has emerged as a new reliable, scalable and flexible virtual computing environment (VCE). In this new VCE, users can use the available resources as a service by paying for that service according to the time for which these resources are used. It remains a significant challenge to achieve quality of service (QoS) in a VCE with the available resources. The main goal is to schedule the available resources so that the overall QoS delivered by the VCE can be improved. Resources are assumed to be located both at local and global sites. We propose a three-step scheme: resource selection, scheduling of users requests with shared resources and a new Resource Allocation and Adaptive Job Scheduling algorithm, which improves the QoS delivered by the cloud. For job scheduling, we define a new weight metric that is used to efficiently schedule jobs competing for available resources. Our proposed strategy increases the reliability of resource availability for a job and reduces the job completion time, which in turn increases the QoS delivered to end-users. We evaluate our proposed scheme using well-known heuristics. The results obtained show that our proposed scheme considerably reduces the job execution time, and increases the reliability of resource availability for job execution and throughput.},
  keywords={},
  doi={10.1093/comjnl/bxt024},
  ISSN={1460-2067},
  month={Feb},}@INPROCEEDINGS{7852595,
  author={Rodziah binti Atan},
  booktitle={2016 2nd International Conference on Science in Information Technology (ICSITech)}, 
  title={Enhancing service quality through Service Level Agreement (SLA) full implementation}, 
  year={2016},
  volume={},
  number={},
  pages={1-1},
  abstract={Various SLA monitoring systems are proposed by different features and abilities to evaluate the agreed SLA. The current SLA monitoring systems in cloud computing for its structural, behavioral characteristics and situation are also in place. The systematic reviews of a well-known methods and approaches shows a significant numbers of researches been done in this area. Based on the number of effort and researches, the quality of services should proportionately increase alongside them. We look this matter from the perspectives of enforcement, that evident the stand of quality of services. Service Level Agreement (SLA) enforcement impact measures is a potential research area to be explored. Assumptions that this study is making are, SLA management will become better by a firm enforcement, where every customers are responsible to launch report of bugs or mischief of services such as unsatisfactory quality or service unavailability to a collection pool, and the provider will react immediately to the complaints so that the total downtime not exceeding the SLA value, with efficient enforcement. This study establishes fundamental theory to measure enforcement impact to SLA monitoring and management. We proposed eight activity phases from formulating until analyzing and decision formation. Descriptive statistics is utilized to analyze the extracted data. The SLA validation detection is the most frequent purpose of SLA monitoring systems in cloud by 58% and throughput is checked as an attribute target by 28%. The self-monitoring SLA, self-healing system, hierarchical structure are recognized points of SLA monitoring systems which need improvement before the enforcement could be based upon.},
  keywords={},
  doi={10.1109/ICSITech.2016.7852595},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{7193080,
  author={Vijayakumar, N and Ramya, R},
  booktitle={2015 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS)}, 
  title={The real time monitoring of water quality in IoT environment}, 
  year={2015},
  volume={},
  number={},
  pages={1-5},
  abstract={In order to ensure the safe supply of the drinking water the quality needs to be monitor in real time. In this paper we present a design and development of a low cost system for real time monitoring of the water quality in IOT(internet of things). The system consist of several sensors is used to measuring physical and chemical parameters of the water. The parameters such as temperature, PH, turbidity, conductivity, dissolved oxygen of the water can be measured. The measured values from the sensors can be processed by the core controller. The raspberry PI B+ model can be used as a core controller. Finally, the sensor data can be viewed on internet using cloud computing.},
  keywords={},
  doi={10.1109/ICIIECS.2015.7193080},
  ISSN={},
  month={March},}@INPROCEEDINGS{7159459,
  author={Vijayakumar, N and Ramya, R},
  booktitle={2015 International Conference on Circuits, Power and Computing Technologies [ICCPCT-2015]}, 
  title={The real time monitoring of water quality in IoT environment}, 
  year={2015},
  volume={},
  number={},
  pages={1-4},
  abstract={In order to ensure the safe supply of the drinking water the quality needs to be monitor in real time. In this paper we present a design and development of a low cost system for real time monitoring of the water quality in IOT(internet of things).the system consist of several sensors is used to measuring physical and chemical parameters of the water. The parameters such as temperature, PH, turbidity, conductivity, dissolved oxygen of the water can be measured. The measured values from the sensors can be processed by the core controller. The raspberry PI B+ model can be used as a core controller. Finally, the sensor data can be viewed on internet using cloud computing.},
  keywords={},
  doi={10.1109/ICCPCT.2015.7159459},
  ISSN={},
  month={March},}@INPROCEEDINGS{9302797,
  author={Flinck Lindström, Sebastian and Wetterberg, Markus and Carlsson, Niklas},
  booktitle={2020 IEEE/ACM 13th International Conference on Utility and Cloud Computing (UCC)}, 
  title={Cloud Gaming: A QoE Study of Fast-paced Single-player and Multiplayer Gaming}, 
  year={2020},
  volume={},
  number={},
  pages={34-45},
  abstract={Cloud computing offers an attractive solution for modern computer games. By moving the increasingly demanding graphical calculations (e.g., generation of real-time video streams) to the cloud, consumers can play games using small, cheap devices. While cloud gaming has many advantages and is increasingly deployed, not much work has been done to understand the underlying factors impacting players' user experience when moving the processing to the cloud. In this paper, we study the impact of the quality of service (QoS) factors most affecting the players' quality of experience (QoE) and in-game performance. In particular, these relationships are studied from multiple perspectives using complementing analysis methods applied on the data collected via instrumented user tests. During the tests, we manipulated the players' network conditions and collected low-level QoS metrics and in-game performance, and after each game, the users answered questions capturing their QoE. New insights are provided using different correlation/auto-correlation/cross-correlation statistics, regression models, and a thorough breakdown of the QoS metric most strongly correlated with the users' QoE. We find that the frame age is the most important QoS metric for predicting in-game performance and QoE, and that spikes in the frame age caused by large frame transfers can have extended negative impact as they can cause processing backlogs. The study emphasizes the need to carefully consider and optimize the parts making up the frame age, including dependencies between the processing steps. By lowering the frame age, more enjoyable gaming experiences can be provided.},
  keywords={},
  doi={10.1109/UCC48980.2020.00023},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9702517,
  author={Chauhan, Rishabh and Kumar, Sunil},
  booktitle={2021 5th International Conference on Information Systems and Computer Networks (ISCON)}, 
  title={Packet Loss Prediction Using Artificial Intelligence Unified with Big Data Analytics, Internet of Things and Cloud Computing Technologies}, 
  year={2021},
  volume={},
  number={},
  pages={01-06},
  abstract={Big Data Analytics, Artificial Intelligence and cloud computing all together has emerged with an ultimate goal of automating and changing human life by providing their services. These incredibly strong technologies have huge potential by working together, making human life simpler and advanced. To increase the popularity of any of these services, Quality of Service metrics are needed to be defined clear. One of those quality metrics is packet loss or packet delivery, which is the main research idea of this paper. With advancement in Intelligent Network there exists a scope to predict packet loss, by analyzing the recorded network traffic and processing said data under certain machine learning algorithms to create a model to either predict packet loss or tell which variable is responsible for packet loss. This paper includes the study of packet loss behavior of networks. The Analytics techniques applied successfully by analyzing big network traffic data, processing of data, using AI and Machine Learning classifier “XGBoost” and hence designed a model to predict Packet loss which is a QoS metric with an accuracy of 90 percent. The model is personalized to work on WireShark data.},
  keywords={},
  doi={10.1109/ISCON52037.2021.9702517},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9284541,
  author={Martins, Wictor Souza and Tardiole Kuehne, Bruno and Sobrinho, Rafael Ferreira and Preti, Fábio},
  booktitle={2020 IEEE International Conference on Services Computing (SCC)}, 
  title={A Reference Method for Performance Evaluation in Big Data Architectures}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper presents a reference method for performance evaluation in Big Data architectures, called by Improvement Method for Big Data Architectures (IMBDA) aiming to increase the performance, and consequently raising the quality of service provided. The method will contribute to small businesses and startups that have limited financial re-sources (impossible to invest in market solutions). The proposed approach considers the relationship of the processes in a data processing flow to find possible bottlenecks and optimization points. To this end, IMBDA collects system logs to compose functional metrics (e.g., processing time) and non-functional metrics (e.g., CPU and memory utilization, and other cloud computing infrastructure resources). The system stores these metrics in an external data analysis tool that investigates the correlation of performance between processes. The reference method applies to the architecture of a Big Data application, which provides solutions in fleet logistics. With the use of IMBDA, it was possible to identify performance bottlenecks, allowing the reconfiguration of the architecture to increase service quality at the lowest possible cost.},
  keywords={},
  doi={10.1109/SCC49832.2020.00044},
  ISSN={2474-2473},
  month={Nov},}@INPROCEEDINGS{7536961,
  author={Chaemin Seong and Minsoo Jang and Kyungshik Lim},
  booktitle={2016 Eighth International Conference on Ubiquitous and Future Networks (ICUFN)}, 
  title={Context-aware HTTP Adaptive Streaming in mobile cloud environments}, 
  year={2016},
  volume={},
  number={},
  pages={1062-1067},
  abstract={With advances of cloud computing, seamless video streaming from video server to cloud client has been one of technical challenges for multimedia cloud applications. Especially in case that Desktop-as-a-Service (DaaS) as a major cloud application is deployed via wireless networks, it could raise a new set of issues to be addressed. To solve the problem, we propose a Cloud-based Context-aware HTTP Adaptive Streaming (C2HAS) agent located at cloud server. The goal of the agent is to maximize the video quality of seamless streaming perceived by cloud client, given a dynamically changing network context. From network context we derive a major metric for adapting and maximizing the video quality perceived by cloud clients, which is the throughput ratio of backbone networks and access networks. Based on the metric, we can provide a maximal quality of seamless video streaming to cloud users who might be connected via distant and/or lossy wireless links. The experimental performance analysis shows that the C2HAS agent could be a viable solution for cloud-based multimedia applications.},
  keywords={},
  doi={10.1109/ICUFN.2016.7536961},
  ISSN={2165-8536},
  month={July},}@INPROCEEDINGS{9333865,
  author={Han, Jaehyun and Zhu, Guangyu and Lee, Eunseo and Lee, Sangmook and Son, Yongseok},
  booktitle={2021 International Conference on Information Networking (ICOIN)}, 
  title={An Empirical Evaluation and Analysis of Performance of Multiple Optane SSDs}, 
  year={2021},
  volume={},
  number={},
  pages={541-545},
  abstract={Cloud Computing as a service-on-demand architecture has grown in importance over the previous few years. The storage subsystem in cloud computing has undergone enormous innovation in order to provide high-quality cloud services. Emerging non-volatile memory express (NVMe) technology has a considerable attraction in cloud computing by delivering high I/O performance in terms of latency and bandwidth. Especially, multiple NVMe SSDs can provide higher performance, fault tolerance, and storage capacity in the cloud computing environment. In this paper, we perform an empirical evaluation study of performance on recent NVMe SSDs (i.e., Intel Optane SSDs) with different RAID environments. We analyze the performance of the multiple NVMe SSDs with RAID in terms of different performance metrics via micro and macro benchmarks. We anticipate that the experimental results and performance analysis will provide the implications on various storage systems.},
  keywords={},
  doi={10.1109/ICOIN50884.2021.9333865},
  ISSN={1976-7684},
  month={Jan},}@INPROCEEDINGS{8883458,
  author={Biondi, Katalina and Al-Masri, Eyhab and Baiocchi, Orlando and Jeyaraman, Suganya and Pospisil, Eric and Boyer, Graham and de Souza, Cleonilson Protasio},
  booktitle={2019 International Conference in Engineering Applications (ICEA)}, 
  title={Air Pollution Detection System using Edge Computing}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={Existing solutions to measuring air quality can be expensive and potentially mutes high air pollution events. The IoT Pollution Project is exploring how IoT concepts can be applied with smart systems to detect pollution in real-time. Using a network of Raspberry Pi prototypes, the project aims to measure heavily populated areas around the City of Tacoma, while building a real-time interface measuring current air quality. The project also explores the use of edge computing as an alternative to cloud computing. The vast expansion of IoT devices poses threats to the infrastructure of cloud computing as more devices process and store data to the cloud. The project demonstrates how edge devices can alleviate the work done on the cloud by calculating rolling averages over a time interval on the edge device and then deploying the data to the cloud. The project uses Microsoft Azure Framework, IoT concepts and edge computing concepts to build the project architecture.},
  keywords={},
  doi={10.1109/CEAP.2019.8883458},
  ISSN={},
  month={July},}@INPROCEEDINGS{8073634,
  author={Muralitharan, D. Boobala and Reebha, S. Arockia Babi and Saravanan, D.},
  booktitle={2017 International Conference on IoT and Application (ICIOT)}, 
  title={Optimization of performance and scheduling of HPC applications in cloud using cloudsim and scheduling approach}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={Cloud computing is emerging as a promising alternative to supercomputers for some High-Performance Computing (HPC) applications. Cloud computing is an essential component of the back bone of the Internet of Things (IoT). Clouds are needed to support huge numbers of interactions with varying quality requirements. Hence, Service quality will be a vital differentiator among cloud providers. In order to differentiate themselves from their competitors, cloud providers should offer best services that meet customers' expectations. A quality model can be used to represent, measure and compare the quality of the providers, such that a mutual understanding can be established among clouds take holders. With cloud as an additional deployment option, HPC users and providers faces the challenges of dealing with highly heterogeneous resources, where the variability spans across a wide range of processor configurations, interconnects, virtualization environments, and pricing models. HPC applications are increasingly being used in academia and laboratories for scientific research and in industries for business and analytics. Cloud computing offers the benefits of virtualization, elasticity of resources and elimination of cluster setup cost and time to HPC applications users. Effort was taken for holistic viewpoint to answer the questions - why and who should choose cloud for HPC, for what applications and how the cloud can be used for HPC? Comprehensive performance and cost evaluation and analysis of running a set of HPC applications on a range of platforms, varying from supercomputers to clouds was carried out. Further, performance of HPC applications is improved in cloud by optimizing HPC applications' characteristics for cloud and cloud virtualization mechanisms for HPC. In this paper, a novel heuristics for online application-aware job scheduling in multi-platform environments is presented. Experimental results and Simulations using CloudSim show that current clouds cannot substitute supercomputers but can effectively complement them.},
  keywords={},
  doi={10.1109/ICIOTA.2017.8073634},
  ISSN={},
  month={May},}@INPROCEEDINGS{8920865,
  author={Hlaing, Yamin Thet Htar and Yee, Tin Tin},
  booktitle={2019 International Conference on Advanced Information Technologies (ICAIT)}, 
  title={Static Independent Task Scheduling on Virtualized Servers in Cloud Computing Environment}, 
  year={2019},
  volume={},
  number={},
  pages={55-59},
  abstract={Cloud Computing is the advanced design of client-server computing, cluster computing and grid computing. The cloud providers provide cloud services mainly as Infrastructure as a Service (IaaS), Platform as a Service (PaaS), Software as a Service (SaaS) to the users who can access publicly, privately or hybrid via the Internet. In Cloud computing, there are many research areas like task scheduling, allocation of resource, security and privacy etc. Task scheduling is a vital area in the cloud computing, and it must be optimized by considering different parameters. Nowadays, there are a lot of different scheduling algorithms to minimize execution time and cost, to improve the quality of service, system performance and to maximize resource utilization and load balancing, etc. This paper proposed a Static Independent Task Scheduling on Virtualized Servers in Cloud Computing Environment in which tasks are allocated to the suitable VM by measuring the availability of each resource with respect to its processing power, cost and the number of available processing elements and by grouping tasks according to their instruction length. This method is simulated on Cloud Simulator (Cloudsim toolkit) and results show the proposed method that maximizes total execution time and minimizes execution cost for all tasks than scheduling algorithms such as Shortest Job First (SJF) and First Come First Serve (FCFS) algorithms.},
  keywords={},
  doi={10.1109/AITC.2019.8920865},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{7566494,
  author={Chandu P.M.S.S and Kata, Divyasree},
  booktitle={2016 International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET)}, 
  title={Integrating and enhancing the quality of services in cloud computing with software testing}, 
  year={2016},
  volume={},
  number={},
  pages={2008-2010},
  abstract={Cloud computing involves to delivering the hosted services throughout the internet. Testing tools are used to test the desktop applications, web applications and the cloud based software systems that are used to address the quality of the cloud infrastructure such as tremendous extensibility and aggressive composition. In the existing paper it is not providing the quality of services in the effective manner. In this paper we focused on integrating the software metrics for getting the quality of services, in terms of speed, memory size, RAM, ROM size and we are also using the D-cloud and prefail testing tools to perform the fault tolerance and recovery testing. By using OVMP algorithm we are minimizing the cost spending for services and load prediction algorithm and it is also used to reduce the load. The aim is to extend the above framework with cross cloud testing scenario involving communications between heterogeneous cloud hosts. The results shows that the cloud environment ensures more flexible and quality of services.},
  keywords={},
  doi={10.1109/WiSPNET.2016.7566494},
  ISSN={},
  month={March},}@INPROCEEDINGS{8097142,
  author={Jelassi, Mariem and Ghazel, Cherif and Saïdane, Leila Azzouz},
  booktitle={2017 3rd International Conference on Frontiers of Signal Processing (ICFSP)}, 
  title={A survey on quality of service in cloud computing}, 
  year={2017},
  volume={},
  number={},
  pages={63-67},
  abstract={The quality of service is one of challenges posed by the Cloud Computing. This issue plays an important role in making the Cloud services acceptable to customers, denotes the levels of performance, reliability, and availability offered by Cloud services. Literature has reported many implementations for measuring and ensuring QoS in Cloud Computing systems to achieve better results and meet the needs of producers and consumers. In this paper, we have presented a survey on QoS in Cloud Computing, the mechanisms and methods to guarantee quality of service (QoS) used to Cloud Computing services.},
  keywords={},
  doi={10.1109/ICFSP.2017.8097142},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{7924927,
  author={Yazhou Hu and Bo Deng and Fuyang Peng},
  booktitle={2016 2nd IEEE International Conference on Computer and Communications (ICCC)}, 
  title={Autoscaling prediction models for cloud resource provisioning}, 
  year={2016},
  volume={},
  number={},
  pages={1364-1369},
  abstract={The elasticity mechanism of cloud computing can auto scale cloud resources to meet users' need. Elastic adding or removing virtual machines is the most common method to achieve the auto scaling. But the elastic scaling often takes tens of minutes, which is inefficient for the running workload. To reduce the latency and improve the quality of service (QoS), the new virtual machine should be provisioned when the request arrives. In this paper, we present a prediction framework for virtual machines provisioning. This prediction framework includes three main modules: monitor, filter and predictor. This framework aims to predict the upcoming workload and provision the virtual machines in advance. To get the reasonable monitored metrics, we propose the Kalman filter method to preprocess the raw data. Moreover, we present five different prediction models as the based predictor. These prediction models include moving average (MA), auto regression (AR), auto regression integrated moving average (ARIMA), neural networks (NN) and support vector machine (SVM). Meanwhile, we propose four evaluation metrics, including the prediction error, the time saving, under-prediction resource and over-prediction resource, to evaluate the performance of prediction framework. In addition, we use Alicloud as the experimental infrastructure. Experimental results demonstrate that the prediction framework can reduce the latency of provisioning cloud resource and improve the cloud service quality.},
  keywords={},
  doi={10.1109/CompComm.2016.7924927},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9369609,
  author={Heideker, Alexandre and Kamienski, Carlos},
  booktitle={2021 IEEE 18th Annual Consumer Communications & Networking Conference (CCNC)}, 
  title={Towards a Network Queuing Assessment for Elasticity Management of Virtualized Services}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={With the increasing adoption of cloud computing, microservice architecture, and network function virtualization (NFV), addressing scalability and elasticity management becomes essential. The high demand for these services challenges the research community to create new automated management techniques, from which an essential part is the detection of bottlenecks in infrastructures and application boxes. The traditional approach based on hardware resource metrics (CPU and RAM) is the most straightforward strategy, providing independence from particular applications but may not capture the application's behavior in terms of workload variations. On the other hand, using an application-oriented approach provides a significant correlation with the end-user quality of experience but needs to be tailored for each case. We propose the Network Queuing Assessment (NQA) that breaks away with this tradeoff, capturing the application's workload variations and providing a significant correlation with the end-user quality of experience. Also, similarly to CPU and RAM, it is independent of particular applications. Our performance analysis results for CPU, RAM, and NQA metrics using virtualized applications and network functions in a cloud environment confirm this approach's usefulness.},
  keywords={},
  doi={10.1109/CCNC49032.2021.9369609},
  ISSN={2331-9860},
  month={Jan},}@INPROCEEDINGS{9397031,
  author={Haque, Halima and Labeeb, Kashshaf and Riha, Rabea Basri and Khan, Md. Nasfikur R.},
  booktitle={2021 International Conference on Emerging Smart Computing and Informatics (ESCI)}, 
  title={IoT Based Water Quality Monitoring System By Using Zigbee Protocol}, 
  year={2021},
  volume={},
  number={},
  pages={619-622},
  abstract={This paper dictates the damages caused by water and what can be done to resolve those issues by involving the Internet of things (IoT). Keeping the quality of water in check is today's ultimate objective. Thereby, to guarantee safe drinking water supply, the quality of water should be observed regularly. The use of IoT based solution, focused mainly on water quality monitoring has therefore been suggested. In order to support the issue, an IoT-based water quality checking network has been introduced that continuously monitors and evaluates the quality of water and tries to distinguish whether it is up to the mark for general use. This paper includes the use of specific sensors that calculates the various parameters of the quality of water which includes conductivity and dissolved oxygen (DO), turbidity, pH, and temperature. The values from the sensors have been measured and calculated using the microcontrollers. Then these processed remote values have been transmitted to the raspberry pi, the central controller which uses the Zigbee protocol. Lastly, all the data from the sensors are then accessible via cloud computing through any browser, on request.},
  keywords={},
  doi={10.1109/ESCI50559.2021.9397031},
  ISSN={},
  month={March},}@INPROCEEDINGS{9604373,
  author={Wang, Lei and He, Qiang and Gao, Demin and Wan, Jing and Zhang, Yunqiu},
  booktitle={2021 IEEE World Congress on Services (SERVICES)}, 
  title={Temporal-Perturbation aware Reliability Sensitivity Measurement for Adaptive Cloud Service Selection}, 
  year={2021},
  volume={},
  number={},
  pages={8-8},
  abstract={Benefiting from the pay-as-you-go business model, cloud computing has significantly promoted service computing techniques in real-world industrial applications. Software applications based on cloud computing are becoming more and more popular. By integrating existing component cloud services through the internet, composite cloud systems can be built to meet sophisticated application logic. Stable execution of such systems is desirable in the long term so that the service-level agreements (SLAs), as well as users’ quality of experience (QoE), can be fulfilled. To achieve this goal, it is critical to identify and fault-tolerate system components at high risks of failing. This is extremely challenging due to the dynamic and uncertainty of the cloud environment that hosts the component cloud services. Nevertheless, existing approaches pay little attention to the modeling and analysis of system components’ reliability time series. To address the above issues, we first present a reliability evaluation method for component cloud services based on the reliability model and their failure probability under continuous client-side invocation tests. Then, we propose a perturbation-aware reliability sensitivity measurement approach (named PARS) for measuring the reliability sensitivity of component cloud services. It first analyzes the negative perturbations in component cloud services’ historical reliability time series based on the Markov chain rule. Then, it calculates the reliability sensitivity of component cloud services by analyzing how their reliability perturbations impact the reliability of the entire cloud system. To guarantee the execution quality of the composite cloud system, we further propose a proactive adaptation approach named PA-PARS that enables 1-out-of-2 N-version Programming fault-tolerance for composite cloud systems based on PARS. PA-PARS takes the reliability sensitivity of component cloud services estimated by PARS as input to assure the reliability of the cloud system. It consists of four parts: 1) risky system component identification; 2) adaptation trigger; 3) candidate component cloud service selection; and 4) NVP-based system construction as the proactive adaptation for the composite cloud system. The results of experiments conducted on two widely-used datasets demonstrate the effectiveness and efficiency of the proposed approaches in ensuring the reliability of composite cloud systems.},
  keywords={},
  doi={10.1109/SERVICES51467.2021.00019},
  ISSN={2642-939X},
  month={Sep.},}@ARTICLE{7355287,
  author={Zuo, Liyun and Shu, Lei and Dong, Shoubin and Zhu, Chunsheng and Hara, Takahiro},
  journal={IEEE Access}, 
  title={A Multi-Objective Optimization Scheduling Method Based on the Ant Colony Algorithm in Cloud Computing}, 
  year={2015},
  volume={3},
  number={},
  pages={2687-2699},
  abstract={For task-scheduling problems in cloud computing, a multi-objective optimization method is proposed here. First, with an aim toward the biodiversity of resources and tasks in cloud computing, we propose a resource cost model that defines the demand of tasks on resources with more details. This model reflects the relationship between the user's resource costs and the budget costs. A multi-objective optimization scheduling method has been proposed based on this resource cost model. This method considers the makespan and the user's budget costs as constraints of the optimization problem, achieving multi-objective optimization of both performance and cost. An improved ant colony algorithm has been proposed to solve this problem. Two constraint functions were used to evaluate and provide feedback regarding the performance and budget cost. These two constraint functions made the algorithm adjust the quality of the solution in a timely manner based on feedback in order to achieve the optimal solution. Some simulation experiments were designed to evaluate this method's performance using four metrics: 1) the makespan; 2) cost; 3) deadline violation rate; and 4) resource utilization. Experimental results show that based on these four metrics, a multi-objective optimization method is better than other similar methods, especially as it increased 56.6% in the best case scenario.},
  keywords={},
  doi={10.1109/ACCESS.2015.2508940},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7976761,
  author={Bashar, Abul},
  booktitle={2017 IEEE 7th International Advance Computing Conference (IACC)}, 
  title={BN-Based Approach for Predictive Admission Control of Cloud Services}, 
  year={2017},
  volume={},
  number={},
  pages={59-64},
  abstract={A phenomenal growth in the demand for Cloud Computing services by the cloud consumers has necessitated the efficient and proactive management of the data center hosted services having varied characteristics. One of the major issues concerning both the cloud service providers and consumers is the provisioning of highest level of Quality of Service (QoS) under unpredictable service demands, while maintaining required revenue targets. Traditional Admission Control (AC) approaches which are usually mathematical or analytical in nature, have limited performance levels in the situations where service types, QoS parameters and user demands become highly unpredictable. To this end, an opportunity exists to utilize the self-learning capabilities of Machine Learning (ML) approaches to incorporate predictive and adaptive Admission Control of service requests without violating the Service Level Agreements (SLA) and simultaneously ensuring targeted revenue to the providers. This paper proposes, implements and evaluates a Bayesian Networks based predictive modeling framework (termed as BNSAC) to provide an autonomic Admission Control of cloud service requests. In summary, the BN-based model learns the historical behavior of the system involving various performance metrics (indicators) and predicts the desired unknown metric (e.g. SLA parameter) for making admission control decisions. It presents simulated experimental results involving various service demand scenarios which provide insights into the feasibility and applicability of the proposed approach for improving the QoS in the cloud computing setup.},
  keywords={},
  doi={10.1109/IACC.2017.0027},
  ISSN={2473-3571},
  month={Jan},}@INPROCEEDINGS{9510130,
  author={Bhonde, Aparna and Devane, Satish},
  booktitle={2021 International Conference on Communication information and Computing Technology (ICCICT)}, 
  title={Impact of Cloud Attacks on Service Level Agreement}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Cloud computing has taken center stage in the current business due to reduced cost, high performance and zero infrastructure. Cloud computing paradigm is yet unable to provide quality of service (QoS) by complying service level agreement (SLA) because of lack of analysis on the unaddressed security issues, challenges, threats which has paved the path for researchers to overcome the lapses in order to improve the QoS. In this paper, we present a survey on the cloud service model attacks and threat analysis. It is been observed after thorough analysis of attacks on all the service models that there is a need to have stronger security for infrastructure as a service level attack. Trust can be ensured among the cloud users with the introduction of security metrics in the service level agreement. Cloud service providers can mention the security metrics in SLA only if it can confidently address these attacks by adding security for infrastructure as a service.},
  keywords={},
  doi={10.1109/ICCICT50803.2021.9510130},
  ISSN={},
  month={June},}@INPROCEEDINGS{8441460,
  author={Keserwani, Pankaj Kumar and Samaddar, Shefalika Ghosh},
  booktitle={2017 Ninth International Conference on Advanced Computing (ICoAC)}, 
  title={An SLA Design with Digital Forensic Capabilities}, 
  year={2017},
  volume={},
  number={},
  pages={109-113},
  abstract={Cloud computing is getting rapid momentum as an alternative to traditional and professional Infrastructure of Information Technology due to its attractive features of getting everything in a service mode rather than in a product mode. Service mode using cloud makes the products and services cost effective. As consumers willing to pass on their tasks as services provider to cloud providers, trust factor is required especially when consumers have critical data. The Service Level Agreements (SLA) between cloud service consumers (CSCs) and cloud service providers (CSPs) play important role for building up trust between involved parties. SLA between parties is established in a satisfactory way upon agreements. Cloud computing is very dynamic in nature, hence continuous monitoring on Quality of Service (QoS) attributes as mentioned in SLA is required to be implemented dynamically. Managing SLAs is complicated due to complex nature of the cloud due to multi-tenancy and distributed resource sharing. The paper proposes a methodology for SLAs to be signed digitally and its further management in a single or multi cloud computing environment. The framework had been used in Web Service Level Agreement (WSLA) for monitoring and enforcement of SLA using Service Oriented Architecture (SOA) environment. Cloud broker agents have the capability of automatic extraction of metrics from SLAs. The use of the third party support feature to manage the digital forensics in case of requirement of any violation of SLAs suggested in the present paper and it is also solving the trust issues as demonstrated in digital forensics usage from the initiation of SLA; making the SLA naturally forensic enabled.},
  keywords={},
  doi={10.1109/ICoAC.2017.8441460},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8509050,
  author={Kumar Koditala, Nikhil and Shekar Pandey, Purnendu},
  booktitle={2018 International Conference on Research in Intelligent and Computing in Engineering (RICE)}, 
  title={Water Quality Monitoring System Using IoT and Machine Learning}, 
  year={2018},
  volume={},
  number={},
  pages={1-5},
  abstract={World Economic Forum ranked drinking water crisis as one of the global risk, due to which around 200 children are dying per day. Drinking unsafe water alone causes around 3.4 million deaths per year. Despite the advancements in technology, sufficient quality measures are not present to measure the quality of drinking water. By focusing on the above issue, this paper proposes a low cost water quality monitoring system using emerging technologies such as IoT, Machine Learning and Cloud Computing which can replace traditional way of quality monitoring. This helps in saving people of rural areas from various dangerous diseases such as fluorosis, bone deformities etc. The proposed model also has a capacity to control temperature of water and adjusts it so as to suit environment temperature. Based on our model we have achieved R-squared score of 0.933.},
  keywords={},
  doi={10.1109/RICE.2018.8509050},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{7207386,
  author={Cedillo, Priscila and Jimenez-Gomez, Javier and Abrahao, Silvia and Insfran, Emilio},
  booktitle={2015 IEEE International Conference on Services Computing}, 
  title={Towards a Monitoring Middleware for Cloud Services}, 
  year={2015},
  volume={},
  number={},
  pages={451-458},
  abstract={Cloud Computing represents a new trend in the development and use of software. Many organizations are currently adopting the use of services that are hosted in the cloud by employing the Software as a Service (SaaS) model. Services are typically accompanied by a Service Level Agreement (SLA), which defines the quality terms that a provider offers to its customers. Many monitoring tools have been proposed to report compliance with the SLA. However, they have some limitations when changes to monitoring requirements must be made and because of the complexity involved in capturing low-level raw data from services at runtime. In this paper, we propose the design of a platform-independent monitoring middleware for cloud services, which supports the monitoring of SLA compliance and provides a report containing SLA violations that may help stakeholders to make decisions regarding how to improve the quality of cloud services. Moreover, our middleware definition is based on the use of models@run.time, which allows the dynamic change of quality requirements and/or the dynamic selection of different metric operationalizations (i.e., Calculation formulas) with which to measure the quality of services. In order to demonstrate the feasibility of our approach, we show the instantiation of the proposed middleware that can be used to monitor services when deployed on the Microsoft Azure© platform.},
  keywords={},
  doi={10.1109/SCC.2015.68},
  ISSN={},
  month={June},}@INPROCEEDINGS{7436036,
  author={Gholami, Atoosa and Arani, Mostafa Ghobaei},
  booktitle={2015 2nd International Conference on Knowledge-Based Engineering and Innovation (KBEI)}, 
  title={A trust model for resource selection in cloud computing environment}, 
  year={2015},
  volume={},
  number={},
  pages={144-151},
  abstract={In recent years, cloud computing technology has been increasingly embraced by people and most organizations tend to use this technology in their business processes. On the other hand, the use of this technology is not so easy and many organizations are concerned about the storage of their sensitive data in their data centers instead of storing them in the cloud storage centers. Today, one of the most important factors for the success of cloud computing is to create trust and security. Cloud computing will face a lot of challenges when the key element trust is absent. Trust is one of the most important ways to improve the reliability of cloud computing resources provided in the cloud environment and plays an important role in business carried out in the cloud business environments. User trust contributes to selection of appropriate sources in heterogeneous cloud infrastructure. In this paper, we present the trust model based on standards of appropriate service quality and speed of implementation for choose the best source. The proposed approach, in addition to taking into account criteria of quality of service such as cost, response time, bandwidth, and processor speed. Simulation results show that the proposed approach compared with similar approaches, in addition to taking into account measures of the quality of service, selects the most reliable source in a cloud environment by taking into account the speed of things.},
  keywords={},
  doi={10.1109/KBEI.2015.7436036},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8251862,
  author={Tirta, Manggiardi B.W. and Shidik, Guruh Fajar},
  booktitle={2017 International Seminar on Application for Technology of Information and Communication (iSemantic)}, 
  title={Evaluation performance of cloud computing with network attached storage for video render}, 
  year={2017},
  volume={},
  number={},
  pages={157-163},
  abstract={One of the benefits of Cloud Computing is the use of virtual machines for efficiency and resource utilization. The study utilizes a virtual machine on cloud computing technology for video rendering needs and is integrated with Network Attached Storage (NAS) storage methods, a centralized storage method that uses network media to connect storage media with users. The rendering process is then analyzed using several metering tools to measure the rendering time frame, VM Utilization, network performance, and NAS Network Performance. The results show that rendering takes longer, then CPU Utilization shows a maximum of 77%, Memory Utilization 55%, and Network Utilization 10%. The bandwidth available between NAS and VM storage in a cloud computing system only generates a maximum of 295.1 Mbps, which should reach 1 Gbps. The quality of video rendering in VM cloud computing shows similar results with rendering on physical computers, the results obtained from testing between frames using mean-square error algorithm.},
  keywords={},
  doi={10.1109/ISEMANTIC.2017.8251862},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8005362,
  author={Brataas, Grunnar and Herbst, Nikolas and Ivansek, Simon and Polutnik, Jure},
  booktitle={2017 IEEE International Conference on Autonomic Computing (ICAC)}, 
  title={Scalability Analysis of Cloud Software Services}, 
  year={2017},
  volume={},
  number={},
  pages={285-292},
  abstract={Cloud computing theoretically offers its customers unlimited cloud resources. However, the scalability of software services is often limited by their underlying architecture. In contrast to current scalability analysis approaches, we make work parameters, quality thresholds, as well as the resource space explicit in a conceptually consistent set of equations. We propose two scalability metric functions based on these equations. The resource scalability metric function describes the relation between the capacity of the multi-tier cloud software service and its use of cloud resources, whereas the cost scalability metric function replaces cloud resources with cost. We validate using the Cloud-Store application. CloudStore follows the TPC-W specification, representing an online book store. We have experimented with 21 different public Amazon Web Service configurations and two private OpenStack configurations.},
  keywords={},
  doi={10.1109/ICAC.2017.34},
  ISSN={2474-0756},
  month={July},}@INPROCEEDINGS{7404740,
  author={Vallone, Joël and Birke, Robert and Chen, Lydia Y. and Falsafi, Babak},
  booktitle={2015 IEEE 23rd International Symposium on Quality of Service (IWQoS)}, 
  title={Contention detection by throttling: A black-box on-line approach}, 
  year={2015},
  volume={},
  number={},
  pages={237-242},
  abstract={Visualization technology powers up the cloud computing paradigm and inevitably raises concerns about performance isolation of collocated virtual machines (VM). It is imperative for public cloud providers to guarantee performance targets for tenants' VMs while respecting strict business confidentiality, e.g., having no information on applications nor their performance. A large body of related work addresses the challenges of detecting performance interferences by leveraging client's quality of service (QoS) metrics, such as latency, and additional profiling servers. Whereas to assist cloud providers, we resort to an on-line blackbox approach based on throttling that detects a wide range of resource contentions with no cooperation need from the virtual machines. We focus on different resource metrics and actively monitor them from the hypervisor in fine time granularity at low cost. To detect resource contention, we propose a three-phase algorithm: an alarm phase, to identify statistical outliers in the victim's VM resource metrics; a passive diagnosis phase, to match the current sample to historical behaviors; and, an active learning phase, to discern contentions from application phase changes via throttling. We evaluate our algorithm on a prototype running Wikimedia as victim application across a set of VMs collocated with neighboring VMs running resource hoggers, i.e. PARSEC and Cachebench. Our extensive experimental results show that we can reach an average detection accuracy above 90% while limiting the performance degradation experienced by offender workloads to short learning phases.},
  keywords={},
  doi={10.1109/IWQoS.2015.7404740},
  ISSN={},
  month={June},}@INPROCEEDINGS{9080012,
  author={Kotteswari, K. and Bharathi, A.},
  booktitle={2019 International Conference on Advances in Computing and Communication Engineering (ICACCE)}, 
  title={Spectral Expansion Method for Cloud Reliability Analysis}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  abstract={Cloud Computing is a computing hypothesis, where a huge group of systems linked together in private, public or hybrid network, to offer dynamically amendable infrastructure for data storage, file storage and application. With this emerging technology, application hosting, delivery, content storage, and reduced computation cost, and it acts as an essential module for backbone of the Internet of Things (IOT). The efficiency of cloud Service providers (CSP) could be improved by considering significant factors such as availability, reliability, usability, security, responsiveness, and elasticity. Assessment of these factors leads to efficiency in designing scheduler for CSP. This metrics also improved the Quality of Service (QoS) in cloud. Many existing model and approaches evaluate this metrics. But these existing approaches doesn't offer efficient outcome. In this paper, a prominent performance model named as Spectral Expansion Method (SPM) evaluates cloud reliability. Spectral expansion Method (SPM) is a huge technique useful in reliability and performance modelling of computing system. This approach solves the Markov model of Cloud service Provider (CSP) to predict the reliability. The SPM is better compared to matrix geometric methods.},
  keywords={},
  doi={10.1109/ICACCE46606.2019.9080012},
  ISSN={},
  month={April},}@INPROCEEDINGS{7016607,
  author={Abdeladim, Alfath and Baina, Salah and Baina, Karim},
  booktitle={2014 Third IEEE International Colloquium in Information Science and Technology (CIST)}, 
  title={Elasticity and scalability centric quality model for the cloud}, 
  year={2014},
  volume={},
  number={},
  pages={135-140},
  abstract={Cloud computing seems to be the most logical shift in terms of Information Technology after Internet, Social Networking. Despite the potential benefits that cloud computing offers, the model brings new issues, challenges, and needs in term of SLA formalization, Quality of Service (QoS) evaluation due to the heterogeneous resources and to the special features it implies, such as Elasticity and Scalability. In the scope of this paper we focus on the Elasticity and Scalability attributes to assess their impact on the QoS. The paper provides a multi-lenses overview that can help both cloud consumers and potential business application's owners to understand, analyze, and evaluate important aspects related to Scalability and Elasticity capabilities. We determine and analyze the key features of these characteristics and derive metrics that evaluate the cloud elasticity-centric capabilities. We present a specific quality model for those two characteristics derived from their sub-attributes.},
  keywords={},
  doi={10.1109/CIST.2014.7016607},
  ISSN={2327-1884},
  month={Oct},}@INPROCEEDINGS{7182659,
  author={Young-Rok Shin and Eui-Nam Huh},
  booktitle={2015 Seventh International Conference on Ubiquitous and Future Networks}, 
  title={QoE metrics aggregation for hierarchical Service Level Agreement in Cross-Layered SLA architecture}, 
  year={2015},
  volume={},
  number={},
  pages={831-836},
  abstract={Numerous services are developed using cloud computing technology. It is possible to use service from remote location, not in place of local computer. Accordingly, the research groups predict that the scale of cloud service also will be grown. One of cloud computing's advantage is scalability. It can extend its service scale and range using collaboration between cloud service providers. To make it possible, however, interoperability is required in that environment. Cross-Layered SLA architecture is the cloud service environment that supports interoperability. In this paper, we propose aggregation functions and quality model for QoE metrics and newly generating Service Level Agreement in cross-layered SLA architecture. We expect that this aggregation function and quality model will solve the possible problems in the cloud service area.},
  keywords={},
  doi={10.1109/ICUFN.2015.7182659},
  ISSN={2165-8536},
  month={July},}@INPROCEEDINGS{7474163,
  author={Bousselmi, Khadija and Brahmi, Zaki and Gammoudi, Mohamed Mohsen},
  booktitle={2016 IEEE 30th International Conference on Advanced Information Networking and Applications (AINA)}, 
  title={QoS-Aware Scheduling of Workflows in Cloud Computing Environments}, 
  year={2016},
  volume={},
  number={},
  pages={737-745},
  abstract={Cloud Computing has emerged as a service model that enables on-demand network access to a large number of available virtualized resources and applications with a minimal management effort and a minor price. The spread of Cloud Computing technologies allowed dealing with complex applications such as Scientific Workflows, which consists of a set of intensive computational and data manipulation operations. Cloud Computing helps such Workflows to dynamically provision compute and storage resources necessary for the execution of its tasks thanks to the elasticity asset of these resources. However, the dynamic nature of the Cloud incurs new challenges, as some allocated resources may be overloaded or out of access during the execution of the Workflow. Moreover, for data intensive tasks, the allocation strategy should consider the data placement constraints since data transmission time can increase notably in this case which implicates the increase of the overall completion time and cost of the Workflow. Likewise, for intensive computational tasks, the allocation strategy should consider the type of the allocated virtual machines, more specifically its CPU, memory and network capacities. Yet, a critical challenge is how to efficiently schedule the Workflow tasks on Cloud resources to optimize its overall quality of service. In this paper, we propose a QoS-aware algorithm for Scientific Workflows scheduling that aims to improve the overall quality of service (QoS) by considering the metrics of execution time, data transmission time, cost, resources availability and data placement constraints. We extended the Parallel Cat Swarm Optimization (PCSO) algorithm to implement our proposed approach. We tested our algorithm within two sample Workflows of different scales and we compared the results to those given by the standard PSO, the CSO and the PCSO algorithms. The results show that our proposed algorithm improves the overall quality of service of the tested Workflows.},
  keywords={},
  doi={10.1109/AINA.2016.72},
  ISSN={1550-445X},
  month={March},}@ARTICLE{8204552,
  author={Sun, Chang-ai and Pan, Lin and Wang, Qiaoling and Liu, Huai and Zhang, Xiangyu},
  journal={The Computer Journal}, 
  title={An Empirical Study on Mutation Testing of WS-BPEL Programs}, 
  year={2017},
  volume={60},
  number={1},
  pages={143-158},
  abstract={Nowadays, applications are increasingly deployed as Web services in the globally distributed cloud computing environment. Multiple services are normally composed to fulfill complex functionalities. Business Process Execution Language for Web Services (WS-BPEL) is an XML-based service composition language that is used to define a complex business process by orchestrating multiple services. Compared with traditional applications, WS-BPEL programs pose many new challenges to the quality assurance, especially testing, of service compositions. A number of techniques have been proposed for testing WS-BPEL programs, but only a few studies have been conducted to systematically evaluate the effectiveness of these techniques. Mutation testing has been widely acknowledged as not only a testing method in its own right but also a popular technique for measuring the fault-detection effectiveness of other testing methods. Several previous studies have proposed a family of mutation operators for generating mutants by seeding various faults into WS-BPEL programs. In this study, we conduct a series of empirical studies to evaluate the applicability and effectiveness of various mutation operators for WS-BPEL programs. The experimental results provide insightful and comprehensive guidance for mutation testing of WS-BPEL programs in practice. In particular, our work is the systematic study in the selection of effective mutation operators specifically for WS-BPEL programs.},
  keywords={},
  doi={10.1093/comjnl/bxw076},
  ISSN={1460-2067},
  month={Jan},}@INPROCEEDINGS{8350688,
  author={Indrawati and Puspita, Fitri Maya and Erlita, Sri and Nadeak, Inosensius and Arisha, Bella},
  booktitle={2018 International Conference on Information and Communications Technology (ICOIACT)}, 
  title={LINGO-based optimization problem of cloud computing of bandwidth consumption in the Internet}, 
  year={2018},
  volume={},
  number={},
  pages={436-441},
  abstract={Optimization problem is an important issue in the network Internet. With the dynamic approach in modeling networks, we can strengthen network performance and ensure that the cost will be minimized and profit of provider can be maximized. This research aims to study, analyze the scheme for cloud networking and formulate a plan of new models of dynamic networks and can work under a cloud of wireless networks. Mixed Integer Non Linear Programming (MINLP) is an integer linear programming model to optimize a particular purpose. In MINLP process, the objective function is determined beforehand. The optimal solution of MINLP lies in the majority of decision variables that can be an integer, Boolean or fractions. Model Cloud computing is one of the areas that is most discussed and promising in modern computer science. Cloud computing is a computing model in which resources such as processors, storage, network and software information that can be accessed by customers via the Internet. In the cloud computing implementation, we require a good traffic for performance and reliability of the system is maintained. QoS (Quality of Services) refers to the distribution of bandwidth. QoS is used as a measure of whether or not the characteristics of the network to meet the needs of different services that use the same infrastructure. Tests carried out on the quality of service parameters, namely, delay, packet loss, throughput and bandwidth. To formulate and solve optimization problems used LINGO software applications. The results show that by designing the optimization problem, the cost of consumption of the demand of the internet can be reduced; the maximum profit for the provider can be increased.},
  keywords={},
  doi={10.1109/ICOIACT.2018.8350688},
  ISSN={},
  month={March},}@INPROCEEDINGS{9732606,
  author={Le, Van Thanh and El Ioini, Nabil and Pahl, Claus and Barzegar, Hamid R. and Ardagna, Claudio},
  booktitle={2021 Sixth International Conference on Fog and Mobile Edge Computing (FMEC)}, 
  title={A Distributed Trust Layer for Edge Infrastructure}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  abstract={Recently, Mobile Edge Cloud computing (MEC) has attracted attention both from academia and industry. The idea of moving a part of cloud resources closer to users and data sources can bring many advantages in terms of speed, data traffic, security and context-aware services. The MEC infrastructure does not only host and serves applications next to the end-users, but services can be dynamically migrated and reallocated as mobile users move in order to guarantee latency and performance constraints. This specific requirement calls for the involvement and collaboration of multiple MEC providers, which raises a major issue related to trustworthiness. Two main challenges need to be addressed: i) trustworthiness needs to be handled in a manner that does not affect latency or performance, ii) trustworthiness is considered in different dimensions - not only security metrics but also performance and quality metrics in general. In this paper, we propose a trust layer for public MEC infrastructure that handles establishing and updating trust relations among all MEC entities, making the interaction withing a MEC network transparent. First, we define trust attributes affecting the trusted quality of the entire infrastructure and then a methodology with a computation model that combines these trust attribute values. Our experiments showed that the trust model allows us to reduce latency by removing the burden from a single MEC node, while at the same time increase the network trustworthiness.},
  keywords={},
  doi={10.1109/FMEC54266.2021.9732606},
  ISSN={},
  month={Dec},}@ARTICLE{6595652,
  author={Xia, Yunni and Zhou, MengChu and Luo, Xin and Zhu, Qingsheng and Li, Jia and Huang, Yu},
  journal={IEEE Transactions on Automation Science and Engineering}, 
  title={Stochastic Modeling and Quality Evaluation of Infrastructure-as-a-Service Clouds}, 
  year={2015},
  volume={12},
  number={1},
  pages={162-170},
  abstract={Cloud computing is a recently developed new technology for complex systems with massive service sharing, which is different from the resource sharing of the grid computing systems. In a cloud environment, service requests from users go through numerous provider-specific steps from the instant it is submitted to when the requested service is fully delivered. Quality modeling and analysis of clouds are not easy tasks because of the complexity of the automated provisioning mechanism and dynamically changing cloud environment. This work proposes an analytical model-based approach for quality evaluation of Infrastructure-as-a-Service cloud by considering expected request completion time, rejection probability, and system overhead rate as key quality metrics. It also features with the modeling of different warm-up and cool-down strategies of machines and the ability to identify the optimal balance between system overhead and performance. To validate the correctness of the proposed model, we obtain simulative quality-of-service (QoS) data and conduct a confidence interval analysis. The result can be used to help design and optimize industrial cloud computing systems.},
  keywords={},
  doi={10.1109/TASE.2013.2276477},
  ISSN={1558-3783},
  month={Jan},}@INPROCEEDINGS{8394855,
  author={Bouzidi, Mohammed Ridha and Soltani, Abdelghani and Bouhank, Asma and Daoudi, Mourad},
  booktitle={2018 5th International Conference on Control, Decision and Information Technologies (CoDIT)}, 
  title={New Search Based Methods to Solve Workflow Scheduling Problem in Cloud Computing}, 
  year={2018},
  volume={},
  number={},
  pages={647-652},
  abstract={Scheduling has a big influence on the performance of the cloud computing environment, and still remains of big interest for researchers, in particular when a certain level of quality should be maintained in order to satisfy the customer. We consider the particular scheduling multiobjective optimization problem of allocating workflows to the resources of a cloud computing environment, by managing four QoS metrics: makespan, cost, reliability and the availability. It belongs to a category of NP Hard problems. A particular metaheuristic, BBO is investigated. New workflow scheduling BBO based methods are proposed. Further, two multiobjective pareto based optimization methods MOHEFT and NSGA-II are considered in solving our problem. Tests are performed on well-known benchmarks, showing a good behavior of the different methods.},
  keywords={},
  doi={10.1109/CoDIT.2018.8394855},
  ISSN={2576-3555},
  month={April},}@INPROCEEDINGS{9627219,
  author={Patel, Jatin and Halabi, Talal},
  booktitle={2021 IEEE 6th International Conference on Smart Cloud (SmartCloud)}, 
  title={Optimizing the Performance of Web Applications in Mobile Cloud Computing}, 
  year={2021},
  volume={},
  number={},
  pages={33-37},
  abstract={Cloud computing adoption is on the rise. Many organizations have decided to shift their workload to the cloud to benefit from the scalability, resilience, and cost reduction characteristics. Mobile Cloud Computing (MCC) is an emerging computing paradigm that also provides many advantages to mobile users. Mobile devices function on wireless internet connectivity, which entails issues of limited bandwidth and network congestion. Hence, the primary focus of Web applications in MCC is on improving performance by quickly fulfilling customer's requests to improve service satisfaction. This paper investigates a new approach to caching data in these applications using Redis, an in-memory data store, to enhance Quality of Service. We highlight the two implementation approaches of fetching the data of an application either directly from the database or from the cache. Our experimental analysis shows that, based on performance metrics such as response time, throughput, latency, and number of hits, the caching approach achieves better performance by speeding up the data retrieval by up to four times. This improvement is of significant importance in mobile devices considering their limitation of network bandwidth and wireless connectivity.},
  keywords={},
  doi={10.1109/SmartCloud52277.2021.00013},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{7000073,
  author={Ravanello, Anderson and Desharnais, Jean-Marc and Bautista Villalpando, Luis Eduardo and April, Alain and Gherbi, Abdelouahed},
  booktitle={2014 Joint Conference of the International Workshop on Software Measurement and the International Conference on Software Process and Product Measurement}, 
  title={Performance Measurement for Cloud Computing Applications Using ISO 25010 Standard Characteristics}, 
  year={2014},
  volume={},
  number={},
  pages={41-49},
  abstract={Measuring the performance of cloud computing-based applications using ISO quality characteristics is a complex activity for various reasons, among them the complexity of the typical cloud computing infrastructure on which an application operates. To address this issue, the authors use Bautista's proposed performance measurement framework [1] on log data from an actual data centre to map and statistically analyze one of the ISO quality characteristics: time behavior. This empirical case study was conducted on an industry private cloud. The results of the study demonstrate that it is possible to use the proposed performance measurement framework in a cloud computing context. They also show that the framework holds great promise for expanding the experimentation to other ISO quality characteristics, larger volumes of data, and other statistical techniques that could be used to analyze performance.},
  keywords={},
  doi={10.1109/IWSM.Mensura.2014.33},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9581580,
  author={Zolait, Ali Hussein and Alalas, Sumaya and Ali, Noor and Showaiter, Aya},
  booktitle={2021 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT)}, 
  title={Quality of Life Integrated Framework: Perspective of Cloud Computing Usage}, 
  year={2021},
  volume={},
  number={},
  pages={537-544},
  abstract={This research aims to measure the impact of cloud computing on people's quality of life in the Kingdom of Bahrain and recognize factors that could impact people's intention to use cloud computing services. An online survey has been used to collect primary data for the research. It was distributed to a random sample of 443 respondents in the Kingdom of Bahrain. The achievable sample comprised 394 represent people of different ages and educational levels. The researchers adapted selected factors from the diffusion of innovation (DOI) theory, including relative advantage, complexity, and compatibility. In addition to the quality of life factors consisting of education, healthcare, wellbeing, and entertainment. These factors are used to establishing the framework of this research. The research limitation was in examining only the variables proposed in the framework. Also, as a consequence of the coronavirus's current situation (COVID-19), collecting data was restricted to the quantitative approach using an online survey. Findings show that administrability of cloud computing usage is the most impacting factor on people's quality of life and, more specifically, on people's education.},
  keywords={},
  doi={10.1109/3ICT53449.2021.9581580},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8818401,
  author={Yu, Guangba and Chen, Pengfei and Zheng, Zibin},
  booktitle={2019 IEEE International Conference on Web Services (ICWS)}, 
  title={Microscaler: Automatic Scaling for Microservices with an Online Learning Approach}, 
  year={2019},
  volume={},
  number={},
  pages={68-75},
  abstract={Recently, the microservice becomes a popular architecture to construct cloud native systems due to its agility. In cloud native systems, autoscaling is a core enabling technique to adapt to workload changes by scaling out/in. However, it becomes a challenging problem in a microservice system, since such a system usually comprises a large number of different micro services with complex interactions. When bursty and unpredictable workloads arrive, it is difficult to pinpoint the scaling-needed services which need to scale and evaluate how much resource they need. In this paper, we present a novel system named Microscaler to automatically identify the scaling-needed services and scale them to meet the service level agreement (SLA) with an optimal cost for micro-service systems. Microscaler collects the quality of service metrics (QoS) with the help of the service mesh enabled infrastructure. Then, it determines the under-provisioning or over-provisioning services with a novel criterion named service power. By combining an online learning approach and a step-by-step heuristic approach, Microscaler could achieve the optimal service scale satisfying the SLA requirements. The experimental evaluations in a micro-service benchmark show that Microscaler converges to the optimal service scale faster than several state-of-the-art methods.},
  keywords={},
  doi={10.1109/ICWS.2019.00023},
  ISSN={},
  month={July},}@INPROCEEDINGS{9165482,
  author={Khan, Michel Gokan and Taheri, Javid and Khoshkholghi, Mohammad Ali and Kassler, Andreas and Cartwright, Carolyn and Darula, Marian and Deng, Shuiguang},
  booktitle={2020 6th IEEE Conference on Network Softwarization (NetSoft)}, 
  title={A Performance Modelling Approach for SLA-Aware Resource Recommendation in Cloud Native Network Functions}, 
  year={2020},
  volume={},
  number={},
  pages={292-300},
  abstract={Network Function Virtualization (NFV) becomes the primary driver for the evolution of 5G networks, and in recent years, Network Function Cloudification (NFC) proved to be an inevitable part of this evolution. Microservice architecture also becomes the de facto choice for designing a modern Cloud Native Network Function (CNF) due to its ability to decouple components of each CNF into multiple independently manageable microservices. Even though taking advantage of microservice architecture in designing CNFs solves specific problems, this additional granularity makes estimating resource requirements for a Production Environment (PE) a complex task and sometimes leads to an over-provisioned PE. Traditionally, performance engineers dimension each CNF within a Service Function Chain (SFC) in a smaller Performance Testing Environment (PTE) through a series of performance benchmarks. Then, considering the Quality of Service (QoS) constraints of a Service Provider (SP) that are guaranteed in the Service Level Agreement (SLA), they estimate the required resources to set up the PE. In this paper, we used a machine learning approach to model the impact of each microservice's resource configuration (i.e., CPU and memory) on the QoS metrics (i.e. serving throughput and latency) of each SFC in a PTE. Then, considering an SP's Service Level Objectives (SLO), we proposed an algorithm to predict each microservice's resource capacities in a PE. We evaluated the accuracy of our prediction on a prototype of a cloud native 5G Home Subscriber Server (HSS). Our model showed 95%-78% accuracy in a PE that has 2-5 times more computing resources than the PTE.},
  keywords={},
  doi={10.1109/NetSoft48620.2020.9165482},
  ISSN={},
  month={June},}@INPROCEEDINGS{9582214,
  author={Aggarwal, Pooja and Nagar, Seema and Gupta, Ajay and Shwartz, Larisa and Mohapatra, Prateeti and Wang, Qing and Paradkar, Amit and Mandal, Atri},
  booktitle={2021 IEEE 14th International Conference on Cloud Computing (CLOUD)}, 
  title={Causal Modeling based Fault Localization in Cloud Systems using Golden Signals}, 
  year={2021},
  volume={},
  number={},
  pages={124-135},
  abstract={In cloud-native applications, a large fraction of operational failures, known as outages, result in violations of Service Level Objectives (SLOs). SLOs are defined around specific measurable characteristics: availability, throughput, frequency, response time, and quality. Four metrics, latency, traffic, errors, and saturation, ensure coverage for most outages of an application. These are often called golden signals. The dynamicity and complexity of cloud-native applications complicate Site Reliability Engineers’ (SREs) efforts in problem determination, in particular in its fault localization. The fault localization is often a try-and-error process in which SREs rely on their domain knowledge and experience. It is laborious and frequently results in long Mean Time To Resolution (MTTR) for outages. This paper describes a lightweight fault localization system, that establishes causal relationships among the golden signal service errors and error logs, and further leverages PageRank centrality of the derived causal graph for generating a ranked list of faulty microservices.},
  keywords={},
  doi={10.1109/CLOUD53861.2021.00026},
  ISSN={2159-6190},
  month={Sep.},}@INPROCEEDINGS{7982313,
  author={Althani, B. and Khaddaj, S. and Makoond, B.},
  booktitle={2016 IEEE Intl Conference on Computational Science and Engineering (CSE) and IEEE Intl Conference on Embedded and Ubiquitous Computing (EUC) and 15th Intl Symposium on Distributed Computing and Applications for Business Engineering (DCABES)}, 
  title={A Quality Assured Framework for Cloud Adaptation and Modernization of Enterprise Applications}, 
  year={2016},
  volume={},
  number={},
  pages={634-637},
  abstract={Cloud Computing has emerged as a viable alternative to in-house computing resources for many organisations. It offers an alternative solution for many enterprise applications, particularly large-scale legacy applications. In addition, it can offer a cost effective strategy for small and medium-sized enterprises (SMEs) where the high set-up and maintenance cost of computing resources can be prohibiting. Thus, in this paper a System Migration Life Cycle (SMLC) framework is proposed, which includes a step by-stepmigration strategy that is descriptive at the business analyst level and based on quality metrics modelling at the technical level, to estimate the potential computational needs, risks, and costs for an organisation. The proposed framework is generic and adaptable in order to accommodate various organisational requirements, thus covering a wide range of enterprise applications and following a number of novel software requirements and quality engineering principles.},
  keywords={},
  doi={10.1109/CSE-EUC-DCABES.2016.251},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8821787,
  author={Mahenge, Michael P. J. and Li, Chunlin and Sanga, Camilius A.},
  booktitle={2019 IEEE 4th International Conference on Computer and Communication Systems (ICCCS)}, 
  title={Collaborative Mobile Edge and Cloud Computing: Tasks Unloading for Improving Users’ Quality of Experience in Resource-Intensive Mobile Applications}, 
  year={2019},
  volume={},
  number={},
  pages={322-326},
  abstract={The advancement in resource-intensive and latency-sensitive applications challenge the legacy systems in Mobile Cloud Computing (MCC) in terms of network congestion, bandwidth utilization, performance and Quality of Service (QoS) metrics. Such challenges emanate from first, limited energy sources and resource poverty of mobile devices. Second, multi-hop connection between user devices and the cloud. To address such challenges, mobile edge computing is a promising solution. This study proposes an architecture that considers unloading resource-intensive tasks from clients' devices to more resourceful edge servers which exploit cooperative approach for tasks processing. Thus, it is essential for minimizing delay, bandwidth usage, congestion to the core network and guarantees cost-effective approach for meeting user's demands. The simulation results show that the proposed approach through unloading, it reduces response time and energy usage. This in turn improves performance, system utility and Quality of Experience (QoE).},
  keywords={},
  doi={10.1109/CCOMS.2019.8821787},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{6897195,
  author={Baliyan, Niyati and Kumar, Sandeep},
  booktitle={2014 Seventh International Conference on Contemporary Computing (IC3)}, 
  title={Towards software engineering paradigm for software as a service}, 
  year={2014},
  volume={},
  number={},
  pages={329-333},
  abstract={The Software as a Service model of Cloud Computing offers economies of scale through the pay per use model; however, it renders the modern software very different from traditional software. Hence, there is a need to adapt Software Engineering approach in a manner that will make the development process and delivery of Software as a Service more efficient and of high quality. After performing literature review, a classification of ongoing research in this direction of adaptation is presented. Various research gaps in the areas of software development process, software reengineering, measurement, metrics, and quality models targeted at Software as a Service are identified, which can be a first step towards the definition of standards and guidelines for Software as a Service development.},
  keywords={},
  doi={10.1109/IC3.2014.6897195},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{7170460,
  author={Armando Cabrera, S. and Abad, E. Marco and Danilo Jaramillo, H. and Poma, G. Ana and Verdúm, José Carrillo},
  booktitle={2015 10th Iberian Conference on Information Systems and Technologies (CISTI)}, 
  title={Incidence of software quality attributes in the design, construction and deployment of Cloud architectural environments}, 
  year={2015},
  volume={},
  number={},
  pages={1-7},
  abstract={Cloud Computing (CC) is a new paradigm in the world of computing, it includes several service and deployment models. This project is part of a general study that starts from the software engineering process and the software development life cycle (SDLC), this study is based on the ISO / IEC / IEEE 12207 standard, to evaluate the software implementation process and then we review some software quality aspects by applying the standard ISO / IEC 9126; finally we review some key terms, features, models, architecture, taxonomy, deployment scenarios and scope statements of Cloud Computing. After that we proceed to identify the key characteristics of private and public SaaS environments and obtained a quality model of service (QoS) using quality attributes and their corresponding metrics derived from the ISO / IEC 9126 Standard.},
  keywords={},
  doi={10.1109/CISTI.2015.7170460},
  ISSN={2166-0727},
  month={June},}@ARTICLE{9097181,
  author={Belgaum, Mohammad Riyaz and Musa, Shahrulniza and Alam, Muhammad Mansoor and Su’ud, Mazliham Mohd},
  journal={IEEE Access}, 
  title={A Systematic Review of Load Balancing Techniques in Software-Defined Networking}, 
  year={2020},
  volume={8},
  number={},
  pages={98612-98636},
  abstract={The traditional networks are facing difficulties in managing the services offered by cloud computing, big data, and the Internet of Things as the users have become more dependent on their services. Software-Defined Networking (SDN) has pulled enthusiasm in the integration process of technologies and function as per the user's requirements for both academia and industry, and it has begun to be embraced in actual framework usage. The emergence of SDN has given another idea to empower the focal programmability of the system. Because of the increasing demand and the scarcity of resources, the load balancing issue needs to be addressed efficiently to manage the incoming traffic and resources and to improve network performance. One of the most critical issues is the role of the controller in SDN to balance the load for having a better Quality of Service (QoS). Though there are few survey articles written on load balancing, there is no detail and systematic review conducted in load balancing in SDN. Hence, this paper extends and reviews the discussion with a taxonomy of current emerging load balancing techniques in SDN systematically by categorizing the techniques as conventional and artificial intelligence-based techniques to improve the service quality. The review also includes the study of metrics and parameters which have been used to measure the performance. This review would allow gaining more information on load balancing approaches in SDN and enables the researchers to fill the current research gaps.},
  keywords={},
  doi={10.1109/ACCESS.2020.2995849},
  ISSN={2169-3536},
  month={},}@ARTICLE{8737926,
  author={Liu, Ying and Wang, Ke and Ge, Liang and Ye, Lei and Cheng, Jingde},
  journal={IEEE Access}, 
  title={Adaptive Evaluation of Virtual Machine Placement and Migration Scheduling Algorithms Using Stochastic Petri Nets}, 
  year={2019},
  volume={7},
  number={},
  pages={79810-79824},
  abstract={More and more mobile applications rely on the combination of both mobile and cloud computing technology to bring out their full potential. The cloud is usually used for providing additional computing resources that cannot be handled efficiently by the mobile devices. Cloud usage, however, results in several challenges related to the management of virtualized resources. A large number of scheduling algorithms are proposed to balance between performance and cost of data center. Due to huge cost and time consuming of measure-based and simulation method, this paper proposes an adaptive method to evaluate scheduling algorithms. In this method, the virtual machine placement and migration process are modeled by using Stochastic Reward Nets. Different scheduling methods are described as reward functions to perform the adaptive evaluation. Two types of performance metrics are also discussed: one is about quality of service, such as system availability, mean waiting time, and mean service time, and the other is the cost of runtime, such as energy consumption and cost of migration. Compared to a simulation method, the analysis model in this paper only modifies the reward function for different scheduling algorithms and does not need to reconstruct the process. The numeric results suggest that it also has a good accuracy and can quantify the influence of scheduling algorithms on both quality of service and cost of runtime.},
  keywords={},
  doi={10.1109/ACCESS.2019.2923592},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7312289,
  author={Zhang, Xiaodong and Dechen, Zhan and Nie, Lanshun and Zhao, Tianqi and Xiong, Xiao},
  booktitle={2014 International Conference on Service Sciences}, 
  title={An Optimal Service-Selection Model Based on Capability and Quality of Resource Service}, 
  year={2014},
  volume={},
  number={},
  pages={47-52},
  abstract={Most of the researches on optimal service selection are based on the assumption that the capabilities of the services fully meet the requirements. Their limitation is the ignorance of the resources which is the basic factor supporting the implementation of services and it may cause a waste of resources. In cloud computing environment which benefits from its large-scale, there are a large number of resources. Therefore, the waste of resources in it would be a big problem. This paper introduces 'service equivalent' as the basic metric to measure the capabilities of service resources and proposes an optimal service selection model based on capability and quality of service resources and algorithm, in order to solve the issues about the matching capability of service resource and the optimal selection of service resource based on quality. Finally it proves that the model can effectively reduce the waste of resources by the test, which achieves the expected goal.},
  keywords={},
  doi={10.1109/ICSS.2014.39},
  ISSN={2165-3836},
  month={May},}@INPROCEEDINGS{9412544,
  author={Paolanti, Marina and Mameli, Marco and Frontoni, Emanuele and Gioacchini, Giorgia and Giorgini, Elisabetta and Notarstefano, Valentina and Zacà, Carlotta and Carnevali, Oliana and Borini, Andrea},
  booktitle={2020 25th International Conference on Pattern Recognition (ICPR)}, 
  title={Automatic Classification of Human Granulosa Cells in Assisted Reproductive Technology using vibrational spectroscopy imaging}, 
  year={2021},
  volume={},
  number={},
  pages={209-216},
  abstract={In the field of reproductive technology, the biochemical composition of female gametes has been successfully investigated with the use of vibrational spectroscopy. Currently, in assistive reproductive technology (ART), there are no shared criteria for the choice of oocyte, and automatic classification methods for the best quality oocytes have not yet been applied. In this paper, considering the lack of criteria in Assisted Reproductive Technology (ART), we use Machine Learning (ML) techniques to predict oocyte quality for a successful pregnancy. To improve the chances of successful implantation and minimize any complications during the pregnancy, Fourier transform infrared microspectroscopy (FTIRM) analysis has been applied on granulosa cells (GCs) collected along with the oocytes during oocyte aspiration, as it is routinely done in ART, and specific spectral biomarkers were selected by multivariate statistical analysis. A proprietary biological reference dataset (BRD) was successfully collected to predict the best oocyte for a successful pregnancy. Personal health information are stored, maintained and backed up using a cloud computing service. Using a user-friendly interface, the user will evaluate whether or not the selected oocyte will have a positive result. This interface includes a dashboard for retrospective analysis, reporting, real-time processing, and statistical analysis. The experimental results are promising and confirm the efficiency of the method in terms of classification metrics: precision, recall, and F1-score (F1) measures.},
  keywords={},
  doi={10.1109/ICPR48806.2021.9412544},
  ISSN={1051-4651},
  month={Jan},}@INPROCEEDINGS{8230005,
  author={Kumar, Somansh and Jasuja, Ashish},
  booktitle={2017 International Conference on Computing, Communication and Automation (ICCCA)}, 
  title={Air quality monitoring system based on IoT using Raspberry Pi}, 
  year={2017},
  volume={},
  number={},
  pages={1341-1346},
  abstract={Air pollution is the largest environmental and public health challenge in the world today. Air pollution leads to adverse effects on Human health, climate and ecosystem. Air is getting polluted because of release of Toxic gases by industries, vehicular emissions and increased concentration of harmful gases and particulate matter in the atmosphere. Particulate matter is one of the most important parameter having the significant contribution to the increase in air pollution. This creates a need for measurement and analysis of real-time air quality monitoring so that appropriate decisions can be taken in a timely period. This paper presents a real-time standalone air quality monitoring system which includes various parameters: PM 2.5, carbon monoxide, carbon dioxide, temperature, humidity and air pressure. Internet of Things is nowadays finding profound use in each and every sector, plays a key role in our air quality monitoring system too. Internet of Things converging with cloud computing offers a novel technique for better management of data coming from different sensors, collected and transmitted by low power, low cost ARM based minicomputer Raspberry pi. The system is tested in Delhi and the measurements are compared with the data provided by the local environment control authority and are presented in a tabular form. The values of the parameters measured are shown in IBM Bluemix Cloud.},
  keywords={},
  doi={10.1109/CCAA.2017.8230005},
  ISSN={},
  month={May},}@INPROCEEDINGS{9080705,
  author={Hussain, Mujahid and Aleem, Sadaf and Karim, Arif and Ghazanfar, Faisal and Hai, Mansoor and Hussain, Kashif},
  booktitle={2020 International Conference on Emerging Trends in Smart Technologies (ICETST)}, 
  title={Design of Low Cost, Energy Efficient, IoT Enabled, Air Quality Monitoring System with Cloud Based Data Logging, Analytics and AI}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper presents a design of real-time Air Quality Monitoring System (AQMS) which incorporates Internet of Things (IoT) and cloud computing. AQMS utilizes solar panel and battery pack for independent and autonomous operation, thus, making it self-powered and sustainable. AQMS is based on AVR Microcontroller (Atmega32) and GSM modem (Sim900) for connectivity with the cloud application. The design is made low cost and scalable so that around 50nos. of such systems can be installed on roundabouts of market places, residential and industrial areas. The AQMS monitors the air quality with the help of a miniature suction pump (5volt DC) which establishes a controlled and constant stream of air-flow through a manifold that encapsulates electromechanical sensors, thus measuring the concentration of O2, CO, CO2, SO / SO2 (SOx), NO/ NO2 (NOx), Hydrocarbon (CxHx), temperature, humidity and noise. By default, the air sampling is carried out once in an hour which may be changed depending on the change in air quality, i.e. making it adoptive for energy conservation and extending the sensor's life. The data collected at the cloud application will be processed using data analytics and Artificial Intelligence (AI) for getting insights of data (data mining) regarding the potential locations where the emissions are critical and disastrous for environmental, thus, leading to prevent any mishap. The design is mapped over a metropolitan city of Pakistan, i.e. Karachi, thus initiating the transformation of Karachi to a smart city.},
  keywords={},
  doi={10.1109/ICETST49965.2020.9080705},
  ISSN={},
  month={March},}@INPROCEEDINGS{7883186,
  author={Shan Luo and Yanhui Zhou},
  booktitle={2016 7th IEEE International Conference on Software Engineering and Service Science (ICSESS)}, 
  title={How to guarantee the cloud services quality}, 
  year={2016},
  volume={},
  number={},
  pages={791-795},
  abstract={At present, cloud computing is used widely. Cloud services through the cloud platform provide various services to users. And cloud services will play an increasingly important role in the economy and society. Service level agreement (SLA) is an indispensable part of information service in the cloud environment. It is not only the legal protection of the quality of the cloud services, but also provides the service terms and services between the providers and users. Cloud services quality is directly reflected in the user's satisfaction, and it is still a problem to be solved. In this paper, a simple cloud SLA model is proposed to solve the problem of cloud service quality which cannot be measured by the SLA case.},
  keywords={},
  doi={10.1109/ICSESS.2016.7883186},
  ISSN={2327-0594},
  month={Aug},}@INPROCEEDINGS{7349726,
  author={Shi, Peichang and Gangopadhyay, Aryya},
  booktitle={2015 International Conference on Healthcare Informatics}, 
  title={Personalized Health Plan Ranking - One Application of Cloud Computing to Health Care Data}, 
  year={2015},
  volume={},
  number={},
  pages={447-447},
  abstract={Health plan ranking is one important factor when people are considering their health plan selection. The current health plan ranking is done by National Committee for Quality Assurance, which calculates the ratings based on three types of quality measures and gives an overall ranking of health plans. Individual consumers may be more interested in the ranks of health plans for people with similar conditions. For example, what is the plan ranking for people with both asthma and diabetes? This paper will explore how to combine some data mining techniques and cloud computing to provide a personalized health plan ranking based on each individual's physical conditions.},
  keywords={},
  doi={10.1109/ICHI.2015.65},
  ISSN={},
  month={Oct},}@ARTICLE{8016558,
  author={Mubeen, Saad and Asadollah, Sara Abbaspour and Papadopoulos, Alessandro Vittorio and Ashjaei, Mohammad and Pei-Breivold, Hongyu and Behnam, Moris},
  journal={IEEE Access}, 
  title={Management of Service Level Agreements for Cloud Services in IoT: A Systematic Mapping Study}, 
  year={2018},
  volume={6},
  number={},
  pages={30184-30207},
  abstract={Cloud computing and Internet of Things (IoT) are computing technologies that provide services to consumers and businesses, allowing organizations to become more agile and flexible. Therefore, ensuring quality of service (QoS) through service-level agreements (SLAs) for such cloud-based services is crucial for both the service providers and service consumers. As SLAs are critical for cloud deployments and wider adoption of cloud services, the management of SLAs in cloud and IoT has thus become an important and essential aspect. This paper investigates the existing research on the management of SLAs in IoT applications that are based on cloud services. For this purpose, a systematic mapping study (a well-defined method) is conducted to identify the published research results that are relevant to SLAs. This paper identifies 328 primary studies and categorizes them into seven main technical classifications: SLA management, SLA definition, SLA modeling, SLA negotiation, SLA monitoring, SLA violation and trustworthiness, and SLA evolution. This paper also summarizes the research types, research contributions, and demographic information in these studies. The evaluation of the results shows that most of the approaches for managing SLAs are applied in academic or controlled experiments with limited industrial settings rather than in real industrial environments. Many studies focus on proposal models and methods to manage SLAs, and there is a lack of focus on the evolution perspective and a lack of adequate tool support to facilitate practitioners in their SLA management activities. Moreover, the scarce number of studies focusing on concrete metrics for qualitative or quantitative assessment of QoS in SLAs urges the need for in-depth research on metrics definition and measurements for SLAs.},
  keywords={},
  doi={10.1109/ACCESS.2017.2744677},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7037641,
  author={Kritikos, Kyriakos and Domaschka, Jörg and Rossini, Alessandro},
  booktitle={2014 IEEE 6th International Conference on Cloud Computing Technology and Science}, 
  title={SRL: A Scalability Rule Language for Multi-cloud Environments}, 
  year={2014},
  volume={},
  number={},
  pages={1-9},
  abstract={The benefits of cloud computing have led to a proliferation of infrastructures and platforms covering the provisioning and deployment requirements of many cloud-based applications. However, the requirements of an application may change during its life cycle. Therefore, its provisioning and deployment should be adapted so that the application can deliver its target quality of service throughout its entire life cycle. Existing solutions typically support only simple adaptation scenarios, whereby scalability rules map conditions on fixed metrics to a single scaling action targeting a single cloud environment (e.g., Scale out an application component). However, these solutions fail to support complex adaptation scenarios, whereby scalability rules could map conditions on custom metrics to multiple scaling actions targeting multi-cloud environments. In this paper, we propose the Scalability Rule Language (SRL), a language for specifying scalability rules that support such complex adaptation scenarios of multi-cloud applications. SRL provides Eclipse-based tool support, thus allowing modellers not only to specify scalability rules but also to syntactically and semantically validate them. Moreover, SRL is well integrated with the Cloud Modelling Language (Cloud ML), thus allowing modellers to associate their scalability rules with the components and virtual machines of provisioning and deployment models.},
  keywords={},
  doi={10.1109/CloudCom.2014.170},
  ISSN={},
  month={Dec},}@ARTICLE{9121263,
  author={Junaid, Muhammad and Sohail, Adnan and Ahmed, Adeel and Baz, Abdullah and Khan, Imran Ali and Alhakami, Hosam},
  journal={IEEE Access}, 
  title={A Hybrid Model for Load Balancing in Cloud Using File Type Formatting}, 
  year={2020},
  volume={8},
  number={},
  pages={118135-118155},
  abstract={Maintaining accuracy in load balancing using metaheuristics is a difficult task even with the help of recent hybrid approaches. In the existing literature, various optimized metaheuristic approaches are being used to achieve their combined benefits for proper load balancing in the cloud. These approaches often adopt multi-objective QoS metrics, such as reduced SLA violations, reduced makespan, high throughput, low overload, low energy consumption, high optimization, minimum migrations, and higher response time. The cloud applications are generally computation-intensive and can grow exponentially in memory with the increase in size if no proper effective and efficient load balancing technique is adopted resulting in poor quality solutions. To provide a better load balancing solution in cloud computing, with extensive data, a new hybrid model is being proposed that performs classification on the number of files present in the cloud using file type formatting. The classification is performed using Support Vector Machine (SVM) considering various file formats such as audio, video, text maps, and images in the cloud. The resultant data class provides high classification accuracy which is further fed into a metaheuristic algorithm namely Ant Colony Optimization (ACO) using File Type Formatting FTF for better load balancing in the cloud. Frequently used QoS metrics, such as SLA violations, migration time, throughput time, overhead time, and optimization time are evaluated in the cloud environment and comparative analysis is performed with recent metaheuristics, such as Ant Colony Optimization-Particle Swarm Optimization (ACOPS), Chaotic Particle Swarm Optimization (CPSO), Q- learning Modified Particle Swarm Optimization (QMPSO), Cat Swarm Optimization (CSO) and D-ACOELB. The proposed algorithm outperforms them and provides good performance with scalability and robustness.},
  keywords={},
  doi={10.1109/ACCESS.2020.3003825},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7558009,
  author={Meng, Shunmei and Zhou, Zuojian and Huang, Taigui and Li, Duanchao and Wang, Song and Fei, Fan and Wang, Wenping and Dou, Wanchun},
  booktitle={2016 IEEE International Conference on Web Services (ICWS)}, 
  title={A Temporal-Aware Hybrid Collaborative Recommendation Method for Cloud Service}, 
  year={2016},
  volume={},
  number={},
  pages={252-259},
  abstract={With the rapid development of cloud computing, large scale of cloud services are provided to users. Recommender systems have been proven to be valuable tools to deal with information overload and be able to provide appropriate recommendations to users. The cloud environment is dynamic and uncertain, which makes the quality of cloud services time-sensitive. However, most existing recommender systems did not take temporal influence into consideration, therefore could not accommodate the dynamic cloud environment. In view of this challenge, we propose a temporal-aware hybrid collaborative recommendation method for cloud service. It aims at providing users with appropriate recommendations from time-sensitive cloud services. In our method, by distinguishing temporal QoS metrics from stable QoS metrics, temporal influence is integrated into classical neighborhood-based collaborative recommender algorithm. Besides, to get an optimal recommendation, a temporal-aware latent factor model based on tensor decomposition is proposed and combined to improve the recommendation performance. Finally, experiments are designed and conducted to demonstrate the efficiency of our method.},
  keywords={},
  doi={10.1109/ICWS.2016.40},
  ISSN={},
  month={June},}@INPROCEEDINGS{9500259,
  author={Ramos, Felipe and Viegas, Eduardo and Santin, Altair and Horchulhack, Pedro and dos Santos, Roger R. and Espindola, Allan},
  booktitle={ICC 2021 - IEEE International Conference on Communications}, 
  title={A Machine Learning Model for Detection of Docker-based APP Overbooking on Kubernetes}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Resource allocation overbooking is an approach used by cloud providers that allocates more virtual resources than available on physical hardware, which may imply service quality degradation. Docker in cloud computing environments is being increasingly used due to their fast provisioning and deployment, while the impact of overbooking of resources allocation due to multi-tenancy remains overlooked. This paper proposes a machine learning model to detect overbooking in Kubernetes environments within the docker container. The proposed model continuously monitors distributed container OS usage and application performance metrics. The collected metrics are used as input to a machine learning model that identifies multi-tenancy interference incurring in application performance degradation. Experiments performed on a Kubernetes cluster with a Docker-based Big Data processing application showed that our proposed model could detect resource overbooking with up to 98% accuracy. This implies an overbooking on a resource of up to 1.2 in the client’s domain.},
  keywords={},
  doi={10.1109/ICC42927.2021.9500259},
  ISSN={1938-1883},
  month={June},}@INPROCEEDINGS{7564810,
  author={Chatterjee, Subarna and Misra, Sudip},
  booktitle={2016 IEEE Wireless Communications and Networking Conference}, 
  title={QoS estimation and selection of CSP in oligopoly environment for Internet of Things}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={This work focuses on an automated selection of Cloud Service Provider (CSP) for a naive end-user in an IoT scenario. In traditional cloud computing model, the end-users are knowledgeable about the Virtual Machines (VMs) and are technically aware of their requirements in terms of the computing cores, processing abilities, and storage requirements. In case of IoT, the users are envisioned to be widespread from naive, unsophisticated people to even objects or things who are devoid of the required knowledge and expertise. Further, in IoT technology, multiple Cloud Service Providers (CSPs) may possess the potential of serving an IoT application. Therefore, it is required for the end-user to judiciously select a single CSP based on the maximum obtainable Quality of Service (QoS) from a CSP. This work proposes an algorithm QoS based Automated Selection of CSP (QASeC) for automated selection of a CSP from a set of nominated CSPs based on the maximum achievable QoS. The work identifies and models the QoS parameters for every CSP and defines a QoS utility metric for each CSP. Based on the metric, the work proposes an optimization for selection of the appropriate CSP and the cloud gateway associated with it. From the obtained results, we infer the suitability of QASeC in real-life IoT scenarios.},
  keywords={},
  doi={10.1109/WCNC.2016.7564810},
  ISSN={1558-2612},
  month={April},}@INPROCEEDINGS{9310816,
  author={Firdhous, M.F.M. and Budiarto, Rahmat},
  booktitle={2020 5th International Conference on Information Technology Research (ICITR)}, 
  title={BTDM: A QoS-based Trust Distribution Mechanism for Cloud Computing}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={Cloud computing makes the delivery of computing resources over the Internet as services. As there are many providers in the market, it is necessary to monitor their performance. Several mechanisms for monitoring service quality of providers have been reported in the literature. But, it is not possible to monitor the entire cloud system by a single monitor. Hence, there is a need for a mechanism to share the performance metrics across a large geographical area. In this paper, the authors propose a mechanism called Bayesian Trust Distribution Mechanism (BTDM) for sharing the performance metrics as trust scores across an extended geographical area. The proposed BTDM also checks the reliability of the received scores based on their previous experience and adjusts them based on the reliability of sender. BTDM was tested using simulations and the results show that it performs better than the other mechanisms reported in the literature.},
  keywords={},
  doi={10.1109/ICITR51448.2020.9310816},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8114483,
  author={Maiyama, Kabiru Muhammad and Kouvatsos, Demetres and Mohammed, Bashir and Kiran, Mariam and Kamala, Mumtaz Ahmed},
  booktitle={2017 IEEE 5th International Conference on Future Internet of Things and Cloud (FiCloud)}, 
  title={Performance Modelling and Analysis of an OpenStack IaaS Cloud Computing Platform}, 
  year={2017},
  volume={},
  number={},
  pages={198-205},
  abstract={Performance is one of the main aspects that should be taken into consideration during the design, development, tuning and optimisation of computer networks supported by cloud computing platforms (CCPs). Queueing network models (QNMs) of CCPs constitute essential quantitative tools of investigation towards identifying acceptable levels of quality-of-service (QoS), whether for upgrading an existing CCP or designing a new one. In this paper, a new stable open QNM with either single or multiple server queueing stations, first-come-first-served (FCFS) scheduling and random routing is proposed for the performance modelling and analysis of an OpenStack Infrastructure as a Service (IaaS) CCP. In this context, it is assumed that the external arrival process is Poisson and the queueing stations provide exponentially distributed service times. Based on Jackson's Theorem, the open QNM is decomposed into individual M/M/c queues with c server(s) (c≥ 1) and exponential inter-arrival and service times, each of which can be analysed in isolation. Consequently, closed form expressions for key performance metrics of the QNM are determined, such as those for the mean response time, throughput, server (resource) utilisation and the probability of the number of requests by clients at each queueing station during waiting for and/or receiving resource provisioning. The evaluation of these metrics identifies the bottlenecks of the CCP that are causing the worst network delays and associated performance degradation and thus, provides insights into the capacity planning of networks with OpenStack IaaS solutions for CSPs.},
  keywords={},
  doi={10.1109/FiCloud.2017.54},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{7930199,
  author={Haupt, Florian and Leymann, Frank and Scherer, Anton and Vukojevic-Haupt, Karolina},
  booktitle={2017 IEEE International Conference on Software Architecture (ICSA)}, 
  title={A Framework for the Structural Analysis of REST APIs}, 
  year={2017},
  volume={},
  number={},
  pages={55-58},
  abstract={Today, REST APIs have established as a means for realizing distributed systems and are supposed to gain even more importance in the context of Cloud Computing, Internet of Things, and Microservices. Nevertheless, many existing REST APIs are known to be not well-designed, resulting in the absence of desirable quality attributes that truly RESTful systems entail. Although existing analysis show, that many REST APIs are not fully REST compliant, it is still an open issue how to improve this deficit and where to start. In this work, we introduce a framework for the structural analysis of REST APIs based on their description documents, as this allows for a comprehensive, well-structured analysis approach that also includes analyzing the corresponding API description languages. A first validation builds on a set of 286 real world API descriptions available as Swagger documents, and comprises their transformation into a canonical metamodel for REST APIs as well as a metrics-based analysis and discussion of their structural characteristics with respect to compliance with the REST architectural style.},
  keywords={},
  doi={10.1109/ICSA.2017.40},
  ISSN={},
  month={April},}@INPROCEEDINGS{7515747,
  author={Farias, Victor A. E. and Sousa, Flávio R. C. and Maia, José G. R. and Gomes, João P. P. and Machado, Javam C.},
  booktitle={2016 16th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid)}, 
  title={Machine Learning Approach for Cloud NoSQL Databases Performance Modeling}, 
  year={2016},
  volume={},
  number={},
  pages={617-620},
  abstract={Cloud computing is a successful, emerging paradigm that supports on-demand services with pay-as-you-go model. With the exponential growth of data, NoSQL databases have been used to manage data in the cloud. In these newly emerging settings, mechanisms to guarantee Quality of Service heavily relies on performance predictability, i.e., the ability to estimate the impact of concurrent query execution on the performance of individual queries in a continuously evolving workload. This paper presents a performance modeling approach for NoSQL databases in terms of performance metrics which is capable of capturing the non-linear effects caused by concurrency and distribution aspects. Experimental results confirm that our performance modeling can accurately predict mean response time measurements under a wide range of workload configurations.},
  keywords={},
  doi={10.1109/CCGrid.2016.83},
  ISSN={},
  month={May},}@INPROCEEDINGS{7116128,
  author={Al-Jawad, Ahmed and Trestian, Ramona and Shah, Purav and Gemikonakli, Orhan},
  booktitle={Proceedings of the 2015 1st IEEE Conference on Network Softwarization (NetSoft)}, 
  title={BaProbSDN: A probabilistic-based QoS routing mechanism for Software Defined Networks}, 
  year={2015},
  volume={},
  number={},
  pages={1-5},
  abstract={Over the past decade there has been an exponential increase in the Internet traffic especially with the proliferation of cloud computing and other distributed data services. This explosion of data traffic with its dynamically changing traffic patterns and flows might result in degradation of the network performance. In this context, there is a need for an intelligent and efficient network management system that delivers guaranteed services. To this extent, this paper proposes BaProbSDN, a probabilistic Quality of Service (QoS) routing mechanism for Software Defined Networks (SDN). The QoS routing algorithm employs the bandwidth availability metric as a QoS routing constraint for unicast data delivery. BaProbSDN makes use of Bayes' theorem and Bayesian network model to determine the link probability in order to select the route that satisfies the given bandwidth constraint. The performance of the proposed probabilistic QoS routing algorithm was tested in a simulation-based environment and compared against the widest-shortest path routing (WSR) algorithm. The results demonstrate that BaProbSDN can achieve up to 8.02% decrease in the bandwidth blocking rate when compared to WSR in the presence of link update inaccuracies of threshold and time delay.},
  keywords={},
  doi={10.1109/NETSOFT.2015.7116128},
  ISSN={},
  month={April},}@INPROCEEDINGS{8079983,
  author={Gabi, Danlami and Ismail, Abdul Samad and Zainal, Anazida and Zakaria, Zalmiyah and Al-Khasawneh, Ahmad},
  booktitle={2017 8th International Conference on Information Technology (ICIT)}, 
  title={Cloud scalable multi-objective task scheduling algorithm for cloud computing using cat swarm optimization and simulated annealing}, 
  year={2017},
  volume={},
  number={},
  pages={1007-1012},
  abstract={In cloud computing, customers-desired Quality of Service (QoS) expectations are quite superficial due to lack of scalable task scheduling solutions that can adjust to long-time changes. Researchers in the literature have put forward several task scheduling algorithms to account for customers' QoS expectations. Unfortunately, most of these algorithms need improvements to ensure the provisioning of better consumers' QoS expectation. In this study, a Multi-Objective QoS model to address customers' expectation based on execution time and execution cost criteria is presented. A Cloud Scalable Multi-Objective Cat Swarm Optimization (CSO) based Simulated Annealing (SA) (CSM-CSOSA) algorithm is then proposed to solve the model. In this method, the Taguchi Orthogonal approach is used to enhanced the SA and incorporated into the local search of the proposed algorithm for enhancing it exploration capability. Implementation of the algorithm is carried out on CloudSim tool and evaluated using one dataset (Normal distributed) and one Parallel Workload (High-Performance Computing Center North(HPC2N)). Quantitative analysis of the algorithm performance is taken based on metrics of execution time, execution cost, QoS and percentage improvement. Result obtained is compared with that of Multi-Objective Genetic Algorithm (MOGA), Multi-Objective Ant Colony (MOSACO) and Multi-Objective Particle Swarm Optimization (MOPSO), where proposed method is able to return substantial performance with improved QoS.},
  keywords={},
  doi={10.1109/ICITECH.2017.8079983},
  ISSN={},
  month={May},}@INPROCEEDINGS{8646562,
  author={Zhu, Hongbin and Wang, Haifeng and Luo, Xiliang and Qian, Hua},
  booktitle={2018 IEEE Global Conference on Signal and Information Processing (GlobalSIP)}, 
  title={AN ONLINE LEARNING APPROACH TO WIRELESS COMPUTATION OFFLOADING}, 
  year={2018},
  volume={},
  number={},
  pages={678-682},
  abstract={Fog computing extends cloud computing and services to the edge of networks, bringing advantages of the cloud closer to where data is created and acted upon. To support real time applications, latency performance is a crucial metric in fog computing. In this paper, we consider a sequential decision-making problem for computation offloading with unknown dynamics in which a mobile user offloads its arrival tasks to associated fog nodes (FNs) at each time slot. The queue of arrival tasks at each FN is modeled as a Markov chain. In order to provide satisfactory quality of experience, the network latency, which is directly associated with the queue condition, needs to be minimized. Taking advantage of reinforcement learning, the sequential decision-making problem is formulated as a restless multi-armed bandit problem. We construct a policy with interleaved exploration and exploitation stages, which achieves a regret with sub-linear order. Both analytical and simulation results validate the effectiveness of the proposed method in dealing with sequential decision-making problem.},
  keywords={},
  doi={10.1109/GlobalSIP.2018.8646562},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8936206,
  author={Lima, Diana Bezerra Correia and da Silva Lima, Rubens Matheus Brasil and de Farias Medeiros, Douglas and Pereira, Renata Imaculada Soares and de Souza, Cleonilson Protasio and Baiocchi, Orlando},
  booktitle={2019 IEEE 10th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON)}, 
  title={A Performance Evaluation of Raspberry Pi Zero W Based Gateway Running MQTT Broker for IoT}, 
  year={2019},
  volume={},
  number={},
  pages={0076-0081},
  abstract={The Internet of Things (IoT) has become widely used in recent years in a wide range of applications, such as, weather condition monitoring, transportation, smart homes, smart cities, smart farm, etc. The ecosystem of the IoT is also vast, including from sensor and hardware devices up to cloud-computing. An approach that is getting more and more attention in the IoT ecosystem is the edge-computing and one of its fundamental pieces of equipment is the edge-computing gateway (GTW), which can working as a data-processing device nearer to the things and as a bridge to the Internet, as well. The most important features for these GTWs must be robustness and efficiency and a very popular solution is to use low-cost Raspberry Pi card-size computers. Considering protocol solution, Message Queue Telemetry Transport (MQTT) communication protocol has been considered one of the most applicable to IoT because of its low-power capability. In this context, this paper describes a study about the performance evaluation of a low-power member of the Raspberry Pi family, the Raspberry Pi Zero W, working as an IoT gateway and running MQTT. The experimental results show its performance using as metrics: the processor temperature, the CPU usage level, and rate of MQTT received messages under different Quality of Services (QoS).},
  keywords={},
  doi={10.1109/IEMCON.2019.8936206},
  ISSN={2644-3163},
  month={Oct},}@INPROCEEDINGS{8641090,
  author={Xu, Jianwen and Ota, Kaoru and Dong, Mianxiong},
  booktitle={2018 IEEE/CIC International Conference on Communications in China (ICCC)}, 
  title={Plug-and-Play for Fog: Dynamic Service Placement in Wireless Multimedia Networks}, 
  year={2018},
  volume={},
  number={},
  pages={490-494},
  abstract={Initially as an extension of cloud computing, fog computing has been inspiring new ideas about moving computing tasks to the edge of a network. In fog, we often repeat the procedure of placing service because of the geographical distribution of mobile users. We may not expect a fixed demand and supply relationship between users and service providers since users always prefer nearby service with less time delay and transmission consumption. That is, a plug-and-play service mode is what we need in fog. In this paper, we put forward a dynamic placement strategy for fog service in a three-tier wireless multimedia network to guarantee the normal service provision and optimize the Quality of Service (QoS). The simulation results show that our strategy can achieve better performance under metrics including energy consumption and end-to-end latency compared with existed methods.},
  keywords={},
  doi={10.1109/ICCChina.2018.8641090},
  ISSN={2377-8644},
  month={Aug},}@INPROCEEDINGS{6927024,
  author={Mdhaffar, Afef and Halima, Riadh Ben and Jmaiel, Mohamed and Freisleben, Bernd},
  booktitle={2014 IEEE 23rd International WETICE Conference}, 
  title={CEP4Cloud: Complex Event Processing for Self-Healing Clouds}, 
  year={2014},
  volume={},
  number={},
  pages={62-67},
  abstract={This paper presents a cross-layer self-healing approach for Cloud computing environments, based on the Complex Event Processing method. It analyzes monitored events to detect performance-related problems and performs action to fix them without human intervention. Our proposal makes use of novel analysis rules, derived from a comprehensive study of the relationships between monitored metrics across multiple Cloud layers. The results of our study are used to define and optimize the analysis rules and identify the causes of performance-related problems. The results of several experiments demonstrate the benefits of the proposed approach in terms of speeding up the analysis without affecting the quality of the diagnosis.},
  keywords={},
  doi={10.1109/WETICE.2014.56},
  ISSN={1524-4547},
  month={June},}
