@ARTICLE{10251860,
  author={Al-Debagy, O. and Martinek, P.},
  journal={Journal of Web Engineering}, 
  title={A Metrics Framework for Evaluating Microservices Architecture Designs}, 
  year={2020},
  volume={19},
  number={3–4},
  pages={341-370},
  abstract={Microservices are becoming a more popular software architecture among companies and developers. Therefore, there is a need to develop methods for quantifying the process of measuring the quality of microservices design. This paper has created a novel set of metrics for microservices architecture applications. The proposed metrics are the Service Granularity Metric “SGM”, the Lack of Cohesion Metric “LCOM”, and the Number of Operations “NOO”. The proposed metrics measure the granularity, cohesion, and complexity of individual microservices through analyzing the application programming interface “API”. Using these metrics, it is possible to evaluate the overall quality of the design of microservices applications. The proposed metrics were measured on 5 applications with different sizes and business cases. This research found that the value for the SGM metric needs to be between 0.2 and 0.6. Besides, the value of LCOM metric for a microservice needs to be between 0 and 0.8 with less than ten operations per microservice. These findings can be applied in the decomposition process of monolithic applications as well.},
  keywords={},
  doi={10.13052/jwe1540-9589.19341},
  ISSN={1544-5976},
  month={June},}@INPROCEEDINGS{9101318,
  author={Santos, Nuno and Rito Silva, António},
  booktitle={2020 IEEE International Conference on Software Architecture (ICSA)}, 
  title={A Complexity Metric for Microservices Architecture Migration}, 
  year={2020},
  volume={},
  number={},
  pages={169-178},
  abstract={Monolith applications tend to be difficult to deploy, upgrade, maintain, and understand. Microservices, on the other hand, have the advantages of being independently developed, tested, deployed, scaled and, more importantly, easier to change and maintain. This paper addresses the problem of migrating a monolith to a microservices architecture. Therefore, we address two research questions: (1) Can we define the cost of decomposition in terms of the effort to redesign a functionality, which is implemented in the monolith as an ACID transaction, into several distributed transactions? (2) Considering several similarity measures between domain entities, which provide a better decomposition when they are compared using the proposed complexity metric? To answer the first research question, we propose a complexity metric, for each functionality of the monolith application, that measures the impact of relaxing the functionality consistency on the architecture redesign and implementation. Regarding the second research question, we experiment with four similarity measures, each based on a different type of information collected from monolith functionality implementation. We evaluated our approach with three monolith systems and compared our complexity metric against industry metrics of cohesion and coupling. We also evaluated the different similarity measures in terms of the complexity of the decomposition they produce. We were able to correctly correlate the complexity metric with other metrics of cohesion and coupling defined in other research and we conclude that no single combination of similarity measures outperforms the other, which is confirmed by the existing research. Additionally, we conclude that the approach can help on an incremental migration to microservices, which, actually, is the strategy proposed by the industry experts.},
  keywords={},
  doi={10.1109/ICSA47634.2020.00024},
  ISSN={},
  month={March},}@INPROCEEDINGS{9012140,
  author={Raj, Vinay and Ravichandra, S.},
  booktitle={2018 3rd IEEE International Conference on Recent Trends in Electronics, Information & Communication Technology (RTEICT)}, 
  title={Microservices: A perfect SOA based solution for Enterprise Applications compared to Web Services}, 
  year={2018},
  volume={},
  number={},
  pages={1531-1536},
  abstract={The Software Engineering community has defined different types of architectures to build applications. One among them is Service Oriented Architecture(SOA) which has created significant impact the way software applications are built. There are many implementations of SOA like Web Services, REST services etc. But Web Services and REST services do not fully follow all the principles of SOA. Microservices as an architectural style recently emerged from SOA by which we can develop business requirements with loosely coupled, self deploying and scalable services. Microservices have gained more popularity in application development as they are easy to understand, scale and deploy. In this paper we discuss principles of SOA, major drawbacks of web services and benefits of Microservices over SOA based web services. We have highlighted the importance of Microservices in software development. This paper gives information for architects as to why choose Microservices architecture over web services. We have also discussed metrics used for calculating Coupling between services and we evaluated by considering a smart payment application for ecommerce which is built using both the styles. We observed that Microservices architectural style has less coupling between services compared to Web Service style based on the metric values of the application.},
  keywords={},
  doi={10.1109/RTEICT42901.2018.9012140},
  ISSN={},
  month={May},}@INPROCEEDINGS{9095617,
  author={Rosa, Thatiane de Oliveira and Goldman, Alfredo and Guerra, Eduardo Martins},
  booktitle={2020 IEEE International Conference on Software Architecture Companion (ICSA-C)}, 
  title={How ‘micro’ are your services?}, 
  year={2020},
  volume={},
  number={},
  pages={75-78},
  abstract={Microservice is an architectural style that proposes that a complex system should be developed from small and independent services that work together. There is not a welldefined boundary about when a software architecture can be considered based on microservices or not. Because of that, defining microservices context and infrastructure is challenging, especially to characterize aspects related to microservice size, data consistency, and microservices coupling. Thus, it is crucial to understand the microservices-based software characteristics, to comprehend the impact of some evolutions on architecture, and evaluate how much a particular architecture fits the microservices architectural style. Therefore, based on bibliographic research and case studies conducted in academical and industrial environments, we aim to propose a model to characterize the architecture structure based on the main guidelines of the microservice architectural style. This model introduces dimensions that measure characteristics based on modules size, coupling to data sources, and service collaboration. This study should facilitate the mapping, measurement, and monitoring of different impacts generated in the software architecture from increments and refactoring performed. This work is on the initial development stage and as a result, we expected that the model supports architectural decisions that consider different quality attributes to achieve the right balance between service independence and collaboration for a given system.},
  keywords={},
  doi={10.1109/ICSA-C50368.2020.00023},
  ISSN={},
  month={March},}@INPROCEEDINGS{9672417,
  author={Yilmaz, Rahime and Buzluca, Feza},
  booktitle={2021 2nd International Informatics and Software Engineering Conference (IISEC)}, 
  title={A Fuzzy Quality Model to Measure the Maintainability of Microservice Architectures}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Microservice architecture (MSA) is a type of software and systems architecture that is based on the modularization principle. It proposes designing systems employing small-scaled, loosely coupled, and independently deployable microservices. There are several benefits of microservices architecture in terms of maintainability, scalability, and productivity which have led to rise in its popularity. Even though there are several studies about development in MSA, the studies on the quality of the microservice-based systems are limited. In this study, we propose a quality model based on fuzzy logic to measure and assess quality attributes of systems in MSA that can be used by software architects, developers, and project managers. We focus on maintainability of microservices because it is one of the most important quality attributes of software systems. We identified sub-characteristics and properties of microservices that affect maintainability, and constructed a hierarchical quality model based on ISO/IEC 250xy standard SQuaRE (System and Software Quality Requirements and Evaluation). Our fuzzy model measures maintainability of microservices in three levels, i.e., low, medium, and high. We provided a basis for the development and application of quality models in industrial practice as well as a basis for further extension. To demonstrate and evaluate our methodology, we used open-source applications designed in MSA. The results show that our method can assess maintainability of microservices realistically.},
  keywords={},
  doi={10.1109/IISEC54230.2021.9672417},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9095641,
  author={Avritzer, Alberto},
  booktitle={2020 IEEE International Conference on Software Architecture Companion (ICSA-C)}, 
  title={Challenges and Approaches for the Assessment of Micro-Service Architecture Deployment Alternatives in DevOps : A tutorial presented at ICSA 2020}, 
  year={2020},
  volume={},
  number={},
  pages={1-2},
  abstract={The goal of this tutorial is to provide an overview of challenges and approaches for architecture/dependability assessment in the context of DevOps and microservices. Specifically, we present approaches that employ operational data obtained from production-level application performance management (APM) tools, giving access to operational workload profiles, architectural information, failure models, and security intrusions. We use this data to automatically create and conFigure architecture assessments based on models, load tests, and resilience benchmarks. The focus of this tutorial is on approaches that employ production usage, because these approaches provide more accurate recommendations for microservice architecture dependability assessment than approaches that do not consider production usage.We present an overview of (1) the state-of-the-art approaches for obtaining operational data from production systems using APM tools, (2) the challenges of dependability for DevOps and microservices, (3) selected approaches based on operational data to assess dependability. The architecture assessment focus of this tutorial is on scalability, resilience, survivability, and security. Particularly, we present a demo of the automated approach for the evaluation of a domain-based scalability and security metric assessment that is based on the microservice architecture ability to satisfy the performance requirement under load and/or intrusions. We illustrate the approach by presenting experimental results using a benchmark microservice architecture.},
  keywords={},
  doi={10.1109/ICSA-C50368.2020.00007},
  ISSN={},
  month={March},}@INPROCEEDINGS{9568289,
  author={Weerasinghe, L. D. S. B. and Perera, Indika},
  booktitle={2021 International Research Conference on Smart Computing and Systems Engineering (SCSE)}, 
  title={An exploratory evaluation of replacing ESB with microservices in service-oriented architecture}, 
  year={2021},
  volume={4},
  number={},
  pages={137-144},
  abstract={With the continuous progress in technology during the past few decades, cloud computing has become a fast-growing technology in the world, making computerized systems widespread. The emergence of Cloud Computing has evolved towards microservice concepts, which are highly demanded by corporates for enterprise application level. Most enterprise applications have moved away from traditional unified models of software programs like monolithic architecture and traditional SOA architecture to microservice architecture to ensure better scalability, lesser investment in hardware, and high performance. The monolithic architecture is designed in a manner that all the components and the modules are packed together and deployed on a single binary. However, in the microservice architecture, components are developed as small services so that horizontally and vertically scaling is made easier in comparison to monolith or SOA architecture. SOA and monolithic architecture are at a disadvantage compared to Microservice architecture, as they require colossal hardware specifications to scale the software. In general terms, the system performance of these architectures can be measured considering different aspects such as system capacity, throughput, and latency. This research focuses on how scalability and performance software quality attributes behave when converting the SOA system to microservice architecture. Experimental results have shown that microservice architecture can bring more scalability with a minimum cost generation. Nevertheless, specific gaps in performance are identified in the perspective of the final user experiences due to the interservice communication in the microservice architecture in a distributed environment.},
  keywords={},
  doi={10.1109/SCSE53661.2021.9568289},
  ISSN={2613-8662},
  month={Sep.},}@INPROCEEDINGS{9335808,
  author={Levin, Joshua and Benson, Theophilus A.},
  booktitle={2020 IEEE 9th International Conference on Cloud Networking (CloudNet)}, 
  title={ViperProbe: Rethinking Microservice Observability with eBPF}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={Recent shifts to microservice-based architectures and the supporting servicemesh radically disrupt the landscape of performance-oriented management tasks. While the adoption of frameworks like Istio and Kubernetes ease the management and organization of such systems, they do not themselves provide strong observability. Microservice observability requires diverse, highly specialized, and often adaptive, metrics and algorithms to monitor both the health of individual services and the larger application. However, modern metrics collection frameworks are relatively static and rigid. We introduce ViperProbe, an eBPF-based microservices collection framework that provides (1) dynamic sampling and (2) collection of deep, diverse, and precise system metrics. Viper-Probe builds on the observation that the adoption of a common set of design patterns, e.g., servicemesh, enables offline analysis. By examining the performance profile of these patterns before deploying on production, ViperProbe can effectively reduce the set of collected metrics, thereby improving the efficiency and effectiveness of those metrics. To the best of our knowledge, ViperProbe is the first scalable eBPF-based dynamic and adaptive microservices metrics collection framework. Our results show ViperProbe has limited overhead, while significantly more effective for traditional management tasks, e.g., horizontal autoscaling.},
  keywords={},
  doi={10.1109/CloudNet51028.2020.9335808},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8466390,
  author={Perera, K. J. P. G. and Perera, I.},
  booktitle={2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS)}, 
  title={TheArchitect: A Serverless-Microservices Based High-level Architecture Generation Tool}, 
  year={2018},
  volume={},
  number={},
  pages={204-210},
  abstract={Software is ubiquitous in today's systems and business operations. Most importantly the architecture of a software system determines its quality and longevity, because the development work related to the software system will be carried out to be in line with its architecture design. Hence, it's highly important to structure the high-level software architecture accordingly to deliver the expected customer requirements while accounting for quality measures such as scalability, high availability and high performance. We propose TheArchitect, a serverless-microservices based high-level architecture generation tool, which will auto generate serverless-microservices based high-level architecture for a given business application, preserving the highlighted quality measures providing a tool based support for the software architect with respect to designing the high-level architecture. TheArchitect will provide any software developer to generate a proper architecture minimizing the involvement of an experienced software architect. Furthermore, the positives that microservices and serverless technologies has brought to the world of software engineering has made the software engineering community shift from the era of building large monolith applications containing overly complex designs, to microservices and serverless based technologies. Hence TheArchitect focuses on generating best fitted microservices and serverless based high-level architecture for a given application.},
  keywords={},
  doi={10.1109/ICIS.2018.8466390},
  ISSN={},
  month={June},}@INPROCEEDINGS{8544423,
  author={Perera, K. J. P. G. and Perera, I.},
  booktitle={2018 IEEE International Systems Engineering Symposium (ISSE)}, 
  title={A Rule-based System for Automated Generation of Serverless-Microservices Architecture}, 
  year={2018},
  volume={},
  number={},
  pages={1-8},
  abstract={Software being ubiquitous in today's systems and business operations, it's highly important to structure the high-level architecture of a software application accordingly to deliver the expected customer requirements while accounting for quality measures such as scalability, high availability and high performance. We propose The Architect, a rule-based system for serverless-microservices based high-level architecture generation. In the process of auto generating serverless-microservices high-level architecture, TheArchitect will preserve the highlighted quality measures. It will also provide a tool based support for the high-level architecture designing process of the software architect. Any software developer will be able to use TheArchitect to generate a proper architecture minimizing the involvement of a software architect. Furthermore, the positives of microservices and serverless technologies have made a significant impact on the software engineering community in terms of shifting from the era of building large monolith applications containing overly complex designs, to microservices and serverless based technologies. Hence The Architect focuses on generating best fitted microservices and serverless based high-level architecture for a given application.},
  keywords={},
  doi={10.1109/SysEng.2018.8544423},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8029803,
  author={Mazlami, Genc and Cito, Jürgen and Leitner, Philipp},
  booktitle={2017 IEEE International Conference on Web Services (ICWS)}, 
  title={Extraction of Microservices from Monolithic Software Architectures}, 
  year={2017},
  volume={},
  number={},
  pages={524-531},
  abstract={Driven by developments such as mobile computing, cloud computing infrastructure, DevOps and elastic computing, the microservice architectural style has emerged as a new alternative to the monolithic style for designing large software systems. Monolithic legacy applications in industry undergo a migration to microservice-oriented architectures. A key challenge in this context is the extraction of microservices from existing monolithic code bases. While informal migration patterns and techniques exist, there is a lack of formal models and automated support tools in that area. This paper tackles that challenge by presenting a formal microservice extraction model to allow algorithmic recommendation of microservice candidates in a refactoring and migration scenario. The formal model is implemented in a web-based prototype. A performance evaluation demonstrates that the presented approach provides adequate performance. The recommendation quality is evaluated quantitatively by custom microservice-specific metrics. The results show that the produced microservice candidates lower the average development team size down to half of the original size or lower. Furthermore, the size of recommended microservice conforms with microservice sizing reported by empirical surveys and the domain-specific redundancy among different microservices is kept at a low rate.},
  keywords={},
  doi={10.1109/ICWS.2017.61},
  ISSN={},
  month={June},}@INPROCEEDINGS{7965739,
  author={Asik, Tugrul and Selcuk, Yunus Emre},
  booktitle={2017 IEEE 15th International Conference on Software Engineering Research, Management and Applications (SERA)}, 
  title={Policy enforcement upon software based on microservice architecture}, 
  year={2017},
  volume={},
  number={},
  pages={283-287},
  abstract={Microservice is an architectural style that has recently started gaining popularity to become a new architectural phenomenon. Microservice architecture provides new opportunities to deploy scalable, language free and dynamically adjustable applications. This type of applications consist of hundreds or more of service instances. So that, management, monitoring, refactoring and testing of applications are more complex than monolithic applications. Therefore, some metrics and policies for measuring the quality of an application which is based on microservice architecture is needed. Moreover, automated tools are needed to carry out those tasks and enforce those policies. This work represents such metrics and policies. Additionally, an automated tool is implemented for automatic analysis of those metrics and policies upon software.},
  keywords={},
  doi={10.1109/SERA.2017.7965739},
  ISSN={},
  month={June},}@INPROCEEDINGS{9527003,
  author={Weng, Tianjun and Yang, Wanqi and Yu, Guangba and Chen, Pengfei and Cui, Jieqi and Zhang, Chuanfu},
  booktitle={2021 IEEE/ACM International Workshop on Cloud Intelligence (CloudIntelligence)}, 
  title={Kmon: An In-kernel Transparent Monitoring System for Microservice Systems with eBPF}, 
  year={2021},
  volume={},
  number={},
  pages={25-30},
  abstract={Currently, the architecture of software systems is shifting from “monolith” to “microservice” which is an important enabling technology of cloud native systems. Since the advantages of microservice in agility, efficiency, and scaling, it has become the most popular architecture in the industry. However, as the increase of microservice complexity and scale, it becomes challenging to monitor such a large number of microservices. Traditional monitoring techniques such as end-to-end tracing cannot well fit microservice environment, because they need code instrumentation with great effort. Moreover, they cannot explore the fine-grained internal states of microservice instances. To tackle this problem, we propose Kmon, which is an In-kernel transparent monitoring system for microservice systems with extended Berkeley Packet Filter (eBPF). Kmon can provide multiple kinds of run-time information of micrservices such as latency, topology, performance metrics with a low overhead.},
  keywords={},
  doi={10.1109/CloudIntelligence52565.2021.00014},
  ISSN={},
  month={May},}@INPROCEEDINGS{9359175,
  author={Cui, Jieqi and Chen, Pengfei and Yu, Guangba},
  booktitle={2020 IEEE 26th International Conference on Parallel and Distributed Systems (ICPADS)}, 
  title={A Learning-based Dynamic Load Balancing Approach for Microservice Systems in Multi-cloud Environment}, 
  year={2020},
  volume={},
  number={},
  pages={334-341},
  abstract={Multi-cloud environment has become common since companies manage to prevent cloud vendor lock-in for security and cost concerns. Meanwhile, the microservice architecture is often considered for its flexibility. Combining multi-cloud with microservice, the problem of routing requests among all possible microservice instances in multi-cloud environment arises. This paper presents a learning-based approach to route requests in order to balance the load. In our approach, the performance of microservice is modeled explicitly through machine learning models. The model can derive the response time from request volume, route decision, and other cloud metrics. Then the balanced route decision is obtained from optimizing the model with Bayesian Optimization. With this approach, the request route decision can adjust to dynamic runtime metrics instead of remaining static for all different circumstances. Explicit performance modeling avoids searching on an actual microservice system which is time-consuming. Experiments show that our approach reduces average response time by 10% at least.},
  keywords={},
  doi={10.1109/ICPADS51040.2020.00052},
  ISSN={2690-5965},
  month={Dec},}@INPROCEEDINGS{9101217,
  author={Zhang, Yukun and Liu, Bo and Dai, Liyun and Chen, Kang and Cao, Xuelian},
  booktitle={2020 IEEE International Conference on Software Architecture (ICSA)}, 
  title={Automated Microservice Identification in Legacy Systems with Functional and Non-Functional Metrics}, 
  year={2020},
  volume={},
  number={},
  pages={135-145},
  abstract={Since microservice has merged as a promising architectural style with advantages in maintainability, scalability, evolvability, etc., increasing companies choose to restructure their legacy monolithic software systems as the microservice architecture. However, it is quite a challenge to properly partitioning the systems into suitable parts as microservices. Most approaches perform microservices identification from a function-splitting perspective and with sufficient legacy software artifacts. That may be not realistic in industrial practices and possibly results in generating unexpected microservices. To address this, we proposed an automated microservice identification (AMI) approach that extracts microservices from the execution and performance logs without providing documentation, models or source codes, while taking both functional and non-functional metrics into considerations. Our work firstly collects logs from the executable legacy system. Then, controller objects (COs) are identified as the key objects to converge strongly related subordinate objects (SOs). Subsequently, the relation between each pair of CO and SO is evaluated by a relation matrix from both the functional and non-functional perspective. We ultimately cluster classes(objects) into the microservices by optimizing the multi-objective of high-cohesion-low-coupling and load balance. The usefulness of the proposed approach is illustrated by applying to a case study.},
  keywords={},
  doi={10.1109/ICSA47634.2020.00021},
  ISSN={},
  month={March},}@INPROCEEDINGS{9110450,
  author={Lin, Thomas and Leon-Garcia, Alberto},
  booktitle={NOMS 2020 - 2020 IEEE/IFIP Network Operations and Management Symposium}, 
  title={Towards a Client-Centric QoS Auto-Scaling System}, 
  year={2020},
  volume={},
  number={},
  pages={1-9},
  abstract={Many modern day cloud services are composites of multiple smaller services working correctly together. This design has become increasingly prevalent due to the rise of the microservices application architecture, as well as service chaining in Network Function Virtualization (NFV). Future composite applications and services will be deployed on multi-tier clouds where their constituent microservices may be geographically spread over different regions. To optimize the delivery of such composites, the constituent microservices must be placed in locations where their clients, which may be other microservices, are able to meet certain QoS constraints. We propose an architecture and present a prototype system for incorporating network metrics into the auto-scaling and scheduling decisions of cloud management systems. Given a service with QoS constraints, our system monitors the network metrics (e.g. latency and bandwidth) of their clients. If a particular client is unable to receive the required latency or bandwidth of the service, our system auto-scales the service and strategically places the new instance(s) in a location capable of meeting the service quality, and re-directs traffic to the new instance.},
  keywords={},
  doi={10.1109/NOMS47738.2020.9110450},
  ISSN={2374-9709},
  month={April},}@INPROCEEDINGS{9101266,
  author={Selmadji, Anfel and Seriai, Abdelhak-Djamel and Bouziane, Hinde Lilia and Oumarou Mahamane, Rahina and Zaragoza, Pascal and Dony, Christophe},
  booktitle={2020 IEEE International Conference on Software Architecture (ICSA)}, 
  title={From Monolithic Architecture Style to Microservice one Based on a Semi-Automatic Approach}, 
  year={2020},
  volume={},
  number={},
  pages={157-168},
  abstract={Due to its tremendous advantages, microservice architectural style has become an essential element for the development of applications deployed on the cloud and for those adopting the DevOps practices. Nevertheless, while microservices can be used to develop new applications, there are monolithic ones, that are not well adapted neither to the cloud nor to DevOps. Migrating these applications towards microservices appears as a solution to adapt them to both. In this context, we propose an approach aiming to achieve this objective by focusing on the step of microservices identification. The proposed identification, in this paper, is based on an analysis of the relationships between source code elements, their relationships with the persistent data manipulated in this code and finally the knowledge, often partial, of the architect concerning the system to migrate. A function that measures the quality of a microservice based on its ability to provide consistent service and its interdependence with others microservice in the resulting architecture was defined. Moreover, the architect recommendations are used, when available, to guide the identification process. The conducted experiment shows the relevance of the obtained microservices by our approach.},
  keywords={},
  doi={10.1109/ICSA47634.2020.00023},
  ISSN={},
  month={March},}@INPROCEEDINGS{9165482,
  author={Khan, Michel Gokan and Taheri, Javid and Khoshkholghi, Mohammad Ali and Kassler, Andreas and Cartwright, Carolyn and Darula, Marian and Deng, Shuiguang},
  booktitle={2020 6th IEEE Conference on Network Softwarization (NetSoft)}, 
  title={A Performance Modelling Approach for SLA-Aware Resource Recommendation in Cloud Native Network Functions}, 
  year={2020},
  volume={},
  number={},
  pages={292-300},
  abstract={Network Function Virtualization (NFV) becomes the primary driver for the evolution of 5G networks, and in recent years, Network Function Cloudification (NFC) proved to be an inevitable part of this evolution. Microservice architecture also becomes the de facto choice for designing a modern Cloud Native Network Function (CNF) due to its ability to decouple components of each CNF into multiple independently manageable microservices. Even though taking advantage of microservice architecture in designing CNFs solves specific problems, this additional granularity makes estimating resource requirements for a Production Environment (PE) a complex task and sometimes leads to an over-provisioned PE. Traditionally, performance engineers dimension each CNF within a Service Function Chain (SFC) in a smaller Performance Testing Environment (PTE) through a series of performance benchmarks. Then, considering the Quality of Service (QoS) constraints of a Service Provider (SP) that are guaranteed in the Service Level Agreement (SLA), they estimate the required resources to set up the PE. In this paper, we used a machine learning approach to model the impact of each microservice's resource configuration (i.e., CPU and memory) on the QoS metrics (i.e. serving throughput and latency) of each SFC in a PTE. Then, considering an SP's Service Level Objectives (SLO), we proposed an algorithm to predict each microservice's resource capacities in a PE. We evaluated the accuracy of our prediction on a prototype of a cloud native 5G Home Subscriber Server (HSS). Our model showed 95%-78% accuracy in a PE that has 2-5 times more computing resources than the PTE.},
  keywords={},
  doi={10.1109/NetSoft48620.2020.9165482},
  ISSN={},
  month={June},}@INPROCEEDINGS{9237055,
  author={Shiraishi, Takashi and Noro, Masaaki and Kondo, Reiko and Takano, Yosuke and Oguchi, Naoki},
  booktitle={2020 21st Asia-Pacific Network Operations and Management Symposium (APNOMS)}, 
  title={Real-time Monitoring System for Container Networks in the Era of Microservices}, 
  year={2020},
  volume={},
  number={},
  pages={161-166},
  abstract={Large-scale web services are increasingly adopting the microservice architecture that mainly utilizes container technologies. Microservices are operated on complex configured infrastructures, such as containers, virtual machines, and physical machines. To ensure service quality of microservices, it is important to monitor not only the quality of services but also the quality of the infrastructures utilized by the services. Therefore, the metrics of the infrastructure related with the services should be traced. An extended Berkeley Packet Filter (eBPF) is a relatively new Linux's function, which is effectively used as a sensor of container-network metrics. There are two key challenges in realizing the service-linked monitoring system. One challenge is making the full-stack topology between microservices, containers, and machines visible to set the sensor related with the services. Another challenge is dynamic sensor management that can relocate the sensor quickly after the topology's change. In this paper, we propose a real-time monitoring system that creates a full-stack topology and relocates the sensor in conjunction with events from a container orchestrator. The system enables a dynamic deployment of the sensors related with the monitored services.},
  keywords={},
  doi={10.23919/APNOMS50412.2020.9237055},
  ISSN={2576-8565},
  month={Sep.},}@INPROCEEDINGS{9285951,
  author={Rossi, Fabiana and Cardellini, Valeria and Presti, Francesco Lo},
  booktitle={2020 28th International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems (MASCOTS)}, 
  title={Self-adaptive Threshold-based Policy for Microservices Elasticity}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={The microservice architecture structures an application as a collection of loosely coupled and distributed services. Since application workloads usually change over time, the number of replicas per microservice should be accordingly scaled at run-time. The most widely adopted scaling policy relies on statically defined thresholds, expressed in terms of system-oriented metrics. This policy might not be well-suited to scale multi-component and latency-sensitive applications, which express requirements in terms of response time. In this paper, we present a two-layered hierarchical solution for controlling the elasticity of microservice-based applications. The higher-level controller estimates the microservice contribution to the application performance, and informs the lower-level components. The latter accordingly scale the single microservices using a dynamic threshold-based policy. So, we propose MB Threshold and QL Threshold, two policies that employ respectively model-based and model-free reinforcement learning approaches to learn threshold update strategies. These policies can compute different thresholds for the different application components, according to the desired deployment objectives. A wide set of simulation results shows the benefits and flexibility of the proposed solution, emphasizing the advantages of using dynamic thresholds over the most adopted policy that uses static thresholds.},
  keywords={},
  doi={10.1109/MASCOTS50786.2020.9285951},
  ISSN={2375-0227},
  month={Nov},}@INPROCEEDINGS{9590257,
  author={Agarwal, Shivali and Sinha, Raunak and Sridhara, Giriprasad and Das, Pratap and Desai, Utkarsh and Tamilselvam, Srikanth and Singhee, Amith and Nakamuro, Hiroaki},
  booktitle={2021 IEEE International Conference on Web Services (ICWS)}, 
  title={Monolith to Microservice Candidates using Business Functionality Inference}, 
  year={2021},
  volume={},
  number={},
  pages={758-763},
  abstract={In this paper, we propose a novel approach for monolith decomposition, that maps the implementation structure of a monolith application to a functional structure that in turn can be mapped to business functionality. First, we infer the classes in the monolith application that are distinctively representative of the business functionality in the application domain. This is done using formal concept analysis on statically determined code flow structures in a completely automated manner. Then, we apply a clustering technique, guided by the inferred representatives, on the classes belonging to the monolith to group them into different types of partitions, mainly: 1) functional groups representing microservice candidates, 2) a utility class group, and 3) a group of classes that require significant refactoring to enable a clean microservice architecture. This results in microservice candidates that are naturally aligned with the different business functions exposed by the application. A detailed evaluation on four publicly available applications show that our approach is able to determine better quality microservice candidates when compared to other existing state of the art techniques. We also conclusively show that clustering quality metrics like modularity are not reliable indicators of microservice candidate goodness.},
  keywords={},
  doi={10.1109/ICWS53863.2021.00104},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9460467,
  author={Ramesh, Srinivasan and Malony, Allen D. and Carns, Philip and Ross, Robert B. and Dorier, Matthieu and Soumagne, Jerome and Snyder, Shane},
  booktitle={2021 IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, 
  title={SYMBIOSYS: A Methodology for Performance Analysis of Composable HPC Data Services}, 
  year={2021},
  volume={},
  number={},
  pages={35-45},
  abstract={Microservices are a powerful new way of building, customizing, and deploying distributed services owing to their flexibility and maintainability. Several large-scale distributed platforms have emerged to serve the growing needs of data-centric workloads and services in commercial computing. Concurrently, high-performance computing (HPC) systems and software are rapidly evolving to meet the demands of diversified applications and heterogeneity. The interplay of hardware factors, software configuration parameters, and the flexibility offered with a microservice architecture makes it nontrivial to estimate the optimal service instantiation for a given application workload. Further, this problem is exacerbated when considering that these services operate in a dynamic and heterogeneous HPC environment. An optimally integrated service can be vastly more performant than a haphazardly integrated one. Existing performance tools for HPC either fail to understand the request-response model of communication inherent to microservices or they operate within a narrow scope, limiting the insight that can be gleaned from employing them in isolation.We propose a methodology for integrated performance analysis of HPC microservices frameworks and applications called SYMBIOSYS. We describe its design and implementation within the context of the Mochi framework. This integration is achieved by combining distributed callpath profiling and tracing with a performance data exchange strategy that collects fine-grained, low-level metrics from the RPC communication library and network layers. The result is a portable, low-overhead performance analysis setup that provides a holistic profile of the dependencies among microservices and how they interact with the Mochi RPC software stack. Using HEPnOS, a production-quality Mochi data service, we demonstrate the low-overhead operation of SYMBIOSYS at scale and use it to identify the root causes of poorly performing service configurations.},
  keywords={},
  doi={10.1109/IPDPS49936.2021.00013},
  ISSN={1530-2075},
  month={May},}@INPROCEEDINGS{9482273,
  author={Tang, Ming and Xia, Fei and Zou, Haodong and Hu, Youjun and Liu, Jun and Liu, Sai},
  booktitle={2021 IEEE 4th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)}, 
  title={Cloud platform load balancing mechanism for microservice architecture}, 
  year={2021},
  volume={4},
  number={},
  pages={435-439},
  abstract={In response to the increase in request response latency under the microservice architecture, from the perspective of cloud platform load balancing, the average request latency and host load on the microservice chain are used as metrics to formalize the latency and problem environment. A request load balancing algorithm perceived by the microservice chain is proposed as the load balancing strategy of the load balancer. Simulation experiments prove that the algorithm in this paper can effectively reduce request latency in a complex microservice chain environment, and it can also maintain relatively good performance in an environment where instances are unevenly distributed, and for workloads between hosts.},
  keywords={},
  doi={10.1109/IMCEC51613.2021.9482273},
  ISSN={2693-2776},
  month={June},}@INPROCEEDINGS{8258201,
  author={Alipour, Hanieh and Liu, Yan},
  booktitle={2017 IEEE International Conference on Big Data (Big Data)}, 
  title={Online machine learning for cloud resource provisioning of microservice backend systems}, 
  year={2017},
  volume={},
  number={},
  pages={2433-2441},
  abstract={Microservices are bundled and generating traffic on the backend systems that need to scale on demand. When microservices generate variant and unexpected, the challenge is to classify the workload on the backend systems and adjust the scaling policy to reflect the resource demand timely and accurately. In this paper, we propose a microservice architecture that encapsulates functions of monitoring metrics and learning workload pattern. Then this service architecture is used to predict the future workload for decision making on resource provisioning. We deploy two machine learning algorithms and predict the resource demand of the backend systems of microservices emulated by a Netflix workload benchmark application. This service architecture presents an integrated solution of implementing self-managing cloud data services under variant workload.},
  keywords={},
  doi={10.1109/BigData.2017.8258201},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9492620,
  author={Behrad, Shanay and Espes, David and Bertin, Philippe and Phan, Cao-Thanh},
  booktitle={2021 IEEE 7th International Conference on Network Softwarization (NetSoft)}, 
  title={Impacts of Service Decomposition Models on Security Attributes: A Case Study with 5G Network Repository Function}, 
  year={2021},
  volume={},
  number={},
  pages={470-476},
  abstract={Microservices-based architectures gain more and more attention in industry and academia due to their tremendous advantages such as providing resiliency, scalability, composability, etc. To benefit from these advantages, a proper architectural design is very important. The decomposition model of services into microservices and the granularity of these microservices affect the different aspects of the system such as flexibility, maintainability, performance, and security. An inappropriate service decomposition into microservices (improper granularity) may increase the attack surface of the system and lower its security level. In this paper, first, we study the probability of compromising services before and after decomposition. Then we formulate the impacts of possible service decomposition models on confidentiality, integrity, and availability attributes of the system. To do so, we provide equations for measuring confidentiality, integrity, and availability risks of the decomposed services in the system. It is also shown that the number of entry points to the decomposed services and the size of the microservices affect the security attributes of the system. As a use case, we propose three different service decomposition models for the 5G NRF (Network Repository Function) and calculate the impacts of these decomposition models on the confidentiality, integrity, and availability of the system using the provided equations.},
  keywords={},
  doi={10.1109/NetSoft51509.2021.9492620},
  ISSN={2693-9789},
  month={June},}@INPROCEEDINGS{8940402,
  author={Fernandes Mioto de Oliveira dos Santos, Eduardo and Lima Werner, Claudia Maria},
  booktitle={2019 International Conference on Information Systems and Software Technologies (ICI2ST)}, 
  title={A Survey on Microservices Criticality Attributes on Established Architectures}, 
  year={2019},
  volume={},
  number={},
  pages={149-155},
  abstract={The microservice oriented software architecture considers the delegation of responsibilities by separate components, thus creating a set of interconnected but independent services. Information about the most critical microservices is relevant to software architects and other decision-makers, thus guiding the maintenance and evolution of architecture in a more assertive and guided way. This paper aims to observe the need for a method to measure criticality in a microservice oriented architecture, motivated by this purpose, during August 2019, a survey with twenty experienced participants from the industry and academia was conducted, where the lack of a grounded method to measure the criticality on established architectures was observed.},
  keywords={},
  doi={10.1109/ICI2ST.2019.00028},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9582573,
  author={de Toledo, Saulo S. and Martini, Antonio and Sjøberg, Dag I.K. and Przybyszewska, Agata and Frandsen, Johannes Skov},
  booktitle={2021 47th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)}, 
  title={Reducing Incidents in Microservices by Repaying Architectural Technical Debt}, 
  year={2021},
  volume={},
  number={},
  pages={196-205},
  abstract={Architectural technical debt (ATD) may create a substantial extra effort in software development, which is called interest. There is little evidence about whether repaying ATD in microservices reduces such interest. Objectives: We wanted to conduct a first study on investigating the effect of removing ATD on the occurrence of incidents in a microservices architecture. Method: We conducted a quantitative and qualitative case study of a project with approximately 1000 microservices in a large, international financing services company. We measured and compared the number of software incidents of different categories before and after repaying ATD. Results: The total number of incidents was reduced by 84%, and the numbers of critical- and high-priority incidents were both reduced by approximately 90% after the architectural refactoring. The number of incidents in the architecture with the ATD was mainly constant over time, but we observed a slight increase of low priority incidents related to inaccessibility and the environment in the architecture without the ATD. Conclusion: This study shows evidence that refactoring ATDs, such as lack of communication standards, poor management of dead-letter queues, and the use of inadequate technologies in microservices, reduces the number of critical- and high-priority incidents and, thus, part of its interest, although some low priority incidents may increase.},
  keywords={},
  doi={10.1109/SEAA53835.2021.00033},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8845242,
  author={Tseng, Yuchia and Imadali, Sofiane and Houatra, Drissa and Aravinthan, Gopalasingham and Thomas, Laurent},
  booktitle={IEEE INFOCOM 2019 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)}, 
  title={Demo Abstract: Monitoring Virtualized Telco Services for Multisided Platforms with SQL-like Query}, 
  year={2019},
  volume={},
  number={},
  pages={949-950},
  abstract={The Telco ecosystem transformation towards cloud-native network services enables constructing an integrative platform business model in the form of a Multi-Sided Platform (MSP) leveraging microservice-based Virtualized Network Function architecture. In particular, MSP based architectures enable a multi-organizational ecosystem with increased automation possibilities for carrier-grade services creation and operations. We present a microservice-based monitoring system for virtualized Telco services based on OpenAirInterface (OAI) with an SQL-like query manager for metrics. We demonstrate two monitoring scenarios: (1) Average receiving (rx) PDU in bytes at MAC layer from the targeted user equipment (UE). (2) Finding the UE who consumes the most Physical Resource Blocks (PRB) within a specific time interval for the uplink and downlink transmission.},
  keywords={},
  doi={10.1109/INFCOMW.2019.8845242},
  ISSN={},
  month={April},}@INPROCEEDINGS{9644910,
  author={Hou, Chuanjia and Jia, Tong and Wu, Yifan and Li, Ying and Han, Jing},
  booktitle={2021 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)}, 
  title={Diagnosing Performance Issues in Microservices with Heterogeneous Data Source}, 
  year={2021},
  volume={},
  number={},
  pages={493-500},
  abstract={Microservices architecture is vulnerable to performance issues due to its highly fine-grained decomposition of an application. To diagnose performance issues in microservices, existing works utilize system metrics as the specific indicator and do a lot of heavy computation such as building service dependency graphs during the diagnosing process.To improve the effectiveness and efficiency of issue diagnosing, we propose PDiagnose, a practical approach using multiple data sources including metrics, logs and traces jointly to diagnose performance issues in microservices systems. Through combining lightweight unsupervised anomaly detection algorithms and vote-based issue localization strategy, PDiagnose is application-agnostic and can localize root cause indicators accurately. Our evaluation on two public-available datasets shows that PDiagnose can achieve an overall recall of 84.8%, outperforming the best baseline approach. Meanwhile, the diagnosis duration of PDiagnose is also promising.},
  keywords={},
  doi={10.1109/ISPA-BDCloud-SocialCom-SustainCom52081.2021.00074},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9556733,
  author={Song, Da and Yuan, Long and Zhao, Weixing and Yu, Quanxi and Du, Jie and Pan, Kaiyan},
  booktitle={2021 China International Conference on Electricity Distribution (CICED)}, 
  title={Cloud-Edge Computing Resource Collaborative Optimization Method for Power Distribution Fault Analysis Service}, 
  year={2021},
  volume={},
  number={},
  pages={627-632},
  abstract={The cloud-edge computing architecture of distribution network can meet the computing and communication requirements of most novel and traditional distribution services. However, the demand for computing resources of fault service is often greater than the resource capacity of edge computing terminal. Therefore, based on the cloud-edge collaborative architecture, this paper proposes a collaborative optimization method of cloud and edge computing resources for fault service in distribution network. Firstly, this paper elaborates the characteristics of fault service in distribution network, and describes the possibility of cloud-edge collaborative information interaction and microservice offloading based on container technology. Then, a cloud-edge collaborative service computing model and the microservice model of fault service are established. According to the offloading mechanism, a microservice offloading decision optimization model is established, which take the system operation cost and calculation delay as the comprehensive measuring index. Finally, the method proposed in this paper is simulated by MATLAB, and the simulation results show that this method can effectively reduce the microservice response time of distribution network and meet the computing resource requirements of fault service.},
  keywords={},
  doi={10.1109/CICED50259.2021.9556733},
  ISSN={2161-749X},
  month={April},}@INPROCEEDINGS{9196461,
  author={Rossi, Fabiana and Cardellini, Valeria and Presti, Francesco Lo},
  booktitle={2020 IEEE International Conference on Autonomic Computing and Self-Organizing Systems (ACSOS)}, 
  title={Hierarchical Scaling of Microservices in Kubernetes}, 
  year={2020},
  volume={},
  number={},
  pages={28-37},
  abstract={In the last years, we have seen the increasing adoption of the microservice architectural style where applications satisfy user requests by invoking a set of independently deployable services. Software containers and orchestration tools, such as Kubernetes, have simplified the development and management of microservices. To manage containers' horizontal elasticity, Kubernetes uses a decentralized threshold-based policy that requires to set thresholds on system-oriented metrics (i.e., CPU utilization). This might not be well-suited to scale latency-sensitive applications, which need to express requirements in terms of response time. Moreover, being a fully decentralized solution, it may lead to frequent and uncoordinated application reconfigurations. In this paper, we present me-kube (Multi-level Elastic Kubernetes), a Kubernetes extension that introduces a hierarchical architecture for controlling the elasticity of microservice-based applications. At higher level, a centralized per-application component coordinates the run-time adaptation of subordinated distributed components, which, in turn, locally control the adaptation of each microservice. Then, we propose novel proactive and reactive hierarchical control policies, based on queuing theory. To show that me-kube provides general mechanisms, we also integrate reinforcement learning-based scaling policies. Using me-kube, we perform a large set of experiments, aimed to show the advantages of a hierarchical control over the default Kubernetes autoscaler.},
  keywords={},
  doi={10.1109/ACSOS49614.2020.00023},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9355698,
  author={Ray, Kaustabha and Banerjee, Ansuman and Narendra, Nanjangud C.},
  booktitle={2020 IEEE/ACM Symposium on Edge Computing (SEC)}, 
  title={Proactive Microservice Placement and Migration for Mobile Edge Computing}, 
  year={2020},
  volume={},
  number={},
  pages={28-41},
  abstract={In recent times, Mobile Edge Computing (MEC) has emerged as a new paradigm allowing low-latency access to services deployed on edge nodes offering computation, storage and communication facilities. Vendors deploy their services on MEC servers to improve performance and mitigate network latencies often encountered in accessing cloud services. A service placement policy determines which services are deployed on which MEC servers. A number of mechanisms exist in literature to determine the optimal placement of services considering different performance metrics. However, for applications designed as microservice workflow architectures, service placement schemes need to be re-examined through a different lens owing to the inherent interdependencies which exist between microservices. Indeed, the dynamic environment, with stochastic user movement and service invocations, along with a large placement configuration space makes microservice placement in MEC a challenging task. Additionally, owing to user mobility, a placement scheme may need to be recalibrated, triggering service migrations to maintain the advantages offered by MEC. Existing microservice placement and migration schemes consider on-demand strategies. In this work, we take a different route and propose a Reinforcement Learning based proactive mechanism for microservice placement and migration. We use the San Francisco Taxi dataset to validate our approach. Experimental results show the effectiveness of our approach in comparison to other state-of-the-art methods.},
  keywords={},
  doi={10.1109/SEC50012.2020.00010},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9105640,
  author={Valdivia, José A. and Limón, Xavier and Cortes-Verdin, Karen},
  booktitle={2019 7th International Conference in Software Engineering Research and Innovation (CONISOFT)}, 
  title={Quality attributes in patterns related to microservice architecture: a Systematic Literature Review}, 
  year={2019},
  volume={},
  number={},
  pages={181-190},
  abstract={Microservices is an interesting option for those who want to migrate their systems to improve performance, maintainability, scalability, and interoperability. Microservice architecture is a collection of self-sufficient services working together to provide functionalities. Nowadays, there are many options to build microservices, some of them are lead by patterns. However, the mapping between quality attributes and patterns is not clear yet. This systematic literature review presents a microservice pattern collection, it describes their benefits and the association between patterns and quality attributes. Finally, some metrics of quality attributes are identified.},
  keywords={},
  doi={10.1109/CONISOFT.2019.00034},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9130466,
  author={Al-Debagy, Omar and Martinek, Péter},
  booktitle={2020 IEEE 15th International Conference of System of Systems Engineering (SoSE)}, 
  title={Extracting Microservices’ Candidates from Monolithic Applications: Interface Analysis and Evaluation Metrics Approach}, 
  year={2020},
  volume={},
  number={},
  pages={289-294},
  abstract={There is a migration trend toward microservices architecture coming from the monolithic applications. This research proposes a decomposition method that extracts microservices’ candidates through analyzing the application programming interface in order to extract the operations and the parameters. Then the operation names are converted into word representations using word embedding models. Next, semantically similar operations are clustered together to provide a microservice’ candidate. Additional step is to evaluate the proposed candidate using cohesion and complexity metrics. The proposed algorithm improved the decomposition approach for big applications but did not affect the decomposition of smaller applications.},
  keywords={},
  doi={10.1109/SoSE50414.2020.9130466},
  ISSN={},
  month={June},}@INPROCEEDINGS{8399148,
  author={Guaman, Daniel and Yaguachi, Lady and Samanta, Cueva C. and Danilo, Jaramillo H. and Soto, Fernanda},
  booktitle={2018 13th Iberian Conference on Information Systems and Technologies (CISTI)}, 
  title={Performance evaluation in the migration process from a monolithic application to microservices}, 
  year={2018},
  volume={},
  number={},
  pages={1-8},
  abstract={Microservices are considered as a software architecture that allows the decomposition of a system, its components or its functionalities into a set of small services, which are implemented, deployed and managed independently. In this study, the models that allow migrating a Monolith to Microservices such as NGINX and IBM are analyzed. From these models, activities that allow such migration are carefully selected and identified. In order to implement and evaluate the activities proposed in those models, an application that initially does not have any structure at the design and coding level (using PHP programming language) is applied. Then, the application's coding language changes to Java and the classes and libraries are distributed into packages. Subsequently, as it is suggested in the models, services are identified and implemented using RESTful Web Services to finally implement the microservices using technologies such as Spring Boot, Eureka, and Zuul. In the migration process, the application under study is modified at the code and design level, including patterns such as Singleton, Façade, Strangler, Single Service per Host, Service Discovery, and API Gateway, which are used to evaluate performance as a quality attribute in each migration phase. In order to obtain the performance related metrics and to analyze the advantages and disadvantages of each migration phase, Apache JMeter as tool is used. This tool is set up to generate results regarding the use of resources such as CPU, memory, network, and database access. Finally, the results show scenarios of several concurrent users who access to consult records in the database that uses the aforementioned application in each migration phase.},
  keywords={},
  doi={10.23919/CISTI.2018.8399148},
  ISSN={},
  month={June},}@ARTICLE{9507486,
  author={Xu, Rongxu and Jin, Wenquan and Kim, Dohyeun},
  journal={IEEE Access}, 
  title={Enhanced Service Framework Based on Microservice Management and Client Support Provider for Efficient User Experiment in Edge Computing Environment}, 
  year={2021},
  volume={9},
  number={},
  pages={110683-110694},
  abstract={Leveraging the edge computing paradigm, computing resources are deployed in the network edge to provide heterogeneous services. Edge computing delivers sensing and actuating services to the Internet from the constrained Internet of Things (IoT) devices. Meanwhile, management of various elements is provided by offloading sufficient computing and storage to the edge of the networks for the IoT environments such as home, factory, and private spaces without cloud servers. In this paper, we propose an enhanced service framework based on microservice management and client support provider for efficient user experiments in the edge computing environment. For providing the edge computing service and management in the network edge, this paper presents an edge-computing architecture that provides various functions through microservice modules on the edge platform engine. Through the microservices, the interfaces are provided to the client to access the device, data, and additional services. Using Docker, the microservice modules are deployed in the edge platform to provide the services. However, the services and management functions need to be presented to the clients based on the friendly user interfaces. For providing the user interfaces of the services and Docker engine to the clients, the client support service provider is developed and deployed in the network edge based on the edge platform. Therefore, the proposed edge platform provides the services and management to the users for accessing the resources and functions through visualized interfaces in the IoT environment based on edge computing. The performance of our proposed system can be checked through the test result screen and delay time. Compared to controlling edge computing by using a command-line tool for users, we made it easy for general users who are not computer savvy to access edge services through a graphic user interface. And by measuring the delay time and comparing the execution time, it can be seen that the proposed system operates faster.},
  keywords={},
  doi={10.1109/ACCESS.2021.3102595},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7829777,
  author={Parimala, N. and Kohar, Rachna},
  booktitle={2016 Eleventh International Conference on Digital Information Management (ICDIM)}, 
  title={A quality metric for BPEL process under evolution}, 
  year={2016},
  volume={},
  number={},
  pages={197-202},
  abstract={In Service-Oriented Architecture (SOA), behaviour of a business process is specified using Business Process Execution Language (BPEL) which is a XML based language. In today's competitive market, enterprises change their business processes frequently. Changes in BPEL process may affect the quality of BPEL process for the consumer. It is desirable to measure and evaluate the BPEL process quality when changes occur. Metrics are vastly used to provide a quantitative measure for the quality. In this paper, BPEL Process Usefulness Metric under Evolution (BUME) is proposed to measure quality of a BPEL process when it evolves. The applicability of the metric is demonstrated using simulated data for different versions of a BPEL process.},
  keywords={},
  doi={10.1109/ICDIM.2016.7829777},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{7562758,
  author={Honamore, Suhas and Kumar, Lov and Rath, Santanu Ku.},
  booktitle={2016 International Conference on Internet of Things and Applications (IOTA)}, 
  title={Analysis of control flow complexity metrics for web service composition}, 
  year={2016},
  volume={},
  number={},
  pages={389-394},
  abstract={In service oriented computing, web services are combined to meet the interoperability demands in different heterogeneous and distributed applications. However, incisively measuring the control flow complexity of Web Service Composition (WSC) is not an easy task due to characteristics of distributed, loose-coupling, and heterogeneity. In Service Oriented Architecture (SOA), Business Process Execution Language (BPEL) is used to describe the combination of web services. This paper mainly focuses on the complexity measurement of web service composition from BPEL. Petri-net is one of the models to represent the work flow. The BPEL of WSC is converted into Petri-net based model and by extracting the information of places, transitions, and their interrelationship; the complexity is measured for that Petri-net model. Two metric sets are considered for analysis of the WSC's complexity, which are identified by studying the workflow's execution dependency relations. The first metric set describes the static features, and second metric set describes about the dynamic complexity of business process.},
  keywords={},
  doi={10.1109/IOTA.2016.7562758},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{9304633,
  author={Cebotari, Vadim and Kugele, Stefan},
  booktitle={2020 IEEE Intelligent Vehicles Symposium (IV)}, 
  title={Playground for Early Automotive Service Architecture Design and Evaluation}, 
  year={2020},
  volume={},
  number={},
  pages={1349-1356},
  abstract={Context: We consider the structure of service-oriented architectures in vehicular software. Aim: We aim at evaluating the structure and grouping of service architectures. Method: We propose and discuss architectural metrics tailored towards automotive service-oriented architectures. We apply the metrics on an adaptive cruise control case example extracted from the AUTOSAR standard. Results: The application of the proposed metrics to two different service groupings for ACC points clearly to the same service grouping that we consider, after a thorough analysis, to be better with respect to coupling and cohesion attributes. Conclusion: We demonstrate the usefulness of proposed service group metrics in early design phases of the development process and validate the metrics on the case example of an adaptive cruise control function.},
  keywords={},
  doi={10.1109/IV47402.2020.9304633},
  ISSN={2642-7214},
  month={Oct},}@INPROCEEDINGS{8614791,
  author={Parekh, Nikunj and Kurunji, Swathi and Beck, Alan},
  booktitle={2018 IEEE 9th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON)}, 
  title={Monitoring Resources of Machine Learning Engine In Microservices Architecture}, 
  year={2018},
  volume={},
  number={},
  pages={486-492},
  abstract={Microservices architecture facilitates building distributed scalable software products, usually deployed in a cloud environment. Monitoring microservices deployed in a Kubernetes orchestrated distributed advanced analytics machine learning engines is at the heart of many cloud resource management solutions. In addition, measuring resource utilization at more granular level such as per query or sub-query basis in an MPP Machine Learning Engine (MLE) is key to resource planning and is also the focus of our work. In this paper we propose two mechanisms to measure resource utilization in Teradata Machine Learning Engine (MLE). First mechanism is the Cluster Resource Monitoring (CRM). CRM is a high-level resource measuring mechanism for IT administrators and analytics users to visualize, plot, generates alerts and perform live and historical-analytics on overall cluster usage statistics. Second mechanism is the Query Resource Monitoring (QRM). QRM enables IT administrators and MLE users to measure compute resource utilization per individual query and its sub-queries. When query takes long time, QRM provides insights. This is useful to identify expensive phases within a query that tax certain resources more and skew the work distribution. We show the results of proposed mechanisms and highlight use-cases.},
  keywords={},
  doi={10.1109/IEMCON.2018.8614791},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8972825,
  author={Samir, Areeg and Pahl, Claus},
  booktitle={2019 7th International Conference on Future Internet of Things and Cloud (FiCloud)}, 
  title={DLA: Detecting and Localizing Anomalies in Containerized Microservice Architectures Using Markov Models}, 
  year={2019},
  volume={},
  number={},
  pages={205-213},
  abstract={Container-based microservice architectures are emerging as a new approach for building distributed applications as a collection of independent services that works together. As a result, with microservices, we are able to scale and update their applications based on the load attributed to each service. Monitoring and managing the load in a distributed system is a complex task as the degradation of performance within a single service will cascade reducing the performance of other dependent services. Such performance degradations may result in anomalous behaviour observed for instance for the response time of a service. This paper presents a Detection and Localization system for Anomalies (DLA) that monitors and analyzes performance-related anomalies in container-based microservice architectures. To evaluate the DLA, an experiment is done using R, Docker and Kubernetes, and different performance metrics are considered. The results show that DLA is able to accurately detect and localize anomalous behaviour.},
  keywords={},
  doi={10.1109/FiCloud.2019.00036},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{6986002,
  author={Nik Daud, Nik Marsyahariani and Wan Kadir, Wan M. N.},
  booktitle={2014 8th. Malaysian Software Engineering Conference (MySEC)}, 
  title={Static and dynamic classifications for SOA structural attributes metrics}, 
  year={2014},
  volume={},
  number={},
  pages={130-135},
  abstract={Evaluating qualities of software based on software structural attributes such as coupling and cohesion are frequently done in practice as these attributes directly have impacts on value of higher level quality. Concerning oneself with structural attributes values early on helps developers to predict quality attributes level in the software. Service-Oriented Architecture (SOA) is an architectural concept where services are used as building blocks in developing new software. Lots of structural attributes metrics related to SOA had been proposed these recent years, which triggered an investigation to classify these metrics based on specific criteria. In this paper, we introduce classifications for SOA based structural attributes metrics, where the metrics are restricted to coupling, cohesion and complexity metrics. These metrics are classified based on software static and dynamic aspects with some brief introduction for each metric. By classifying these SOA based structural attributes metrics, it will allow user to avoid redundancy in proposing similar metrics thus increases the reusability of existing metrics.},
  keywords={},
  doi={10.1109/MySec.2014.6986002},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9000664,
  author={Orduz, Juan S. and Orozco, Gabriel D. and Tobar-Arteaga, Carlos H. and Rendon, Oscar Mauricio Caicedo},
  booktitle={2019 IEEE 44th LCN Symposium on Emerging Topics in Networking (LCN Symposium)}, 
  title={μvIMS: A Finer-Scalable Architecture Based on Microservices}, 
  year={2019},
  volume={},
  number={},
  pages={141-148},
  abstract={The steps toward all over IP have defined to the IP Multimedia Subsystem (IMS) as the de facto technology for end-to-end multimedia service provisioning in 5G. However, the unpredictable growth of users in 5G requires to improve IMS scalability to handle dynamic user traffic. Several works have addressed this issue by introducing auto-scaling mechanisms in virtualized IMS (vIMS) architectures. However, the current vIMS deployments use monolithic designs that do not allow finer-scalability. In this paper, we present μvIMS, an architecture that uses microservices to provide finer-scalability and more effective resource usage than regular monolithic design. To test our architecture, we evaluate μvIMS prototype regarding CPU usage, RAM usage, Successful Call Rate (SCR), and latency metrics. Our test results reveal that μvIMS achieves a higher SCR, using the available resources effectively with a negligible latency increasing. Thus, we can state that dividing the monolithic vIMS architecture in microservices allows providing finer-scalability.},
  keywords={},
  doi={10.1109/LCNSymposium47956.2019.9000664},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9527007,
  author={Wu, Li and Tordsson, Johan and Bogatinovski, Jasmin and Elmroth, Erik and Kao, Odej},
  booktitle={2021 IEEE/ACM International Workshop on Cloud Intelligence (CloudIntelligence)}, 
  title={MicroDiag: Fine-grained Performance Diagnosis for Microservice Systems}, 
  year={2021},
  volume={},
  number={},
  pages={31-36},
  abstract={Microservice architecture has emerged as a popular pattern for developing large-scale applications for its benefits of flexibility, scalability, and agility. However, the large number of services and complex dependencies make it difficult and time-consuming to diagnose performance issues. We propose Micro-Diag, an automated system to localize root causes of performance issues in microservice systems at a fine granularity, including not only locating the faulty component but also discovering detailed information for its abnormality. MicroDiag constructs a component dependency graph and performs causal inference on diverse anomaly symptoms to derive a metrics causality graph, which is used to infer root causes. Our experimental evaluation on a microservice benchmark running in a Kubernetes cluster shows that MicroDiag localizes root causes well, with 97% precision of the top 3 most likely root causes, outperforming state-of-the-art methods by at least 31.1%.},
  keywords={},
  doi={10.1109/CloudIntelligence52565.2021.00015},
  ISSN={},
  month={May},}@INPROCEEDINGS{9582183,
  author={Choochotkaew, Sunyanan and Chiba, Tatsuhiro and Trent, Scott and Amaral, Marcelo},
  booktitle={2021 IEEE 14th International Conference on Cloud Computing (CLOUD)}, 
  title={Run Wild: Resource Management System with Generalized Modeling for Microservices on Cloud}, 
  year={2021},
  volume={},
  number={},
  pages={609-618},
  abstract={Microservice architecture competes with the traditional monolithic design by offering benefits of agility, flexibility, reusability resilience, and ease of use. Nevertheless, due to the increase in internal communication complexity, care must be taken for resource-usage scaling in harmony with placement scheduling, and request balancing to prevent cascading performance degradation across microservices. We prototype Run Wild, a resource management system that controls all mechanisms in the microservice-deployment process covering scaling, scheduling, and balancing to optimize for desirable performance on the dynamic cloud driven by an automatic, united, and consistent deployment plan. In this paper, we also highlight the significance of co-location aware metrics on predicting the resource usage and computing the deployment plan. We conducted experiments with an actual cluster on the IBM Cloud platform. RunWild reduced the 90th percentile response time by 11% and increased average throughput by 10% with more than 30% lower resource usage for widely used autoscaling benchmarks on Kubernetes clusters.},
  keywords={},
  doi={10.1109/CLOUD53861.2021.00079},
  ISSN={2159-6190},
  month={Sep.},}@INPROCEEDINGS{9680438,
  author={Ramesh, Srinivasan and Ross, Robert and Dorier, Matthieu and Malony, Allen and Carns, Philip and Huck, Kevin},
  booktitle={2021 IEEE 28th International Conference on High Performance Computing, Data, and Analytics (HiPC)}, 
  title={SYMBIOMON: A High-Performance, Composable Monitoring Service}, 
  year={2021},
  volume={},
  number={},
  pages={332-342},
  abstract={High-performance computing (HPC) software is evolving to support an increasingly diverse set of applications and heterogeneous hardware architectures. As part of this evolution, the construction of scientific software has shifted from a traditional monolithic message passing interface executable model to a coupled, services-style model in which simulations run alongside a host of distributed HPC data services within the same batch job allocation. Microservices have emerged as a powerful new way to build these distributed data services through a composition model. However, performance analysis of composed microservices is a daunting challenge. It requires collecting, monitoring, aggre-gating, and exporting performance data from multiple sources. To be effective, the design of such a monitoring solution must allow for seamless integration into HPC applications and distributed services alike, be scalable, operate with a low overhead, and take advantage of the HPC platform. We propose SYMBIOMON, a monitoring service that is built by composing high-performance microservices. We describe its design and implementation within the context of the Mochi framework. SYMBIOMON combines a time-series data model with existing Mochi data services to collect, aggregate, and export performance metrics in a distributed manner. SYMBIOMON enables seamless, low-overhead monitoring and analysis of data services and HPC applications alike. Using HEPnOS, a production-quality Mochi data service, we demonstrate the use of SYMBIOMON to identify better service configurations.},
  keywords={},
  doi={10.1109/HiPC53243.2021.00047},
  ISSN={2640-0316},
  month={Dec},}@INPROCEEDINGS{7899252,
  author={Do, Nam H. and Van Do, Tien and Thi Tran, Xuan and Farkas, Lóránt and Rotter, Csaba},
  booktitle={2017 20th Conference on Innovations in Clouds, Internet and Networks (ICIN)}, 
  title={A scalable routing mechanism for stateful microservices}, 
  year={2017},
  volume={},
  number={},
  pages={72-78},
  abstract={Scalability is an important requirement in the development and the operation of applications in a cloud environment. To handling heavy concurrency in the input load, many design-related and operational factors should be considered. The microservice architecture patterns provide better means to increase the scalability than traditional software architecture patterns. However, certain aspects of applications such as the need to persist/maintain the application state require additional measures in the design and the supporting mechanism. We propose a scalable routing mechanism for applications designed according to the microservice architecture. In particular, a cloud infrastructure resource reservation application has been designed with some stateful services. The proposed approach maintains a good scalability, which provides a mean to achieve the efficient usage of the infrastructure resources.},
  keywords={},
  doi={10.1109/ICIN.2017.7899252},
  ISSN={2472-8144},
  month={March},}@INPROCEEDINGS{8494072,
  author={Pulparambil, Supriya and Baghdadi, Youcef and Al-Hamdani, Abdullah and Al-Badawi, Mohammed},
  booktitle={2018 9th International Conference on Computing, Communication and Networking Technologies (ICCCNT)}, 
  title={Service Design Metrics to Predict IT-Based Drivers of Service Oriented Architecture Adoption}, 
  year={2018},
  volume={},
  number={},
  pages={1-7},
  abstract={The key factors for deploying successful services is centered on the service design practices adopted by an enterprise. The design level information should be validated and measures are required to quantify the structural attributes. The metrics at this stage will support an early discovery of design flaws and help designers to predict the capabilities of service oriented architecture (SOA) adoption. In this work, we take a deeper look at how we can forecast the key SOA capabilities infrastructure efficiency and service reuse from the service designs modeled by SOA modeling language. The proposed approach defines metrics based on the structural and domain level similarity of service operations. The proposed metrics are analytically validated with respect to software engineering metrics properties. Moreover, a tool has been developed to automate the proposed approach and the results indicate that the metrics predict the SOA capabilities at the service design stage. This work can be further extended to predict the business based capabilities of SOA adoption such as flexibility and agility.},
  keywords={},
  doi={10.1109/ICCCNT.2018.8494072},
  ISSN={},
  month={July},}@INPROCEEDINGS{9525743,
  author={Gamage, Isuru Udara Piyadigama and Perera, Indika},
  booktitle={2021 Moratuwa Engineering Research Conference (MERCon)}, 
  title={Using dependency graph and graph theory concepts to identify anti-patterns in a microservices system: A tool-based approach}, 
  year={2021},
  volume={},
  number={},
  pages={699-704},
  abstract={Microservice architecture (MSA) based application developments are becoming the common trend in implementing large-scale applications. Unlike the traditional monolith applications, MSA applications are composed of many services hence there is an immense possibility of anti-patterns introduced into the system. To identify these design problems, a detailed analysis of the architecture needs to be performed. We see great potential for adopting graph concepts and algorithms in this regard. However, the few tools proposed by existing work to find anti-patterns that adopt graph concepts are not up to providing developers with adequate statistical information such as metrics along with visualization techniques or they are not fully automated. In this research, we present a tool-based solution for this problem which is capable of utilizing traced data of an MSA system to generate dependency graphs and thereby extract metrics using graph theory concepts and algorithms. We analyze a sample MSA system for anti-patterns with the tool. To verify the usability of the tool further, a group of developers also analyze an open-source system with the tool.},
  keywords={},
  doi={10.1109/MERCon52712.2021.9525743},
  ISSN={2691-364X},
  month={July},}@INPROCEEDINGS{9198750,
  author={Brusakova, I. A.},
  booktitle={2020 XXIII International Conference on Soft Computing and Measurements (SCM)}, 
  title={Metrics for Cognitive Management of IT Services}, 
  year={2020},
  volume={},
  number={},
  pages={259-261},
  abstract={The article presents metrics for managing IT services in a service-oriented architecture of the information system. Cognitive management of the effectiveness of IT services is considered on a variety of ICT infrastructure management metrics, information system management metrics, IT service management metrics. The necessary components of the formation of an analytical platform for the cognitive management of IT services in the EIM environment for SAP BI (Business Objects Business Intelligent) are considered. A model of cognitive management of IT services using key performance indicators (KPIs) for managing IT service metrics is presented.},
  keywords={},
  doi={10.1109/SCM50615.2020.9198750},
  ISSN={},
  month={May},}@INPROCEEDINGS{8029780,
  author={Wang, Hanzhang and Kessentini, Marouane and Hassouna, Taghreed and Ouni, Ali},
  booktitle={2017 IEEE International Conference on Web Services (ICWS)}, 
  title={On the Value of Quality of Service Attributes for Detecting Bad Design Practices}, 
  year={2017},
  volume={},
  number={},
  pages={341-348},
  abstract={Service-Oriented Architectures (SOAs) successfully evolve over time to update existing exposed features to the users and fix possible bugs. This evolution process may have a negative impact on the design quality of Web services. Recent studies addressed the problem of Web service antipatterns detection (bad design practices). To the best of our knowledge, these studies focused only on the use of metrics extracted from the implementation details (source code) of the interface and the services. However, the quality of service (QoS) metrics, widely used to evaluate the overall performance, are never used in the context of Web service antipatterns detection. We start, in this work, from the hypothesis that these bad design practices may impact several QoS metrics such as the response time. Furthermore, the source code metrics of services may not be always available. Without the consideration of these QoS metrics, the current detection processes of antipatterns will still lack the integration of symptoms that could be extracted from the usage of services. In this paper, we propose an automated approach to generate Web service defect detection rules that consider not only the code/interface level metrics but also the quality of service attributes. Through multi-objective optimization, the proposed approach generates solutions (detection rules) that maximize the coverage of antipattern examples and minimize the coverage of well-designed service examples. An empirical validation is performed with eight different common types of Web design defects to evaluate our approach. We compared our results with three other state of the art techniques which are not using QoS metrics. The statistical analysis of the obtained results confirm that our approach outperforms other techniques and generates detection rules that are more meaningful from the services' user perspective.},
  keywords={},
  doi={10.1109/ICWS.2017.126},
  ISSN={},
  month={June},}@INPROCEEDINGS{9369609,
  author={Heideker, Alexandre and Kamienski, Carlos},
  booktitle={2021 IEEE 18th Annual Consumer Communications & Networking Conference (CCNC)}, 
  title={Towards a Network Queuing Assessment for Elasticity Management of Virtualized Services}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={With the increasing adoption of cloud computing, microservice architecture, and network function virtualization (NFV), addressing scalability and elasticity management becomes essential. The high demand for these services challenges the research community to create new automated management techniques, from which an essential part is the detection of bottlenecks in infrastructures and application boxes. The traditional approach based on hardware resource metrics (CPU and RAM) is the most straightforward strategy, providing independence from particular applications but may not capture the application's behavior in terms of workload variations. On the other hand, using an application-oriented approach provides a significant correlation with the end-user quality of experience but needs to be tailored for each case. We propose the Network Queuing Assessment (NQA) that breaks away with this tradeoff, capturing the application's workload variations and providing a significant correlation with the end-user quality of experience. Also, similarly to CPU and RAM, it is independent of particular applications. Our performance analysis results for CPU, RAM, and NQA metrics using virtualized applications and network functions in a cloud environment confirm this approach's usefulness.},
  keywords={},
  doi={10.1109/CCNC49032.2021.9369609},
  ISSN={2331-9860},
  month={Jan},}@INPROCEEDINGS{8704556,
  author={Alvarez Q., Juan M. and Sanabria O., John A. and Garcia M., Jose I},
  booktitle={2019 IEEE Latin American Test Symposium (LATS)}, 
  title={Microservices-based architecture for fault diagnosis in tele-rehabilitation equipment operated via Internet}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper presents the design of a microservices based architecture allows early fault detection and diagnosis on a remote controlled physical rehabilitation machine using the Internet as a communication channel. Aforementioned architecture is composed of three layers: the low layer which collects variables from the rehabilitation machine components, using Internet of Things protocols. The middle layer which analyses the provided variables and diagnoses the component status, using fuzzy logic. And finally, the upper layer which makes decisions depending on the diagnosis data. The proposed architecture is suitable for heterogeneous systems.This paper also shows how this architecture fulfills the specific and rigorous safety measures for critical mission devices like technical aids for health-care.},
  keywords={},
  doi={10.1109/LATW.2019.8704556},
  ISSN={2373-0862},
  month={March},}@INPROCEEDINGS{6966260,
  author={Gomathy, C. K. and Rajalakshmi, S.},
  booktitle={Second International Conference on Current Trends In Engineering and Technology - ICCTET 2014}, 
  title={A software quality metric performance of professional management in service oriented architecture}, 
  year={2014},
  volume={},
  number={},
  pages={41-47},
  abstract={Service-oriented architecture (SOA) is generally the way of containing and examines to develop the information management needs in order to make dealing responsive and elastic in pace with forceful quality conditions. Adopting, implementing and running SOA require considerable thought and effort in order to distribute high-quality metrics data and become conscious the complete assessment of SOA. In this paper, inspect the sequentially and quality related metrics issues that have been investigated organizations in order to uncover the activities in regard to information quality within their initiatives of implementing SOA. In the succession of quality behavior that solve certain information quality and maintenance, development issues therefore, can be enthusiastically established across any industry to support the building of high quality and then making SOA solutions. In current days service oriented architecture design is also incorporated and potentially distributed with the quality metrics and to perform a superior evaluation of the representation.},
  keywords={},
  doi={10.1109/ICCTET.2014.6966260},
  ISSN={},
  month={July},}@INPROCEEDINGS{8818401,
  author={Yu, Guangba and Chen, Pengfei and Zheng, Zibin},
  booktitle={2019 IEEE International Conference on Web Services (ICWS)}, 
  title={Microscaler: Automatic Scaling for Microservices with an Online Learning Approach}, 
  year={2019},
  volume={},
  number={},
  pages={68-75},
  abstract={Recently, the microservice becomes a popular architecture to construct cloud native systems due to its agility. In cloud native systems, autoscaling is a core enabling technique to adapt to workload changes by scaling out/in. However, it becomes a challenging problem in a microservice system, since such a system usually comprises a large number of different micro services with complex interactions. When bursty and unpredictable workloads arrive, it is difficult to pinpoint the scaling-needed services which need to scale and evaluate how much resource they need. In this paper, we present a novel system named Microscaler to automatically identify the scaling-needed services and scale them to meet the service level agreement (SLA) with an optimal cost for micro-service systems. Microscaler collects the quality of service metrics (QoS) with the help of the service mesh enabled infrastructure. Then, it determines the under-provisioning or over-provisioning services with a novel criterion named service power. By combining an online learning approach and a step-by-step heuristic approach, Microscaler could achieve the optimal service scale satisfying the SLA requirements. The experimental evaluations in a micro-service benchmark show that Microscaler converges to the optimal service scale faster than several state-of-the-art methods.},
  keywords={},
  doi={10.1109/ICWS.2019.00023},
  ISSN={},
  month={July},}@INPROCEEDINGS{9407977,
  author={Tummalapalli, Sahithi and Kumar, Lov and Neti, Lalita Bhanu Murthy and Krishna, Aneesh},
  booktitle={2020 IEEE 22nd International Conference on High Performance Computing and Communications; IEEE 18th International Conference on Smart City; IEEE 6th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, 
  title={An Empirical Analysis on the Role of WSDL Metrics in Web Service Anti-Pattern Prediction}, 
  year={2020},
  volume={},
  number={},
  pages={559-564},
  abstract={Service-Oriented Architecture (SOA) is one of the most well-known models for designing web systems. SOA system evolution and maintenance is challenging because of its distributive nature and secondly due to the demand of designing high-quality, stable interfaces. This evolution leads to a problem called Anti-patterns in web services. It is observed that these anti-patterns negatively impact the evolution and maintenance of software systems, making the early detection and correction of them a primary concern for the software developers. The primary motivation of this work is to investigate the relationship between the Web Service Description Language(WSDL) metrics and anti-patterns in web services. This research aims to develop an automatic method for the detection of web service anti-patterns. The core idea of the methodology defined is to identify the most crucial WSDL metrics with the association of various feature selection techniques for the prediction of anti-patterns. Experimental results show that the model developed by using all the WSDL quantity metrics(AM) shows a bit high performance compared to the models developed with the other metric sets. Experimental results also showed that the performance of the models generated using Decision Tree(DT) and Major Voting Ensemble(MVE) is high compared to the models generated using other classifier techniques.},
  keywords={},
  doi={10.1109/HPCC-SmartCity-DSS50907.2020.00070},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8035019,
  author={Alnahdi, Amany and Liu, Shih-Hsi},
  booktitle={2017 IEEE International Conference on Services Computing (SCC)}, 
  title={Identifying Characteristic Attributes for Estimating Cost of Service in Service Oriented Architecture}, 
  year={2017},
  volume={},
  number={},
  pages={467-470},
  abstract={Web services are software modules that provide interoperability over a network. Web services provide Web service users platform independence while using software. It enables businesses to collaborate by using Web services from Web service providers. Estimating a Cost of Service (CoS) is essential when pricing, selecting, and monitoring a Web service. The concept of cost is not restricted to financial value of technology hardware and software. The cost concept can also include time, usability, and maintenance. Cost of a Web service can be estimated by identifying the attributes of cost from the perspective of different stakeholders such as Web service provider, Web service consumer, Web service repository moderator, and Web service policy maker. In addition, analyzing different roles in Service Oriented Architecture (SOA) will further provide more knowledge about different perspectives of cost concepts in SOA. This paper addresses the essential attributes of estimating cost of a Web service. Moreover, this paper specifies attributes of measuring CoS, defines these attributes, and defines metrics and units of these attributes. Additionally, it provides further hierarchy classification of Web service cost concepts. It also provides a model for evaluating Web service cost based on different cost criteria. By measuring CoS, Web service stakeholders will be able to estimate an accurate value to the CoS.},
  keywords={},
  doi={10.1109/SCC.2017.66},
  ISSN={2474-2473},
  month={June},}@INPROCEEDINGS{8786277,
  author={Delgado, Andrea},
  booktitle={2018 XLIV Latin American Computer Conference (CLEI)}, 
  title={Monitoring and Analyzing Service Execution from Business Processes: An AXIS Extension}, 
  year={2018},
  volume={},
  number={},
  pages={582-589},
  abstract={Implementing Business Processes (BPs) with services (and microservices) is nowadays the main way to support the execution of automated activities in processes, both within the organization itself, and externally interacting with customers, suppliers and other participants. In order to do so, it is important not only to model and implement services but also to define Quality of Service (QoS) characteristics for services, to monitor and evaluate their execution. Although there are many proposals for services monitoring and evaluation from the services point of view, there are not many from the BPs perspective. In this paper we present a reference architecture for service monitoring tools, along with a prototype implementation as an extension of the web services execution environment AXIS2. We show that existing service measures and new ones can be defined into the monitor to collect execution data and relate this data with BPs execution, to measure BPs and service execution in an integrated manner.},
  keywords={},
  doi={10.1109/CLEI.2018.00075},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9307705,
  author={Camilli, Matteo and Colarusso, Carmine and Russo, Barbara and Zimeo, Eugenio},
  booktitle={2020 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)}, 
  title={Domain Metric Driven Decomposition of Data-Intensive Applications}, 
  year={2020},
  volume={},
  number={},
  pages={189-196},
  abstract={The microservices architectural style is picking up more and more momentum in IT industry for the development of systems as loosely coupled, collaborating services. Companies that undergo the migration of their own applications have aspirations such as increasing maintainability and the scale of operation. Such a process is worthwhile but not easy, since it should ensure atomic improvements to the overall architecture for each migration step. Furthermore, the systematic evaluation of migration steps becomes cumbersome without sensible optimization metrics that take into account performance and scalability under expected operational conditions. Recent lines of research recognize this task as challenging, especially in data-intensive applications where known approaches based, for instance, on Domain Driven Design may not be adequate. In this paper, we introduce an approach to evaluate a migration in an iterative way and recognize whether it represents an improvement in terms of performance and scalability. The approach leverages a Domain Metric-based analysis to quantitatively evaluate alternative architectures. We exemplified the envisioned approach on a data-intensive application case study in the domain of smart mobility. Preliminary results from our controlled experiments show the effectiveness of our approach to support systematic and automated evaluation of migration processes.},
  keywords={},
  doi={10.1109/ISSREW51248.2020.00071},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8986987,
  author={Tripathi, Manish K and Chaubisa, Divyanshu and Kumar, Lov and Murthy Neti, Lalita Bhanu},
  booktitle={2018 15th IEEE India Council International Conference (INDICON)}, 
  title={Prediction of Quality of Service Parameters Using Aggregate Software Metrics and Machine Learning Techniques}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={In todays Service-Oriented Architecture (SOA) world, software systems are built by composing web services offered by Service Providers (SPs). There are different SPs offering services for the same set of functional requirements. Service providers are expected to be highly competitive in their offerings to enhance their market. The quality of web services is an important factor that differentiates one service provider from another. Twelve parameters are identified by which quality of service can be measured. The prediction of these twelve QoS parameters help SPs to enhance the quality of their service. Each web service is realized by several programming files. CK and object oriented metrics of the underlying Java files of the web services are important features for predicting QoS parameters of the web service. The aggregated measure, mean, is chosen to be a feature in predicting the QoS parameters in earlier studies. We propose to build prediction models using 16 aggregate measures and show that there is significant difference between these aggregate measures. We find best feature subset using six feature selection techniques and build prediction models using Extreme Learning Machines with different kernels. We show that feature selection techniques might not enhance prediction accuracies and the ensemble algorithm out performs other learning algorithms.},
  keywords={},
  doi={10.1109/INDICON45594.2018.8986987},
  ISSN={2325-9418},
  month={Dec},}@INPROCEEDINGS{8767397,
  author={White, Gary and Palade, Andrei and Cabrera, Christian and Clarke, Siobhán},
  booktitle={2019 IEEE International Conference on Pervasive Computing and Communications (PerCom}, 
  title={Autoencoders for QoS Prediction at the Edge}, 
  year={2019},
  volume={},
  number={},
  pages={1-9},
  abstract={In service-oriented architectures, collaborative filtering is a key technique for service recommendation based on QoS prediction. Matrix factorisation has emerged as one of the main approaches for collaborative filtering as it can handle sparse matrices and produces good prediction accuracy. However, this process is resource-intensive and training must take place in the cloud, which can lead to a number of issues for user privacy and being able to update the model with new QoS information. Due to the time-varying nature of QoS it is essential to update the QoS prediction model to ensure that it is using the most recent values to maintain prediction accuracy. The request time, which is the time for a middleware to submit a user's information and receive QoS metrics for a candidate services is also important due to the limited time during dynamic service adaptations to choose suitable replacement services. In this paper we propose a stacked autoencoder with dropout on a deep edge architecture and show how this can be used to reduce training and request time compared to traditional matrix factorisation algorithms, while maintaining predictive accuracy. To evaluate the accuracy of the algorithms we compare the actual and predicted QoS values using standard error metrics such as MAE and RMSE. In addition, we propose an alternative evaluation technique using the predictions as part of a service composition and measuring the impact that the predictions have on the response time and throughput of the final composition. This more clearly shows the direct impact that these algorithms will have in practice.},
  keywords={},
  doi={10.1109/PERCOM.2019.8767397},
  ISSN={2474-249X},
  month={March},}@INPROCEEDINGS{7434265,
  author={Bora, Abhijit and Bezboruah, Tulshi},
  booktitle={2015 IEEE International Conference on Research in Computational Intelligence and Communication Networks (ICRCICN)}, 
  title={Some aspects of QoS for interoperability of multi service multi functional service oriented computing}, 
  year={2015},
  volume={},
  number={},
  pages={363-368},
  abstract={Quality of service is the key indicator for service oriented architectures, because it directly expresses the operability and computational nature of the system. As such, we propose a quality evaluation framework for multi service multi functional hierarchical SOAP based web service. The overall interoperable quality is evaluated through load testing using Mercury Load Runner with Apache Tomcat web server and MySQL database engine. The recorded quality metrics are analyzed statistically. We present here in detail the architecture, observed metrics and analyzed results of the service oriented computing to validate the acceptability of the evaluation framework.},
  keywords={},
  doi={10.1109/ICRCICN.2015.7434265},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8539382,
  author={Park, Youngki and Yang, Hyunsik and Kim, Younghan},
  booktitle={2018 International Conference on Information and Communication Technology Convergence (ICTC)}, 
  title={Performance Analysis of CNI (Container Networking Interface) based Container Network}, 
  year={2018},
  volume={},
  number={},
  pages={248-250},
  abstract={The increasing significance of lightweight cloud infrastructure for microservices cannot be overstated. This has led many researchers to propose container based virtualized computing services. Specifically, for networks, Container Networking Interface technologies are proposed to connect heterogeneous network services between virtual-machine based clouds and containers. In order to improve network performance of cloud systems, a comparison with detailed design and performance verification of network configuration using CNI technologies is required. In this paper, centering on various CNI technologies, we designed network architectures with OpenStack cloud platform and Kubernetes container management environment, and subsequently measured network performance for each design. The results of the evaluation are useful to provide guidelines for containerized cloud system deployment.},
  keywords={},
  doi={10.1109/ICTC.2018.8539382},
  ISSN={2162-1233},
  month={Oct},}@INPROCEEDINGS{9272016,
  author={Liu, Bo and Betancourt, Victor Pazmino and Zhu, Yimeng and Becker, Jürgen},
  booktitle={2020 IEEE International Symposium on Systems Engineering (ISSE)}, 
  title={Towards an On-Demand Redundancy Concept for Autonomous Vehicle Functions using Microservice Architecture}, 
  year={2020},
  volume={},
  number={},
  pages={1-5},
  abstract={More and more functionalities will be deployed on heterogeneous devices in the vehicle for future autonomous driving. These devices will be connected not only within the vehicle but also to the internet to receive information or consume services provided by other vehicles or road-side units. Even some functions could be offloaded to the cloud infrastructure. However, this high connectivity also means more cyber-security issues for future autonomous driving cars. As cyber-attacks become a more serious issue for the future automotive industry, keeping high availability of safety-critical and non-safety-critical vehicle functions when connected devices in the vehicle are being attacked is an important and challenging task. In this paper, we propose an on-demand redundancy concept to get high availability for autonomous vehicle functions using microservice architecture and container technology. We implemented the concept of embedded devices and showed the feasibility of this concept. The results showed that redundancy could be setup dynamically for non-safety-critical vehicle functions in a cost-effective manner using the proposed approach. This approach could be taken as a security measure while certain devices are being attacked, and the system could continue working without being influenced.},
  keywords={},
  doi={10.1109/ISSE49799.2020.9272016},
  ISSN={2687-8828},
  month={Oct},}@INPROCEEDINGS{9279887,
  author={Băjenaru, Lidia and Dobre, Ciprian and Ciobanu, Radu-Ioan and Dedu, Georgiana and Pantelimon, Silviu-George and Marinescu, Ion Alexandru and Gavrilă, Veronica},
  booktitle={2020 International Conference on e-Health and Bioengineering (EHB)}, 
  title={Depth-based Human Activity Recognition: vINCI Case Study}, 
  year={2020},
  volume={},
  number={},
  pages={1-4},
  abstract={The growing aging of the world's population is leading to the need to take assistance measures and prepare health care systems for the elderly. The innovative vINCI system provides technologies and uses smart devices that can noninvasively monitor the activity of elderly, to intervene in case of alerts, to prevent possible health problems, such as falling, in the same time to keep their life independent and to improve their quality of life. Monitoring physical activity of the elderly with the help of smart cameras is important in identifying one of the most important lifestyle risk factors for many chronic conditions in the older age. In this paper there are presented the microservice-based vINCI architecture and how an Orbbec Persee camera is used to monitor the physical activity as well as to recognize the elderly. The advantages of the monitoring physical activity application consist in detecting a low level of activity or detecting health problems allowing intervention and correction of an unhealthy lifestyle.},
  keywords={},
  doi={10.1109/EHB50910.2020.9279887},
  ISSN={2575-5145},
  month={Oct},}@INPROCEEDINGS{9628475,
  author={de Faria, Brenno Tondato and Aguzzi, Cristiano and Bates, Travis and Campbell, Colin and Tomei, Fausto and Bittelli, Marco and Roffia, Luca},
  booktitle={2021 IEEE International Workshop on Metrology for Agriculture and Forestry (MetroAgriFor)}, 
  title={Predict soil moisture into the future: on the integration of CRITERIA-1D into ZENTRA cloud}, 
  year={2021},
  volume={},
  number={},
  pages={331-335},
  abstract={This paper presents a case of study of a IoT cloud plat-form composed of a microservices architecture that has been developed to integrate the CRITERIA-1D into the ZENTRA cloud. CRITERIA-1D is an open-source agro-hydrological model developed by ARPAE simulating one-dimensional soil water fluxes, crop development, and crop water needs. CRITERIA-1D comes with a default set of crops and soils that can be used or tuned for a specific scenarios. Taking as input the weather forecasts (i.e., temperatures and precipitations), the model can be used to predict the soil water content and soil water potential at different depths. Along with the design of the implemented solution, this paper presents the process of tuning crop and soil parameters for a specific use case. The results show that the tuned model estimates very well with respect to the measures observed by sensors, paving the way to its application within the larger context of the METER’s ZENTRA cloud.},
  keywords={},
  doi={10.1109/MetroAgriFor52389.2021.9628475},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{7062707,
  author={Nuraini, Aminah and Widyani, Yani},
  booktitle={2014 International Conference on Data and Software Engineering (ICODSE)}, 
  title={Software with service oriented architecture quality assessment}, 
  year={2014},
  volume={},
  number={},
  pages={1-6},
  abstract={Service Oriented Architecture (SOA) is becoming popular since its flexibility fulfill the need of rapidly changing enterprise requirement. Therefore, expectation of a good quality software with SOA is getting higher. To address this need, this paper presents a guideline to conduct quality assessment using an existing tool. The quality assessment model is designed by selecting the relevant quality factors, choosing an appropriate quality to metric mapping method, identifying the relevant metrics, and mapping each quality factor to the metrics. Using the model, the quality assessment process is prepared by identifying data and selecting the appropriate tools. The chosen tool may require some modification. The proposed quality assessment guideline can help the software quality assurance team to assess quality of their software with SOA. The proposed guideline has been used to assess the quality of an existing sofware with SOA (Bonita BPM). The result is considered as promising, although several improvement are still needed.},
  keywords={},
  doi={10.1109/ICODSE.2014.7062707},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8622058,
  author={Streiffer, Christopher and Raghavendra, Ramya and Benson, Theophilus and Srivatsa, Mudhakar},
  booktitle={2018 IEEE International Conference on Big Data (Big Data)}, 
  title={Learning to Simplify Distributed Systems Management}, 
  year={2018},
  volume={},
  number={},
  pages={1837-1845},
  abstract={Managing large-scale distributed systems is a difficult task. System administrators are responsible for the upkeep and maintenance of numerous components with complex dependencies. With the shift to microservices-based architectures, these systems can consist of 100s to 1000s of interconnected nodes. To combat this difficulty, administrators rely on analyzing logs and metrics collected from the different services. However, the number of available metrics for large systems presents complexity and scaling issues. To combat these issues, we present Minerva, an unsupervised Machine Learning (ML) framework for performing network diagnosis analysis. Minerva is composed of a multi-stage pipeline, where each component can act individually or cohesively to perform various management tasks. Our system offers a unified and extensible framework for managing the complexity of large networks, and presents administrators with a swiss-army knife for diagnosing the overall health of their systems. To demonstrate the feasibility of Minerva, we evaluate its performance on a production-scale system. We present use cases for the various management tools made available by Minerva, and show how these tools can be used to make strong inferences about the system using unsupervised techniques.},
  keywords={},
  doi={10.1109/BigData.2018.8622058},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9453517,
  author={Lennick, David and Azim, Akramul and Liscano, Ramiro},
  booktitle={2021 22nd IEEE International Conference on Industrial Technology (ICIT)}, 
  title={A Microservice-Based Architecture for Performance and Energy Benchmarking of Docker-Host Linux Distributions on Internet-of-Things Devices}, 
  year={2021},
  volume={1},
  number={},
  pages={705-711},
  abstract={Containers are rapidly being adopted in several areas of the information technology industry. A major area is edge and embedded Internet-of-Things systems. In this paper, we present a microservice-based architecture for performance analysis and energy consumption of Internet-of-Things "Docker host" Linux distributions. Our methodology builds on previous container benchmarking work, with analysis of performance metrics such as processing, memory, and disk throughput. Furthermore, our methodology introduces container-engine performance metrics related to container lifecycle operations, and concurrent container performance. We demonstrate by comparing four Linux distributions in this domain: BalenaOS, HypriotOS, RancherOS, and Raspbian Lite. All source code is provided.},
  keywords={},
  doi={10.1109/ICIT46573.2021.9453517},
  ISSN={},
  month={March},}@INPROCEEDINGS{7019405,
  author={Deepiga A S and Senthil Velan S and Babu, Chitra},
  booktitle={2014 IEEE International Conference on Advanced Communications, Control and Computing Technologies}, 
  title={Empirical investigation of introducing Aspect Oriented Programming across versions of an SOA application}, 
  year={2014},
  volume={},
  number={},
  pages={1732-1739},
  abstract={Service Oriented Architecture (SOA) is an architectural style used to provide services to consumers that promotes loose coupling between services. The scattered and tangled functionalities modeled in an SOA application can be redesigned using Aspect Oriented Programming (AOP). This results in two sets of services, the first set having services for the base functionalities and the other modeling cross-cutting functionalities. During compilation, cross-cutting functionalities in the second set are woven to the functionalities modeled in the first set. By introducing AOP in SOA, the quality attributes such as re-usability, extendibility and maintainability can be improved. The objective of this paper is to perform an empirical investigation by quantitatively measuring the effect of introducing Aspect Orientation (AO) in SOA by developing with multiple versions of a given application. An AO based SOA application (University Automation System) for automating the functionalities of a typical University with multiple versions has been developed as an experimental test bed. An equivalent set of versions without introducing aspectization are also developed in parallel. The values of the AOP metrics are measured for the different versions of University Automation System both aspectized and unaspectized. The measured values show that the quality attributes namely maintainability, reusability and extendibility improve whereas the complexity of the application decreases during the evolution of the case study application.},
  keywords={},
  doi={10.1109/ICACCCT.2014.7019405},
  ISSN={},
  month={May},}@INPROCEEDINGS{6830891,
  author={Alzahmi, Salwa Mohamed and Abu-Matar, Mohammad and Mizouni, Rabeb},
  booktitle={2014 IEEE 8th International Symposium on Service Oriented System Engineering}, 
  title={A Practical Tool for Automating Service Oriented Software Product Lines Derivation}, 
  year={2014},
  volume={},
  number={},
  pages={90-97},
  abstract={Service Oriented Architecture (SOA) is a business driven architecture that supports business strategies and goals. In enterprise systems, it offers flexibility for building IT solutions that can respond rapidly to changing business requirements and technology. The success of a service-oriented application implementation is measured by the level of flexibility, extendibility and customization in the provided services. In effect, it raises variability management concerns that require a good understanding of the business domain and a careful design of the application artifacts to cater for various service consumers' demands and requirements. Many approaches and frameworks have been proposed to realize variability in SOA by applying the concept of Software Product Lines (SPL) where services are the core assets and each member of the service-oriented product line is a possible assembly of those services. However, there are few tools that support these approaches and ease the derivation process of member applications taking into consideration the variability from different perspectives. In this paper we present a tool that facilitates the automatic derivation of SOA applications based on Model Driven Engineering (MDE) as an implementation methodology. The tool is based on the Multiple-Views Service-Oriented Product Line Variability approach. The tool architecture as well as its implemented modules is first described. Then, an example in the e-health domain is presented.},
  keywords={},
  doi={10.1109/SOSE.2014.16},
  ISSN={},
  month={April},}@INPROCEEDINGS{8009904,
  author={Arcuri, Andrea},
  booktitle={2017 IEEE International Conference on Software Quality, Reliability and Security (QRS)}, 
  title={RESTful API Automated Test Case Generation}, 
  year={2017},
  volume={},
  number={},
  pages={9-20},
  abstract={Nowadays, web services play a major role in the development of enterprise applications. Many such applications are now developed using a service-oriented architecture (SOA), where microservices is one of its most popular kind. A RESTful web service will provide data via an API over the network using HTTP, possibly interacting with databases and other web services. Testing a RESTful API poses challenges, as inputs/outputs are sequences of HTTP requests/responses to a remote server. Many approaches in the literature do black-box testing, as the tested API is a remote service whose code is not available. In this paper, we consider testing from the point of view of the developers, which do have full access to the code that they are writing. Therefore, we propose a fully automated white-box testing approach, where test cases are automatically generated using an evolutionary algorithm. Tests are rewarded based on code coverage and fault finding metrics. We implemented our technique in a tool called EVOMASTER, which is open-source. Experiments on two open-source, yet non-trivial RESTful services and an industrial one, do show that our novel technique did automatically find 38 real bugs in those applications. However, obtained code coverage is lower than the one achieved by the manually written test suites already existing in those services. Research directions on how to further improve such approach are therefore discussed.},
  keywords={},
  doi={10.1109/QRS.2017.11},
  ISSN={},
  month={July},}@INPROCEEDINGS{8595113,
  author={Bogner, Justus and Fritzsch, Jonas and Wagner, Stefan and Zimmermann, Alfred},
  booktitle={2018 IEEE/ACM International Conference on Technical Debt (TechDebt)}, 
  title={Limiting Technical Debt with Maintainability Assurance – An Industry Survey on Used Techniques and Differences with Service- and Microservice-Based Systems}, 
  year={2018},
  volume={},
  number={},
  pages={125-133},
  abstract={Maintainability assurance techniques are used to control this quality attribute and limit the accumulation of potentially unknown technical debt. Since the industry state of practice and especially the handling of Service-and Microservice-Based Systems in this regard are not well covered in scientific literature, we created a survey to gather evidence for a) used processes, tools, and metrics in the industry, b) maintainability-related treatment of systems based on service-orientation, and c) influences on developer satisfaction w.r.t. maintainability. 60 software professionals responded to our online questionnaire. The results indicate that using explicit and systematic techniques has benefits for maintainability. The more sophisticated the applied methods the more satisfied participants were with the maintainability of their software while no link to a hindrance in productivity could be established. Other important findings were the absence of architecture-level evolvability control mechanisms as well as a significant neglect of service-oriented particularities for quality assurance. The results suggest that industry has to improve its quality control in these regards to avoid problems with long-living service-based software systems.},
  keywords={},
  doi={},
  ISSN={},
  month={May},}@ARTICLE{9285284,
  author={Rumez, Marcel and Grimm, Daniel and Kriesten, Reiner and Sax, Eric},
  journal={IEEE Access}, 
  title={An Overview of Automotive Service-Oriented Architectures and Implications for Security Countermeasures}, 
  year={2020},
  volume={8},
  number={},
  pages={221852-221870},
  abstract={New requirements from the customers' and manufacturers' point of view such as adding new software functions during the product life cycle require a transformed architecture design for future vehicles. The paradigm of signal-oriented communication established for many years will increasingly be replaced by service-oriented approaches in order to increase the update and upgrade capability. In this article, we provide an overview of current protocols and communication patterns for automotive architectures based on the service-oriented architecture (SOA) paradigm and compare them with signal-oriented approaches. Resulting challenges and opportunities of SOAs with respect to information security are outlined and discussed. For this purpose, we explain different security countermeasures and present a state of the section of automotive approaches in the fields of firewalls, Intrusion Detection Systems (IDSs) and Identity and Access Management (IAM). Our final discussion is based on an exemplary hybrid architecture (signal- and service-oriented) and examines the adaptation of existing security measures as well as their specific security features.},
  keywords={},
  doi={10.1109/ACCESS.2020.3043070},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7959309,
  author={Zavvar, Mohammad and Garavand, Shole and Sabbagh, Esmaeel and Rezaei, Meysam and Khalili, Hajar and Zavvar, Mohammad Hossein and Motameni, Homayun},
  booktitle={2017 3th International Conference on Web Research (ICWR)}, 
  title={Measuring service quality in service-oriented architectures using a hybrid particle swarm optimization algorithm and artificial neural network (PSO-ANN)}, 
  year={2017},
  volume={},
  number={},
  pages={78-83},
  abstract={Web service combination is an important task performed in different phases of the service-oriented architecture lifecycle. Measuring service quality based on the non-functional characteristics is an exceedingly difficult task. Therefore, this paper presents a Multilayer Perceptron Artificial Neural Network (MLPANN) to provide a method for measuring quality of service in a service-oriented architecture. To improve network performance, Particle Swarm Optimization (PSO) is used to optimize the weights of the network. Finally, our results are compared to those of a combination of Different Evolution (DE) algorithm and MLPANN in terms of Mean Square Error (MSE), Root Mean Square Error (RMSE) and Standard Deviation (STD). The results demonstrate the superiority of the proposed method.},
  keywords={},
  doi={10.1109/ICWR.2017.7959309},
  ISSN={},
  month={April},}@INPROCEEDINGS{9628703,
  author={du Plessis, Shani and Correia, Noélia},
  booktitle={2021 IEEE International Conference on Internet of Things and Intelligence Systems (IoTaIS)}, 
  title={A Comparative Study of Software Architectures in Constrained Device IoT Deployments}, 
  year={2021},
  volume={},
  number={},
  pages={35-41},
  abstract={The Internet of Things (IoT) is an area that has consistently seen growth and development and will no doubt continue to do so. One group of IoT devices - constrained devices - has seen significant developments in recent years. With the advent of constrained devices in almost every area of life, e.g. industrial, leisure and medical, this group of devices is well worth studying. Clearly, resource management is a critical aspect to ensure optimal use of such devices. A number of factors can have a significant impact on resource management, such as the operating system and the software architecture.This study aimed to compare the power consumption, runtime performance and memory consumption of two software architectures: microservices and monolithic. The study was conducted using a constrained device, and to ensure that the results are not language-specific, three different programming languages were used: Go, Python and C++. It was found that, for smallscale applications, the monolithic architecture performed better across most metrics. These results may provide valuable insights to engineers for the design and implementation of constrained-device IoT applications. It was recommended that additional research be conducted on larger-scale applications.},
  keywords={},
  doi={10.1109/IoTaIS53735.2021.9628703},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8638056,
  author={Ahmed, Abdelmuttlib Ibrahim Abdalla and Khan, Suleman and Gani, Abdullah and Hamid, Siti Hafizah Ab and Guizani, Mohsen},
  booktitle={2018 IEEE 43rd Conference on Local Computer Networks (LCN)}, 
  title={Entropy-based Fuzzy AHP Model for Trustworthy Service Provider Selection in Internet of Things}, 
  year={2018},
  volume={},
  number={},
  pages={606-613},
  abstract={Nowadays, trust and reputation models are used to build a wide range of trust-based security mechanisms and trust-based service management applications on the Internet of Things (IoT). Considering trust as a single unit can result in missing important and significant factors. We split trust into its building-blocks, then we sort and assign weight to these building-blocks (trust metrics) on the basis of its priorities for the transaction context of a particular goal. To perform these processes, we consider trust as a multi-criteria decision-making problem, where a set of trust worthiness metrics represent the decision criteria. We introduce Entropy-based fuzzy analytic hierarchy process (EFAHP) as a trust model for selecting a trustworthy service provider, since the sense of decision making regarding multi-metrics trust is structural. EFAHP gives 1) fuzziness, which fits the vagueness, uncertainty, and subjectivity of trust attributes; 2) AHP, which is a systematic way for making decisions in complex multi-criteria decision making; and 3) entropy concept, which is utilized to calculate the aggregate weights for each service provider. We present a numerical illustration in trust-based Service Oriented Architecture in the IoT (SOA-IoT) to demonstrate the service provider selection using the EFAHP Model in assessing and aggregating the trust scores.},
  keywords={},
  doi={10.1109/LCN.2018.8638056},
  ISSN={0742-1303},
  month={Oct},}@ARTICLE{6812231,
  author={Hertis, Matej and Juric, Matjaz B.},
  journal={IEEE Transactions on Software Engineering}, 
  title={An Empirical Analysis of Business Process Execution Language Usage}, 
  year={2014},
  volume={40},
  number={8},
  pages={738-757},
  abstract={The current state of executable business process languages allows for and demands optimization of design practices and specifications. In this paper, we present the first empirical study that analyses Web Services Business Process Execution Language (WS-BPEL or BPEL) usage and characteristics of real world executable business processes. We have analysed 1,145 BPEL processes by measuring activity usage and process complexity. In addition, we investigated the occurrence of activity usage patterns. The results revealed that the usage frequency of BPEL activities varies and that some activities have a strong co-occurrence. BPEL activities often appear in activity patterns that are repeated in multiple processes. Furthermore, the current process complexity metrics have proved to be inadequate for measuring BPEL process complexity. The empirical results provide fundamental knowledge on how BPEL specification and process design practices can be improved. We propose BPEL design guidelines and BPEL language improvements for the design of more understandable and less complex processes. The results are of interest to business process language designers, business process tool developers, business process designers and developers, and software engineering researchers, and contribute to the general understanding of BPEL and service-oriented architecture.},
  keywords={},
  doi={10.1109/TSE.2014.2322618},
  ISSN={1939-3520},
  month={Aug},}@INPROCEEDINGS{8536110,
  author={Langermeier, Melanie and Bauer, Bernhard},
  booktitle={2018 IEEE 22nd International Enterprise Distributed Object Computing Workshop (EDOCW)}, 
  title={A Model-Based Method for the Evaluation of Project Proposal Compliance within EA Planning}, 
  year={2018},
  volume={},
  number={},
  pages={97-106},
  abstract={The business model and IT infrastructure of organizations is continually changing. Trends like microservices and digital transformation demand an adaption of the business models and IT infrastructure in order to stay competitive. It is important to ensure the compliance of these new projects with the current goals and principles. The discipline of Enterprise Architecture Planning provides methods for the structured development of the business and IT of an organization. In this paper we propose a tool-supported method for EA planning to evaluate to the project compliance based on established models. Different analyses are used to support the architect during project planning. Gap and impact analysis are used to ensure the change consistency. The compliance with the current strategy is finally evaluated with view generation and metric calculation. Foundation of the method is a generic generic analysis architecture execution environment (A2E), that provides us with the required flexibility to adapt to different needs and meta models. The method and the proposed analyses are evaluated within a case study from a medium-sized software product company.},
  keywords={},
  doi={10.1109/EDOCW.2018.00024},
  ISSN={2325-6605},
  month={Oct},}@INPROCEEDINGS{9150502,
  author={Mahajan, Yash and Krishnaswamy, Dilip and Chelliah, Pethuru Raj},
  booktitle={2020 IEEE Conference on Technologies for Sustainability (SusTech)}, 
  title={MiSA - A System for a Microlending Service to Assist Edge Communities}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={In this paper, we propose a distributed edge+cloud system to assist with microlending services to communities, with machine learning catered to that specific community. A combination of technologies including microservices-based architecture and blockchain technology coupled with machine learning is utilized to provide microfinancing services to help sustain businesses in a local community, and to enable the community to grow into a thriving economy. To minimize the widespread expressed risk, in our prototype, the prediction of whether a loan will default or not is based on the various decision-enabling parameters and on any available information about the borrowers' past transaction as well as aggregate metrics related to the community that the borrower resides in. The authors hope that the suggested distributed edge+cloud architecture in the paper can be leveraged for other emerging sustainable edge applications as well.},
  keywords={},
  doi={10.1109/SusTech47890.2020.9150502},
  ISSN={},
  month={April},}@INPROCEEDINGS{8705779,
  author={Afwani, Royana and Irmawati, Budi and Jatmika, Andy Hidayat and Agitha, Nadiyasari},
  booktitle={2018 5th International Conference on Data and Software Engineering (ICoDSE)}, 
  title={Specialized Mobile Health Design Using the Open Group Architecture Framework (TOGAF): A Case Study in Child and Maternity Health Services Organization}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={Mobile health applications are well known effective to provide education materials, receive personalized prompts, as a reminder system, and also create great impacts as early diagnose system and even facilitate a doctor to recommend treatments for patients in rural area as well as in the disaster area. E-health projects failed with the major problem was “no clear definition of the system requirements”. Another challenge for health organization that have specialized units are flexibility, easily expandable, and sustainability information system architecture to be integrated. Therefore, providing a good architecture design for build mobile health application is important. This research have done initial study to particular units in health care organization (Maternal and Child Health Services - PKIA), observation, site interview, and data collection. The research main phase are analyze and design TOGAF architecture for PKIA organization. TOGAF produced some tables and matrices to address detailed requirements in specialized mobile health services. The result from enterprise architecture than becomes reference for the design and development of mobile information system based on service oriented architecture and can be used on mobile devices for multiple platforms. For future work, we will create a model to map the diagrams and tables of enterprise architecture into specific software design, and work for detailed architecture validation using ALMA and object-oriented metrics.},
  keywords={},
  doi={10.1109/ICODSE.2018.8705779},
  ISSN={2640-0227},
  month={Nov},}@INPROCEEDINGS{9172283,
  author={LaSorda, Maj Michael and Borky, John and Sega, Ron},
  booktitle={2020 IEEE Aerospace Conference}, 
  title={Model-Based Systems Architecting with Decision Quantification for Cybersecurity, Cost, and Performance}, 
  year={2020},
  volume={},
  number={},
  pages={1-13},
  abstract={The architecture selection process early in a major system acquisition is a critical step in determining the success of a program. There are recognized deficiencies that frequently occur in this step such as poor transparency into the final selection decision and excessive focus on lowest cost, which does not necessarily result in best value. This research investigates improvements to this process by integrating Model-Based Systems Engineering (MBSE) techniques; enforcing rigorous, quantitative evaluation metrics with a corresponding understanding of uncertainties; and eliciting stakeholder feedback in order to generate an architecture that is better optimized and trusted to provide improved value for the stakeholders. The proposed methodology presents a decision authority with an integrated assessment of architecture alternatives, to include expected performance evaluated against desired parameters with corresponding uncertainty distributions, and traceable to the concerns of the system's stakeholders. This thus enables a more informed and objective selection of the preferred alternative. We present a case study that analyzes the evaluation of a service-oriented architecture (SOA) providing satellite command and control with cyber security protections. This serves to define and demonstrate a new, more transparent and trusted architecture selection process, and the results show that it consistently achieves the desired improvements. Several excursions are also presented to show how rigorously capturing uncertainty could potentially lead to greater insights in architecture evaluation, which is a robust area for further investigation. The primary contribution of this research then is improved decision support to an architecture selection in the early phases of a system acquisition program.},
  keywords={},
  doi={10.1109/AERO47225.2020.9172283},
  ISSN={1095-323X},
  month={March},}@INPROCEEDINGS{6917306,
  author={Zhang, Lili and Yu, Shusong and Ding, Xiangqian and Wang, Xiaodong},
  booktitle={2014 Sixth International Conference on Intelligent Human-Machine Systems and Cybernetics}, 
  title={Research on IOT RESTful Web Service Asynchronous Composition Based on BPEL}, 
  year={2014},
  volume={1},
  number={},
  pages={62-65},
  abstract={In recent years, The Internet of Things(IOT) is one of the hottest research topics. It was originally defined as connected all the things through the sensing devices to the Internet. In addition, Service-Oriented methodology has gradually drawn people's attention. Therefore, integrated The IOT with Service-Oriented methodology is very important. But now IOT service composition is mostly synchronous and service model is more complex. RESTful web services have been widely recognized and used because of their lightweight and succinct. RESTful web services introduce a new kind of abstraction, the resource, so that they are hard to compose using the Business Process Execution Language (BPEL). In order to compose asynchronous RESTful web services and make use of various IOT services, this paper proposes an asynchronous RESTful web service recursive measure, which is based on the BPEL extention. First, design the architecture of IOT RESTful web services, the architecture is divided into six layers so that it can integrate The IOT and RESTful web services effectively. Second, we show how to invoke the RESTful web services from the IOT and publish a BPEL process as a RESTful web service by extending BPEL. Finally, through an experiment to verify the correctness and validity of the proposed method in this paper.},
  keywords={},
  doi={10.1109/IHMSC.2014.23},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{7153891,
  author={Abid, Kashif Sohail and Abid, Asif Sohail and Ansari, M. Mohsen},
  booktitle={2015 IEEE International Conference on Multimedia Big Data}, 
  title={A Better Approach for Conceptual Readability of WSDL}, 
  year={2015},
  volume={},
  number={},
  pages={260-263},
  abstract={Issues that concerns with the inter-operability on a heterogeneous environment can easily be address using the flexible platform of Service Oriented Architecture (SOA). Web service is an implementation and modeling of Service Oriented Architecture (SOA). Web service description language (WSDL)is a standard describing a web service in XML form. This Description can be categorized in two parts i.e. Structural and non-structural. The readability of a web service helps the consumer to understand it easily, it is suggested to provide sufficient details about functionality scope and limitation of scope in WSDL, so that it can easily be understandable. Readability depends upon interaction of two variables i.e. Text and reader. The maximum details about a web service could lead to it's reproduction by business competitor, and it may helps in maximizing vulnerabilities in it. This paper focuses on a technique for computing readability index by a detail analysis of WSDL document. This readability index obtain using this approach helps the producer of a web service to adjust readability, so that it can easily be understandable by consumer. The better readability index can also leads the provider to a better service discovery. To calculate Readability Index, extraction of WSDL file components was performed. After extraction of key concepts, they were mapped with the Domain Ontology. The words that were not mapped in the ontology, synonyms are employed by consulting the Word Net. Final readability was obtained using Simplified Dale Chall readability index (DaCw). The Web Service Readability can be measure more precisely by considering words that were not found in the mapping process.},
  keywords={},
  doi={10.1109/BigMM.2015.52},
  ISSN={},
  month={April},}@INPROCEEDINGS{7060895,
  author={Mohamed, Merabet and Mohamed, Benslimane Sidi and El Amine Chergui, Mohamed},
  booktitle={2014 Second World Conference on Complex Systems (WCCS)}, 
  title={A hybrid particle swarm optimization for service identification from business process}, 
  year={2014},
  volume={},
  number={},
  pages={122-127},
  abstract={Service identification - as the first step of Service-Oriented Architecture -holds the main emphasis on the modeling process and has a broad influence on the system development. Selecting appropriate service identification method is essential for the prosperity of any service-oriented architecture project. Existing methods for service identification ignore the automation capability while providing human based prescriptive guidelines, which mostly are not applicable at enterprise scales. In this paper, we propose a top down approach to identify automatically services from business process. We use for clustering a hybrid particle swarm optimization algorithm and several design metrics for produce reusable services with proper granularity and acceptable level of cohesion and coupling. The experimental results show that our method HPSOSI (Hybrid Particle Swarm Algorithm for Service Identification) can achieve a high performance in terms of execution time and convergence speed.},
  keywords={},
  doi={10.1109/ICoCS.2014.7060895},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8537823,
  author={Saadaoui, Alaeddine and Scott, Stephen L.},
  booktitle={2018 IEEE 4th International Conference on Collaboration and Internet Computing (CIC)}, 
  title={Lightweight Web Services Migration Framework in Hybrid Clouds}, 
  year={2018},
  volume={},
  number={},
  pages={106-113},
  abstract={Service-oriented architectures allow the deployment of loosely coupled services that are platform independent. An enterprise can take advantage of service-oriented architecture in two different directions. On one side, the abstraction of technology implementation allows the deployment of web services in disparate systems. On the other side, the flexibility and independence of services from each other makes scalability easier to achieve. This paper presents a migration solution of web services in hybrid clouds. The adoption of hybrid cloud solutions is valuable for dynamic workloads to maintain the availability of web services during periods of spikes in demand. The migration solution is a lightweight framework composed of web services to manage cloud instances and the migration task of web services deployed on Java-based web containers. The peak management process is based on Java Management Extensions (JMX) technology to monitor resources and deployed web services. In addition, the framework dynamically integrates a set of JMX metrics to synchronize enterprise demand for resources with the migration process. Finally, a design of the framework prototype is described and a real case of CPU intensive web service is presented to test the migration process and show an improvement of CPU usage and execution time.},
  keywords={},
  doi={10.1109/CIC.2018.00025},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{7275851,
  author={Kumari, Smita and Rath, Santanu Kumar},
  booktitle={2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)}, 
  title={Performance comparison of SOAP and REST based Web Services for Enterprise Application Integration}, 
  year={2015},
  volume={},
  number={},
  pages={1656-1660},
  abstract={Web Services are common means to exchange data and information over the network. Web Services make themselves available over the internet, where technology and platform are independent. Once web services are built it is accessed via uniform resource locator (URL) and their functionalities can be utilized in the application domain. Web services are self-contained, modular, distributed and dynamic in nature. These web services are described and then published in Service Registry e.g., UDDI and then they are invoked over the Internet. Web Services are basic Building blocks of Services Oriented Architecture (SOA). These web services can be developed based on two interaction styles such as Simple Object Access Protocol (SOAP) and Representational State Transfer Protocol (REST). It is important to select appropriate interaction styles i.e., either SOAP or REST for building Web Sevices. Choosing service interaction style is an important architectural decision for designers and developers, as it influences the underlying requirements for implementing web service solutions. In this study, the performance of application of web services for Enterprise Application Integration (EAI) based on SOAP and REST is compared. Since web services operate over network throughput and response time are considered as a metrics parameter for evaluation.},
  keywords={},
  doi={10.1109/ICACCI.2015.7275851},
  ISSN={},
  month={Aug},}@ARTICLE{6517184,
  author={Bianchini, Devis and Cappiello, Cinzia and De Antonellis, Valeria and Pernici, Barbara},
  journal={IEEE Transactions on Services Computing}, 
  title={Service Identification in Interorganizational Process Design}, 
  year={2014},
  volume={7},
  number={2},
  pages={265-278},
  abstract={Service identification is one of the main phases in the design of a service-oriented application. The way in which services are identified may influence the effectiveness of the SOA architecture. More specifically, the granularity of the services is very important in reaching flexibility and reusing them. Such properties are crucial in interorganizational interactions based on collaborative business processes. In fact, collaboration is facilitated by ensuring a homogeneous description of services at the right level of granularity. In this paper, we provide a detailed description of P2S (Process-to-Services), a computer-aided methodology to enable the identification of services that compose a collaborative business process. The methodology is based on metrics defined to setup service granularity, cohesion, coupling, and reuse. A prototype tool based on the methodology is also described with reference to a real case scenario.},
  keywords={},
  doi={10.1109/TSC.2013.26},
  ISSN={1939-1374},
  month={April},}@INPROCEEDINGS{8621924,
  author={Guntupally, Kavya and Devarakonda, Ranjeet and Kehoe, Kenneth},
  booktitle={2018 IEEE International Conference on Big Data (Big Data)}, 
  title={Spring Boot based REST API to Improve Data Quality Report Generation for Big Scientific Data: ARM Data Center Example}, 
  year={2018},
  volume={},
  number={},
  pages={5328-5329},
  abstract={Web application technologies are growing rapidly with continuous innovation and improvements. This paper focuses on the popular Spring Boot [1] java-based framework for building web and enterprise applications and how it provides the flexibility for service-oriented architecture (SOA). One challenge with any Spring-based applications is its level of complexity with configurations. Spring Boot makes it easy to create and deploy stand-alone, production-grade Spring applications with very little Spring configuration. Example, if we consider Spring Model-View-Controller (MVC) framework [2], we need to configure dispatcher servlet, web jars, a view resolver, and component scan among other things. To solve this, Spring Boot provides several Auto Configuration options to setup the application with any needed dependencies. Another challenge is to identify the framework dependencies and associated library versions required to develop a web application. Spring Boot offers simpler dependency management by using a comprehensive, but flexible, framework and the associated libraries in one single dependency, which provides all the Spring related technology that you need for starter projects as compared to CRUD web applications. This framework provides a range of additional features that are common across many projects such as embedded server, security, metrics, health checks, and externalized configuration. Web applications are generally packaged as war and deployed to a web server, but Spring Boot application can be packaged either as war or jar file, which allows to run the application without the need to install and/or configure on the application server. In this paper, we discuss how Atmospheric Radiation Measurement (ARM) Data Center (ADC) at Oak Ridge National Laboratory, is using Spring Boot to create a SOA based REST [4] service API, that bridges the gap between frontend user interfaces and backend database. Using this REST service API, ARM scientists are now able to submit reports via a user form or a command line interface, which captures the same data quality or other important information about ARM data.},
  keywords={},
  doi={10.1109/BigData.2018.8621924},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8372741,
  author={Al-Shammari, Haider Qays and Lawey, Ahmed and El-Gorashi, Taisir and Elmirghani, Jaafar M. H.},
  booktitle={2018 27th Wireless and Optical Communication Conference (WOCC)}, 
  title={Energy efficient service embedding in IoT networks}, 
  year={2018},
  volume={},
  number={},
  pages={1-5},
  abstract={The Internet of Things (IoT) is anticipated to participate in performing diverse and complex tasks in the near future. IoT objects capable of handling multiple sensing and actuating functions will be the corner stone of future IoT systems in smart cities. In this paper, we present an energy efficient service embedding framework in IoT network by using mixed integer linear programming (MILP). This framework addresses a set of metrics such as scalability, flexible resource allocation, cost reduction, and efficient use of resources. We consider the event-driven paradigm of Service Oriented Architecture (SOA) in our framework in order to provide service abstraction of basic services which can be composed into complex services and exploited by the upper application layer. The results show that our optimized network can save an average of 27% and 36% of the processing and network power consumption, respectively, compared to an energy unaware service embedding scheme.},
  keywords={},
  doi={10.1109/WOCC.2018.8372741},
  ISSN={2379-1276},
  month={April},}@INPROCEEDINGS{7396198,
  author={Chituc, Claudia-Melania},
  booktitle={2015 IEEE 7th International Conference on Cloud Computing Technology and Science (CloudCom)}, 
  title={Towards a Methodology for Trade-off Analysis in a Multi-cloud Environment Considering Monitored QoS Metrics and Economic Performance Assessment Results}, 
  year={2015},
  volume={},
  number={},
  pages={479-482},
  abstract={Cloud computing and service-oriented computing brought new opportunities for companies. However, numerous challenges, (e.g., related to application design and deployment, service monitoring) are associated with the cloud and provisioned services. Complex SLAs need to be established and monitored. Current approaches do not sufficiently address the challenges of QoS monitoring in multi-cloud environments in a holistic manner, tackling mainly technical aspects. This paper presents an on-going research project towards the development of a methodology for a trade-off analysis in a multi-cloud environment considering monitored QoS metrics and economic performance assessment results. The research methodology followed and partial results are presented, and directions for future work are discussed. Based on the needs identified, an architecture for SLA monitoring and dynamic runtime adaptations in multi-cloud environments is proposed, tackling technical and business-economic aspects.},
  keywords={},
  doi={10.1109/CloudCom.2015.87},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8441460,
  author={Keserwani, Pankaj Kumar and Samaddar, Shefalika Ghosh},
  booktitle={2017 Ninth International Conference on Advanced Computing (ICoAC)}, 
  title={An SLA Design with Digital Forensic Capabilities}, 
  year={2017},
  volume={},
  number={},
  pages={109-113},
  abstract={Cloud computing is getting rapid momentum as an alternative to traditional and professional Infrastructure of Information Technology due to its attractive features of getting everything in a service mode rather than in a product mode. Service mode using cloud makes the products and services cost effective. As consumers willing to pass on their tasks as services provider to cloud providers, trust factor is required especially when consumers have critical data. The Service Level Agreements (SLA) between cloud service consumers (CSCs) and cloud service providers (CSPs) play important role for building up trust between involved parties. SLA between parties is established in a satisfactory way upon agreements. Cloud computing is very dynamic in nature, hence continuous monitoring on Quality of Service (QoS) attributes as mentioned in SLA is required to be implemented dynamically. Managing SLAs is complicated due to complex nature of the cloud due to multi-tenancy and distributed resource sharing. The paper proposes a methodology for SLAs to be signed digitally and its further management in a single or multi cloud computing environment. The framework had been used in Web Service Level Agreement (WSLA) for monitoring and enforcement of SLA using Service Oriented Architecture (SOA) environment. Cloud broker agents have the capability of automatic extraction of metrics from SLAs. The use of the third party support feature to manage the digital forensics in case of requirement of any violation of SLAs suggested in the present paper and it is also solving the trust issues as demonstrated in digital forensics usage from the initiation of SLA; making the SLA naturally forensic enabled.},
  keywords={},
  doi={10.1109/ICoAC.2017.8441460},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{7068197,
  author={Thirumaran, M. and Jannani, M.},
  booktitle={Proceedings of IEEE International Conference on Computer Communication and Systems ICCCS14}, 
  title={Theoretical foundation to evaluate the change measures for an effective web service change management}, 
  year={2014},
  volume={},
  number={},
  pages={226-232},
  abstract={With the advent in the need for a cost effective and efficient solution which supports the evolution and enhancement of the Enterprise Information Systems, the adoption of Service Oriented Architectures (SOAs) for the automation of business processes and the integration of IT systems is increasing. These SOAs rely on web service standards for the implementation of service invocations across machine boundaries. Web services are software systems designed to support interoperable machine-to-machine interaction over a network. This interoperability is gained through a set of XML-based open standards. These standards provide a common approach for defining, publishing, and using web services. However after a product is introduced in the market, its successful growth against the competitors depends critically on the company's ability to rapidly improve and extend its product in response to customer feedback. These changes must be reflected accordingly in the web service without injecting any disputes. Hence an effective web service Change Management with appropriate change measures is very essential. This paper focuses on such change measures for an effective change management.},
  keywords={},
  doi={10.1109/ICCCS.2014.7068197},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{8259711,
  author={Fethallah, Hadjila and Ismail, Smahi Mohamed and Mohamed, Merzoug and Zeyneb, Torchane},
  booktitle={2017 International Conference on Mathematics and Information Technology (ICMIT)}, 
  title={An outranking model for web service discovery}, 
  year={2017},
  volume={},
  number={},
  pages={162-167},
  abstract={The web service discovery is the cornerstone of the service oriented architecture. To solve this issue, we usually leverage a matching model as well as the operation signature in order to minimize the residual errors. In this paper, we resolve this problem by combining a set of similarity measures through the use of a majority voting model called “outranking”. The Experimental evaluation confirms that this model performs better than the well-known Borda and all input similarity measures.},
  keywords={},
  doi={10.1109/MATHIT.2017.8259711},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{6901158,
  author={Mcheick, Hamid and Mohammad, Atif Farid},
  booktitle={2014 IEEE 27th Canadian Conference on Electrical and Computer Engineering (CCECE)}, 
  title={The evident use of evidence theory in big data analytics using cloud computing}, 
  year={2014},
  volume={},
  number={},
  pages={1-6},
  abstract={We live in the world of evidence. This research survey comprises of several research works and has an example implying dempster-shafer theory of evidence. We have witnessed several advances in computational performance, which have brought us the design and development of high-performance computing simulation tools. It is a fact that we have to account for uncertainty, while generating such high-performance systems using such simulation tools can fail in service performance predictions. We have seen that evidence theory is utilized to measure uncertainty in terms of the uncertain measures of belief and plausibility. It is also witnessed in computing community that Cloud computing has provided a flexible and scalable infrastructures to grow beyond contemporary borders to the organizations as wells the users everyday use of services. It also has increased availability of high-performance computing applications to small/ medium-sized businesses as well as academic users to work with. This paper also sheds light on Cloud computing and Service-Oriented Architecture.},
  keywords={},
  doi={10.1109/CCECE.2014.6901158},
  ISSN={0840-7789},
  month={May},}@INPROCEEDINGS{9217849,
  author={Gehrmann, Tobias and Duplys, Paul},
  booktitle={2020 23rd Euromicro Conference on Digital System Design (DSD)}, 
  title={Intrusion Detection for SOME/IP: Challenges and Opportunities}, 
  year={2020},
  volume={},
  number={},
  pages={583-587},
  abstract={Due to ever increasing complexity and the introduction of more and more connectivity, modern cars have an ever growing attack surface. To cope with this, intrusion detection should be used as an additional layer of defense complementing dedicated security measures. There is, however, very little published work on intrusion detection in cars, in particular for service-oriented communication. In this short paper, we first discuss selected challenges and opportunities for intrusion detection in SOME/IP, a standard protocol for service-oriented communication in cars. We then propose an architecture for a SOME/IP intrusion detection system, discuss its security properties and report preliminary experimental results.},
  keywords={},
  doi={10.1109/DSD51259.2020.00096},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8377634,
  author={Kumar, Lov and Sureka, Ashish},
  booktitle={2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)}, 
  title={An Empirical Analysis on Web Service Anti-pattern Detection Using a Machine Learning Framework}, 
  year={2018},
  volume={01},
  number={},
  pages={2-11},
  abstract={Web Services are application components characterised by interoperability, extensibility, distributed application development and service oriented architecture. A complex distributed application can be developed by combing several third-party web-services. Anti-patterns are counter-productive and poor design and practices. Web-services suffer from a multitude of anti-patterns such as God object Web service and Fine grained Web service. Our work is motivated by the need to build techniques for automatically detecting common web-services anti-patterns by static analysis of the source code implementing a web-service. Our approach is based on the premise that summary values of object oriented source code metrics computed at a web-service level can be used as a predictor for anti-patterns. We present an empirical analysis of 4 data sampling techniques to encounter the class imbalance problem, 5 feature ranking techniques to identify the most informative and relevant features and 8 machine learning algorithms for predicting 5 different types of anti-patterns on 226 real-world web-services across several domains. We conclude that it is possible to predict anti-patterns using source code metrics and a machine learning framework. Our analysis reveals that the best performing classification algorithm is Random Forest, best performing data sampling technique is SMOTE and the best performing feature ranking method is OneR.},
  keywords={},
  doi={10.1109/COMPSAC.2018.00010},
  ISSN={0730-3157},
  month={July},}@INPROCEEDINGS{9678708,
  author={Wang, Hanzhang and Wu, Zhengkai and Jiang, Huai and Huang, Yichao and Wang, Jiamu and Kopru, Selcuk and Xie, Tao},
  booktitle={2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={Groot: An Event-graph-based Approach for Root Cause Analysis in Industrial Settings}, 
  year={2021},
  volume={},
  number={},
  pages={419-429},
  abstract={For large-scale distributed systems, it is crucial to efficiently diagnose the root causes of incidents to maintain high system availability. The recent development of microservice architecture brings three major challenges (i.e., complexities of operation, system scale, and monitoring) to root cause analysis (RCA) in industrial settings. To tackle these challenges, in this paper, we present Groot, an event-graph-based approach for RCA. Groot constructs a real-time causality graph based on events that summarize various types of metrics, logs, and activities in the system under analysis. Moreover, to incorporate domain knowledge from site reliability engineering (SRE) engineers, Groot can be customized with user-defined events and domain-specific rules. Currently, Groot supports RCA among 5,000 real production services and is actively used by the SRE teams in eBay, a global e-commerce system serving more than 159 million active buyers per year. Over 15 months, we collect a data set containing labeled root causes of 952 real production incidents for evaluation. The evaluation results show that Groot is able to achieve 95% top-3 accuracy and 78% top-1 accuracy. To share our experience in deploying and adopting RCA in industrial settings, we conduct a survey to show that users of Groot find it helpful and easy to use. We also share the lessons learned from deploying and adopting Groot to solve RCA problems in production environments.},
  keywords={},
  doi={10.1109/ASE51524.2021.9678708},
  ISSN={2643-1572},
  month={Nov},}@ARTICLE{8726136,
  author={Jin, Hai and Li, Zhi and Zou, Deqing and Yuan, Bin},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={DSEOM: A Framework for Dynamic Security Evaluation and Optimization of MTD in Container-Based Cloud}, 
  year={2021},
  volume={18},
  number={3},
  pages={1125-1136},
  abstract={Due to the lightweight features, the combination of container technology and microservice architecture makes container-based cloud environment more efficient and agile than VM-based cloud environment. However, it also greatly amplifies the dynamism and complexity of the cloud environment and increases the uncertainty of security issues in the system concurrently. In this case, the effectiveness of defense mechanisms with fixed strategies would fluctuate as the updates occur in cloud environment. We refer this problem as effectiveness drift problem of defense mechanisms, which is particularly acute in the proactive defense mechanisms, such as moving target defense (MTD). To tackle this problem, we present DSEOM, a framework that can automatically perceive updates of container-based cloud environment, rapidly evaluate the effectiveness change of MTD and dynamically optimize MTD strategies. Specifically, we establish a multi-dimensional attack graphs model to formalize various complex attack scenarios. Combining with this model, we introduce the concept of betweenness centrality to effectively evaluate and optimize the implementation strategies of MTD. In addition, we present a series of security and performance metrics to quantify the effectiveness of MTD strategies in DSEOM. And we conduct extensive experiments to illustrate the existence of the effectiveness drift problem and demonstrate the usability and scalability of DSEOM.},
  keywords={},
  doi={10.1109/TDSC.2019.2916666},
  ISSN={1941-0018},
  month={May},}@ARTICLE{9036958,
  author={Herrera, José and Moltó, Germán},
  journal={IEEE Access}, 
  title={Toward Bio-Inspired Auto-Scaling Algorithms: An Elasticity Approach for Container Orchestration Platforms}, 
  year={2020},
  volume={8},
  number={},
  pages={52139-52150},
  abstract={The wide adoption of microservices architectures has introduced an unprecedented granularisation of computing that requires the coordinated execution of multiple containers with diverse lifetimes and with potentially different auto-scaling requirements. These applications are managed by means of container orchestration platforms and existing centralised approaches for auto-scaling face challenges when used for the timely adaptation of the elasticity required for the different application components. This paper studies the impact of integrating bio-inspired approaches for dynamic distributed auto-scaling on container orchestration platforms. With a focus on running self-managed containers, we compare alternative configuration options for the container life cycle. The performance of the proposed models is validated through simulations subjected to both synthetic and real-world workloads. Also, multiple scaling options are assessed with the purpose of identifying exceptional cases and improvement areas. Furthermore, a nontraditional metric for scaling measurement is introduced to substitute classic analytical approaches. We found out connections for two related worlds (biological systems and software container elasticity procedures) and we open a new research area in software containers that features potential self-guided container elasticity activities.},
  keywords={},
  doi={10.1109/ACCESS.2020.2980852},
  ISSN={2169-3536},
  month={},}

@INPROCEEDINGS{9251052,
  author={Kesim, Dominik and van Hoorn, André and Frank, Sebastian and Häussler, Matthias},
  booktitle={2020 IEEE 31st International Symposium on Software Reliability Engineering (ISSRE)}, 
  title={Identifying and Prioritizing Chaos Experiments by Using Established Risk Analysis Techniques}, 
  year={2020},
  volume={},
  number={},
  pages={229-240},
  abstract={The prevalence of microservice architectures and container orchestration technologies increases the complexity of assessing such systems' resilience. Chaos engineering is an emerging approach for resilience assessment by testing hypotheses after intentionally injecting faults into a distributed system and observing customer- and business-affecting metrics. As the number of potential risks within a complex system is high, the identification and prioritization of effective and efficient chaos experiments are non-trivial. In the scope of an industrial case study, this work investigates means to identify and prioritize chaos experiments by using established risk analysis techniques known from engineering safety-critical systems, namely i) Fault Tree Analysis, ii) Failure Mode and Effects Analysis, iii) and Computer Hazard and Operability Study. We conducted semi-structured interviews to elicit architectural information and resilience requirements of the case study system. The extracted knowledge was leveraged during the application of the risk analysis techniques. A subset of the identified and prioritized risks was used to create and execute chaos experiments. The risk analysis resulted in over 100 findings and revealed that the system is rather fragile as it comprises a high amount of single points of failure. The chaos experiments revealed further weaknesses for formerly unknown system behavior.},
  keywords={},
  doi={10.1109/ISSRE5003.2020.00030},
  ISSN={2332-6549},
  month={Oct},}@INPROCEEDINGS{8548336,
  author={Filipe, Ricardo and Correia, Jaime and Araujo, Filipe and Cardoso, Jorge},
  booktitle={2018 IEEE 17th International Symposium on Network Computing and Applications (NCA)}, 
  title={On Black-Box Monitoring Techniques for Multi-Component Services}, 
  year={2018},
  volume={},
  number={},
  pages={1-5},
  abstract={Despite the advantages of microservice and function-oriented architectures, there is an increase in complexity to monitor such highly dynamic systems. In this paper, we analyze two distinct methods to tackle the monitoring problem in a system with reduced instrumentation. Our goal is to understand the feasibility of such approach with one specific driver: simplicity. We aim to determine the extent to which it is possible to characterize the state of two generic tandem processes, using as little information as possible. To answer this question, we resorted to a simulation approach. Using a queue system, we simulated two services, that we could manipulate with distinct operation sets for each module. We used the total response time seen upstream of the system. Having this setup and metric, we applied two distinct methods to analyze the results. First, we used supervised machine learning algorithms to identify where the bottleneck is happening. Secondly, we used an exponential decomposition to identify the occupation in the two components in a more black-box fashion. Results show that both methodologies have their advantages and limitations. The separation of the signal more accurately identifies occupation in low occupied resources, but when a service is totally dominating the overall time, it lacks precision. The machine learning has a more stable error, but needs the training set. This study suggest that a black-box occupation approach with both techniques is possible and very useful.},
  keywords={},
  doi={10.1109/NCA.2018.8548336},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8076798,
  author={Sekar, K. R. and Sethuraman, J. and Srinivasan, Manav and Ravichandran, K.S. and Manikandan, R.},
  booktitle={2017 International Conference on Networks & Advances in Computational Technologies (NetACT)}, 
  title={Concurrent classifier based analysis for climate prediction using service oriented architecture}, 
  year={2017},
  volume={},
  number={},
  pages={370-375},
  abstract={Climate prediction is the essential one for the unforeseen world and reduces the uncertainty. Many research articles are available in bountiful in research arena. In this work the climate prediction will be obtained through concurrent classifiers, usually pronounced as ensemble classifier. Using `N' number of weather forecasting, web sites the training set well called semantic has formulated with a worthy attributes. The interface has created using the concept of Service oriented Architecture (SoA), so that to provide rooms for other applications can also integrated in the future trend. Using the climate prediction, what are the remedial measures to be taken and estimating their budget cost planning can be the one another good application to integrate with the existing application. The homogeneous property of the application can also be verified while integrating with the existing applications. SoA architecture needs umpteen number of services, to accomplish that factor, software components and web services are plays a important role. In the heterogeneous environment the weather forecasting is inevitable for the meter logical department to predict the season of the day.},
  keywords={},
  doi={10.1109/NETACT.2017.8076798},
  ISSN={},
  month={July},}@INPROCEEDINGS{7030325,
  author={Musavi, Maryam and Pasha, Mohammad Reza and Hamzehnia, Mahnaz and Hoseini, Mahyar},
  booktitle={2014 6th Conference on Information and Knowledge Technology (IKT)}, 
  title={A QoS-based fuzzy model for evaluation service quality parameters in service-oriented architecture}, 
  year={2014},
  volume={},
  number={},
  pages={15-19},
  abstract={Nowadays, service-oriented architecture is developed as a flexible architecture for developing dynamic systems. In consider to the importance of quality of service (QoS), measured parameters in this architectural services such as security, reliability and ... has a special place. Uncertainty of parameters affect service quality is considered as a key challenge in such environments. This requiring measurement of these parameters reveals a consistent and efficient manner. Since fuzzy logic is able to express the relative value of the credit in real-world concepts, this article proposes an approach on fuzzy logic to deal with these challenges and evaluation of quality of service.},
  keywords={},
  doi={10.1109/IKT.2014.7030325},
  ISSN={},
  month={May},}@INPROCEEDINGS{8987957,
  author={Kumar, T Sathis and Latha, K},
  booktitle={2019 International Conference on Smart Systems and Inventive Technology (ICSSIT)}, 
  title={Interoperability Performance in Adaptive Middleware for Enterprise Business Applications}, 
  year={2019},
  volume={},
  number={},
  pages={652-656},
  abstract={To improve the presentation of B2B (Business to Business) and B2C (Business to Consumer) regarding venture wide Service Oriented Architecture (SOA), we need middleware interoperability particularly with agent building to be specific CORBA (Common Object Request Broker Architecture) proposed by Object Management Group ORB programming named ORBeline. Unmistakable models for client server correspondences have just been created and executed specifically Handle Driven ORB (H-ORB), Forwarding ORB (F-ORB), and the Adaptive ORB (A- ORB). This paper concentrates how to improve the presentation of the interoperability in Adaptive ORB (A-ORB) as for client server collaboration in N-level engineering alongside multithreading condition. We have presented a strategy called linear discriminant interoperable support learning method and how it will in general be used for improving the presentation of interoperability is examined. The outcome gives the framework conduct especially the impact of message measure, between hub deferrals; torpidity and flexibility of solicitation/reaction administration times for the A-ORB engineering are broke down.},
  keywords={},
  doi={10.1109/ICSSIT46314.2019.8987957},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{7495852,
  author={Pinarer, Ozgun and Gripay, Yann and Servigne, Sylvie and Ozgovde, Atay},
  booktitle={2016 24th Signal Processing and Communication Application Conference (SIU)}, 
  title={Real-time multi-application based sensor flux management}, 
  year={2016},
  volume={},
  number={},
  pages={765-768},
  abstract={Smart building management systems become very popular research topics due to high energy consumption of buildings in developed countries. Proposed approaches in the literature commonly focus on smart building energy management systems to improve this high consumption and on network communications between deployed devices. However, these approaches are specialized for a single monitoring application, and adopt static wireless sensor device configurations. In this study, we focus on the energy and lifetime of the monitoring architecture itself. We consider a monitoring system as a set of applications that exploit sensor measures in real-time, where these applications are declaratively expressed as (service-oriented) continuous queries over sensor data streams. We tackle the optimization of interactions between application real-time requirements for data and wireless sensor devices that produces those data. In this context, we present a novel approach, an energy-aware dynamic sensor configuration mechanism for a sustainable declarative monitoring architecture that can support multiple applications. We first introduce formalization of application requirements and sensor configuration based on data acquisition/transmission and continuous stream queries. We then propose a self-adaptive energy-aware algorithm that dynamically generates optimized sensor configurations based on real-time query requirements. We also present a Smart-Service Stream-oriented Sensor Management (3SoSM) Gateway that optimizes sensor configurations and manages sensor data streams. Finally, we present a set of experiments we conducted with a wireless sensor network simulator and with a real Smart Building platform.},
  keywords={},
  doi={10.1109/SIU.2016.7495852},
  ISSN={},
  month={May},}@INPROCEEDINGS{9622915,
  author={Huang, Pei-Shu and Fahmi, Faisal and Wang, Feng-Jian and Yang, Hongji},
  booktitle={2021 8th International Conference on Dependable Systems and Their Applications (DSA)}, 
  title={Constructing A Creative Service Software with Semantic Web}, 
  year={2021},
  volume={},
  number={},
  pages={499-507},
  abstract={In software development, Service Oriented Architecture (SOA) and creative computing can be adopted to utilize multiple-domain knowledges to construct service software possessing creative properties, i.e., novel, useful, and surprising. In the past, several theoretical evaluation metrics have been proposed to measure creativity of a software system. However, a systematic practical method to construct creative service software is rarely considered in current researches. In this paper, we propose a model for creative service software development based on semantic web, which is applied in two phases: domain-creative requirement specification and semantic-based service design. The model can reduce communication work between domain experts and software engineers, improve traceability of the specifications, and improve machine readability during the generation of creativity. After the model of service design is validated for completeness and consistency, the creative service software is well-designed and can be implemented and reused effectively without losing of creativity.},
  keywords={},
  doi={10.1109/DSA52907.2021.00074},
  ISSN={2767-6684},
  month={Aug},}@INPROCEEDINGS{7829931,
  author={Garusinghe, Asanka and Perera, Indika and Meedeniya, Dulani},
  booktitle={2016 Sixteenth International Conference on Advances in ICT for Emerging Regions (ICTer)}, 
  title={Managing Service Level Agreements in Service Oriented Product Lines}, 
  year={2016},
  volume={},
  number={},
  pages={274-280},
  abstract={Service Oriented Architecture (SOA) and Software Product Line (SPL) have individually proven to be Software Engineering concepts, which are creating values for developing software systems. While SOA is being used for developing applications from an orchestration of web services, SPL has ability to prepare core sets of assets and manage with variable components. The combination of SOA and SPL has highlighted the term of Service Oriented Product Line (SOPL) which is setting up the application to manage common parts and reuse them without developing from scratch. It helps to manage service component bundles dynamically according to identified commonalities and variabilities. In this paper, we present our implementation approach of SOPL and manage Service Level Agreements (SLAs) in such environments by monitoring Quality of Service (QoS) attributes in bundles of web service components. The designing and developing service bundles for representing core sets of assets in SOPL are followed by the initial feature based analysis and identification of service components. Then, the managing SLAs is handled by detecting the deviation between actual and acceptable pre-defined QoS metrics values in previously analysed web service components via Web Service Level Agreement (WSLA) language specified templates.},
  keywords={},
  doi={10.1109/ICTER.2016.7829931},
  ISSN={2472-7598},
  month={Sep.},}@INPROCEEDINGS{8118424,
  author={Torkura, Kennedy A. and Sukmana, Muhammad I.H. and Cheng, Feng and Meinel, Christoph},
  booktitle={2017 IEEE International Conference on Smart Cloud (SmartCloud)}, 
  title={Leveraging Cloud Native Design Patterns for Security-as-a-Service Applications}, 
  year={2017},
  volume={},
  number={},
  pages={90-97},
  abstract={This paper discusses a new approach for designing and deploying Security-as-a-Service (SecaaS) applications using cloud native design patterns. Current SecaaS approaches do not efficiently handle the increasing threats to computer systems and applications. For example, requests for security assessments drastically increase after a high-risk security vulnerability is disclosed. In such scenarios, SecaaS applications are unable to dynamically scale to serve requests. A root cause of this challenge is employment of architectures not specifically fitted to cloud environments. Cloud native design patterns resolve this challenge by enabling certain properties e.g. massive scalability and resiliency via the combination of microservice patterns and cloud-focused design patterns. However adopting these patterns is a complex process, during which several security issues are introduced. In this work, we investigate these security issues, we redesign and deploy a monolithic SecaaS application using cloud native design patterns while considering appropriate, layered security counter-measures i.e. at the application and cloud networking layer. Our prototype implementation out-performs traditional, monolithic applications with an average Scanner Time of 6 minutes, without compromising security. Our approach can be employed for designing secure, scalable and performant SecaaS applications that effectively handle unexpected increase in security assessment requests.},
  keywords={},
  doi={10.1109/SmartCloud.2017.21},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9006025,
  author={De Iasio, Antonio and Furno, Angelo and Goglia, Lorenzo and Zimeo, Eugenio},
  booktitle={2019 IEEE International Conference on Big Data (Big Data)}, 
  title={A Microservices Platform for Monitoring and Analysis of IoT Traffic Data in Smart Cities}, 
  year={2019},
  volume={},
  number={},
  pages={5223-5232},
  abstract={The ongoing digitization of cities, enabled by the diffusion of interconnected sensors and devices, makes it possible to continuously collect and analyze huge streams of data at extremely large spatio-temporal scales and fine resolutions. These data can be used to monitor, detect and anticipate different kinds of infrastructure vulnerabilities and anomalies, as well as to implement more personalized services that could improve citizens' life. In this new context, full of opportunities, it is difficult to foresee and develop, in advance, the set of applications and services that can be potentially useful for administrators and citizens to solve the manifold compelling needs a city may have to face. Novel ICT paradigms and technologies can help designing agile, general-purpose smart city platforms aimed at supporting the collection and treatment of large-scale, multi-source (streams of) data and the development of novel applications that could fulfill diverse functional requirements under strict non-functional constraints. This paper presents the reference architecture, a prototype implementation and a city-scale case-study evaluation of PROMENADE, a platform that exploits IoT/Fog/Cloud paradigms, microservices and DevOps infrastructures to guarantee continuous development of robust and reliable applications for real-time monitoring and analysis of traffic data generated by IoT devices in large smart cities. The prototype has been evaluated in a case study concerning the quasi real-time detection of road networks vulnerabilities via centrality measures from on-line traffic conditions, emulated from off-line real datasets available for the city of Lyon, France.},
  keywords={},
  doi={10.1109/BigData47090.2019.9006025},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8089863,
  author={Serth, Sebastian and Podlesny, Nikolai and Bornstein, Marvin and Lindemann, Jan and Latt, Johanna and Selke, Jan and Schlosser, Rainer and Boissier, Martin and Uflacker, Matthias},
  booktitle={2017 IEEE 21st International Enterprise Distributed Object Computing Conference (EDOC)}, 
  title={An Interactive Platform to Simulate Dynamic Pricing Competition on Online Marketplaces}, 
  year={2017},
  volume={},
  number={},
  pages={61-66},
  abstract={E-commerce marketplaces are highly dynamic with constant competition. While this competition is challenging for many merchants, it also provides plenty of opportunities, e.g., by allowing them to automatically adjust prices in order to react to changing market situations. For practitioners however, testing automated pricing strategies is time-consuming and potentially hazardously when done in production. Researchers, on the other side, struggle to study how pricing strategies interact under heavy competition. As a consequence, we built an open continuous time framework to simulate dynamic pricing competition called Price Wars. The microservice-based architecture provides a scalable platform for large competitions with dozens of merchants and a large random stream of consumers. Our platform stores each event in a distributed log. This allows to provide different performance measures enabling users to compare profit and revenue of various repricing strategies in real-time. For researchers, price trajectories are shown which ease evaluating mutual price reactions of competing strategies. Furthermore, merchants can access historical marketplace data and apply machine learning. By providing a set of customizable, artificial merchants, users can easily simulate both simple rule-based strategies as well as sophisticated data-driven strategies using demand learning to optimize their pricing strategies.},
  keywords={},
  doi={10.1109/EDOC.2017.17},
  ISSN={2325-6362},
  month={Oct},}@INPROCEEDINGS{9209674,
  author={Li, Zhuo and Cao, Jiannong and Liu, Xiulong and Zhang, Jiuwu and Hu, Haoyuan and Yao, Didi},
  booktitle={2020 29th International Conference on Computer Communications and Networks (ICCCN)}, 
  title={A Self-Adaptive Bluetooth Indoor Localization System using LSTM-based Distance Estimator}, 
  year={2020},
  volume={},
  number={},
  pages={1-9},
  abstract={In recent years, there is an increasing demand for indoor localization services with the aim to locate people and objects inside buildings. However, localization accuracy is susceptible to inaccurate and high variant sensor measurements due to the unpredictable fluctuations of received wireless signals and the sensitivity of hardware devices. To address this issue, in this paper, we establish a new Bluetooth indoor localization system, whose architecture can be basically decomposed into two parts: the internet-of-things (IoT) framework and the localization module. Concretely, the IoT platform uses the state-of-the-art light weight Spring Boot microservice framework consisting of multi-layer structure. In the localization module, it follows the general process of trilateration but significantly distinguished from it. A set of measures are adopted to strengthen the system's robustness when obtained measurements cannot be fully trusted. Specifically, in the first place, rather than using conventional propagation model to predict the distance between Bluetooth transmitter and receiver, we design a bran-new LSTM-based distance estimator which can better depict the nonlinearity of attenuation characteristics of radio signal. Moreover, we also employ a series of self-adaptive mechanisms, including elastic radius intersecting, multiple weighted centroid localization and self-adaptive Kalman tracking, to make the system robust against inaccurate measurements and unpredictable sudden variation of received wireless signal. A bunch of tests are conducted in both ideal lab environment and Alibaba's large-scale warehouse, and experimental results show our indoor localization system outperforms the state-of-the-art benchmarks by a large margin in both localization accuracy and stability.},
  keywords={},
  doi={10.1109/ICCCN49398.2020.9209674},
  ISSN={2637-9430},
  month={Aug},}@INPROCEEDINGS{9470894,
  author={Andersen, Nicklas Sindlev and Chiarandini, Marco and Mauro, Jacopo},
  booktitle={2021 IEEE/ACM 3rd International Workshop on Software Engineering for Healthcare (SEH)}, 
  title={Wandering and getting lost: the architecture of an app activating local communities on dementia issues}, 
  year={2021},
  volume={},
  number={},
  pages={36-43},
  abstract={We describe the architecture of Sammen Om Demens (SOD), an application for portable devices aiming at helping persons with dementia when wandering and getting lost through the involvement of caregivers, family members, and ordinary citizens who volunteer.To enable the real-time detection of a person with dementia that has lost orientation, we transfer location data at high frequency from a frontend on the smartphone of a person with dementia to a backend system. The backend system must be able to cope with the high throughput data and carry out possibly heavy computations for the detection of anomalous behavior via artificial intelligence techniques. This sets certain performance and architectural requirements on the design of the backend.In the paper, we discuss our design and implementation choices for the backend of SOD that involve microservices and serverless services to achieve efficiency and scalability. We give evidence of the achieved goals by deploying the SOD backend on a public cloud and measuring the performance on simulated load tests.},
  keywords={},
  doi={10.1109/SEH52539.2021.00014},
  ISSN={},
  month={June},}@INPROCEEDINGS{9659766,
  author={&#x00DC;nl&#x00FC;, H&#x00FC;seyin and Hacalo&#x011F;lu, Tuna and Leblebici, Onur and Demir&#x00F6;rs, Onur},
  booktitle={2021 15th Turkish National Software Engineering Symposium (UYMS)}, 
  title={Effort Prediction for Microservices: A Case Study}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Software size measurement is critical as an input to perform important project management processes such as effort, cost and schedule estimation. Functional size measurement (FSM) methods are beneficial in terms of being applicable in the early phases of the software life cycle over functional requirements and providing a systematic and repeatable method. However, in agile organizations, it can be challenging to seperate measurement components of FSM methods from requirements in the early phases as the documentation is kept to a minimum compared to traditional methods such as the Waterfall Model and is detailed as the project steps. In addition, the existing FSM methods are not fully compatible with today&#x0027;s architectural structures, which are from being data-driven and to evolve into a behaviour-oriented structure. In this study, we performed a case study which includes a project developed with agile methods and using microservice-based architecture to compare the effectiveness of COSMIC FSM and event-based software size measurement. For this purpose, we measured the size of the project and created effort estimation models based on two methods. The measurers had difficulty in applying both methods due to the limited detail level of the requirements in the project. However, the event-based method was found to estimate effort with less error than the COSMIC FSM method.},
  keywords={},
  doi={10.1109/UYMS54260.2021.9659766},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{6945146,
  author={Triantafyllidis, Andreas K. and Koutkias, Vassilis G. and Chouvarda, Ioanna and Maglaveras, Nicos},
  booktitle={2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society}, 
  title={Development and usability of a personalized sensor-based system for pervasive healthcare}, 
  year={2014},
  volume={},
  number={},
  pages={6623-6626},
  abstract={Although a plethora of remote health monitoring systems have been proposed for chronic conditions, the challenge posed by the changing patient needs and the requirement for personalization in health monitoring to move beyond proprietary, difficult to extend, and unsustainable solutions still pertains. In this direction, we describe a mobile health system based on a smartphone, portable/wearable sensors for measuring the patient's physiological parameters, and back-end platforms for the health professionals to monitor the patient condition and configure monitoring plans in an individualized manner. A prototype system was developed based on a Service-oriented Architecture and integrating commercially available sensing devices. An experimental study has been conducted with 53 patients in order to investigate the usability of the proposed system. The patients were able to perform the majority of the target tasks successfully (Success Rate = 77%), while the perceived usability using the System Usability Scale (SUS) was found to be above average (SUS score = 73%), indicating that the patients overall perceived the system as both easy to use and useful.},
  keywords={},
  doi={10.1109/EMBC.2014.6945146},
  ISSN={1558-4615},
  month={Aug},}@INPROCEEDINGS{7013150,
  author={Wijayanto, Arie Wahyu and Suhardi},
  booktitle={2014 International Conference on ICT For Smart Society (ICISS)}, 
  title={Service oriented architecture design using SOMA for optimizing public satisfaction in government agency: Case study: BPN - National Land Authority of Indonesia}, 
  year={2014},
  volume={},
  number={},
  pages={49-55},
  abstract={Service oriented architecture (SOA) enables organizations to easily integrate systems, data, and business processes. Implementation of SOA solution in private sector is widely used and successfully proven to increase their profit. But there are different challenge in public sector which is not profit oriented and has different business model. In public sector, user satisfaction on government agencies is one of common indicator to measure quality of public service. This paper presents SOA solution for public sector using SOMA to conduct a service integration for optimizing public satisfaction. We also combined SWOT and Porter's Value Chain to support business modelling analysis. The result shows that there is a simplicity and feasibility for users to access the service after SOA integration, which improves user satisfaction.},
  keywords={},
  doi={10.1109/ICTSS.2014.7013150},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9074950,
  author={Dongre, Yashwant and Ingle, Rajesh},
  booktitle={2020 2nd International Conference on Innovative Mechanisms for Industry Applications (ICIMIA)}, 
  title={An Investigation of QoS Criteria for Optimal Services Selection in Composition}, 
  year={2020},
  volume={},
  number={},
  pages={705-710},
  abstract={Web service plays a vital role in the service industry to improve the web service applications and it is service oriented architecture. Due to which formation of composite service leads to non-optimal. Service selection task in the composition process is to select the best service for each candidate services out of available services which are a functionally similar but non-functional measures of services are different. This paper, presents the investigation of quality of service parameters and optimality criteria for services selection. The work in the paper provides the analysis of quality of service parameters used in existing works for services selection/composition. Through the survey and analysis it has been revealed that the response time, availability, and reliability are most common used quality of service attributes with minimum/maximum as optimality criteria. However, after analysis of these parameters, the work suggests to use these attributes to solve optimal services selection problem in composition.},
  keywords={},
  doi={10.1109/ICIMIA48430.2020.9074950},
  ISSN={},
  month={March},}@INPROCEEDINGS{8082679,
  author={Chaudhari, Nikhil and Bhadoria, Robin Singh and Prasad, Siddharth},
  booktitle={2016 8th International Conference on Computational Intelligence and Communication Networks (CICN)}, 
  title={Information Handling and Processing Using Enterprise Service Bus in Service-Oriented Architecture System}, 
  year={2016},
  volume={},
  number={},
  pages={418-421},
  abstract={Information is key factor in delivering service across networks. Messaging is important aspect in handing information using Enterprise Service Bus (ESB) in Service Oriented Architecture (SOA). Such information is generally passes and used as interaction parameters upon communication between two parties that could be carried out amongst multiple services. Integration between multiple application services could be strengthened by adopting this methodology which is important to handle web services over networks. ESB is messaging middleware framework that helps in designing and developing web services through which software intermediary could be possible. It is a kind of depletion layer that efficiently handles various overheads during communication and interaction between multiple application services. This paper details about issues related to application services with message handling and control. Testing and simulation has been carried out on - AdroitLogic UltraESB, WSO2 ESB and Red Hat JBoss Fuse ESBs. Several parameters like total and average message counts, overall bytes measure, overall message received and sent, processing time of messages, and memory allocation.},
  keywords={},
  doi={10.1109/CICN.2016.88},
  ISSN={2472-7555},
  month={Dec},}@INPROCEEDINGS{9441601,
  author={Sun, Yu and Mao, Shaojie and Huang, Songhua and Mao, Xiaobin},
  booktitle={2021 2nd Information Communication Technologies Conference (ICTC)}, 
  title={Load Balancing Method for Service Scheduling of Command Information System}, 
  year={2021},
  volume={},
  number={},
  pages={297-301},
  abstract={In order to satisfy the capability generation requirement of command information system, a load balancing method for service scheduling is studied. Considering that a work which will be finished by command information system based on service-oriented architecture is composed of several jobs, the paper analyzes the work completion process in detail. Then, a method to measure the load on a service which is scheduled to participate in a work is designed. On that basis, a load balancing mathematical model for service scheduling is established and a model solving algorithm that is based on greedy strategy and has polynomial time is put forward. Simulated experimental results show that the method proposed in this paper can allocate load to the services of command information system in a balanced way.},
  keywords={},
  doi={10.1109/ICTC51749.2021.9441601},
  ISSN={},
  month={May},}@INPROCEEDINGS{8029043,
  author={Su, Rui and Wan, Bo and Deng, Zhaoyun and Mei, Zheng and Mi, Weimin and Xie, Qiaoyun and Lin, Wenbin},
  booktitle={2017 36th Chinese Control Conference (CCC)}, 
  title={Research and application on integrated maintenance of smart substation and remote control center based on SOA}, 
  year={2017},
  volume={},
  number={},
  pages={10588-10593},
  abstract={The RCC-SS (Remote Control Center — Smart Substation) integrated maintenance technology based on SOA (Service Oriented Architecture) is proposed to solve the following problems: the complexity of debugging and maintenance when connecting the smart substation to the remote control center, the singularity of information exchange, and the difficulty to support advanced interactive application. By the construction of a wide-area distribution service system between the RCC (Remote Control Center) and the SS (Smart Substation), this proposal provides services in modelling, communication interface, real-time and historic data, and information verification as example. This RCC-SS system also unifies the modeling and the configuration, develops integrated maintenance tools, converts the substation SCD (Substation Configuration Description) file to CIM/E (Common Information Model / Efficient model exchange format) file and CIM/G (Common Information Model / Graphic exchange format) file used in remote control center, associates ID (Identification) between model and graphic files, imports all the information and stores in database, and lastly executes the automatic checking of the tele-measuring, tele-signaling and protection signaling. As a result, the smart substation's programmatic and automatic connection to the RCC is achieved, and the information exchange and business collaboration capabilities between the RCC and the SS is enhanced.},
  keywords={},
  doi={10.23919/ChiCC.2017.8029043},
  ISSN={1934-1768},
  month={July},}@INPROCEEDINGS{8862722,
  author={Ribin, Jones S.B and Kumar, N.},
  booktitle={2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI)}, 
  title={Precursory study on varieties of DDoS attacks and its implications in Cloud Systems}, 
  year={2019},
  volume={},
  number={},
  pages={1003-1008},
  abstract={Cloud Computing has emerged into an inevitable platform for computing services by effectively implementing Service Oriented Architecture (SOA) and Virtualization. However it is still vulnerable to traditional security threats and offers scope for innovative security attacks such as EDoS [1]. While it offers platform to generate innumerable Virtual components from a single physical component, it inadvertently provides wide spectrum of possibilities for distributed attacks. Moreover such attacks have adapted to cloud platform and have exploited various inherent vulnerabilities. In an unprecedented manner, they became unpredictable, evasive and challenging to Cloud Security measures. Therefore various versions of DDoS attack that targets the cloud platform have been extensively researched and narrated. The Cloud Security faces unprecedented challenges such as the Single-point-of-Failure occurs when a Cloud Supervisory Component or hypervisor fails due to a security breach. Moreover Cloud requirements often require being liberal to meet the Clients needs. This does not help the CSP to adapt traditional stringent security measures in Cloud System the reasons have been discussed in details.},
  keywords={},
  doi={10.1109/ICOEI.2019.8862722},
  ISSN={},
  month={April},}@INPROCEEDINGS{6824100,
  author={Alzaghoul, Esra and Bahsoon, Rami},
  booktitle={2014 23rd Australian Software Engineering Conference}, 
  title={Evaluating Technical Debt in Cloud-Based Architectures Using Real Options}, 
  year={2014},
  volume={},
  number={},
  pages={1-10},
  abstract={A Cloud-based Service-Oriented Architecture (CBSOA) is typically composed of web services, which are offered off the cloud marketplace. CB-SOA can improve its utility and add value to its composition by switching among its constituent services. We look at the option to defer the decision of substitution under uncertainty. We exploit Binomial Options to the formulation. We quantify the time-value of the architecture decisions of switching web services and technical debt they can imply on the structure. As CB-SOA are market-sensitive, dynamic and "volatile", the decision of deferral tends to be sensitive to these dynamics. Henceforth, the structural complexity of a CB-SOAcan change over time and so the technical debt as its constituent web services are modified, replaced, upgraded, etc. The method builds on Design Structure Matrix (DSM) and introduces time and complexity aware propagation cost metrics to assess the value of deferral decisions relative to changes in the structure. Architects of CB-SOA can use our method to assess the time value of deferring the decisions to switch web services relative to complexity, technical debt and value creation. We demonstrate the applicability of the method using an illustrative example.},
  keywords={},
  doi={10.1109/ASWEC.2014.27},
  ISSN={2377-5408},
  month={April},}@INPROCEEDINGS{8585730,
  author={OULMAHDI, Mohamed and CHASSOT, Christophe and VAN WAMBEKE, Nicolas},
  booktitle={2018 International Conference on Smart Communications in Network Technologies (SaCoNeT)}, 
  title={Extensible and Adaptive Architecture for an Evolutive Transport Layer}, 
  year={2018},
  volume={},
  number={},
  pages={102-107},
  abstract={The world of communications and networking knows and important evolution over the years. While this evolution is concretized by a deployment of many modern protocols at most of protocol layers, the Transport one continues to use old TCP and UDP protocols. This despite that an important number of modern protocols and mechanisms have been proposed. In this context, we study in this paper the obstacle of the deployment of new transport protocols and propose a new architecture to support the deployment and the adaptation of new Transport solutions. This was achieved by adding extensibility and adaptability capabilities using service-oriented and component-based paradigms. The architecture performances are studied at the end to measure the impact and the benefits of the new architecture comparing to classical Transport protocol.},
  keywords={},
  doi={10.1109/SaCoNeT.2018.8585730},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{7037678,
  author={Hecht, Geoffrey and Jose-Scheidt, Benjamin and De Figueiredo, Clement and Moha, Naouel and Khomh, Foutse},
  booktitle={2014 IEEE 6th International Conference on Cloud Computing Technology and Science}, 
  title={An Empirical Study of the Impact of Cloud Patterns on Quality of Service (QoS)}, 
  year={2014},
  volume={},
  number={},
  pages={278-283},
  abstract={Cloud patterns are described as good solutions to recurring design problems in a cloud context. These patterns are often inherited from Service Oriented Architectures or Object Oriented Architectures where they are considered good practices. However, there is a lack of studies that assess the benefits of these patterns for cloud applications. In this paper, we conduct an empirical study on a Restful application deployed in the cloud, to investigate the individual and the combined impact of three cloud patterns (i.e., Local Database proxy, Local Sharding-Based Router and Priority Queue Patterns) on Quality of Service (QoS). We measure the QoS using the application's response time, average, and maximum number of requests processed per seconds. Results show that cloud patterns doesn't always improve the response time of an application. In the case of the Local Database proxy pattern, the choice of algorithm used to route requests has an impact on response time, as well as the average and maximum number of requests processed per second. Combinations of patterns can significantly affect the QoS of applications. Developers and software architects can make use of these results to guide their design decisions.},
  keywords={},
  doi={10.1109/CloudCom.2014.141},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{7509323,
  author={Pulparambil, Supriya and Baghdadi, Youcef},
  booktitle={2016 IEEE Students' Conference on Electrical, Electronics and Computer Science (SCEECS)}, 
  title={SOA maturity model a frame of reference}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={Service Oriented Architecture (SOA) is an architectural style that supports service orientation. In reality, SOA is much more than architecture. SOA adoption is prerequisite for organization to excel their service deliveries, as the delivery platforms are shifting to mobile, cloud and social media. A maturity model is a tool to accelerate enterprise SOA adoption, however it depends on how it should be applied. This paper presents a literature review of existing maturity models and proposes 5 major aspects that a maturity model has to address to improve SOA practices of an enterprise. A maturity model can be used as: (i) a roadmap for SOA adoption, (ii) a reference guide for SOA adoption, (iii) a tool to gauge maturity of process execution, (iv) a tool to measure the effectiveness of SOA motivations, and (v) a review tool for governance framework. This paper also sheds light on how SOA maturity assessment can be modeled. A model for SOA process execution maturity and perspective maturity assessment has been proposed along with a framework to include SOA scope of adoption.},
  keywords={},
  doi={10.1109/SCEECS.2016.7509323},
  ISSN={},
  month={March},}@INPROCEEDINGS{8560743,
  author={Marmsoler, Diego},
  booktitle={2018 International Symposium on Theoretical Aspects of Software Engineering (TASE)}, 
  title={On Syntactic and Semantic Dependencies in Service-Oriented Architectures}, 
  year={2018},
  volume={},
  number={},
  pages={132-137},
  abstract={In service oriented architectures, components provide services on their output ports and consume services from other components on their input ports. Thereby, a component is said to depend on another component if the former consumes a service provided by the latter. This notion of dependency (which we call syntactic dependency) is used by many architecture analysis tools as a measure for system maintainability. With this paper, we introduce a weaker notion of dependency, still sufficient, however, to guarantee semantic independence between components. Thereby, we discover the concepts of weak and strong semantic dependency and prove that strong semantic dependency indeed implies syntactic dependency. Our alternative notion of dependency paves the way to more precise dependency analysis tools. Moreover, our results about the different types of dependencies can be used for the verification of semantic independence.},
  keywords={},
  doi={10.1109/TASE.2018.00025},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9402637,
  author={Yang, Meixia and Yang, JingJing and Xiao, Zhe and Huang, Ming},
  booktitle={2021 International Conference on Computer Communication and Informatics (ICCCI)}, 
  title={A modular spectrum sensing node for Resources-Oriented Radio Monitoring}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  abstract={The existing radio monitoring practices suffer from two critical limitations: 1) current practices have been limited to isolated measuring and are unable to integrate data from different spectrum sensors; 2) these practices still require human operators to interpret signals, which prevent automated and intelligent processing. To address these limitations, we present a novel design of a spectrum sensing node based on the Representational State Transfer (REST) architecture. The spectrum sensing node exploits the REST architecture to integrate resources (data) into the web and to make it effortless to collect and share resources by exposing resources as service-oriented Web APIs. In addition, the spectrum sensing node introduces standardization and automation to radio monitoring. We outline the procedures of spectrum analysis and signal analysis for radio monitoring. Furthermore, to automate spectrum sensing node functionalities, we implement spectrum analysis and signal analysis using machine learning methods, which reliably extract and learn intrinsic features of complex data. The spectrum sensing node has been packaged and deployed in Honghe Hani and Yi Autonomous Prefecture of China for radio spectrum management. We describe and discuss our implemented prototype of the spectrum sensing node to demonstrate its practical advantages.},
  keywords={},
  doi={10.1109/ICCCI50826.2021.9402637},
  ISSN={2329-7190},
  month={Jan},}@ARTICLE{6530636,
  author={Li, Shancang and Zhao, Shanshan and Wang, Xinheng and Zhang, Kewang and Li, Ling},
  journal={IEEE Systems Journal}, 
  title={Adaptive and Secure Load-Balancing Routing Protocol for Service-Oriented Wireless Sensor Networks}, 
  year={2014},
  volume={8},
  number={3},
  pages={858-867},
  abstract={Service-oriented architectures for wireless sensor networks (WSNs) have been proposed to provide an integrated platform, where new applications can be rapidly developed through flexible service composition. In WSNs, the existing multipath routing schemes have demonstrated the effectiveness of traffic distribution over multipaths to fulfill the quality of service requirements of applications. However, the failure of links might significantly affect the transmission performance, scalability, reliability, and security of WSNs. Thus, by considering the reliability, congestion control, and security for multipath, it is desirable to design a reliable and service-driven routing scheme to provide efficient and failure-tolerant routing scheme. In this paper, an evaluation metric, path vacant ratio, is proposed to evaluate and then find a set of link-disjoint paths from all available paths. A congestion control and load-balancing algorithm that can adaptively adjust the load over multipaths is proposed. A threshold sharing algorithm is applied to split the packets into multiple segments that will be delivered via multipaths to the destination depending on the path vacant ratio. Simulations demonstrate the performance of the adaptive and secure load-balance routing scheme.},
  keywords={},
  doi={10.1109/JSYST.2013.2260626},
  ISSN={1937-9234},
  month={Sep.},}@INPROCEEDINGS{6930517,
  author={Yaqub, Edwin and Yahyapour, Ramin and Wieder, Philipp and Kotsokalis, Constantinos and Lu, Kuan and Jehangiri, Ali Imran},
  booktitle={2014 IEEE International Conference on Services Computing}, 
  title={Optimal Negotiation of Service Level Agreements for Cloud-Based Services through Autonomous Agents}, 
  year={2014},
  volume={},
  number={},
  pages={59-66},
  abstract={Cloud-based services have become a cornerstone of today's IT. The self-service feature inherent in Cloud systems allows customers to play a greater role in service procurement. However, this restricts the value propositions and Service Level Agreements (SLAs) that Cloud providers offer because Quality of Service (QoS) and Non Functional Property (NFP) requirements vary from customer to customer. In feature-rich SLA templates, the contract space gets large, objectives are confidential and preferences over QoS and NFP often conflict between providers and customers. Hence, an SLA-gap exists between the two and contemporary providers bind their offerings to the inflexible take-it-or-leave-it SLAs. In this work, we address this problem by presenting a robust and computationally inexpensive negotiation strategy, using which agents can efficiently create near-optimal SLAs under time constraints. Experimental evaluations validate that our strategy performs at par with state of the art learning and non-learning strategies against a variety of metrics including utility, social welfare, social utility and the Pareto-optimal bids. This enables a dynamic SLA negotiation mechanism on top of our OpenShift (PaaS) based Cloud system designed using Service Oriented Cloud Computing Infrastructure (SOCCI) architecture. Negotiated procurement of services is shown to improve satisfaction of participants and reducing the SLA-gap.},
  keywords={},
  doi={10.1109/SCC.2014.17},
  ISSN={},
  month={June},}@ARTICLE{8119814,
  author={Wang, Chao and Gong, Lei and Li, Xi and Yu, Qi and Wang, Aili and Hung, Patrick and Zhou, Xuehai},
  journal={IEEE Transactions on Services Computing}, 
  title={SOLAR: Services-Oriented Deep Learning Architectures-Deep Learning as a Service}, 
  year={2021},
  volume={14},
  number={1},
  pages={262-273},
  abstract={Deep learning has been an emerging field of machine learning during past decades. However, the diversity and large scale data size have posed significant challenge to construct a flexible and high performance implementations of deep learning neural networks. In order to improve the performance as well to maintain the scalability, in this paper we present SOLAR, a services-oriented deep learning architecture using various accelerators like GPU and FPGA. SOLAR provides a uniform programming model to users so that the hardware implementation and the scheduling is invisible to the programmers. At runtime, the services can be executed either on the software processors or the hardware accelerators. To leverage the trade-offs between the metrics among performance, power, energy, and efficiency, we present a multitarget design space exploration. Experimental results on the real state-of-the-art FPGA board demonstrate that the SOLAR is able to provide a ubiquitous framework for diverse applications without increasing the burden of the programmers. Moreover, the speedup of the GPU and FPGA hardware accelerator in SOLAR can achieve significant speedup comparing to the conventional Intel i5 processors with great scalability.},
  keywords={},
  doi={10.1109/TSC.2017.2777478},
  ISSN={1939-1374},
  month={Jan},}@INPROCEEDINGS{7558028,
  author={Li, Zhinan and Yang, Xiaodong},
  booktitle={2016 IEEE International Conference on Web Services (ICWS)}, 
  title={A Reliability-Oriented Web Service Discovery Scheme with Cross-Layer Design in MANET}, 
  year={2016},
  volume={},
  number={},
  pages={404-411},
  abstract={Web service technologies are playing an increasingly important role in service-oriented architecture design and application convergence over Mobile ad hoc networks (MANET). Due to the decentralized administration and dynamic wireless connectivity problems, accomplishing reliable service discovery in MANET faces a large number of challenges. In order to relieve the communication inefficiency among service providers and clients caused mainly by the unpredictable node mobility, this paper proposes a cross-layer service discovery scheme which enables improved network efficiency and reduced resource consumption. Firstly a network-layer based underlay framework is presented. It specifically establishes a reliability-oriented source routing mechanism which is equipped with a novel reliability-maximized path selection metric and a backup path support fast route recovery strategy. The cross-layer design is prudentially realized by piggybacking service discovery procedures on the reliability enhanced underlay routing mechanism. Simulation analysis verifies that the proposed scheme improves service discovery reliability by achieving low rediscovery frequency, and guarantees high network efficiency by providing reduced service discovery delay and control overhead.},
  keywords={},
  doi={10.1109/ICWS.2016.59},
  ISSN={},
  month={June},}@ARTICLE{9274356,
  author={Chiu, Kai-Cheng and Liu, Chien-Chang and Chou, Li-Der},
  journal={IEEE Access}, 
  title={CAPC: Packet-Based Network Service Classifier With Convolutional Autoencoder}, 
  year={2020},
  volume={8},
  number={},
  pages={218081-218094},
  abstract={The Internet has been evolving from a traditional mechanism to a modern service-oriented architecture, such as quality-of-service (QoS) policies, to meet users’ various requirements for high service quality. An instant and effective network traffic classification method is indispensable to identify network services to enforce QoS policies on the corresponding service. Network managers can easily flexibly deploy traffic classification modules and configure the network policies with the help of the emerging software-defined networking. However, most existing traffic classification solutions, such as port-based methods or deep packet inspection, cannot handle real-time and encrypted traffic classification. In this research, a Convolutional Autoencoder Packet Classifier (CAPC) has been proposed to immediately classify incoming packets in fine-grained and coarse-grained manners, that is, classifying a service to a single application and a rough genre, respectively. The CAPC is a packet-based deep learning model consisting of a 1D convolutional neural network and an autoencoder, which can handle dynamic-port and encrypted traffic and even cluster similar applications. This classifier is verified on not only the private self-captured traffic but also a public VPN dataset to demonstrate its performance. Moreover, the CAPC classifies different types of service traffic with an accuracy of over 99.9% on the private dataset of 16 services and over 97% on the public dataset of 24 services, thereby outperforming other deep learning classifiers. Experimental results also show other performance metrics, including stability, average precision, and recall and the highest F1-score values of 15 and 18 services on the private and public datasets, respectively.},
  keywords={},
  doi={10.1109/ACCESS.2020.3041806},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9529361,
  author={Huang, Pei-Shu and Fahmi, Faisal and Wang, Feng-Jian},
  booktitle={2021 IEEE 45th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={A Model to Helping the Construction of Creative Service-Based Software}, 
  year={2021},
  volume={},
  number={},
  pages={1235-1242},
  abstract={With the advent of the Service Oriented Architecture (SOA) in system design, various domain knowledges are included in a service-based application, such as the design of Artificial Intelligence (AI) or augmented reality (AR) systems. While merging one or multiple domains into computation systems, the computation systems can be widely applied in various domain usages with novelty, useful, and surprising properties, which are defined as systems of creative computing. In creative computing, several theoretical evaluation metrics and verification approaches have been proposed for system design in several domains. However, a solid practical design environment for creative service-based systems is rarely considered in current researches. In this paper, we propose a model for creative service software development based on semantic web, which is applied in two phases: (1) requirement specification and (2) service design. In order to bridge the knowledge gap between domain experts and software engineers, and provide a machine-readable format for creative computing, two sub-models, Requirement Specification and Service Structure Models, are constructed in both phases, sequentially. After the latter sub-model is validated, the creative service software is well-constructed based on the services definition and composition represented by the model.},
  keywords={},
  doi={10.1109/COMPSAC51774.2021.00171},
  ISSN={0730-3157},
  month={July},}@INPROCEEDINGS{7009432,
  author={Mishra, Siba and Kumar, Chiranjeev},
  booktitle={The 2014 2nd International Conference on Systems and Informatics (ICSAI 2014)}, 
  title={Estimating development size and effort of business process service-oriented architecture applications}, 
  year={2014},
  volume={},
  number={},
  pages={1006-1011},
  abstract={Service-oriented Architecture (SOA) is adopted by many industrial and business organizations, as an efficient means for designing, developing and integrating enterprise business processes applications. With the built of Web Services, the developed business processes can be easily combined to achieve a composite business solution. Generally, any business applications are mixture of processes and some tasks corresponding to the processes. In the planning phase of software project management, estimation of development effort is very critical and crucial for software/business organizations. Having an accurate effort estimate guarantees the managers that the projects are completed within time and budget. So, estimation techniques/models need to be very efficient and should highlights all important cost drivers. The estimation of development effort for business processes primarily depends on the number of processes and it's associated tasks. The development effort of business applications primarily depends on the size of integrated applications. In this paper, some metrics for predicting the size of integrated business process SOA applications have been proposed. After estimating size, the development effort calculated by using the popular COCOMO model. A comparison of various performance evaluation criterion for assessing the accuracy of proposed model has been computed and shown.},
  keywords={},
  doi={10.1109/ICSAI.2014.7009432},
  ISSN={},
  month={Nov},}@ARTICLE{7103341,
  author={Anta, Antonio Fernández and Gramoli, Vincent and Jiménez, Ernesto and Kermarrec, Anne-Marie and Raynal, Michel},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Distributed Slicing in Dynamic Systems}, 
  year={2016},
  volume={27},
  number={4},
  pages={1030-1043},
  abstract={Peer to peer (P2P) systems have moved from application specific architectures to a generic service oriented design philosophy. This raised interesting problems in connection with providing useful P2P middleware services capable of dealing with resource assignment and management in a large-scale, heterogeneous and unreliable environment. The slicing problem consists of partitioning a P2P network into $k$  groups (slices) of a given portion of the network nodes that share similar resource values. As the network is large and dynamic this partitioning is continuously updated without any node knowing the network size. In this paper, we propose the first algorithm to solve the slicing problem. We introduce the metric of slice disorder and show that the existing ordering algorithm cannot nullify this disorder. We propose a new algorithm that speeds up the existing ordering algorithm but that suffers from the same inaccuracy. Then, we propose another algorithm based on ranking that is provably convergent under reasonable assumptions. In particular, we notice experimentally that ordering algorithms suffer from resource-correlated churn while the ranking algorithm can cope with it. These algorithms are proved viable theoretically and experimentally.},
  keywords={},
  doi={10.1109/TPDS.2015.2430856},
  ISSN={1558-2183},
  month={April},}@INPROCEEDINGS{8618153,
  author={Aljawawdeh, Hamzeh and Odeh, Mohammed and Simons, Christopher and Lebzo, Nawras},
  booktitle={2018 1st International Conference on Cancer Care Informatics (CCI)}, 
  title={A Metaheuristic Search Framework to Derive Cancer Care Services from Business Process Models}, 
  year={2018},
  volume={},
  number={},
  pages={142-151},
  abstract={Cancer Care involves not only handling patients' medical or physical needs but also other services to facilitate patient needs which are underpinned by appropriate software systems that assist in patient care processes. The Service-Oriented Architecture (SOA) model of computing has become widely adopted and can provide efficient and agile business solutions in the face of rapid changes to business requirements. Instead of adopting a more traditional way of building an IT system for Cancer Care by rigidly piecing together a collection of hardware, software and networking, SOA offers the opportunity to build the IT systems in an increasingly flexible and reconfigurable way. However, current service identification methods can suffer from shortcomings such as a lack of computational support, and not being able to address all the necessary activities of the service identification. To address these shortcomings, this paper presents a comprehensive metaheuristic search framework for deriving SOA-based services applied to Cancer Care business process models. This framework is evaluated using both quantitative and qualitative methods with the help of domain experts at King Hussein Cancer Centre (KHCC), Jordan. Evaluation by domain experts confirmed that the resulting services are feasible (i.e., valid services that can be practically applied for real-life projects) that the domain experts might not have arrived at manually. Statistical analysis shows candidate services produced by the search-based framework are superior to the services produced manually by domain experts at KHCC with respect to metrics for coupling and cohesion.},
  keywords={},
  doi={10.1109/CANCERCARE.2018.8618153},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{7077302,
  author={Kim, Yukyong and Choi, Jong-Seok and Shin, Yongtae},
  booktitle={2014 4th World Congress on Information and Communication Technologies (WICT 2014)}, 
  title={A decision model for optimizing the service portfolio in SOA governance}, 
  year={2014},
  volume={},
  number={},
  pages={57-62},
  abstract={Effective service-oriented architecture (SOA) governance requires an appropriate process in place by which services described by a service model become candidates to enter the service portfolio. This is a planning for the appropriate identified services to create business agility and maximize reuse. Not all services in the service model can be realized in the form of IT solutions, so if our intended use of the service portfolio is to drive IT development planning, we must first decide which services are potentially realizable and which services are not. In this paper, we present a decision model to evaluate the services based on the proposed metrics. Comparing the relative value of each service with its development or maintenance cost should make the prioritization. The decision model is useful to support an approach to identifying the optimum portfolio of services based on the prioritization of business needs, followed by an estimation of the technical feasibility for each candidate service.},
  keywords={},
  doi={10.1109/WICT.2014.7077302},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8030635,
  author={Azarmi, Mehdi and Bhargava, Bharat},
  booktitle={2017 IEEE 10th International Conference on Cloud Computing (CLOUD)}, 
  title={An End-to-End Dynamic Trust Framework for Service-Oriented Architecture}, 
  year={2017},
  volume={},
  number={},
  pages={568-575},
  abstract={Service-oriented architecture (SOA) is an architectural paradigm that advocates composition of loosely-coupled services in order to construct more complex applications. The agility and complexity of modern web services on one hand and the arbitrary interconnections among them on the other hand, make it difficult to maintain a sustainable trustworthiness in long-running SOA-based applications. Moreover, the chain of participating services in a specific SOA invocation may not be visible to the service consumers, which leads to a lack of accountability. To address these challenges in SOA, we propose the following contributions. First, we design a new dynamic and flexible trust model based on graph abstraction that uses multiple trust strategies to calculate trust across SOA. This trust model keeps track of three trust metrics: individual service trust, session trust, and composite trust. We further design a trust engine component that implements the proposed trust model and that continuously maintains the quantitative end-to-end trust based on processing actual execution of services. Second, to prove the practicality and usefulness of the proposed framework, we have implemented an adaptive and secure service composition engine (ASSC) which takes advantage of an efficient algorithm to generate service compositions with near-optimal trustworthiness under predefined QoS constraints. Finally, we have developed a tool that is able to automatically deploy SOA testbeds from arbitrary directed acyclic graphs (created in the GUI). This tool enables the researcher to study the dynamics of new trust algorithms and strategies under different scenarios (e.g., arbitrary SOA topologies and attacks). We have extensively studied the effectiveness and performance of the proposed solutions using testbeds in the Amazon EC2 cloud.},
  keywords={},
  doi={10.1109/CLOUD.2017.78},
  ISSN={2159-6190},
  month={June},}@INPROCEEDINGS{9592453,
  author={Fahmi, Faisal and Huang, Pei-Shu and Wang, Feng-Jian and Yang, Hongji},
  booktitle={2021 IEEE International Conference on Services Computing (SCC)}, 
  title={Constructing a Creative Software with Services}, 
  year={2021},
  volume={},
  number={},
  pages={134-144},
  abstract={Service Oriented Architecture (SOA) and Creative Computing can be applied to construct a creative service software by utilizing various domain knowledges, where the software contains a solution that not only effective, but also novel, useful and surprising. In creative computing, several theoretical evaluation metrics and verification approaches have been proposed for system design in several domains. However, a solid methodology for development of creative service software is rarely considered in current researches. In this paper, we propose a method composed of requirement specification and service design phases to develop creative software with SOA, where each phase applies a specification model based on semantic web. Inside the development, the models containing XML structures and the associated directed graphs are constructed in both phases to improve machine readability for automatic information processing in creative computing and reduce communication work among development participants with different knowledges, respectively. The graph models defined also can improve the traceability of the specifications and support machine processing. After the model resulted in the second phase is validated for consistency and completeness, the creative service software is well-constructed and can be implemented and reused effectively. Besides, a real example is adopted to demonstrate the workings of the method.},
  keywords={},
  doi={10.1109/SCC53864.2021.00026},
  ISSN={2474-2473},
  month={Sep.},}@INPROCEEDINGS{7521492,
  author={Gomes, Luiza Barcelos Gualberto and Farias, Pedro Porfírio Muniz and Bessa Albuquerque, Adriano and Herden, Adriana},
  booktitle={2016 11th Iberian Conference on Information Systems and Technologies (CISTI)}, 
  title={Software measure based on BPMN activity points}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={BPMN usage has been extended beyond the workflow systems and service-oriented architecture. Development methodologies have been proposed using BPMN to describe use cases, to specify the activities flow that forms each scenario of general purpose systems and business process execution with web services. This article proposes a metric to estimate software size, called BPMN Activity Points based on activities counting from three different perspectives, in which these scores are increasingly detailed and refined.},
  keywords={},
  doi={10.1109/CISTI.2016.7521492},
  ISSN={},
  month={June},}@ARTICLE{8288619,
  author={Akbar, Adnan and Kousiouris, George and Pervaiz, Haris and Sancho, Juan and Ta-Shma, Paula and Carrez, Francois and Moessner, Klaus},
  journal={IEEE Access}, 
  title={Real-Time Probabilistic Data Fusion for Large-Scale IoT Applications}, 
  year={2018},
  volume={6},
  number={},
  pages={10015-10027},
  abstract={Internet of Things (IoT) data analytics is underpinning numerous applications, however, the task is still challenging predominantly due to heterogeneous IoT data streams, unreliable networks, and ever increasing size of the data. In this context, we propose a two-layer architecture for analyzing IoT data. The first layer provides a generic interface using a service oriented gateway to ingest data from multiple interfaces and IoT systems, store it in a scalable manner and analyze it in real-time to extract high-level events; whereas second layer is responsible for probabilistic fusion of these high-level events. In the second layer, we extend state-of-the-art event processing using Bayesian networks in order to take uncertainty into account while detecting complex events. We implement our proposed solution using open source components optimized for large-scale applications. We demonstrate our solution on real-world use-case in the domain of intelligent transportation system where we analyzed traffic, weather, and social media data streams from Madrid city in order to predict probability of congestion in real-time. The performance of the system is evaluated qualitatively using a web-interface where traffic administrators can provide the feedback about the quality of predictions and quantitatively using F-measure with an accuracy of over 80%.},
  keywords={},
  doi={10.1109/ACCESS.2018.2804623},
  ISSN={2169-3536},
  month={},}@ARTICLE{8643377,
  author={Macis, Silvia and Loi, Daniela and Ulgheri, Andrea and Pani, Danilo and Solinas, Giuliana and Manna, Serena La and Cestone, Vincenzo and Guerri, Davide and Raffo, Luigi},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Design and Usability Assessment of a Multi-Device SOA-Based Telecare Framework for the Elderly}, 
  year={2020},
  volume={24},
  number={1},
  pages={268-279},
  abstract={Telemonitoring is a branch of telehealth that aims at remotely monitoring vital signs, which is important for chronically ill patients and the elderly living alone. The available standalone devices and applications for the self-monitoring of health parameters largely suffer from interoperability problems; meanwhile, telemonitoring medical devices are expensive, self-contained, and are not integrated into user-friendly technological platforms for the end user. This paper presents the technical aspects and usability assessment of the telemonitoring features of the HEREiAM platform, which supports heterogeneous information technology systems. By exploiting a service-oriented architecture, the measured parameters collected by off-the-shelf Bluetooth medical devices are sent as XML documents to a private cloud that implements an interoperable health service infrastructure, which is compliant with the most recent healthcare standards and security protocols. This Android-based system is designed to be accessible both via TV and portable devices, and includes other utilities designed to support the elderly living alone. Four usability assessment sessions with quality-validated questionnaires were performed to accurately understand the ease of use, usefulness, acceptance, and quality of the proposed system. The results reveal that our system achieved very high usability scores even at its first use, and the scores did not significantly change over time during a field trial that lasted for four months, reinforcing the idea of an intuitive design. At the end of such a trial, the user-experience questionnaire achieved excellent scores in all aspects with respect to the benchmark. Good results were also reported by general practitioners who assessed the quality of their remote interfaces for telemonitoring.},
  keywords={},
  doi={10.1109/JBHI.2019.2894552},
  ISSN={2168-2208},
  month={Jan},}@INPROCEEDINGS{7357508,
  author={Manso, Marco and Alcaraz Calero, Jose Maria and Barz, Christoph and Bloebaum, Trude Hafsøe and Chan, Kevin and Jansen, Norman and Johnsen, Frank Trethan and Markarian, Garik and Meiler, Peter-Paul and Owens, Ian and Sliwa, Joanna and Wang, Qi},
  booktitle={MILCOM 2015 - 2015 IEEE Military Communications Conference}, 
  title={SOA and Wireless Mobile Networks in the tactical domain: Results from experiments}, 
  year={2015},
  volume={},
  number={},
  pages={593-598},
  abstract={The NATO research task group IST-118 titled “SOA recommendations for disadvantaged grids in the tactical domain” is addressing the challenge of implementing the Service Oriented Architecture (SOA) paradigm at the tactical level by providing guidance and best practices in the form of a Tactical SOA Profile. The group will conduct identification and feasibility assessments of possible improvements of the Tactical SOA Profile, over a series of live and emulated experiments. In this paper, we describe our first experiments in applying SOA Web services to mobile nodes that are connected using Wireless Broadband Mobile Networks (WBMN) in the tactical domain. The experiments involved components provided by various nations, including radio hardware equipment, the Publish/Subscribe messaging service and NATO Friendly Force Information (NFFI) (as our functional service). We measured the system performance at service and physical (radio) levels in the presence of network disruption. We conclude by presenting the results of the experiments and a view of future work.},
  keywords={},
  doi={10.1109/MILCOM.2015.7357508},
  ISSN={},
  month={Oct},}@ARTICLE{7192623,
  author={Trang, Mai Xuan and Murakami, Yohei and Ishida, Toru},
  journal={IEEE Transactions on Services Computing}, 
  title={Policy-Aware Service Composition: Predicting Parallel Execution Performance of Composite Services}, 
  year={2018},
  volume={11},
  number={4},
  pages={602-615},
  abstract={With the increasing volume of data to be analysed, one of the challenges in Service Oriented Architecture (SOA) is to make web services efficient in processing large-scale data. Parallel execution and cloud technologies are the keys to speed-up the service invocation. In SOA, service providers typically employ policies to limit parallel execution of the services based on arbitrary decisions. In order to attain optimal performance improvement, users need to adapt to the services policies. A composite service is a combination of several atomic services provided by various providers. To use parallel execution for greater composite service efficiency, the degree of parallelism (DOP) of the composite services need to be optimized by considering the policies of all atomic services. We propose a model that embeds service policies into formulae to calculate composite service performance. From the calculation, we predict the optimal DOP for the composite service, where it attains the best performance. Extensive experiments are conducted on real-world translation services. We use several measures such as mean prediction error (MPE), mean absolute deviation (MAD) and tracking signal (TS) to evaluate our model. The analysis results show that our proposed model has good prediction accuracy in identifying optimal DOPs for composite services.},
  keywords={},
  doi={10.1109/TSC.2015.2467330},
  ISSN={1939-1374},
  month={July},}@INPROCEEDINGS{8599786,
  author={Johnsen, Frank T. and Landmark, Lars and Hauge, Mariann and Larsen, Erlend and Kure, Øivind},
  booktitle={MILCOM 2018 - 2018 IEEE Military Communications Conference (MILCOM)}, 
  title={Publish/Subscribe Versus a Content-Based Approach for Information Dissemination}, 
  year={2018},
  volume={},
  number={},
  pages={1-9},
  abstract={NATO has identified the WS-Notification standard from OASIS to support event-driven communication in the NATO enterprise and when building coalition networks. Using this standard promotes interoperability. However, there is significant overhead associated with WS-Notification since it is built on SOAP Web services (WS). Overhead can be problematic in networks with scarce resources. In this paper we perform a small-scale comparative evaluation of overhead of WS-Notification with another publish/subscribe standard: Message Queuing Telemetry Transport (MQTT). We also measure how these standards compare to the novel approach of content-based networking under the same networking conditions. We use the Named Data Networking (NDN) flavor of content-based networking for our experiment. Though fundamentally different, these approaches can be used to realize the Service-Oriented Architecture (SOA) paradigm. The drawback of standard publish/subscribe approaches is that they usually rely on a broker, which constitutes a single point of failure. NDN, on the other hand, has no broker which makes it interesting to consider for tactical networks. We use NATO Friendly Force Information (NFFI), which is much used for friendly force tracking, as the data format for the payload in all our tests. In the paper we focus on the respective approaches' network resource consumption. Based on the results we argue that the content-based approach seems promising and should be investigated further.},
  keywords={},
  doi={10.1109/MILCOM.2018.8599786},
  ISSN={2155-7586},
  month={Oct},}@INPROCEEDINGS{9080034,
  author={Soomro, Arif Hussain and Jilani, Muhammad Taha},
  booktitle={2020 International Conference on Information Science and Communication Technology (ICISCT)}, 
  title={Application of IoT and Artificial Neural Networks (ANN) for Monitoring of Underground Coal Mines}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={Explosions in coal mines during the work time is a one of major cause of casualties in the coal mines. Thus possess a life threaten situation for coal miners. In this paper we propose a system in which sensors sense concentration of gases (Methane and carbon monoxide) in the air, measures the mine temperature and humidity and heartbeat of miner. In response it generate the alerts, and identifies the location of miners. We propose ZigBee based wireless sensor network (WSN) for communication between sensors and coal mine safety monitoring system. The iBeacons are proposed for identification of miners. A service oriented architecture (SOA) has used to develop the system. The main purpose of this research paper is to ensure miners safety, by predicting the methane has with artificial neural network (ANN). The application of ANN seems more viable than others, the calculated values shows that its prove a negligible relative error that is around 0.05.. than the actual measurements. The proposed work is then compared with the state-of-the-art methods that overcomes the limitations form the existing systems.},
  keywords={},
  doi={10.1109/ICISCT49550.2020.9080034},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{8695920,
  author={Yunofri and Suhardi and Kurniawan, Novianto Budi},
  booktitle={2018 International Conference on Information Technology Systems and Innovation (ICITSI)}, 
  title={Designing Service Computing Platform for Statistical Project Management Based on SOA}, 
  year={2018},
  volume={},
  number={},
  pages={99-104},
  abstract={Statistical are identical to conducting surveys. The process of conducting a survey is still not in accordance with the stages of planning, so that the impact on business processes is not maximized from the entire survey. The implementation of the project management system in statistical is expected to improve the control function in the survey. As information technology develops, service concepts can improve project management systems. Project management services make every component in project management work effectively and efficiently. Project management services develop in the addition of features, technology and resources. So there needs to be a system that can accommodate these needs by having functions that can be expanded. The service computing platform is the answer to this problem. A service computing platform is an architecture designed to support the process of preparing web services, and can provide tools and techniques for modeling, simulating, analyzing, planning, providing and monitoring service-oriented applications in real time. This platform can also be used as a basis for implementing various surveys. Statistics Indonesia (SI) needs to make improvements in conducting surveys. In line with the increasing quality of data produced by SI, it is necessary to develop a service computing platform for statistical project management. This study proposes a service computing platform using the Service Computing System Engineering (SCSE) methodology. After getting the service computing platform design, the proposed design is evaluated. Design evaluation is measured by Coupling Factor 0.0034 (loose coupling), Cohesion Factor 0.9198 (high cohesion), Complexity Factor 0.00368 (low complexity) and Reusability Factor 5.28571 (reusable) indicating that the design value is quite good.},
  keywords={},
  doi={10.1109/ICITSI.2018.8695920},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{7152572,
  author={Beier, Maximilian and Jansen, Christoph and Mayer, Geert and Penzel, Thomas and Rodenbeck, Andrea and Siewert, René and Wu, Jie and Krefting, Dagmar},
  booktitle={2015 15th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing}, 
  title={Multicenter Data Sharing for Collaboration in Sleep Medicine}, 
  year={2015},
  volume={},
  number={},
  pages={880-889},
  abstract={Clinical Sleep Research is an inherent multidisciplinary field, as many health issues may affect a person's sleep conditions and sleep disorders may cause several health problems. Many patients with chronic sleep disorders suffer from different further medical conditions - called multimorbidity. Due to the high variety of the reasons and the courses of sleep disorders, individual cases are difficult to compare. Therefore there is a high demand for sleep researchers to collaborate with each other to reach necessary participant numbers and multidisciplinary expertise. To date, inter-institutional sleep research is poorly supported by IT systems. In particular the heterogeneity and the quality variations within the acquired bio signal data - caused by different bio signal recorders or different measurement procedures - are impeding common bio signal data processing. In this manuscript we introduce a virtual research platform supporting inter-institutional data sharing and processing. The infrastructure is based on XNAT - a free and open-source neuroimaging research platform - a loosely coupled service oriented architecture and scalable virtualization in the backend. The system is capable of local pseudonymization of bio signal data, mapping to a standardized set of parameters and automatic quality assessment. Terms and quality measures are derived from the "Manual for the Scoring of Sleep and Associated Events" of the American Academy of Sleep Medicine, the de-facto standard for diagnostic bio signal analysis in sleep medicine.},
  keywords={},
  doi={10.1109/CCGrid.2015.148},
  ISSN={},
  month={May},}@INPROCEEDINGS{8035002,
  author={Radwan, Wafaa and Hassouneh, Yousef and Sayyad, Abdel Salam and Ammar, Nariman},
  booktitle={2017 IEEE International Conference on Services Computing (SCC)}, 
  title={YAFA-SOA: A GA-Based Optimizer for Optimizing Security and Cost in Service Compositions}, 
  year={2017},
  volume={},
  number={},
  pages={330-337},
  abstract={This paper studies heuristic search-based optimization of service compositions. We have investigated applying Genetic Algorithms (GA) to optimize service-oriented architectures (SOA) in terms of security goals and cost, we help software Engineers to map the optimized service composition to the business process model based on security and cost. Service composition security risk is measured by implementing the aggregation rules from the local security risk values of the aggregated services in the composition. We adapt the DREAD model for Security risk assessment by suggesting new categorizations for calculating DREAD factors based on a proposed service structure and service attributes. We implemented the YAFA-SOA Optimizer as an extension of an existing GA implementation to solve multi-objective optimization problems for varying number of objectives in the context of SOA. We evaluated the tool in a case study. The study results show that applying multi-objective GA is feasible to find the optimized security and cost in SOA-based systems. We were able to approve that adding security services to the generated composition reduces the risk severity of the generated composition and enhances its security in terms of confidentiality, integrity and availability (CIA). We found that the generated service composition risk severity is less than 0.5, which matches the validation results obtained from a security expert.},
  keywords={},
  doi={10.1109/SCC.2017.49},
  ISSN={2474-2473},
  month={June},}@INPROCEEDINGS{7133511,
  author={Harrer, Simon and Geiger, Matthias and Preißinger, Christian R. and Bimamisa, David and Schuberth, Stephan J.A. and Wirtz, Guido},
  booktitle={2015 IEEE Symposium on Service-Oriented System Engineering}, 
  title={Improving the Static Analysis Conformance of BPEL Engines with BPELlint}, 
  year={2015},
  volume={},
  number={},
  pages={31-39},
  abstract={Today, process-aware systems are ubiquitous. They are built by leveraging process languages for both business and implementation perspectives. In the typical context of a Web Services-based Service-oriented Architecture, the obvious choice to implement service orchestrations is still the Business Process Execution Language (BPEL). For BPEL, a variety of open source and commercial engines have emerged. Although the BPEL standard document defines a set of static analysis rules which should be checked by engines prior to deployment to be standard conformant, previous work revealed that most engines are not capable of revealing all violations of these constraints, resulting in costly runtime errors later on. In this paper, we aim to improve the static analysis conformance of BPEL engines. We implement the tool BPELlint that validates 71 static analysis rules of the BPEL specification, show that the tool can be easily integrated into the deployment process of existing engines, and evaluate its performance to measure the effect on the time to deploy. The results demonstrate that BPELlint can improve the static analysis conformance of BPEL engines with an acceptable performance overhead.},
  keywords={},
  doi={10.1109/SOSE.2015.21},
  ISSN={},
  month={March},}@INPROCEEDINGS{8776974,
  author={Barnwal, Anil and Jangade, Rajesh and Pugla, Satyakam},
  booktitle={2019 9th International Conference on Cloud Computing, Data Science & Engineering (Confluence)}, 
  title={Analyzing and Predicting the Allocation and Utilization of Resources in Cloud Computing System}, 
  year={2019},
  volume={},
  number={},
  pages={56-62},
  abstract={The increasing use of cloud computing, constructed on good research in utility computing, networking, virtualization and web services provides some important benefits such as flexibility, cost reduction and easy availability for people using the system. These advantages are expected to increase the demand for more cloud services which further increase the installation of more clouds and its customer base. These demands lead to many technical issues such as applications of internet services, service oriented architecture including high scalability and availability, fault tolerance. So the core issue is to develop techniques for balancing of load effectively. It is clear from the fact that the measure and complexity makes these systems infeasible for assignment of centralized jobs to specific servers. So there is need of productive distributed solutions. In the current paper three proposed load balancing solutions for distributed environment is investigated. They are biased Random Sampling, Honeybee Foraging and Active Clustering.},
  keywords={},
  doi={10.1109/CONFLUENCE.2019.8776974},
  ISSN={},
  month={Jan},}

@INPROCEEDINGS{9779690,
  author={Zaragoza, Pascal and Seriai, Abdelhak-Djamel and Seriai, Abderrahmane and Shatnawi, Anas and Derras, Mustapha},
  booktitle={2022 IEEE 19th International Conference on Software Architecture (ICSA)}, 
  title={Leveraging the Layered Architecture for Microservice Recovery}, 
  year={2022},
  volume={},
  number={},
  pages={135-145},
  abstract={The microservice-oriented architecture (MSA) is an architectural style which involves organizing an application as of small independent services, each oriented towards one business functionality while being data autonomous. In pursuit of modernizing their software to take advantage of the Cloud, companies have been eager to migrate their monolithic legacy software towards an MSA. This migration necessitates an identification phase to reorganize classes around the monolith’s functionalities as a set of microservice candidates. However, most identification approaches fail to utilize the monolith’s internal multilayered architecture to identify those functionalities, and thus the microservices. As a consequence, ignoring the internal multilayered architecture increases the risk of identifying microservice by their technical layer which is recognized as a conceptual anti-pattern. In this paper, we explore the impact of the multi-layer architecture in monolithic applications during the identification to develop a semi-automatic approach that relies on it to identify an MSA. Particularly, we analyze the presentation layer to determine the endpoints of each business functionality of the monolith. From these endpoints, we apply a vertical decomposition to identify the necessary classes to implement each feature as a microservice. In the process, we also define the bounded context of each microservice during the vertical decomposition of the data-access layer. For the evaluation, we implemented a model-driven process and applied it on a set of varying open-source applications commonly used in the literature. We compared the results of approach with and without the reverse-engineering of the internal architecture to measure the impact of our approach on the identification of quality microservices. Using decomposition metrics (e.g., MoJoFM, c2ccvg), we were able to measure a significant positive impact.},
  keywords={},
  doi={10.1109/ICSA53651.2022.00021},
  ISSN={},
  month={March},}@INPROCEEDINGS{10043222,
  author={Wang, Yu-Te and Ma, Shang-Pin and Lai, Yue-Jun and Liang, Yan-Cih},
  booktitle={2022 29th Asia-Pacific Software Engineering Conference (APSEC)}, 
  title={Analyzing and Monitoring Kubernetes Microservices based on Distributed Tracing and Service Mesh}, 
  year={2022},
  volume={},
  number={},
  pages={477-481},
  abstract={The microservice system architecture (MSA) outperforms the monolithic system architecture in terms of maintainability, extensibility, scalability, and fault tolerance. This is prompting a widescale migration of software systems from existing monolith systems to MSA. Most microservice systems utilize container technology for deployment. The fact that Kubernetes (K8s) provides a fully-fledged toolchain for managing container-based applications is prompting many organizations to adopt the K8s protocol for microservice system deployment and operations. Microservice monitoring is essential to the success of any service operation. The collection of logs and aggregation of metrics by most existing microservice monitoring systems is somewhat intrusive. Furthermore, the heterogeneity of Kubernetes technology means that most monitoring methods are inapplicable in situations where microservices are developed for a system using a variety of underlying languages and platforms. In the current study, we developed a monitoring mechanism that provides various metrics specific to microservice systems in a nonintrusive way. The proposed K8s-based microservice monitoring system, referred to as KMamiz (Kubernetes-based Microservice Analysis and Monitoring using Istio and Zipkin), enables the construction and visualization for service-level/endpoint-level dependency graphs and endpoint request chains, and the service cohesion/coupling analysis to enhance system quality for the development team.},
  keywords={},
  doi={10.1109/APSEC57359.2022.00066},
  ISSN={2640-0715},
  month={Dec},}@INPROCEEDINGS{9955300,
  author={Joyce, Josephine Eskaline and Sebastian, Shoney},
  booktitle={2022 IEEE 4th PhD Colloquium on Emerging Domain Innovation and Technology for Society (PhD EDITS)}, 
  title={Reinforcement Learning based Autoscaling for Kafka-centric Microservices in Kubernetes}, 
  year={2022},
  volume={},
  number={},
  pages={1-2},
  abstract={Microservices and Kafka have become a perfect match for enabling the Event-driven Architecture and this encourages microservices integration with various opensource platforms in the world of Cloud Native applications. Kubernetes is an opensource container orchestration platform, that can enable high availability, and scalability for Kafkacentric microservices. Kubernetes supports diverse autoscaling mechanisms like Horizontal Pod Autoscaler (HPA), Vertical Pod Autoscaler (VPA) and Cluster Autoscaler (CA). Among others, HPA automatically scales the number of pods based on the default Resource Metrics, which includes CPU and memory usage. With Prometheus integration, custom metrics for an application can be monitored. In a Kafkacentric microservices, processing time and speed depends on the number of messages published. There is a need for auto scaling policy which can be based on the number of messages processed. This paper proposes a new autoscaling policy, which scales Kafka-centric microservices deployed in an eventdriven deployment architecture, using a Reinforcement Learning model.},
  keywords={},
  doi={10.1109/PhDEDITS56681.2022.9955300},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10350465,
  author={Zhang, Yang and Li, Yang and Yang, Yilong and Chen, Shuang and Gao, Juntao and Wang, Weiru and Yin, Yongfeng},
  booktitle={2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)}, 
  title={RapidMS: A Tool for Supporting Rapid Microservices Generation and Refinement from Requirements Model}, 
  year={2023},
  volume={},
  number={},
  pages={45-49},
  abstract={Microservices is a crucial architecture design pat-tern for developing cloud-native applications, which focuses on decomposing a large and complex software system into autonomous components that can be independently developed and deployed. However, microservices design is not a trivial task, which highly depends on the profound knowledge and experience of system design and target domain. This is a challenge for novice software architects. In this paper, we propose a microservices design tool named RapidMS, which only requires architects to specify potential context boundaries on the requirements model. The microservices architecture design model with component structure and interaction views can be automatically generated without extra human effort. Moreover, the proposed tool can automatically calculate the characteristic metrics of the microservices, which indicate the quality of the different aspects of models to support rapid architecture refinements. We demonstrate the tool's effectiveness through five case studies. The experimental result shows that architects can get better decomposition of requirement model within four iterations and over 90% of microservice architecture diagrams can be correctly generated within 10 seconds. RapidMS can be further extended and applied in the software industry to reduce the cost and difficulty of microservices decomposition and design. The tool can be downloaded at https://rm2pt.com/advs/ rapidms, and a demo video casting its features is at https://youtu.be/AoIM41FTnFO},
  keywords={},
  doi={10.1109/MODELS-C59198.2023.00017},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10074842,
  author={Yang, Xikang and Wang, Juan and Zhou, Biyu and Wang, Wang and Liu, Wantao and Dong, Yangchen},
  booktitle={2022 IEEE 24th Int Conf on High Performance Computing & Communications; 8th Int Conf on Data Science & Systems; 20th Int Conf on Smart City; 8th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)}, 
  title={Fine-grained Spatiotemporal Features-Based for Anomaly Detection in Microservice Systems}, 
  year={2022},
  volume={},
  number={},
  pages={847-856},
  abstract={More and more applications use microservice architecture. Protecting the reliability of the microservice system is very important for the stable operation of applications. However, the complexity of microservice systems poses a great challenge to operation and maintenance. Researchers have proposed a series of anomaly detection algorithms, which can automatically detect the anomalies of cloud systems in time. However, for the microservice system with a complex spatial structure, there is no effective method to represent the fine-grained features of the internal metric level of the microservice. To solve this problem, we propose a fine-grained metric-level spatial feature graph TopoMetrics and use a spatiotemporal neural network STAD to obtain the spatiotemporal features of microservices, which can accurately detect the anomalies of complex microservices. We compare STAD with the most advanced algorithms in three open microservice workloads. The experimental results show that the average precision of STAD is significantly higher than that of the most advanced baseline method.},
  keywords={},
  doi={10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00138},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9836297,
  author={Pulnil, Sermsook and Senivongse, Twittie},
  booktitle={2022 19th International Joint Conference on Computer Science and Software Engineering (JCSSE)}, 
  title={A Microservices Quality Model Based on Microservices Anti-patterns}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Microservices architecture is becoming popular as many software organizations have the need to transform large complex systems into small-sized software units whose functions are separated by business capabilities. Microservices architecture is preferable since it promotes independence of software modification, maintenance, and deployment. However, anti-patterns or poor development patterns of microservices can decrease the software quality. Nonetheless, quality measurement of microservices design based on anti-patterns has not been found in existing research. Using the QMOOD method for quality model design, this paper proposes a microservices quality model based on 11 microservices anti-patterns and ISO/IEe 25010 as a standard reference for quality attributes. Also, a microservices quality measurement tool called MSA Nose+ is developed to measure the quality of microservices applications. In an experiment to validate the proposed model, the result shows that the quality values obtained from the proposed model improve consistently with the refactorings that are applied to a microservice-based system. Thus, development teams can use the proposed model and quality measurements as part of the decision making on quality improvement and maintenance of microservices applications.},
  keywords={},
  doi={10.1109/JCSSE54890.2022.9836297},
  ISSN={2642-6579},
  month={June},}@INPROCEEDINGS{9820743,
  author={Wang, Xinkai and Li, Chao and Zhang, Lu and Hou, Xiaofeng and Chen, Quan and Guo, Minyi},
  booktitle={2022 IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, 
  title={Exploring Efficient Microservice Level Parallelism}, 
  year={2022},
  volume={},
  number={},
  pages={223-233},
  abstract={The microservice architecture has recently become a driving trend in the cloud by disaggregating a monolithic application into many scenario-oriented service blocks (microservices). The decomposition process results in a highly dynamic execution scenario, in which various chained microservices contend for computing resources in different ways. While parallelism has been exploited at both the instruction/thread level and the task/request level, very limited work has been done with the grain-size of a microservice. Current parallel processing solutions are sub-optimal as they neither capture the unique characteristics of microservices nor consider the uncertainty arises in the microservice environment. In this work we introduce microservice level parallelism (MLP), a technique that aims to precisely coalesce and align parallel microservice chains for better system performance and resource utilization. We identify major issues that prevent servers from effectively exploiting MLP and we define metrics that can guide MLP optimization. We propose v-MLP, a volatility-aware MLP that is able to adapt to a highly heterogeneous and dynamic microservice environment. We show that v-MLP can reduce tail latency by up to 50% and improve resource utilization by up to 15 % under various scenarios.},
  keywords={},
  doi={10.1109/IPDPS53621.2022.00030},
  ISSN={1530-2075},
  month={May},}@INPROCEEDINGS{10350596,
  author={Li, Yang and Zhang, Yang and Yang, Yilong and Wang, Weiru and Yin, Yongfeng},
  booktitle={2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)}, 
  title={RM2MS: A Tool for Automatic Identification of Microservices from Requirements Models}, 
  year={2023},
  volume={},
  number={},
  pages={50-54},
  abstract={Microservices identification is the key development process of cloud-native applications. It focuses on decomposing system into decoupling autonomous components to support development and deployment independently. This process requires sophisticated human efforts for careful requirements analysis and validation to identify the appropriate microservices boundary inside system modules. Our previous work RM2PT can help to achieve a validated requirements model through automatically generating prototypes from original requirements models. The validated requirements model contains the precise definitions of functionality and data structure that can help in microservices identification. In this paper, we present a tool named RM2MS to further alleviate the problem of cloud-native application development to support automatic identification of microservices from the validated requirements model. RM2MS can automatically analyse the relationship between functionality and data structure, and trade-off non-functional factors for microservices identification. We demonstrate that the microservice architecture solution generated by RM2MS demonstrates a average gain of 27.1% over the manual approach in three key metrics(Function-Cohesion, Modularity, and Instability), while exhibiting efficiency that surpasses the manual process by more than 10-fold through five case studies. The proposed approach can be further extended and applied for the cloud-native application development in the software industry. The tool can be downloaded at https://rm2pt.com/advs/rm2ms, and a demo video casting its features is at https://www.youtube.com/watch?v=T71vQDasOSw},
  keywords={},
  doi={10.1109/MODELS-C59198.2023.00018},
  ISSN={},
  month={Oct},}@ARTICLE{10332462,
  author={Xu, Yueshen and Qiu, Zhibo and Gao, Honghao and Zhao, Xinkui and Wang, Lu and Li, Rui},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={Heterogeneous Data-Driven Failure Diagnosis for Microservice-Based Industrial Clouds Towards Consumer Digital Ecosystems}, 
  year={2023},
  volume={},
  number={},
  pages={1-1},
  abstract={Consumer digital ecosystems include a large volume of different types of applications, and those applications are usually deployed in industrial cloud computing systems. Currently, microservices are one of the most prevailing architectures for industrial clouds. Similar to other architectures, microservices may also produce failures, so failure diagnosis for microservices becomes an inevitable problem in industrial clouds. A majority of existing methods focus on statistical analysis for monitoring data or system topological structure. However, because these methods usually only harness service-level or machine-level metrics, they cannot complete fine-grained failure diagnosis, increasing the running risk of microservice-based industrial clouds. To tackle this issue, in this paper, we design a novel graph structure to represent failure dependencies, especially the heterogeneity, and name it as the heterogeneous failure dependence graph (HFDG). We propose a framework to inform engineers which type of and where failures occur in industrial clouds. The HFDG can be used to mine the propagation of failures between different types of components. We also propose a novel neural network model based on attention mechanism and heterogeneous graph neural network, to fully leverage the metric data and HFDG. We performed experiments on three large-scale public datasets from real-world microservices-based systems. The experimental results demonstrate the superior performance of our model compared to well-known baselines.},
  keywords={},
  doi={10.1109/TCE.2023.3337351},
  ISSN={1558-4127},
  month={},}@INPROCEEDINGS{10256409,
  author={Jack, Chang Hoong and Teck, See Kwee and Ming, Lim Tong and Hong, Ding Ying},
  booktitle={2023 IEEE 8th International Conference On Software Engineering and Computer Systems (ICSECS)}, 
  title={An Overview Analysis of Authentication Mechanism in Microservices-Based Software Architecture: A Discussion Paper}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Microservices-based software architecture promotes scalability and flexibility by breaking down a software application into smaller modules and making it more independent and loosely coupled services compared to monolith systems. However, securing microservices in a distributed nature has become one of the challenges. Authentication is one of the most critical components that should be focused in the microservices security measures. It helps to identify that only authenticated personnel and services can access sensitive information and secure the trust between microservices. This discussion paper aims to provide an overview analysis and extensive understanding on the authentication mechanism in microservices-based software architecture. In this study, we explore different authentication mechanisms including Mutual Transport Layer Security (mTLS), Token based authentication and API Gateway authentication. This study examines the strengths and limitations of different authentication mechanisms in microservices-based software architecture. It also emphasizes the importance of authentication and the need for having a well-designed authentication mechanism to ensure the integrity and security of microservices-based software architecture is crucial.},
  keywords={},
  doi={10.1109/ICSECS58457.2023.10256409},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9779811,
  author={Speth, Sandro and Stieß, Sarah and Becker, Steffen},
  booktitle={2022 IEEE 19th International Conference on Software Architecture Companion (ICSA-C)}, 
  title={A Saga Pattern Microservice Reference Architecture for an Elastic SLO Violation Analysis}, 
  year={2022},
  volume={},
  number={},
  pages={116-119},
  abstract={Reference architectures are becoming increasingly popular for industry and researchers as benchmark solutions to test their novel concepts and tools. While many reference architectures exist in the microservice domain, they are often not built on state-of-the-art technologies. Furthermore, many existing reference architectures do not use lightweight and asynchronous communications, such as messaging, do not have out-of-the-box self-adaptation and do not consider state-of-the-art microservice patterns. Therefore, this paper proposes a self-adaptive microservice reference architecture that implements the microservice saga pattern. The architecture is implemented in Java Spring Boot and uses the Eventuate Tram framework for the saga orchestration. Moreover, the architecture is instrumented to export performance metrics for monitoring and data for system-wide tracing to check for correct execution of the system and its adaptations. The objective of this reference architecture is to provide a benchmark for explaining self-adaptation and propagation of service-level objective (SLOs) violations across an architecture with complex patterns. In addition to the architecture, we provide defined SLOs and load profiles to stress the architecture.},
  keywords={},
  doi={10.1109/ICSA-C54293.2022.00029},
  ISSN={2768-4288},
  month={March},}@ARTICLE{9090324,
  author={Ma, Meng and Lin, Weilan and Pan, Disheng and Wang, Ping},
  journal={IEEE Transactions on Services Computing}, 
  title={Self-Adaptive Root Cause Diagnosis for Large-Scale Microservice Architecture}, 
  year={2022},
  volume={15},
  number={3},
  pages={1399-1410},
  abstract={The emergence of microservice architecture in Cloud systems poses a new challenges for the reliability operation and maintenance. Due to numerous services and diverse types of metrics, it is time-consuming and challenging to identify the root cause of anomaly in large-scale microservice architecture. To solve this issue, this article presents a multi-metric and self-adaptive root cause diagnosis framework, named MS-Rank. MS-Rank decomposes the task into four phases: impact graph construction, random walk diagnosis, result precision evaluation, metrics weight update. Initially, we introduce the concept of implicit metrics and propose a composite impact graph construction algorithm, using multiple types of metrics to discover causal relationships between services. Afterwards, we propose a diagnostic algorithm in which forward, selfward and backward transitions are designed to heuristically identify the root cause services. In addition, we establish a self-adaptive mechanism to update the confidence of different metrics dynamically according to their diagnostic precision. Lastly, we develop a prototype system and integrate MS-Rank into real production system - IBM Cloud. Experimental results show that MS-Rank has a high diagnostic precision and its performance outperforms several selected benchmarks. Through multiple rounds of diagnosis, MS-Rank can optimize itself effectively. MS-Rank can be rapidly deployed in various microservice-based systems and applications, requiring no predefined knowledge. MS-Rank also allows us to introduce expert experiences into its framework to improve the diagnostic efficiency and precision.},
  keywords={},
  doi={10.1109/TSC.2020.2993251},
  ISSN={1939-1374},
  month={May},}@ARTICLE{9784409,
  author={Sebrechts, Merlijn and Volckaert, Bruno and De Turck, Filip and Yang, Kun and Al-Naday, Mays},
  journal={IEEE Communications Magazine}, 
  title={Fog Native Architecture: Intent-Based Workflows to Take Cloud Native toward the Edge}, 
  year={2022},
  volume={60},
  number={8},
  pages={44-50},
  abstract={The cloud native approach is rapidly transforming how applications are developed and operated, turning monolithic applications into microservice applications, allowing teams to release faster, increase reliability, and expedite operations by taking full advantage of cloud resources and their elasticity. At the same time, “fog computing” is emerging, bringing the cloud toward the edge, near the end user, in order to increase privacy, improve resource efficiency, and reduce latency. Combining these two trends, however, proves difficult because of four fundamental disconnects between the cloud native paradigm and fog computing. This article identifies these disconnects and proposes a fog native architecture along with a set of design patterns to take full advantage of the fog. Central to this approach is turning microservice applications into microservice workflows, constructed dynamically by the system using an intent-based approach taking into account a number of factors such as user requirements, request location, and available infrastructure and microservices. The architecture introduces a novel softwarized fog mesh facilitating both inter-microservice connectivity, external communication, and end-user aggregation. Our evaluation analyzes the impact of distributing microservice-based applications over a fog ecosystem, illustrating the impact of CPU and network latency and application metrics on perceived quality of service of fog native workflows compared to the cloud. The results show the fog can offer superior application performance given the right conditions.},
  keywords={},
  doi={10.1109/MCOM.003.2101075},
  ISSN={1558-1896},
  month={August},}@INPROCEEDINGS{10336221,
  author={Sarda, Komal},
  booktitle={2023 IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion (ACSOS-C)}, 
  title={Leveraging Large Language Models for Auto-remediation in Microservices Architecture}, 
  year={2023},
  volume={},
  number={},
  pages={16-18},
  abstract={Microservices architecture is popular due to its scalability and flexibility. However, managing and troubleshooting distributed microservices-based systems can be challenging and time consuming. Auto-remediation of anomalies, that is the automated detection and root-causes generation and execution of repair scripts, can reduce the down-times and increase the availability of systems. This thesis will explore the potential and effectiveness of using large language models (LLMs) in auto-remediation. It will develop an auto-remediation framework to mitigate the effects of performance-based anomalies in self-adaptive microservice architectures. Multiple sample microservice applications as test-bed will be rigorously studied, and a dataset will be created to evaluate LLM-based codegeneration models using semantic, lexical, and correctness metrics in zero-shot and few-shot scenarios. Additionally, we will develop reliable prompts for automated Ansible runbook generation and assess their efficiency for orchestrating the auto-remediation process, including deployment, configuration changes, and system recovery to improve application reliability and operational efficiency.},
  keywords={},
  doi={10.1109/ACSOS-C58168.2023.00025},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10062468,
  author={Frank, Sebastian and Wagner, Lion and Hakamian, Alireza and Straesser, Martin and van Hoorn, André},
  booktitle={2022 IEEE 22nd International Conference on Software Quality, Reliability and Security (QRS)}, 
  title={MiSim: A Simulator for Resilience Assessment of Microservice-Based Architectures}, 
  year={2022},
  volume={},
  number={},
  pages={1014-1025},
  abstract={Increased resilience compared to monolithic architectures is both one of the key promises of microservice-based architectures and a big challenge, e.g., due to the systems’ distributed nature. Resilience assessment through simulation requires fewer resources than the measurement-based techniques used in practice. However, there is no existing simulation approach that is suitable for a holistic resilience assessment of microservices comprised of (i) representative fault injections, (ii) common resilience mechanisms, and (iii) time-varying workloads. This paper presents MiSim — an extensible simulator for resilience assessment of microservice-based architectures. It overcomes the stated limitations of related work. MiSim fits resilience engineering practices by supporting scenario-based experiments and requiring only lightweight input models. We demonstrate how MiSim simulates (1) common resilience mechanisms — i.e., circuit breaker, connection limiter, retry, load balancer, and autoscaler — and (2) fault injections — i.e., instance/service killing and latency injections. In addition, we use TeaStore, a reference microservice-based architecture, aiming to reproduce scaling behavior from an experiment by using simulation. Our results show that MiSim allows for quantitative insights into microservice-based systems’ complex transient behavior by providing up to 25 metrics.},
  keywords={},
  doi={10.1109/QRS57517.2022.00105},
  ISSN={2693-9177},
  month={Dec},}@ARTICLE{9057418,
  author={Yu, Guangba and Chen, Pengfei and Zheng, Zibin},
  journal={IEEE Transactions on Cloud Computing}, 
  title={Microscaler: Cost-Effective Scaling for Microservice Applications in the Cloud With an Online Learning Approach}, 
  year={2022},
  volume={10},
  number={2},
  pages={1100-1116},
  abstract={Recently, the microservice becomes a popular architecture to construct cloud native systems due to its agility. In cloud native systems, autoscaling is a key enabling technique to adapt to workload changes by acquiring or releasing the right amount of computing resources. However, it becomes a challenging problem in microservice applications, since such an application usually comprises a large number of different microservices with complex interactions. When the performance decreases due to an unpredictable workload peak, it is difficult to pinpoint the scaling-needed services which need to scale out and evaluate how many resources they need. In this article, we present a novel system named Microscaler to automatically identify the scaling-needed services and scale them to meet the Service Level Agreement (SLA) with an optimal cost for microservice applications. Microscaler first collects the quality of service (QoS) metrics in the service mesh enabled microservice infrastructure. Then, it determines under-provisioning or over-provisioning service instances along the service dependency graph with a novel scaling-needed service criterion named service power. The service dependency graph could be obtained by correlating each request flow in the service mesh. By combining an online learning approach and a step-by-step heuristic approach, Microscaler can precisely reach the optimal service scale meeting the SLA requirements. The experimental evaluations in a microservice benchmark show that Microscaler achieves an average 93 percent precision in scaling-needed service determination and converges to the optimal service scale faster than several state-of-the-art methods. Moreover, Microscaler is lightweight and flexible enough to work in a large-scale microservice system.},
  keywords={},
  doi={10.1109/TCC.2020.2985352},
  ISSN={2168-7161},
  month={April},}@INPROCEEDINGS{10123637,
  author={Li, Yuewei and Lu, Yan and Wang, Jingyu and Qi, Qi and Wang, Jing and Wang, Yingying and Liao, Jianxin},
  booktitle={2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)}, 
  title={TADL: Fault Localization with Transformer-based Anomaly Detection for Dynamic Microservice Systems}, 
  year={2023},
  volume={},
  number={},
  pages={718-722},
  abstract={Due to the complexity of microservice architecture, it is difficult to accomplish efficient microservice anomaly detection and localization tasks and achieve the target of high system reliability. For rapid failure recovery and user satisfaction, it is significant to detect and locate anomalies fast and accurately in microservice systems. In this paper, we propose an anomaly detection and localization model based on Transformer, named TADL (Transformer-based Anomaly Detector and Locator), which models the temporal features and dynamically captures container relationships using Transformer with sandwich structure. TADL uses readily available container performance metrics, making it easy to implement in already-running container clusters. Evaluations are conducted on a sock-shop dataset collected from a real microservice system and a publicly available dataset SMD. Empirical studies on the above two datasets demonstrate that TADL can outperform baseline methods in the performance of anomaly detection, the latency of anomaly detection, and the effect of anomalous container localization, which indicates that TADL is useful in maintaining complex and dynamic microservice systems in the real world.},
  keywords={},
  doi={10.1109/SANER56733.2023.00078},
  ISSN={2640-7574},
  month={March},}@INPROCEEDINGS{10015475,
  author={Pearce, Glen and Pflaum, Alexis and Balasoiu, Dumitru Alin and Szabo, Claudia},
  booktitle={2022 Winter Simulation Conference (WSC)}, 
  title={Jeopardy Assessment for Dynamic Configuration of Collaborative Microservice Architectures}, 
  year={2022},
  volume={},
  number={},
  pages={2070-2081},
  abstract={Microservice architectures, which are lightweight, flexible, and adapt easily to changes, have recently been considered for system development in military operations in contested and dynamic environments. However, in a military setting, the dynamic configuration of collaborative microservices execution becomes critical, and testing that microservice configurations behave as expected becomes paramount. In this paper, we propose a complex jeopardy metric and reconfiguration process that dynamically configures collaborative algorithms running on multiple nodes. Our metric and proposed scenarios will allow for the automated evaluation of microservice configurations and their re-configuration to suit operational needs. We evaluate our proposed scenario, metric, and various reconfiguration algorithms to show the benefits of this approach.},
  keywords={},
  doi={10.1109/WSC57314.2022.10015475},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{9978950,
  author={Bi, Tingzhu and Pan, Yicheng and Jiang, Xinrui and Ma, Meng and Wang, Ping},
  booktitle={2022 IEEE 33rd International Symposium on Software Reliability Engineering (ISSRE)}, 
  title={VECROsim: A Versatile Metric-oriented Microservice Fault Simulation System (Tools and Artifact Track)}, 
  year={2022},
  volume={},
  number={},
  pages={297-308},
  abstract={Automated fault diagnosis of microservice systems has been a hot topic in recent years. As most incidents in real commercial cloud systems are not publicly available, we have witnessed researchers putting considerable effort into developing various experimental systems. However, previous tools cannot quickly refactor their functionality, scale the architecture, and customize fault characteristics. Given this, we develop VECROsim, a versatile metric-oriented microservice fault simulation system, and release the VECROsim benchmark dataset. VECROsim works delicately as a highly-customizable toolkit to generate abnormal performance metrics datasets of microservice systems on demand and automatically. Validation of representative services from the benchmark dataset confirms the capability of VECROsim to generate realistic performance metrics for diverse real-world systems. Our case studies on root cause analysis and dynamic correlation discovery demonstrated the superiority of VECROsim. We also witnessed that the VECROsim dataset brings new research challenges to state-of-the-art fault diagnosis schemes. VECROsim concretely supports microservice developers from the industry, as well as academic researchers working on fault diagnosis or broader research topics in many ways.},
  keywords={},
  doi={10.1109/ISSRE55969.2022.00037},
  ISSN={2332-6549},
  month={Oct},}@ARTICLE{10034937,
  author={Gu, Shenghui and Rong, Guoping and Ren, Tian and Zhang, He and Shen, Haifeng and Yu, Yongda and Li, Xian and Ouyang, Jian and Chen, Chunan},
  journal={IEEE Transactions on Software Engineering}, 
  title={TrinityRCL: Multi-Granular and Code-Level Root Cause Localization Using Multiple Types of Telemetry Data in Microservice Systems}, 
  year={2023},
  volume={49},
  number={5},
  pages={3071-3088},
  abstract={The microservice architecture has been commonly adopted by large scale software systems exemplified by a wide range of online services. Service monitoring through anomaly detection and root cause analysis (RCA) is crucial for these microservice systems to provide stable and continued services. However, compared with monolithic systems, software systems based on the layered microservice architecture are inherently complex and commonly involve entities at different levels of granularity. Therefore, for effective service monitoring, these systems have a special requirement of multi-granular RCA. Furthermore, as a large proportion of anomalies in microservice systems pertain to problematic code, to timely troubleshoot these anomalies, these systems have another special requirement of RCA at the finest code-level. Microservice systems rely on telemetry data to perform service monitoring and RCA of service anomalies. The majority of existing RCA approaches are only based on a single type of telemetry data and as a result can only support uni-granular RCA at either application-level or service-level. Although there are attempts to combine metric and tracing data in RCA, their objective is to improve RCA's efficiency or accuracy rather than to support multi-granular RCA. In this article, we propose a new RCA solution TrinityRCL that is able to localize the root causes of anomalies at multiple levels of granularity including application-level, service-level, host-level, and metric-level, with the unique capability of code-level localization by harnessing all three types of telemetry data to construct a causal graph representing the intricate, dynamic, and nondeterministic relationships among the various entities related to the anomalies. By implementing and deploying TrinityRCL in a real production environment, we evaluate TrinityRCL against two baseline methods and the results show that TrinityRCL has a significant performance advantage in terms of accuracy at the same level of granularity with comparable efficiency and is particularly effective to support large-scale systems with massive telemetry data.},
  keywords={},
  doi={10.1109/TSE.2023.3241299},
  ISSN={1939-3520},
  month={May},}@ARTICLE{9215019,
  author={Khazaei, Hamzeh and Mahmoudi, Nima and Barna, Cornel and Litoiu, Marin},
  journal={IEEE Transactions on Cloud Computing}, 
  title={Performance Modeling of Microservice Platforms}, 
  year={2022},
  volume={10},
  number={4},
  pages={2848-2862},
  abstract={Microservice architecture has transformed the way developers are building and deploying applications in the nowadays cloud computing centers. This new approach provides increased scalability, flexibility, manageability, and performance while reducing the complexity of the whole software development life cycle. The increase in cloud resource utilization also benefits microservice providers. Various microservice platforms have emerged to facilitate the DevOps of containerized services by enabling continuous integration and delivery. Microservice platforms deploy application containers on virtual or physical machines provided by public/private cloud infrastructures in a seamless manner. In this article, we study and evaluate the provisioning performance of microservice platforms by incorporating the details of all layers (i.e., both micro and macro layers) in the modeling process. To this end, we first build a microservice platform on top of Amazon EC2 cloud and then leverage it to develop a comprehensive performance model to perform what-if analysis and capacity planning for microservice platforms at scale. In other words, the proposed performance model provides a systematic approach to measure the elasticity of the microservice platform by analyzing the provisioning performance at both the microservice platform and the back-end macroservice infrastructures.},
  keywords={},
  doi={10.1109/TCC.2020.3029092},
  ISSN={2168-7161},
  month={Oct},}@ARTICLE{10160171,
  author={Abgaz, Yalemisew and McCarren, Andrew and Elger, Peter and Solan, David and Lapuz, Neil and Bivol, Marin and Jackson, Glenn and Yilmaz, Murat and Buckley, Jim and Clarke, Paul},
  journal={IEEE Transactions on Software Engineering}, 
  title={Decomposition of Monolith Applications Into Microservices Architectures: A Systematic Review}, 
  year={2023},
  volume={49},
  number={8},
  pages={4213-4242},
  abstract={Microservices architecture has gained significant traction, in part owing to its potential to deliver scalable, robust, agile, and failure-resilient software products. Consequently, many companies that use large and complex software systems are actively looking for automated solutions to decompose their monolith applications into microservices. This paper rigorously examines 35 research papers selected from well-known databases using a Systematic Literature Review (SLR) protocol and snowballing method, extracting data to answer the research questions, and presents the following four contributions. First, the Monolith to Microservices Decomposition Framework (M2MDF) which identifies the major phases and key elements of decomposition. Second, a detailed analysis of existing decomposition approaches, tools and methods. Third, we identify the metrics and datasets used to evaluate and validate monolith to microservice decomposition processes. Fourth, we propose areas for future research. Overall, the findings suggest that monolith decomposition into microservices remains at an early stage and there is an absence of methods for combining static, dynamic, and evolutionary data. Insufficient tool support is also in evidence. Furthermore, standardised metrics, datasets, and baselines have yet to be established. These findings can assist practitioners seeking to understand the various dimensions of monolith decomposition and the community's current capabilities in that endeavour. The findings are also of value to researchers looking to identify areas to further extend research in the monolith decomposition space.},
  keywords={},
  doi={10.1109/TSE.2023.3287297},
  ISSN={1939-3520},
  month={Aug},}@INPROCEEDINGS{9919941,
  author={Yang, Linwei and Li, Jing and Shi, Kuanzhi and Yang, Songlin and Yang, Qingfu and Sun, Jiangang},
  booktitle={2022 23rd Asia-Pacific Network Operations and Management Symposium (APNOMS)}, 
  title={MicroMILTS: Fault Location for Microservices Based Mutual Information and LSTM Autoencoder}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Driven by the development of cloud computing and artificial intelligence, architecture has dramatically improved in terms of flexibility and scalability in software development. Therefore, it is increasingly being used to build large-scale applications for agile development. However, along with the technology heterogeneity, the dynamics of running instances, and the complexity of service dependencies, fault localization is extraordinarily difficult. In this paper, we present MicroMILTS, a microservice fault location method based on mutual information and an LSTM Autoencoder. MicroMILTS first uses BIRCH for anomaly detection based on the analysis of the performance metrics data correlated to microservice anomalies. Once anomalies are detected, a service dependency property graph is constructed based on the real-time microservice invocation relationships and the reconstructed deviations of performance metrics with the LSTM Autoencoder. Next, MicroMILTS dynamically updates the weight of each node in the service dependency property graph. Then, a PageRank-based random walk is applied for further ranking root causes. Finally, a Sock-shop microservice system is built on the Huawei Cloud to evaluate the performance of MicroMILTS. The experiment shows that MicroMILTS achieves a good root cause location result, with 90.4 % in precision and 91.6% in mean average precision, outperforming state-of-the-art methods.},
  keywords={},
  doi={10.23919/APNOMS56106.2022.9919941},
  ISSN={2576-8565},
  month={Sep.},}@ARTICLE{10125010,
  author={Zdun, Uwe and Queval, Pierre-Jean and Simhandl, Georg and Scandariato, Riccardo and Chakravarty, Somik and Jelić, Marjan and Jovanović, Aleksandar},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={Detection Strategies for Microservice Security Tactics}, 
  year={2023},
  volume={},
  number={},
  pages={1-17},
  abstract={Microservice architectures are widely used today to implement distributed systems. Securing microservice architectures is challenging because of their polyglot nature, continuous evolution, and various security concerns relevant to such architectures. This article proposes a novel, model-based approach providing detection strategies to address the automated detection of security tactics (or patterns and best practices) in a given microservice architecture decomposition model. Our novel detection strategies are metrics-based rules that decide conformance to a security recommendation based on a statistical predictor. The proposed approach models this recommendation using Architectural Design Decisions (ADDs). We apply our approach for four different security-related ADDs on access management, traffic control, and avoiding plaintext sensitive data in the context of microservice systems. We then apply our approach to a model data set of 10 open-source microservice systems and 20 variants of those systems. Our results are detection strategies showing a very low bias, a very high correlation, and a low prediction error in our model data set.},
  keywords={},
  doi={10.1109/TDSC.2023.3276487},
  ISSN={1941-0018},
  month={},}@INPROCEEDINGS{10092594,
  author={Filippone, Gianluca and Qaisar Mehmood, Nadeem and Autili, Marco and Rossi, Fabrizio and Tivoli, Massimo},
  booktitle={2023 IEEE 20th International Conference on Software Architecture (ICSA)}, 
  title={From monolithic to microservice architecture: an automated approach based on graph clustering and combinatorial optimization}, 
  year={2023},
  volume={},
  number={},
  pages={47-57},
  abstract={Migrating from a legacy monolithic system to a microservice architecture is a complex and time-consuming process. Software engineers may strongly benefit from automated support to identify a high-cohesive and loose-coupled set of microservices with proper granularity. The automated approach proposed in this paper extracts microservices by using graph clustering and combinatorial optimization to maximize cohesion and minimize coupling. The approach performs static analysis of the code to obtain a graph representation of the monolithic system. Then, it uses graph clustering to detect high-cohesive communities of nodes using the Louvain community algorithm. In parallel, the tool clusters the domain entities (i.e., classes representing uniquely identifiable concepts in a system domain) within bounded contexts to identify the required service granularity. Finally, it uses combinatorial optimization to minimize the coupling, hence deriving the microservice architecture. The approach is fully implemented. We applied it over four different monolithic systems and found valuable results. We evaluated the identified architectures through cohesion and coupling metrics, along with a comparison with other state-of-the-art approaches based on features such as granularity level, number of produced services, and methods applied. The approach implementation and the experimental results are publicly available.},
  keywords={},
  doi={10.1109/ICSA56044.2023.00013},
  ISSN={},
  month={March},}@INPROCEEDINGS{10371619,
  author={Ünlü, Hüseyin and Hacaloğlu, Tuna and Ömüral, Neslihan Küçükateş and Çalişkanel, Neslihan and Leblebici, Onur and Demirörs, Onur},
  booktitle={2023 49th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)}, 
  title={An Exploratory Case Study on Effort Estimation in Microservices}, 
  year={2023},
  volume={},
  number={},
  pages={215-218},
  abstract={Software project management plays an important role in producing high-quality software, and effort estimation can be considered as a backbone for successful project management. Size is a very significant attribute of software by being the only input to perform early effort estimation. Even though functional size measurement methods showed successful results in effort estimation of traditional data-centric architectures such as monoliths, they were not designed for today’s architectures which are more service-based and decentralized such as microservices. In these new systems, the event concept is highly used specifically for communication among different services. By being motivated by this fact, in this study, we looked for more microservice-compatible ways of sizing microservices using events and developed a method accordingly. Then, we conducted an exploratory case study in an organization using agile methods and measured the size of 17 Product Backlog Items (PBIs) to assess how this proposed method can be useful in effort estimation in microservices. The implication from the case study is that despite performing a more accurate effort estimation using the proposed size measurement than COSMIC, we were unable to significantly outperform using the total number of events. However, our suggested approach demonstrated to us a different way to use software size in terms of events, namely, to determine the coupling complexity of the project. This finding can be beneficial specifically when evaluating the change requests.},
  keywords={},
  doi={10.1109/SEAA60479.2023.00040},
  ISSN={2376-9521},
  month={Sep.},}@INPROCEEDINGS{10295809,
  author={Adrio, Kendricko and Tanzil, Clementius Nichklaus and Lianto, Michael Christian and Rasjid, Zulfany Erlisa},
  booktitle={2023 10th International Conference on Electrical Engineering, Computer Science and Informatics (EECSI)}, 
  title={Comparative Analysis of Monolith, Microservice API Gateway and Microservice Federated Gateway on Web-based application using GraphQL API}, 
  year={2023},
  volume={},
  number={},
  pages={654-660},
  abstract={The purpose of this research is to provide a detailed explanation regarding the characteristics as well as the pros and cons offered by various software development architecture, such as monolithic and Microservice architecture implemented with graph-based API called GraphQL. Monolithic architecture offers a centralized software development pattern with relatively simpler integration and development process. Conversely, Microservices architecture such as Gateway Aggregation and Federated Gateway will divide independent components of the application into smaller modules. Gateway Aggregation utilizes a single Gateway which acts as the main entry point for data exchange between the client and the application. In this research aims an application is developed using the three different architectures to measure the quality, both qualitative and quantitative performances of each architecture. There are several different parameters that are going to be used to measure the architecture’s performance such as response time and data throughput which become an essential criterion in conducting load and stress testing. The result is that the Monolithic architecture offers some advantages in its quantitative performance measurement due to better efficiency in collecting and processing requested data in a single application which utilizes fewer resources and shorter time. In contrast, the Gateway Aggregation architecture and Federated Gateway architecture also have some significant performance differences because it costs resources to combine several subgraphs together into a valid graph.},
  keywords={},
  doi={10.1109/EECSI59885.2023.10295809},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10031648,
  author={Kleftakis, Spyridon and Mavrogiorgou, Argyro and Zafeiropoulos, Nikolaos and Mavrogiorgos, Konstantinos and Kiourtis, Athanasios and Kyriazis, Dimosthenis},
  booktitle={2022 IEEE International Conference on Computing (ICOCO)}, 
  title={A Comparative Study of Monolithic and Microservices Architectures in Machine Learning Scenarios}, 
  year={2022},
  volume={},
  number={},
  pages={352-357},
  abstract={Choosing the most suitable architecture for applications is not an easy decision. While the software giants have almost all put in place the microservices architecture, on smaller platforms such decision it is not so obvious. In the healthcare domain and specifically when accomplishing Machine Learning (ML) tasks in this domain, considering its special characteristics, the decision should be made based on specific metrics. In the context of the beHEALTHIER platform, a platform that is able to handle heterogeneous healthcare data towards their successful management and analysis by applying various ML tasks, such research gap was fully investigated. There has been conducted an experiment by installing the platform in three (3) different architectural ways, referring to the monolithic architecture, the clustered microservices architecture exploiting docker compose, and the microservices architecture exploiting Kubernetes cluster. For these three (3) environments, time-based measurements were made for each Application Programming Interface (API) of the diverse platform’s functionalities (i.e., components) and useful conclusions were drawn towards the adoption of the most suitable software architecture.},
  keywords={},
  doi={10.1109/ICOCO56118.2022.10031648},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9885761,
  author={Chen, Yufu and Yan, Meng and Yang, Dan and Zhang, Xiaohong and Wang, Ziliang},
  booktitle={2022 IEEE International Conference on Web Services (ICWS)}, 
  title={Deep Attentive Anomaly Detection for Microservice Systems with Multimodal Time-Series Data}, 
  year={2022},
  volume={},
  number={},
  pages={373-378},
  abstract={Software architecture is undergoing a transition from monolithic architectures to microservices to achieve resilience, agility, and scalability in the software life circle. However, microservice architecture is not perfect and suffers from intermittent faults, leading to economic and user losses. Therefore, it is essential to detect anomalies in microservice systems accurately. The key limitation of current approaches lies in a lack of ability to detect multitype anomalies, excessive resource overhead, and requirements of expert knowledge. In this paper, we present a Deep Attentive anomaly detection approach with Multimodal data named DAM. With multimodal fusion, attentive LSTM, and a dynamic threshold selecting algorithm, DAM could detect anomalies accurately and efficiently in an unsupervised manner. We evaluate our approach by injecting six types of anomalies on a widely used microservice system, Train-Ticket. The result shows that DAM could detect multitype anomalies well, with 80.46% F-measure, achieving 16.76% and 29.52% improvement over two state-of-the-art baselines (Donut and DAGMM), respectively.},
  keywords={},
  doi={10.1109/ICWS55610.2022.00062},
  ISSN={},
  month={July},}@INPROCEEDINGS{10211993,
  author={Abbasi, Maryam and Melo, Pedro and Saraiva, Luzia and Pereira, Pedro and Martins, Pedro and Sá, Filipe and Cardoso, Filipe},
  booktitle={2023 18th Iberian Conference on Information Systems and Technologies (CISTI)}, 
  title={Enhancing Banking Operations with Microservices and Mobile Technology}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper presents a novel architecture for enhancing the banking experience by combining microservices and a mobile application. The use of microservices provides scalability and flexibility in the development process, making it easier to add new features or modify existing ones. The results of the study shows that the proposed architecture is capable of handling high volume of transactions and requests while providing high quality of service. The mobile application provides a user-friendly interface for accessing financial information, and the use of microservices ensures efficient management of data and transactions. The architecture also has the potential to improve security through the use of security measures to protect sensitive data. As a future research direction, the proposed architecture can be evaluated in real-world settings and its security can be further tested. The field of technology in the banking sector is constantly evolving, and it is important to stay updated with new advancements that can potentially improve the proposed architecture.},
  keywords={},
  doi={10.23919/CISTI58278.2023.10211993},
  ISSN={2166-0727},
  month={June},}@ARTICLE{10183809,
  author={Zeb, Shah and Rathore, Muhammad Ahmad and Hassan, Syed Ali and Raza, Saleem and Dev, Kapal and Fortino, Giancarlo},
  journal={IEEE Wireless Communications}, 
  title={Toward AI-Enabled NextG Networks with Edge Intelligence-Assisted Microservice Orchestration}, 
  year={2023},
  volume={30},
  number={3},
  pages={148-156},
  abstract={Network agility, automation, and intelligence are at the forefront of the next-generation networks (NGNs) vision, which aims to provide zero-touch service management and self-optimizing networks. In this article, we give an overview of the significance of artificial intelligence (Ali-enabled NGNs, their projected benefits, design requirements, and critical challenges for evolving heterogeneous softwarized networks where microservices can be autonomously orchestrated, scaled, and maintained. The convergence of emerging disruptive technologies, for example, AI, network softwarization, hybrid cloud/edge-native computing architecture, with NGNs accelerates the enhanced service-oriented architecture at the network core/edge level to support on-demand microservices, such as visibility services for intelligent network management. In addition, we present a use case study and conduct experiments based on a novel design of an edge intelligence framework that orchestrates and deploys AI microservices utilizing the testbed resources of a multisite cloud/edge-native NGNs. We use a deep learning-based forecaster model to predict near real-time edge network flow between a centralized service orchestrator hub and multiple edge devices, geographically apart. The obtained results show that the deployed forecaster model accurately predicts the throughput and latency of edge network flow (verified against the groundtruth observations), which is additionally validated through two performance metrics obtained, low root-mean-square error, and high coefficient of determination values. Finally, we outline some of the potential future prospects for AI-enabled NGNs research.},
  keywords={},
  doi={10.1109/MWC.015.2200461},
  ISSN={1558-0687},
  month={June},}@ARTICLE{9744560,
  author={Rossi, Fabiana and Cardellini, Valeria and Presti, Francesco Lo and Nardelli, Matteo},
  journal={IEEE Transactions on Cloud Computing}, 
  title={Dynamic Multi-Metric Thresholds for Scaling Applications Using Reinforcement Learning}, 
  year={2023},
  volume={11},
  number={2},
  pages={1807-1821},
  abstract={Cloud-native applications increasingly adopt the microservices architecture, which favors elasticity to satisfy the application performance requirements in face of variable workloads. To simplify the elasticity management, the trend is to create an auto-scaler instance per microservice, which controls its horizontal scalability by using the classic threshold-based policy. Although easy to implement, setting manually the scaling thresholds, which are usually statically-defined on a single metric, may lead to poor scaling decisions when applications are heterogeneous in terms of resource consumption. In this article, we study dynamic multi-metric threshold-based scaling policies, that exploit Reinforcement Learning (RL) to autonomously update the scaling thresholds, one per controlled resource (CPU and memory). The proposed RL approaches (i.e., QL, MB, and DQL Threshold) use different degrees of knowledge about the system dynamics. To model the thresholds’ adaptation actions, we consider two RL-based architectures. In the single-agent architecture, one agent drives the updates of both scaling thresholds. To speed-up the learning, the multi-agent architecture adopts a distinct agent per threshold. Simulation- and prototype-based results show the benefits of the proposed solutions when compared to the state-of-the-art policies and highlight the advantages of multi-agent MB Threshold and DQL Threshold approaches, in terms of deployment objectives and execution times.},
  keywords={},
  doi={10.1109/TCC.2022.3163357},
  ISSN={2168-7161},
  month={April},}@INPROCEEDINGS{10279802,
  author={Raghunandan, Arpitha and Kalasapura, Deepti and Caesar, Matthew},
  booktitle={ICC 2023 - IEEE International Conference on Communications}, 
  title={Digital Twinning for Microservice Architectures}, 
  year={2023},
  volume={},
  number={},
  pages={3018-3023},
  abstract={Digital twins have been designed and implemented for diverse applications like smart manufacturing, healthcare, supply chain and retail management. They provide monitoring, remote prognostics and health management capabilities for the various physical assets used in these domains. Many of these capabilities would be beneficial to microservice architectures as well, given the need for lightweight monitoring solutions in multitenant environments. In particular, twins can provide operators with real-time resource usage metrics which help with operational objectives such as resource planning, anomaly detection, rewind and replay and so on. In this work, we propose a design for building digital twins for microservice architectures. As a proof of concept, we focus on modelling the resource utilization as that is a key requirement for monitoring system reliability and security. In general, digital twins require a real world counterpart, a virtual model and a mechanism for consistently keeping both synchronized. We focus on the two latter aspects of the digital twin. Our approach involves converting a formal model of a microservice architecture into a digital twin that can capture and execute an actual cluster's state. We present an extensible architecture connecting the various components of the system and the twin and evaluate the twin's ability to capture the real-time state of a real Kubernetes cluster. We also discuss future extensions which can enhance the system's security by detecting a broad range of attacks.},
  keywords={},
  doi={10.1109/ICC45041.2023.10279802},
  ISSN={1938-1883},
  month={May},}@INPROCEEDINGS{10037281,
  author={Raharjo, Agus Budi and Andyartha, Putu Krisna and Wijaya, William Handi and Purwananto, Yudhi and Purwitasari, Diana and Juniarta, Nyoman},
  booktitle={2022 International Conference on Computer Engineering, Network, and Intelligent Multimedia (CENIM)}, 
  title={Reliability Evaluation of Microservices and Monolithic Architectures}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={Software is continuously evolving as business processes that needed to be solved become increasingly complex. Software architecture is an important aspect during software design, with monolithic and microservices being two of the most common with their own advantages and disadvantages. Monolithic is a unified system with a relatively fast development time. Meanwhile, microservices facilitates low coupling and high cohesion, prioritizing maintenance, and ease of modification post-development. This research compares microservices and monolithic API-based thesis monitoring systems. Implementations are done using PHP, Redis, PostgreSQL, Docker, and Heroku. Reliability evaluations are done through automated tests with Apache JMeter. Metrics used are maturity, availability, fault tolerance, and recoverability based on the ISO/IEC 25010 reliability quality characteristics. The conclusion section showed that microservices are more reliable than the monolithic by demonstrating much better fault tolerance and recoverability, with comparable maturity and availability.},
  keywords={},
  doi={10.1109/CENIM56801.2022.10037281},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9984530,
  author={Hettiarachchi, Lasal Sandeepa and Jayadeva, Senura Vihan and Bandara, Rusiru Abhisheak Vikum and Palliyaguruge, Dilmi and Arachchillage, Udara Srimath S. Samaratunge and Kasthurirathna, Dharshana},
  booktitle={2022 13th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Artificial Intelligence-Based Centralized Resource Management Application for Distributed Systems}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Due to the decentralized nature and emergence of new practices, tools, and platforms, microservices have become one of the most widely spread software architectures in the modern software industry. Furthermore, the advancement of software packaging tools like Docker and orchestration platforms such as Kubernetes enable developers and operation engineers to deploy and manage microservice applications more effectively and efficiently. However, establishing and managing microservice applications are still cumbersome due to the infrastructure configuration and array of disjoint tools that fail to understand the application’s dynamic behavior. As a result, developers need to configure multiple tools and platforms to automate the deployment and monitoring process to provide the optimal deployment strategy for microservices. Even though many tools are available in the industry, the fully automated product which comprises deployment, monitoring, resiliency evaluation and optimization were not developed yet. In response to this issue, we propose an artificial intelligence (AI)-based centralized resource management tool, that provides an automated low latency container management, cluster metrics gathering, resiliency evaluation and optimal deployment strategy behave in dynamic nature.},
  keywords={},
  doi={10.1109/ICCCNT54827.2022.9984530},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10371525,
  author={Daniel, João and Guerra, Eduardo and Rosa, Thatiane and Goldman, Alfredo},
  booktitle={2023 49th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)}, 
  title={Towards the Detection of Microservice Patterns Based on Metrics}, 
  year={2023},
  volume={},
  number={},
  pages={132-139},
  abstract={Microservices is a popular architectural approach for complex systems in companies, despite its nature of decentralization. There is a comprehensive set of microservices architectural patterns that guides implementations and helps developers to overcome issues. However, the community still scarcely adopts these patterns and only has a theoretical understanding of them. In this work, in order to increase awareness of such patterns and provide aid to developers to better understand an architecture based on microservices, we propose a detection approach based on metrics for microservices patterns. We focused on structural or architectural patterns, and implemented detection for five of them. We conducted two case studies with real-world applications and evaluated the accuracy and applicability of our approach with the developers of those applications.},
  keywords={},
  doi={10.1109/SEAA60479.2023.00029},
  ISSN={2376-9521},
  month={Sep.},}@INPROCEEDINGS{10298321,
  author={Huang, Jun and Yang, Yang and Yu, Hang and Li, Jianguo and Zheng, Xiao},
  booktitle={2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={Twin Graph-Based Anomaly Detection via Attentive Multi-Modal Learning for Microservice System}, 
  year={2023},
  volume={},
  number={},
  pages={66-78},
  abstract={Microservice architecture has sprung up over recent years for managing enterprise applications, due to its ability to independently deploy and scale services. Despite its benefits, ensuring the reliability and safety of a microservice system remains highly challenging. Existing anomaly detection algorithms based on a single data modality (i.e., metrics, logs, or traces) fail to fully account for the complex correlations and interactions between different modalities, leading to false negatives and false alarms, whereas incorporating more data modalities can offer opportunities for further performance gain. As a fresh attempt, we propose in this paper a semi-supervised graph-based anomaly detection method, MSTGAD, which seamlessly integrates all available data modalities via attentive multi-modal learning. First, we extract and normalize features from the three modalities, and further integrate them using a graph, namely MST (microservice system twin) graph, where each node represents a service instance and the edge indicates the scheduling relationship between different service instances. The MST graph provides a virtual representation of the status and scheduling relationships among service instances of a real-world microservice system. Second, we construct a transformer-based neural network with both spatial and temporal attention mechanisms to model the inter-correlations between different modalities and temporal dependencies between the data points. This enables us to detect anomalies automatically and accurately in real-time. Extensive experiments on two real-world datasets verify the effectiveness of our proposed MSTGAD method, achieving competitive performance against state-of-the-art approaches, with a 0.961 F1-score and an average increase of 4.85%. The source code of MST-GAD is publicly available at https://github.com/ant-research/microservice_system_twin_graph_based_anomaly_detection.},
  keywords={},
  doi={10.1109/ASE56229.2023.00138},
  ISSN={2643-1572},
  month={Sep.},}@INPROCEEDINGS{9932943,
  author={Pramesti, Annisa Ayu and Kistijantoro, Achmad Imam},
  booktitle={2022 9th International Conference on Advanced Informatics: Concepts, Theory and Applications (ICAICTA)}, 
  title={Autoscaling Based on Response Time Prediction for Microservice Application in Kubernetes}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Containerized application are evolving along with the microservice architectures in distributed application development. This trend shows the importance of managing and orchestrating containerized applications thus applications can operate properly. One of the aspects of container orchestration is scaling or increasing the application’s ability to handle more requests. In this study, an autoscaler based on response time prediction is developed for microservice applications in Kubernetes environment. The prediction function is developed using a machine learning model that features performance metrics at the microservice and node levels. The response time prediction is then used to calculate the number of pods required by the application to meet the target response time. Our experiment shows that the proposed autoscaler can serve more requests that match the target response time compare with the Kubernetes Horizontal Pod Autoscaler (HPA) that are using CPU usage as the target. However, as the consequence, the proposed autoscaler consumes more resources than the Kubernetes HPA.},
  keywords={},
  doi={10.1109/ICAICTA56449.2022.9932943},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10279721,
  author={Kalinagac, Onur and Soussi, Wissem and Anser, Yacine and Gaber, Chrystel and Gür, Gürkan},
  booktitle={ICC 2023 - IEEE International Conference on Communications}, 
  title={Root Cause and Liability Analysis in the Microservices Architecture for Edge IoT Services}, 
  year={2023},
  volume={},
  number={},
  pages={3277-3283},
  abstract={In this work, we present a liability analysis frame-work for root cause analysis (RCA) in the microservices architecture with IoT-oriented containerized network services. We keep track of the performance metrics of microservices, such as service response time, memory usage and availability, to detect anomalies. By injecting faults in the services, we construct a Causal Bayesian Network (CBN) which represents the relation between service faults and metrics. Service Level Agreement (SLA) data obtained from a descriptor named TRAILS (sTakeholder Responsibility, AccountabIlity and Liability deScriptor) is also used to flag service providers which have failed their commitments. In the case of SLA violation, the constructed CBN is used to predict the fault probability of services under given metric readings and to identify the root cause.},
  keywords={},
  doi={10.1109/ICC45041.2023.10279721},
  ISSN={1938-1883},
  month={May},}@INPROCEEDINGS{9960012,
  author={Ivanov, Rosen and Yordanov, Stanimir and Dinev, Dinko},
  booktitle={2022 International Conference Automatics and Informatics (ICAI)}, 
  title={Internet of Things–based pregnancy tracking and monitoring service}, 
  year={2022},
  volume={},
  number={},
  pages={298-302},
  abstract={This paper presents the architecture and implementation of a service for pregnancy tracking and monitoring. The main goal of the service is to analyze the behavior of pregnant women in order to proactively decide to notify medical staff when symptoms are detected that are risky for the normal pregnancy. This is achieved by (1) providing the necessary pregnancy-related information for each of the gestational weeks (nutrition, physical activity, normal and risk symptoms, necessary screening tests, etc.), (2) analysis of physical activity of pregnant women, (3) measurement and analysis of basic biological indicators using a wireless sensor network (pulse oximeter, human body temperature, biopotential channel to obtain electrocardiogram (ECG) and bioimpedance channel to measure respiration), and (4) receiving push notifications about important events related to the pregnancy; scheduled medical examinations; risk factors; and messages from the obstetrician under whose supervision the pregnant woman is. The service has a distributed architecture - it uses multiple microservices. The communication between clients (mobile app), wireless sensor network and microservices is realized through a message broker. Microservices use its own MongoDB databases hosted in the Azure cluster. Experiments were conducted to prove the feasibility of the service on simulated wireless sensor network.},
  keywords={},
  doi={10.1109/ICAI55857.2022.9960012},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10248319,
  author={Castro, Jessica and Laranjeiro, Nuno and Vieira, Marco},
  booktitle={2023 IEEE International Conference on Web Services (ICWS)}, 
  title={Exploring Logic Scoring of Preference for DoS Attack Detection in Microservice Applications}, 
  year={2023},
  volume={},
  number={},
  pages={573-584},
  abstract={Microservice architectures allow the development of highly scalable, flexible, and manageable systems. However, such architectures raise new security problems and exacerbate the challenge of monitoring applications at runtime due to their high service granularity and distributed nature. Developing effective monitoring and security strategies is thus crucial to effectively detect potential attacks. This paper explores the applicability of Logic Scoring of Preference (LSP), a multi-criteria decision-making method to compute a score based on a set of preferences, for attack detection in microservice applications. We present an extensive experimental study and define a model based on LSP and application-level metrics to characterize the impact of DoS attacks. The output of the model is a unique score used to determine whether a microservice is under a DoS attack. The results of the experimental study show precision, recall, and f1-score rates of more than 80%, indicating that LSP could effectively characterize the application under attack, opening several possibilities for future work.},
  keywords={},
  doi={10.1109/ICWS60048.2023.00076},
  ISSN={2836-3868},
  month={July},}@INPROCEEDINGS{10083635,
  author={S, Savitha and C, Sangana and K, Devendran and L, Pravin and M, Rajkumar and C, Nirmal},
  booktitle={2023 7th International Conference on Computing Methodologies and Communication (ICCMC)}, 
  title={Auto Scaling Infrastructure with Monitoring Tools using Linux Server on Cloud}, 
  year={2023},
  volume={},
  number={},
  pages={45-52},
  abstract={Cloud computing is the term that has gained widespread usage over these last few years. Due to the rapid increase in the use of information in the digital age of the 21st century, it is increasingly becoming a more attractive option for individuals and organizations to manage all their essential data, projects, and collaborations, rather than relying solely on in-house computers. The user's requirement for hardware and software is reduced via cloud computing. The interface software of cloud computing systems, typically as simple as a web browser, is the only thing the user must operate, and the Cloud network handles the rest. To decrease operational costs, both business and government organizations are adopting cloud computing, seeking a flexible and adaptable solution for the supply and delivery of their product services. Microservices and decoupled apps are becoming more popular. These container-based architectures make it easier to build sophisticated SaaS apps quickly, but managing and creating microservices can be a daunting task. Managing and creating microservices that involve a wide range of diverse functions, including handling and storing information, and performing predictive and prescriptive analysis, can be a challenging undertaking. Establishing auto scaling infrastructure on doud can be challenging due to several reasons, some of which are: understanding the application architecture, setting up monitoring, scaling policies, cost optimization and implementation complexity. Server farms include the tremendous and heterogeneous virtualized frameworks, which are continually extending and broadening after sometime are the essential starting point for registering specialized organizations. These solutions also need to be integrated into existing systems while adhering to Quality of Service (QoS) requirements. The principal objective of this work is to propose an on-premise design to leverage Kubernetes and Docker containers to improve the quality of service based on resource usage and Service Level Objectives (SLOs). The Prometheus Administrator set up is used to perform namespace checking. Normally, doud providers enable their own monitoring tools (like CloudWatch) for monitoring CPU, storage and network usage, service component, however these tools cannot monitor the service component. Additionally, the advancements have restricted the capacity to follow QoS highlights at the application level (like security and execution) since the main focus will be dedicated towards the equipment assets. These types of node-level monitoring make it difficult to scale requests and deploy pods to match the demand. Infrastructure monitoring should enable runtime changes to monitor the requirements or metric operationalization should be done on those criteria without modifying the underlying infrastructure.},
  keywords={},
  doi={10.1109/ICCMC56507.2023.10083635},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10036308,
  author={Basciftci, Fatih and Aydemir, Fikri},
  booktitle={2022 IEEE 20th Jubilee International Symposium on Intelligent Systems and Informatics (SISY)}, 
  title={Strategies for Request-Response Logging in Microservices Architecture}, 
  year={2022},
  volume={},
  number={},
  pages={000121-000126},
  abstract={Microservices Architecture is the prevailing architectural choice today for building distributed software systems in various business sectors, such as telecommunications, e-commerce, and finance. It is often necessary to log the full content of request and response messages (i.e., the entire body of these messages) that are entering and leaving such distributed systems due to legal book-keeping requirements. In this work, two systematic design strategies were used to realize the structured logging of request-response messages including their entire message body, particularly in a microservices architecture-based distributed software system. As a case study, a prototype per strategy was implemented and deployed into an existing Microservices Architecture-based banking system, which was provided by a commercial bank for the research presented in this paper in the Kubernetes cluster. Load tests were performed against this banking system to measure average request throughputs and average response times per logging strategy for analysis purposes. The results that are presented in this paper are expected to be helpful for both researchers and practitioners in the software industry who need a similar logging solution.},
  keywords={},
  doi={10.1109/SISY56759.2022.10036308},
  ISSN={1949-0488},
  month={Sep.},}@INPROCEEDINGS{10262956,
  author={Yang, Yunhao and Jiang, Ying},
  booktitle={2023 IEEE 9th International Conference on Cloud Computing and Intelligent Systems (CCIS)}, 
  title={Microservice Indicator Prediction Method Based on STE and CNN-BiLSTM}, 
  year={2023},
  volume={},
  number={},
  pages={511-515},
  abstract={Due to the extensibility and continuous evolution of microservice architecture, there are a lot of uncertainties in the microservice system, which brings great risks to the reliability of the service. Indicator prediction plays an important role in service reliability. If the predicted value exceeds the safe range, alarms are generated and measures are taken to prevent faults. Therefore, a microservice indicator prediction method based on SET and CNN-BiLSTM is proposed. Symbolic transfer entropy (STE) is used to analyze the nonlinear causality, and a prediction model based on CNN-BiLSTM is established. The simulation results show that this method can capture the causal relationship between the indicators with nonlinear relationship effectively and improve the prediction accuracy.},
  keywords={},
  doi={10.1109/CCIS59572.2023.10262956},
  ISSN={2376-595X},
  month={Aug},}@INPROCEEDINGS{10303332,
  author={Jhingran, Sushant and Rakesh, Nitin},
  booktitle={2023 International Conference on Sustainable Emerging Innovations in Engineering and Technology (ICSEIET)}, 
  title={Application Deployment and Performance Measurement in Serverless Cloud for Microservices}, 
  year={2023},
  volume={},
  number={},
  pages={173-177},
  abstract={The effectiveness of Cloud technology relies heavily on its ability to perform at a high level. To measure this performance, it is necessary to conduct a performance evaluation based on specific aims and applications and assess the capabilities of the cloud services. In the case of enterprise applications deployed on the cloud, the service provider must consider the application's deployment model, security, networking, and operational constraints. This evaluation involves identifying benchmarks, configuring the system, running tests, analyzing results, and providing recommendations. There are various performance metrics that can be applied to different aspects of the cloud services to evaluate their performance. The figures below display data on resource utilization and the impact of the load on the application. Microservices offer organizations the opportunity to deploy applications on the cloud by providing web service functions and an architecture that enables scaling and updating of applications with minimal inconsistency. Through public cloud technology such as Amazon Web Services, organizations can deploy secure and valuable applications to the cloud.},
  keywords={},
  doi={10.1109/ICSEIET58677.2023.10303332},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9779689,
  author={Vale, Guilherme and Correia, Filipe Figueiredo and Guerra, Eduardo Martins and de Oliveira Rosa, Thatiane and Fritzsch, Jonas and Bogner, Justus},
  booktitle={2022 IEEE 19th International Conference on Software Architecture (ICSA)}, 
  title={Designing Microservice Systems Using Patterns: An Empirical Study on Quality Trade-Offs}, 
  year={2022},
  volume={},
  number={},
  pages={69-79},
  abstract={The promise of increased agility, autonomy, scalability, and reusability has made the microservices architecture a de facto standard for the development of large-scale and cloud-native commercial applications. Software patterns are an important design tool, and often they are selected and combined with the goal of obtaining a set of desired quality attributes. However, from a research standpoint, many patterns have not been widely validated against industry practice, making them not much more than interesting theories. To address this, we investigated how practitioners perceive the impact of 14 patterns on 7 quality attributes. Hence, we conducted 9 semi-structured interviews to collect industry expertise regarding (1) knowledge and adoption of software patterns, (2) the perceived architectural trade-offs of patterns, and (3) metrics professionals use to measure quality attributes. We found that many of the trade-offs reported in our study matched the documentation of each respective pattern, and identified several gains and pains which have not yet been reported, leading to novel insight about microservice patterns.},
  keywords={},
  doi={10.1109/ICSA53651.2022.00015},
  ISSN={},
  month={March},}@INPROCEEDINGS{10136018,
  author={Lin, Zhichao and Wang, Qingsheng and Yang, Shifeng and Luo, Busheng and Ma, Qiujie and Yu, Chuankun},
  booktitle={2023 8th Asia Conference on Power and Electrical Engineering (ACPEE)}, 
  title={Modeling and Performance Analysis of Cloud-Based Active Distribution Networks Based on EdgeCloudSim}, 
  year={2023},
  volume={},
  number={},
  pages={1682-1687},
  abstract={In order to realise the performance + analysis of the cloud-based active distribution network, this paper proposes the modeling and performance analysis method of the cloud-based active distribution network. Firstly, based on the task processing requirements of the active distribution network, the corresponding task modeling method based on microservices is proposed. Then, the cloud-based active distribution network architecture modeling is proposed, and the corresponding dynamic resource allocation process is realised. In addition, through the professional edge computing simulation software EdgeCloudSim, the modeling of the cloud-based active distribution network is realised. The modeling includes specific scenarios, resource allocation and two task spatio-temporal logics. Task delay and resource load rate are as performance metrics. Finally, with microservices as the research granularity, the performance differences of different task spatio-temporal logics are analysed.},
  keywords={},
  doi={10.1109/ACPEE56931.2023.10136018},
  ISSN={},
  month={April},}@INPROCEEDINGS{9788687,
  author={Xu, Beibei and Zhao, Yanqing and Kuzminykh, Valeriy and Zhu, Shiwei and Yu, Junfeng and Zhang, Mingjun and Li, Sisi},
  booktitle={ICETIS 2022; 7th International Conference on Electronic Technology and Information Science}, 
  title={Research on the Evaluation System of International S&T Cooperation Based on Microservice Architecture}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={The development of the world has benefited from advances in science and technology, and the destiny of mankind has become closer due to scientific and technological cooperation. International scientific and technological innovation cooperation is one of the important indicators to measure the potential and technological innovation of a country or region. Scientific evaluation and performance evaluation of international scientific and technological cooperation have become important for effectively improving the management level of international scientific and technological cooperation projects and promoting scientific and technological output. Means, the construction of a scientific cooperation evaluation and performance evaluation system has become a realistic demand for promoting international scientific and technological cooperation and strengthening performance management of international scientific and technological cooperation in the new era. Based on the analysis of the data sources, data structure, index evaluation system and system functions of the international scientific and technological cooperation evaluation system, the article proposes the system logic and hierarchical structure under the microservice architecture, and designs and implements the international scientific and technological cooperation evaluation system based on the microservice architecture.},
  keywords={},
  doi={},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{9874065,
  author={Chinthavali, Supriya and Hasan, S.M.Shamimul and Yoginath, Srikanth and Xu, Haowen and Nugent, Phil and Jones, Terry and Engebretsen, Cozmo and Olatt, Joseph and Tansakul, Varisara and Christopher, Carter and Polsky, Yarom},
  booktitle={2022 IEEE 23rd International Conference on Information Reuse and Integration for Data Science (IRI)}, 
  title={An Alternative Timing and Synchronization Approach for Situational Awareness and Predictive Analytics}, 
  year={2022},
  volume={},
  number={},
  pages={172-177},
  abstract={Accurate and synchronized timing information is required by power system operators for controlling the grid infrastructure (relays, Phasor Measurement Units (PMUs), etc.) and determining asset positions. Satellite-based global positioning system (GPS) is the primary source of timing information. However, GPS disruptions today (both intentional and unintentional) can significantly compromise the reliability and security of our electric grids. A robust alternate source for accurate timing is critical to serve both as a deterrent against malicious attacks and as a redundant system in enhancing the resilience against extreme events that could disrupt the GPS network. To achieve this, we rely on the highly accurate, terrestrial atomic clock-based network for alternative timing and synchronization. In this paper, we discuss an experimental setup for an alternative timing approach. The data obtained from this experimental setup is continuously monitored and analyzed using various time deviation metrics. We also use these metrics to compute deviations of our clock with respect to the National Institute of Standards and Technologys (NIST) GPS data. The results obtained from these metric computations are elaborately discussed. Finally, we discuss the integration of the procedures involved, like real-time data ingestion, metric computation, and result visualization, in a novel microservices-based architecture for situational awareness.},
  keywords={},
  doi={10.1109/IRI54793.2022.00047},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9973518,
  author={Chapman, Martin and G-Medhin, Abigail and Sassoon, Isabel and Kökciyan, Nadin and Sklar, Elizabeth I. and Curcin, Vasa},
  booktitle={2022 IEEE 18th International Conference on e-Science (e-Science)}, 
  title={Using Microservices to Design Patient-facing Research Software}, 
  year={2022},
  volume={},
  number={},
  pages={44-54},
  abstract={With a significant amount of software now being developed for use in patient-facing studies, there is a pressing need to consider how to design this software effectively in order to support the needs of both researchers and patients. We posit that a microservice architecture-which offers a large amount of flexibility for development and deployment, while at the same time ensuring certain quality attributes, such as scalability, are present-provides an effective mechanism for designing such software. To explore this proposition, in this work we show how the paradigm has been applied to the design of Consult, a decision support system that provides autonomous support to stroke patients and is characterised by its use of a data-backed AI reasoner. We discuss the impact that the use of this software architecture has had on the teams developing Consult and measure the performance of the system produced. We show that the use of microservices can deliver software that is able to facilitate both research and effective patient interactions. However, we also conclude that the impact of the approach only goes so far, with additional techniques needed to address its limitations.},
  keywords={},
  doi={10.1109/eScience55777.2022.00019},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9808684,
  author={Hrusto, Adha and Engström, Emelie and Runeson, Per},
  booktitle={2022 IEEE/ACM 10th International Workshop on Software Engineering for Systems-of-Systems and Software Ecosystems (SESoS)}, 
  title={Optimization of Anomaly Detection in a Microservice System Through Continuous Feedback from Development}, 
  year={2022},
  volume={},
  number={},
  pages={13-20},
  abstract={Monitoring a microservice system may bring a lot of benefits to development teams such as early detection of run-time errors and various performance anomalies. In this study, we explore deep learning (DL) solutions for detection of anomalous system’s behavior based on collected monitoring data that consists of applications’ and systems’ performance metrics. The study is conducted in a collaboration with a Swedish company responsible for ticket and payment management in public transportation. Moreover, we specifically address a shortage of approaches for evaluating DL models without any ground truth data. Hence, we propose a solution design for anomaly detection and reporting alerts inspired by state-of-the-art DL solutions. Furthermore, we propose a plan for its in-context implementation and evaluation empowered by feedback from the development team. Through continuous feedback from development, the labeled data is generated and used for optimization of the DL model. In this way, a microservice system may leverage DL solutions to address rising challenges within its architecture. CCS CONCEPTS • Software and its engineering → Software post-development issues; • Information systems → Data mining; Computing platforms; • Computing methodologies → Machine learning.},
  keywords={},
  doi={},
  ISSN={},
  month={May},}@INPROCEEDINGS{10254995,
  author={Garbi, Giulio and Incerto, Emilio and Tribastone, Mirco},
  booktitle={2023 IEEE 16th International Conference on Cloud Computing (CLOUD)}, 
  title={μP: A Development Framework for Predicting Performance of Microservices by Design}, 
  year={2023},
  volume={},
  number={},
  pages={178-188},
  abstract={Microservice (MS) architecture has become a popular paradigm in software engineering and has been embraced in the industry (e.g., Amazon, Netflix) for cloud-based applications with crucial performance requirements. Surprisingly, assessing how the MS designs affect performance is still a challenging issue, which is generally tackled by extensive and expensive profiling. In this paper, we propose $\mu \mathbf{P}$, a novel development framework for MS applications where performance can be predicted $by$ design. $\mu \mathbf{P}$ offers an API that automatically generates a per-formance model based on Layered Queuing Networks (LQNs) without requiring any development effort beyond writing the actual system code. The model can then be queried to predict performance metrics such as response time and utilization of individual microservices. We validate $\mu \mathbf{P}$ on four benchmarks taken from the literature. The results show the effectiveness of $\mu \mathbf{P}$ in accurately predicting performance due to increasing user load, vertical and horizontal scaling. We report prediction errors for response times consistently lower than 10% across a wide range of operating conditions.},
  keywords={},
  doi={10.1109/CLOUD60044.2023.00029},
  ISSN={2159-6190},
  month={July},}@INPROCEEDINGS{10092637,
  author={Pinciroli, Riccardo and Aleti, Aldeida and Trubiani, Catia},
  booktitle={2023 IEEE 20th International Conference on Software Architecture (ICSA)}, 
  title={Performance Modeling and Analysis of Design Patterns for Microservice Systems}, 
  year={2023},
  volume={},
  number={},
  pages={35-46},
  abstract={The adoption of design patterns in the microservice architecture and cloud-native development scope was recently reviewed to investigate the industry practice. Interestingly, when considering performance-related aspects, practitioners focus on specific metrics (e.g., the time taken to handle requests) to identify sources of performance hindrance. This paper investigates a subset of seven design patterns that industrial practitioners indicate as relevant for system performance. We are interested to quantify the impact of these patterns while considering heterogeneous workloads, thus supporting software architects in understanding the root causes of performance issues. We use queuing networks to build the performance models of the seven design patterns and extract quantitative insights from model-based performance analysis. Our performance models are flexible in their input parameterization and reusable in different application contexts. We find that most design patterns confirm the expectation of practitioners, and our experimental results assess the identified performance gains and pains. One design pattern (i.e., Gateway Offloading) shows the peculiar characteristic of contributing to performance pains in some cases, leading to novel insights about the impact of design patterns in microservice systems.},
  keywords={},
  doi={10.1109/ICSA56044.2023.00012},
  ISSN={},
  month={March},}@INPROCEEDINGS{10074951,
  author={Li, Gongliang and Wen, Zepeng and Xie, Xin},
  booktitle={2022 IEEE 24th Int Conf on High Performance Computing & Communications; 8th Int Conf on Data Science & Systems; 20th Int Conf on Smart City; 8th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)}, 
  title={Unsupervised Anomaly Detection Based on CNN-VAE with Spectral Residual for KPIs}, 
  year={2022},
  volume={},
  number={},
  pages={1307-1313},
  abstract={Current large-scale applications, such as trading systems, blockchain, social software, etc, are increasingly adopting microservice architecture, which bring challenges to manual operation and maintenance, intrusion detection. In both operations and intrusion detection, there are a common characteristic that service metrics and network traffic are normal for most of the time, but anomaly data is more important. In this paper, we propose an unsupervised anomaly detection algorithm based on convolutional neural network with Spectral Residual, which is verified experimentally and has potential application capability with 19.2% f1-score improvement compared to the Variational AutoEncoder.},
  keywords={},
  doi={10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00204},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10216673,
  author={Jaival, Madhavi and Mkrtchyan, Katya and Kaplan, Adam},
  booktitle={2022 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Serverless Cloud Functions - Opportunity in Chaos}, 
  year={2022},
  volume={},
  number={},
  pages={1330-1335},
  abstract={Due to its cost-effectiveness and limited scope of administration, Serverless Computing has fast become a favorite cloud computing execution model. Meanwhile, with the rise of distributed cloud architectures and microservices in the last decade, many development teams have adopted the principles of Chaos Engineering. This allows them to assess the effects of random failures or delays on an application. In prior literature, serverless developers measured and reported cold-start penalties and transaction latency, whereas Chaos Engineers have studied security and resiliency in cloud infrastructure. In this work, we combine these approaches to measure the performance of a set of serverless cloud functions which implement common server-side file and database operations. We study each function's performance response under a set of controlled chaos experiments, wherein we emulate various client load conditions, as well as inject random delays into the function execution. We find that under heavy 1000-client load, the longest-latency operations can provide as much as 36.5% improvement to overall response time by failing early.},
  keywords={},
  doi={10.1109/CSCI58124.2022.00239},
  ISSN={2769-5654},
  month={Dec},}@INPROCEEDINGS{10175431,
  author={Centofanti, C. and Tiberti, W. and Marotta, A. and Graziosi, F. and Cassioli, D.},
  booktitle={2023 IEEE 9th International Conference on Network Softwarization (NetSoft)}, 
  title={Latency-Aware Kubernetes Scheduling for Microservices Orchestration at the Edge}, 
  year={2023},
  volume={},
  number={},
  pages={426-431},
  abstract={Network and computing infrastructures are nowadays challenged to meet the increasingly stringent requirements of novel applications. One of the most critical aspect is optimizing the latency perceived by the end-user accessing the services. New network architectures offer a natural framework for the efficient orchestration of microservices. However, how to incorporate accurate latency metrics into orchestration decisions still represents an open challenge.In this work we propose a novel architectural approach to perform scheduling operations in Kubernetes environment. Existing approaches proposed the collection of network metrics, e.g. latency between nodes in the cluster, via purposely-built external measurement services deployed in the cluster. Compared to other approaches the proposed one: (i) collects performance metrics at the application layer instead of network layer; (ii) relies on latency measurements performed inside the service of interest instead of utilizing external measurement services; (iii) takes scheduling decisions based on effective end-user perceived latency instead of considering the latency between cluster nodes.We show the effectiveness of our approach by adopting an iterative discovery strategy able to dynamically determine which node operates with the lowest latency for the Kubernetes pod placement.},
  keywords={},
  doi={10.1109/NetSoft57336.2023.10175431},
  ISSN={2693-9789},
  month={June},}@INPROCEEDINGS{9908059,
  author={Leiter, Ákos and Huszti, Dániel and Galambosi, Nándor and Lami, Edina and Salah, Mohamad Saleh and Kulics, Péter and Bokor, László},
  booktitle={2022 13th International Symposium on Communication Systems, Networks and Digital Signal Processing (CSNDSP)}, 
  title={Cloud-native IP-based mobility management: a MIPv6 Home Agent standalone microservice design}, 
  year={2022},
  volume={},
  number={},
  pages={252-257},
  abstract={The ever-increasing traffic and mobility events impose an unprecedented load on mobile networks. Meanwhile, the number of connected users and devices has been growing continuously; hence IPv6 is necessary to serve them. The mobility extension of IPv6 (Mobile IPv6) can also support and handle the rising demand for mobility management in the IP layer. At the same time, concepts like Network Function Virtualization, Software Defined Networks, and microservice architectures have changed the landscape of telecommunication services. In this paper, our prototype implementation is measured and evaluated: what containerization causes in case of different MIPv6-re1ated traffic types on the top of Kubernetes. Additionally, Kubernetes Container Network Interface types are compared for a microservice and container-based standalone Home Agent entity of a cloud-native Mobile IPv6 implementation.},
  keywords={},
  doi={10.1109/CSNDSP54353.2022.9908059},
  ISSN={},
  month={July},}@INPROCEEDINGS{10118016,
  author={Schindewolf, Marc and Grimm, Daniel and Lingor, Christian and Sax, Eric},
  booktitle={2022 IEEE 1st International Conference on Cognitive Mobility (CogMob)}, 
  title={Toward a Resilient Automotive Service-Oriented Architecture by using Dynamic Orchestration}, 
  year={2022},
  volume={},
  number={},
  pages={000147-000154},
  abstract={Modern software development in vehicles is focusing on a service-oriented approach. Structuring software systems into self-sufficient software components that provide specific capabilities to the overall system allow software engineers to make changes to vehicle functions more granularly. The decentralized SOA approach offers advantages, as it enables loose coupling between components instead of statically implementing their relationships. But with the increasing degree of autonomy and dynamism of the vehicle's software, the system's safety and security requirements are also growing. Preventive measures will no longer suffice here; instead, resilient systems are required that provide a minimum level of safety even in the event of an unexpected problem. Today, a SOA's services are assigned to a hardware platform during development and executed there, which lacks being able to react to problems or changing requirements. One possibility for being more flexible at runtime, is the use of an orchestrator, which dynamically allocates resources to services while retaining the advantages of a loosely coupled architecture. This paper proposes a methodology for implementing a resilient vehicular electronic architecture based on orchestrating containerized software. To avoid a single point of failure, a distributed approach for a dynamic orchestrator that deploys the software to appropriate execution platforms is proposed. The orchestrator makes its deployment decisions based on specifiable parameters (e.g., required RAM, GPU) and dependencies between services. The decision process adapts to changes in these factors dynamically, making the system able to react to external influences. The concept differentiates itself from other approaches by tracking dynamic changes to specified parameters and easily extensible interfaces for new parameters or requirements. In addition, the concept introduces a priority metric to describe the impact of services in the system and models how this metric is inherited through dependencies. The concept is evaluated qualitatively by three exemplary use cases, demonstrating the effect of dynamic orchestration on the resilience of the vehicle.},
  keywords={},
  doi={10.1109/CogMob55547.2022.10118016},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9779839,
  author={Serbout, Souhaila and Lauro, Fabio Di and Pautasso, Cesare},
  booktitle={2022 IEEE 19th International Conference on Software Architecture Companion (ICSA-C)}, 
  title={Web APIs Structures and Data Models Analysis}, 
  year={2022},
  volume={},
  number={},
  pages={84-91},
  abstract={Microservice architectures emphasize keeping components small, to foster autonomy, low coupling and independent evolution. In this large-scale empirical study we measure the size of Web API specifications mined from open source repositories. These APIs are modeled using the OpenAPI Specification (OAS), which, in addition to documenting the offered operations, also contain schemas definitions for the data exchanged with the API request and response message payloads. This study has as a goal to build empirical knowledge about: (1) How big and diverse are real-world web APIs both in terms of their operations and data, (2) How different API structures use and reuse schema definitions. By mining public software repositories on Github, we gathered 42,194 valid OAS specifications published between 2014-2021. These specifications include descriptions of Web APIs of well-known services providers such as Google, VMware (Avi Networks), Twilio, Amazon. After measuring the size of API structures and their data model schemas, we found that most APIs are rather small. Also there is a medium correlation between the size of the APIs’ functional structures and their data models. API developers do reuse schema definitions within the same API model.},
  keywords={},
  doi={10.1109/ICSA-C54293.2022.00059},
  ISSN={2768-4288},
  month={March},}@INPROCEEDINGS{10011525,
  author={Ünlü, Hüseyin and Hacaloglu, Tuna and Büber, Fatma and Berrak, Kıvılcım and Leblebici, Onur and Demirörs, Onur},
  booktitle={2022 48th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)}, 
  title={Utilization of Three Software Size Measures for Effort Estimation in Agile World: A Case Study}, 
  year={2022},
  volume={},
  number={},
  pages={239-246},
  abstract={Functional size measurement (FSM) methods, by being systematic and repeatable, are beneficial in the early phases of the software life cycle for core project management activities such as effort, cost, and schedule estimation. However, in agile projects, requirements are kept minimal in the early phases and are detailed over time as the project progresses. This situation makes it challenging to identify measurement components of FSM methods from requirements in the early phases, hence complicates applying FSM in agile projects. In addition, the existing FSM methods are not fully compatible with today’s architectural styles, which are evolving into event-driven decentralized structures. In this study, we present the results of a case study to compare the effectiveness of different size measures: functional -COSMIC Function Points (CFP)-, event-based - Event Points-, and code length-based - Line of Code (LOC)-on projects that were developed with agile methods and utilized a microservice-based architecture. For this purpose, we measured the size of the project and created effort estimation models based on three methods. It is found that the event-based method estimated effort with better accuracy than the CFP and LOC-based methods.},
  keywords={},
  doi={10.1109/SEAA56994.2022.00045},
  ISSN={},
  month={Aug},}@ARTICLE{9758767,
  author={Surantha, Nico and Utomo, Oei K. and Lionel, Earlicha M. and Gozali, Isabella D. and Isa, Sani M.},
  journal={IEEE Access}, 
  title={Intelligent Sleep Monitoring System Based on Microservices and Event-Driven Architecture}, 
  year={2022},
  volume={10},
  number={},
  pages={42069-42080},
  abstract={Sleep monitoring using polysomnography (PSG) in hospitals can be considered expensive, so the preferable way is to use contactless and wearable sensors to monitor sleep daily by patients at home. In this study, the Internet-of-Things (IoT) platform was utilized for sleep monitoring with contactless or wearable sensors as an integrated system developed based on an event-driven and microservice architecture. Multiple services that respond to events are provided within the system. Electrocardiogram (ECG) data were used as the input in the sleep monitoring system. The combination of the weighted extreme learning machine (WELM) algorithm with particle swarm optimization (PSO) was used to process the ECG data, followed by fuzzy logic to measure sleep quality, then display the data on the dashboard. Based on the experimental results, the proposed architecture increased throughput by 34.76%, decreased response time by 55.85%, and reduced memory consumption by 37.26% per instance replication compared to the non-event-driven architecture. The accuracies of the sleep stage classification were 78.78% and 73.09% for the three and four classes, respectively, and the area under a receiver operating characteristic (ROC) curve (AUC) reached 0.89 for both the three and four class classifications.},
  keywords={},
  doi={10.1109/ACCESS.2022.3167637},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9912639,
  author={El Malki, Amine and Zdun, Uwe and Pautasso, Cesare},
  booktitle={2022 IEEE International Conference on Service-Oriented System Engineering (SOSE)}, 
  title={Impact of API Rate Limit on Reliability of Microservices-Based Architectures}, 
  year={2022},
  volume={},
  number={},
  pages={19-28},
  abstract={Many API patterns and best practices have been developed around microservices-based architectures, such as Rate Limiting and Circuit Breaking, to increase quality properties such as reliability, availability, scalability, and performance. Even though estimates on such properties would be beneficial, especially during the early design of such architectures, the real impact of the patterns on these properties has not been rigorously studied yet. This paper focuses on API Rate Limit and its impact on reliability properties from the perspective of API clients. We present an analytical model that considers specific workload configurations and predefined rate limits and then accurately predicts the success and failure rates of the back-end services. The model also presents a method for adaptively fine-tuning rate limits. We performed two extensive data experiments to validate the model and measured Rate Limiting impacts, firstly on a private cloud to minimize latency and other biases, and secondly on the Google Cloud Platform to test our model in a realistic cloud environment. In both experiments, we observed a low percentage of prediction errors. Thus, we conclude that our model can provide distributed system engineers and architects with insights into an acceptable value for the rate limits to choose for a given workload. Very few works empirically studied the impact of Rate Limit or similar API-related patterns on reliability.},
  keywords={},
  doi={10.1109/SOSE55356.2022.00009},
  ISSN={2642-6587},
  month={Aug},}@INPROCEEDINGS{9861873,
  author={Vosteen, Lars and John, Fabian and Schuljak, Joerg and Sievers, Bjoern and Hanemann, Andreas and Hellbrueck, Horst},
  booktitle={Mobile Communication - Technologies and Applications; 26th ITG-Symposium}, 
  title={Practical Security Analysis and Measures for 5G Private Industrial Standalone (SA) Deployments}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={The standardization of the fifth generation of mobile communications has been completed, and the expansion of the 5G system is currently being driven forward. In addition to public mobile networks, the 5G mobile network standard foresees privately operated systems. Private 5G systems are started to be deployed and operated in industrial and academic environments using off-the-shelf components like standard computing hardware, software-defined radios, and open-source software with costs below 10k EUR. 5G systems are extensible and scalable due to the service-oriented architecture of the distributed 5G system. Especially in industrial deployment, the demand for security of networks is high, for example, to protect in-house data. In this paper, we present a security analysis for 5G systems from different possible attack points from the operator’s perspective. We conduct selected attacks to highlight and demonstrate weakness on our private indoor 5G testbed at the University of Applied Sciences in Lübeck. From the results of the security analysis and attacks, we derive measures to improve the security of the 5G system. Finally, we verify the effectiveness of the measures by additional tests.},
  keywords={},
  doi={},
  ISSN={},
  month={May},}@INPROCEEDINGS{10334274,
  author={Beingolea, Jorge R. and Zegarra, Milagros and Bolivar, Renzo and Rendulich, Jorge and Borja-Murillo, Juan},
  booktitle={2023 IEEE Colombian Conference on Communications and Computing (COLCOM)}, 
  title={Heterogeneous Devices: Network Layer Integration Experience}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The work proposes the development of an integration architecture for highly heterogeneous sensor network ecosystems. The implementation is carried out on a device called the “integration device”. The device functions as a management and abstraction layer, integrated with the communication and data layer of a service-oriented middleware. The integration device controls real-time events through the programming of thread groups, which have the role of managing and abstracting the heterogeneity of data and communication protocols of wireless sensor devices. A part of the integration device implementation is presented, and data transfer rate experiments are conducted to measure its performance.},
  keywords={},
  doi={10.1109/COLCOM59909.2023.10334274},
  ISSN={2771-568X},
  month={July},}@INPROCEEDINGS{10044743,
  author={Yensabai, Chavapol and Ngoenthai, Waranyu and Leangarun, Teema and Koolpiruck, Diew},
  booktitle={2023 Third International Symposium on Instrumentation, Control, Artificial Intelligence, and Robotics (ICA-SYMP)}, 
  title={Digital Retail Shop Services in Cyber-Physical Retail System: A Case Study of Food Business}, 
  year={2023},
  volume={},
  number={},
  pages={61-64},
  abstract={Food demand is expected to grow substantially as a result of major factors such as population. It necessitates that food manufacturers streamline their supply chain to accommodate shorter product life cycles. To manage sustainable food solutions and successful supply chain management, cyber-physical systems at the supply chain level attempt to challenge the integration of data from suppliers, manufacturing, logistics, and retail. The implementation of Cyber-Physical Retail Systems (CPRS) was developed to sense and analyze dynamic market environments to modify sales and shop operation activities. The data were collected from several ERP modules and operational technology (OT) data. The shop CPS was managed using the OSIsoft-PI platform, which is based on service-oriented architecture (SOA) and then integrated into the Enterprise Cloud. The customer analytics service in CPRS was used as an example of a self-aware concept to notify the sales function and was implemented on the Azure platform. The results show that churn prediction in retail shops can be detected monthly for warning sales staff based on the customer object goal. The models that were used are RF, LR and GBC. The overall performance of GBC outperforms all measures with 78.05% accuracy. While the remaining were around 65%.},
  keywords={},
  doi={10.1109/ICA-SYMP56348.2023.10044743},
  ISSN={},
  month={Jan},}@ARTICLE{8851303,
  author={Cabrera, Christian and Clarke, Siobhán},
  journal={IEEE Transactions on Services Computing}, 
  title={A Self-Adaptive Service Discovery Model for Smart Cities}, 
  year={2022},
  volume={15},
  number={1},
  pages={386-399},
  abstract={City services are frequently supported by software services that are managed by service-oriented architectures. However, a large number of software services is likely to cause performance issues when discovering software services. The distributed organisation of services information improves discovery performance. Existing research proposes to organise services information according to service location, domains, or city context, keeping that organisation constant under an assumption that cities do not change. However, cities are dynamic environments where entities interact, causing events that in turn, effect changes in the city. The organisation of services information must evolve or it will become outdated, negatively impacting discovery performance. We propose a self-adaptive service model for smart cities to support service discovery. This model adapts the organisation of services information according to city events. We introduce a self-adaptive architecture that keeps track of the discovery metrics and moves information about services between registries to maintain the discovery efficiency. We evaluate the proposed model in simulated environments and a real IoT testbed. Results show that our model outperforms competitors when reactive adaptation is triggered by a specific event. However, proactive adaptation needs further research. Results from the real IoT testbed present the costs of the proposed model.},
  keywords={},
  doi={10.1109/TSC.2019.2944356},
  ISSN={1939-1374},
  month={Jan},}@INPROCEEDINGS{9796395,
  author={Paleyes, Andrei and Cabrera, Christian and Lawrence, Neil D.},
  booktitle={2022 IEEE/ACM 1st International Conference on AI Engineering – Software Engineering for AI (CAIN)}, 
  title={An Empirical Evaluation of Flow Based Programming in the Machine Learning Deployment Context}, 
  year={2022},
  volume={},
  number={},
  pages={54-64},
  abstract={As use of data driven technologies spreads, software engineers are more often faced with the task of solving a business problem using data-driven methods such as machine learning (ML) algorithms. Deployment of ML within large software systems brings new challenges that are not addressed by standard engineering practices and as a result businesses observe high rate of ML deployment project failures. Data Oriented Architecture (DOA) is an emerging approach that can support data scientists and software developers when addressing such challenges. However, there is a lack of clarity about how DOA systems should be implemented in practice. This paper proposes to consider Flow-Based Programming (FBP) as a paradigm for creating DOA applications. We empirically evaluate FBP in the context of ML deployment on four applications that represent typical data science projects. We use Service Oriented Architecture (SOA) as a baseline for comparison. Evaluation is done with respect to different application domains, ML deployment stages, and code quality metrics. Results reveal that FBP is a suitable paradigm for data collection and data science tasks, and is able to simplify data collection and discovery when compared with SOA. We discuss the advantages of FBP as well as the gaps that need to be addressed to increase FBP adoption as a standard design paradigm for DOA. CCS CONCEPTS • Software and its engineering → Software design tradeoffs; • Computing methodologies → Machine learning.},
  keywords={},
  doi={10.1145/3522664.3528601},
  ISSN={},
  month={May},}@ARTICLE{8936375,
  author={Sun, Chang-ai and Dai, Hepeng and Wang, Guan and Towey, Dave and Chen, Tsong Yueh and Cai, Kai-Yuan},
  journal={IEEE Transactions on Services Computing}, 
  title={Dynamic Random Testing of Web Services: A Methodology and Evaluation}, 
  year={2022},
  volume={15},
  number={2},
  pages={736-751},
  abstract={In recent years, service oriented architecture (SOA) has been increasingly adopted to develop distributed applications in the context of the Internet. To develop reliable SOA-based applications, an important issue is how to ensure the quality of web services. In this article, we propose a dynamic random testing (DRT) technique for web services, which is an improvement over the widely-practiced random testing (RT) and partition testing (PT) approaches. We examine key issues when adapting DRT to the context of SOA, including a framework, guidelines for parameter settings, and a prototype for such an adaptation. Empirical studies are reported where DRT is used to test three real-life web services, and mutation analysis is employed to measure the effectiveness. Our experimental results show that, compared with the three baseline techniques, RT, Adaptive Testing (AT) and Random Partition Testing (RPT), DRT demonstrates higher fault-detection effectiveness with a lower test case selection overhead. Furthermore, the theoretical guidelines of parameter setting for DRT are confirmed to be effective. The proposed DRT and the prototype provide an effective and efficient approach for testing web services.},
  keywords={},
  doi={10.1109/TSC.2019.2960496},
  ISSN={1939-1374},
  month={March},}@ARTICLE{9222262,
  author={Wang, Chen and Ma, Hui and Chen, Gang and Hartmann, Sven and Branke, J&#x00FC;rgen},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, 
  title={Robustness Estimation and Optimisation for Semantic Web Service Composition With Stochastic Service Failures}, 
  year={2022},
  volume={6},
  number={1},
  pages={77-92},
  abstract={Service-oriented architecture (SOA) is a widely adopted software engineering paradigm that encourages modular and reusable applications. One popular application of SOA is web service composition, which aims to loosely couple web services to accommodate complex goals not achievable through any individual web service. Many approaches have been proposed to construct composite services with optimized Quality of Service (QoS), assuming that QoS of web services never changes. However, the constructed composite services may not perform well and may not be executable later due to its component services' failure. Therefore, it is important to build composite services that are robust to stochastic service failures. Two challenges of building robust composite services are to efficiently generate service composition with near-optimal quality in a large search space of available services and to accurately measure the robustness of composite services considering all possible failure scenarios. This article proposes a novel two-stage GA-based approach to robust web service composition with an adaptive evolutionary control and an efficient robustness measurement. This approach can generate robust composite service at the design phase, which can cope with stochastic service failures and maintain high quality at the time of execution. We have conducted experiments with benchmark datasets to evaluate the performance of our proposed approach. Our experiments show that our method can produce highly robust composite services, achieving outstanding performance consistently in the event of stochastic service failures, on service repositories with varying sizes.},
  keywords={},
  doi={10.1109/TETCI.2020.3027870},
  ISSN={2471-285X},
  month={Feb},}@ARTICLE{9463396,
  author={Chen, Jeng-Chung and Chen, Chun-Chih and Shen, Chih-Hsiung and Chen, Ho-Wen},
  journal={IEEE Internet of Things Journal}, 
  title={User Integration in Two IoT Sustainable Services by Evaluation Grid Method}, 
  year={2022},
  volume={9},
  number={3},
  pages={2242-2252},
  abstract={To meet the need for sustainable development, Taiwan has been spreading a network of micro-monitoring stations to measure the environmental quality in rivers and air to protect people from environmental pollution. As a result, more and more information technology companies develop Internet of Things (IoT) services for this job. However, most IoT services are screened out of the market because lacking design thinking. Therefore, including users’ desires in IoT products and services is a critical determinant for their survival in this permanently changing market. Thus, this study proposed a systematic framework to identify the users’ desires from different stakeholders to determine technological development. For this, we use the evaluation grid method (EGM) to explore the users’ desires by a series of in-depth interviews and visualize the user’s response as a hierarchical evaluation map of attraction. After that, an IoT prototype is built and used to capture the insightful feedback of respondents. Meanwhile, we adopt the minimum viable product (MVP) design principles to develop two prototypes that manage a wastewater treatment plant and household environment. Overall, this study proposes an applicable user integration procedure to help IT engineers develop the IoT for sustainable service. This study also confirms that the MVP method can help to accelerate user integration. We propose a service-oriented IoT architecture in technology development and develop a decision-making service of human dispatch in operating environmental facilities and a context-awareness service for environmental control.},
  keywords={},
  doi={10.1109/JIOT.2021.3091688},
  ISSN={2327-4662},
  month={Feb},}

@INPROCEEDINGS{8477218,
  author={Li, Keqin},
  booktitle={2018 IEEE 16th International Conference on Software Engineering Research, Management and Applications (SERA)}, 
  title={Quantitative Modeling and Analytical Calculation of Elasticity in Cloud Computing}, 
  year={2018},
  volume={},
  number={},
  pages={3-3},
  abstract={Elasticity is a fundamental feature of cloud computing and can be considered as a great advantage and a key benefit of cloud computing. Our research makes the following significant contributions. First, we present a new, quantitative, and formal definition of elasticity in cloud computing, i.e., the probability that the computing resources provided by a cloud platform match the current workload. Our definition is applicable to any cloud platform and can be easily measured and monitored. Furthermore, we develop an analytical model to study elasticity by treating a cloud platform as a queueing system, and use a continuous-time Markov chain (CTMC) model to precisely calculate the elasticity value of a cloud platform by using an analytical and numerical method based on just a few parameters, namely, the task arrival rate, the service rate, the virtual machine start-up and shut-down rates. In addition, we formally define auto-scaling schemes and point out that our model and method can be easily extended to handle arbitrarily sophisticated scaling schemes. Second, we apply our model and method to predict many other important properties of an elastic cloud computing system, such as average task response time, throughput, quality of service, average number of VMs, average number of busy VMs, utilization, cost, cost-performance ratio, productivity, and scalability. In fact, from a cloud consumer's point of view, these performance and cost metrics are even more important than the elasticity metric. Ourperformance and cost guarantee using the results developed in this talk. On the other hand, a cloud service provider can optimize its elastic scaling scheme to deliver the best cost-performance ratio. study in this talk has two significance. On one hand, a cloud service provider can predict its To the best of our knowledge, this is the first work that analytically and comprehensively studies elasticity, performance, and cost in cloud computing. Our model and method significantly contribute to the understanding of cloud elasticity and management of elastic cloud computing systems.},
  keywords={},
  doi={10.1109/SERA.2018.8477218},
  ISSN={},
  month={June},}@INPROCEEDINGS{8477227,
  author={Li, Keqin},
  booktitle={2018 IEEE 16th International Conference on Software Engineering Research, Management and Applications (SERA)}, 
  title={Quantitative Modeling and Analytical Calculation of Elasticity in Cloud Computing}, 
  year={2018},
  volume={},
  number={},
  pages={3-3},
  abstract={Elasticity is a fundamental feature of cloud computing and can be considered as a great advantage and a key benefit of cloud computing. Our research makes the following significant contributions. First, we present a new, quantitative, and formal definition of elasticity in cloud computing, i.e., the probability that the computing resources provided by a cloud platform match the current workload. Our definition is applicable to any cloud platform and can be easily measured and monitored. Furthermore, we develop an analytical model to study elasticity by treating a cloud platform as a queueing system, and use a continuous-time Markov chain (CTMC) model to precisely calculate the elasticity value of a cloud platform by using an analytical and numerical method based on just a few parameters, namely, the task arrival rate, the service rate, the virtual machine start-up and shut-down rates. In addition, we formally define auto-scaling schemes and point out that our model and method can be easily extended to handle arbitrarily sophisticated scaling schemes. Second, we apply our model and method to predict many other important properties of an elastic cloud computing system, such as average task response time, throughput, quality of service, average number of VMs, average number of busy VMs, utilization, cost, cost-performance ratio, productivity, and scalability. In fact, from a cloud consumer's point of view, these performance and cost metrics are even more important than the elasticity metric. Ourperformance and cost guarantee using the results developed in this talk. On the other hand, a cloud service provider can optimize its elastic scaling scheme to deliver the best cost-performance ratio. study in this talk has two significance. On one hand, a cloud service provider can predict its To the best of our knowledge, this is the first work that analytically and comprehensively studies elasticity, performance, and cost in cloud computing. Our model and method significantly contribute to the understanding of cloud elasticity and management of elastic cloud computing systems.},
  keywords={},
  doi={10.1109/SERA.2018.8477227},
  ISSN={},
  month={June},}@INPROCEEDINGS{7450805,
  author={Lehrig, Sebastian and Eikerling, Hendrik and Becker, Steffen},
  booktitle={2015 11th International ACM SIGSOFT Conference on Quality of Software Architectures (QoSA)}, 
  title={Scalability, elasticity, and efficiency in cloud computing: A systematic literature review of definitions and metrics}, 
  year={2015},
  volume={},
  number={},
  pages={83-92},
  abstract={Context In cloud computing, there is a multitude of definitions and metrics for scalability, elasticity, and efficiency. However, stakeholders have little guidance for choosing fitting definitions and metrics for these quality properties, thus leading to potential misunderstandings. For example, cloud consumers and providers cannot negotiate reliable and quantitative service level objectives directly understood by each stakeholder. Objectives Therefore, we examine existing definitions and metrics for these quality properties from the viewpoint of cloud consumers, cloud providers, and software architects with regard to commonly used concepts. Methods We execute a systematic literature review (SLR), reproducibly collecting common concepts in definitions and metrics for scalability, elasticity, and efficiency. As quality selection criteria, we assess whether existing literature differentiates the three properties, exemplifies metrics, and considers typical cloud characteristics and cloud roles. Results Our SLR yields 418 initial results from which we select 20 for in-depth evaluation based on our quality selection criteria. In our evaluation, we recommend concepts, definitions, and metrics for each property. Conclusions Software architects can use our recommendations to analyze the quality of cloud computing applications. Cloud providers and cloud consumers can specify service level objectives based on our metric suggestions.},
  keywords={},
  doi={10.1145/2737182.2737185},
  ISSN={},
  month={May},}@INPROCEEDINGS{7207388,
  author={Zhou, Nianjun and Mohindra, Ajay},
  booktitle={2015 IEEE International Conference on Services Computing}, 
  title={Causality-Driven Performance Monitoring and Scaling Automation for Managed Solutions}, 
  year={2015},
  volume={},
  number={},
  pages={467-474},
  abstract={A key feature of Cloud computing is its agility and flexibility to support the scalability needs of business solutions. Currently, the agility is only limited to the scalability of the compute, memory and storage. To improve an application's agility, we need to monitor & measure solution level metrics and associate the performance of the metrics to the business agility needs of the solution by making real-time scalability or change decisions. In this paper, we illustrate a scaling decision mechanism utilizing the monitoring data from infrastructure, middleware, and business level metrics. We use these performance metrics as input to a causality analysis model to make architecture changes or scalability decisions. Mathematically, we define the causality as a graph to link the changes in the measured metric values to the action of the solution change. The causality analysis follows scalability principles as best practices. They are a) the principle of performance scalability b) principle of contribution margin for scalability, and c) principle of the least cost of SLA compliance. We define these scalability principles as the rules to ensure that the business stakeholder of the solution can maintain or improve their business quality or profit margins as the computing capability scales up or down. To implement those principles, we need to establish the linkages of the business metrics to the decision of changes. To make such linkage, we first utilize causality analysis to identify feasible scaling actions, and then associate those actions with the system, application, and business performance metrics. With the help of causality analysis, we implement a performance monitoring and scaling automation framework for managed solutions using an Open Source Monitoring system.},
  keywords={},
  doi={10.1109/SCC.2015.70},
  ISSN={},
  month={June},}@ARTICLE{9139920,
  author={Guerron, Ximena and Abrahão, Silvia and Insfran, Emilio and Fernández-Diego, Marta and González-Ladrón-De-Guevara, Fernando},
  journal={IEEE Access}, 
  title={A Taxonomy of Quality Metrics for Cloud Services}, 
  year={2020},
  volume={8},
  number={},
  pages={131461-131498},
  abstract={A large number of metrics with which to assess the quality of cloud services have been proposed over the last years. However, this knowledge is still dispersed, and stakeholders have little or no guidance when choosing metrics that will be suitable to evaluate their cloud services. The objective of this paper is, therefore, to systematically identify, taxonomically classify, and compare existing quality of service (QoS) metrics in the cloud computing domain. We conducted a systematic literature review of 84 studies selected from a set of 4333 studies that were published from 2006 to November 2018. We specifically identified 470 metric operationalizations that were then classified using a taxonomy, which is also introduced in this paper. The data extracted from the metrics were subsequently analyzed using thematic analysis. The findings indicated that most metrics evaluate quality attributes related to performance efficiency (64%) and that there is a need for metrics that evaluate other characteristics, such as security and compatibility. The majority of the metrics are used during the Operation phase of the cloud services and are applied to the running service. Our results also revealed that metrics for cloud services are still in the early stages of maturity - only 10% of the metrics had been empirically validated. The proposed taxonomy can be used by practitioners as a guideline when specifying service level objectives or deciding which metric is best suited to the evaluation of their cloud services, and by researchers as a comprehensive quality framework in which to evaluate their approaches.},
  keywords={},
  doi={10.1109/ACCESS.2020.3009079},
  ISSN={2169-3536},
  month={},}@ARTICLE{7153530,
  author={Zhao, Feng and Nian, Guodong and Jin, Hai and Yang, Laurence T. and Zhu, Yajun},
  journal={IEEE Systems Journal}, 
  title={A Hybrid eBusiness Software Metrics Framework for Decision Making in Cloud Computing Environment}, 
  year={2017},
  volume={11},
  number={2},
  pages={1049-1059},
  abstract={Developing high-quality software is essential for eBusiness organizations to cope with drastic market competition. With the development of cloud computing technologies, eBusiness systems and applications pay more attention to open endedness. In a cloud computing environment, eBusiness systems have the ability to provide information technology resources on demand. Traditional software metric methods in distributed systems and applications are technical and project driven, making the market demand and internal practical operation not perfectly balanced within a cloud-computing-based eBusiness corporation. To address this issue, this paper presents a hybrid framework based on the goal/question/metric paradigm to evaluate the quality and efficiency of previous software products, projects, and development organizations in a cloud computing environment. In our approach, to support decision making at the project and organization levels, three angular metrics are used, i.e., project metrics, product metrics, and organization metrics. Furthermore, an improved radial-basis-function-based model is also provided to manage existing projects and design new projects. Experimental results on a well-known eBusiness organization show that the proposed framework is effective, efficient, and operational. Moreover, using the described decision-making algorithm, the predicted data are very close to actual results on the software cost, the fault rate, the development workload, etc., which are greatly helpful in achieving high-quality software.},
  keywords={},
  doi={10.1109/JSYST.2015.2443049},
  ISSN={1937-9234},
  month={June},}@ARTICLE{7845614,
  author={Li, Keqin},
  journal={IEEE Transactions on Cloud Computing}, 
  title={Quantitative Modeling and Analytical Calculation of Elasticity in Cloud Computing}, 
  year={2020},
  volume={8},
  number={4},
  pages={1135-1148},
  abstract={Elasticity is a fundamental feature of cloud computing and can be considered as a great advantage and a key benefit of cloud computing. One key challenge in cloud elasticity is lack of consensus on a quantifiable, measurable, observable, and calculable definition of elasticity and systematic approaches to modeling, quantifying, analyzing, and predicting elasticity. Another key challenge in cloud computing is lack of effective ways for prediction and optimization of performance and cost in an elastic cloud platform. The present paper makes the following significant contributions. First, we present a new, quantitative, and formal definition of elasticity in cloud computing, i.e., the probability that the computing resources provided by a cloud platform match the current workload. Our definition is applicable to any cloud platform and can be easily measured and monitored. Furthermore, we develop an analytical model to study elasticity by treating a cloud platform as a queueing system, and use a continuous-time Markov chain (CTMC) model to precisely calculate the elasticity value of a cloud platform by using an analytical and numerical method based on just a few parameters, namely, the task arrival rate, the service rate, the virtual machine start-up and shut-down rates. In addition, we formally define auto-scaling schemes and point out that our model and method can be easily extended to handle arbitrarily sophisticated scaling schemes. Second, we apply our model and method to predict many other important properties of an elastic cloud computing system, such as average task response time, throughput, quality of service, average number of VMs, average number of busy VMs, utilization, cost, cost-performance ratio, productivity, and scalability. In fact, from a cloud consumer's point of view, these performance and cost metrics are even more important than the elasticity metric. Our study in this paper has two significance. On one hand, a cloud service provider can predict its performance and cost guarantee using the results developed in this paper. On the other hand, a cloud service provider can optimize its elastic scaling scheme to deliver the best cost-performance ratio. To the best of our knowledge, this is the first paper that analytically and comprehensively studies elasticity, performance, and cost in cloud computing. Our model and method significantly contribute to the understanding of cloud elasticity and management of elastic cloud computing systems.},
  keywords={},
  doi={10.1109/TCC.2017.2665549},
  ISSN={2168-7161},
  month={Oct},}@INPROCEEDINGS{8613297,
  author={Al-Said Ahmad, Amro and Andras, Peter},
  booktitle={2018 Fifth International Symposium on Innovation in Information and Communication Technology (ISIICT)}, 
  title={Measuring and Testing the Scalability of Cloud-based Software Services}, 
  year={2018},
  volume={},
  number={},
  pages={1-8},
  abstract={Performance and scalability testing and measurements of cloud-based software services are critically important in the context of rapid growth of cloud computing and supporting the delivery of these services. Cloud-based software services performance aspects are interrelated, both elasticity and efficiency are depending on the delivery of a sufficient level of scalability performance. In this work, we focused on testing and measuring the scalability of cloud-based software services in technical terms. This paper uses technical scalability metrics that address both volume and quality scaling, that inspired by earlier technical metrics of elasticity. We show how our technical scalability metrics can be integrated into an earlier utility oriented metric of scalability. We demonstrate the application of the metrics using a practical example and discuss the importance of them.},
  keywords={},
  doi={10.1109/ISIICT.2018.8613297},
  ISSN={},
  month={Oct},}@ARTICLE{8391708,
  author={Xu, Han and Qiu, Xiwei and Sheng, Yongpan and Luo, Liang and Xiang, Yanping},
  journal={IEEE Access}, 
  title={A Qos-Driven Approach to the Cloud Service Addressing Attributes of Security}, 
  year={2018},
  volume={6},
  number={},
  pages={34477-34487},
  abstract={Recently, cloud computing has been widely used by relying on its powerful resource integration and computing abilities. In the cloud computing system (CCS), the quality of service (QoS) is an important service evaluation criterion from provider and client perspectives, which directly affects the client experience and profit of the cloud providers. Thus, a precise evaluation of the QoS can help the cloud provider develop reasonable resource allocation strategies for improving the client experience. The performance metric is usually adopted to quantify QoS. Many approaches and methods for evaluating performance have been widely studied. However, another important metric, i.e., security, does not receive adequate attention in the evaluation of QoS. More importantly, security also has serious effects on the performance metric, that is, complex security-performance (S-P) correlations. To address these issues, this paper first builds a Markov model to analyze and assess the security of the CCS that captures two critical security factors, i.e., malicious attacks and the security protection mechanism. Then, a hierarchical modeling approach is presented to flexibly build the connection between security and the service performance. Finally, we propose a correlation metric to quantify random service performance. This correlation metric comprehensively considers the effect of the security factors and thus becomes more realistic and precise. The experimental results reveal the dynamic change of performance caused by the security factors and demonstrate the important S-P correlation. Therefore, security cannot be ignored in the modeling and evaluation of the QoS metric.},
  keywords={},
  doi={10.1109/ACCESS.2018.2849594},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{6968746,
  author={Poggi, Nicolas and Carrera, David and Ayguadé, Eduard and Torres, Jordi},
  booktitle={2014 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={POSTER: Profit-aware cloud resource provisioner for ecommerce}, 
  year={2014},
  volume={},
  number={},
  pages={274-275},
  abstract={In recent years, the Cloud Computing paradigm has proven effective in scaling dynamically the number of servers according to simple performance metrics and the incoming workload. However while some applications are able to scale-out, as current scaling metrics do not relate system performance to sales, hosting costs and profits are not optimized completely. The following article proposes a novel technique for dynamic resource provisioning based on revenue and cost metrics, to optimize profits for online retailers in the Cloud. The proposal relies on user behavior models that relate Quality-of-Service (QoS) to service capacity, and to the intention of users to buy a product on an Ecommerce site. We show how such metrics can enable profit-aware resource management by setting an optimal number of servers at each time of the day. Experiments are performed on custom, real-life datasets from an Ecommerce retailer contain over two years of access, performance, and sales data from popular travelWeb applications.},
  keywords={},
  doi={10.1109/CLUSTER.2014.6968746},
  ISSN={2168-9253},
  month={Sep.},}@INPROCEEDINGS{9719517,
  author={Nayak, Samaleswari Prasad and Rout, Suchismita and Das, Surajit and Patra, Sudhansu Shekhar},
  booktitle={2021 19th OITS International Conference on Information Technology (OCIT)}, 
  title={Error rate reduction of Air Quality Parameters in Health Care Industry using SD-IoT Environment}, 
  year={2021},
  volume={},
  number={},
  pages={454-459},
  abstract={The air quality index has a major impact on the health of a person. This parameter must be carefully monitored to take all the necessary arrangements to improve the environmental conditions. The error rate must be minimized for accurate data collection and processing. In this paper, an IoT -based air quality platform is designed with the name ‘'IAQM (Industry Air Quality Monitoring)”. This platform relies on IoT, SDN, and Cloud computing technology to monitor the air quality of the health care industry. Apart from the health care sector, this system can be used anywhere and anytime. We measure its performance metrics with existing AQMS. IAQM gives better performance than the existing approach as per the resultant graphs.},
  keywords={},
  doi={10.1109/OCIT53463.2021.00094},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8343082,
  author={Ibrahim, Abdallah A. Z. A. and Varrette, Sebastien and Bouvry, Pascal},
  booktitle={2018 International Conference on Information Networking (ICOIN)}, 
  title={PRESENCE: Toward a novel approach for performance evaluation of mobile cloud SaaS Web Services}, 
  year={2018},
  volume={},
  number={},
  pages={50-55},
  abstract={Cloud Services Providers (CSPs) deliver cloud services to cloud customers on a pay-per-use model. The quality of the provided services are defined using Service Level Agreements (SLAs). The recent developments around edge computing and the advent of mobile cloud computing platforms contribute to the success of this approach and the multiplication of offers. Unfortunately, despite the projections foreseeing a growing market for the coming years, there is no standard mechanism which exists to verify and assure that delivered services satisfy the signed SLA agreement. Accurate measures of the provided Quality of Service (QoS) is also missing most of time. In this context, we aim at offering an automatic framework named PRESENCE, to evaluate the QoS and SLA compliance of Web Services (WSs) offered across several CSPs. PRESENCE aims at quantifying in a fair and by stealth way the performance and scalability of the delivered WS. By stealthiness, we refer to the capacity of evaluating a given Cloud service by orchestrating multiple workload patterns that making them indistinguishable from a regular user traffic from the provider point of view. PRESENCE defines a set of Common performance metrics handled by a set of agents within a customized client (called the Auditor) for measuring the behaviour of cloud applications on top of a given CSP. This position paper offers a description of the PRESENCE framework, and the way each modules are foreseen to be designed. This opens novel perspectives for assessing the SLA compliance of Cloud providers using the PRESENCE framework.},
  keywords={},
  doi={10.1109/ICOIN.2018.8343082},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{7913123,
  author={Khurana, Ravi and Bawa, Rajesh Kumar},
  booktitle={2016 Fourth International Conference on Parallel, Distributed and Grid Computing (PDGC)}, 
  title={Quality based cloud simulators: State-of-the-art & road ahead}, 
  year={2016},
  volume={},
  number={},
  pages={101-106},
  abstract={Cloud Computing is an emerging technology nowadays. It has been used by many leading organisations. They deploy their critical information onto the cloud. Several challenges are associated with it like quality issues, security, energy consumption etc. Continuous research is going on to cater these issues. It is not easy to setup a cloud for any researcher or group of researchers, it needs huge investment. Big organisations having huge budgets can only afford that. To address these issues cloud simulators are really helpful. Cloud simulator is a simulating environment through which one can realize actual cloud environment. Data centers, virtual machines, hosts and networks can be setup virtually. Numbers of cloud simulators are there in the literature each offering different scenario. Cloudsim, a well known cloud simulator calculates start time, finish time and total time for execution of cloudlet. Another cloud simulator GreenCloud calculates energy consumption by data centers, hosts, switches and other network equipments. In the present paper, we focus on quality metrics addressed by cloud simulators. With each simulator, we will enlist quality metrics discussed by them. At the end, we conclude that there is a need to develop simulator which will address relevant quality metrics.},
  keywords={},
  doi={10.1109/PDGC.2016.7913123},
  ISSN={},
  month={Dec},}@ARTICLE{9220139,
  author={Feng, Jie Xu and Si, Guannan and Zhou, Fengyu},
  journal={IEEE Access}, 
  title={Overview and Framework of Quality Service Metrics for Cloud-Based Robotics Platforms}, 
  year={2020},
  volume={8},
  number={},
  pages={185885-185898},
  abstract={With the rapid development of big data, cloud computing and other technologies, Cloud-based robotic has become one of the key research directions for service robot, such as used in hospitals. A framework and set of metrics for evaluating the quality of service (QOS) of a cloud robotic platform would be greatly facilitate research into and actual practice of service robots. In this paper, a QOS metrics framework of cloud robotic computing is summarized and the research of components and metrics of a cloud robotic platform is reviewed. QOS metrics are organized into software, network, and robotic services. By summarizing and analyzing the above three groups of metrics, a QOS framework or index system is proposed. Finally, future research towards open source and standardization of components of robotic cloud platform is discussed.},
  keywords={},
  doi={10.1109/ACCESS.2020.3030069},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8058324,
  author={Upadhyaya, Jolly and Ahuja, Neelu Jyoti},
  booktitle={2017 International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)}, 
  title={Quality of service in cloud computing in higher education: A critical survey and innovative model}, 
  year={2017},
  volume={},
  number={},
  pages={137-140},
  abstract={Cloud Computing, an emerging trend, in the e-learning sector has attracted number of service providers to the market in very less time, providing users with several applications at their disposal. However, while providing such service, not sufficient importance is given to the quality of the service, especially from the user's point of view. Hence it becomes necessary to monitor, track and quantify the QoS of the cloud computing e-learning applications in order to provide the right information to both the customers and the service providers. This information would help both the parties in terms of the comparison between the expectations and the capacity to meet them, but in this sector there is no standard model which defines the QoS parameters from the user's point of view. Thus, the need arises for developing a metrics model for enhancing the quality of service in cloud computing e-learning applications for higher education sector. In the current work, Quality of Service models are studied and comprehensive review of work done in this field is presented. Additionally an innovative QoS model for resolving this issue has been suggested.},
  keywords={},
  doi={10.1109/I-SMAC.2017.8058324},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{8389549,
  author={Geetha, P. and Robin, C.R. Rene},
  booktitle={2017 International Conference on Energy, Communication, Data Analytics and Soft Computing (ICECDS)}, 
  title={A comparative-study of load-cloud balancing algorithms in cloud environments}, 
  year={2017},
  volume={},
  number={},
  pages={806-810},
  abstract={The enrichment knowledge of Cloud Computing is Green Cloud Computing. The term of Cloud Computing is a globally inter — connected networks of Computing Resources( Servers, Networks, Applications, Hardwares, Softwares). The Green Computing is an Environmental Benefits of eco-friendly usage of Computing Resources. The combination of Green Computing and Cloud computing is Green Cloud Computing. GCC performs both performance and efficiency. The combination of Mobile Computing and Cloud Computing is known as Mobile Cloud Computing. Now, the Computational science is changing to be data-intensive. So, Load balancing is a technique to distribute the load across a given Green Cloud Network Vs Mobile Cloud Network. In this proposed system, the in-depth analysis of Load Balancing Algorithms. The Load of Cloud Balancing is a process of reassigning the total load to the individual nodes in a given network. Then the Comparative study of load balancing algorithms with its quality metrics are summarized.},
  keywords={},
  doi={10.1109/ICECDS.2017.8389549},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8467224,
  author={Dhirani, Lubna Luxmi and Newe, Thomas and Nizamani, Shahzad},
  booktitle={2018 5th International Multi-Topic ICT Conference (IMTIC)}, 
  title={Hybrid Cloud Computing QoS Glitches}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={The Hybrid Cloud Computing model has been growing extensively due to its Infrastructure as a Service (IaaS) architecture, customisation and cost benefits. The hybrid cloud services are measured based on the Quality of Service parameters defined by the public cloud vendors. These parameters (i.e. availability, scalability, latency etc.) vary from vendor-to-vendor, developing complexity and confusion on the grounds of methods of service assessments. A Cloud Service Level Agreement (SLA) lists the QoS provisions to be provided to the tenant, the objectives, and exclusions. Regardless of vendors promised uptimes and service metrics, the tenants are susceptible to the following threats: data governance, Denial of Services, multi-tenancy, etc. Cloud computing has often been compared as a utility, but the basic different between a utility and the cloud is the amount of risk involved with data protection, provisioning and control. Few cloud standards have been developed for standardizing the hybrid cloud model but since each public cloud vendor provides different applications and services, these standards do not resolve the existing cloud QoS issue. Since each enterprise implementing the cloud and vendor supplying the services is diverse, a customized Trio (Cloud-IT-Business) QoS model is required to resolve the business need. The authors have designed a model to resolve this existing cloud QoS issue, the abstraction of the model is detailed in this paper.},
  keywords={},
  doi={10.1109/IMTIC.2018.8467224},
  ISSN={},
  month={April},}@INPROCEEDINGS{8611562,
  author={Shin, Young-Rok and Son, A-Young and Jo, Hyeok Kyun and Huh, Eui-Nam},
  booktitle={2018 Second World Conference on Smart Trends in Systems, Security and Sustainability (WorldS4)}, 
  title={Cloud Service Broker Based Quality Metrics Integration Model for Mobile Environment}, 
  year={2018},
  volume={},
  number={},
  pages={254-259},
  abstract={Mobile cloud computing is high technology that extends existing IT capabilities and requirements. And it can also access to shareable remote computing resources pool through the network. As the concept of mobile cloud, many providers have served the mobile cloud services using their own service policies. In other words, there is no formal definition of quality criteria for mobile cloud service evaluation. To solve this problem, some quality models are proposed for cloud service evaluation. However, those did not include many metrics to evaluate the services. Even if the model included a number of criteria, it is difficult to identify whether the metrics are proper or not. Furthermore, most existing models were not concerned about mobile characteristics. Therefore, we propose a cloud service integration model to solve the problem as we mentioned above. First, we select additional metrics to satisfy the mobile characteristics. Second, we present an extended SLA model for modeling complex service-dependencies in mobile cloud services. Third, we describe a method of discovering relations between the metrics of service belonging to mobile cloud services and then using these relations for establishing newly generated SLA.},
  keywords={},
  doi={10.1109/WorldS4.2018.8611562},
  ISSN={},
  month={Oct},}@ARTICLE{9178326,
  author={Ahamed Ahanger, Tariq and Tariq, Usman and Ibrahim, Atef and Ullah, Imdad and Bouteraa, Yassine},
  journal={IEEE Access}, 
  title={ANFIS-Inspired Smart Framework for Education Quality Assessment}, 
  year={2020},
  volume={8},
  number={},
  pages={175306-175318},
  abstract={In the education sector, the Internet of Things (IoT) technology, integrated with fog-cloud computing, has offered productive services. Motivated by this, the smart recommender system offers the facility to the students to opt for the course and college based on the education quality. This research provides an IoT-fog-cloud paradigm for evaluating the academic environment with a perspective to enhance quality education. Specifically, IoT technology is incorporated to gather data about the academic environment that directly and indirectly influence the quality of education. Using the Bayesian Modeling Technique, the data collected is analyzed utilizing a fog-cloud computing framework to quantify the measure of the probability of education quality (PoEQ). Moreover, the Education Quality Assurance Index (EQAI) is calculated to analyze the quality assessment over a temporal scale. Furthermore, predictive decision-making is performed for quality estimation using the Adaptive Neuro-Fuzzy Inference System (ANFIS). The experimental simulation on 4 challenging datasets namely C1 (2124 instances), C2 (2112), C3 (2139), and C4 (2109) shows the effectiveness of the proposed framework. Simulation findings are compared with state-of-the-art techniques to measure the overall performance enhancement of the proposed system. Also, the mathematical analysis was carried out to assess the analytical performance of the proposed framework.},
  keywords={},
  doi={10.1109/ACCESS.2020.3019682},
  ISSN={2169-3536},
  month={},}@ARTICLE{8207422,
  author={Noormohammadpour, Mohammad and Raghavendra, Cauligi S.},
  journal={IEEE Communications Surveys & Tutorials}, 
  title={Datacenter Traffic Control: Understanding Techniques and Tradeoffs}, 
  year={2018},
  volume={20},
  number={2},
  pages={1492-1525},
  abstract={Datacenters provide cost-effective and flexible access to scalable compute and storage resources necessary for today's cloud computing needs. A typical datacenter is made up of thousands of servers connected with a large network and usually managed by one operator. To provide quality access to the variety of applications and services hosted on datacenters and maximize performance, it deems necessary to use datacenter networks effectively and efficiently. Datacenter traffic is often a mix of several classes with different priorities and requirements. This includes user-generated interactive traffic, traffic with deadlines, and long-running traffic. To this end, custom transport protocols and traffic management techniques have been developed to improve datacenter network performance. In this tutorial paper, we review the general architecture of datacenter networks, various topologies proposed for them, their traffic properties, general traffic control challenges in datacenters and general traffic control objectives. The purpose of this paper is to bring out the important characteristics of traffic control in datacenters and not to survey all existing solutions (as it is virtually impossible due to massive body of existing research). We hope to provide readers with a wide range of options and factors while considering a variety of traffic control mechanisms. We discuss various characteristics of datacenter traffic control, including management schemes, transmission control, traffic shaping, prioritization, load balancing, multipathing, and traffic scheduling. Next, we point to several open challenges as well as new and interesting networking paradigms. At the end of this paper, we briefly review inter-datacenter networks that connect geographically dispersed datacenters, which have been receiving increasing attention recently and pose interesting and novel research problems. To measure the performance of datacenter networks, different performance metrics have been used, such as flow completion times, deadline miss rate, throughput, and fairness. Depending on the application and user requirements, some metrics may need more attention. While investigating different traffic control techniques, we point out the tradeoffs involved in terms of costs, complexity, and performance. We find that a combination of different traffic control techniques may be necessary at particular entities and layers in the network to improve the variety of performance metrics. We also find that despite significant research efforts, there are still open problems that demand further attention from the research community.},
  keywords={},
  doi={10.1109/COMST.2017.2782753},
  ISSN={1553-877X},
  month={Secondquarter},}@INPROCEEDINGS{7336367,
  author={Zhou, Ping and Wang, Zhipeng and Li, Wenjing and Jiang, Ning},
  booktitle={2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems}, 
  title={Quality Model of Cloud Service}, 
  year={2015},
  volume={},
  number={},
  pages={1418-1423},
  abstract={In recent years, services based on cloud computing have been used more and more widely. Stakeholders have paid more and more attention on the quality of cloud service. But most of them don't know how to evaluate the quality of cloud service. This paper proposes a comprehensive, structurized, and hierarchical quality model of cloud service, which concerned not only the IT features but also the service features of cloud service. The quality model was constructed by 6 characteristics, i.e., usability, security, reliability, tangibility, responsiveness, and empathy. We divided each characteristic into several subcharacteristics. In order to apply the cloud service model better, and to evaluate the service quality systematically, we provide a metrics framework for those subcharacteristics, which was made up of objective and subjective metrics. We give a brief intro to the methodology on evaluating the cloud service quality. We also illustrate the evaluation process with a case study.},
  keywords={},
  doi={10.1109/HPCC-CSS-ICESS.2015.134},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9711797,
  author={Padma, P. and Akshaya, RS. and Akshaya, H. and Harini, R.},
  booktitle={2021 4th International Conference on Computing and Communications Technologies (ICCCT)}, 
  title={Perlustrate Study on Cloud Security and Vulnerabilities}, 
  year={2021},
  volume={},
  number={},
  pages={293-296},
  abstract={In this modern technology,cloud computing plays an integral role which is also the fastest emerging technology. Cloud computing refers to manipulating,configuring and accessing the applications online. It offers online data storage,infrastructure and application. It is both a combination of software and hardware based computing resources delivered as a network service. High Quality services with improved performance and with reduced cost made the cloud computing a popular paradigm. Cloud computing has numerous advantages to the customer, like its ability to scale and recover from various problems agility and flexibility. As every technology emerges with its own pros and cons cloud computing is vulnerable to certain threats regarding security issues which makes the clients a lack of confidence to adopt cloud technologies. The main reason why companies are leaving the cloud is due to security concerns. Cloud security measures are often inadequate to protect sensitive data. This work aims at presenting a survey of various security issues faced by clients and the necessary measures to counter these threats.},
  keywords={},
  doi={10.1109/ICCCT53315.2021.9711797},
  ISSN={},
  month={Dec},}@ARTICLE{6740846,
  author={Zheng, Xianrong and Martin, Patrick and Brohman, Kathryn and Xu, Li Da},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={CLOUDQUAL: A Quality Model for Cloud Services}, 
  year={2014},
  volume={10},
  number={2},
  pages={1527-1536},
  abstract={Cloud computing is an important component of the backbone of the Internet of Things (IoT). Clouds will be required to support large numbers of interactions with varying quality requirements. Service quality will therefore be an important differentiator among cloud providers. In order to distinguish themselves from their competitors, cloud providers should offer superior services that meet customers' expectations. A quality model can be used to represent, measure, and compare the quality of the providers, such that a mutual understanding can be established among cloud stakeholders. In this paper, we take a service perspective and initiate a quality model named CLOUDQUAL for cloud services. It is a model with quality dimensions and metrics that targets general cloud services. CLOUDQUAL contains six quality dimensions, i.e., usability, availability, reliability, responsiveness, security, and elasticity, of which usability is subjective, whereas the others are objective. To demonstrate the effectiveness of CLOUDQUAL, we conduct empirical case studies on three storage clouds. Results show that CLOUDQUAL can evaluate their quality. To demonstrate its soundness, we validate CLOUDQUAL with standard criteria and show that it can differentiate service quality.},
  keywords={},
  doi={10.1109/TII.2014.2306329},
  ISSN={1941-0050},
  month={May},}@INPROCEEDINGS{7427071,
  author={Khan, Hassan Mahmood and Chan, Gaik-Yee and Chua, Fang-Fang},
  booktitle={2016 International Conference on Information Networking (ICOIN)}, 
  title={An adaptive monitoring framework for ensuring accountability and quality of services in cloud computing}, 
  year={2016},
  volume={},
  number={},
  pages={249-253},
  abstract={Cloud computing platform has gained popularity among service providers and consumers to perform business operations due to the ease of communication and transaction convenience in terms of accessibility and availability. However, due to the vulnerability of this dynamic open environment, it is crucial to have a binding agreement between all the service parties for ensuring trust while fulfilling the expected Quality of Services (QoS). There is a need to improve on the current Service Level Agreements (SLAs) practice which does not focus on the QoS and accountability assurance. In this paper, we propose an adaptive monitoring framework to dynamically monitor QoS metrics and performance measures to verify compliances to the respective SLAs. The framework is validated with scenarios on response time and availability which shown to provide adaptive remedy action to rectify violation situation. Besides, any service party which establishes non-compliance to SLAs shall be penalized in monetary terms.},
  keywords={},
  doi={10.1109/ICOIN.2016.7427071},
  ISSN={},
  month={Jan},}@INBOOK{9116755,
  author={Wu, Chu‐ge and Wang, Ling},
  booktitle={Fog Computing: Theory and Practice: Theory and Practice}, 
  title={An Estimation of Distribution Algorithm to Optimize the Utility of Task Scheduling Under Fog Computing Systems}, 
  year={2020},
  volume={},
  number={},
  pages={371-384},
  abstract={The Internet of Things (IoT) is realized initially today. A large amount of data is produced and a range of IoT services are settled down. Based on it, a range of responsive IoT applications arise. To satisfy the quality of experience (QoE) of users, the applications are needed to be processed in a timely manner. Compared with traditional cloud computing systems, fog computing is one of the promising solutions to processing the huge amount of local data and decreasing the end‐to‐end latency. Different time‐dependent functions are adopted to measure the utility of different tasks and in this work, the resource allocation and task scheduling problem under the fog system is considered to maximize the sum of the utility of tasks. And an estimation of distributed algorithm to maximum the task utility (uEDA) with a repair procedure and local search is adopted to determine the task processing order and computing node allocation. The comparative results show that the performance of our algorithm exceeds significantly the heuristic method on the utility metrics.},
  keywords={},
  doi={10.1002/9781119551713.ch14},
  ISSN={},
  publisher={Wiley},
  isbn={},
  url={https://ieeexplore.ieee.org/document/9116755},}@INPROCEEDINGS{6974100,
  author={Brilhante, Jonathan and Silva, Bruno and Maciel, Paulo and Zimmermann, Armin},
  booktitle={2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={Dependability models for Eucalyptus infrastructure clouds considering VM life-cycle}, 
  year={2014},
  volume={},
  number={},
  pages={1336-1341},
  abstract={Managing a cloud computing provider is a difficult task, which involves the control and maintenance of several components, such as computers, network infrastructures and software components. In these environments, availability, security and low costs are important requirements to achieve high quality of service. Therefore, the evaluation of these systems is important to find a configuration that meets the constraints of users and provider. A widely adopted strategy to evaluate cloud computing systems consists by the utilization of stochastic models (e.g., stochastic Petri nets - SPN) to assess the concern metrics. In this context, Eucalyptus is an open source private cloud software for building private and hybrid clouds. This work presents dependability models for evaluation on Eucalyptus clouds. These models focus on the user point of view metrics (e.g., number of running virtual machines) to assess the dependability metrics. In order to demonstrate the feasibility of the proposed models, we evaluate a real world environment and validate the presented models by using Eucabomber tool version 2.0.},
  keywords={},
  doi={10.1109/SMC.2014.6974100},
  ISSN={1062-922X},
  month={Oct},}@ARTICLE{8131852,
  author={Hussain, Omar Khadeer and Rahman, Zia-ur- and Hussain, Farookh Khadeer and Singh, Jaipal and Janjua, Naeem Khalid and Chang, Elizabeth},
  journal={The Computer Journal}, 
  title={A User-Based Early Warning Service Management Framework in Cloud Computing}, 
  year={2015},
  volume={58},
  number={3},
  pages={472-496},
  abstract={Cloud computing is a very attractive option for service users and service providers for their businesses because of the benefits it provides. A major concern among service users regarding cloud adoption, however, is the unpredictability of performance in relation to the services provided. Even though guarantees in the form of service-level agreements are provided to users by service providers, real-time service-level degradability remains a critical concern; hence, there is a need for an approach that assists users to manage a service before it fails. The approaches proposed in the literature assess and evaluate the performance of the cloud infrastructure of providers, but this does not guarantee that a given service instance will meet the desired quality level because there may be factors other than the provider's infrastructure that will affect the level of quality of the service instance. In this paper, we present an approach that measures the quality of a service instance in real time and provides important analysis for service users as to whether they will achieve their desired objectives. This analysis also constitutes an important input for service users in the assessment and management of a service to avoid the failure to achieve objectives.},
  keywords={},
  doi={10.1093/comjnl/bxu064},
  ISSN={1460-2067},
  month={March},}@INPROCEEDINGS{8251864,
  author={Gustamas, R. Gargista and Shidik, Guruh Fajar},
  booktitle={2017 International Seminar on Application for Technology of Information and Communication (iSemantic)}, 
  title={Analysis of network infrastructure performance on cloud computing}, 
  year={2017},
  volume={},
  number={},
  pages={169-174},
  abstract={Cloud Computing offers more convenience than conventional that provide custom Virtual Machine (VM) for any computation requirements. Network connectivity is closely related to the quality of cloud infrastructure itself. This paper focus in preliminary study to test the performance of cloud infrastructure with two type test. First test to measure Network performance and the second to measure cloud computation performance. OpenStack was used as cloud computing software infrastructure. We perform simple cloud infrastructure topology which is divided into three zones, there are Internal Zone, External Zone and Outside Cloud Infrastructure Zone. The parameter tested in this research are quality of bandwidth, latency, jitter and also Processing time during rendering process. The results show VM from simple topology cloud computing which is used to render video, able to perform processing time that slightly longer than using personal computer (PC) with same specification. The network side has been considering as a key of degradation render performance in cloud computing.},
  keywords={},
  doi={10.1109/ISEMANTIC.2017.8251864},
  ISSN={},
  month={Oct},}@ARTICLE{9070142,
  author={Xu, Jianwen and Ota, Kaoru and Dong, Mianxiong},
  journal={China Communications}, 
  title={A real plug-and-play fog: Implementation of service placement in wireless multimedia networks}, 
  year={2019},
  volume={16},
  number={10},
  pages={191-201},
  abstract={Initially as an extension of cloud computing, fog computing has been inspiring new ideas about moving computing tasks to the edge of networks. In fog, we often repeat the procedure of placing services because of the geographical distribution of mobile users. We may not expect a fixed demand and supply relationship between users and service providers since users always prefer nearby service with less time delay and transmission consumption. That is, a plug-and-play service mode is what we need in fog. In this paper, we put forward a dynamic placement strategy for fog service to guarantee the normal service provision and optimize the Quality of Service (QoS). The simulation results show that our strategy can achieve better performance under metrics including energy consumption and end-to-end latency. Moreover, we design a real Plug-and-Play Fog (PnPF) based on Raspberry Pi and OpenWrt to provide fog services for wireless multimedia networks.},
  keywords={},
  doi={10.23919/JCC.2019.10.012},
  ISSN={1673-5447},
  month={Oct},}@ARTICLE{8130579,
  author={Kumar, Neeraj and Chilamkurti, Naveen and Zeadally, Sherali and Jeong, Young-Sik},
  journal={The Computer Journal}, 
  title={Achieving Quality of Service (QoS) Using Resource Allocation and Adaptive Scheduling in Cloud Computing with Grid Support}, 
  year={2014},
  volume={57},
  number={2},
  pages={281-290},
  abstract={In the past few years, cloud computing has emerged as a new reliable, scalable and flexible virtual computing environment (VCE). In this new VCE, users can use the available resources as a service by paying for that service according to the time for which these resources are used. It remains a significant challenge to achieve quality of service (QoS) in a VCE with the available resources. The main goal is to schedule the available resources so that the overall QoS delivered by the VCE can be improved. Resources are assumed to be located both at local and global sites. We propose a three-step scheme: resource selection, scheduling of users requests with shared resources and a new Resource Allocation and Adaptive Job Scheduling algorithm, which improves the QoS delivered by the cloud. For job scheduling, we define a new weight metric that is used to efficiently schedule jobs competing for available resources. Our proposed strategy increases the reliability of resource availability for a job and reduces the job completion time, which in turn increases the QoS delivered to end-users. We evaluate our proposed scheme using well-known heuristics. The results obtained show that our proposed scheme considerably reduces the job execution time, and increases the reliability of resource availability for job execution and throughput.},
  keywords={},
  doi={10.1093/comjnl/bxt024},
  ISSN={1460-2067},
  month={Feb},}@INPROCEEDINGS{7852595,
  author={Rodziah binti Atan},
  booktitle={2016 2nd International Conference on Science in Information Technology (ICSITech)}, 
  title={Enhancing service quality through Service Level Agreement (SLA) full implementation}, 
  year={2016},
  volume={},
  number={},
  pages={1-1},
  abstract={Various SLA monitoring systems are proposed by different features and abilities to evaluate the agreed SLA. The current SLA monitoring systems in cloud computing for its structural, behavioral characteristics and situation are also in place. The systematic reviews of a well-known methods and approaches shows a significant numbers of researches been done in this area. Based on the number of effort and researches, the quality of services should proportionately increase alongside them. We look this matter from the perspectives of enforcement, that evident the stand of quality of services. Service Level Agreement (SLA) enforcement impact measures is a potential research area to be explored. Assumptions that this study is making are, SLA management will become better by a firm enforcement, where every customers are responsible to launch report of bugs or mischief of services such as unsatisfactory quality or service unavailability to a collection pool, and the provider will react immediately to the complaints so that the total downtime not exceeding the SLA value, with efficient enforcement. This study establishes fundamental theory to measure enforcement impact to SLA monitoring and management. We proposed eight activity phases from formulating until analyzing and decision formation. Descriptive statistics is utilized to analyze the extracted data. The SLA validation detection is the most frequent purpose of SLA monitoring systems in cloud by 58% and throughput is checked as an attribute target by 28%. The self-monitoring SLA, self-healing system, hierarchical structure are recognized points of SLA monitoring systems which need improvement before the enforcement could be based upon.},
  keywords={},
  doi={10.1109/ICSITech.2016.7852595},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{7193080,
  author={Vijayakumar, N and Ramya, R},
  booktitle={2015 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS)}, 
  title={The real time monitoring of water quality in IoT environment}, 
  year={2015},
  volume={},
  number={},
  pages={1-5},
  abstract={In order to ensure the safe supply of the drinking water the quality needs to be monitor in real time. In this paper we present a design and development of a low cost system for real time monitoring of the water quality in IOT(internet of things). The system consist of several sensors is used to measuring physical and chemical parameters of the water. The parameters such as temperature, PH, turbidity, conductivity, dissolved oxygen of the water can be measured. The measured values from the sensors can be processed by the core controller. The raspberry PI B+ model can be used as a core controller. Finally, the sensor data can be viewed on internet using cloud computing.},
  keywords={},
  doi={10.1109/ICIIECS.2015.7193080},
  ISSN={},
  month={March},}@INPROCEEDINGS{7159459,
  author={Vijayakumar, N and Ramya, R},
  booktitle={2015 International Conference on Circuits, Power and Computing Technologies [ICCPCT-2015]}, 
  title={The real time monitoring of water quality in IoT environment}, 
  year={2015},
  volume={},
  number={},
  pages={1-4},
  abstract={In order to ensure the safe supply of the drinking water the quality needs to be monitor in real time. In this paper we present a design and development of a low cost system for real time monitoring of the water quality in IOT(internet of things).the system consist of several sensors is used to measuring physical and chemical parameters of the water. The parameters such as temperature, PH, turbidity, conductivity, dissolved oxygen of the water can be measured. The measured values from the sensors can be processed by the core controller. The raspberry PI B+ model can be used as a core controller. Finally, the sensor data can be viewed on internet using cloud computing.},
  keywords={},
  doi={10.1109/ICCPCT.2015.7159459},
  ISSN={},
  month={March},}@INPROCEEDINGS{9302797,
  author={Flinck Lindström, Sebastian and Wetterberg, Markus and Carlsson, Niklas},
  booktitle={2020 IEEE/ACM 13th International Conference on Utility and Cloud Computing (UCC)}, 
  title={Cloud Gaming: A QoE Study of Fast-paced Single-player and Multiplayer Gaming}, 
  year={2020},
  volume={},
  number={},
  pages={34-45},
  abstract={Cloud computing offers an attractive solution for modern computer games. By moving the increasingly demanding graphical calculations (e.g., generation of real-time video streams) to the cloud, consumers can play games using small, cheap devices. While cloud gaming has many advantages and is increasingly deployed, not much work has been done to understand the underlying factors impacting players' user experience when moving the processing to the cloud. In this paper, we study the impact of the quality of service (QoS) factors most affecting the players' quality of experience (QoE) and in-game performance. In particular, these relationships are studied from multiple perspectives using complementing analysis methods applied on the data collected via instrumented user tests. During the tests, we manipulated the players' network conditions and collected low-level QoS metrics and in-game performance, and after each game, the users answered questions capturing their QoE. New insights are provided using different correlation/auto-correlation/cross-correlation statistics, regression models, and a thorough breakdown of the QoS metric most strongly correlated with the users' QoE. We find that the frame age is the most important QoS metric for predicting in-game performance and QoE, and that spikes in the frame age caused by large frame transfers can have extended negative impact as they can cause processing backlogs. The study emphasizes the need to carefully consider and optimize the parts making up the frame age, including dependencies between the processing steps. By lowering the frame age, more enjoyable gaming experiences can be provided.},
  keywords={},
  doi={10.1109/UCC48980.2020.00023},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9702517,
  author={Chauhan, Rishabh and Kumar, Sunil},
  booktitle={2021 5th International Conference on Information Systems and Computer Networks (ISCON)}, 
  title={Packet Loss Prediction Using Artificial Intelligence Unified with Big Data Analytics, Internet of Things and Cloud Computing Technologies}, 
  year={2021},
  volume={},
  number={},
  pages={01-06},
  abstract={Big Data Analytics, Artificial Intelligence and cloud computing all together has emerged with an ultimate goal of automating and changing human life by providing their services. These incredibly strong technologies have huge potential by working together, making human life simpler and advanced. To increase the popularity of any of these services, Quality of Service metrics are needed to be defined clear. One of those quality metrics is packet loss or packet delivery, which is the main research idea of this paper. With advancement in Intelligent Network there exists a scope to predict packet loss, by analyzing the recorded network traffic and processing said data under certain machine learning algorithms to create a model to either predict packet loss or tell which variable is responsible for packet loss. This paper includes the study of packet loss behavior of networks. The Analytics techniques applied successfully by analyzing big network traffic data, processing of data, using AI and Machine Learning classifier “XGBoost” and hence designed a model to predict Packet loss which is a QoS metric with an accuracy of 90 percent. The model is personalized to work on WireShark data.},
  keywords={},
  doi={10.1109/ISCON52037.2021.9702517},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9284541,
  author={Martins, Wictor Souza and Tardiole Kuehne, Bruno and Sobrinho, Rafael Ferreira and Preti, Fábio},
  booktitle={2020 IEEE International Conference on Services Computing (SCC)}, 
  title={A Reference Method for Performance Evaluation in Big Data Architectures}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper presents a reference method for performance evaluation in Big Data architectures, called by Improvement Method for Big Data Architectures (IMBDA) aiming to increase the performance, and consequently raising the quality of service provided. The method will contribute to small businesses and startups that have limited financial re-sources (impossible to invest in market solutions). The proposed approach considers the relationship of the processes in a data processing flow to find possible bottlenecks and optimization points. To this end, IMBDA collects system logs to compose functional metrics (e.g., processing time) and non-functional metrics (e.g., CPU and memory utilization, and other cloud computing infrastructure resources). The system stores these metrics in an external data analysis tool that investigates the correlation of performance between processes. The reference method applies to the architecture of a Big Data application, which provides solutions in fleet logistics. With the use of IMBDA, it was possible to identify performance bottlenecks, allowing the reconfiguration of the architecture to increase service quality at the lowest possible cost.},
  keywords={},
  doi={10.1109/SCC49832.2020.00044},
  ISSN={2474-2473},
  month={Nov},}@INPROCEEDINGS{7536961,
  author={Chaemin Seong and Minsoo Jang and Kyungshik Lim},
  booktitle={2016 Eighth International Conference on Ubiquitous and Future Networks (ICUFN)}, 
  title={Context-aware HTTP Adaptive Streaming in mobile cloud environments}, 
  year={2016},
  volume={},
  number={},
  pages={1062-1067},
  abstract={With advances of cloud computing, seamless video streaming from video server to cloud client has been one of technical challenges for multimedia cloud applications. Especially in case that Desktop-as-a-Service (DaaS) as a major cloud application is deployed via wireless networks, it could raise a new set of issues to be addressed. To solve the problem, we propose a Cloud-based Context-aware HTTP Adaptive Streaming (C2HAS) agent located at cloud server. The goal of the agent is to maximize the video quality of seamless streaming perceived by cloud client, given a dynamically changing network context. From network context we derive a major metric for adapting and maximizing the video quality perceived by cloud clients, which is the throughput ratio of backbone networks and access networks. Based on the metric, we can provide a maximal quality of seamless video streaming to cloud users who might be connected via distant and/or lossy wireless links. The experimental performance analysis shows that the C2HAS agent could be a viable solution for cloud-based multimedia applications.},
  keywords={},
  doi={10.1109/ICUFN.2016.7536961},
  ISSN={2165-8536},
  month={July},}@INPROCEEDINGS{9333865,
  author={Han, Jaehyun and Zhu, Guangyu and Lee, Eunseo and Lee, Sangmook and Son, Yongseok},
  booktitle={2021 International Conference on Information Networking (ICOIN)}, 
  title={An Empirical Evaluation and Analysis of Performance of Multiple Optane SSDs}, 
  year={2021},
  volume={},
  number={},
  pages={541-545},
  abstract={Cloud Computing as a service-on-demand architecture has grown in importance over the previous few years. The storage subsystem in cloud computing has undergone enormous innovation in order to provide high-quality cloud services. Emerging non-volatile memory express (NVMe) technology has a considerable attraction in cloud computing by delivering high I/O performance in terms of latency and bandwidth. Especially, multiple NVMe SSDs can provide higher performance, fault tolerance, and storage capacity in the cloud computing environment. In this paper, we perform an empirical evaluation study of performance on recent NVMe SSDs (i.e., Intel Optane SSDs) with different RAID environments. We analyze the performance of the multiple NVMe SSDs with RAID in terms of different performance metrics via micro and macro benchmarks. We anticipate that the experimental results and performance analysis will provide the implications on various storage systems.},
  keywords={},
  doi={10.1109/ICOIN50884.2021.9333865},
  ISSN={1976-7684},
  month={Jan},}@INPROCEEDINGS{8883458,
  author={Biondi, Katalina and Al-Masri, Eyhab and Baiocchi, Orlando and Jeyaraman, Suganya and Pospisil, Eric and Boyer, Graham and de Souza, Cleonilson Protasio},
  booktitle={2019 International Conference in Engineering Applications (ICEA)}, 
  title={Air Pollution Detection System using Edge Computing}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={Existing solutions to measuring air quality can be expensive and potentially mutes high air pollution events. The IoT Pollution Project is exploring how IoT concepts can be applied with smart systems to detect pollution in real-time. Using a network of Raspberry Pi prototypes, the project aims to measure heavily populated areas around the City of Tacoma, while building a real-time interface measuring current air quality. The project also explores the use of edge computing as an alternative to cloud computing. The vast expansion of IoT devices poses threats to the infrastructure of cloud computing as more devices process and store data to the cloud. The project demonstrates how edge devices can alleviate the work done on the cloud by calculating rolling averages over a time interval on the edge device and then deploying the data to the cloud. The project uses Microsoft Azure Framework, IoT concepts and edge computing concepts to build the project architecture.},
  keywords={},
  doi={10.1109/CEAP.2019.8883458},
  ISSN={},
  month={July},}@INPROCEEDINGS{8073634,
  author={Muralitharan, D. Boobala and Reebha, S. Arockia Babi and Saravanan, D.},
  booktitle={2017 International Conference on IoT and Application (ICIOT)}, 
  title={Optimization of performance and scheduling of HPC applications in cloud using cloudsim and scheduling approach}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={Cloud computing is emerging as a promising alternative to supercomputers for some High-Performance Computing (HPC) applications. Cloud computing is an essential component of the back bone of the Internet of Things (IoT). Clouds are needed to support huge numbers of interactions with varying quality requirements. Hence, Service quality will be a vital differentiator among cloud providers. In order to differentiate themselves from their competitors, cloud providers should offer best services that meet customers' expectations. A quality model can be used to represent, measure and compare the quality of the providers, such that a mutual understanding can be established among clouds take holders. With cloud as an additional deployment option, HPC users and providers faces the challenges of dealing with highly heterogeneous resources, where the variability spans across a wide range of processor configurations, interconnects, virtualization environments, and pricing models. HPC applications are increasingly being used in academia and laboratories for scientific research and in industries for business and analytics. Cloud computing offers the benefits of virtualization, elasticity of resources and elimination of cluster setup cost and time to HPC applications users. Effort was taken for holistic viewpoint to answer the questions - why and who should choose cloud for HPC, for what applications and how the cloud can be used for HPC? Comprehensive performance and cost evaluation and analysis of running a set of HPC applications on a range of platforms, varying from supercomputers to clouds was carried out. Further, performance of HPC applications is improved in cloud by optimizing HPC applications' characteristics for cloud and cloud virtualization mechanisms for HPC. In this paper, a novel heuristics for online application-aware job scheduling in multi-platform environments is presented. Experimental results and Simulations using CloudSim show that current clouds cannot substitute supercomputers but can effectively complement them.},
  keywords={},
  doi={10.1109/ICIOTA.2017.8073634},
  ISSN={},
  month={May},}@INPROCEEDINGS{8920865,
  author={Hlaing, Yamin Thet Htar and Yee, Tin Tin},
  booktitle={2019 International Conference on Advanced Information Technologies (ICAIT)}, 
  title={Static Independent Task Scheduling on Virtualized Servers in Cloud Computing Environment}, 
  year={2019},
  volume={},
  number={},
  pages={55-59},
  abstract={Cloud Computing is the advanced design of client-server computing, cluster computing and grid computing. The cloud providers provide cloud services mainly as Infrastructure as a Service (IaaS), Platform as a Service (PaaS), Software as a Service (SaaS) to the users who can access publicly, privately or hybrid via the Internet. In Cloud computing, there are many research areas like task scheduling, allocation of resource, security and privacy etc. Task scheduling is a vital area in the cloud computing, and it must be optimized by considering different parameters. Nowadays, there are a lot of different scheduling algorithms to minimize execution time and cost, to improve the quality of service, system performance and to maximize resource utilization and load balancing, etc. This paper proposed a Static Independent Task Scheduling on Virtualized Servers in Cloud Computing Environment in which tasks are allocated to the suitable VM by measuring the availability of each resource with respect to its processing power, cost and the number of available processing elements and by grouping tasks according to their instruction length. This method is simulated on Cloud Simulator (Cloudsim toolkit) and results show the proposed method that maximizes total execution time and minimizes execution cost for all tasks than scheduling algorithms such as Shortest Job First (SJF) and First Come First Serve (FCFS) algorithms.},
  keywords={},
  doi={10.1109/AITC.2019.8920865},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{7566494,
  author={Chandu P.M.S.S and Kata, Divyasree},
  booktitle={2016 International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET)}, 
  title={Integrating and enhancing the quality of services in cloud computing with software testing}, 
  year={2016},
  volume={},
  number={},
  pages={2008-2010},
  abstract={Cloud computing involves to delivering the hosted services throughout the internet. Testing tools are used to test the desktop applications, web applications and the cloud based software systems that are used to address the quality of the cloud infrastructure such as tremendous extensibility and aggressive composition. In the existing paper it is not providing the quality of services in the effective manner. In this paper we focused on integrating the software metrics for getting the quality of services, in terms of speed, memory size, RAM, ROM size and we are also using the D-cloud and prefail testing tools to perform the fault tolerance and recovery testing. By using OVMP algorithm we are minimizing the cost spending for services and load prediction algorithm and it is also used to reduce the load. The aim is to extend the above framework with cross cloud testing scenario involving communications between heterogeneous cloud hosts. The results shows that the cloud environment ensures more flexible and quality of services.},
  keywords={},
  doi={10.1109/WiSPNET.2016.7566494},
  ISSN={},
  month={March},}@INPROCEEDINGS{8097142,
  author={Jelassi, Mariem and Ghazel, Cherif and Saïdane, Leila Azzouz},
  booktitle={2017 3rd International Conference on Frontiers of Signal Processing (ICFSP)}, 
  title={A survey on quality of service in cloud computing}, 
  year={2017},
  volume={},
  number={},
  pages={63-67},
  abstract={The quality of service is one of challenges posed by the Cloud Computing. This issue plays an important role in making the Cloud services acceptable to customers, denotes the levels of performance, reliability, and availability offered by Cloud services. Literature has reported many implementations for measuring and ensuring QoS in Cloud Computing systems to achieve better results and meet the needs of producers and consumers. In this paper, we have presented a survey on QoS in Cloud Computing, the mechanisms and methods to guarantee quality of service (QoS) used to Cloud Computing services.},
  keywords={},
  doi={10.1109/ICFSP.2017.8097142},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{7924927,
  author={Yazhou Hu and Bo Deng and Fuyang Peng},
  booktitle={2016 2nd IEEE International Conference on Computer and Communications (ICCC)}, 
  title={Autoscaling prediction models for cloud resource provisioning}, 
  year={2016},
  volume={},
  number={},
  pages={1364-1369},
  abstract={The elasticity mechanism of cloud computing can auto scale cloud resources to meet users' need. Elastic adding or removing virtual machines is the most common method to achieve the auto scaling. But the elastic scaling often takes tens of minutes, which is inefficient for the running workload. To reduce the latency and improve the quality of service (QoS), the new virtual machine should be provisioned when the request arrives. In this paper, we present a prediction framework for virtual machines provisioning. This prediction framework includes three main modules: monitor, filter and predictor. This framework aims to predict the upcoming workload and provision the virtual machines in advance. To get the reasonable monitored metrics, we propose the Kalman filter method to preprocess the raw data. Moreover, we present five different prediction models as the based predictor. These prediction models include moving average (MA), auto regression (AR), auto regression integrated moving average (ARIMA), neural networks (NN) and support vector machine (SVM). Meanwhile, we propose four evaluation metrics, including the prediction error, the time saving, under-prediction resource and over-prediction resource, to evaluate the performance of prediction framework. In addition, we use Alicloud as the experimental infrastructure. Experimental results demonstrate that the prediction framework can reduce the latency of provisioning cloud resource and improve the cloud service quality.},
  keywords={},
  doi={10.1109/CompComm.2016.7924927},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9369609,
  author={Heideker, Alexandre and Kamienski, Carlos},
  booktitle={2021 IEEE 18th Annual Consumer Communications & Networking Conference (CCNC)}, 
  title={Towards a Network Queuing Assessment for Elasticity Management of Virtualized Services}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={With the increasing adoption of cloud computing, microservice architecture, and network function virtualization (NFV), addressing scalability and elasticity management becomes essential. The high demand for these services challenges the research community to create new automated management techniques, from which an essential part is the detection of bottlenecks in infrastructures and application boxes. The traditional approach based on hardware resource metrics (CPU and RAM) is the most straightforward strategy, providing independence from particular applications but may not capture the application's behavior in terms of workload variations. On the other hand, using an application-oriented approach provides a significant correlation with the end-user quality of experience but needs to be tailored for each case. We propose the Network Queuing Assessment (NQA) that breaks away with this tradeoff, capturing the application's workload variations and providing a significant correlation with the end-user quality of experience. Also, similarly to CPU and RAM, it is independent of particular applications. Our performance analysis results for CPU, RAM, and NQA metrics using virtualized applications and network functions in a cloud environment confirm this approach's usefulness.},
  keywords={},
  doi={10.1109/CCNC49032.2021.9369609},
  ISSN={2331-9860},
  month={Jan},}@INPROCEEDINGS{9397031,
  author={Haque, Halima and Labeeb, Kashshaf and Riha, Rabea Basri and Khan, Md. Nasfikur R.},
  booktitle={2021 International Conference on Emerging Smart Computing and Informatics (ESCI)}, 
  title={IoT Based Water Quality Monitoring System By Using Zigbee Protocol}, 
  year={2021},
  volume={},
  number={},
  pages={619-622},
  abstract={This paper dictates the damages caused by water and what can be done to resolve those issues by involving the Internet of things (IoT). Keeping the quality of water in check is today's ultimate objective. Thereby, to guarantee safe drinking water supply, the quality of water should be observed regularly. The use of IoT based solution, focused mainly on water quality monitoring has therefore been suggested. In order to support the issue, an IoT-based water quality checking network has been introduced that continuously monitors and evaluates the quality of water and tries to distinguish whether it is up to the mark for general use. This paper includes the use of specific sensors that calculates the various parameters of the quality of water which includes conductivity and dissolved oxygen (DO), turbidity, pH, and temperature. The values from the sensors have been measured and calculated using the microcontrollers. Then these processed remote values have been transmitted to the raspberry pi, the central controller which uses the Zigbee protocol. Lastly, all the data from the sensors are then accessible via cloud computing through any browser, on request.},
  keywords={},
  doi={10.1109/ESCI50559.2021.9397031},
  ISSN={},
  month={March},}@INPROCEEDINGS{9604373,
  author={Wang, Lei and He, Qiang and Gao, Demin and Wan, Jing and Zhang, Yunqiu},
  booktitle={2021 IEEE World Congress on Services (SERVICES)}, 
  title={Temporal-Perturbation aware Reliability Sensitivity Measurement for Adaptive Cloud Service Selection}, 
  year={2021},
  volume={},
  number={},
  pages={8-8},
  abstract={Benefiting from the pay-as-you-go business model, cloud computing has significantly promoted service computing techniques in real-world industrial applications. Software applications based on cloud computing are becoming more and more popular. By integrating existing component cloud services through the internet, composite cloud systems can be built to meet sophisticated application logic. Stable execution of such systems is desirable in the long term so that the service-level agreements (SLAs), as well as users’ quality of experience (QoE), can be fulfilled. To achieve this goal, it is critical to identify and fault-tolerate system components at high risks of failing. This is extremely challenging due to the dynamic and uncertainty of the cloud environment that hosts the component cloud services. Nevertheless, existing approaches pay little attention to the modeling and analysis of system components’ reliability time series. To address the above issues, we first present a reliability evaluation method for component cloud services based on the reliability model and their failure probability under continuous client-side invocation tests. Then, we propose a perturbation-aware reliability sensitivity measurement approach (named PARS) for measuring the reliability sensitivity of component cloud services. It first analyzes the negative perturbations in component cloud services’ historical reliability time series based on the Markov chain rule. Then, it calculates the reliability sensitivity of component cloud services by analyzing how their reliability perturbations impact the reliability of the entire cloud system. To guarantee the execution quality of the composite cloud system, we further propose a proactive adaptation approach named PA-PARS that enables 1-out-of-2 N-version Programming fault-tolerance for composite cloud systems based on PARS. PA-PARS takes the reliability sensitivity of component cloud services estimated by PARS as input to assure the reliability of the cloud system. It consists of four parts: 1) risky system component identification; 2) adaptation trigger; 3) candidate component cloud service selection; and 4) NVP-based system construction as the proactive adaptation for the composite cloud system. The results of experiments conducted on two widely-used datasets demonstrate the effectiveness and efficiency of the proposed approaches in ensuring the reliability of composite cloud systems.},
  keywords={},
  doi={10.1109/SERVICES51467.2021.00019},
  ISSN={2642-939X},
  month={Sep.},}@ARTICLE{7355287,
  author={Zuo, Liyun and Shu, Lei and Dong, Shoubin and Zhu, Chunsheng and Hara, Takahiro},
  journal={IEEE Access}, 
  title={A Multi-Objective Optimization Scheduling Method Based on the Ant Colony Algorithm in Cloud Computing}, 
  year={2015},
  volume={3},
  number={},
  pages={2687-2699},
  abstract={For task-scheduling problems in cloud computing, a multi-objective optimization method is proposed here. First, with an aim toward the biodiversity of resources and tasks in cloud computing, we propose a resource cost model that defines the demand of tasks on resources with more details. This model reflects the relationship between the user's resource costs and the budget costs. A multi-objective optimization scheduling method has been proposed based on this resource cost model. This method considers the makespan and the user's budget costs as constraints of the optimization problem, achieving multi-objective optimization of both performance and cost. An improved ant colony algorithm has been proposed to solve this problem. Two constraint functions were used to evaluate and provide feedback regarding the performance and budget cost. These two constraint functions made the algorithm adjust the quality of the solution in a timely manner based on feedback in order to achieve the optimal solution. Some simulation experiments were designed to evaluate this method's performance using four metrics: 1) the makespan; 2) cost; 3) deadline violation rate; and 4) resource utilization. Experimental results show that based on these four metrics, a multi-objective optimization method is better than other similar methods, especially as it increased 56.6% in the best case scenario.},
  keywords={},
  doi={10.1109/ACCESS.2015.2508940},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7976761,
  author={Bashar, Abul},
  booktitle={2017 IEEE 7th International Advance Computing Conference (IACC)}, 
  title={BN-Based Approach for Predictive Admission Control of Cloud Services}, 
  year={2017},
  volume={},
  number={},
  pages={59-64},
  abstract={A phenomenal growth in the demand for Cloud Computing services by the cloud consumers has necessitated the efficient and proactive management of the data center hosted services having varied characteristics. One of the major issues concerning both the cloud service providers and consumers is the provisioning of highest level of Quality of Service (QoS) under unpredictable service demands, while maintaining required revenue targets. Traditional Admission Control (AC) approaches which are usually mathematical or analytical in nature, have limited performance levels in the situations where service types, QoS parameters and user demands become highly unpredictable. To this end, an opportunity exists to utilize the self-learning capabilities of Machine Learning (ML) approaches to incorporate predictive and adaptive Admission Control of service requests without violating the Service Level Agreements (SLA) and simultaneously ensuring targeted revenue to the providers. This paper proposes, implements and evaluates a Bayesian Networks based predictive modeling framework (termed as BNSAC) to provide an autonomic Admission Control of cloud service requests. In summary, the BN-based model learns the historical behavior of the system involving various performance metrics (indicators) and predicts the desired unknown metric (e.g. SLA parameter) for making admission control decisions. It presents simulated experimental results involving various service demand scenarios which provide insights into the feasibility and applicability of the proposed approach for improving the QoS in the cloud computing setup.},
  keywords={},
  doi={10.1109/IACC.2017.0027},
  ISSN={2473-3571},
  month={Jan},}@INPROCEEDINGS{9510130,
  author={Bhonde, Aparna and Devane, Satish},
  booktitle={2021 International Conference on Communication information and Computing Technology (ICCICT)}, 
  title={Impact of Cloud Attacks on Service Level Agreement}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Cloud computing has taken center stage in the current business due to reduced cost, high performance and zero infrastructure. Cloud computing paradigm is yet unable to provide quality of service (QoS) by complying service level agreement (SLA) because of lack of analysis on the unaddressed security issues, challenges, threats which has paved the path for researchers to overcome the lapses in order to improve the QoS. In this paper, we present a survey on the cloud service model attacks and threat analysis. It is been observed after thorough analysis of attacks on all the service models that there is a need to have stronger security for infrastructure as a service level attack. Trust can be ensured among the cloud users with the introduction of security metrics in the service level agreement. Cloud service providers can mention the security metrics in SLA only if it can confidently address these attacks by adding security for infrastructure as a service.},
  keywords={},
  doi={10.1109/ICCICT50803.2021.9510130},
  ISSN={},
  month={June},}@INPROCEEDINGS{8441460,
  author={Keserwani, Pankaj Kumar and Samaddar, Shefalika Ghosh},
  booktitle={2017 Ninth International Conference on Advanced Computing (ICoAC)}, 
  title={An SLA Design with Digital Forensic Capabilities}, 
  year={2017},
  volume={},
  number={},
  pages={109-113},
  abstract={Cloud computing is getting rapid momentum as an alternative to traditional and professional Infrastructure of Information Technology due to its attractive features of getting everything in a service mode rather than in a product mode. Service mode using cloud makes the products and services cost effective. As consumers willing to pass on their tasks as services provider to cloud providers, trust factor is required especially when consumers have critical data. The Service Level Agreements (SLA) between cloud service consumers (CSCs) and cloud service providers (CSPs) play important role for building up trust between involved parties. SLA between parties is established in a satisfactory way upon agreements. Cloud computing is very dynamic in nature, hence continuous monitoring on Quality of Service (QoS) attributes as mentioned in SLA is required to be implemented dynamically. Managing SLAs is complicated due to complex nature of the cloud due to multi-tenancy and distributed resource sharing. The paper proposes a methodology for SLAs to be signed digitally and its further management in a single or multi cloud computing environment. The framework had been used in Web Service Level Agreement (WSLA) for monitoring and enforcement of SLA using Service Oriented Architecture (SOA) environment. Cloud broker agents have the capability of automatic extraction of metrics from SLAs. The use of the third party support feature to manage the digital forensics in case of requirement of any violation of SLAs suggested in the present paper and it is also solving the trust issues as demonstrated in digital forensics usage from the initiation of SLA; making the SLA naturally forensic enabled.},
  keywords={},
  doi={10.1109/ICoAC.2017.8441460},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8509050,
  author={Kumar Koditala, Nikhil and Shekar Pandey, Purnendu},
  booktitle={2018 International Conference on Research in Intelligent and Computing in Engineering (RICE)}, 
  title={Water Quality Monitoring System Using IoT and Machine Learning}, 
  year={2018},
  volume={},
  number={},
  pages={1-5},
  abstract={World Economic Forum ranked drinking water crisis as one of the global risk, due to which around 200 children are dying per day. Drinking unsafe water alone causes around 3.4 million deaths per year. Despite the advancements in technology, sufficient quality measures are not present to measure the quality of drinking water. By focusing on the above issue, this paper proposes a low cost water quality monitoring system using emerging technologies such as IoT, Machine Learning and Cloud Computing which can replace traditional way of quality monitoring. This helps in saving people of rural areas from various dangerous diseases such as fluorosis, bone deformities etc. The proposed model also has a capacity to control temperature of water and adjusts it so as to suit environment temperature. Based on our model we have achieved R-squared score of 0.933.},
  keywords={},
  doi={10.1109/RICE.2018.8509050},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{7207386,
  author={Cedillo, Priscila and Jimenez-Gomez, Javier and Abrahao, Silvia and Insfran, Emilio},
  booktitle={2015 IEEE International Conference on Services Computing}, 
  title={Towards a Monitoring Middleware for Cloud Services}, 
  year={2015},
  volume={},
  number={},
  pages={451-458},
  abstract={Cloud Computing represents a new trend in the development and use of software. Many organizations are currently adopting the use of services that are hosted in the cloud by employing the Software as a Service (SaaS) model. Services are typically accompanied by a Service Level Agreement (SLA), which defines the quality terms that a provider offers to its customers. Many monitoring tools have been proposed to report compliance with the SLA. However, they have some limitations when changes to monitoring requirements must be made and because of the complexity involved in capturing low-level raw data from services at runtime. In this paper, we propose the design of a platform-independent monitoring middleware for cloud services, which supports the monitoring of SLA compliance and provides a report containing SLA violations that may help stakeholders to make decisions regarding how to improve the quality of cloud services. Moreover, our middleware definition is based on the use of models@run.time, which allows the dynamic change of quality requirements and/or the dynamic selection of different metric operationalizations (i.e., Calculation formulas) with which to measure the quality of services. In order to demonstrate the feasibility of our approach, we show the instantiation of the proposed middleware that can be used to monitor services when deployed on the Microsoft Azure© platform.},
  keywords={},
  doi={10.1109/SCC.2015.68},
  ISSN={},
  month={June},}@INPROCEEDINGS{7436036,
  author={Gholami, Atoosa and Arani, Mostafa Ghobaei},
  booktitle={2015 2nd International Conference on Knowledge-Based Engineering and Innovation (KBEI)}, 
  title={A trust model for resource selection in cloud computing environment}, 
  year={2015},
  volume={},
  number={},
  pages={144-151},
  abstract={In recent years, cloud computing technology has been increasingly embraced by people and most organizations tend to use this technology in their business processes. On the other hand, the use of this technology is not so easy and many organizations are concerned about the storage of their sensitive data in their data centers instead of storing them in the cloud storage centers. Today, one of the most important factors for the success of cloud computing is to create trust and security. Cloud computing will face a lot of challenges when the key element trust is absent. Trust is one of the most important ways to improve the reliability of cloud computing resources provided in the cloud environment and plays an important role in business carried out in the cloud business environments. User trust contributes to selection of appropriate sources in heterogeneous cloud infrastructure. In this paper, we present the trust model based on standards of appropriate service quality and speed of implementation for choose the best source. The proposed approach, in addition to taking into account criteria of quality of service such as cost, response time, bandwidth, and processor speed. Simulation results show that the proposed approach compared with similar approaches, in addition to taking into account measures of the quality of service, selects the most reliable source in a cloud environment by taking into account the speed of things.},
  keywords={},
  doi={10.1109/KBEI.2015.7436036},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8251862,
  author={Tirta, Manggiardi B.W. and Shidik, Guruh Fajar},
  booktitle={2017 International Seminar on Application for Technology of Information and Communication (iSemantic)}, 
  title={Evaluation performance of cloud computing with network attached storage for video render}, 
  year={2017},
  volume={},
  number={},
  pages={157-163},
  abstract={One of the benefits of Cloud Computing is the use of virtual machines for efficiency and resource utilization. The study utilizes a virtual machine on cloud computing technology for video rendering needs and is integrated with Network Attached Storage (NAS) storage methods, a centralized storage method that uses network media to connect storage media with users. The rendering process is then analyzed using several metering tools to measure the rendering time frame, VM Utilization, network performance, and NAS Network Performance. The results show that rendering takes longer, then CPU Utilization shows a maximum of 77%, Memory Utilization 55%, and Network Utilization 10%. The bandwidth available between NAS and VM storage in a cloud computing system only generates a maximum of 295.1 Mbps, which should reach 1 Gbps. The quality of video rendering in VM cloud computing shows similar results with rendering on physical computers, the results obtained from testing between frames using mean-square error algorithm.},
  keywords={},
  doi={10.1109/ISEMANTIC.2017.8251862},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8005362,
  author={Brataas, Grunnar and Herbst, Nikolas and Ivansek, Simon and Polutnik, Jure},
  booktitle={2017 IEEE International Conference on Autonomic Computing (ICAC)}, 
  title={Scalability Analysis of Cloud Software Services}, 
  year={2017},
  volume={},
  number={},
  pages={285-292},
  abstract={Cloud computing theoretically offers its customers unlimited cloud resources. However, the scalability of software services is often limited by their underlying architecture. In contrast to current scalability analysis approaches, we make work parameters, quality thresholds, as well as the resource space explicit in a conceptually consistent set of equations. We propose two scalability metric functions based on these equations. The resource scalability metric function describes the relation between the capacity of the multi-tier cloud software service and its use of cloud resources, whereas the cost scalability metric function replaces cloud resources with cost. We validate using the Cloud-Store application. CloudStore follows the TPC-W specification, representing an online book store. We have experimented with 21 different public Amazon Web Service configurations and two private OpenStack configurations.},
  keywords={},
  doi={10.1109/ICAC.2017.34},
  ISSN={2474-0756},
  month={July},}@INPROCEEDINGS{7404740,
  author={Vallone, Joël and Birke, Robert and Chen, Lydia Y. and Falsafi, Babak},
  booktitle={2015 IEEE 23rd International Symposium on Quality of Service (IWQoS)}, 
  title={Contention detection by throttling: A black-box on-line approach}, 
  year={2015},
  volume={},
  number={},
  pages={237-242},
  abstract={Visualization technology powers up the cloud computing paradigm and inevitably raises concerns about performance isolation of collocated virtual machines (VM). It is imperative for public cloud providers to guarantee performance targets for tenants' VMs while respecting strict business confidentiality, e.g., having no information on applications nor their performance. A large body of related work addresses the challenges of detecting performance interferences by leveraging client's quality of service (QoS) metrics, such as latency, and additional profiling servers. Whereas to assist cloud providers, we resort to an on-line blackbox approach based on throttling that detects a wide range of resource contentions with no cooperation need from the virtual machines. We focus on different resource metrics and actively monitor them from the hypervisor in fine time granularity at low cost. To detect resource contention, we propose a three-phase algorithm: an alarm phase, to identify statistical outliers in the victim's VM resource metrics; a passive diagnosis phase, to match the current sample to historical behaviors; and, an active learning phase, to discern contentions from application phase changes via throttling. We evaluate our algorithm on a prototype running Wikimedia as victim application across a set of VMs collocated with neighboring VMs running resource hoggers, i.e. PARSEC and Cachebench. Our extensive experimental results show that we can reach an average detection accuracy above 90% while limiting the performance degradation experienced by offender workloads to short learning phases.},
  keywords={},
  doi={10.1109/IWQoS.2015.7404740},
  ISSN={},
  month={June},}@INPROCEEDINGS{9080012,
  author={Kotteswari, K. and Bharathi, A.},
  booktitle={2019 International Conference on Advances in Computing and Communication Engineering (ICACCE)}, 
  title={Spectral Expansion Method for Cloud Reliability Analysis}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  abstract={Cloud Computing is a computing hypothesis, where a huge group of systems linked together in private, public or hybrid network, to offer dynamically amendable infrastructure for data storage, file storage and application. With this emerging technology, application hosting, delivery, content storage, and reduced computation cost, and it acts as an essential module for backbone of the Internet of Things (IOT). The efficiency of cloud Service providers (CSP) could be improved by considering significant factors such as availability, reliability, usability, security, responsiveness, and elasticity. Assessment of these factors leads to efficiency in designing scheduler for CSP. This metrics also improved the Quality of Service (QoS) in cloud. Many existing model and approaches evaluate this metrics. But these existing approaches doesn't offer efficient outcome. In this paper, a prominent performance model named as Spectral Expansion Method (SPM) evaluates cloud reliability. Spectral expansion Method (SPM) is a huge technique useful in reliability and performance modelling of computing system. This approach solves the Markov model of Cloud service Provider (CSP) to predict the reliability. The SPM is better compared to matrix geometric methods.},
  keywords={},
  doi={10.1109/ICACCE46606.2019.9080012},
  ISSN={},
  month={April},}@INPROCEEDINGS{7016607,
  author={Abdeladim, Alfath and Baina, Salah and Baina, Karim},
  booktitle={2014 Third IEEE International Colloquium in Information Science and Technology (CIST)}, 
  title={Elasticity and scalability centric quality model for the cloud}, 
  year={2014},
  volume={},
  number={},
  pages={135-140},
  abstract={Cloud computing seems to be the most logical shift in terms of Information Technology after Internet, Social Networking. Despite the potential benefits that cloud computing offers, the model brings new issues, challenges, and needs in term of SLA formalization, Quality of Service (QoS) evaluation due to the heterogeneous resources and to the special features it implies, such as Elasticity and Scalability. In the scope of this paper we focus on the Elasticity and Scalability attributes to assess their impact on the QoS. The paper provides a multi-lenses overview that can help both cloud consumers and potential business application's owners to understand, analyze, and evaluate important aspects related to Scalability and Elasticity capabilities. We determine and analyze the key features of these characteristics and derive metrics that evaluate the cloud elasticity-centric capabilities. We present a specific quality model for those two characteristics derived from their sub-attributes.},
  keywords={},
  doi={10.1109/CIST.2014.7016607},
  ISSN={2327-1884},
  month={Oct},}@INPROCEEDINGS{7182659,
  author={Young-Rok Shin and Eui-Nam Huh},
  booktitle={2015 Seventh International Conference on Ubiquitous and Future Networks}, 
  title={QoE metrics aggregation for hierarchical Service Level Agreement in Cross-Layered SLA architecture}, 
  year={2015},
  volume={},
  number={},
  pages={831-836},
  abstract={Numerous services are developed using cloud computing technology. It is possible to use service from remote location, not in place of local computer. Accordingly, the research groups predict that the scale of cloud service also will be grown. One of cloud computing's advantage is scalability. It can extend its service scale and range using collaboration between cloud service providers. To make it possible, however, interoperability is required in that environment. Cross-Layered SLA architecture is the cloud service environment that supports interoperability. In this paper, we propose aggregation functions and quality model for QoE metrics and newly generating Service Level Agreement in cross-layered SLA architecture. We expect that this aggregation function and quality model will solve the possible problems in the cloud service area.},
  keywords={},
  doi={10.1109/ICUFN.2015.7182659},
  ISSN={2165-8536},
  month={July},}@INPROCEEDINGS{7474163,
  author={Bousselmi, Khadija and Brahmi, Zaki and Gammoudi, Mohamed Mohsen},
  booktitle={2016 IEEE 30th International Conference on Advanced Information Networking and Applications (AINA)}, 
  title={QoS-Aware Scheduling of Workflows in Cloud Computing Environments}, 
  year={2016},
  volume={},
  number={},
  pages={737-745},
  abstract={Cloud Computing has emerged as a service model that enables on-demand network access to a large number of available virtualized resources and applications with a minimal management effort and a minor price. The spread of Cloud Computing technologies allowed dealing with complex applications such as Scientific Workflows, which consists of a set of intensive computational and data manipulation operations. Cloud Computing helps such Workflows to dynamically provision compute and storage resources necessary for the execution of its tasks thanks to the elasticity asset of these resources. However, the dynamic nature of the Cloud incurs new challenges, as some allocated resources may be overloaded or out of access during the execution of the Workflow. Moreover, for data intensive tasks, the allocation strategy should consider the data placement constraints since data transmission time can increase notably in this case which implicates the increase of the overall completion time and cost of the Workflow. Likewise, for intensive computational tasks, the allocation strategy should consider the type of the allocated virtual machines, more specifically its CPU, memory and network capacities. Yet, a critical challenge is how to efficiently schedule the Workflow tasks on Cloud resources to optimize its overall quality of service. In this paper, we propose a QoS-aware algorithm for Scientific Workflows scheduling that aims to improve the overall quality of service (QoS) by considering the metrics of execution time, data transmission time, cost, resources availability and data placement constraints. We extended the Parallel Cat Swarm Optimization (PCSO) algorithm to implement our proposed approach. We tested our algorithm within two sample Workflows of different scales and we compared the results to those given by the standard PSO, the CSO and the PCSO algorithms. The results show that our proposed algorithm improves the overall quality of service of the tested Workflows.},
  keywords={},
  doi={10.1109/AINA.2016.72},
  ISSN={1550-445X},
  month={March},}@ARTICLE{8204552,
  author={Sun, Chang-ai and Pan, Lin and Wang, Qiaoling and Liu, Huai and Zhang, Xiangyu},
  journal={The Computer Journal}, 
  title={An Empirical Study on Mutation Testing of WS-BPEL Programs}, 
  year={2017},
  volume={60},
  number={1},
  pages={143-158},
  abstract={Nowadays, applications are increasingly deployed as Web services in the globally distributed cloud computing environment. Multiple services are normally composed to fulfill complex functionalities. Business Process Execution Language for Web Services (WS-BPEL) is an XML-based service composition language that is used to define a complex business process by orchestrating multiple services. Compared with traditional applications, WS-BPEL programs pose many new challenges to the quality assurance, especially testing, of service compositions. A number of techniques have been proposed for testing WS-BPEL programs, but only a few studies have been conducted to systematically evaluate the effectiveness of these techniques. Mutation testing has been widely acknowledged as not only a testing method in its own right but also a popular technique for measuring the fault-detection effectiveness of other testing methods. Several previous studies have proposed a family of mutation operators for generating mutants by seeding various faults into WS-BPEL programs. In this study, we conduct a series of empirical studies to evaluate the applicability and effectiveness of various mutation operators for WS-BPEL programs. The experimental results provide insightful and comprehensive guidance for mutation testing of WS-BPEL programs in practice. In particular, our work is the systematic study in the selection of effective mutation operators specifically for WS-BPEL programs.},
  keywords={},
  doi={10.1093/comjnl/bxw076},
  ISSN={1460-2067},
  month={Jan},}@INPROCEEDINGS{8350688,
  author={Indrawati and Puspita, Fitri Maya and Erlita, Sri and Nadeak, Inosensius and Arisha, Bella},
  booktitle={2018 International Conference on Information and Communications Technology (ICOIACT)}, 
  title={LINGO-based optimization problem of cloud computing of bandwidth consumption in the Internet}, 
  year={2018},
  volume={},
  number={},
  pages={436-441},
  abstract={Optimization problem is an important issue in the network Internet. With the dynamic approach in modeling networks, we can strengthen network performance and ensure that the cost will be minimized and profit of provider can be maximized. This research aims to study, analyze the scheme for cloud networking and formulate a plan of new models of dynamic networks and can work under a cloud of wireless networks. Mixed Integer Non Linear Programming (MINLP) is an integer linear programming model to optimize a particular purpose. In MINLP process, the objective function is determined beforehand. The optimal solution of MINLP lies in the majority of decision variables that can be an integer, Boolean or fractions. Model Cloud computing is one of the areas that is most discussed and promising in modern computer science. Cloud computing is a computing model in which resources such as processors, storage, network and software information that can be accessed by customers via the Internet. In the cloud computing implementation, we require a good traffic for performance and reliability of the system is maintained. QoS (Quality of Services) refers to the distribution of bandwidth. QoS is used as a measure of whether or not the characteristics of the network to meet the needs of different services that use the same infrastructure. Tests carried out on the quality of service parameters, namely, delay, packet loss, throughput and bandwidth. To formulate and solve optimization problems used LINGO software applications. The results show that by designing the optimization problem, the cost of consumption of the demand of the internet can be reduced; the maximum profit for the provider can be increased.},
  keywords={},
  doi={10.1109/ICOIACT.2018.8350688},
  ISSN={},
  month={March},}@INPROCEEDINGS{9732606,
  author={Le, Van Thanh and El Ioini, Nabil and Pahl, Claus and Barzegar, Hamid R. and Ardagna, Claudio},
  booktitle={2021 Sixth International Conference on Fog and Mobile Edge Computing (FMEC)}, 
  title={A Distributed Trust Layer for Edge Infrastructure}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  abstract={Recently, Mobile Edge Cloud computing (MEC) has attracted attention both from academia and industry. The idea of moving a part of cloud resources closer to users and data sources can bring many advantages in terms of speed, data traffic, security and context-aware services. The MEC infrastructure does not only host and serves applications next to the end-users, but services can be dynamically migrated and reallocated as mobile users move in order to guarantee latency and performance constraints. This specific requirement calls for the involvement and collaboration of multiple MEC providers, which raises a major issue related to trustworthiness. Two main challenges need to be addressed: i) trustworthiness needs to be handled in a manner that does not affect latency or performance, ii) trustworthiness is considered in different dimensions - not only security metrics but also performance and quality metrics in general. In this paper, we propose a trust layer for public MEC infrastructure that handles establishing and updating trust relations among all MEC entities, making the interaction withing a MEC network transparent. First, we define trust attributes affecting the trusted quality of the entire infrastructure and then a methodology with a computation model that combines these trust attribute values. Our experiments showed that the trust model allows us to reduce latency by removing the burden from a single MEC node, while at the same time increase the network trustworthiness.},
  keywords={},
  doi={10.1109/FMEC54266.2021.9732606},
  ISSN={},
  month={Dec},}@ARTICLE{6595652,
  author={Xia, Yunni and Zhou, MengChu and Luo, Xin and Zhu, Qingsheng and Li, Jia and Huang, Yu},
  journal={IEEE Transactions on Automation Science and Engineering}, 
  title={Stochastic Modeling and Quality Evaluation of Infrastructure-as-a-Service Clouds}, 
  year={2015},
  volume={12},
  number={1},
  pages={162-170},
  abstract={Cloud computing is a recently developed new technology for complex systems with massive service sharing, which is different from the resource sharing of the grid computing systems. In a cloud environment, service requests from users go through numerous provider-specific steps from the instant it is submitted to when the requested service is fully delivered. Quality modeling and analysis of clouds are not easy tasks because of the complexity of the automated provisioning mechanism and dynamically changing cloud environment. This work proposes an analytical model-based approach for quality evaluation of Infrastructure-as-a-Service cloud by considering expected request completion time, rejection probability, and system overhead rate as key quality metrics. It also features with the modeling of different warm-up and cool-down strategies of machines and the ability to identify the optimal balance between system overhead and performance. To validate the correctness of the proposed model, we obtain simulative quality-of-service (QoS) data and conduct a confidence interval analysis. The result can be used to help design and optimize industrial cloud computing systems.},
  keywords={},
  doi={10.1109/TASE.2013.2276477},
  ISSN={1558-3783},
  month={Jan},}@INPROCEEDINGS{8394855,
  author={Bouzidi, Mohammed Ridha and Soltani, Abdelghani and Bouhank, Asma and Daoudi, Mourad},
  booktitle={2018 5th International Conference on Control, Decision and Information Technologies (CoDIT)}, 
  title={New Search Based Methods to Solve Workflow Scheduling Problem in Cloud Computing}, 
  year={2018},
  volume={},
  number={},
  pages={647-652},
  abstract={Scheduling has a big influence on the performance of the cloud computing environment, and still remains of big interest for researchers, in particular when a certain level of quality should be maintained in order to satisfy the customer. We consider the particular scheduling multiobjective optimization problem of allocating workflows to the resources of a cloud computing environment, by managing four QoS metrics: makespan, cost, reliability and the availability. It belongs to a category of NP Hard problems. A particular metaheuristic, BBO is investigated. New workflow scheduling BBO based methods are proposed. Further, two multiobjective pareto based optimization methods MOHEFT and NSGA-II are considered in solving our problem. Tests are performed on well-known benchmarks, showing a good behavior of the different methods.},
  keywords={},
  doi={10.1109/CoDIT.2018.8394855},
  ISSN={2576-3555},
  month={April},}@INPROCEEDINGS{9627219,
  author={Patel, Jatin and Halabi, Talal},
  booktitle={2021 IEEE 6th International Conference on Smart Cloud (SmartCloud)}, 
  title={Optimizing the Performance of Web Applications in Mobile Cloud Computing}, 
  year={2021},
  volume={},
  number={},
  pages={33-37},
  abstract={Cloud computing adoption is on the rise. Many organizations have decided to shift their workload to the cloud to benefit from the scalability, resilience, and cost reduction characteristics. Mobile Cloud Computing (MCC) is an emerging computing paradigm that also provides many advantages to mobile users. Mobile devices function on wireless internet connectivity, which entails issues of limited bandwidth and network congestion. Hence, the primary focus of Web applications in MCC is on improving performance by quickly fulfilling customer's requests to improve service satisfaction. This paper investigates a new approach to caching data in these applications using Redis, an in-memory data store, to enhance Quality of Service. We highlight the two implementation approaches of fetching the data of an application either directly from the database or from the cache. Our experimental analysis shows that, based on performance metrics such as response time, throughput, latency, and number of hits, the caching approach achieves better performance by speeding up the data retrieval by up to four times. This improvement is of significant importance in mobile devices considering their limitation of network bandwidth and wireless connectivity.},
  keywords={},
  doi={10.1109/SmartCloud52277.2021.00013},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{7000073,
  author={Ravanello, Anderson and Desharnais, Jean-Marc and Bautista Villalpando, Luis Eduardo and April, Alain and Gherbi, Abdelouahed},
  booktitle={2014 Joint Conference of the International Workshop on Software Measurement and the International Conference on Software Process and Product Measurement}, 
  title={Performance Measurement for Cloud Computing Applications Using ISO 25010 Standard Characteristics}, 
  year={2014},
  volume={},
  number={},
  pages={41-49},
  abstract={Measuring the performance of cloud computing-based applications using ISO quality characteristics is a complex activity for various reasons, among them the complexity of the typical cloud computing infrastructure on which an application operates. To address this issue, the authors use Bautista's proposed performance measurement framework [1] on log data from an actual data centre to map and statistically analyze one of the ISO quality characteristics: time behavior. This empirical case study was conducted on an industry private cloud. The results of the study demonstrate that it is possible to use the proposed performance measurement framework in a cloud computing context. They also show that the framework holds great promise for expanding the experimentation to other ISO quality characteristics, larger volumes of data, and other statistical techniques that could be used to analyze performance.},
  keywords={},
  doi={10.1109/IWSM.Mensura.2014.33},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9581580,
  author={Zolait, Ali Hussein and Alalas, Sumaya and Ali, Noor and Showaiter, Aya},
  booktitle={2021 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT)}, 
  title={Quality of Life Integrated Framework: Perspective of Cloud Computing Usage}, 
  year={2021},
  volume={},
  number={},
  pages={537-544},
  abstract={This research aims to measure the impact of cloud computing on people's quality of life in the Kingdom of Bahrain and recognize factors that could impact people's intention to use cloud computing services. An online survey has been used to collect primary data for the research. It was distributed to a random sample of 443 respondents in the Kingdom of Bahrain. The achievable sample comprised 394 represent people of different ages and educational levels. The researchers adapted selected factors from the diffusion of innovation (DOI) theory, including relative advantage, complexity, and compatibility. In addition to the quality of life factors consisting of education, healthcare, wellbeing, and entertainment. These factors are used to establishing the framework of this research. The research limitation was in examining only the variables proposed in the framework. Also, as a consequence of the coronavirus's current situation (COVID-19), collecting data was restricted to the quantitative approach using an online survey. Findings show that administrability of cloud computing usage is the most impacting factor on people's quality of life and, more specifically, on people's education.},
  keywords={},
  doi={10.1109/3ICT53449.2021.9581580},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8818401,
  author={Yu, Guangba and Chen, Pengfei and Zheng, Zibin},
  booktitle={2019 IEEE International Conference on Web Services (ICWS)}, 
  title={Microscaler: Automatic Scaling for Microservices with an Online Learning Approach}, 
  year={2019},
  volume={},
  number={},
  pages={68-75},
  abstract={Recently, the microservice becomes a popular architecture to construct cloud native systems due to its agility. In cloud native systems, autoscaling is a core enabling technique to adapt to workload changes by scaling out/in. However, it becomes a challenging problem in a microservice system, since such a system usually comprises a large number of different micro services with complex interactions. When bursty and unpredictable workloads arrive, it is difficult to pinpoint the scaling-needed services which need to scale and evaluate how much resource they need. In this paper, we present a novel system named Microscaler to automatically identify the scaling-needed services and scale them to meet the service level agreement (SLA) with an optimal cost for micro-service systems. Microscaler collects the quality of service metrics (QoS) with the help of the service mesh enabled infrastructure. Then, it determines the under-provisioning or over-provisioning services with a novel criterion named service power. By combining an online learning approach and a step-by-step heuristic approach, Microscaler could achieve the optimal service scale satisfying the SLA requirements. The experimental evaluations in a micro-service benchmark show that Microscaler converges to the optimal service scale faster than several state-of-the-art methods.},
  keywords={},
  doi={10.1109/ICWS.2019.00023},
  ISSN={},
  month={July},}@INPROCEEDINGS{9165482,
  author={Khan, Michel Gokan and Taheri, Javid and Khoshkholghi, Mohammad Ali and Kassler, Andreas and Cartwright, Carolyn and Darula, Marian and Deng, Shuiguang},
  booktitle={2020 6th IEEE Conference on Network Softwarization (NetSoft)}, 
  title={A Performance Modelling Approach for SLA-Aware Resource Recommendation in Cloud Native Network Functions}, 
  year={2020},
  volume={},
  number={},
  pages={292-300},
  abstract={Network Function Virtualization (NFV) becomes the primary driver for the evolution of 5G networks, and in recent years, Network Function Cloudification (NFC) proved to be an inevitable part of this evolution. Microservice architecture also becomes the de facto choice for designing a modern Cloud Native Network Function (CNF) due to its ability to decouple components of each CNF into multiple independently manageable microservices. Even though taking advantage of microservice architecture in designing CNFs solves specific problems, this additional granularity makes estimating resource requirements for a Production Environment (PE) a complex task and sometimes leads to an over-provisioned PE. Traditionally, performance engineers dimension each CNF within a Service Function Chain (SFC) in a smaller Performance Testing Environment (PTE) through a series of performance benchmarks. Then, considering the Quality of Service (QoS) constraints of a Service Provider (SP) that are guaranteed in the Service Level Agreement (SLA), they estimate the required resources to set up the PE. In this paper, we used a machine learning approach to model the impact of each microservice's resource configuration (i.e., CPU and memory) on the QoS metrics (i.e. serving throughput and latency) of each SFC in a PTE. Then, considering an SP's Service Level Objectives (SLO), we proposed an algorithm to predict each microservice's resource capacities in a PE. We evaluated the accuracy of our prediction on a prototype of a cloud native 5G Home Subscriber Server (HSS). Our model showed 95%-78% accuracy in a PE that has 2-5 times more computing resources than the PTE.},
  keywords={},
  doi={10.1109/NetSoft48620.2020.9165482},
  ISSN={},
  month={June},}@INPROCEEDINGS{9582214,
  author={Aggarwal, Pooja and Nagar, Seema and Gupta, Ajay and Shwartz, Larisa and Mohapatra, Prateeti and Wang, Qing and Paradkar, Amit and Mandal, Atri},
  booktitle={2021 IEEE 14th International Conference on Cloud Computing (CLOUD)}, 
  title={Causal Modeling based Fault Localization in Cloud Systems using Golden Signals}, 
  year={2021},
  volume={},
  number={},
  pages={124-135},
  abstract={In cloud-native applications, a large fraction of operational failures, known as outages, result in violations of Service Level Objectives (SLOs). SLOs are defined around specific measurable characteristics: availability, throughput, frequency, response time, and quality. Four metrics, latency, traffic, errors, and saturation, ensure coverage for most outages of an application. These are often called golden signals. The dynamicity and complexity of cloud-native applications complicate Site Reliability Engineers’ (SREs) efforts in problem determination, in particular in its fault localization. The fault localization is often a try-and-error process in which SREs rely on their domain knowledge and experience. It is laborious and frequently results in long Mean Time To Resolution (MTTR) for outages. This paper describes a lightweight fault localization system, that establishes causal relationships among the golden signal service errors and error logs, and further leverages PageRank centrality of the derived causal graph for generating a ranked list of faulty microservices.},
  keywords={},
  doi={10.1109/CLOUD53861.2021.00026},
  ISSN={2159-6190},
  month={Sep.},}@INPROCEEDINGS{7982313,
  author={Althani, B. and Khaddaj, S. and Makoond, B.},
  booktitle={2016 IEEE Intl Conference on Computational Science and Engineering (CSE) and IEEE Intl Conference on Embedded and Ubiquitous Computing (EUC) and 15th Intl Symposium on Distributed Computing and Applications for Business Engineering (DCABES)}, 
  title={A Quality Assured Framework for Cloud Adaptation and Modernization of Enterprise Applications}, 
  year={2016},
  volume={},
  number={},
  pages={634-637},
  abstract={Cloud Computing has emerged as a viable alternative to in-house computing resources for many organisations. It offers an alternative solution for many enterprise applications, particularly large-scale legacy applications. In addition, it can offer a cost effective strategy for small and medium-sized enterprises (SMEs) where the high set-up and maintenance cost of computing resources can be prohibiting. Thus, in this paper a System Migration Life Cycle (SMLC) framework is proposed, which includes a step by-stepmigration strategy that is descriptive at the business analyst level and based on quality metrics modelling at the technical level, to estimate the potential computational needs, risks, and costs for an organisation. The proposed framework is generic and adaptable in order to accommodate various organisational requirements, thus covering a wide range of enterprise applications and following a number of novel software requirements and quality engineering principles.},
  keywords={},
  doi={10.1109/CSE-EUC-DCABES.2016.251},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8821787,
  author={Mahenge, Michael P. J. and Li, Chunlin and Sanga, Camilius A.},
  booktitle={2019 IEEE 4th International Conference on Computer and Communication Systems (ICCCS)}, 
  title={Collaborative Mobile Edge and Cloud Computing: Tasks Unloading for Improving Users’ Quality of Experience in Resource-Intensive Mobile Applications}, 
  year={2019},
  volume={},
  number={},
  pages={322-326},
  abstract={The advancement in resource-intensive and latency-sensitive applications challenge the legacy systems in Mobile Cloud Computing (MCC) in terms of network congestion, bandwidth utilization, performance and Quality of Service (QoS) metrics. Such challenges emanate from first, limited energy sources and resource poverty of mobile devices. Second, multi-hop connection between user devices and the cloud. To address such challenges, mobile edge computing is a promising solution. This study proposes an architecture that considers unloading resource-intensive tasks from clients' devices to more resourceful edge servers which exploit cooperative approach for tasks processing. Thus, it is essential for minimizing delay, bandwidth usage, congestion to the core network and guarantees cost-effective approach for meeting user's demands. The simulation results show that the proposed approach through unloading, it reduces response time and energy usage. This in turn improves performance, system utility and Quality of Experience (QoE).},
  keywords={},
  doi={10.1109/CCOMS.2019.8821787},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{6897195,
  author={Baliyan, Niyati and Kumar, Sandeep},
  booktitle={2014 Seventh International Conference on Contemporary Computing (IC3)}, 
  title={Towards software engineering paradigm for software as a service}, 
  year={2014},
  volume={},
  number={},
  pages={329-333},
  abstract={The Software as a Service model of Cloud Computing offers economies of scale through the pay per use model; however, it renders the modern software very different from traditional software. Hence, there is a need to adapt Software Engineering approach in a manner that will make the development process and delivery of Software as a Service more efficient and of high quality. After performing literature review, a classification of ongoing research in this direction of adaptation is presented. Various research gaps in the areas of software development process, software reengineering, measurement, metrics, and quality models targeted at Software as a Service are identified, which can be a first step towards the definition of standards and guidelines for Software as a Service development.},
  keywords={},
  doi={10.1109/IC3.2014.6897195},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{7170460,
  author={Armando Cabrera, S. and Abad, E. Marco and Danilo Jaramillo, H. and Poma, G. Ana and Verdúm, José Carrillo},
  booktitle={2015 10th Iberian Conference on Information Systems and Technologies (CISTI)}, 
  title={Incidence of software quality attributes in the design, construction and deployment of Cloud architectural environments}, 
  year={2015},
  volume={},
  number={},
  pages={1-7},
  abstract={Cloud Computing (CC) is a new paradigm in the world of computing, it includes several service and deployment models. This project is part of a general study that starts from the software engineering process and the software development life cycle (SDLC), this study is based on the ISO / IEC / IEEE 12207 standard, to evaluate the software implementation process and then we review some software quality aspects by applying the standard ISO / IEC 9126; finally we review some key terms, features, models, architecture, taxonomy, deployment scenarios and scope statements of Cloud Computing. After that we proceed to identify the key characteristics of private and public SaaS environments and obtained a quality model of service (QoS) using quality attributes and their corresponding metrics derived from the ISO / IEC 9126 Standard.},
  keywords={},
  doi={10.1109/CISTI.2015.7170460},
  ISSN={2166-0727},
  month={June},}@ARTICLE{9097181,
  author={Belgaum, Mohammad Riyaz and Musa, Shahrulniza and Alam, Muhammad Mansoor and Su’ud, Mazliham Mohd},
  journal={IEEE Access}, 
  title={A Systematic Review of Load Balancing Techniques in Software-Defined Networking}, 
  year={2020},
  volume={8},
  number={},
  pages={98612-98636},
  abstract={The traditional networks are facing difficulties in managing the services offered by cloud computing, big data, and the Internet of Things as the users have become more dependent on their services. Software-Defined Networking (SDN) has pulled enthusiasm in the integration process of technologies and function as per the user's requirements for both academia and industry, and it has begun to be embraced in actual framework usage. The emergence of SDN has given another idea to empower the focal programmability of the system. Because of the increasing demand and the scarcity of resources, the load balancing issue needs to be addressed efficiently to manage the incoming traffic and resources and to improve network performance. One of the most critical issues is the role of the controller in SDN to balance the load for having a better Quality of Service (QoS). Though there are few survey articles written on load balancing, there is no detail and systematic review conducted in load balancing in SDN. Hence, this paper extends and reviews the discussion with a taxonomy of current emerging load balancing techniques in SDN systematically by categorizing the techniques as conventional and artificial intelligence-based techniques to improve the service quality. The review also includes the study of metrics and parameters which have been used to measure the performance. This review would allow gaining more information on load balancing approaches in SDN and enables the researchers to fill the current research gaps.},
  keywords={},
  doi={10.1109/ACCESS.2020.2995849},
  ISSN={2169-3536},
  month={},}@ARTICLE{8737926,
  author={Liu, Ying and Wang, Ke and Ge, Liang and Ye, Lei and Cheng, Jingde},
  journal={IEEE Access}, 
  title={Adaptive Evaluation of Virtual Machine Placement and Migration Scheduling Algorithms Using Stochastic Petri Nets}, 
  year={2019},
  volume={7},
  number={},
  pages={79810-79824},
  abstract={More and more mobile applications rely on the combination of both mobile and cloud computing technology to bring out their full potential. The cloud is usually used for providing additional computing resources that cannot be handled efficiently by the mobile devices. Cloud usage, however, results in several challenges related to the management of virtualized resources. A large number of scheduling algorithms are proposed to balance between performance and cost of data center. Due to huge cost and time consuming of measure-based and simulation method, this paper proposes an adaptive method to evaluate scheduling algorithms. In this method, the virtual machine placement and migration process are modeled by using Stochastic Reward Nets. Different scheduling methods are described as reward functions to perform the adaptive evaluation. Two types of performance metrics are also discussed: one is about quality of service, such as system availability, mean waiting time, and mean service time, and the other is the cost of runtime, such as energy consumption and cost of migration. Compared to a simulation method, the analysis model in this paper only modifies the reward function for different scheduling algorithms and does not need to reconstruct the process. The numeric results suggest that it also has a good accuracy and can quantify the influence of scheduling algorithms on both quality of service and cost of runtime.},
  keywords={},
  doi={10.1109/ACCESS.2019.2923592},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7312289,
  author={Zhang, Xiaodong and Dechen, Zhan and Nie, Lanshun and Zhao, Tianqi and Xiong, Xiao},
  booktitle={2014 International Conference on Service Sciences}, 
  title={An Optimal Service-Selection Model Based on Capability and Quality of Resource Service}, 
  year={2014},
  volume={},
  number={},
  pages={47-52},
  abstract={Most of the researches on optimal service selection are based on the assumption that the capabilities of the services fully meet the requirements. Their limitation is the ignorance of the resources which is the basic factor supporting the implementation of services and it may cause a waste of resources. In cloud computing environment which benefits from its large-scale, there are a large number of resources. Therefore, the waste of resources in it would be a big problem. This paper introduces 'service equivalent' as the basic metric to measure the capabilities of service resources and proposes an optimal service selection model based on capability and quality of service resources and algorithm, in order to solve the issues about the matching capability of service resource and the optimal selection of service resource based on quality. Finally it proves that the model can effectively reduce the waste of resources by the test, which achieves the expected goal.},
  keywords={},
  doi={10.1109/ICSS.2014.39},
  ISSN={2165-3836},
  month={May},}@INPROCEEDINGS{9412544,
  author={Paolanti, Marina and Mameli, Marco and Frontoni, Emanuele and Gioacchini, Giorgia and Giorgini, Elisabetta and Notarstefano, Valentina and Zacà, Carlotta and Carnevali, Oliana and Borini, Andrea},
  booktitle={2020 25th International Conference on Pattern Recognition (ICPR)}, 
  title={Automatic Classification of Human Granulosa Cells in Assisted Reproductive Technology using vibrational spectroscopy imaging}, 
  year={2021},
  volume={},
  number={},
  pages={209-216},
  abstract={In the field of reproductive technology, the biochemical composition of female gametes has been successfully investigated with the use of vibrational spectroscopy. Currently, in assistive reproductive technology (ART), there are no shared criteria for the choice of oocyte, and automatic classification methods for the best quality oocytes have not yet been applied. In this paper, considering the lack of criteria in Assisted Reproductive Technology (ART), we use Machine Learning (ML) techniques to predict oocyte quality for a successful pregnancy. To improve the chances of successful implantation and minimize any complications during the pregnancy, Fourier transform infrared microspectroscopy (FTIRM) analysis has been applied on granulosa cells (GCs) collected along with the oocytes during oocyte aspiration, as it is routinely done in ART, and specific spectral biomarkers were selected by multivariate statistical analysis. A proprietary biological reference dataset (BRD) was successfully collected to predict the best oocyte for a successful pregnancy. Personal health information are stored, maintained and backed up using a cloud computing service. Using a user-friendly interface, the user will evaluate whether or not the selected oocyte will have a positive result. This interface includes a dashboard for retrospective analysis, reporting, real-time processing, and statistical analysis. The experimental results are promising and confirm the efficiency of the method in terms of classification metrics: precision, recall, and F1-score (F1) measures.},
  keywords={},
  doi={10.1109/ICPR48806.2021.9412544},
  ISSN={1051-4651},
  month={Jan},}@INPROCEEDINGS{8230005,
  author={Kumar, Somansh and Jasuja, Ashish},
  booktitle={2017 International Conference on Computing, Communication and Automation (ICCCA)}, 
  title={Air quality monitoring system based on IoT using Raspberry Pi}, 
  year={2017},
  volume={},
  number={},
  pages={1341-1346},
  abstract={Air pollution is the largest environmental and public health challenge in the world today. Air pollution leads to adverse effects on Human health, climate and ecosystem. Air is getting polluted because of release of Toxic gases by industries, vehicular emissions and increased concentration of harmful gases and particulate matter in the atmosphere. Particulate matter is one of the most important parameter having the significant contribution to the increase in air pollution. This creates a need for measurement and analysis of real-time air quality monitoring so that appropriate decisions can be taken in a timely period. This paper presents a real-time standalone air quality monitoring system which includes various parameters: PM 2.5, carbon monoxide, carbon dioxide, temperature, humidity and air pressure. Internet of Things is nowadays finding profound use in each and every sector, plays a key role in our air quality monitoring system too. Internet of Things converging with cloud computing offers a novel technique for better management of data coming from different sensors, collected and transmitted by low power, low cost ARM based minicomputer Raspberry pi. The system is tested in Delhi and the measurements are compared with the data provided by the local environment control authority and are presented in a tabular form. The values of the parameters measured are shown in IBM Bluemix Cloud.},
  keywords={},
  doi={10.1109/CCAA.2017.8230005},
  ISSN={},
  month={May},}@INPROCEEDINGS{9080705,
  author={Hussain, Mujahid and Aleem, Sadaf and Karim, Arif and Ghazanfar, Faisal and Hai, Mansoor and Hussain, Kashif},
  booktitle={2020 International Conference on Emerging Trends in Smart Technologies (ICETST)}, 
  title={Design of Low Cost, Energy Efficient, IoT Enabled, Air Quality Monitoring System with Cloud Based Data Logging, Analytics and AI}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper presents a design of real-time Air Quality Monitoring System (AQMS) which incorporates Internet of Things (IoT) and cloud computing. AQMS utilizes solar panel and battery pack for independent and autonomous operation, thus, making it self-powered and sustainable. AQMS is based on AVR Microcontroller (Atmega32) and GSM modem (Sim900) for connectivity with the cloud application. The design is made low cost and scalable so that around 50nos. of such systems can be installed on roundabouts of market places, residential and industrial areas. The AQMS monitors the air quality with the help of a miniature suction pump (5volt DC) which establishes a controlled and constant stream of air-flow through a manifold that encapsulates electromechanical sensors, thus measuring the concentration of O2, CO, CO2, SO / SO2 (SOx), NO/ NO2 (NOx), Hydrocarbon (CxHx), temperature, humidity and noise. By default, the air sampling is carried out once in an hour which may be changed depending on the change in air quality, i.e. making it adoptive for energy conservation and extending the sensor's life. The data collected at the cloud application will be processed using data analytics and Artificial Intelligence (AI) for getting insights of data (data mining) regarding the potential locations where the emissions are critical and disastrous for environmental, thus, leading to prevent any mishap. The design is mapped over a metropolitan city of Pakistan, i.e. Karachi, thus initiating the transformation of Karachi to a smart city.},
  keywords={},
  doi={10.1109/ICETST49965.2020.9080705},
  ISSN={},
  month={March},}@INPROCEEDINGS{7883186,
  author={Shan Luo and Yanhui Zhou},
  booktitle={2016 7th IEEE International Conference on Software Engineering and Service Science (ICSESS)}, 
  title={How to guarantee the cloud services quality}, 
  year={2016},
  volume={},
  number={},
  pages={791-795},
  abstract={At present, cloud computing is used widely. Cloud services through the cloud platform provide various services to users. And cloud services will play an increasingly important role in the economy and society. Service level agreement (SLA) is an indispensable part of information service in the cloud environment. It is not only the legal protection of the quality of the cloud services, but also provides the service terms and services between the providers and users. Cloud services quality is directly reflected in the user's satisfaction, and it is still a problem to be solved. In this paper, a simple cloud SLA model is proposed to solve the problem of cloud service quality which cannot be measured by the SLA case.},
  keywords={},
  doi={10.1109/ICSESS.2016.7883186},
  ISSN={2327-0594},
  month={Aug},}@INPROCEEDINGS{7349726,
  author={Shi, Peichang and Gangopadhyay, Aryya},
  booktitle={2015 International Conference on Healthcare Informatics}, 
  title={Personalized Health Plan Ranking - One Application of Cloud Computing to Health Care Data}, 
  year={2015},
  volume={},
  number={},
  pages={447-447},
  abstract={Health plan ranking is one important factor when people are considering their health plan selection. The current health plan ranking is done by National Committee for Quality Assurance, which calculates the ratings based on three types of quality measures and gives an overall ranking of health plans. Individual consumers may be more interested in the ranks of health plans for people with similar conditions. For example, what is the plan ranking for people with both asthma and diabetes? This paper will explore how to combine some data mining techniques and cloud computing to provide a personalized health plan ranking based on each individual's physical conditions.},
  keywords={},
  doi={10.1109/ICHI.2015.65},
  ISSN={},
  month={Oct},}@ARTICLE{8016558,
  author={Mubeen, Saad and Asadollah, Sara Abbaspour and Papadopoulos, Alessandro Vittorio and Ashjaei, Mohammad and Pei-Breivold, Hongyu and Behnam, Moris},
  journal={IEEE Access}, 
  title={Management of Service Level Agreements for Cloud Services in IoT: A Systematic Mapping Study}, 
  year={2018},
  volume={6},
  number={},
  pages={30184-30207},
  abstract={Cloud computing and Internet of Things (IoT) are computing technologies that provide services to consumers and businesses, allowing organizations to become more agile and flexible. Therefore, ensuring quality of service (QoS) through service-level agreements (SLAs) for such cloud-based services is crucial for both the service providers and service consumers. As SLAs are critical for cloud deployments and wider adoption of cloud services, the management of SLAs in cloud and IoT has thus become an important and essential aspect. This paper investigates the existing research on the management of SLAs in IoT applications that are based on cloud services. For this purpose, a systematic mapping study (a well-defined method) is conducted to identify the published research results that are relevant to SLAs. This paper identifies 328 primary studies and categorizes them into seven main technical classifications: SLA management, SLA definition, SLA modeling, SLA negotiation, SLA monitoring, SLA violation and trustworthiness, and SLA evolution. This paper also summarizes the research types, research contributions, and demographic information in these studies. The evaluation of the results shows that most of the approaches for managing SLAs are applied in academic or controlled experiments with limited industrial settings rather than in real industrial environments. Many studies focus on proposal models and methods to manage SLAs, and there is a lack of focus on the evolution perspective and a lack of adequate tool support to facilitate practitioners in their SLA management activities. Moreover, the scarce number of studies focusing on concrete metrics for qualitative or quantitative assessment of QoS in SLAs urges the need for in-depth research on metrics definition and measurements for SLAs.},
  keywords={},
  doi={10.1109/ACCESS.2017.2744677},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7037641,
  author={Kritikos, Kyriakos and Domaschka, Jörg and Rossini, Alessandro},
  booktitle={2014 IEEE 6th International Conference on Cloud Computing Technology and Science}, 
  title={SRL: A Scalability Rule Language for Multi-cloud Environments}, 
  year={2014},
  volume={},
  number={},
  pages={1-9},
  abstract={The benefits of cloud computing have led to a proliferation of infrastructures and platforms covering the provisioning and deployment requirements of many cloud-based applications. However, the requirements of an application may change during its life cycle. Therefore, its provisioning and deployment should be adapted so that the application can deliver its target quality of service throughout its entire life cycle. Existing solutions typically support only simple adaptation scenarios, whereby scalability rules map conditions on fixed metrics to a single scaling action targeting a single cloud environment (e.g., Scale out an application component). However, these solutions fail to support complex adaptation scenarios, whereby scalability rules could map conditions on custom metrics to multiple scaling actions targeting multi-cloud environments. In this paper, we propose the Scalability Rule Language (SRL), a language for specifying scalability rules that support such complex adaptation scenarios of multi-cloud applications. SRL provides Eclipse-based tool support, thus allowing modellers not only to specify scalability rules but also to syntactically and semantically validate them. Moreover, SRL is well integrated with the Cloud Modelling Language (Cloud ML), thus allowing modellers to associate their scalability rules with the components and virtual machines of provisioning and deployment models.},
  keywords={},
  doi={10.1109/CloudCom.2014.170},
  ISSN={},
  month={Dec},}@ARTICLE{9121263,
  author={Junaid, Muhammad and Sohail, Adnan and Ahmed, Adeel and Baz, Abdullah and Khan, Imran Ali and Alhakami, Hosam},
  journal={IEEE Access}, 
  title={A Hybrid Model for Load Balancing in Cloud Using File Type Formatting}, 
  year={2020},
  volume={8},
  number={},
  pages={118135-118155},
  abstract={Maintaining accuracy in load balancing using metaheuristics is a difficult task even with the help of recent hybrid approaches. In the existing literature, various optimized metaheuristic approaches are being used to achieve their combined benefits for proper load balancing in the cloud. These approaches often adopt multi-objective QoS metrics, such as reduced SLA violations, reduced makespan, high throughput, low overload, low energy consumption, high optimization, minimum migrations, and higher response time. The cloud applications are generally computation-intensive and can grow exponentially in memory with the increase in size if no proper effective and efficient load balancing technique is adopted resulting in poor quality solutions. To provide a better load balancing solution in cloud computing, with extensive data, a new hybrid model is being proposed that performs classification on the number of files present in the cloud using file type formatting. The classification is performed using Support Vector Machine (SVM) considering various file formats such as audio, video, text maps, and images in the cloud. The resultant data class provides high classification accuracy which is further fed into a metaheuristic algorithm namely Ant Colony Optimization (ACO) using File Type Formatting FTF for better load balancing in the cloud. Frequently used QoS metrics, such as SLA violations, migration time, throughput time, overhead time, and optimization time are evaluated in the cloud environment and comparative analysis is performed with recent metaheuristics, such as Ant Colony Optimization-Particle Swarm Optimization (ACOPS), Chaotic Particle Swarm Optimization (CPSO), Q- learning Modified Particle Swarm Optimization (QMPSO), Cat Swarm Optimization (CSO) and D-ACOELB. The proposed algorithm outperforms them and provides good performance with scalability and robustness.},
  keywords={},
  doi={10.1109/ACCESS.2020.3003825},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7558009,
  author={Meng, Shunmei and Zhou, Zuojian and Huang, Taigui and Li, Duanchao and Wang, Song and Fei, Fan and Wang, Wenping and Dou, Wanchun},
  booktitle={2016 IEEE International Conference on Web Services (ICWS)}, 
  title={A Temporal-Aware Hybrid Collaborative Recommendation Method for Cloud Service}, 
  year={2016},
  volume={},
  number={},
  pages={252-259},
  abstract={With the rapid development of cloud computing, large scale of cloud services are provided to users. Recommender systems have been proven to be valuable tools to deal with information overload and be able to provide appropriate recommendations to users. The cloud environment is dynamic and uncertain, which makes the quality of cloud services time-sensitive. However, most existing recommender systems did not take temporal influence into consideration, therefore could not accommodate the dynamic cloud environment. In view of this challenge, we propose a temporal-aware hybrid collaborative recommendation method for cloud service. It aims at providing users with appropriate recommendations from time-sensitive cloud services. In our method, by distinguishing temporal QoS metrics from stable QoS metrics, temporal influence is integrated into classical neighborhood-based collaborative recommender algorithm. Besides, to get an optimal recommendation, a temporal-aware latent factor model based on tensor decomposition is proposed and combined to improve the recommendation performance. Finally, experiments are designed and conducted to demonstrate the efficiency of our method.},
  keywords={},
  doi={10.1109/ICWS.2016.40},
  ISSN={},
  month={June},}@INPROCEEDINGS{9500259,
  author={Ramos, Felipe and Viegas, Eduardo and Santin, Altair and Horchulhack, Pedro and dos Santos, Roger R. and Espindola, Allan},
  booktitle={ICC 2021 - IEEE International Conference on Communications}, 
  title={A Machine Learning Model for Detection of Docker-based APP Overbooking on Kubernetes}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Resource allocation overbooking is an approach used by cloud providers that allocates more virtual resources than available on physical hardware, which may imply service quality degradation. Docker in cloud computing environments is being increasingly used due to their fast provisioning and deployment, while the impact of overbooking of resources allocation due to multi-tenancy remains overlooked. This paper proposes a machine learning model to detect overbooking in Kubernetes environments within the docker container. The proposed model continuously monitors distributed container OS usage and application performance metrics. The collected metrics are used as input to a machine learning model that identifies multi-tenancy interference incurring in application performance degradation. Experiments performed on a Kubernetes cluster with a Docker-based Big Data processing application showed that our proposed model could detect resource overbooking with up to 98% accuracy. This implies an overbooking on a resource of up to 1.2 in the client’s domain.},
  keywords={},
  doi={10.1109/ICC42927.2021.9500259},
  ISSN={1938-1883},
  month={June},}@INPROCEEDINGS{7564810,
  author={Chatterjee, Subarna and Misra, Sudip},
  booktitle={2016 IEEE Wireless Communications and Networking Conference}, 
  title={QoS estimation and selection of CSP in oligopoly environment for Internet of Things}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={This work focuses on an automated selection of Cloud Service Provider (CSP) for a naive end-user in an IoT scenario. In traditional cloud computing model, the end-users are knowledgeable about the Virtual Machines (VMs) and are technically aware of their requirements in terms of the computing cores, processing abilities, and storage requirements. In case of IoT, the users are envisioned to be widespread from naive, unsophisticated people to even objects or things who are devoid of the required knowledge and expertise. Further, in IoT technology, multiple Cloud Service Providers (CSPs) may possess the potential of serving an IoT application. Therefore, it is required for the end-user to judiciously select a single CSP based on the maximum obtainable Quality of Service (QoS) from a CSP. This work proposes an algorithm QoS based Automated Selection of CSP (QASeC) for automated selection of a CSP from a set of nominated CSPs based on the maximum achievable QoS. The work identifies and models the QoS parameters for every CSP and defines a QoS utility metric for each CSP. Based on the metric, the work proposes an optimization for selection of the appropriate CSP and the cloud gateway associated with it. From the obtained results, we infer the suitability of QASeC in real-life IoT scenarios.},
  keywords={},
  doi={10.1109/WCNC.2016.7564810},
  ISSN={1558-2612},
  month={April},}@INPROCEEDINGS{9310816,
  author={Firdhous, M.F.M. and Budiarto, Rahmat},
  booktitle={2020 5th International Conference on Information Technology Research (ICITR)}, 
  title={BTDM: A QoS-based Trust Distribution Mechanism for Cloud Computing}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={Cloud computing makes the delivery of computing resources over the Internet as services. As there are many providers in the market, it is necessary to monitor their performance. Several mechanisms for monitoring service quality of providers have been reported in the literature. But, it is not possible to monitor the entire cloud system by a single monitor. Hence, there is a need for a mechanism to share the performance metrics across a large geographical area. In this paper, the authors propose a mechanism called Bayesian Trust Distribution Mechanism (BTDM) for sharing the performance metrics as trust scores across an extended geographical area. The proposed BTDM also checks the reliability of the received scores based on their previous experience and adjusts them based on the reliability of sender. BTDM was tested using simulations and the results show that it performs better than the other mechanisms reported in the literature.},
  keywords={},
  doi={10.1109/ICITR51448.2020.9310816},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8114483,
  author={Maiyama, Kabiru Muhammad and Kouvatsos, Demetres and Mohammed, Bashir and Kiran, Mariam and Kamala, Mumtaz Ahmed},
  booktitle={2017 IEEE 5th International Conference on Future Internet of Things and Cloud (FiCloud)}, 
  title={Performance Modelling and Analysis of an OpenStack IaaS Cloud Computing Platform}, 
  year={2017},
  volume={},
  number={},
  pages={198-205},
  abstract={Performance is one of the main aspects that should be taken into consideration during the design, development, tuning and optimisation of computer networks supported by cloud computing platforms (CCPs). Queueing network models (QNMs) of CCPs constitute essential quantitative tools of investigation towards identifying acceptable levels of quality-of-service (QoS), whether for upgrading an existing CCP or designing a new one. In this paper, a new stable open QNM with either single or multiple server queueing stations, first-come-first-served (FCFS) scheduling and random routing is proposed for the performance modelling and analysis of an OpenStack Infrastructure as a Service (IaaS) CCP. In this context, it is assumed that the external arrival process is Poisson and the queueing stations provide exponentially distributed service times. Based on Jackson's Theorem, the open QNM is decomposed into individual M/M/c queues with c server(s) (c≥ 1) and exponential inter-arrival and service times, each of which can be analysed in isolation. Consequently, closed form expressions for key performance metrics of the QNM are determined, such as those for the mean response time, throughput, server (resource) utilisation and the probability of the number of requests by clients at each queueing station during waiting for and/or receiving resource provisioning. The evaluation of these metrics identifies the bottlenecks of the CCP that are causing the worst network delays and associated performance degradation and thus, provides insights into the capacity planning of networks with OpenStack IaaS solutions for CSPs.},
  keywords={},
  doi={10.1109/FiCloud.2017.54},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{7930199,
  author={Haupt, Florian and Leymann, Frank and Scherer, Anton and Vukojevic-Haupt, Karolina},
  booktitle={2017 IEEE International Conference on Software Architecture (ICSA)}, 
  title={A Framework for the Structural Analysis of REST APIs}, 
  year={2017},
  volume={},
  number={},
  pages={55-58},
  abstract={Today, REST APIs have established as a means for realizing distributed systems and are supposed to gain even more importance in the context of Cloud Computing, Internet of Things, and Microservices. Nevertheless, many existing REST APIs are known to be not well-designed, resulting in the absence of desirable quality attributes that truly RESTful systems entail. Although existing analysis show, that many REST APIs are not fully REST compliant, it is still an open issue how to improve this deficit and where to start. In this work, we introduce a framework for the structural analysis of REST APIs based on their description documents, as this allows for a comprehensive, well-structured analysis approach that also includes analyzing the corresponding API description languages. A first validation builds on a set of 286 real world API descriptions available as Swagger documents, and comprises their transformation into a canonical metamodel for REST APIs as well as a metrics-based analysis and discussion of their structural characteristics with respect to compliance with the REST architectural style.},
  keywords={},
  doi={10.1109/ICSA.2017.40},
  ISSN={},
  month={April},}@INPROCEEDINGS{7515747,
  author={Farias, Victor A. E. and Sousa, Flávio R. C. and Maia, José G. R. and Gomes, João P. P. and Machado, Javam C.},
  booktitle={2016 16th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid)}, 
  title={Machine Learning Approach for Cloud NoSQL Databases Performance Modeling}, 
  year={2016},
  volume={},
  number={},
  pages={617-620},
  abstract={Cloud computing is a successful, emerging paradigm that supports on-demand services with pay-as-you-go model. With the exponential growth of data, NoSQL databases have been used to manage data in the cloud. In these newly emerging settings, mechanisms to guarantee Quality of Service heavily relies on performance predictability, i.e., the ability to estimate the impact of concurrent query execution on the performance of individual queries in a continuously evolving workload. This paper presents a performance modeling approach for NoSQL databases in terms of performance metrics which is capable of capturing the non-linear effects caused by concurrency and distribution aspects. Experimental results confirm that our performance modeling can accurately predict mean response time measurements under a wide range of workload configurations.},
  keywords={},
  doi={10.1109/CCGrid.2016.83},
  ISSN={},
  month={May},}@INPROCEEDINGS{7116128,
  author={Al-Jawad, Ahmed and Trestian, Ramona and Shah, Purav and Gemikonakli, Orhan},
  booktitle={Proceedings of the 2015 1st IEEE Conference on Network Softwarization (NetSoft)}, 
  title={BaProbSDN: A probabilistic-based QoS routing mechanism for Software Defined Networks}, 
  year={2015},
  volume={},
  number={},
  pages={1-5},
  abstract={Over the past decade there has been an exponential increase in the Internet traffic especially with the proliferation of cloud computing and other distributed data services. This explosion of data traffic with its dynamically changing traffic patterns and flows might result in degradation of the network performance. In this context, there is a need for an intelligent and efficient network management system that delivers guaranteed services. To this extent, this paper proposes BaProbSDN, a probabilistic Quality of Service (QoS) routing mechanism for Software Defined Networks (SDN). The QoS routing algorithm employs the bandwidth availability metric as a QoS routing constraint for unicast data delivery. BaProbSDN makes use of Bayes' theorem and Bayesian network model to determine the link probability in order to select the route that satisfies the given bandwidth constraint. The performance of the proposed probabilistic QoS routing algorithm was tested in a simulation-based environment and compared against the widest-shortest path routing (WSR) algorithm. The results demonstrate that BaProbSDN can achieve up to 8.02% decrease in the bandwidth blocking rate when compared to WSR in the presence of link update inaccuracies of threshold and time delay.},
  keywords={},
  doi={10.1109/NETSOFT.2015.7116128},
  ISSN={},
  month={April},}@INPROCEEDINGS{8079983,
  author={Gabi, Danlami and Ismail, Abdul Samad and Zainal, Anazida and Zakaria, Zalmiyah and Al-Khasawneh, Ahmad},
  booktitle={2017 8th International Conference on Information Technology (ICIT)}, 
  title={Cloud scalable multi-objective task scheduling algorithm for cloud computing using cat swarm optimization and simulated annealing}, 
  year={2017},
  volume={},
  number={},
  pages={1007-1012},
  abstract={In cloud computing, customers-desired Quality of Service (QoS) expectations are quite superficial due to lack of scalable task scheduling solutions that can adjust to long-time changes. Researchers in the literature have put forward several task scheduling algorithms to account for customers' QoS expectations. Unfortunately, most of these algorithms need improvements to ensure the provisioning of better consumers' QoS expectation. In this study, a Multi-Objective QoS model to address customers' expectation based on execution time and execution cost criteria is presented. A Cloud Scalable Multi-Objective Cat Swarm Optimization (CSO) based Simulated Annealing (SA) (CSM-CSOSA) algorithm is then proposed to solve the model. In this method, the Taguchi Orthogonal approach is used to enhanced the SA and incorporated into the local search of the proposed algorithm for enhancing it exploration capability. Implementation of the algorithm is carried out on CloudSim tool and evaluated using one dataset (Normal distributed) and one Parallel Workload (High-Performance Computing Center North(HPC2N)). Quantitative analysis of the algorithm performance is taken based on metrics of execution time, execution cost, QoS and percentage improvement. Result obtained is compared with that of Multi-Objective Genetic Algorithm (MOGA), Multi-Objective Ant Colony (MOSACO) and Multi-Objective Particle Swarm Optimization (MOPSO), where proposed method is able to return substantial performance with improved QoS.},
  keywords={},
  doi={10.1109/ICITECH.2017.8079983},
  ISSN={},
  month={May},}@INPROCEEDINGS{8646562,
  author={Zhu, Hongbin and Wang, Haifeng and Luo, Xiliang and Qian, Hua},
  booktitle={2018 IEEE Global Conference on Signal and Information Processing (GlobalSIP)}, 
  title={AN ONLINE LEARNING APPROACH TO WIRELESS COMPUTATION OFFLOADING}, 
  year={2018},
  volume={},
  number={},
  pages={678-682},
  abstract={Fog computing extends cloud computing and services to the edge of networks, bringing advantages of the cloud closer to where data is created and acted upon. To support real time applications, latency performance is a crucial metric in fog computing. In this paper, we consider a sequential decision-making problem for computation offloading with unknown dynamics in which a mobile user offloads its arrival tasks to associated fog nodes (FNs) at each time slot. The queue of arrival tasks at each FN is modeled as a Markov chain. In order to provide satisfactory quality of experience, the network latency, which is directly associated with the queue condition, needs to be minimized. Taking advantage of reinforcement learning, the sequential decision-making problem is formulated as a restless multi-armed bandit problem. We construct a policy with interleaved exploration and exploitation stages, which achieves a regret with sub-linear order. Both analytical and simulation results validate the effectiveness of the proposed method in dealing with sequential decision-making problem.},
  keywords={},
  doi={10.1109/GlobalSIP.2018.8646562},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8936206,
  author={Lima, Diana Bezerra Correia and da Silva Lima, Rubens Matheus Brasil and de Farias Medeiros, Douglas and Pereira, Renata Imaculada Soares and de Souza, Cleonilson Protasio and Baiocchi, Orlando},
  booktitle={2019 IEEE 10th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON)}, 
  title={A Performance Evaluation of Raspberry Pi Zero W Based Gateway Running MQTT Broker for IoT}, 
  year={2019},
  volume={},
  number={},
  pages={0076-0081},
  abstract={The Internet of Things (IoT) has become widely used in recent years in a wide range of applications, such as, weather condition monitoring, transportation, smart homes, smart cities, smart farm, etc. The ecosystem of the IoT is also vast, including from sensor and hardware devices up to cloud-computing. An approach that is getting more and more attention in the IoT ecosystem is the edge-computing and one of its fundamental pieces of equipment is the edge-computing gateway (GTW), which can working as a data-processing device nearer to the things and as a bridge to the Internet, as well. The most important features for these GTWs must be robustness and efficiency and a very popular solution is to use low-cost Raspberry Pi card-size computers. Considering protocol solution, Message Queue Telemetry Transport (MQTT) communication protocol has been considered one of the most applicable to IoT because of its low-power capability. In this context, this paper describes a study about the performance evaluation of a low-power member of the Raspberry Pi family, the Raspberry Pi Zero W, working as an IoT gateway and running MQTT. The experimental results show its performance using as metrics: the processor temperature, the CPU usage level, and rate of MQTT received messages under different Quality of Services (QoS).},
  keywords={},
  doi={10.1109/IEMCON.2019.8936206},
  ISSN={2644-3163},
  month={Oct},}@INPROCEEDINGS{8641090,
  author={Xu, Jianwen and Ota, Kaoru and Dong, Mianxiong},
  booktitle={2018 IEEE/CIC International Conference on Communications in China (ICCC)}, 
  title={Plug-and-Play for Fog: Dynamic Service Placement in Wireless Multimedia Networks}, 
  year={2018},
  volume={},
  number={},
  pages={490-494},
  abstract={Initially as an extension of cloud computing, fog computing has been inspiring new ideas about moving computing tasks to the edge of a network. In fog, we often repeat the procedure of placing service because of the geographical distribution of mobile users. We may not expect a fixed demand and supply relationship between users and service providers since users always prefer nearby service with less time delay and transmission consumption. That is, a plug-and-play service mode is what we need in fog. In this paper, we put forward a dynamic placement strategy for fog service in a three-tier wireless multimedia network to guarantee the normal service provision and optimize the Quality of Service (QoS). The simulation results show that our strategy can achieve better performance under metrics including energy consumption and end-to-end latency compared with existed methods.},
  keywords={},
  doi={10.1109/ICCChina.2018.8641090},
  ISSN={2377-8644},
  month={Aug},}@INPROCEEDINGS{6927024,
  author={Mdhaffar, Afef and Halima, Riadh Ben and Jmaiel, Mohamed and Freisleben, Bernd},
  booktitle={2014 IEEE 23rd International WETICE Conference}, 
  title={CEP4Cloud: Complex Event Processing for Self-Healing Clouds}, 
  year={2014},
  volume={},
  number={},
  pages={62-67},
  abstract={This paper presents a cross-layer self-healing approach for Cloud computing environments, based on the Complex Event Processing method. It analyzes monitored events to detect performance-related problems and performs action to fix them without human intervention. Our proposal makes use of novel analysis rules, derived from a comprehensive study of the relationships between monitored metrics across multiple Cloud layers. The results of our study are used to define and optimize the analysis rules and identify the causes of performance-related problems. The results of several experiments demonstrate the benefits of the proposed approach in terms of speeding up the analysis without affecting the quality of the diagnosis.},
  keywords={},
  doi={10.1109/WETICE.2014.56},
  ISSN={1524-4547},
  month={June},}

@INPROCEEDINGS{7173479,
  author={Techio, Leila Regina and Misaghi, Mehran},
  booktitle={Fifth International Conference on the Innovative Computing Technology (INTECH 2015)}, 
  title={EMSCLOUD – an evaluative model of cloud services cloud service management}, 
  year={2015},
  volume={},
  number={},
  pages={100-105},
  abstract={Cloud computing is considered a paradigm both technology and business. Its widespread adoption is an increasingly effective trend. However, the lack of quality metrics and audit of services offered in the cloud slows its use, and it stimulates the increase in focused discussions with the adaptation of existing standards in management services for cloud services offered. This article describes the EMSCloud, that is an Evaluative Model of Cloud Services following interoperability standards, risk management and audit of cloud IT services. Aims to present that is possible to assess the life cycle of services offered in the cloud in the technical dimensions of usability, good practices and economic viability.},
  keywords={},
  doi={10.1109/INTECH.2015.7173479},
  ISSN={},
  month={May},}@INPROCEEDINGS{8080065,
  author={Gabi, Danlami and Ismail, Abdul Samad and Zainal, Anazida and Zakaria, Zalmiyah and Al-Khasawneh, Ahmad},
  booktitle={2017 8th International Conference on Information Technology (ICIT)}, 
  title={Cloud scalable multi-objective task scheduling algorithm for cloud computing using cat swarm optimization and simulated annealing}, 
  year={2017},
  volume={},
  number={},
  pages={599-604},
  abstract={In cloud computing, customers-desired Quality of Service (QoS) expectations are quite superficial due to lack of scalable task scheduling solutions that can adjust to long-time changes. Researchers in the literature have put forward several task scheduling algorithms to account for customers' QoS expectations. Unfortunately, most of these algorithms need improvements to ensure the provisioning of better consumers' QoS expectation. In this study, a Multi-Objective QoS model to address customers profit based on execution time and execution cost criteria is presented. A Cloud Scalable Multi-Objective Cat Swarm Optimization (CSO) based Simulated Annealing (SA) (CSM-CSOSA) algorithm is then proposed to solve the model. In this method, the Taguchi Orthogonal approach is used to enhanced the SA and incorporated into the local search of the proposed algorithm for enhancing it exploration capability. Implementation of the algorithm is carried out on CloudSim tool and evaluated using one dataset (Normal distributed) and one Parallel Workload (High-Performance Computing Center North(HPC2N)). Quantitative analysis of the algorithm performance is taken based on metrics of execution time, execution cost, QoS and percentage improvement. Result obtained is compared with that of Multi-Objective Genetic Algorithm (MOGA), Multi-Objective Ant Colony (MOSACO) and Multi-Objective Particle Swarm Optimization (MOPSO), where proposed method is able to returned substantial performance with improved QoS.},
  keywords={},
  doi={10.1109/ICITECH.2017.8080065},
  ISSN={},
  month={May},}@INPROCEEDINGS{8109266,
  author={Gonçalves, Charles Ferreira},
  booktitle={2017 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)}, 
  title={Benchmarking the Security of Virtualization Infrastructures: Motivation and Approach}, 
  year={2017},
  volume={},
  number={},
  pages={100-103},
  abstract={With the growing adoption of cloud computing for business systems, the efforts to keep those environments secure are also increasing. Virtualization infrastructures are key to support such systems, but engineers lack means to help them in selecting the best solutions according to their security requirements. The goal of this work is to define and develop a benchmarking approach to assess and compare the security of virtualization infrastructures. The approach allows the benchmark user to define his usage scenario, which will influence the assessment metrics and quality model. Well established performance benchmarks will be used as workload. The evaluation procedure comprises two key phases: i) security qualification to make sure that detectable/known vulnerabilities are not present; ii) trustworthiness assessment to gather further evidences of the system security. We believe this approach will allow assessing and comparing systems in terms of security, thus helping IaaS providers to select the best infrastructure for their specific needs.},
  keywords={},
  doi={10.1109/ISSREW.2017.70},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9269114,
  author={Papakonstantinou, Ioannis and Kalafatidis, Sarantis and Mamatas, Lefteris},
  booktitle={2020 16th International Conference on Network and Service Management (CNSM)}, 
  title={A Techno-Economic Assessment of Microservices}, 
  year={2020},
  volume={},
  number={},
  pages={1-5},
  abstract={The microservices design paradigm enables applications, usually based on containers, exploiting the flexibility of cloud computing and bringing unique scalability, fault-tolerance and resource-allocation benefits. A number of orchestration facilities, including Kubernetes, target the efficient deployment and operation of containers and are mainly focusing on the maintenance of server resource allocation under predefined thresholds, i.e., through scaling up or down containers to mitigate dynamic changes in the workload. In this work, we highlight the technical capabilities and cost-saving impact of microservices in contrast to traditional monolithic applications, based on a techno-economic analysis. We also investigate the service performance vs resource allocation trade-off, uncovering interesting dynamics when elasticity is driven from service quality metrics. This approach allows the Service Providers (SPs) to balance their profit margins with the customer satisfaction, i.e., reducing the infrastructure cost while keeping the service performance at an acceptable level.},
  keywords={},
  doi={10.23919/CNSM50824.2020.9269114},
  ISSN={2165-963X},
  month={Nov},}@INPROCEEDINGS{7018544,
  author={Nodehi, Tahereh and Ghimire, Sudeep and Jardim-Gonçalves, Ricardo},
  booktitle={2014 2nd International Conference on Model-Driven Engineering and Software Development (MODELSWARD)}, 
  title={Toward a unified intercloud interoperability conceptual model for IaaS cloud service}, 
  year={2014},
  volume={},
  number={},
  pages={673-681},
  abstract={The concept of interoperation between cloud providers is a recent research challenging objective. Current cloud systems have been developed without concerns of seamless cloud interconnection, and actually they do not support intercloud interoperability. The paper proposes a conceptual model for Intercloud Interoperability, to enable schedule dynamic operation for Infrastructure as a Service (IaaS) between different clouds. The paper is providing a better understanding of elaborates on the cloud computing architecture, appropriate metrics for Service Level Agreements (SLA) and Quality of Service (QoS) models that are required for seamless integration and interoperability between cloud environments. Then, a conceptual model for the Intercloud Interoperability Framework for Workload Migration is proposed. The novel component of the framework that provides interoperability is the Transformation Engine that maps workload between heterogeneous cloud providers, whilst Model Driven Architecture (MDA) is adopted as an applicable method for developing the Transformation Engine module.},
  keywords={},
  doi={},
  ISSN={},
  month={Jan},}@ARTICLE{7403967,
  author={Wang, Lujia and Liu, Ming and Meng, Max Q.-H.},
  journal={IEEE Transactions on Cybernetics}, 
  title={A Hierarchical Auction-Based Mechanism for Real-Time Resource Allocation in Cloud Robotic Systems}, 
  year={2017},
  volume={47},
  number={2},
  pages={473-484},
  abstract={Cloud computing enables users to share computing resources on-demand. The cloud computing framework cannot be directly mapped to cloud robotic systems with ad hoc networks since cloud robotic systems have additional constraints such as limited bandwidth and dynamic structure. However, most multirobotic applications with cooperative control adopt this decentralized approach to avoid a single point of failure. Robots need to continuously update intensive data to execute tasks in a coordinated manner, which implies real-time requirements. Thus, a resource allocation strategy is required, especially in such resource-constrained environments. This paper proposes a hierarchical auction-based mechanism, namely link quality matrix (LQM) auction, which is suitable for ad hoc networks by introducing a link quality indicator. The proposed algorithm produces a fast and robust method that is accurate and scalable. It reduces both global communication and unnecessary repeated computation. The proposed method is designed for firm real-time resource retrieval for physical multirobot systems. A joint surveillance scenario empirically validates the proposed mechanism by assessing several practical metrics. The results show that the proposed LQM auction outperforms state-of-the-art algorithms for resource allocation.},
  keywords={},
  doi={10.1109/TCYB.2016.2519525},
  ISSN={2168-2275},
  month={Feb},}@INPROCEEDINGS{9504780,
  author={Saemi, Behzad and Sadeghilalimi, Mehdi and Rahmani Hosseinabadi, Ali Asghar and Mouhoub, Malek and Sadaoui, Samira},
  booktitle={2021 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={A New Optimization Approach for Task Scheduling Problem Using Water Cycle Algorithm in Mobile Cloud Computing}, 
  year={2021},
  volume={},
  number={},
  pages={530-539},
  abstract={Mobile devices are used by numerous applications that continuously need computing power to grow. Due to limited resources for complex computing, offloading, a service offered for mobile devices, is commonly used in cloud computing. In Mobile Cloud Computing (MCC), offloading decides where to execute the tasks to efficiently maximize the benefits. Hence, we represent offloading as a Task Scheduling Problem (TSP). This latter is a Multi-Objective Optimization (MOO) problem where the goal is to find the best schedule for processing mobile source tasks, while minimizing both the average processor energy consumption and the average task processing time. Owing to the combinatorial nature of the problem, the TSP in MCC is known as NP-hard. To overcome this difficulty in practice, we adopt meta-heuristic search techniques as they offer a good trade-off between solution quality and scalability. More precisely, we introduce a new optimization approach, that we call Multi-objective Discrete Water Cycle Algorithm (MDWCA), to schedule tasks from mobile source nodes to processor resources in a hybrid MCC architecture, including public cloud, cloudlets, and mobile devices. To evaluate the performance of our proposed approach, we conducted several comparative experiments on many generated TSP instances in MCC. The simulation results show that MDWCA outperforms the state-of-the-art optimization algorithms for several quality metrics.},
  keywords={},
  doi={10.1109/CEC45853.2021.9504780},
  ISSN={},
  month={June},}@INPROCEEDINGS{9171079,
  author={Hans, Manoj and Jagtap, Nilesh and Deokate, Jivan Balasaheb and Jogi, Vivek Kant},
  booktitle={2020 Fourth International Conference on Inventive Systems and Control (ICISC)}, 
  title={Peak Load Management in Smart Grid – Integration of Rescheduling & Cloud Computing}, 
  year={2020},
  volume={},
  number={},
  pages={861-865},
  abstract={Ever-increasing demand for power has motivated researchers to come up with methodologies for meeting the demand. A smart grid is one of the solutions to minimizing the issue. A smart grid has become a proven way to optimize the load flow, hence the balance between the demand and supply of power is maintained. Though the problem of demand and supply is resolved to some extent still problems persist. The efficiency of the system i.e. end to end must be high. The quality of power must be intact. Considering above mentioned factors there can be checkpoints at three different levels. Remedial measures can be at the utility or the consumer end. As much can’t be done at the utility side due to several constraints hence there is a need for implementation of remedial measures on the consumer end, also known as the Demand Side Management (DSM). The demand-side management must be given emphasis because of several advantages it serves to the consumer as well as to the utility. DSM has been implemented at the Institute premises with the application of cloud computing. Communication of data between the cloud and the microgrid at the institute has been monitored and analyzed in the experimentation. Through analysis has been presented in the paper.},
  keywords={},
  doi={10.1109/ICISC47916.2020.9171079},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{9684637,
  author={Udomsripaiboon, Thana and Chaewsuwan, Chutiphan and Chumpoowang, Thanatip and Saetoen, Natthachai and Rojanavasu, Pornthep and Chaewsuwan, Thitirath},
  booktitle={2021 25th International Computer Science and Engineering Conference (ICSEC)}, 
  title={The Atmospheric Ozone Monitoring System by using Internet of Things Technology for Nanosatellites (3U CubeSat)}, 
  year={2021},
  volume={},
  number={},
  pages={325-329},
  abstract={This paper presents the system for monitoring the condition of the earth's ozone layer using Internet of Things (IoT) technology. The proposed system deploys a 3U CubeSat satellite to measure ultraviolet intensity to compare the intensity value of ultraviolet radiation at each terrestrial base station through the web application. The measured data is computed and classified by cloud computing into five levels of the regional ozone layer's quality: excellent, good, average, fair, and poor. These data can also be gathered as statistics and retrieved on a daily, monthly and annual basis. Consequently, by this information, campaigning for people to reduce the destructive behaviours of the ozone layer in each area would be incredibly advantageous. In addition, each base station can be built for less than $150 using commonly available electronics and sensors, allowing the proposed system to be implemented and deployed globally. As a result, this project would be of great benefit to humanity to have information on the health of the ozone layer in each region around the world. This paper could be better inform monitoring strategies to reduce the greenhouse effect that brings unfamiliar and unpredictable impacts of climate change to the world.},
  keywords={},
  doi={10.1109/ICSEC53205.2021.9684637},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{7498925,
  author={Karadimce, Aleksandar and Davcev, Danco},
  booktitle={2016 Eighth International Conference on Quality of Multimedia Experience (QoMEX)}, 
  title={Perception of quality in cloud computing based services}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={Cloud computing consists of hardware and software resources, available on the Internet as a set of services for users. This technology aims to provide stable, reliable and encapsulated dynamic information and communication environment for end users to be able to simultaneously access shared resources that are available anywhere and at any time. The major benefit of cloud computing is used to improve the perception of quality for the client requests. Commonly in the communications industry, the term Quality of Experience (QoE) is used as a measure for the user perception of service from the user's point of view. In this research, we propose a classification of cloud-based services based on objective and subjective characteristics for perception of quality. The main contribution in this paper is a novel approach based on Bayesian modeling for efficient assessment of QoE perception for cloud-based services considering the level of interactivity, service complexity, usage domain, and multimedia-intensity.},
  keywords={},
  doi={10.1109/QoMEX.2016.7498925},
  ISSN={},
  month={June},}@ARTICLE{7501820,
  author={Chen, Yunliang and Wang, Lizhe and Chen, Xiaodao and Ranjan, Rajiv and Zomaya, Albert Y. and Zhou, Yuchen and Hu, Shiyan},
  journal={IEEE Transactions on Cloud Computing}, 
  title={Stochastic Workload Scheduling for Uncoordinated Datacenter Clouds with Multiple QoS Constraints}, 
  year={2020},
  volume={8},
  number={4},
  pages={1284-1295},
  abstract={Cloud computing is now a well-adopted computing paradigm. With unprecedented scalability and flexibility, the computational cloud is able to carry out large scale computing tasks in parallel. The datacenter cloud is a new cloud computing model that uses multi-datacenter architectures for large scale massive data processing or computing. In datacenter cloud computing, the overall efficiency of the cloud depends largely on the workload scheduler, which allocates clients' tasks to different Cloud datacenters. Developing high performance workload scheduling techniques in Cloud computing imposes a great challenge which has been extensively studied. Most previous works aim only at minimizing the completion time of all tasks. However, timeliness is not the only concern, reliability and security are also very important. In this work, a comprehensive Quality of Service (QoS) model is proposed to measure the overall performance of datacenter clouds. An advanced Cross-Entropy based stochastic scheduling (CESS) algorithm is developed to optimize the accumulative QoS and sojourn time of all tasks. Experimental results show that our algorithm improves accumulative QoS and sojourn time by up to 56.1 and 25.4 percent respectively compared to the baseline algorithm. The runtime of our algorithm grows only linearly with the number of Cloud datacenters and tasks. Given the same arrival rate and service rate ratio, our algorithm steadily generates scheduling solutions with satisfactory QoS without sacrificing sojourn time.},
  keywords={},
  doi={10.1109/TCC.2016.2586048},
  ISSN={2168-7161},
  month={Oct},}@INPROCEEDINGS{9091376,
  author={Zhang, Ziyi and Guo, Caishan and Sun, Yuyan and Hu, Kaiqiang and Wang, Qinghai and Wu, Yuzhao and Cai, Zexiang},
  booktitle={2019 IEEE International Conference on Smart Cloud (SmartCloud)}, 
  title={Cloud Computing Placement Optimization Under Ubiquitous Power Internet of Things Background}, 
  year={2019},
  volume={},
  number={},
  pages={13-18},
  abstract={With the development of power system and the introduction of the Energy Internet, the implementation of Ubiquitous Power Internet of Things (UPIoT) is necessary for power utilities to meet the demands of Integrated Energy Applications. Massive heterogeneous data from various devices surge into power system via UPIoT, which puts heavy burden on data processing capabilities of power system. Cloud computing is an effective measure to provide big data processing capabilities and the establishment of cloud computing for power system is of great significance. Firstly, the architecture of UPIoT and the cloud computing system based on UPIoT background are analyzed. Considering the characteristics of power system, a distributed cloud computing architecture for power system is proposed. A coordinated placement optimization strategy based on minimum cost and satisfaction of quality of service for the proposed architecture is formulated. Based on a given case, the placement optimization simulations are studied. The simulation results prove that the proposed architecture is cost-efficient and the proposed optimization strategy is effective and efficient.},
  keywords={},
  doi={10.1109/SmartCloud.2019.00012},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8422956,
  author={Skourletopoulos, Georgios and Mavromoustakis, Constandinos X. and Mastorakis, George and Batalla, Jordi Mongay and Song, Houbing and Sahalos, John N. and Pallis, Evangelos},
  booktitle={2018 IEEE International Conference on Communications (ICC)}, 
  title={Elasticity Debt Analytics Exploitation for Green Mobile Cloud Computing: An Equilibrium Model}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={Mobile cloud computing is being accepted as the model for mobile users to ubiquitously access a shared pool of cloud computing resources, data and services on-demand. In this context, elasticity debt analytics can be harnessed as a measure for efficient scheduling of cloud resources and guarantee of quality of service requirements. This paper proposes a novel green-driven, game theoretic approach to minimizing the elasticity debt on mobile cloud-based service level, investigating the case when a task is offloaded, scheduled and executed on a mobile cloud computing system. The decision to offload a mobile device user's task on cloud affects the level of elasticity debt minimization for the provided services. The research problem is formulated as an elasticity debt quantification game, elaborating on an incentive mechanism to: (a) predict elasticity debt and mitigate the risk of service overutilization, (b) achieve scalability as the number of mobile device user requests for cloud resources increases or decreases accordingly, and (c) optimize cloud resource provisioning, parameterizing the current pool of active users per service. The experimental results prove the effectiveness of the equilibrium model, which allocates the mobile device user requests to high elasticity debt-level services and facilitate elasticity debt minimization for greener mobile cloud computing environments.},
  keywords={},
  doi={10.1109/ICC.2018.8422956},
  ISSN={1938-1883},
  month={May},}@ARTICLE{8752013,
  author={Yang, Xiao and Pavelsky, Tamlin M. and Allen, George H. and Donchyts, Gennadii},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={RivWidthCloud: An Automated Google Earth Engine Algorithm for River Width Extraction From Remotely Sensed Imagery}, 
  year={2020},
  volume={17},
  number={2},
  pages={217-221},
  abstract={The wetted width of a river is one of the most important hydraulic parameters that can be readily measured using remote sensing. Remotely sensed river widths are used to estimate key attributes of river systems, including changes in their surface area, channel storage, and discharge. Although several published algorithms automate river network and width extraction from remote sensing images, they are limited by only being able to run on local computers and do not automatically manage cloudy images as input. Here we present RivWidthCloud, a river width software package developed on the Google Earth Engine cloud computing platform. RivWidthCloud automatically extracts river centerline and widths from optical satellite images with the ability to flag observations that are obstructed by features like clouds, cloud shadows, and snow based on existing quality band classification. Because RivWidthCloud is built on a popular cloud computing platform, it allows users to easily apply the algorithm to the platform's vast archive of remote sensing images, thereby reducing the users' overhead for computing hardware and data storage. By comparing RivWidthCloud-derived widths from Landsat images to in situ widths from the U.S. and Canada, we show that RivWidthCloud can estimate widths with high accuracy (root mean square error: 99 m; mean absolute error: 43 m; mean bias: -21 m). By making RivWidthCloud publicly available, we anticipate that it will be used to address both river science questions and operational applications of water resource management.},
  keywords={},
  doi={10.1109/LGRS.2019.2920225},
  ISSN={1558-0571},
  month={Feb},}@INPROCEEDINGS{7328126,
  author={Al-Shammari, Shaymaa and Al-Yasiri, Adil},
  booktitle={2015 IEEE 9th International Symposium on the Maintenance and Evolution of Service-Oriented and Cloud-Based Environments (MESOCA)}, 
  title={MonSLAR: a middleware for monitoring SLA for RESTFUL services in cloud computing}, 
  year={2015},
  volume={},
  number={},
  pages={46-50},
  abstract={Measuring the quality of cloud computing provision from the client's point of view is important in order to ensure that the service conforms to the level specified in the service level agreement (SLA). With a view to avoid SLA violation, the main parameters should be determined in the agreement and then used to evaluate the fulfillment of the SLA terms at the client's side. Current studies in cloud monitoring only handle monitoring the provider resources with little or no consideration to the client's side. This paper presents MonSLAR, a User-centric middleware for Monitoring SLA for Restful services in SaaS cloud computing environments. MonSLAR uses a distributed architecture that allows SLA parameters and the monitored data to be embedded in the requests and responses of the REST protocol.},
  keywords={},
  doi={10.1109/MESOCA.2015.7328126},
  ISSN={2326-6937},
  month={Oct},}@INPROCEEDINGS{8279168,
  author={Shibu, Sini and Naik, Archana},
  booktitle={2017 International Conference on Information, Communication, Instrumentation and Control (ICICIC)}, 
  title={An approach to increase the awareness of e-governance initiatives based on cloud computing}, 
  year={2017},
  volume={},
  number={},
  pages={1-4},
  abstract={E-governance is being adopted by the governments of every country for its operations through the ICT (Information and Communication Technology) i.e. incorporating its operations through IT model so that the schemes can be reached to the masses. In India too, as of now, nearly every state government has its own e-Governance model. Cloud computing is now being widely used in e-governance. With the help of the features of Cloud computing, e-Governance operations can be built up as cost effective technology solutions and can be geographically distributed to heterogeneous resources thereby increasing the quality of service to the users. In fact, G-cloud (Governance on Cloud) is designed for using Government services. It is not merely enough to set up e-governance models but its awareness amongst masses is equally important. This paper analyses the cloud based model of e-governance and suggests measures to increase awareness among people regarding the various e-governance initiatives taken by the Government of Madhya Pradesh.},
  keywords={},
  doi={10.1109/ICOMICON.2017.8279168},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{7453380,
  author={Singh, Sarbjeet and Sidhu, Jagpreet},
  booktitle={2015 2nd International Conference on Recent Advances in Engineering & Computational Sciences (RAECS)}, 
  title={A collaborative trust calculation scheme for cloud computing systems}, 
  year={2015},
  volume={},
  number={},
  pages={1-5},
  abstract={One of the major hurdles in the widespread use of cloud computing systems is the lack of trust between consumer and service provider. Lack of trust can put consumer's sensitive data and applications at risk. Consumers need assurance that service providers will provide services as per agreement and will not deviate from agreed terms and conditions. Though trust is a subjective term, it can be measured objectively also. In this paper we present the design and simulation of a collaborative trust calculation scheme in which trust on a service provider is build by participants in a collaborative way. Each collaborator shares its experience of service provider with the coordinator and then shared experiences are aggregated by coordinator to compute final trust value which represents the trustworthiness of service provider. The scheme makes use of fuzzy logic to aggregate responses and to handle uncertain and imprecise information. Collaborative trust calculation scheme makes it difficult for untrustworthy service provider to build its reputation in the system by providing quality services only to a selected set of participants. A service provider has to provide agreed services to all participants uniformly in order to build reputation in the environment. Simulation has been done using MATLAB toolkit. Simulation results show that the scheme is workable and can be adopted for use in collaborative cloud computing systems to determine trustworthiness of service providers.},
  keywords={},
  doi={10.1109/RAECS.2015.7453380},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8666838,
  author={Mengge, YUAN and Rui, LI and Ning, ZHAO},
  booktitle={2018 International Conference on Information Systems and Computer Aided Education (ICISCAE)}, 
  title={Optimization of the Number of Servers in Cloud Computing Centers}, 
  year={2018},
  volume={},
  number={},
  pages={269-273},
  abstract={To improve the service quality and save the system cost of the cloud computing center, this paper studies the joint optimization problem of energy consumption and performance of cloud computing centers with a batch Markovian arrival process. The system has multiple parallel processors and the processing time of each processor follows phase type distribution. The system has finite buffer. We construct the system as a BMAP/PH/N/M queueing system and analyze the performance of the system based on queuing theory. An optimization model is established by combing the energy consumption and system performance measures. The optimal number of servers is analyzed. Some managerial insights are given by numerical analysis.},
  keywords={},
  doi={10.1109/ICISCAE.2018.8666838},
  ISSN={},
  month={July},}@INPROCEEDINGS{9084987,
  author={Chen, Zhijia and Di, Yanqiang and Yuan, Hongli and Feng, Shaochong},
  booktitle={2020 IEEE 4th Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)}, 
  title={Intelligent Cloud Training System based on Edge Computing and Cloud Computing}, 
  year={2020},
  volume={1},
  number={},
  pages={1550-1553},
  abstract={Equipment simulation training based on cloud computing is emerging. However, the latency between cloud center and client is long, and the energy consumption management is difficult, which are influencing the development of cloud training. Intelligent cloud training system based on edge computing and cloud computing is introduced in this paper. Intelligent gateway is introduced, through which the task and resources are scheduled and managed together. The popularity of training resources is analyzed. The management of servers in cloud center and edge is intelligently switched between timing sleep and task-activation. Intelligent training service provisioning is achieved through above measures. The simulation results show that the system and management methods are effective on improving training service quality and lower the energy consumption.},
  keywords={},
  doi={10.1109/ITNEC48623.2020.9084987},
  ISSN={},
  month={June},}@ARTICLE{8852632,
  author={Ala’anzy, Mohammed and Othman, Mohamed},
  journal={IEEE Access}, 
  title={Load Balancing and Server Consolidation in Cloud Computing Environments: A Meta-Study}, 
  year={2019},
  volume={7},
  number={},
  pages={141868-141887},
  abstract={The data-center is considered the heart of cloud computing. Recently, the growing demand for cloud computing services has caused a growing load on data centers. In terms of system behavior and workload, patterns of cloud computing are very dynamic; and that might serve to imbalance the load among data center resources. Eventually, some data-center resources could come to be over-loaded/under-loaded, which leads to an increase in energy consumption in addition to decreased functioning and wastage of resources. Just considering energy-efficiency (that can be attained efficiently by consolidate the servers) may not be enough for real applications because it may cause problems such as unbalanced load for each Physical Machine (PM). Therefore, this paper surveys published load balancing algorithms that achieved by server consolidation via a meta-analysis. Load balancing with server consolidation enriches the exploitation of resource utilization and can enhance Quality of Service (QoS) metrics, since data-centers and their applications are increasing exponentially. This meta-study, reviews the literature on load balancing and server consolidation and presents a ready reference taxonomy on the most efficient algorithms that achieve load balancing and server consolidation. This work attempts to present a taxonomy with a new classification for load balancing and server consolidation, such as migration overhead, hardware threshold, network traffic, and reliability.},
  keywords={},
  doi={10.1109/ACCESS.2019.2944420},
  ISSN={2169-3536},
  month={},}@ARTICLE{9261243,
  author={Bui, Khiet Thanh and Van Vo, Len and Nguyen, Canh Minh and Pham, Tran Vu and Tran, Hung Cong},
  journal={Journal of Communications and Networks}, 
  title={A fault detection and diagnosis approach for multi-tier application in cloud computing}, 
  year={2020},
  volume={22},
  number={5},
  pages={399-414},
  abstract={Ensuring the availability of cloud computing services always concerns both service providers and end users. Therefore, the system always needs precautions for unexpected cases. Accordingly, cloud computing services must be capable of identifying faults and behaving appropriately when it is abnormal to ensure the smoothness as well as the service quality. In this study, we propose a fault detection method for multi-tier web application in cloud computing deployment environment based on the Fuzzy One-class support vector machine and Exponentially Weighted Moving Average method. And then, the suspicious metrics are located by using feature selection method which based on Random Forest algorithm. To evaluate our approach, a multi-tier application is deployed by a transnational web e-Commerce benchmark by using TPC-W (TPC Benchmark™ W, simulates the activities of a business oriented transaction web server in a controlled internet commerce environment) in private cloud and then it is injected typical faults. The effectiveness of the fault detection and diagnosis are demonstrated in experiment results.},
  keywords={},
  doi={10.1109/JCN.2020.000023},
  ISSN={1976-5541},
  month={Oct},}@INPROCEEDINGS{8422909,
  author={Kong, Cuiyu and Rimal, Bhaskar Prasad and Bhattarai, Bishnu P. and Devetsikiotis, Michael},
  booktitle={2018 IEEE International Conference on Communications (ICC)}, 
  title={Cloud-Based Charging Management of Electric Vehicles in a Network of Charging Stations}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={A large scale of electric vehicles (EVs) and the operation of smart grid requires the support of a reliable and robust communication infrastructure. Cloud computing has gained popularity in smart grid for reducing computational and communication complexity. Based on cloud computing services, this paper considers the issues of high charging demand in fast charging stations (FCSs) during peak hours and communication among a large-scale of EVs, a network of FCSs, and system operator (SO). More specifically, we propose a novel cloud-based hierarchical charging management model of EVs, whereby two levels of cloud computing infrastructures are considered to meet different latency requirements of customers in highway exits and parking lots. Considering the quality of service (QoS) metrics (average waiting time in the queue, and blocking probability), the model is composed of: server planning in the cloud, capacity planning in FCSs, and profit maximization. Meanwhile, a price incentive mechanism is applied to shift the heavy load from peak hours to off-peak hours. Numerical results demonstrate the effectiveness of the proposed method, which can guarantee QoS and system profit, thereby more customers can satisfy their charging demand.},
  keywords={},
  doi={10.1109/ICC.2018.8422909},
  ISSN={1938-1883},
  month={May},}@INPROCEEDINGS{8229905,
  author={Baghel, Dinesh Kumar and Singh, Arun and Deka, Pratyush Kumar},
  booktitle={2017 International Conference on Computing, Communication and Automation (ICCCA)}, 
  title={Agricultural management using cloud computing in India}, 
  year={2017},
  volume={},
  number={},
  pages={801-806},
  abstract={Although agriculture now accounts for only 14 percent of Gross Domestic Product (GDP), rapid growth of agriculture in India is critical for inclusiveness. Information Communication and Technology (ICT) provides greater role in offering greater expertise to producers regarding pricing, good quality seed information, fertilizers, disease detail, sharing new discoveries of scientists working at various Agricultural Institutes. An effective implementation of cloud computing in agricultural sector is encouraging and required for overall development of agricultural sector of India. There are potential risks in cloud computing which if properly addressed can be a potent ICT tool in agricultural sector in India. Considering the benefits of cloud computing, a design is proposed for Indian agricultural sector and two performance metrics are discussed which can be used to assess any cloud based application.},
  keywords={},
  doi={10.1109/CCAA.2017.8229905},
  ISSN={},
  month={May},}@INPROCEEDINGS{8390054,
  author={Gopavanitha, K. and Nagaraju, S.},
  booktitle={2017 International Conference on Energy, Communication, Data Analytics and Soft Computing (ICECDS)}, 
  title={A low cost system for real time water quality monitoring and controlling using IoT}, 
  year={2017},
  volume={},
  number={},
  pages={3227-3229},
  abstract={Water is a prerequisite element required for humans and therefore there must be mechanisms put in place to vigorously test the quality of drinking water in real time. This paper proposes a low cost system for real time water quality monitoring and controlling using IoT. The system consist of physiochemical sensors which can measures the physical and chemical parameters of the water such as Temperature, Turbidity, Conductivity, pH and Flow. By these sensors, water contaminants are detected. The sensor values processed by Raspberry pi and send to the cloud. Finally the sensed data is visible on the cloud using cloud computing and the flow of the water in the pipeline is controlled through IoT.},
  keywords={},
  doi={10.1109/ICECDS.2017.8390054},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{7974607,
  author={Li, Suyou and Guo, Zhigang and Shou, Guochu and Hu, Yihong and Li, Hongxing},
  booktitle={2016 IEEE International Conference on Network Infrastructure and Digital Content (IC-NIDC)}, 
  title={QoE analysis of NFV-based mobile edge computing video application}, 
  year={2016},
  volume={},
  number={},
  pages={411-415},
  abstract={Mobile Edge Computing (MEC) provides mobile and cloud computing capabilities within the access network. Network Functions Virtualization (NFV) leverages standard IT Virtualization technology to decouple the network functions from the underlying physical infrastructure. Basing on the ICT demand, MEC can be consolidated into NFV, as a network element within access network. This paper presents an architecture of NFV-based MEC platform and analyzes its Quality of Service (QoS) compared with the remote servers (Shenzhen and Qingdao). Then, this paper measures the Quality of Experience (QoE) of HTTP videos deployed in the servers. The result shows MEC can offer a service environment with higher bandwidth, which supports 10-fold gains, and ultra-low latency, jitter and packet loss rate. Moreover, along with the higher resolution and bitrates, the range of the video QoE improvement on this platform rises compared with the remote servers. In a word, the NFV-based MEC can achieve better performance than the remote servers.},
  keywords={},
  doi={10.1109/ICNIDC.2016.7974607},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9242798,
  author={Abdulwahid, Ali Hadi},
  booktitle={2020 9th International Conference on Renewable Energy Research and Application (ICRERA)}, 
  title={IoT Based Water Quality Monitoring System for Rural Areas}, 
  year={2020},
  volume={},
  number={},
  pages={279-282},
  abstract={To ensure that safety is guaranteed, it is essential to implement monitoring in real-time for the quality of potable water. This work is about the use of Internet of Things (IoT) technology to develop an affordable system to control water quality in real-time. Several sensors are integrated into the system to measure various chemical and physical water properties, such as conductivity, pH, turbidity, and temperature. The core controller, which can also be the microprocessor, manages the processing of data captured by the sensor. The visualization of data can be accomplished on cloud computing via the Internet.},
  keywords={},
  doi={10.1109/ICRERA49962.2020.9242798},
  ISSN={2572-6013},
  month={Sep.},}@INPROCEEDINGS{8310143,
  author={Puteaux, Pauline and Puech, William},
  booktitle={2017 Seventh International Conference on Image Processing Theory, Tools and Applications (IPTA)}, 
  title={Reversible data hiding in encrypted images based on adaptive local entropy analysis}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={With the development of cloud computing, the growth in information technology has led to serious security issues. For this reason, a lot of multimedia files are stored in encrypted forms. Methods of reversible data hiding in encrypted images (RDHEI) have been designed to provide authentication and integrity in the encrypted domain. The original image is firstly encrypted to ensure confidentiality, by making the content unreadable. A secret message is then embedded in the encrypted image, without the need of the encryption key or any access to the clear content. The challenge lies in finding the best trade-off between embedding capacity and quality of the reconstructed image. In 2008, Puech et al. suggested using the AES algorithm to encrypt an original image and to embed one bit in each block of 16 pixels (payload = 0.0625 bpp) [12]. During the decryption phase, the original image is reconstructed by measuring the standard deviation into each block. In this paper, we propose an improvement to this method, by performing an adaptive local entropy measurement. We can achieve a larger payload without altering the recovered image quality. Our obtained results are very good and better than most of the modern state-of-the-art methods, whilst offering an improved security level with the use of the AES algorithm, defined as the encryption standard by the NIST.},
  keywords={},
  doi={10.1109/IPTA.2017.8310143},
  ISSN={2154-512X},
  month={Nov},}@INPROCEEDINGS{8364051,
  author={Ramos da Paixão, Ermínio Augusto and Vieira, Rafael Fogarolli and Araújo, Welton Vasconcelos and Cardoso, Diego Lisboa},
  booktitle={2018 Third International Conference on Fog and Mobile Edge Computing (FMEC)}, 
  title={Optimized load balancing by dynamic BBU-RRH mapping in C-RAN architecture}, 
  year={2018},
  volume={},
  number={},
  pages={100-104},
  abstract={Cloud Radio Access Network (C-RAN) is one of the key architectures for the next generation of mobile networks (5G) that aim at centralized processing and management, collaborative radios and cloud computing in real time. These features enable the architectures to make a rational adjustment to the connection between remote radio heads (RRHs) and baseband units (BBUs) dynamically. This is important since if this feature is neglected, it can cause difficulties such as blocked calls and low-quality connections. This study investigates this area and proposes an optimized mapping model for RRH-BBU that seeks a more equitable and effective balancing. The Key Performance Indicator (KPI) of blocked calls was used for this to measure the quality of service (QoS). A particle Swarm algorithm (PSO) was created to minimize the number of blocked calls and additionally balancing the processing load between the BBUs. Scenario from literature was employed that consists of 19 RRHs distributed in a geographic area, which can be mapped in a BBU pool that manages two BBUs with three sectors each. The initial configuration on average, led to 80 blocked calls. The results obtained by the PSO show that there was a reduction of up to 100% of blocked calls, as well as a more equitable load distribution between the BBUs. Additionally, realistic scenarios with different user profiles were also included, since they demonstrate that these factors have a direct impact on the load generated in the BBUs and hence, affect their balance.},
  keywords={},
  doi={10.1109/FMEC.2018.8364051},
  ISSN={},
  month={April},}@INPROCEEDINGS{9178684,
  author={Wang, Chengrong and Zhang, Xiaodong and Chu, Dianhui},
  booktitle={2020 5th International Conference on Computational Intelligence and Applications (ICCIA)}, 
  title={Research on Service Composition Optimization Method Based on Composite Services QoS}, 
  year={2020},
  volume={},
  number={},
  pages={206-210},
  abstract={With the development of Cloud Computing, Internet of Things, and the advent of the era of Big Data, the types and scale of services are getting larger and larger, and the problem space of service composition is exploding. In order to measure the composite services quality of different combination schemes, this paper shows the calculation method of composite services QoS (Quality of Service), and improves the Ant Colony Algorithm by introducing Skyline calculation to further improve the efficiency of service composition and respond to user quickly. Finally, it is verified on the real QoS data set, and the feasibility and effectiveness of the method are proved through experiments.},
  keywords={},
  doi={10.1109/ICCIA49625.2020.00046},
  ISSN={},
  month={June},}@ARTICLE{7517217,
  author={Lyu, Xinchen and Tian, Hui and Sengul, Cigdem and Zhang, Ping},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={Multiuser Joint Task Offloading and Resource Optimization in Proximate Clouds}, 
  year={2017},
  volume={66},
  number={4},
  pages={3435-3447},
  abstract={Proximate cloud computing enables computationally intensive applications on mobile devices, providing a rich user experience. However, remote resource bottlenecks limit the scalability of offloading, requiring optimization of the offloading decision and resource utilization. To this end, in this paper, we leverage the variability in capabilities of mobile devices and user preferences. Our system utility metric is a measure of quality of experience (QoE) based on task completion time and energy consumption of a mobile device. We propose a heuristic offloading decision algorithm (HODA), which is semidistributed and jointly optimizes the offloading decision, and communication and computation resources to maximize system utility. Our main contribution is to reduce the problem to a submodular maximization problem and prove its NP-hardness by decomposing it into two subproblems: 1) optimization of communication and computation resources solved by quasiconvex and convex optimization and 2) offloading decision solved by submodular set function optimization. HODA reduces the complexity of finding the local optimum to O(K3), where K is the number of mobile users. Simulation results show that HODA performs within 5% of the optimal on average. Compared with other solutions, HODA's performance is significantly superior as the number of users increases.},
  keywords={},
  doi={10.1109/TVT.2016.2593486},
  ISSN={1939-9359},
  month={April},}@ARTICLE{8082532,
  author={Abdul-Rahman, Omar Arif and Aida, Kento},
  journal={IEEE Transactions on Cloud Computing}, 
  title={Google Users as Sequences: A Robust Hierarchical Cluster Analysis Study}, 
  year={2020},
  volume={8},
  number={1},
  pages={167-179},
  abstract={In this era of cloud computing, users encounter the challenging task of effectively composing and running their applications on the cloud. By understanding user behavior in constructing applications and interacting with typical cloud infrastructures, cloud managers can develop better systems that improve the users' experience. In this paper, we analyze a large dataset of a Google cluster to characterize the users into distinct groups of similar usage behavior. We used a wide range of measured metrics to model user behavior in composing applications from the perspective of actions around application architecting, capacity planning, and workload type planning and to model user interaction behavior around the session view. The trajectories of users' actions are represented as sequences using categorical and proportional encoding schemes. We used techniques from the sequence analysis paradigm to quantify dissimilarity among users. We employed a robust cluster analysis procedure based on the agglomerative hierarchical methods to optimally classify users into 12 classes. We used a variety of formal indices and visual aids to confirm the quality and stability of the outcomes. By visual inspection, we regrouped the obtained clusters into 5 main groups that reveal interesting insights about the characteristics which underline different groups' utilization behavior.},
  keywords={},
  doi={10.1109/TCC.2017.2766227},
  ISSN={2168-7161},
  month={Jan},}@INPROCEEDINGS{7152489,
  author={Kuang, Wei and Brown, Laura E. and Wang, Zhenlin},
  booktitle={2015 15th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing}, 
  title={Modeling Cross-Architecture Co-Tenancy Performance Interference}, 
  year={2015},
  volume={},
  number={},
  pages={231-240},
  abstract={Cloud computing has become a dominant computing paradigm to provide elastic, affordable computing resources to end users. Due to the increased computing power of modern machines powered by multi/many-core computing, data centers often co-locate multiple virtual machines (VMs) into one physical machine, resulting in co-tenancy, and resource sharing and competition. Applications or VMs co-locating in one physical machine can interfere with each other despite of the promise of performance isolation through virtualization. Modelling and predicting co-run interference therefore becomes critical for data center job scheduling and QoS (Quality of Service) assurance. Co-run interference can be categorized into two metrics, sensitivity and pressure, where the former denotes how an application's performance is affected by its co-run applications, and the latter measures how it impacts the performance of its co-run applications. This paper shows that sensitivity and pressure are both application-and architecture dependent. Further, we propose a regression model that predicts an application's sensitivity and pressure across architectures with high accuracy. This regression model enables a data center scheduler to guarantee the QoS of a VM/application when it is scheduled to co-locate with another VMs/applications.},
  keywords={},
  doi={10.1109/CCGrid.2015.152},
  ISSN={},
  month={May},}@INPROCEEDINGS{7744161,
  author={He, Fei-Long and Chen, Wei-Neng and Hu, Xiao-Min},
  booktitle={2016 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Differential evolution with double-level archives for bi-objective cloud task scheduling}, 
  year={2016},
  volume={},
  number={},
  pages={2942-2949},
  abstract={In cloud computing, scheduling plays a critical role for quality of service (QoS) and provider efficiency which are generally measured by several metrics and make the scheduling a multiobjective problem (MOP). In this paper, we propose a differential evolution algorithm with double-level archives (DE-DLA) for bi-objective cloud task scheduling. The proposed algorithm is based on the newly-developed framework, multiobjective evolutionary algorithm with double-level archives (MOEA-DLA), and uses differential evolution to implement this framework. Global Archive is used to save Pareto-optimal individuals for the whole problem and Sub-archive is used to save several comparatively good individuals for the corresponding sub-problem formed by decomposition. So the algorithm takes advantages of both whole multiobjective problem optimization and decomposition based optimization. Precedence constraint in user's application is considered in the scheduling model of this paper. To minimize cost and makespan simultaneously, the proposed algorithm tries to find optimal resource allocation and optimal order of task executing. In the experiment, compared with two other algorithms, DE-DLA has shown competitive advantages.},
  keywords={},
  doi={10.1109/CEC.2016.7744161},
  ISSN={},
  month={July},}@ARTICLE{6856153,
  author={Shuja, Junaid and Bilal, Kashif and Madani, Sajjad A. and Othman, Mazliza and Ranjan, Rajiv and Balaji, Pavan and Khan, Samee U.},
  journal={IEEE Systems Journal}, 
  title={Survey of Techniques and Architectures for Designing Energy-Efficient Data Centers}, 
  year={2016},
  volume={10},
  number={2},
  pages={507-519},
  abstract={Cloud computing has emerged as the leading paradigm for information technology businesses. Cloud computing provides a platform to manage and deliver computing services around the world over the Internet. Cloud services have helped businesses utilize computing services on demand with no upfront investments. The cloud computing paradigm has sustained its growth, which has led to increase in size and number of data centers. Data centers with thousands of computing devices are deployed as back end to provide cloud services. Computing devices are deployed redundantly in data centers to ensure 24/7 availability. However, many studies have pointed out that data centers consume large amount of electricity, thus calling for energy-efficiency measures. In this survey, we discuss research issues related to conflicting requirements of maximizing quality of services (QoSs) (availability, reliability, etc.) delivered by the cloud services while minimizing energy consumption of the data center resources. In this paper, we present the concept of inception of data center energy-efficiency controller that can consolidate data center resources with minimal effect on QoS requirements. We discuss software- and hardware-based techniques and architectures for data center resources such as server, memory, and network devices that can be manipulated by the data center controller to achieve energy efficiency.},
  keywords={},
  doi={10.1109/JSYST.2014.2315823},
  ISSN={1937-9234},
  month={June},}@ARTICLE{8683979,
  author={Gamal, Marwa and Rizk, Rawya and Mahdi, Hani and Elnaghi, Basem E.},
  journal={IEEE Access}, 
  title={Osmotic Bio-Inspired Load Balancing Algorithm in Cloud Computing}, 
  year={2019},
  volume={7},
  number={},
  pages={42735-42744},
  abstract={Cloud computing is increasing rapidly as a successful paradigm presenting on-demand infrastructure, platform, and software services to clients. Load balancing is one of the important issues in cloud computing to distribute the dynamic workload equally among all the nodes to avoid the status that some nodes are overloaded while others are underloaded. Many algorithms have been suggested to perform this task. Recently, worldview is turning into a new paradigm for optimization search by applying the osmosis theory from chemistry science to form osmotic computing. Osmotic computing is aimed to achieve balance in highly distributed environments. The main goal of this paper is to propose a hybrid metaheuristics technique which combines the osmotic behavior with bio-inspired load balancing algorithms. The osmotic behavior enables the automatic deployment of virtual machines (VMs) that are migrated through cloud infrastructures. Since the hybrid artificial bee colony and ant colony optimization proved its efficiency in the dynamic environment in cloud computing, the paper then exploits the advantages of these bio-inspired algorithms to form an osmotic hybrid artificial bee and ant colony (OH_BAC) optimization load balancing algorithm. It overcomes the drawbacks of the existing bio-inspired algorithms in achieving load balancing between physical machines. The simulation results show that OH_BAC decreases energy consumption, the number of VMs migrations and the number of shutdown hosts compared to existing algorithms. In addition, it enhances the quality of services (QoSs) which is measured by service level agreement violation (SLAV) and performance degradation due to migrations (PDMs).},
  keywords={},
  doi={10.1109/ACCESS.2019.2907615},
  ISSN={2169-3536},
  month={},}@ARTICLE{7066939,
  author={Lillo-Castellano, J. M. and Mora-Jiménez, I. and Santiago-Mozos, R. and Chavarría-Asso, F. and Cano-González, A. and García-Alberola, A. and Rojo-Álvarez, J. L.},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Symmetrical Compression Distance for Arrhythmia Discrimination in Cloud-Based Big-Data Services}, 
  year={2015},
  volume={19},
  number={4},
  pages={1253-1263},
  abstract={The current development of cloud computing is completely changing the paradigm of data knowledge extraction in huge databases. An example of this technology in the cardiac arrhythmia field is the SCOOP platform, a national-level scientific cloud-based big data service for implantable cardioverter defibrillators. In this scenario, we here propose a new methodology for automatic classification of intracardiac electrograms (EGMs) in a cloud computing system, designed for minimal signal preprocessing. A new compression-based similarity measure (CSM) is created for low computational burden, so-called weighted fast compression distance, which provides better performance when compared with other CSMs in the literature. Using simple machine learning techniques, a set of 6848 EGMs extracted from SCOOP platform were classified into seven cardiac arrhythmia classes and one noise class, reaching near to 90% accuracy when previous patient arrhythmia information was available and 63% otherwise, hence overcoming in all cases the classification provided by the majority class. Results show that this methodology can be used as a high-quality service of cloud computing, providing support to physicians for improving the knowledge on patient diagnosis.},
  keywords={},
  doi={10.1109/JBHI.2015.2412175},
  ISSN={2168-2208},
  month={July},}@INPROCEEDINGS{8046685,
  author={Wang, Paul and Takizawa, Shigeyuki and He, David and Ge, Fred and Wang, Orson and Ye, Fred and Liang, Park and Tan, KG},
  booktitle={2017 18th International Conference on Electronic Packaging Technology (ICEPT)}, 
  title={DDR4 dual-contact interconnect methodology, component, and board level reliability}, 
  year={2017},
  volume={},
  number={},
  pages={1337-1344},
  abstract={This article is a series of study on new generation of electronic contact challenges and component interconnects technology for high-end computing products. These products include server and data storage for cloud computing applications at the data center as well as core routers for service providers, edge and branch routers for enterprise networking companies, and small switch and wireless router for commercial and small and home office. All these cloud computing products require high data speed in terabytes per second and high signal integrity for the massive mobile users and loT application whenever and wherever they connected To achieve such mobility and signal integrity the major focus is the electrical interconnections between the CPUlGPU and component in the system. Due to the large number of edge-card connections such as DIMM, PCle, etc. in modern computer systems and due to their relatively low reliability, in previous Part 2 of the study a test vehicle with daisy chain was used to assess the contact interconnect failure related to factors such as soldering flux residue, plating quality, contact interface cleaning and doubt insertion, and particulate control and management. As concluded in Part 2, the heavy flux residue and vibration preconditioning have medium effect on contact failure, however contact interface cleaning and particulate control show no significant contribution and not able to eliminate the last thousands DPPM of DIMM contact failure. The purpose of current study is to look into a new generation of dual-contact interconnect methodology and assess component level contact configuration and interconnect reliability. First, the contact pin configuration and plating morphology such as homogeneity and thickness are carefully examined to ensure contact integrity between DDR4 connect and DIMM module can be achieved. Then normal force of dual-pin and individual first and second contact were measured to benchmark to existing conventional single-contacts. Furthermore the JEDEC Raptor test vehicle was adapted to assess characteristic impedance and four signal integrity tests, RL (return loss), IL (insertion loss), NEXT (near-end cross talk), and FEXT (far-end cross talk) to ensure signal integrity requirements are fulfilled. Finally, board level reliability test is proposed for Raptor test board and trial run on real product. The overall goal of Part 3 of the study is to ensure a smooth migration from conventional single-contact to a new interconnect mechanism with robust board and system reliability for high signal integrity requirement in cloud computing and loT application.},
  keywords={},
  doi={10.1109/ICEPT.2017.8046685},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9667831,
  author={Ishak, Md and Rahman, Raiyan and Mahmud, Tahasin},
  booktitle={2021 5th International Conference on Electrical Engineering and Information Communication Technology (ICEEICT)}, 
  title={Integrating Cloud Computing in E-healthcare: System Design, Implementation and Significance in Context of Developing Countries}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Cloud computing in the medical sector refers to the method of storing, maintaining, and processing electronic health records and relevant services on cloud servers that are accessible over the internet. The flexibility of cloud computing makes it a practical approach for enhancing the quality, dependability, and efficiency of medical services, as well as increasing patient-doctor interaction and safeguarding patient anonymity if proper measures are taken. Furthermore, cloud strategies facilitate healthcare technologies such as computerized healthcare records, remote appointments, mobile applications, patient portals, IoT devices, and big data analytics, enabling trouble-free scalable solutions. Integrating cloud computing technologies can especially be beneficial in increasing the efficiency of healthcare services in developing counties where physical health infrastructure is usually limited. As such, the objective of this work is to explore the feasibility of incorporating cloud and distributed computing in e-healthcare through an extensive requirement analysis and user study. Then, the smart healthcare system will be compared with traditional database-centric healthcare systems and a prototype system will be designed and implemented based on the findings. Finally, we focus on finding the usability and user acceptance of such systems and challenges that lie with integrating cloud services to e-healthcare systems for the general user demographic of developing countries through extensive usability evaluation.},
  keywords={},
  doi={10.1109/ICEEICT53905.2021.9667831},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{7335004,
  author={Dai, Yangyang and Lou, Yuansheng and Lu, Xin},
  booktitle={2015 7th International Conference on Intelligent Human-Machine Systems and Cybernetics}, 
  title={A Task Scheduling Algorithm Based on Genetic Algorithm and Ant Colony Optimization Algorithm with Multi-QoS Constraints in Cloud Computing}, 
  year={2015},
  volume={2},
  number={},
  pages={428-431},
  abstract={Task scheduling problem in cloud computing environment is NP-hard problem, which is difficult to obtain exact optimal solution and is suitable for using intelligent optimization algorithms to approximate the optimal solution. Meanwhile, quality of service (QoS) is an important indicator to measure the performance of task scheduling. In this paper, a novel task scheduling algorithm MQoS-GAAC with multi-QoS constraints is proposed, considering the time-consuming, expenditure, security and reliability in the scheduling process. The algorithm integrates ant colony optimization algorithm (ACO) with genetic algorithm (GA). To generate the initial pheromone efficiently for ACO, GA is invoked. With the designed fitness function, 4-dimensional QoS objectives are evaluated. Then, ACO is utilized to seek out the optimum resource. The experiment indicates that the proposed algorithm has preferable performance both in balancing resources and guaranteeing QoS.},
  keywords={},
  doi={10.1109/IHMSC.2015.186},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{6958835,
  author={Wen, Zi-Yi and Hsiao, Hsu-Feng},
  booktitle={2014 IEEE 16th International Workshop on Multimedia Signal Processing (MMSP)}, 
  title={QoE-driven performance analysis of cloud gaming services}, 
  year={2014},
  volume={},
  number={},
  pages={1-6},
  abstract={With the popularity of cloud computing services and the endorsement from the video game industry, cloud gaming services have emerged promisingly. In a cloud gaming service, the contents of games can be delivered to the clients through either video streaming or file streaming. Due to the strict constraint on the end-to-end latency for real-time interaction in a game, there are still challenges in designing a successful cloud gaming system, which needs to deliver satisfying quality of experience to the customers. In this paper, the methodology for subjective and objective evaluation as well as the analysis of cloud gaming services was developed. The methodology is based on a nonintrusive approach, and therefore, it can be used on different kinds of cloud gaming systems. There are challenges in such objective measurements of important QoS factors, due to the fact that most of the commercial cloud gaming systems are proprietary and closed. In addition, satisfactory QoE is one of the crucial ingredients in the success of cloud gaming services. By combining subjective and objective evaluation results, cloud gaming system developers can infer possible results of QoE levels based on the measured QoS factors. It can also be used in an expert system for choosing the list of games that customers can appreciate at a given environment, as well as for deciding the upper bound of the number of users in a system.},
  keywords={},
  doi={10.1109/MMSP.2014.6958835},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{7037229,
  author={Mazza, Daniela and Tarchi, Daniele and Corazza, Giovanni E.},
  booktitle={2014 IEEE Global Communications Conference}, 
  title={A user-satisfaction based offloading technique for smart city applications}, 
  year={2014},
  volume={},
  number={},
  pages={2783-2788},
  abstract={The Smart cities applications are gaining an increasing interest among administrations, citizens and technologists for their suitability in managing the everyday life. One of the major challenges is regarding the possibility of managing in an efficient way the presence of multiple applications in a Wireless Heterogeneous Network (HetNet) environment, alongside the presence of a Mobile Cloud Computing (MCC) infrastructure. In this context we propose a utility function model derived from the economic world aiming to measure the Quality of Service (QoS), in order to choose the best access point in a HetNet to offload part of an application on the MCC, aiming to save energy for the Smart Mobile Devices (SMDs) and to reduce computational time. We distinguish three different types of application, considering different offloading percentage of computation and analyzing how the cell association algorithm allows energy saving and shortens computation time. The results show that when the network is overloaded, the proposed utility function allows to respect the target values by achieving higher throughput values, and reducing the energy consumption and the computational time.},
  keywords={},
  doi={10.1109/GLOCOM.2014.7037229},
  ISSN={1930-529X},
  month={Dec},}@INPROCEEDINGS{9306518,
  author={Forcan, M. and Maksimović, M. and Forcan, J. and Jokić, S.},
  booktitle={2020 28th Telecommunications Forum (TELFOR)}, 
  title={5G and Cloudification to Enhance Real-Time Electricity Consumption Measuring in Smart Grid}, 
  year={2020},
  volume={},
  number={},
  pages={1-4},
  abstract={The number of smart devices in Smart Grid (SG) increases continuously and the presence of big data demands more efficient communication architectures. It is anticipated that the full potential of the SG vision in terms of better performances, reliability, and quality of service, can be achieved by incorporating the fifth generation of cellular network technology (5G) and Cloudification into the SG. In order to demonstrate their potential in SG, this paper presents the enhancement of real-time electricity consumption measuring with the help of 5G and Cloud computing. 5G-based communication model supporting Advanced Metering Infrastructure (AMI) in SG is built and validated on the example of real-time communication between the SM model and Cloud platform ThingSpeak.},
  keywords={},
  doi={10.1109/TELFOR51502.2020.9306518},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9004389,
  author={Anita, J. Mary and Raina, Roma},
  booktitle={2019 International Conference on Computational Intelligence and Knowledge Economy (ICCIKE)}, 
  title={Review on Smart Grid Communication Technologies}, 
  year={2019},
  volume={},
  number={},
  pages={215-220},
  abstract={Smart grid (SG) has given a better vision for electricity infrastructure. The quality, quantity of power transmitted and the usage of available data from smart sensing, metering and communication has dramatically increased with the introduction of smart grid to power systems. SG also has empowered customer participation by managing their load pattern to take advantage of choosing their supply and pricing options. The heart of the SG lies on the communication between the consumers and the grid operators. Grids operators need the real time customer meter data to schedule their supply and pricing policies and the consumers need the same to manage their loads. The Wireless Sensor Network (WSN) uses Aggregation Protocol with Error Detection (APED) to improve the security of data. The SG with SCADA is facilitated by data acquisitions which includes the meter reading, system conditions, etc. that are monitored and transmitted at regular intervals in real time. The security of data transfer is assured by the introduction of improvised Ciphertext Policy_ Attribute Based Encryption (CP-ABE) is used to achieve the security parameters like confidentiality, integrity, and availability in cloud computing. Block chain-based systems combine distributed register and cryptographic security measures. Introduction of block chain in SG has revolutionized the functioning of SG with smart contracts, and transaction of huge amount of data in a fully decentralized market platform.This paper reviews the modern technologies used in smart grid communication based on IEEE 802.15.4 standard to the SG and how it is modified to ensure effective, efficient and economical and secured communication of the huge real time data from the smart meters.},
  keywords={},
  doi={10.1109/ICCIKE47802.2019.9004389},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9292150,
  author={Gavra, Vlad-Dacian and Pop, Ovidiu Aurel},
  booktitle={2020 IEEE 26th International Symposium for Design and Technology in Electronic Packaging (SIITME)}, 
  title={Usage of ZigBee and LoRa wireless technologies in IoT systems}, 
  year={2020},
  volume={},
  number={},
  pages={221-224},
  abstract={IoT systems are based sensors and actuators to enable ubiquitous sensing to measure environment parameters from delicate ecologies and natural environments to urban environments. By connecting these sensors and actuators to a big network, like internet, an automatization can be performed, and repetitive actions can be done in background by the IoT ecosystem and save a lot of time. IoT can do such things in Home Automation, Smart Cities and even in Air Quality analysis. IoT solution are dependent on the way sensors are transmitting data to cloud or up to the internet. This paper will present the benefits of using Zig Bee instead of using traditional Wi-Fi sensor and present some of the characteristics of LoRa sensors. Cloud computing contributed to the expansion of the IoT systems by offloading local IoT devices of computation intensive tasks. Fog computing brings Cloud closer to the sensors and by doing this minimize communication latencies.},
  keywords={},
  doi={10.1109/SIITME50350.2020.9292150},
  ISSN={2642-7036},
  month={Oct},}@INPROCEEDINGS{7979932,
  author={Lin, Cho-Chin and Kuo, Yuan-Han and Xie, Dong-Ye and Goh, Wei-Ping and Wu, Shyi-Tsong},
  booktitle={2016 7th International Conference on Cloud Computing and Big Data (CCBD)}, 
  title={A Practical Model for Analyzing Push-Based Virtual Machine Live Migration}, 
  year={2016},
  volume={},
  number={},
  pages={347-352},
  abstract={Virtual Technology has been employed by cloud computing to satisfy service requests from the customers. Virtual machine live migration provides non-stop services while an unexpected event impacts the service quality of the host. The cost of performing live migration is measured by the total number of transferred pages and the service suspension time. In this paper, a practical model for analysing push-based live migration is proposed. The model abstracts live migration strategy into trend and sanction functions. Based on the model, the patterns on the numbers of transferred memory frames in the iterations have been analysed for various dirty frequencies and push rules. Furthermore, it is useful for developing a formal method for conducting complex analysis.},
  keywords={},
  doi={10.1109/CCBD.2016.074},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8892932,
  author={Tri, Nguyen Minh and Nagata, Syunya and Tsuru, Masato},
  booktitle={2019 20th Asia-Pacific Network Operations and Management Symposium (APNOMS)}, 
  title={Locating Delay Fluctuation-Prone Links by Packet Arrival Intervals in OpenFlow Networks}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={In cloud computing and content delivery networking, OpenFlow-based centrally managed networks to connect distributed servers are becoming popular these days. To maintain service quality and availability in such networks by flexible and dynamic traffic engineering, detecting and locating deteriorated (e.g., congested) links in an efficient manner is essential. Following our previous study that actively monitors packet loss rate to find deteriorated links, in this paper, we actively estimate packet delay variance on each link (note both up and down directions of each full-duplex link are distinguished) in an OpenFlow network. A notable feature is that packet delay variance is estimated based on monitoring arrival time intervals of probe packets without directly measuring packet delay time over a link. In the proposed scheme, a series of probe packets is launched from a measurement host and traverses each direction of each link once and only once by multicasting, while arrival time intervals of those packets at each input port of OpenFlow switches are monitored. Then the OpenFlow controller collects the arrival time interval statistics from those switches to locate delay fluctuation-prone links, i.e., links with a high packet delay variance, which are likely congested or physically unstable. In addition, to minimize the necessary number of accesses to switch ports, an appropriate order of collecting statistics from switches is dynamically controlled. The results of numerical simulation on large-scale network topologies demonstrate the effectiveness of our proposed scheme. A prototype implementation which requires an extension of OpenFlow is also presented on Mininet.},
  keywords={},
  doi={10.23919/APNOMS.2019.8892932},
  ISSN={2576-8565},
  month={Sep.},}@INPROCEEDINGS{8494151,
  author={Prathibha, K and Hegde, Pawan},
  booktitle={2018 9th International Conference on Computing, Communication and Networking Technologies (ICCCNT)}, 
  title={A Real-Time System for Environmental Study Based on Cloud Computing}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={Following the ecological parameters variation is important keeping in mind the end goal to decide on the nature of our environment. This paper aims at detecting and detailing the changes in the environmental parameters. Environmental monitoring applications based on cloud computing makes use of sensors to help in protecting environmental conditions by checking parameters like temperature, air quality, earthquake and so on. The utilization of present day advances such as the single-board computers can encourage and give much more functionalities to cloud. The significant areas that cover the above said applications are home, industries, buildings and so forth. This is the way toward observing some of the modules of environment and thus providing the features to the admins and clients. It causes the specialists to screen the states of the work in an organization or industry from remote areas and to take prompt measures.},
  keywords={},
  doi={10.1109/ICCCNT.2018.8494151},
  ISSN={},
  month={July},}@INPROCEEDINGS{8998716,
  author={Munadi, Rendy and Irawan, Arif Indra and Romiadi, Yuman Fariz},
  booktitle={2019 International Conference on Mechatronics, Robotics and Systems Engineering (MoRSE)}, 
  title={Security System ATM Machine with One-Time Passcode on M-Banking Application}, 
  year={2019},
  volume={},
  number={},
  pages={92-96},
  abstract={Automated Teller Machine (ATM) security system currently still uses magnetic cards and static PIN as its security system, which create many security holes. This security hole in many cases caused many bank customers to lose money mysteriously. In this paper a two-factor authentication system which uses ATM card and dynamic PIN is proposed to overcome this security hole. In this paper, a prototype of an ATM and m-banking application were built. The ATM prototype uses several components such as the Raspberry Pi 3B, smart card, smart card reader / writer, keypad number and LCD monitor. Dynamic PINs are generated using the CSPRNG-SHA1-MWC random number generator. In developing the prototypes, the framework used in this study is based on mobile applications and cloud computing. To evaluate the quality of the prototype, we performed qualitative and quantitative tests. Qualitatively we tested the prototype using a questionnaire using 165 sample respondents to provide an opinion about the safety and comfort of our prototype and quantitatively we measured the prototype to find out the level of randomness of the generated PIN and the QoS of the designed prototype.},
  keywords={},
  doi={10.1109/MoRSE48060.2019.8998716},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8976772,
  author={Rana, Prateek and Sharma, Monika},
  booktitle={2019 2nd International Conference on Power Energy, Environment and Intelligent Control (PEEIC)}, 
  title={Less Energy Consumption Framework for Fog Computing With IoT}, 
  year={2019},
  volume={},
  number={},
  pages={41-46},
  abstract={IOT applications nowadays have quickly expanded and the basic standard centralized models of cloud computing have faced numerous challenging situations which has excessiveness in latency; have low capacity and the failure of network, less capacity of storing and excessive use of power. Fog computing has brought the cloud nearer to the devices of IOT, which deals with the challenges. The services being provided by the fog have quicker response moreover more better quality, in comparison to the cloud. The choices which are best, allow the IOT to offer services which are efficient and secured for most of the users of IOT, that is being measured by the fog computing. In this paper, we are focusing on the fog computing furthermore the incorporation of fog computing with the IOT by specially focusing on the implementation of the challenges is being presented. We have proposed architecture for the less consumption of energy and power.},
  keywords={},
  doi={10.1109/PEEIC47157.2019.8976772},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9355356,
  author={Yang, Yi},
  booktitle={2020 International Conference on Advance in Ambient Computing and Intelligence (ICAACI)}, 
  title={Simulation Analysis of Standardized Management Measures of Enterprise Accounting Based on Cloud Computing}, 
  year={2020},
  volume={},
  number={},
  pages={143-146},
  abstract={In the current corporate governance, accounting management is an indispensable part, in which the quality of accounting directly affects the prosperity of enterprises. Accounting is a basic work in the related work of enterprise accounting, which is the accounting of economic activities of enterprises under the constraints of relevant laws and regulations, and is a summary of previous economic activities. Accounting, as a basic function and the core content of enterprise accounting work, has always been in a very important position. Accounting information feeds back the problems existing in the production and operation of enterprises, so that relevant personnel can continuously optimize their work, and ultimately enhance the competitiveness of products or services provided by enterprises in the market. This paper discusses the connotation and importance of enterprise accounting standardization management, analyzes the problems existing in the process of enterprise accounting standardization management, and puts forward specific measures of enterprise accounting standardization management based on cloud computing.},
  keywords={},
  doi={10.1109/ICAACI50733.2020.00036},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9602504,
  author={Li, Xu and Gao, Guanbin and Na, Jing and Chen, Xin},
  booktitle={2021 33rd Chinese Control and Decision Conference (CCDC)}, 
  title={Design of an Automatic T-beam Erection System Based on NB-IoT for Bridge-Erecting Cranes}, 
  year={2021},
  volume={},
  number={},
  pages={684-689},
  abstract={Bridge-erecting cranes are often used for beam erection in the construction of expressways. To improve the speed and quality of T-beam erection and ensure the safety of bridge-erecting cranes, an automatic T-beam erection system based on the Internet of Things (IoT) is designed in this paper. Narrow Band Internet of Things (NB-IoT) communication technology is used to integrate laser-ranging sensors, batteries, and communication modules into base station subsystems, which are installed in specific locations of the bridge-erecting crane. The position of the T-beam can be measured in real-time by the laser ranging sensors, with which a closed-loop control system is constructed for the T-beam erection system. The information of the running state including the position of the T-beam, the installation progress, and the position of the bridge-erecting crane is transferred to the cloud computing platform by NB-IoT, which can be viewed by mobile terminals. The experimental tests show that the distance measurement range of the system is 0.045m~30m, and the measurement accuracy is 2mm. Compared with the manual operation, the automatic T-beam erection system can reduce the risk of the T-beam erection and improve efficiency.},
  keywords={},
  doi={10.1109/CCDC52312.2021.9602504},
  ISSN={1948-9447},
  month={May},}@INPROCEEDINGS{9556059,
  author={Jin, Xuan and Xie, Yunlong and Yin, Yitao},
  booktitle={2021 13th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC)}, 
  title={BotCatcher:A Complementary Advantages and Deep Learning Based Scheme for Intrusion Detection}, 
  year={2021},
  volume={},
  number={},
  pages={95-98},
  abstract={In today’s society, computer network is one of the most important and advanced infrastructures. The emerging technologies, represented by cloud computing, have brought many new situations and challenges to network security. This paper presents a novel scheme, called BotCatcher, which is based on the fusion and optimization of two different types of existing methods for intrusion detection. There are two models in the scheme: 1) The high-speed mode based on complementary advantages improves the F-Measure by about 0.06 without reducing the detection rate and 2) The high-quality mode based on deep learning combines the historical behavior of hosts and optimizes the detection index for greater performance improvement.},
  keywords={},
  doi={10.1109/IHMSC52134.2021.00030},
  ISSN={},
  month={Aug},}@ARTICLE{9129768,
  author={Azizi, Sadoon and Shojafar, Mohammad and Abawajy, Jemal and Buyya, Rajkumar},
  journal={IEEE Systems Journal}, 
  title={GRVMP: A Greedy Randomized Algorithm for Virtual Machine Placement in Cloud Data Centers}, 
  year={2021},
  volume={15},
  number={2},
  pages={2571-2582},
  abstract={Cloud computing efficiency greatly depends on the efficiency of the virtual machines (VMs) placement strategy used. However, VM placement has remained one of the major challenging issues in cloud computing mainly because of the heterogeneity in both virtual and physical machines (PMs), the multidimensionality of the resources, and the increasing scale of the cloud data centers (CDCs). An inefficiency in VM placement strategy has a significant influence on the quality of service provided, the amount of energy consumed, and the running costs of the CDCs. To address these issues, in this article, we propose a greedy randomized VM placement (GRVMP) algorithm in a large-scale CDC with heterogeneous and multidimensional resources. GRVMP inspires the “power of two choices” model and places VMs on the more power-efficient PMs to jointly optimize CDC energy usage and resource utilization. The performance of GRVMP is evaluated using synthetic and real-world production scenarios (Amazon EC2) with several performance matrices. The results of the experiment confirm that GRVMP jointly optimizes power usage and the overall wastage of resource utilization. The results also show that GRVMP significantly outperforms the baseline schemes in terms of the performance metrics used.},
  keywords={},
  doi={10.1109/JSYST.2020.3002721},
  ISSN={1937-9234},
  month={June},}@INPROCEEDINGS{6903503,
  author={Lim, Erbin and Thiran, Philippe},
  booktitle={2014 IEEE International Conference on Cloud Engineering}, 
  title={Communication of Technical QoS among Cloud Brokers}, 
  year={2014},
  volume={},
  number={},
  pages={403-409},
  abstract={Service brokers are commonly used in the cloud computing paradigm to represent service requesters to select a service provider. They act as an intermediary between the two parties. One model of the cloud computing paradigm involves 3 layers, the user, the SaaS provider and the Cloud provider. The selection of service requesters is challenging due to the different levels of Quality of Service that each service provider can provide. In this paper we propose a unique mechanism that allows communication between service brokers in different layers in order to further improve this selection. In addition, we introduce a metric, efficiency, which service brokers can use to deterministically compare service providers with each other.},
  keywords={},
  doi={10.1109/IC2E.2014.92},
  ISSN={},
  month={March},}@INPROCEEDINGS{6927759,
  author={Sang-Ho Na and Eui-Nam Huh},
  booktitle={Fourth edition of the International Conference on the Innovative Computing Technology (INTECH 2014)}, 
  title={A methodology of assessing security risk of cloud computing in user perspective for security-service-level agreements}, 
  year={2014},
  volume={},
  number={},
  pages={87-92},
  abstract={underlying cloud computing feature, outsourcing of resources, makes the Service Level Agreement (SLA) is a critical factor for Quality of Service (QoS), and many researchers have addressed the question of how a SLA can be evaluated. Lately, security-SLAs have also received much attention with the Security-as-a-Service mode in cloud computing. The quantitative measurement of security metrics is a considerably difficult problem and might be considered the multi-dimensional aspects of security threats and user requirements. To address these issues, we provide a novel a methodology of security risk assessment for security-service-level agreements in the cloud service based on a multi-dimensional approach depending on services type, probabilities of threats, and network environments to reach a security-SLA evaluation.},
  keywords={},
  doi={10.1109/INTECH.2014.6927759},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9537262,
  author={Reddy, Gangireddy Narendra Kumar and Manikandan, M. Sabarimalai and Murty, N. V. L. Narasimha},
  booktitle={2021 IEEE International Conference on Health, Instrumentation & Measurement, and Natural Sciences (InHeNce)}, 
  title={Lightweight Compressed Sensing (CS) and Partial DCT Based Compression Schemes for Energy-Efficient Wearable PPG Monitoring Devices}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Most wearable medical devices are designed to continuously acquire photoplethysmography (PPG) for measuring vital signs and transmitting acquired PPG data wirelessly to edge-computing device or cloud-computing server. These devices are constrained with limited battery power and data-rate capacity. Therefore, in this paper, we present a lightweight effective data-reduction method by investigating the performance of compressed sensing (CS)-based and and partial discrete cosine transform (DCT)-based compression methods with major objectives of achieving higher compression ratio (CR) with minimal waveform distortion with low reconstruction time. By using both normal and abnormal PPG signals, the performance of the CS-based and DCT-based compression methods is evaluated in terms of CR, global and local distortion measures and processing time. Evaluation results showed that CR values of the partial-DCT based method are 3 times higher (CR ranging from 7.50 to 9.38) without distorting fiducial points and shapes of the PPG signal (percentage root-mean-square difference (PRD) ranging from 1% to 2%) as compared to the CS-based data method (CR from 2.50 to 3.13 for PRD from 2% of 4%). The higher data reduction with acceptable level of reconstruction quality demonstrates that the partial DCT-based method can lead to provide better overall energy consumption reduction solution for resource-constrained wearable devices.},
  keywords={},
  doi={10.1109/InHeNce52833.2021.9537262},
  ISSN={},
  month={July},}@ARTICLE{7226862,
  author={Peng, Kuan-Li and Huang, Chin-Yu},
  journal={IEEE Transactions on Services Computing}, 
  title={Reliability Analysis of On-Demand Service-Based Software Systems Considering Failure Dependencies}, 
  year={2017},
  volume={10},
  number={3},
  pages={423-435},
  abstract={Service-based software systems (SBSSs) are widely deployed due to the growing trend of distributed computing and cloud computing. It is important to ensure high quality of an SBSS, especially in a strongly competitive market. Existing works on SBSS reliability usually assumed independence of service failures. However, the fact that resource sharing exists in different levels of SBSS operations invalidates this assumption. Ignorance of failure dependencies have been discussed as potentially affecting system reliability predictions and lowering the benefits of design diversity, as typically seen in high-reliability systems. In this paper, we propose a reliability framework that incorporates failure dependence modeling, system reliability modeling, as well as reliability analysis for individual services and for failure sources. The framework is also capable of analyzing the internal structures of popular software fault tolerant (FT) schemes. The proposed method is applied to a travel agency system based upon a real-world practice for verifying its accuracy of reliability modeling and effectiveness of varied reliability measures. The results show that failure dependence of the services is an essential factor for analyzing any valuable SBSS system. Further, a set of reliability measures with different capabilities and complexities are available for assisting SBSS engineers with system improvements.},
  keywords={},
  doi={10.1109/TSC.2015.2473843},
  ISSN={1939-1374},
  month={May},}@INPROCEEDINGS{9210369,
  author={Rico-Bautista, Dewar and Maestre-Gongora, Gina and Guerrero, Cesar D.},
  booktitle={2020 Fourth World Conference on Smart Trends in Systems, Security and Sustainability (WorldS4)}, 
  title={Smart University:IoT adoption model}, 
  year={2020},
  volume={},
  number={},
  pages={821-826},
  abstract={Higher education organizations see in new technologies an opportunity to improve the quality of their academic and administrative processes. However, the existence and application of new technologies in this type of institutions does not imply that it really has the expected impact on their processes, so many adoption initiatives fail generating losses and discouragement towards change. This happens mainly because more work is done on technology than on the realities of the institutions. One way to prevent this type of problem and redirect efforts is to align the adoption process itself. As artificial intelligence, cloud computing, IoT (Internet of Things) and Big Data technologies become stronger, it is necessary to have tools at hand that have the capacity to measure the level of adoption by institutions. The objective of measuring adoption by the processes and realities of higher education institutions, with a focus on their users. Many models have been proposed to understand why users accept or use technologies. Among those that have emerged for the study of technology adoption are TAM, UTAUT, UTAUT2, DOI, TPB, TRA, among others. This characterization allows us to conclude about the need for alignment and integration of technology with the organization's processes, calling for greater interaction with senior management.},
  keywords={},
  doi={10.1109/WorldS450073.2020.9210369},
  ISSN={},
  month={July},}@INPROCEEDINGS{8711239,
  author={Navamani, Beaulah A and Yue, Chuan and Zhou, Xiaobo},
  booktitle={2018 IEEE 37th International Performance Computing and Communications Conference (IPCCC)}, 
  title={Discover and Secure (DaS): An Automated Virtual Machine Security Management Framework}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={Cloud computing is very appealing for its convenient central management, the elasticity of resource provisioning and its economic benefits. Undoubtedly, the non-transparent nature of the Cloud infrastructure introduces significant security concerns. Naively, Virtual Machine (VM) migration can weaken or even nullify the security protection on a VM. Attackers compromise such vulnerable hosts and can either take control over their resources or use them as a channel for future attacks. To overcome the hidden security risk, this paper proposes Discover and Secure (DaS) framework for automated VM security management. This framework accomplishes two qualities: 1) to discover whether the VM is an inadvertent security victim 2) to secure the VM and the mission-critical applications running inside them. Modules in this framework detect, extract and measures the new identifiers assigned to the VM. Comparing the new identifiers to the reference table containing the old measured identifier values, verifies the identifier/s status. Transformed identifiers are perceived and replaced with new valid ones, hence, restoring the nullified security. This framework is implemented as VM-Internal security, self-supplied by the user and VM-introspection security, host-supplied by the cloud provider. Experimental results show that DaS framework can armor the VM from obscured security problems and seal the hidden door against attackers.},
  keywords={},
  doi={10.1109/PCCC.2018.8711239},
  ISSN={2374-9628},
  month={Nov},}@INPROCEEDINGS{9732730,
  author={Shrivastava, Ritu and Tiwary, Abhigyan and Yadav, Pranay},
  booktitle={2021 International Conference on Advances in Technology, Management & Education (ICATME)}, 
  title={Challenges Block Chain Technology Using IOT for Improving Personal and Physical Safety - Review}, 
  year={2021},
  volume={},
  number={},
  pages={238-243},
  abstract={Web of Things (IoT) is an interconnection of clever actual articles called things and People. IoT permits each “Thing” to associate and impart in this manner creating and sending a colossal measure of Data like a monster Information System. Because of the immense measure of Data dealing with by IoT gadgets it got fundamental to incorporate Cloud Computing, Machine Learning and Information Modelling into The IoT stage. The enormous development in the field of IoT is causing increment in Information and Communication Technology (ICT) business too. It is anticipated that before the finish of 2020 95% of the new items will have IoT as its canter. As can be seen there will be an expanding presence of IoT objects and thus their perceivability from the Internet and lawful admittance to assets is a subject of grave concern. IoT gives and empowers the formation of creative applications that improved the physical and individual existence of an individual, yet the absence of security and weakness of individuals may prompt basic issues like the wellbeing of our homes might be undermined, and Centralized organizations utilizing delicate information are consistently at a danger hacking. Block-chain innovation is increasing a ton of consideration from different associations and parcel of examination is being done as it gives extraordinary answers for the issues related with the traditional incorporated design of IoT. Since, there are so numerous IoT gadgets which are on the lookout for the upgrade of an individual's physical, mental development and improving the personal satisfaction by and large, a conveyed trust innovation, guaranteeing versatility, security, and unwavering quality, is the need of great importance for the development of IoT conditions. The joining of IoT and BC represents a ton of difficulties. The Objective of this exploration paper is to build up an incorporated IOT and Block-chain Application Environment to upgrade the individual and Physical existence of a being. Consequently, our center will be to build up a safe and safe climate for a Smart home. Our proposed design depends on progressive structure and disseminated foundation of Block-chain to keep up security and protection and make it appropriate for explicit prerequisites of IoT. Subsequently we have coordinated the mechanization of the home alongside the actual soundness of an individual in this manner guaranteeing wellbeing, accommodation and strength of an individual.},
  keywords={},
  doi={10.1109/ICATME50232.2021.9732730},
  ISSN={},
  month={Jan},}@ARTICLE{9153148,
  author={Abdel-Basset, Mohamed and El-Shahat, Doaa and Elhoseny, Mohamed and Song, Houbing},
  journal={IEEE Internet of Things Journal}, 
  title={Energy-Aware Metaheuristic Algorithm for Industrial-Internet-of-Things Task Scheduling Problems in Fog Computing Applications}, 
  year={2021},
  volume={8},
  number={16},
  pages={12638-12649},
  abstract={In Industrial-Internet-of-Things (IIoT) applications, fog computing (FC) has soared as a means to improve the Quality of Services (QoSs) provided to users through cloud computing, which has become overwhelmed by the massive flow of data. Transmitting all these amounts of data to the cloud and coming back with a response can cause high latency and requires high network bandwidth. The availability of sustainable energy sources for FC servers is one of the difficulties that the service providers can face in IIoT applications. The most important factor contributing to energy consumption on fog servers is task scheduling. In this article, we suggest an energy-aware metaheuristic algorithm based on a Harris Hawks optimization algorithm based on a local search strategy (HHOLS) for task scheduling in FC (TSFC) to improve the QoSs provided to the users in IIoT applications. First, we describe the high virtualized layered FC model taking into account its heterogeneous architecture. The normalization and scaling phase aids the standard Harris hawks algorithm to solve the TSFC, which is discrete. Moreover, the swap mutation ameliorates the quality of the solutions due to its ability to balance the workloads among all virtual machines. For further improvements, a local search strategy is integrated with HHOLS. We compare HHOLS with other metaheuristics using various performance metrics, such as energy consumption, makespan, cost, flow time, and emission rate of carbon dioxide. The proposed algorithm gives superior results in comparison with other algorithms.},
  keywords={},
  doi={10.1109/JIOT.2020.3012617},
  ISSN={2327-4662},
  month={Aug},}@INPROCEEDINGS{7063421,
  author={Ran, Yongyi and Shi, Youkang and Yang, Enzhong and Chen, Shuangwu and Yang, Jian},
  booktitle={2014 IEEE Globecom Workshops (GC Wkshps)}, 
  title={Dynamic resource allocation for video transcoding with QoS guaranteeing in cloud-based DASH system}, 
  year={2014},
  volume={},
  number={},
  pages={144-149},
  abstract={Due to diverse network conditions and heterogeneous devices, there may be various video demands with different video qualities and formats from the client side. Compared to keeping all necessary copies for the same video, video transcoding in real-time should be an essential solution. The complex nature of video transcoding enables cloud computing to be uniquely suitable for dynamically providing transcoding resource. However, due to the fluctuation and uncertainty of the future transcoding demand, it is still a challenge to dynamically determine the optimal resource allocation to save cost while guaranteeing the Quality of Service (QoS). Overload may result in the transcoding jitter and increase the lateness which directly affects video freezes while over-provisioning naturally increases the cost. To address this problem, in this paper, by defining the transcoding jitter probability as a metric of QoS, we proposed a dynamic resource allocation algorithm based on the large deviation principle, which is capable of proactive calculating the optimal number of transcoding nodes for the upcoming transcoding demand subject to the transcoding jitter probability below a desired threshold. Finally, the experiments are performed on a cloud-based prototype system to show the attainable performance of the proposed resource allocation algorithm and verify that the proposed algorithm can make a good tradeoff between cost saving and QoS guaranteeing.},
  keywords={},
  doi={10.1109/GLOCOMW.2014.7063421},
  ISSN={2166-0077},
  month={Dec},}@INPROCEEDINGS{7027516,
  author={Keller, Matthias and Robbert, Christoph and Karl, Holger},
  booktitle={2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing}, 
  title={Template Embedding: Using Application Architecture to Allocate Resources in Distributed Clouds}, 
  year={2014},
  volume={},
  number={},
  pages={387-395},
  abstract={In distributed cloud computing, application deployment across multiple sites can improve quality of service. Recent research developed algorithms to find optimal locations for virtual machines. However, those algorithms assume to have either single-tier applications or a fixed number of virtual machines -- a strong simplification of reality. This paper investigates the placement and scaling of complex application architectures. An application is dynamically scaled to fit both the current demand situation and the currently available infrastructure resources. We compare two approaches: The first one is based on virtual network embedding. The second approach is a novel method called Template Embedding. It is based on a hierarchical 1-allocation hub flow problem and combines application scaling and embedding in one step. Extensive experiments on 43200 network configurations showed that Template Embedding outperforms virtual network embedding in all cases in three metrics: success rate, solution quality, and runtime. This positive result shows that template embedding is a promising approach for distributed cloud resource allocation.},
  keywords={},
  doi={10.1109/UCC.2014.49},
  ISSN={},
  month={Dec},}@ARTICLE{9395576,
  author={Cedillo, Priscila and Insfran, Emilio and Abrahão, Silvia and Vanderdonckt, Jean},
  journal={IEEE Access}, 
  title={Empirical Evaluation of a Method for Monitoring Cloud Services Based on Models at Runtime}, 
  year={2021},
  volume={9},
  number={},
  pages={55898-55919},
  abstract={Cloud computing is being adopted by commercial and governmental organizations driven by the need to reduce the operational cost of their information technology resources and search for a scalable and flexible way to provide and release their software services. In this computing model, the Quality of Services (QoS) is agreed between service providers and their customers through Service Level Agreements (SLA). There is thus a need for systematic approaches with which to assess the quality of cloud services and their compliance with the SLA. In previous work, we introduced a generic method for Monitoring cloud Services using models at RunTime (MoS@RT), which allows the monitoring requirements or the metric operationalizations of these requirements to be changed at runtime without the modification of the underlying infrastructure. In this paper, we present the design of a monitoring infrastructure that supports the proposed method with its instantiation to a specific platform and reports the results of an experiment carried out to evaluate the perceived efficacy of 58 undergraduate students when using the infrastructure to configure the monitoring of cloud services deployed on the Microsoft Azure platform. The results show that the participants perceived MoS@RT to be easy to use, useful, and they also expressed their intention to use the method in the future. Although further experiments must be carried out to strengthen these results, MoS@RT has proved to be a promising monitoring method for cloud services.},
  keywords={},
  doi={10.1109/ACCESS.2021.3071417},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9242580,
  author={Albur, Nageshwar and Handigol, Sonal and Naik, Sonali and Mulla, Mohammed Moin and Narayan, D. G.},
  booktitle={2020 12th International Conference on Computational Intelligence and Communication Networks (CICN)}, 
  title={QoS-aware Flow Management in Software Defined Network}, 
  year={2020},
  volume={},
  number={},
  pages={215-220},
  abstract={Software Defined Networking is a developing pattern in a computer network that authorize a controller to control and keep track of the entire network state of a system. Traditional networks are not compatible for business ventures since they are manually configured (static) and are inflexible. To solve the problems related to traditional network framework, SDN is considered as an effective solution because SDN is dynamic and easily manageable. Quality-of-Service (QoS) is a list of network requirements that is mentioned in Service Level Agreement (SLA) and this requirements has to be satisfied when a packet is being streamed from one node to another node in a network. QoS metrics provide a sophisticated way to prioritise the network traffic over a network to guarantee better performance. QoS assures that the priorities of routing does not change because change-in prioritise may lead to jitter, packet loss and delay. With rapid development in the cloud computing environment for hosting various virtual applications, Quality Of Service (QoS) has to be maintained while delivering the services that were specified in the Software Level Agreement (SLA). Network Traffic Management helps the administrator to reduce the congestion, packet loss, latency, and also ensures smooth network operations with the help of traffic monitoring tools and techniques. The proposed work presents the QoS aware routing using the OpenDayLight controller. To implement the routing algorithm the bandwidth and the delay parameters are considered. These help to manage the resources of the network by prioritizing specific types of packets on the network. Packet switching not only forwards the data packets but also focuses on selecting the optimal path available for routing of these packets based on certain parameters.},
  keywords={},
  doi={10.1109/CICN49253.2020.9242580},
  ISSN={2472-7555},
  month={Sep.},}@INPROCEEDINGS{9284567,
  author={Zhang, Yilei and Zhang, Xiao and Zhang, Peiyun and Luo, Jun},
  booktitle={2020 IEEE International Conference on Services Computing (SCC)}, 
  title={Credible and Online QoS Prediction for Services in Unreliable Cloud Environment}, 
  year={2020},
  volume={},
  number={},
  pages={272-279},
  abstract={With the widespread adoption of cloud computing, Service-Orientated Architecture (SOA) facilitates the deployment of large-scale online applications in many key areas where quality and reliability are critical. In order to ensure the performance of cloud applications, Quality of Service (QoS) is widely used as a key metric to enable QoS-driven service selection, composition, adaption, etc. Since QoS data observed by users is sparse due to technical constraints, previous studies have proposed prediction approaches to solve this problem. However, the dynamic nature of the cloud environment requires timely prediction of time-varying QoS values. In addition, unreliable QoS data from untrustworthy users may significantly affect the prediction accuracy. In this paper, we propose a credible online QoS prediction approach to address these challenges. We evaluate user credibility through a reputation mechanism and employ online learning techniques to provide QoS prediction results at runtime. The proposed approach is evaluated on a large-scale real-world QoS dataset, and the experimental results demonstrate its effectiveness and efficiency in unreliable cloud environment.},
  keywords={},
  doi={10.1109/SCC49832.2020.00043},
  ISSN={2474-2473},
  month={Nov},}@INPROCEEDINGS{7761131,
  author={O'Donncha, Fearghal and Venugopal, Srikumar and James, Scott C. and Ragnoli, Emanuele},
  booktitle={OCEANS 2016 MTS/IEEE Monterey}, 
  title={Deploying and optimizing performance of a 3D hydrodynamic model on cloud}, 
  year={2016},
  volume={},
  number={},
  pages={1-7},
  abstract={Container-based cloud computing, as standardised and popularised by the open-source docker project has many potential opportunities for scientific application in highperformance computing. It promises highly flexible and available compute capabilities via cloud, without the resource overheads of traditional virtual machines. Further, productivity gains can be made by easy repackaging of images with additional developments, automated deployments, and version-control integrations. Nevertheless, the impact of container overhead and overlay network implementation and performance are areas that requires detailed study to allow for well-defined quality of service for typical HPC applications. This papers presents details on deploying the Environmental Fluid Dynamics Code (EFDC) on a container-based cloud environment. Results are compared to a bare metal deployment. Application-specific benchmarking tests are complemented by detailed network tests that evaluate isolated MPI communication protocols both at intra-node and inter-node level with varying degrees of self-contention. Cloud-based simulations report significant performance loss in mean run-times. A containerised environment increases simulation time by up to 50%. More detailed analysis demonstrates that much of this performance penalty is a result of large variance in MPI communciation times. This manifests as simulation runtime variance on container cloud that hinders both simulation run-time and collection of well-defined quality-of-service metrics.},
  keywords={},
  doi={10.1109/OCEANS.2016.7761131},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8390400,
  author={Silva, Helber and Barbalho, Felipe and Neto, Augusto},
  booktitle={2018 International Conference on Computing, Networking and Communications (ICNC)}, 
  title={Cross-layer Multiuser Session Control for Improved SDN Cloud Communications}, 
  year={2018},
  volume={},
  number={},
  pages={377-382},
  abstract={The integration of Cloud Computing and Internet of Things (IoT) is foreseen as an enabler to suit a plethora of novel latency critical applications (e.g, e-health, intelligent transportation, safety, energy, smart cities, and many others). These applications require multimedia (mainly video) flows to be handled by the underlying network in an efficient and scalable way, as they expect to consume a massive data produced by billions of things. In view of this, we propose a dynamic multiuser session control plane which leverages 5G's support of Software-Defined Networking (SDN) substrate to advance beyond todays limited, per-flow IP-based communication systems. We handle such limitations by proposing CLASSICO, a Cross-LAyer Sdn SessIon COntrol architecture that exploits SDN to offload the flow streaming computation operations from the IoT cloud platform to the network edge, affording high timeliness and scalability for the IoT-cloudified system. CLASSICO dynamically builds Application Layer multiuser data sessions and maps them into enhanced group-enabled data paths featuring SDN replication at branching nodes. We applied our solution to multimedia-alike use case, and results show that CLASSICO outperforms typical SDN-enabled IoT systems in terms to Quality of Service (QoS) and Quality of Experience (QoE) video metrics.},
  keywords={},
  doi={10.1109/ICCNC.2018.8390400},
  ISSN={},
  month={March},}@INPROCEEDINGS{7847681,
  author={Pendlebury, John and Emeakaroha, Vincent C. and O'Shea, David and Cafferkey, Neil and Morrison, John P. and Lynn, Theo},
  booktitle={2016 2nd International Conference on Cloud Computing Technologies and Applications (CloudTech)}, 
  title={SOMBA - automated anomaly detection for Cloud quality of service}, 
  year={2016},
  volume={},
  number={},
  pages={71-79},
  abstract={Cloud computing has transformed the standard model of service provisioning, allowing the delivery of on-demand services over the Internet. With its inherent requirements for elastic scalability and a pay-as-you-go pricing model, an additional level of complexity is added to its Quality of Service (QoS) management. This has made service provisioning more prone to performance anomalies due to the large-scale and evolving nature of Clouds. Existing methods for anomaly detection based on QoS monitoring in the Cloud rely on probabilistic methods, which are not computationally easy and are often valid for very short times before system dynamics change. We posit that more minimalistic approaches including automated techniques are needed for effective anomaly detection to support QoS enforcement in Clouds. In this paper, we present an automated anomaly detection scheme that recognises and adapts to changes in Clouds for efficient multi-metric performance anomaly detection to guarantee service quality. It includes a monitoring tool for collating performance data in real time for analysis and an anomaly detection technique based on an unsupervised machine learning strategy. Based on a Cloud service provisioning use case scenario, we evaluate our anomaly detection technique and compare it against two statistical anomaly detection approaches to demonstrate its efficiency.},
  keywords={},
  doi={10.1109/CloudTech.2016.7847681},
  ISSN={},
  month={May},}@INPROCEEDINGS{9454002,
  author={Estrela, Vania V. and Andreopoulos, Nikolaos and Sroufer, Robert and de Jesus, Maria A. and Mamani, Wilma Dora Huacasi and Peixoto, Aruquia},
  booktitle={2021 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Transmedia Ecosystems, Quality of Experience and Quality of Service in Fog Computing for Comfortable Learning}, 
  year={2021},
  volume={},
  number={},
  pages={1003-1009},
  abstract={This paper looks at the concepts of Quality of Service (QoS) and Quality of Experience (QoE) for the valuation of Transmedia Ecosystems (TEs) services in fog networking. Fog computing (FC) has delivered new services that cloud computing (CC) cannot make available, particularly those calling for QoE warranties. The suggested model is advantageous in an FC that comprises cloud-like services to sustain users with low latency response necessities. This TE model for QoE/QoS relies on objective and subjective QoE metrics. These assessment mechanisms will capture evidence automatically employing agent technology with user feedback. This proposed structure observes, investigates, yields reports and policy alterations without administrators' intervention.},
  keywords={},
  doi={10.1109/EDUCON46332.2021.9454002},
  ISSN={2165-9567},
  month={April},}@ARTICLE{7018938,
  author={Lu, Yao and Liu, Yao and Dey, Sujit},
  journal={IEEE Journal of Selected Topics in Signal Processing}, 
  title={Cloud Mobile 3D Display Gaming User Experience Modeling and Optimization by Asymmetric Graphics Rendering}, 
  year={2015},
  volume={9},
  number={3},
  pages={517-532},
  abstract={With the arrival of auto-stereoscopic 3D displays for mobile devices, and emergence of more 3D content, there is much anticipation for 3D mobile multimedia experiences, including 3D display gaming. Simultaneously, with the emergence of cloud computing, more mobile applications are being developed to take advantage of the elastic cloud resources. In this paper, we explore the possibility of developing Cloud Mobile 3D Display Gaming, where the 3D video rendering and encoding is performed on cloud servers, with the resulting 3D video streamed over wireless networks to mobile devices with 3D displays for a true 3D mobile gaming experience. However, with the significantly higher bitrate requirement for 3D video, ensuring user experience may be a challenge, both in terms of 3D video quality and network delay (response time), considering the bandwidth constraints and fluctuations of wireless networks. In this paper, we propose a new asymmetric graphics rendering approach which can significantly reduce the video encoding bitrate needed for a certain video quality, thereby making it easier to transmit the video over wireless network. However, since asymmetric graphics rendering may also impair the graphics quality, we need to be able to understand and measure its impact. We conduct subjective tests to study and model the impairments due to asymmetric graphics rendering and network delay, thereby developing a user experience model for cloud based mobile 3D display gaming. By conducting subsequent subjective tests, we prove the correctness of the impairment functions and the resulting user experience model. Furthermore, given any network condition, we propose to solve the problem of selecting the optimal graphics rendering factors for the left and right views so as to maximize user experience of cloud mobile 3D display gaming. In order to solve this problem, we first develop a model to estimate the resulting video bitrate of the rendered 3D video when certain graphics rendering factors are used. Next, we derive a model to predict the delay given the available network bandwidth and the video bitrate of the rendered 3D video. We use the above two models together with a branch and bound algorithm to solve the optimization problem and determine the optimal values for the left and right view rendering factors. Experiments conducted using real 4G-LTE network profiles on commercial cloud service demonstrate the feasibility of significant improvement in user experience when the proposed optimization algorithm is used to dynamically select optimal rendering factors according to changing network conditions.},
  keywords={},
  doi={10.1109/JSTSP.2015.2396475},
  ISSN={1941-0484},
  month={April},}@INPROCEEDINGS{8230340,
  author={Laghari, Asif Ali and He, Hui and Shafiq, Muhammad and Khan, Asiya},
  booktitle={2017 IEEE 9th International Conference on Communication Software and Networks (ICCSN)}, 
  title={Impact of storage of mobile on quality of experience (QoE) at user level accessing cloud}, 
  year={2017},
  volume={},
  number={},
  pages={1402-1409},
  abstract={Quality of Experience (QoE) is referred as level of user's satisfaction, enjoyment, learning and evaluation about the services or products. Recently quality of experience is used for improvement in product development life cycle after getting feedback from end users and service providers also use QoE to measure quality of services (QoS) of their services. Cloud computing provides services such as storage, web hosting, operating system environment, application development platform and CPU resources pay per use. End users are accessing cloud services via mobile apps, but enormous amount of temporary/cache data is generated by apps, so internal storage of mobile devices are filled quickly. Mobile device without any space in internal storage has huge impact on the performance when accessing the cloud services, which degrade the QoE of end users for particular cloud app and services. This paper presents the results of experiments conducted using two mobile devices HTC and Samsung to analyze the impact on end user's QoE during accessing cloud, when internal storage of HTC mobile device is filled and Samsung having 10 GB free space. Finally, on the basis of experimental results future changes in cloud apps are suggested for service provider to improve end user's QoE.},
  keywords={},
  doi={10.1109/ICCSN.2017.8230340},
  ISSN={2472-8489},
  month={May},}@INPROCEEDINGS{9415574,
  author={Younis, Ayman and Qiu, Brian and Pompili, Dario},
  booktitle={2021 16th Annual Conference on Wireless On-demand Network Systems and Services Conference (WONS)}, 
  title={QLRan: Latency-Quality Tradeoffs and Task Offloading in Multi-node Next Generation RANs}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  abstract={Next-Generation Radio Access Network (NG-RAN) is an emerging paradigm that provides flexible distribution of cloud computing and radio capabilities at the edge of the wireless Radio Access Points (RAPs). Computation at the edge bridges the gap for roaming end users, enabling access to rich services and applications. In this paper, we propose a multi-edge node task offloading system, i.e., QLRan, a novel optimization solution for latency and quality tradeoff task allocation in NG-RANs. Considering constraints on service latency, quality loss, and edge capacity, the problem of joint task offloading, latency, and Quality Loss of Result (QLR) is formulated in order to minimize the User Equipment (UEs) task offloading utility, which is measured by a weighted sum of reductions in task completion time and QLR cost. The QLRan optimization problem is proved as a Mixed Integer Nonlinear Program (MINLP) problem, which is a NP-hard problem. To efficiently solve the QLRan optimization problem, we utilize Linear Programming (LP)-based approach that can be later solved by using convex optimization techniques. Additionally, a programmable NG-RAN testbed is presented where the Central Unit (CU), Distributed Unit (DU), and UE are virtualized using the OpenAirInterface (OAI) software platform to characterize the performance in terms of data input, memory usage, and average processing time with respect to QLR levels. Simulation results show that our algorithm performs significantly improves the network latency over different conflgurations.},
  keywords={},
  doi={10.23919/WONS51326.2021.9415574},
  ISSN={},
  month={March},}@INPROCEEDINGS{8545546,
  author={Štofová, Lenka and Szaryszova, Petra and Bosák, Martin and Tarča, Alexander and Hajduová, Zuzana},
  booktitle={2018 XIV International Scientific-Technical Conference on Actual Problems of Electronics Instrument Engineering (APEIE)}, 
  title={Ambient Intelligence for Increasing Innovation Performance of Enterprises}, 
  year={2018},
  volume={},
  number={},
  pages={452-458},
  abstract={The new development of the changing global environment brings to the attention of ideas in the form of trends that show the future environment very differently from the current state. Technical experts are discussing the growing presence of internet of things and technologies, the involvement of all devices, and the prediction of how to create ambient intelligence. This type of intelligence refers to an electronic environment that is sensitive and responsive to the presence of users. Within these ambient systems, we can identify what the user needs and at the same time obtain it without asking for it. Ambient intelligence is a combination of neural networking, smart technologies, cloud computing, big data, websites, bearers, and user interface to services that can automate processes and make recommendations to improve the quality of users' lives. On a wider scale, there are modern high-tech possibilities to closely monitor the impact on the quality and safety of the current market environment by ambient intelligence and sensory management solutions. The aim of the paper is to highlight the selected trends of ambient intelligence system applications as an innovative paradigm to support smart innovation that will further enhance the quality of the automotive industry's technological solution in Slovak republic with advancing developments inspired by other successful companies' results acting in this sector. The reliability of their most important measures were obtained by correlation analysis and multiple linear regression.},
  keywords={},
  doi={10.1109/APEIE.2018.8545546},
  ISSN={2473-8573},
  month={Oct},}@INPROCEEDINGS{6785362,
  author={Yao Lu and Liu, Yao and Dey, Sujit},
  booktitle={2014 International Conference on Computing, Networking and Communications (ICNC)}, 
  title={Enhancing Cloud Mobile 3D display gaming user experience by asymmetric graphics rendering}, 
  year={2014},
  volume={},
  number={},
  pages={368-374},
  abstract={With the arrival of auto-stereoscopic 3D displays for mobile devices, and emergence of more 3D content, there is much anticipation for 3D mobile multimedia experiences, including 3D display gaming. Simultaneously, with the emergence of cloud computing, more mobile applications are being developed to take advantage of the elastic cloud resources. In this paper, we explore the possibility of developing Cloud-based 3D Mobile Gaming, where the 3D video rendering and encoding is performed on cloud servers, with the resulting 3D video streamed over wireless networks to mobile devices with 3D displays for a true 3D mobile gaming experience. However, with the significantly higher bit rate requirement for 3D video, ensuring user experience may be a challenge, both in terms of 3D video quality and network delay (response time), considering the bandwidth constraints and fluctuations of wireless networks. In this paper, we propose a new asymmetric graphics rendering approach which can significantly reduce the video encoding bit rate needed for a certain video quality, thereby making it easier to transmit the video over wireless network. However, since asymmetric rendering may also impair the graphics quality, we need to be able to understand and measure its impact. We conduct subjective tests to study and model the impairments due to asymmetric rendering and network delay, thereby developing a user experience model for cloud based mobile 3D display gaming. By conducting subsequent subjective tests, we prove the correctness of the impairment functions and the resulting user experience model. We also conduct experiments using real 4G-LTE network profile. Experimental results show that by making use of the user experience model, it is possible to set appropriate graphics rendering parameters according to network constraints, such that the user experience can be maintained to a high level.},
  keywords={},
  doi={10.1109/ICCNC.2014.6785362},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{8053360,
  author={Fang, Dongfeng and Ye, Feng and Qian, Yi and Sharif, Hamid},
  booktitle={2017 IEEE International Conference on Electro Information Technology (EIT)}, 
  title={An efficient incentive mechanism for cloud-based mobile sensor network}, 
  year={2017},
  volume={},
  number={},
  pages={229-234},
  abstract={Mobile sensor networks (MSNs) enable extensive applications of data collection, such as accident report in transportation and health prediction in public health. Incentive mechanism (IM) is applied for sensing user (SU) recruitment. However, the IM used in traditional MSN is not efficient due to limited information of SU used for recruitment. With the development of cloud computing technology, cloud-based MSN is the trend to use more information of SUs for IM design to improve its efficiency. In this paper, a novel cloud-based MSN model is presented. Three parties are considered, including data request party, cloud-based platform and SUs. A data quality model is proposed to measure the credit level of SUs. In addition, with consideration of social connections of SUs, a SU recruitment strategy is presented. SUs are divided into first and second degrees based on how they join the sensing task. The utility functions of first degree SUs and cloud-based platform are presented, respectively. At last, an efficient IM is proposed by formulating a Stackelberg game. The performance of the proposed IM on data quality and SU recruitment time comparing with other method are presented and discussed. The simulation results illustrate that the proposed IM ensures data quality for data request party and recruits SUs more efficiently.},
  keywords={},
  doi={10.1109/EIT.2017.8053360},
  ISSN={2154-0373},
  month={May},}@INPROCEEDINGS{7396225,
  author={Heidari, Parisa and Boucheneb, Hanifa and Shami, Abdallah},
  booktitle={2015 IEEE 7th International Conference on Cloud Computing Technology and Science (CloudCom)}, 
  title={A Formal Approach for QoS Assurance in the Cloud}, 
  year={2015},
  volume={},
  number={},
  pages={629-634},
  abstract={Cloud computing is an attractive business model offering cost-efficiency and business agility. Recently, the trend is that small and large businesses are moving their services to cloud environments. The quality of service is always negotiated between the cloud users and the cloud providers and documented in the service level agreement (SLA). Yet assuring -- or even measuring -- the quality of the provided service can be challenging. This paper proposes a formal approach for quantifying the quality of service in the cloud systems as promised in the SLA. The proposed approach uses controller synthesis to find a system configuration that meets the SLA requirement. The formal approach suggested in this paper is based on, but not limited to, %the controller synthesis of Time Petri Nets (TPN). As a case study, we focus on service availability as a key performance indicator in the SLA and for a sample set of resources providing a service, we determine the system configuration satisfying the SLA.},
  keywords={},
  doi={10.1109/CloudCom.2015.36},
  ISSN={},
  month={Nov},}@ARTICLE{7807337,
  author={Singh, Sukhpal and Chana, Inderveer and Buyya, Rajkumar},
  journal={IEEE Transactions on Cloud Computing}, 
  title={STAR: SLA-aware Autonomic Management of Cloud Resources}, 
  year={2020},
  volume={8},
  number={4},
  pages={1040-1053},
  abstract={Cloud computing has recently emerged as an important service to manage applications efficiently over the Internet. Various cloud providers offer pay per use cloud services that requires Quality of Service (QoS) management to efficiently monitor and measure the delivered services through Internet of Things (IoT) and thus needs to follow Service Level Agreements (SLAs). However, providing dedicated cloud services that ensure user's dynamic QoS requirements by avoiding SLA violations is a big challenge in cloud computing. As dynamism, heterogeneity and complexity of cloud environment is increasing rapidly, it makes cloud systems insecure and unmanageable. To overcome these problems, cloud systems require self-management of services. Therefore, there is a need to develop a resource management technique that automatically manages QoS requirements of cloud users thus helping the cloud providers in achieving the SLAs and avoiding SLA violations. In this paper, we present SLA-aware autonomic resource management technique called STAR which mainly focuses on reducing SLA violation rate for the efficient delivery of cloud services. The performance of the proposed technique has been evaluated through cloud environment. The experimental results demonstrate that STAR is efficient in reducing SLA violation rate and in optimizing other QoS parameters which effect efficient cloud service delivery.},
  keywords={},
  doi={10.1109/TCC.2017.2648788},
  ISSN={2168-7161},
  month={Oct},}@ARTICLE{7852434,
  author={Mei, Jing and Li, Kenli and Li, Keqin},
  journal={IEEE Transactions on Sustainable Computing}, 
  title={Customer-Satisfaction-Aware Optimal Multiserver Configuration for Profit Maximization in Cloud Computing}, 
  year={2017},
  volume={2},
  number={1},
  pages={17-29},
  abstract={Along with the development of cloud computing, an increasing number of enterprises start to adopt cloud service, which promotes the emergence of many cloud service providers. For cloud service providers, how to configure their cloud service platforms to obtain the maximum profit becomes increasingly the focus that they pay attention to. In this paper, we take customer satisfaction into consideration to address this problem. Customer satisfaction affects the profit of cloud service providers in two ways. On one hand, the cloud configuration affects the quality of service which is an important factor affecting customer satisfaction. On the other hand, the customer satisfaction affects the request arrival rate of a cloud service provider. However, few existing works take customer satisfaction into consideration in solving profit maximization problem, or the existing works considering customer satisfaction do not give a proper formalized definition for it. Hence, we first refer to the definition of customer satisfaction in economics and develop a formula for measuring customer satisfaction in cloud computing. And then, an analysis is given in detail on how the customer satisfaction affects the profit. Lastly, taking into consideration customer satisfaction, service-level agreement, renting price, energy consumption, and so forth, a profit maximization problem is formulated and solved to get the optimal configuration such that the profit is maximized.},
  keywords={},
  doi={10.1109/TSUSC.2017.2667706},
  ISSN={2377-3782},
  month={Jan},}@ARTICLE{8412190,
  author={El Kassabi, Hadeel T. and Serhani, Mohamed Adel and Dssouli, Rachida and Benatallah, Boualem},
  journal={IEEE Access}, 
  title={A Multi-Dimensional Trust Model for Processing Big Data Over Competing Clouds}, 
  year={2018},
  volume={6},
  number={},
  pages={39989-40007},
  abstract={Cloud computing has emerged as a powerful paradigm for delivering data-intensive services over the Internet. Cloud computing has enabled the implementation and success of big data, a recent phenomenon handling huge data being generated from different sources. Competing clouds have made it challenging to select a cloud provider that guarantees quality of cloud service (QoCS). Also, cloud providers' claims of guaranteeing QoCS are exaggerated for marketing purposes; hence, they cannot often be trusted. Therefore, a comprehensive trust model is necessary to evaluate the QoCS prior to making any selection decision. In this paper, we propose a multi-dimensional trust model for big data workflow processing over different clouds. It evaluates the trustworthiness of cloud providers based on: the most up-to-date cloud resource capabilities, the reputation evidence measured by neighboring users, and a recorded personal history of experiences with the cloud provider. The ultimate goal is to ensure an efficient selection of trustworthiness cloud provider who eventually will guarantee high QoCS and fulfills key big data workflow requirements. Various experiments were conducted to validate our proposed model. The results show that our model captures the different components of trust, ensures high QoCS, and effectively adapts to the dynamic nature of the cloud.},
  keywords={},
  doi={10.1109/ACCESS.2018.2856623},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9148980,
  author={Ma, Kun and Bagula, Antoine and Ajayi, Olasupo and Nyirenda, Clement},
  booktitle={ICC 2020 - 2020 IEEE International Conference on Communications (ICC)}, 
  title={Aiming at QoS: A Modified DE Algorithm for Task Allocation in Cloud Computing}, 
  year={2020},
  volume={},
  number={},
  pages={1-7},
  abstract={The Cloud computing system is characterized by large scale servers being utilized by an even larger number of users. It is a system where there is the need to frequently and efficiently schedule and manage different application tasks, with varied service requirements. One of the challenges of Cloud computing is managing the quality of service (QoS) rendered to users, specifically scheduling tasks between users and Cloud resources in a timely manner. Cloud users usually have widely diverse QoS requirements and meeting these simultaneously is also a challenge. In this paper, in order to improve on Cloud resource allocation and specifically to tailor it towards meeting varied QoS requirements of users, we proposed a new algorithm which combines Differential Evolution with the Shapley Value economic mode. This combination allows us measure the contribution of each virtual machine (VM), so as to improve the probability of obtaining a better tasks-to-resource allocation thereby improving user satisfaction. From results of conducted experiments, when compared with the traditional DE (Differential Evolution) algorithm and the conventional task-VM binding policy in CloudSim, both for allocations where special QoS requirements are required and in instances of multiple QoS requirements; the modified Shapley value based DE algorithm (SVBDA) shows significant improvement.},
  keywords={},
  doi={10.1109/ICC40277.2020.9148980},
  ISSN={1938-1883},
  month={June},}@INPROCEEDINGS{9568289,
  author={Weerasinghe, L. D. S. B. and Perera, Indika},
  booktitle={2021 International Research Conference on Smart Computing and Systems Engineering (SCSE)}, 
  title={An exploratory evaluation of replacing ESB with microservices in service-oriented architecture}, 
  year={2021},
  volume={4},
  number={},
  pages={137-144},
  abstract={With the continuous progress in technology during the past few decades, cloud computing has become a fast-growing technology in the world, making computerized systems widespread. The emergence of Cloud Computing has evolved towards microservice concepts, which are highly demanded by corporates for enterprise application level. Most enterprise applications have moved away from traditional unified models of software programs like monolithic architecture and traditional SOA architecture to microservice architecture to ensure better scalability, lesser investment in hardware, and high performance. The monolithic architecture is designed in a manner that all the components and the modules are packed together and deployed on a single binary. However, in the microservice architecture, components are developed as small services so that horizontally and vertically scaling is made easier in comparison to monolith or SOA architecture. SOA and monolithic architecture are at a disadvantage compared to Microservice architecture, as they require colossal hardware specifications to scale the software. In general terms, the system performance of these architectures can be measured considering different aspects such as system capacity, throughput, and latency. This research focuses on how scalability and performance software quality attributes behave when converting the SOA system to microservice architecture. Experimental results have shown that microservice architecture can bring more scalability with a minimum cost generation. Nevertheless, specific gaps in performance are identified in the perspective of the final user experiences due to the interservice communication in the microservice architecture in a distributed environment.},
  keywords={},
  doi={10.1109/SCSE53661.2021.9568289},
  ISSN={2613-8662},
  month={Sep.},}@INPROCEEDINGS{7904283,
  author={Bruschi, Gustavo C. and Spolon, Roberta and Pauro, Leandro L. and Lobato, Renata S. and Manacero, Aleardo and Cavenaghi, Marcos A.},
  booktitle={2016 15th International Symposium on Parallel and Distributed Computing (ISPDC)}, 
  title={StackAct: Performance Evaluation in an IaaS Cloud Multilayer}, 
  year={2016},
  volume={},
  number={},
  pages={149-156},
  abstract={Cloud Computing has become synonymous of quality, efficiency, and return of investment in Information Technology, creating new challenges for processing and data integrations. This paper presents the StackAct, a mechanism that allows performing monitoring and obtaining data on the consumption of computing resources of a solution in three layers using orchestrator IaaS Apache CloudStack, XenServer hypervisor and data storage on the NAS OpenFiler system. Performance tests were conducted using three different instances profile in a private cloud computing, allowing measuring CPU consumption, I/O disk and memory in three layers with different service offerings. The tests resulted in a comparison between the layers, it is possible to note the high consumption of disk in the data storage layer, in particular I/O data recording and the high memory consumption on the hypervisor layer, which is justified by the hypervisor itself to allocation of VMs being created and used in the process.},
  keywords={},
  doi={10.1109/ISPDC.2016.27},
  ISSN={},
  month={July},}@INPROCEEDINGS{9463991,
  author={Toka, Laszlo and Dobreff, Gergely and Haja, David and Szalay, Mark},
  booktitle={2021 IFIP/IEEE International Symposium on Integrated Network Management (IM)}, 
  title={Predicting cloud-native application failures based on monitoring data of cloud infrastructure}, 
  year={2021},
  volume={},
  number={},
  pages={842-847},
  abstract={The quality of service provided by cloud-deployed online applications is often affected by faults in the underlying cloud platform and infrastructure. In order to discover the cause and effect at application failures, a cloud monitoring system must be in place. The sheer amount of the produced monitoring data calls for smart and automatic handling in order to find the patterns that can be used for fault management. In this paper we present an open source, cloud-native, lightweight cloud monitoring system, and a data analytics pipeline that efficiently processes the gathered data and is able to discover useful inference between infrastructure-, and application-level metrics. We apply time series clustering steps within the pipeline to compress the collected data for fast and lightweight data mining. We show the capabilities of our proposed system in a reactive and a proactive use case. The results prove that the proposed system brings precious insights for root-cause analysis and proactive fault management frameworks of cloud applications.},
  keywords={},
  doi={},
  ISSN={1573-0077},
  month={May},}@INPROCEEDINGS{7565173,
  author={Mushtaq, M. Sajid and Fowler, Scott and Augustin, Brice and Mellouk, Abdelhamid},
  booktitle={2016 IEEE Wireless Communications and Networking Conference}, 
  title={QoE in 5G cloud networks using multimedia services}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={The 4G standard Long Term Evolution-Advanced (LTE-A) has been deployed in many countries. Now, technology is evolving towards the 5G standard since it is expecting to start its service in 2020. The 5G cellular networks will mainly contain in cloud computing and primarily Quality of Service (QoS) parameters (e.g. delay, loss rate, etc.) influence the cloud network performance. The impact of user perceived Quality of Experience (QoE) using multimedia services, and application significantly relies on the QoS parameters. The key challenge of 5G technology is to reduce the delay less than one millisecond. In this paper, we have described a method that minimizes the overall network delay for multimedia services; which are constant bit rate (VoIP) and variable bit rate (video) traffic model. We also proposed a method that measures the user's QoE for video streaming traffic using the network QoS parameters, i.e. delay and packet loss rate. The performance of proposed QoE method is compared with QoV method, and our proposed QoE method performs best by carefully handle the impact of QoS parameters. The results show that our described method successfully reduces the overall network delays, which result to maximize the user's QoE.},
  keywords={},
  doi={10.1109/WCNC.2016.7565173},
  ISSN={1558-2612},
  month={April},}@ARTICLE{7445250,
  author={Shi, Lei and Shi, Yi and Wei, Xing and Ding, Xu and Wei, Zhenchun},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Cost Minimization Algorithms for Data Center Management}, 
  year={2017},
  volume={28},
  number={1},
  pages={60-71},
  abstract={Due to the increasing usage of cloud computing applications, it is important to minimize energy cost consumed by a data center, and simultaneously, to improve quality of service via data center management. One promising approach is to switch some servers in a data center to the idle mode for saving energy while to keep a suitable number of servers in the active mode for providing timely service. In this paper, we design both online and offline algorithms for this problem. For the offline algorithm, we formulate data center management as a cost minimization problem by considering energy cost, delay cost (to measure service quality), and switching cost (to change servers's active/idle mode). Then, we analyze certain properties of an optimal solution which lead to a dynamic programming based algorithm. Moreover, by revising the solution procedure, we successfully eliminate the recursive procedure and achieve an optimal offline algorithm with a polynomial complexity. For the online algorithm, We design it by considering the worst case scenario for future workload. In simulation, we show this online algorithm can always provide near-optimal solutions.},
  keywords={},
  doi={10.1109/TPDS.2016.2549016},
  ISSN={1558-2183},
  month={Jan},}@ARTICLE{9144208,
  author={Vatalaro, Francesco and Ciccarella, Gianfranco},
  journal={IEEE Access}, 
  title={A Network Paradigm for Very High Capacity Mobile and Fixed Telecommunications Ecosystem Sustainable Evolution}, 
  year={2020},
  volume={8},
  number={},
  pages={135075-135090},
  abstract={The main objective for Very High Capacity (VHC) fixed and mobile networks is improving end-user Quality of Experience (QoE), i.e., meeting the Key Performance Indicators (KPIs) - throughput, download time, round trip time, and video delay - required by the applications. KPIs depend on the end-to-end connection between the server and the end-user device. Not only Telco operators must provide the quality needed for the different applications, but also they must address economic sustainability objectives for VHC networks. Today, both goals are often not met, mainly due to the push to increase the access networks bitrate without considering the end-to-end applications KPIs. This paper's main contribution deals with the definition of a VHC network deployment framework able to address performance and cost issues. We show that three are the interventions on which it is necessary to focus: i) the reduction of bit-rate through video compression, ii) the reduction of packet loss rate through artificial intelligence algorithms for access lines stabilization, and iii) the reduction of latency (i.e., the round-trip time) with edge-cloud computing and content delivery platforms, including transparent caching. The concerted and properly phased action of these three measures can allow a Telco to get out of the Ultra Broad Band access network “trap”as defined in the paper. We propose to work on the end-to-end optimization of the bandwidth utilization ratio (i.e., the ratio between the throughput and the bit-rate that any application can use). It leads to better performance experienced by the end-user, enables new business models and revenue streams, and provides a sustainable cost for the Telco operators. To make such a perspective more precise, the case of MoVAR (Mobile Virtual and Augmented Reality), one of the most challenging future services, is finally described.},
  keywords={},
  doi={10.1109/ACCESS.2020.3010348},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8766409,
  author={Brunschwiler, T. and Weiss, J. and Paredes, S. and Sridhar, A. and Pluntke, U. and Chau, S. Mai and Gerke, S. and Barroso, J. and Loertscher, E. and Temiz, Y. and Ruch, P. and Michel, B. and Zafar, S. and van Kessel, T.},
  booktitle={2019 Global IoT Summit (GIoTS)}, 
  title={Internet of the Body - Wearable Monitoring and Coaching}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={Wearables that acquire relevant vital and contextual parameters improve work safety as well as quality of life of elderly citizens or patients with chronic diseases. A scalable architecture connects wearables via a hub to the cloud and combines edge with cloud computing to provide optimal user interaction and allow analytics on multi-stream data. The functionality was expanded to enable demonstrations of physiological and psychological stress classification in firemen and mobile health interventions in patients with lung diseases. Following an initial table-top edge demonstrator a hemi-spherical display improves emotional contact to users. A first use case tested an integrated acquisition and inference system that was trained to differentiate physical and emotional stress. The system measured stress in firemen during training in a cage maze and in hot training locations and provided functions to acquire expert labels. A second use case focused on mobile-health intervention for patients suffering from Chronic-Obstructive-Pulmonary-Disease (COPD), to improve their quality-of-life. Patient-physician conversations are extended through a communication channel and a virtual assistant provides disease related information, reminders, and alerts.},
  keywords={},
  doi={10.1109/GIOTS.2019.8766409},
  ISSN={},
  month={June},}@INPROCEEDINGS{8718133,
  author={Wong, Tong-Sheng and Chan, Gaik-Yee and Chua, Fang-Fang},
  booktitle={2019 International Conference on Information Networking (ICOIN)}, 
  title={Adaptive Preventive and Remedial Measures in Resolving Cloud Quality of Service Violation}, 
  year={2019},
  volume={},
  number={},
  pages={473-479},
  abstract={Cloud Computing acts as a paradigm to support on-demand computing services, from applications to storage, manage and processing capabilities. One of the major challenges in delivering and accessing cloud applications is the management of Quality of Service (QoS) and cloud service providers are mandated to adhere to Service Level Agreement (SLA) in providing quality cloud services to the users. The agreement matching is important for both parties to ensure satisfaction and expectation level. This proposed work aims to resolve cloud QoS violation with the implementation of adaptive preventive and remedial mechanisms. Preventive measure such as horizontal scaling is used to optimize the performance of a running cloud service in order to prevent the cloud service to downgrade to QoS violation condition. Remedial action on the other hand, is to provide fault tolerance using replication for faulty cloud service to recover from failure incidents or already violation condition. Experimental results have demonstrated the feasibility and effectiveness of applying horizontal scaling in preventing and replication in rectifying cloud QoS violations based on response time and throughput.},
  keywords={},
  doi={10.1109/ICOIN.2019.8718133},
  ISSN={1976-7684},
  month={Jan},}@INPROCEEDINGS{7175787,
  author={Hong Shen and Jinglei Meng and Licheng Yu and Xuefeng Fang and Tianzhou Chen and Hui Yan and Honglun Hou},
  booktitle={2014 IEEE 3rd International Conference on Cloud Computing and Intelligence Systems}, 
  title={A quantitative quality control method of big data in cancer patients using artificial neural network}, 
  year={2014},
  volume={},
  number={},
  pages={499-504},
  abstract={Nonstandard treatments for cancer patients are commonly seen in hospitals of developing countries like China. So it is crucial to standardize the treatments for cancer with technological means in order to supervise the process of treatments. Widespread of electronic health records (EHRs) has generated massive data sets which are far beyond the capability of traditional computing model. Although there are process and measures about quality control, but automatic computerized Quantitative Control (QC) and quantization methods are still lack. In this paper, we propose a quantitative quality control method of radiotherapy and chemotherapy based on artificial neural network to automatically analysis and rate the compliance with standard treatment process. The quantitative QC items are established and the artificial neural network is constructed accordingly. Then the selected cases are evaluated by experts for corresponding QC grades to train the artificial neural network. After that, the trained artificial neural network can be used to grade new cases for their QC score. To meet the high requirement of computation and accommodate massive data sets, we adopt our proposal in the cloud. With massive data distributed on computing nodes in the cloud, computing capability of nodes are dynamically allocated to homogenization and ANN computing, each node work both homogenization medical records and ANN computing according to system load balance resulting the quantitative QC process perform in high parallelism.},
  keywords={},
  doi={10.1109/CCIS.2014.7175787},
  ISSN={2376-595X},
  month={Nov},}@ARTICLE{6473795,
  author={Bruneo, Dario},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={A Stochastic Model to Investigate Data Center Performance and QoS in IaaS Cloud Computing Systems}, 
  year={2014},
  volume={25},
  number={3},
  pages={560-569},
  abstract={Cloud data center management is a key problem due to the numerous and heterogeneous strategies that can be applied, ranging from the VM placement to the federation with other clouds. Performance evaluation of cloud computing infrastructures is required to predict and quantify the cost-benefit of a strategy portfolio and the corresponding quality of service (QoS) experienced by users. Such analyses are not feasible by simulation or on-the-field experimentation, due to the great number of parameters that have to be investigated. In this paper, we present an analytical model, based on stochastic reward nets (SRNs), that is both scalable to model systems composed of thousands of resources and flexible to represent different policies and cloud-specific strategies. Several performance metrics are defined and evaluated to analyze the behavior of a cloud data center: utilization, availability, waiting time, and responsiveness. A resiliency analysis is also provided to take into account load bursts. Finally, a general approach is presented that, starting from the concept of system capacity, can help system managers to opportunely set the data center parameters under different working conditions.},
  keywords={},
  doi={10.1109/TPDS.2013.67},
  ISSN={1558-2183},
  month={March},}@INPROCEEDINGS{8029803,
  author={Mazlami, Genc and Cito, Jürgen and Leitner, Philipp},
  booktitle={2017 IEEE International Conference on Web Services (ICWS)}, 
  title={Extraction of Microservices from Monolithic Software Architectures}, 
  year={2017},
  volume={},
  number={},
  pages={524-531},
  abstract={Driven by developments such as mobile computing, cloud computing infrastructure, DevOps and elastic computing, the microservice architectural style has emerged as a new alternative to the monolithic style for designing large software systems. Monolithic legacy applications in industry undergo a migration to microservice-oriented architectures. A key challenge in this context is the extraction of microservices from existing monolithic code bases. While informal migration patterns and techniques exist, there is a lack of formal models and automated support tools in that area. This paper tackles that challenge by presenting a formal microservice extraction model to allow algorithmic recommendation of microservice candidates in a refactoring and migration scenario. The formal model is implemented in a web-based prototype. A performance evaluation demonstrates that the presented approach provides adequate performance. The recommendation quality is evaluated quantitatively by custom microservice-specific metrics. The results show that the produced microservice candidates lower the average development team size down to half of the original size or lower. Furthermore, the size of recommended microservice conforms with microservice sizing reported by empirical surveys and the domain-specific redundancy among different microservices is kept at a low rate.},
  keywords={},
  doi={10.1109/ICWS.2017.61},
  ISSN={},
  month={June},}@ARTICLE{8306964,
  author={Neghabi, Ali Akbar and Jafari Navimipour, Nima and Hosseinzadeh, Mehdi and Rezaee, Ali},
  journal={IEEE Access}, 
  title={Load Balancing Mechanisms in the Software Defined Networks: A Systematic and Comprehensive Review of the Literature}, 
  year={2018},
  volume={6},
  number={},
  pages={14159-14178},
  abstract={With the expansion of the network and increasing their users, as well as emerging new technologies, such as cloud computing and big data, managing traditional networks is difficult. Therefore, it is necessary to change the traditional network architecture. Lately, to address this issue, a notion named software-defined network (SDN) has been proposed, which makes network management more conformable. Due to limited network resources and to meet the requirements of quality of service, one of the points that must be considered is load balancing issue that serves to distribute data traffic among multiple resources in order to maximize the efficiency and reliability of network resources. Load balancing is established based on the local information of the network in the conventional network. Hence, it is not very precise. However, SDN controllers have a global view of the network and can produce more optimized load balances. Although load balancing mechanisms are important in the SDN, to the best of our knowledge, there exists no precise and systematic review or survey on investigating these issues. Hence, this paper reviews the load balancing mechanisms which have been used in the SDN systematically based on two categories, deterministic and non-deterministic. Also, this paper represents benefits and some weakness regarded of the selected load balancing algorithms and investigates the metrics of their algorithms. In addition, the important challenges of these algorithms have been reviewed, so better load balancing techniques can be applied by the researchers in the future.},
  keywords={},
  doi={10.1109/ACCESS.2018.2805842},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8030623,
  author={Al-Dhuraibi, Yahya and Paraiso, Fawaz and Djarallah, Nabil and Merle, Philippe},
  booktitle={2017 IEEE 10th International Conference on Cloud Computing (CLOUD)}, 
  title={Autonomic Vertical Elasticity of Docker Containers with ELASTICDOCKER}, 
  year={2017},
  volume={},
  number={},
  pages={472-479},
  abstract={Elasticity is the key feature of cloud computing to scale computing resources according to application workloads timely. In the literature as well as in industrial products, much attention was given to the elasticity of virtual machines, but much less to the elasticity of containers. However, containers are the new trend for packaging and deploying microservices-based applications. Moreover, most of approaches focus on horizontal elasticity, fewer works address vertical elasticity. In this paper, we propose ELASTICDOCKER, the first system powering vertical elasticity of Docker containers autonomously. Based on the well-known IBM's autonomic computing MAPE-K principles, ELASTICDOCKER scales up and down both CPU and memory assigned to each container according to the application workload. As vertical elasticity is limited to the host machine capacity, ELASTICDOCKER does container live migration when there is no enough resources on the hosting machine. Our experiments show that ELASTICDOCKER helps to reduce expenses for container customers, make better resource utilization for container providers, and improve Quality of Experience for application end-users. In addition, based on the observed migration performance metrics, the experiments reveal a high efficient live migration technique. As compared to horizontal elasticity, ELASTICDOCKER outperforms Kubernetes elasticity by 37.63%.},
  keywords={},
  doi={10.1109/CLOUD.2017.67},
  ISSN={2159-6190},
  month={June},}@ARTICLE{7045510,
  author={Xia, YunNi and Zhou, MengChu and Luo, Xin and Pang, ShanChen and Zhu, QingSheng},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Stochastic Modeling and Performance Analysis of Migration-Enabled and Error-Prone Clouds}, 
  year={2015},
  volume={11},
  number={2},
  pages={495-504},
  abstract={Cloud computing is a promising paradigm capable of rationalizing the use of computational resources by means of outsourcing and virtualization. Virtualization allows to instantiate virtual machines (VMs) on top of fewer physical systems managed by a VM manager. Performance evaluation of clouds is required to evaluate and quantify the cost-benefit of a strategy portfolio and the quality of service (QoS) experienced by end-users. Such evaluation is not feasible by means of simulation or on-the-field measurement, due to the great scale of parameter spaces that have to be traversed. In this study, we present a stochastic-queuing-network-based approach to performance analysis of migration-enabled clouds in error-prone environment. Several performance metrics are defined and evaluated: utilization, expected task completion time, and task rejection rate under different load conditions and error intensities. To validate the proposed approach, we obtain experimental performance data through a real-world cloud and conduct a confidence-interval analysis. The analysis results suggest the perfect coverage of theoretical performance results by corresponding experimental confidence intervals.},
  keywords={},
  doi={10.1109/TII.2015.2405792},
  ISSN={1941-0050},
  month={April},}@ARTICLE{9046283,
  author={Zhu, Zongwei and Han, Guangjie and Jia, Gangyong and Shu, Lei},
  journal={IEEE Internet of Things Journal}, 
  title={Modified DenseNet for Automatic Fabric Defect Detection With Edge Computing for Minimizing Latency}, 
  year={2020},
  volume={7},
  number={10},
  pages={9623-9636},
  abstract={As an essential step in quality control, fabric defect detection plays an important role in the textile manufacturing industry. The traditional manual detection method is inaccurate and incurs a high cost; as a result, it is gradually being replaced by deep learning algorithms based on cloud computing. However, a high data transmission latency between end devices and the cloud has a significant impact on textile production efficiency. In contrast, edge computing, which provides services near end devices by deploying network, computing and storage facilities at the edge of the Internet, can effectively solve the above-mentioned problem. In this article, we propose a deep-learning-based fabric defect detection method for edge computing scenarios. First, this article modifies the structure of DenseNet to better suit a resource-constrained edge computing scenario. To better assess the proposed model, an optimized cross-entropy loss function is also formulated. Afterward, six feasible expansion schemes are utilized to enhance the data set according to the characteristics of various defects in fabric samples. To balance the distribution of samples, proportions of various defect types are used to determine the number of enhancements. Finally, a fabric defect detection system is established to test the performance of the optimized model used on edge devices in a real-world textile industry scenario. Experimental results demonstrate that compared with the conventional convolutional neural network (CNN), the proposed optimized model attains an average improvement of 18% in the area under the curve (AUC) metric for 11 defects. Data transmission is reduced by approximately 50% and latency is reduced by 32% in the Cambricon 1H8 platform compared with a cloud platform.},
  keywords={},
  doi={10.1109/JIOT.2020.2983050},
  ISSN={2327-4662},
  month={Oct},}@ARTICLE{8976136,
  author={Farid, Mazen and Latip, Rohaya and Hussin, Masnida and Abdul Hamid, Nor Asilah Wati},
  journal={IEEE Access}, 
  title={Scheduling Scientific Workflow Using Multi-Objective Algorithm With Fuzzy Resource Utilization in Multi-Cloud Environment}, 
  year={2020},
  volume={8},
  number={},
  pages={24309-24322},
  abstract={The provision of resources and services for scientific workflow applications using a multi-cloud architecture and a pay-per-use rule has recently gained popularity within the cloud computing research domain. This is because workflow applications are computation intensive. Most of the existing studies on workflow scheduling in the cloud mainly focus on finding an ideal makespan or cost. Nevertheless, there are other important quality of service metrics that are of critical concern in workflow scheduling such as reliability and resource utilization. In this respect, this paper proposes a new multi-objective scheduling algorithm with Fuzzy resource utilization (FR-MOS) for scheduling scientific workflow based on particle swarm optimization (PSO) method. The algorithm minimizes cost and makespan while considering reliability constraint. The coding scheme jointly considers task execution location and data transportation order. Simulation experiments reveal that FR-MOS outperforms the basic MOS over the PSO algorithm.},
  keywords={},
  doi={10.1109/ACCESS.2020.2970475},
  ISSN={2169-3536},
  month={},}@ARTICLE{7010388,
  author={Nesmachnow, Sergio and Iturriaga, Santiago and Dorronsoro, Bernabe},
  journal={IEEE Computational Intelligence Magazine}, 
  title={Efficient Heuristics for Profit Optimization of Virtual Cloud Brokers}, 
  year={2015},
  volume={10},
  number={1},
  pages={33-43},
  abstract={This article introduces a new kind of broker for cloud computing, whose business relies on outsourcing virtual machines (VMs) to its customers. More specifically, the broker owns a number of reserved instances of different VMs from several cloud providers and offers them to its customers in an on-demand basis, at cheaper prices than those of the cloud providers. The essence of the business resides in the large difference in price between on-demand and reserved VMs. We define the Virtual Machine Planning Problem, an optimization problem to maximize the profit of the broker. We also propose a number of efficient smart heuristics (seven two-phase list scheduling heuristics and a reordering local search) to allocate a set of VM requests from customers into the available pre-booked ones, that maximize the broker earnings. We perform experimental evaluation to analyze the profit and quality of service metrics for the resulting planning, including a set of 400 problem instances that account for realistic workloads and scenarios using real data from cloud providers.},
  keywords={},
  doi={10.1109/MCI.2014.2369893},
  ISSN={1556-6048},
  month={Feb},}@ARTICLE{9140398,
  author={Fantacci, Romano and Picano, Benedetta},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={Performance Analysis of a Delay Constrained Data Offloading Scheme in an Integrated Cloud-Fog-Edge Computing System}, 
  year={2020},
  volume={69},
  number={10},
  pages={12004-12014},
  abstract={The recent growth in intensive services and applications demand has triggered the functional integration of cloud computing with edge computing capabilities. One of the main goals is to allow a fast processing to tasks with strict real time constraints in order to lower the task dropping probability due to expiration of the associated deadlines. This paper deals with the performance evaluation and optimization of a three layers cloud-fog-edge computing infrastructure by resorting to the use of queueing theory results. In particular, a Markov queueing system model with reneging is proposed for the cloud subsystem, in order to consider the premature computation requests departure due to their deadline expiration. Furthermore, a computational resources allocation method is proposed with the aim at maximizing the social welfare metric, constrained to specific quality of service requirements. Finally, the proposed queueing theory analysis as well as of the computational resources allocation approach is validated by comparing the obtained analytical predictions with simulation results.},
  keywords={},
  doi={10.1109/TVT.2020.3008926},
  ISSN={1939-9359},
  month={Oct},}@ARTICLE{7042798,
  author={Ayoubi, Sara and Assi, Chadi and Shaban, Khaled and Narayanan, Lata},
  journal={IEEE Transactions on Communications}, 
  title={MINTED: Multicast VIrtual NeTwork Embedding in Cloud Data Centers With Delay Constraints}, 
  year={2015},
  volume={63},
  number={4},
  pages={1291-1305},
  abstract={Network virtualization is regarded as the pillar of cloud computing, enabling the multi-tenancy concept where multiple Virtual Networks (VNs) can cohabit the same substrate network. With network virtualization, the problem of allocating resources to the various tenants, commonly known as the Virtual Network Embedding problem, emerges as a challenge. Its NP-Hard nature has drawn a lot of attention from the research community, many of which however overlooked the type of communication that a given VN may exhibit, assuming that they all exhibit a one-to-one (unicast) communication only. In this paper, we motivate the importance of characterizing the mode of communication in VN requests, and we focus our attention on the problem of embedding VNs with a one-to-many (multicast) communication mode. Throughout this paper, we highlight the unique properties of multicast VNs and its distinct Quality of Service (QoS) requirements, most notably the end-delay and delay-variation constraints for delay-sensitive multicast services. Further, we showcase the limitations of handling a multicast VN as unicast. To this extent, we formally define the VNE problem for Multicast VNs (MVNs) and prove its NP-Hard nature. We propose two novel approach to solve the Multicast VNE (MVNE) problem with end-delay and delay variation constraints: A 3-Step MVNE technique, and a Tabu-Search algorithm. We motivate the intuition behind our proposed embedding techniques, and provide a competitive analysis of our suggested approaches over multiple metrics and against other embedding heuristics.},
  keywords={},
  doi={10.1109/TCOMM.2015.2404440},
  ISSN={1558-0857},
  month={April},}

@INPROCEEDINGS{6903296,
  author={Cao, Fei and Zhu, Michelle M. and Wu, Chase Q.},
  booktitle={2014 IEEE World Congress on Services}, 
  title={Energy-Efficient Resource Management for Scientific Workflows in Clouds}, 
  year={2014},
  volume={},
  number={},
  pages={402-409},
  abstract={The elastic resource provision, non-interfering resource sharing and flexible customized configuration provided by the Cloud infrastructure has shed light on efficient execution of many scientific applications. Due to the increasing deployment of data centers and computer servers around the globe escalated by the higher electricity price, the energy cost on running the computing, communication and cooling together with the amount of CO2 emissions have skyrocketed. In order to maintain sustainable Cloud computing facing with ever-increasing problem complexity and big data size in the next decades, we design and develop energy-aware scientific workflow scheduling algorithm to minimize energy consumption and CO2 emission while still satisfying certain Quality of Service (QoS) such as response time specified in Service Level Agreement (SLA). We also apply Dynamic Voltage and Frequency Scaling (DVFS) and DNS scheme to further reduce energy consumption within acceptable performance bounds. Our multiple-step resource provision and allocation algorithm achieves the response time requirement in the step of forwarding task scheduling and minimizes the VM overhead for reduced energy consumption and higher resource utilization rate in the backward task scheduling step. The effectiveness of our algorithm is evaluated under various performance metrics and experimental scenarios using software adapted from open source CloudSim simulator.},
  keywords={},
  doi={10.1109/SERVICES.2014.76},
  ISSN={2378-3818},
  month={June},}@INPROCEEDINGS{6930517,
  author={Yaqub, Edwin and Yahyapour, Ramin and Wieder, Philipp and Kotsokalis, Constantinos and Lu, Kuan and Jehangiri, Ali Imran},
  booktitle={2014 IEEE International Conference on Services Computing}, 
  title={Optimal Negotiation of Service Level Agreements for Cloud-Based Services through Autonomous Agents}, 
  year={2014},
  volume={},
  number={},
  pages={59-66},
  abstract={Cloud-based services have become a cornerstone of today's IT. The self-service feature inherent in Cloud systems allows customers to play a greater role in service procurement. However, this restricts the value propositions and Service Level Agreements (SLAs) that Cloud providers offer because Quality of Service (QoS) and Non Functional Property (NFP) requirements vary from customer to customer. In feature-rich SLA templates, the contract space gets large, objectives are confidential and preferences over QoS and NFP often conflict between providers and customers. Hence, an SLA-gap exists between the two and contemporary providers bind their offerings to the inflexible take-it-or-leave-it SLAs. In this work, we address this problem by presenting a robust and computationally inexpensive negotiation strategy, using which agents can efficiently create near-optimal SLAs under time constraints. Experimental evaluations validate that our strategy performs at par with state of the art learning and non-learning strategies against a variety of metrics including utility, social welfare, social utility and the Pareto-optimal bids. This enables a dynamic SLA negotiation mechanism on top of our OpenShift (PaaS) based Cloud system designed using Service Oriented Cloud Computing Infrastructure (SOCCI) architecture. Negotiated procurement of services is shown to improve satisfaction of participants and reducing the SLA-gap.},
  keywords={},
  doi={10.1109/SCC.2014.17},
  ISSN={},
  month={June},}@ARTICLE{8641327,
  author={Zhou, Xijia and Li, Kenli and Liu, Chubo and Li, Keqin},
  journal={IEEE Access}, 
  title={An Experience-Based Scheme for Energy-SLA Balance in Cloud Data Centers}, 
  year={2019},
  volume={7},
  number={},
  pages={23500-23513},
  abstract={The proliferation of cloud computing has resulted in the establishment of large-scale data centers containing thousands of computing nodes and consuming enormous amounts of electrical energy. However, the low-cost and high-efficiency slogans are getting louder and louder, and the IT industry is also striving for this pursuit. Therefore, it is vital to minimizing the energy consumption for cloud providers while ensuring the quality of service for cloud users. In this paper, we propose several heuristic strategies to optimize these two metrics based on a two-level management model under a heterogeneous cloud environment. First, to detect whether a physical node is continuously overloaded, we propose an empirical forecast algorithm, which predicts the future state of the host by statistically analyzing the historical utilization data of the host. Second, we propose a weighted priority virtual machine (VM) selection algorithm. For each VM on the overloaded host, we weight several utilization factors and calculate its migration priority. Then, we simulate the proposed approach and compare it with the existing overloaded hosts detection algorithms with different VM selection policies under different workloads.},
  keywords={},
  doi={10.1109/ACCESS.2019.2899101},
  ISSN={2169-3536},
  month={},}@ARTICLE{9178309,
  author={He, Xingqiu and Wang, Sheng},
  journal={IEEE Internet of Things Journal}, 
  title={Peer Offloading in Mobile-Edge Computing With Worst Case Response Time Guarantees}, 
  year={2021},
  volume={8},
  number={4},
  pages={2722-2735},
  abstract={Mobile-edge computing (MEC) is a new paradigm that provides cloud computing services at the edge of networks. To achieve better performance with limited computing resources, peer offloading between cooperative edge servers (e.g., MEC-enabled base stations) has been proposed as an effective technique to handle bursty and spatially imbalanced arrival of computation tasks. While various performance metrics of peer offloading policies have been considered in the literature, the worst case response time, a common quality of service (QoS) requirement in real-time applications, yet receives much less attention. To fill the gap, we formulate the peer offloading problem based on a stochastic arrival model and propose two online algorithms for cases with and without prior knowledge of task arrival rate. Our goal is to maximize the utility function of time-average throughput under constraints of energy consumption and worst case response time. Both theoretical analysis and numerical results show that our algorithms are able to produce close to optimal performance.},
  keywords={},
  doi={10.1109/JIOT.2020.3019492},
  ISSN={2327-4662},
  month={Feb},}@INPROCEEDINGS{8514452,
  author={Alqahtani, Awatif and Li, Yinhao and Patel, Pankesh and Solaiman, Ellis and Ranjan, Rajiv},
  booktitle={2018 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={End-to-End Service Level Agreement Specification for IoT Applications}, 
  year={2018},
  volume={},
  number={},
  pages={926-935},
  abstract={The Internet of Things (IoT) promises to help solve a wide range of issues that relate to our wellbeing within applica¬tion domains that include smart cities, healthcare monitoring, and environmental monitoring. IoT is bringing new wireless sensor use cases by taking advantage of the computing power and flexibility provided by Edge and Cloud Computing. However, the software and hardware resources used within such applications must perform correctly and optimally. Especially in applications where a failure of resources can be critical. Service Level Agreements (SLA) where the performance requirements of such applications are defined, need to be specified in a standard way that reflects the end-to-end nature of IoT application domains, accounting for the Quality of Service (QoS) metrics within every layer including the Edge, Network Gateways, and Cloud. In this paper, we propose a conceptual model that captures the key entities of an SLA and their relationships, as a prior step for end-to-end SLA specification and composition. Service level objective (SLO) terms are also considered to express the QoS constraints. Moreover, we propose a new SLA grammar which considers workflow activities and the multi-layered nature of IoT applications. Accordingly, we develop a tool for SLA specification and composition that can be used as a template to generate SLAs in a machine-readable format. We demonstrate the effectiveness of the proposed specification language through a literature survey that includes an SLA language comparison analysis, and via reflecting the user satisfaction results of a usability study.},
  keywords={},
  doi={10.1109/HPCS.2018.00147},
  ISSN={},
  month={July},}@INPROCEEDINGS{8969716,
  author={Maliszewski, Anderson M. and Vogel, Adriano and Griebler, Dalvan and Roloff, Eduardo and Fernandes, Luiz G. and Philippe O. A., Navaux},
  booktitle={2019 IEEE Symposium on Computers and Communications (ISCC)}, 
  title={Minimizing Communication Overheads in Container-based Clouds for HPC Applications}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={Although the industry has embraced the cloud computing model, there are still significant challenges to be addressed concerning the quality of cloud services. Network-intensive applications may not scale in the cloud due to the sharing of the network infrastructure. In the literature, performance evaluation studies are showing that the network tends to limit the scalability and performance of HPC applications. Therefore, we proposed the aggregation of Network Interface Cards (NICs) in a ready-to-use integration with the OpenNebula cloud manager using Linux containers. We perform a set of experiments using a network microbenchmark to get specific network performance metrics and NAS parallel benchmarks to analyze the performance impact on HPC applications. Our results highlight that the implementation of NIC aggregation improves network performance in terms of throughput and latency. Moreover, HPC applications have different patterns of behavior when using our approach, which depends on communication and the amount of data transferring. While network-intensive applications increased the performance up to 38%, other applications with aggregated NICs maintained the same performance or presented slightly worse performance.},
  keywords={},
  doi={10.1109/ISCC47284.2019.8969716},
  ISSN={2642-7389},
  month={June},}@INPROCEEDINGS{7214120,
  author={Bruneo, Dario and Longo, Francesco and Ghosh, Rahul and Scarpa, Marco and Puliafito, Antonio and Trivedi, Kishor S.},
  booktitle={2015 IEEE 8th International Conference on Cloud Computing}, 
  title={Analytical Modeling of Reactive Autonomic Management Techniques in IaaS Clouds}, 
  year={2015},
  volume={},
  number={},
  pages={797-804},
  abstract={Cloud computing infrastructures provide services to a wide number of users whose behavior can deeply change at the occurrence of particular events. To correctly handle such situations a cloud infrastructure have to be reconfigured in a way that does not cause degradation in the overall performance. Otherwise, the quality of service specified in the service level agreement could be violated. To prevent such situations, the infrastructure could be organized as an autonomic system where self-adaptation and self-configuration techniques are implemented. Appropriate design choices become important in order not to fail in this goal. We propose a technique, based on a Petri net model and a specific analytical analysis approach, to represent Infrastructure-as-a-Service (IaaS) systems in the case in which the load conditions can suddenly change and reactive autonomic management techniques are applied to mitigate the consequences of the change. The model we propose is able to appropriately evaluate performance metrics in such critical situations making it suitable as a design tool for IaaS cloud systems.},
  keywords={},
  doi={10.1109/CLOUD.2015.110},
  ISSN={2159-6190},
  month={June},}@INPROCEEDINGS{6969013,
  author={Tchernykh, Andrei and Lozano, Luz and Schwiegelshohn, Uwe and Bouvry, Pascal and Pecero, Johnatan E. and Nesmachnow, Sergio},
  booktitle={2014 IEEE 3rd International Conference on Cloud Networking (CloudNet)}, 
  title={Bi-objective online scheduling with quality of service for IaaS clouds}, 
  year={2014},
  volume={},
  number={},
  pages={307-312},
  abstract={This paper focuses on the bi-objective experimental analysis of online scheduling in the Infrastructure as a Service model of Cloud computing. In this model, customer have the choice between different service levels. Each service level is associated with a price per unit of job execution time and a slack factor that determines the maximal time span to deliver the requested amount of computing resources. It is responsibility of the system and its scheduling algorithm to guarantee the corresponding quality of service for all accepted jobs. We do not consider any optimistic scheduling approach, that is, a job cannot be accepted if its service guarantee will not be observed assuming that all accepted jobs receive the requested resources. We analyze several scheduling algorithms with different cloud configurations and workloads and use the maximization of the provider income and minimization of the total power consumption of a schedule as additional objectives. Therefore, we cannot expect finding a unique solution to a given problem but a set of nondominated solutions also known as Pareto optima. Then we assess the performance of different scheduling algorithms by using a set coverage metric to compare them in terms of Pareto dominance. Based on the presented case study, we claim that a simple algorithm can provide the best energy and income trade-offs. This scheduling algorithm performs well in different scenarios with a variety of workloads and cloud configurations.},
  keywords={},
  doi={10.1109/CloudNet.2014.6969013},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9092335,
  author={Meyer, Vinícius and Kirchoff, Dionatrã F. and da Silva, Matheus L. and De Rose, César A.F.},
  booktitle={2020 28th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)}, 
  title={An Interference-Aware Application Classifier Based on Machine Learning to Improve Scheduling in Clouds}, 
  year={2020},
  volume={},
  number={},
  pages={80-87},
  abstract={To maximize resource utilization and system throughput in cloud platforms, hardware resources are often shared across multiple virtualized services or applications. In such a consolidated scenario, performance of applications running concurrently in the same physical host can be negatively affected due to interference caused by resource contention. This should be taken into account for efficient scheduling of such applications and performance prediction at user level. Nevertheless, resource scheduling in cloud computing is usually based solely on resource capacity, implemented by heuristics such as bin-packing. Our previous work has introduced an interference-aware scheduling model for web-applications considering their resource utilization profile, and to classify applications we applied fixed interference intervals based on common utilization patters. Although this resulted in placements with better overall results, we observed that some applications with more dynamic workload patterns were wrongly classified with intervals. In this paper, we propose an alternative to the use of intervals and present an interference-aware application classifier for cloud-based applications that deals better with dynamic workloads. Our classifier defines automatically interference levels ranges combining two well-known machine learning techniques: Support Vector Machines and K-Means. Preliminary experiments evaluated the applied machine learning techniques in three quality metrics: Accuracy, F1-Score and Rand Index, observing rates over 80%. The proposed solution creates a workload-aware fine-grained classification that was compared with previous work over different workload scenarios. The results demonstrate that our classification approach improves the placement efficiency by 23% on average.},
  keywords={},
  doi={10.1109/PDP50117.2020.00019},
  ISSN={2377-5750},
  month={March},}@INPROCEEDINGS{8458040,
  author={Ma, Kun and Bagula, Antoine and Mauwa, Hope and Celesti, Antonio},
  booktitle={2018 IEEE 6th International Conference on Future Internet of Things and Cloud (FiCloud)}, 
  title={Modelling Cloud Federation: A Fair Profit Distribution Strategy Using the Shapley Value}, 
  year={2018},
  volume={},
  number={},
  pages={393-398},
  abstract={Cloud computing provides software (Software as a Service), platform (Platform as a Service) and infrastructure (Infrastructure as a Service) services to its users by integrating IT resources into a large-scale and scalable resource pool through the virtualisation technology. However, the single cloud resource provider model currently implemented by many providers may fail short to meet the dynamic nature of cloud users' requirements. Cloud federation can mitigate this issue by optimising cloud resource allocation through sharing and re-usability of available resources. This paper revisit the problem of cloud engineering by tackling the key issue of the fair distribution of profit between cloud resource providers, which, to the best of our knowledge, has only been scarcely addressed by the research and practitioners' community. We propose a method that enables the cloud federation to map the contribution of resources of the participants to the federations into a quality of service metric used to achieve a cloud federation. Building upon a federation game implementation, we reveal the possibilities and benefits of different federation compositions using the Shapley value of each resource provider as a way of implementing a fair profit sharing strategy. Using extensions of the CloudSim package, we present simulation results that demonstrate the fairness of our proposed method and strategy.},
  keywords={},
  doi={10.1109/FiCloud.2018.00063},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9207151,
  author={Wang, Binyang and Li, Huifang and Lin, Zhiwei and Xia, Yuanqing},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Temporal Fusion Pointer network-based Reinforcement Learning algorithm for Multi-Objective Workflow Scheduling in the cloud}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={Cloud computing is emerging as a deployment promising environment for hosting exponentially increasing scientific and social media applications, but how to manage and execute these applications efficiently depends mainly on workflow scheduling. However, scheduling workflows in the cloud is an NP-hard problem and its existing solutions have certain limitations when applied to real-world scenarios. In this paper, a Temporal Fusion Pointer network-based Reinforcement Learning algorithm for multi-objective workflow scheduling (TFP-RL) is proposed. Through adopting reinforcement learning, our algorithm can discover its heuristics over time by continuous learning according to the rewards resulting from good scheduling solutions. To make more comprehensive scheduling decisions as the influence of historical actions, a novel temporal fusion pointer network (TFP) is designed for the reinforcement learning agent, which can improve the quality of our resulting solutions and the ability of our algorithm in dealing with versatile workflow applications. To decrease convergence time, we train the proposed TFP-RL model independently by the Asynchronous Advantage Actor-Critic method and use its resulting model for scheduling workflows. Finally, under a multi-agent reinforcement learning framework, a Pareto dominance-oriented criterion for reasonable action selection is established for a multi-objective optimization scenario. We first train our TFP-RL model by taking randomly generated workflows as inputs to validate its effectiveness in scheduling, then compare our trained model with other existing scheduling approaches through practical compute- and data-intensive workflows. Experimental results demonstrate that our proposed algorithm outperforms the benchmarking ones in terms of different metrics.},
  keywords={},
  doi={10.1109/IJCNN48605.2020.9207151},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{9149347,
  author={Alam, A B M Bodrul and Halabi, Talal and Haque, Anwar and Zulkernine, Mohammad},
  booktitle={ICC 2020 - 2020 IEEE International Conference on Communications (ICC)}, 
  title={Multi-Objective Interdependent VM Placement Model based on Cloud Reliability Evaluation}, 
  year={2020},
  volume={},
  number={},
  pages={1-7},
  abstract={Virtual Machine (VM) placement is considered as one of the crucial problems in Cloud Computing environments. From the perspective of Cloud Service Providers (CSPs), finding the optimal VM placement strategy is often related to optimal resource utilization, revenue maximization, and energy efficiency. However, to ensure the continuity of customer services, CSPs should also consider the reliability of deployed applications when placing VMs on their infrastructures. Existing research in this area either do not focus on the Cloud reliability evaluation aspect or do not account for the trade-off between reliability and performance in the VM placement process. In this paper, we propose a multi-objective placement model for interdependent VMs in the Cloud that considers both reliability and workload. Reliability in our model is quantitatively evaluated through a set of metrics that we propose. The model involves an Integer Linear Programming problem that aims at maximizing the reliability of the Cloud while minimizing network delay. A multi-objective genetic algorithm is then used to solve the problem heuristically. The proposed model introduces a level of flexibility and its parameters could be adjusted depending on the requirements of the infrastructure and services. The results show that our model achieves high Cloud reliability and allows to effectively control the trade-off between reliability and Quality of Service.},
  keywords={},
  doi={10.1109/ICC40277.2020.9149347},
  ISSN={1938-1883},
  month={June},}@INPROCEEDINGS{9407931,
  author={Hussain, Razin Farhan and Pakravan, Alireza and Salehi, Mohsen Amini},
  booktitle={2020 IEEE 22nd International Conference on High Performance Computing and Communications; IEEE 18th International Conference on Smart City; IEEE 6th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, 
  title={Analyzing the Performance of Smart Industry 4.0 Applications on Cloud Computing Systems}, 
  year={2020},
  volume={},
  number={},
  pages={11-18},
  abstract={Cloud-based Deep Neural Network (DNN) applications that make latency-sensitive inference are becoming an indispensable part of Industry 4.0. Due to the multi-tenancy and resource heterogeneity, both inherent to the cloud computing environments, the inference time of DNN-based applications are stochastic. Such stochasticity, if not captured, can potentially lead to low Quality of Service (QoS) or even a disaster in critical sectors, such as Oil and Gas industry. To make Industry 4.0 robust, solution architects and researchers need to understand the behavior of DNN-based applications and capture the stochasticity exists in their inference times. Accordingly, in this study, we provide a descriptive analysis of the inference time from two perspectives. First, we perform an application-centric analysis and statistically model the execution time of four categorically different DNN applications on both Amazon and Chameleon clouds. Second, we take a resource-centric approach and analyze a rate-based metric in form of Million Instruction Per Second (MIPS) for heterogeneous machines in the cloud. This non-parametric modeling, achieved via Jackknife and Bootstrap re-sampling methods, provides the confidence interval of MIPS for heterogeneous cloud machines. The findings of this research can be helpful for researchers and cloud solution architects to develop solutions that are robust against the stochastic nature of the inference time of DNN applications in the cloud and can offer a higher QoS to their users and avoid unintended outcomes.},
  keywords={},
  doi={10.1109/HPCC-SmartCity-DSS50907.2020.00003},
  ISSN={},
  month={Dec},}@ARTICLE{6671599,
  author={Shen, Haiying and Lin, Yuhua and Li, Ting},
  journal={IEEE Transactions on Computers}, 
  title={Combining Efficiency, Fidelity, and Flexibility in Resource Information Services}, 
  year={2015},
  volume={64},
  number={2},
  pages={353-367},
  abstract={A large-scale resource sharing system (e.g., collaborative cloud computing and grid computing) creates a virtual supercomputer by providing an infrastructure for sharing tremendous amounts of resources (e.g., computing, storage, and data) distributed over the Internet. A resource information service, which collects resource data and provides resource search functionality for locating desired resources, is a crucial component of the resource sharing system. In addition to resource discovery speed and cost (i.e., efficiency), the ability to accurately locate all satisfying resources (i.e., fidelity) is also an important metric for evaluating service quality. Previously, a number of resource information service systems have been proposed based on Distributed Hash Tables (DHTs) that offer scalable key-based lookup functions. However, these systems either achieve high fidelity at low efficiency, or high efficiency at low fidelity. Moreover, some systems have limited flexibility by only providing exact-matching services or by describing a resource using a pre-defined list of attributes. This paper presents a resource information service that offers high efficiency and fidelity without restricting resource expressiveness, while also providing a similar-matching service. Extensive simulation and PlanetLab experimental results show that the proposed service outperforms other services in terms of efficiency, fidelity, and flexibility; it dramatically reduces overhead and yields significant enhancements in efficiency and fidelity.},
  keywords={},
  doi={10.1109/TC.2013.222},
  ISSN={1557-9956},
  month={Feb},}@INPROCEEDINGS{9659505,
  author={Klinaku, Floriment and Hakamian, Alireza and Becker, Steffen},
  booktitle={2021 IEEE International Conference on Autonomic Computing and Self-Organizing Systems (ACSOS)}, 
  title={Architecture-based Evaluation of Scaling Policies for Cloud Applications}, 
  year={2021},
  volume={},
  number={},
  pages={151-157},
  abstract={The cloud computing model enables organizations to employ policies for the automated provisioning of computing resources. The impact on the quality, such as performance or cost, of such policies is often unknown for complex, large, and highly distributed cloud applications. Software architects lack a feasible approach to evaluate scaling policies for their cloud application quantitatively. While approaches exist in the literature, they are costly and require a high effort. We propose an approach that utilizes modeling and terminating simulations to evaluate alternative styles and configurations for cloud scaling policies. The approach aids the architect in understanding and explaining their dynamic behavior and the existing trade-offs. Third, we conduct simulation experiments on a representative case study model to show the approach&#x0027;s feasibility. We evaluate the performance, cost, efficiency, and complexity of three scaling policies of different styles (e.g., centralized vs. decentralized) on a model. Results show that the policies improve the performance for the selected scenario. However, no significant difference among them exists in terms of performance. Other metrics highlight the present trade-offs across policies. All in all, the case shows that the approach helps architects refine the style and find an appropriate policy for their context.},
  keywords={},
  doi={10.1109/ACSOS52086.2021.00035},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9563355,
  author={Li, Dian and Wang, Weidong and Kang, Yujian},
  booktitle={2021 IEEE International Conference on Electronic Technology, Communication and Information (ICETCI)}, 
  title={A Hierarchical Approach for QoS-Aware Edge Service Scheduling and Composition}, 
  year={2021},
  volume={},
  number={},
  pages={677-681},
  abstract={Edge computing is a new computing paradigm after cloud computing. Edge service scheduling and composition (ESC) has been well recognized as a convenient and flexible way of services sharing and integrating in industrial application fields. The ESC aims at selecting a set of existing edge service candidates with different Quality of Service (QoS) attributes (e.g., price), then compositing them to accomplish a complex task to meet users' QoS requirements, where each edge service may have multiple functionally equivalent, but different QoS metrics. A grand research challenge of the ESC based on QoS is to select proper service candidates to maximize QoS of the composited edge service and meanwhile meet the global QoS requirements. In this article, we focus on this challenge and propose a hierarchical solution for ESC. Specifically, we classify service candidates into specified grades based on their QoS attributes, and use hierarchical model to address service selection problem. Furthermore, in order to expand the flexibility of our approach, we design a near-optimal solution by decomposing the global end-to-end QoS constraints into local QoS constraints and adopting local service selecting and updating strategy based on the hierarchical model. The results of simulation-based experiments are conducted to show our approach is more efficient and valid compared to other existing approaches.},
  keywords={},
  doi={10.1109/ICETCI53161.2021.9563355},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8614209,
  author={Wangsom, Peerasak and Bouvry, Pascal and Lavangnananda, Kittichai},
  booktitle={2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)}, 
  title={Extreme Solutions NSGA-III (E-NSGA-III) for Scientific Workflow Scheduling on Cloud}, 
  year={2018},
  volume={},
  number={},
  pages={1139-1146},
  abstract={The execution of scientific workflows on dynamic environments such as cloud computing has become multi-objective scheduling in order to satisfy user demands from several perspectives. Among these objectives, Cost and Makespan are probably the most common. This research also includes Data Movement as an additional objective as it has significant effect to network utilization and energy consumption in network equipment in cloud data center. This paper proposes a multi-objective scheduling, Extreme Nondominated Sorting Genetic Algorithm (E-NSGA-III). It is an extension of the Nondominated Sorting Genetic Algorithm (NSGA-III). E-NSGA-III utilizes extreme solutions in the population generation module in order improve quality of solutions. Five well-known scientific workflows are selected as testbeds. Hypervolume and the Pareto front are chosen as the performance metrics. E-NSGA-III is evaluated by comparing its performance against the two previous versions (NSGA-II and NSGA-III). The comparison reveals that E-NSGA-III yields the best performance among them in multi-objective scheduling of the five scientific workflows.},
  keywords={},
  doi={10.1109/ICMLA.2018.00184},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9678460,
  author={Noureddine, Staifi and Meriem, Belguidoum},
  booktitle={2021 International Conference on Information Systems and Advanced Technologies (ICISAT)}, 
  title={ML-SLA-IoT: an SLA Specification and Monitoring Framework for IoT applications}, 
  year={2021},
  volume={},
  number={},
  pages={1-12},
  abstract={Service level agreement (SLA) is a formal contract between a service provider and a service consumer to guarantee the Quality of service (QoS) expectations, it is used in all areas of information technology, such as Cloud Computing, Internet of Things (IoT), networks and Web services. For IoT applications, the main challenges are: (1) how to describe the SLA terms, such as QoS properties, service levels, penalties in SLA violation, (2) how to monitor these terms, and (3) how to integrate an SLA into all the IoT application layers. Therefore, in this paper, we propose ML-SLA-IoT, a framework for SLA specification and monitoring. It covers the entire layers of an IoT application. It describes precisely QoS levels, provided services, and obligations. It differs from other SLA specification languages in the specification of user preferences, the use of microservices (for reusability, dynamism and ease of integration) and ML-SLA (multi-level metrics and QoS according to existing constraints and user preferences). Furthermore, ML-SLA-IoT monitors SLA terms in an automatic and decentralised manner using smart contracts and blockchain technologies without the intervention of the third-party. Finally, we present a comparative study and experiments with existing solutions regarding to some criteria for SLA specification and monitoring. Our results show that ML-SLA-IoT gives better performance in terms of dynamic pricing, obligation combination, and SLA monitoring.},
  keywords={},
  doi={10.1109/ICISAT54145.2021.9678460},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8260045,
  author={Afify, Yasmine M. and Badr, Nagwa L. and Moawad, Ibrahim F. and Tolba, Mohamed F.},
  booktitle={2017 Eighth International Conference on Intelligent Computing and Information Systems (ICICIS)}, 
  title={Evaluation of cloud service ontologies}, 
  year={2017},
  volume={},
  number={},
  pages={144-153},
  abstract={It is the cloud computing era. Substantial number of Cloud Services (CS) have emerged. The automation of the cloud services life cycle can be enhanced using domain ontologies in the cloud environment. Ontologies allow more efficient CS publication, discovery, selection, composition and recommendations. However, no broad cloud ontology for this purpose has dominated yet. This paper presents an in-depth analysis of existing cloud taxonomies and service ontologies. We present a comparison of the cloud service ontologies implementation features. Moreover, a semiotic metrics suite of ontology quality is used for the assessment process.},
  keywords={},
  doi={10.1109/INTELCIS.2017.8260045},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9719678,
  author={Gong, Yanqi and Hao, Fei and Sun, Yifei and Guo, Longjiang},
  booktitle={2021 20th International Conference on Ubiquitous Computing and Communications (IUCC/CIT/DSCI/SmartCNS)}, 
  title={Joint Optimization of Latency and Reward for Offloading Dependent Tasks in Mobile Edge Computing}, 
  year={2021},
  volume={},
  number={},
  pages={68-75},
  abstract={In the 5G era with the explosive growth of data, offloading tasks to edge servers that are executed closer to it becomes one of the most popular computational paradigms. Different from cloud computing, mobile edge computing (MEC) significantly addresses the problem of latency-sensitive applications execution, such as online gaming and VR/AR applications. In order to improve the quality of experience of end-users, those applications are often divided into multiple tasks with dependencies. Regarding the problem of offloading tasks with dependencies, the existing researches focus on either latency or reward optimization that leads to the practical difficulty of this problem. Towards this end, this paper first introduces a novel metric reward per unit time which integrates the latency and reward for better optimization of tasks offloading strategy. Then, the reward per unit time is viewed as the objective function, and further addressing the above problem is equivalent to finding the optimal offloading strategy to maximize the value of the objective function. The simulation experiments are conducted for demonstrating that the proposed offloading strategy is feasible and effective.},
  keywords={},
  doi={10.1109/IUCC-CIT-DSCI-SmartCNS55181.2021.00025},
  ISSN={},
  month={Dec},}@ARTICLE{7437245,
  author={Maia, Delano Jose Holanda and Moreira, Leonardo Oliveira and Coutinho, Emanuel Ferreira and Gomes, Danielo Goncalves},
  journal={IEEE Latin America Transactions}, 
  title={MILENA: a model for implementing distributed multiplayer games in computing clouds}, 
  year={2016},
  volume={14},
  number={2},
  pages={951-957},
  abstract={Cloud computing environments are characteristically composed of distributed infrastructure, heterogeneous and virtualized resources, besides serving concurrently a wide range of customers whose service level agreements may require different levels of Quality of Service (QoS). Distributed multiplayer games, in turn, are collaborative distributed applications that must have an acceptable level of QoS to maintain justice among its players. This article proposes MILENA, a model for implementing distributed multiplayer games on computer clouds. The proposed model meets the requirements of QoS, fault tolerance and scalability. As a case study for verification and validation of the proposal, we have developed a game and evaluated its performance by SLA violations and response time of requests metrics. The results show that the MILENA scales up to 100 players without QoS loss, thus improving justice in distributed multiplayer games.},
  keywords={},
  doi={10.1109/TLA.2016.7437245},
  ISSN={1548-0992},
  month={Feb},}@ARTICLE{7972945,
  author={He, Jianhua and Wei, Jian and Chen, Kai and Tang, Zuoyin and Zhou, Yi and Zhang, Yan},
  journal={IEEE Internet of Things Journal}, 
  title={Multitier Fog Computing With Large-Scale IoT Data Analytics for Smart Cities}, 
  year={2018},
  volume={5},
  number={2},
  pages={677-686},
  abstract={Analysis of Internet of Things (IoT) sensor data is a key for achieving city smartness. In this paper a multitier fog computing model with large-scale data analytics service is proposed for smart cities applications. The multitier fog is consisted of ad-hoc fogs and dedicated fogs with opportunistic and dedicated computing resources, respectively. The proposed new fog computing model with clear functional modules is able to mitigate the potential problems of dedicated computing infrastructure and slow response in cloud computing. We run analytics benchmark experiments over fogs formed by Rapsberry Pi computers with a distributed computing engine to measure computing performance of various analytics tasks, and create easy-to-use workload models. Quality of services (QoS) aware admission control, offloading, and resource allocation schemes are designed to support data analytics services, and maximize analytics service utilities. Availability and cost models of networking and computing resources are taken into account in QoS scheme design. A scalable system level simulator is developed to evaluate the fog-based analytics service and the QoS management schemes. Experiment results demonstrate the efficiency of analytics services over multitier fogs and the effectiveness of the proposed QoS schemes. Fogs can largely improve the performance of smart city analytics services than cloud only model in terms of job blocking probability and service utility.},
  keywords={},
  doi={10.1109/JIOT.2017.2724845},
  ISSN={2327-4662},
  month={April},}@ARTICLE{8489955,
  author={Nguyen, Tien-Dung and Huh, Eui-Nam and Jo, Minho},
  journal={IEEE Internet of Things Journal}, 
  title={Decentralized and Revised Content-Centric Networking-Based Service Deployment and Discovery Platform in Mobile Edge Computing for IoT Devices}, 
  year={2019},
  volume={6},
  number={3},
  pages={4162-4175},
  abstract={Mobile edge computing (MEC) is used to offload services (tasks) from cloud computing in order to deliver those services to mobile Internet of Things (IoT) devices near mobile edge nodes. However, even though there are advantages to MEC, we face many significant problems, such as how a service provider (SP) deploys requested services efficiently on a destination MEC node, and how to discover existing services in neighboring MEC nodes to save edge resources. In this paper, we present a decentralized and revised content-centric networking (CCN)-based MEC service deployment/discovery protocol and platform. We organized a gateway in every area according to a three-tiered hierarchical MEC network topology to reduce computing overhead at the centralized controller. We revised CCN to introduce a protocol to help SP deploy their service on MEC node and assist MEC node discover services in neighboring nodes. By using our proposed protocol, MEC nodes can deploy or discover the requested service instances in the proximity of IoT devices to reduce transmission delay. We also present a mathematical model to calculate the round trip time to guarantee quality of service. Numerical experiments measure the performance of our proposed method with various mobile IoT device services. The results show that the proposed service deployment protocol and platform reduce the average service delay by up to 50% compared to legacy cloud. In addition, the proposed method outperforms the legacy protocol of the MEC environment in service discovery time.},
  keywords={},
  doi={10.1109/JIOT.2018.2875489},
  ISSN={2327-4662},
  month={June},}@ARTICLE{9489314,
  author={Cheikhrouhou, Omar and Mahmud, Redowan and Zouari, Ramzi and Ibrahim, Muhammad and Zaguia, Atef and Gia, Tuan Nguyen},
  journal={IEEE Access}, 
  title={One-Dimensional CNN Approach for ECG Arrhythmia Analysis in Fog-Cloud Environments}, 
  year={2021},
  volume={9},
  number={},
  pages={103513-103523},
  abstract={Cardiovascular diseases are considered the number one cause of death across the globe which can be primarily identified by the abnormal heart rhythms of the patients. By generating electrocardiogram (ECG) signals, wearable Internet of Things (IoT) devices can consistently track the patient's heart rhythms. Although Cloud-based approaches for ECG analysis can achieve some levels of accuracy, they still have some limitations, such as high latency. Conversely, the Fog computing infrastructure is more powerful than edge devices but less capable than Cloud computing for executing compositionally intensive data analytic software. The Fog infrastructure can consist of Fog-based gateways directly connected with the wearable devices to offer many advanced benefits, including low latency and high quality of services. To address these issues, a modular one-dimensional convolution neural network (1D-CNN) approach is proposed in this work. The inference module of the proposed approach is deployable over the Fog infrastructure for analysing the ECG signals and initiating the emergency countermeasures within a minimum delay, whereas its training module is executable on the computationally enriched Cloud data centers. The proposed approach achieves the F1-measure score ≈1 on the MIT-BIH Arrhythmia database when applying GridSearch algorithm with the cross-validation method. This approach has also been implemented on a single-board computer and Google Colab-based hybrid Fog-Cloud infrastructure and embodied to a remote patient monitoring system that shows 25% improvement in the overall response time.},
  keywords={},
  doi={10.1109/ACCESS.2021.3097751},
  ISSN={2169-3536},
  month={},}@ARTICLE{7090976,
  author={Candeia, David and Santos, Ricardo Araújo and Lopes, Raquel},
  journal={IEEE Transactions on Cloud Computing}, 
  title={Business-Driven Long-Term Capacity Planning for SaaS Applications}, 
  year={2015},
  volume={3},
  number={3},
  pages={290-303},
  abstract={Capacity Planning is one of the activities developed by Information Technology departments over the years, it aims at estimating the amount of resources needed to offer a computing service. This activity contributes to achieving high Quality of Service levels and also to pursuing better economic results for companies. In the Cloud Computing context, one plausible scenario is to have Software-as-a-Service (SaaS) providers that build their IT infrastructure acquiring resources from Infrastructure-as-a-Service (IaaS) providers. SaaS providers can reduce operational costs and complexity by buying instances from a reservation market, but then need to predict the number of instances needed in the long-term. This work investigates how important is the capacity planning in this context and how simple business-driven heuristics for long-term capacity planning impact on the profit achieved by SaaS providers. Simulation experiments were performed using synthetic e-commerce workloads. Our analysis show that proposed heuristics increase SaaS provider profit, on average, at 9.6501 percent per year. Analysing such results we demonstrate that capacity planning is still an important activity, contributing to the increase of SaaS providers profit. Besides, a good capacity planning may also avoid bad reputation due to unacceptable performance, which is a gain very hard to measure.},
  keywords={},
  doi={10.1109/TCC.2015.2424877},
  ISSN={2168-7161},
  month={July},}@ARTICLE{9165739,
  author={Gao, Zihan and Hao, Wanming and Han, Zhuo and Yang, Shouyi},
  journal={IEEE Access}, 
  title={Q-Learning-Based Task Offloading and Resources Optimization for a Collaborative Computing System}, 
  year={2020},
  volume={8},
  number={},
  pages={149011-149024},
  abstract={Mobile edge computing (MEC) can effectively overcome the shortcomings of high-latency in mobile cloud computing (MCC) by deploying the cloud resources, e.g., storage and computational capability, to the edge. However, the limited computation capability of the MEC restricts the scalability of offloading. Therefore, the basic requirements of the MEC system are to explore effective offloading decisions and resource allocation methods. To address it, we develop a collaborative computing system composed of local computing (mobile device), MEC (edge cloud) and MCC (central cloud). Based on the proposed collaborative computing system, we design a novel Q-learning based computation offloading (QLCOF) policy to achieve the optimal resource allocation and offloading scheme by prescheduling the computation side for each task from a global perspective. Specifically, we first model the offloading decision process as a Markov decision process (MDP) and design a state loss function (STLF) to measure the quality of experience (QoE). After that, we define the cumulation of STLFs as the system loss function (SYLF) and formulate an SYLF minimization problem. Due to the difficulty to directly solve the formulated problem, we decompose it into multiple subproblems and preferentially optimize the transmission power and computation frequency of the edge cloud by the quasi-convex bisection and polynomial analysis method, respectively. Based on the precalculated offline transmission power and edge cloud computation frequency, we develop a Q-learning based offloading (QLOF) scheme to minimize the SYLF by optimizing offloading decisions. Finally, the numeral results show that the proposed QLOF scheme effectively reduces the SYLF under different parameters.},
  keywords={},
  doi={10.1109/ACCESS.2020.3015993},
  ISSN={2169-3536},
  month={},}@ARTICLE{9097295,
  author={Rahman, Sabidur and Ahmed, Tanjila and Huynh, Minh and Tornatore, Massimo and Mukherjee, Biswanath},
  journal={IEEE Transactions on Network and Service Management}, 
  title={Auto-Scaling Network Service Chains Using Machine Learning and Negotiation Game}, 
  year={2020},
  volume={17},
  number={3},
  pages={1322-1336},
  abstract={Network Function Virtualization (NFV) enables Network Operators (NOs) to efficiently respond to the increasing dynamicity of network services. Virtual Network Functions (VNFs) running on commercial off-the-shelf servers are easy to deploy, update, monitor, and manage. Such virtualized services are often deployed as Service Chains (SCs), which require in-sequence placement of computing and memory resources as well as routing of traffic flows. Due to the ongoing migration towards cloudification of networks, the concept of auto-scaling which originated in Cloud Computing, is now receiving attention from networks professionals too. Prior studies on auto-scaling use measured load to dynamically react to traffic changes. Moreover, they often focus on only one of the resources (e.g., compute only, or network capacity only). In this study, we consider three different resource types: compute, memory, and network bandwidth. In prior studies, NO takes auto-scaling decisions, assuming tenants are always willing to auto-scale, and Quality of Service (QoS) requirements are homogeneous. Our study proposes a negotiation-game-based auto-scaling method where tenants and NO both engage in the auto-scaling decision, based on their willingness to participate, heterogeneous QoS requirements, and financial gain (e.g., cost savings). In addition, we propose a proactive Machine Learning (ML) based prediction method to perform SC auto-scaling in dynamic traffic scenario. Numerical examples show that our proposed SC auto-scaling methods powered by ML present a win-win situation for both NO and tenants (in terms of cost savings).},
  keywords={},
  doi={10.1109/TNSM.2020.2995900},
  ISSN={1932-4537},
  month={Sep.},}@INPROCEEDINGS{8366932,
  author={Zhou, Peipei and Ruan, Zhenyuan and Fang, Zhenman and Shand, Megan and Roazen, David and Cong, Jason},
  booktitle={2018 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)}, 
  title={Doppio: I/O-Aware Performance Analysis, Modeling and Optimization for In-memory Computing Framework}, 
  year={2018},
  volume={},
  number={},
  pages={22-32},
  abstract={In conventional Hadoop MapReduce applications, I/O used to play a heavy role in the overall system performance. More recently, a study from the Apache Spark community- state-of-the-art in-memory cluster computing framework- reports that I/O is no longer the bottleneck and has a marginal performance impact on applications like SQL processing. However, we observe that simply replacing HDDs with SSDs in a Spark cluster can have over 10x performance improvement for certain stages in large-scale production-quality genome processing. Therefore, one key question arises: How does I/O quanti- tatively impact the performance of today's big data applications developed using in-memory cluster computing frameworks like Apache Spark? In this paper we select an important yet complex application- the Spark-based Genome Analysis ToolKit (GATK4)-to guide our modeling. We first use different combinations of HDDs and SSDs to measure the I/O impact on GATK4 and change the CPU core number to discover the relation between computation and I/O access. By combining with Spark's underlying implementations, we further analyze the inherent cause of the above observations and build our model based on the analysis. Although we are building upon GATK4, our model maintains generality to other applications. Experimental results show that we can achieve a performance prediction error rate within 10% for typical Spark applications of both iterative and shuffle-heavy algorithms. Finally, we further extend our model to a broader area-that of optimal configuration selection in the public cloud. In Google Cloud, our model enables us to save 38% to 57% of cost for genome sequencing compared with its recommended default configurations. Currently, more and more companies are adopting cloud computing for specific workloads. Our proposed model can have a huge impact on their choices, while also enabling them to significantly reduce their costs.},
  keywords={},
  doi={10.1109/ISPASS.2018.00011},
  ISSN={},
  month={April},}@INPROCEEDINGS{8057143,
  author={Toka, Lászlíó and Lajtha, Balázs and Hosszu, Éva and Formanek, Bence and Géhberger, Dániel and Tapolcai, János},
  booktitle={IEEE INFOCOM 2017 - IEEE Conference on Computer Communications}, 
  title={A resource-aware and time-critical IoT framework}, 
  year={2017},
  volume={},
  number={},
  pages={1-9},
  abstract={Internet of Things (IoT) systems produce great amount of data, but usually have insufficient resources to process them in the edge. Several time-critical IoT scenarios have emerged and created a challenge of supporting low latency applications. At the same time cloud computing became a success in delivering computing as a service at affordable price with great scalability and high reliability. We propose an intelligent resource allocation system that optimally selects the important IoT data streams to transfer to the cloud for processing. The optimization runs on utility functions computed by predictor algorithms that forecast future events with some probabilistic confidence based on a dynamically recalculated data model. We investigate ways of reducing specifically the upload bandwidth of IoT video streams and propose techniques to compute the corresponding utility functions. We built a prototype for a smart squash court and simulated multiple courts to measure the efficiency of dynamic allocation of network and cloud resources for event detection during squash games. By continuously adapting to the observed system state and maximizing the expected quality of detection within the resource constraints our system can save up to 70% of the resources compared to the naive solution.},
  keywords={},
  doi={10.1109/INFOCOM.2017.8057143},
  ISSN={},
  month={May},}@ARTICLE{9458258,
  author={Liu, Li and Lu, Caiwu and Xiao, Fengjun and Liu, Ruimin and Xiong, Neal Naixue},
  journal={IEEE Access}, 
  title={A Practical, Integrated Multi-Criteria Decision-Making Scheme for Choosing Cloud Services in Cloud Systems}, 
  year={2021},
  volume={9},
  number={},
  pages={88391-88404},
  abstract={Currently, with the rapid development and broad application of cloud computing technology, companies tend to use cloud services to build their applications or business systems. Selecting a trustworthy cloud service is a challenging multi-criteria decision-making (MCDM) problem. Moreover, decision makers are more inclined to use linguistic descriptions to assess the quality of service (QoS) for cloud services due to the limitation of the decision makers' knowledge and the vagueness of criteria information. Therefore, we propose a practical, integrated MCDM scheme for cloud service evaluation and selection of cloud systems, allowing decision makers to compare cloud services based on QoS criteria. First, to more accurately and effectively express the uncertainty of qualitative concepts, the cloud model is used as a conversion tool for qualitative and quantitative information to quantify linguistic terms. Second, given the shortcomings of traditional differentiating measures between cloud models, a more comprehensive distance measurement algorithm using cloud droplet distribution is proposed for the cloud model. The new distance measurement algorithm is applied to the calculation of cloud model similarity and the gray correlation coefficient. The dynamic expertise weights are determined by calculating the similarity between the expert evaluation cloud model and the arithmetic mean cloud model. Then, we propose a technique for order preference by similarity to an ideal solution (TOPSIS) improved by the grey relational analysis (GRA) to calculate the relative closeness of alternatives to the positive and negative ideal solutions and establish a multi-objective optimization model that maximizes the relative closeness of all alternatives to determine the weights of the criteria. Finally, we reconstructed the QoS evaluation criteria for cloud services from both application and service perspectives, and the classical TOPSIS is applied to generate alternative rankings. The practicability and robustness of the scheme were tested through the cloud service selection problem experienced by a real mining company's scheduling platform, which can provide practical references with the theoretical basis for the selection and evaluation of cloud services.},
  keywords={},
  doi={10.1109/ACCESS.2021.3089991},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9058016,
  author={Bhardwaj, Tushar and Upadhyay, Himanshu and Sharma, Subhash Chander},
  booktitle={2020 10th International Conference on Cloud Computing, Data Science & Engineering (Confluence)}, 
  title={Framework for Quality Ranking of Components in Cloud Computing: Regressive Rank}, 
  year={2020},
  volume={},
  number={},
  pages={598-604},
  abstract={As the popularity of cloud computing is increasing there is an urgent requirement of developing highly efficient and highly qualitative cloud applications (CA). Hence, it be-comes a big research problem. A recommender system recommends the suitable item to the user and almost all the systems provide a rating score for preference. Traditionally, algorithms predicts the ratings that a user should give to the unrated components to queue the item in recommended list. To select an optimal candidate from a set of function-ally equivalent candidates is crucial through approaches that follow a framework for component quality ranking. More-over, such framework helps in detecting the poor performing candidates from a highly distributed cloud applications. In this paper a novel technique is proposed to provide personalized component ranking for designers by employing the past usage of components by different users. In this approach the similarity between the users is measured based on their rankings for functionally equivalent components set instead of their rating values. In this approach no additional invocation of cloud component is required. Experimental results on real world web-service invocations data set shows that the proposed approach outperforms the previous approaches.},
  keywords={},
  doi={10.1109/Confluence47617.2020.9058016},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{6883911,
  author={Liu, Meng and Dou, Wanchun and Yu, Shui and Zhang, Zhensheng},
  booktitle={2014 IEEE International Conference on Communications (ICC)}, 
  title={A clusterized firewall framework for cloud computing}, 
  year={2014},
  volume={},
  number={},
  pages={3788-3793},
  abstract={Cloud computing is becoming popular as the next infrastructure of computing platform. However, with data and business applications outsourced to a third party, how to protect cloud data centers from numerous attacks has become a critical concern. In this paper, we propose a clusterized framework of cloud firewall, which characters performance and cost evaluation. To provide quantitative performance analysis of the cloud firewall, a novel M/Geo/1 analytical model is established. The model allows cloud defenders to extract key system measures such as request response time, and determine how many resources are needed to guarantee quality of service (QoS). Moreover, we give an insight into financial cost of the proposed cloud firewall. Finally, our analytical results are verified by simulation experiments.},
  keywords={},
  doi={10.1109/ICC.2014.6883911},
  ISSN={1938-1883},
  month={June},}@ARTICLE{9354861,
  author={Sacco, Alessio and Flocco, Matteo and Esposito, Flavio and Marchetto, Guido},
  journal={IEEE Transactions on Network and Service Management}, 
  title={Supporting Sustainable Virtual Network Mutations With Mystique}, 
  year={2021},
  volume={18},
  number={3},
  pages={2714-2727},
  abstract={The abiding attempt of automation has also permeated the networks, with the ability to measure, analyze, and control themselves in an automated manner, by reacting to changes in the environment (e.g., demand). When provided with these features, networks are often labeled as “self-driving” or “autonomous”. In this regard, the provision and orchestration of physical or virtual resources are crucial for both Quality of Service (QoS) guarantees and cost management in the edge/cloud computing environment. To effectively manage the lifecycle of these resources, an auto-scaling mechanism is essential. However, traditional threshold-based and recent Machine Learning (ML)-based policies are often unable to address the soaring complexity of networks due to their centralized approach. By relying on multi-agent reinforcement learning, we propose Mystique, a solution that learns from the load on links to establish the minimal set of active network resources. As traffic demands ebb and flow, our adaptive and self-driving solution can scale up and down and also react to failures in a fully automated, flexible, and efficient manner. Our results demonstrate that the presented solution can reduce network energy consumption while providing an adequate service level, outperforming other benchmark auto-scaling approaches.},
  keywords={},
  doi={10.1109/TNSM.2021.3059647},
  ISSN={1932-4537},
  month={Sep.},}@INPROCEEDINGS{7396178,
  author={Rahulamathavan, Yogachandran and Rajarajan, Muttukrishnan and Rana, Omer F. and Awan, Malik S. and Burnap, Pete and Das, Sajal K.},
  booktitle={2015 IEEE 7th International Conference on Cloud Computing Technology and Science (CloudCom)}, 
  title={Assessing Data Breach Risk in Cloud Systems}, 
  year={2015},
  volume={},
  number={},
  pages={363-370},
  abstract={The emerging cloud market introduces a multitude of cloud service providers, making it difficult for consumers to select providers who are likely to be a low risk from a security perspective. Recently, significant emphasis has arisen on the need to specify Service Level Agreements that address security concerns of consumers (referred to as SecSLAs) -- these are intended to clarify security support in addition to Quality of Service characteristics associated with services. It has been found that such SecSLAs are not consistent among providers, even though they offer services with similar functionality. However, measuring security service levels and the associated risk plays an important role when choosing a cloud provider. Data breaches have been identified as a high priority threat influencing the adoption of cloud computing. This paper proposes a general analysis framework which can compute risk associated with data breaches based on pre-agreed SecSLAs for different cloud providers. The framework exploits a tree based structure to identify possible attack scenarios that can lead to data breaches in the cloud and a means of assessing the use of potential mitigation strategies to reduce such breaches.},
  keywords={},
  doi={10.1109/CloudCom.2015.58},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{6883661,
  author={Si, Pengbo and Yu, F. Richard and Zhang, Yanhua},
  booktitle={2014 IEEE International Conference on Communications (ICC)}, 
  title={Joint cloud and radio resource management for video transmissions in mobile cloud computing networks}, 
  year={2014},
  volume={},
  number={},
  pages={2270-2275},
  abstract={In mobile cloud computing (MCC) systems, the resource in both the cloud and the mobile network should be carefully managed. Cloud resource management and radio resource management have traditionally been addressed separately in previous works. In this paper, we propose to jointly study dynamic cloud and radio resource management so as to improve end-to-end performance of adaptive video transmissions in MCC systems. Video application quality of service performance, distortion, is adopted as the performance measure. An important video application layer parameter, intra-refreshing rate, is optimized to improve the video distortion performance. We formulate the problem as a stochastic restless bandits optimization problem, which facilitates the distributed MCC architecture and simplifies the computation and implementation due to its “indexibility” property. Simulation results are presented to show the effectivenes of the proposed scheme.},
  keywords={},
  doi={10.1109/ICC.2014.6883661},
  ISSN={1938-1883},
  month={June},}@INPROCEEDINGS{9183589,
  author={Winzinger, Stefan and Wirtz, Guido},
  booktitle={2020 IEEE International Conference on Service Oriented Systems Engineering (SOSE)}, 
  title={Applicability of Coverage Criteria for Serverless Applications}, 
  year={2020},
  volume={},
  number={},
  pages={49-56},
  abstract={Serverless computing is a popular trend in cloud computing based on serverless functions. These functions are stateless which can be utilized by the cloud platform provider to scale functions dynamically. While these small functions are easy to test in isolation, integrating them with other resources provided by the cloud platform provider or third parties creates a complex system whose emerging behavior is hard to test. Integration tests help test the interaction of the serverless functions with other resources and their environment. However, it is hard to decide if a test case is adequate and focuses on the critical parts of the system. Therefore, coverage criteria can be used to measure the coverage of the relevant software components and help assess the quality of the test suite. In this paper, we identified serverless applications based on serverless functions on GitHub and used them to investigate which coverage criteria can be used to capture the interaction of serverless functions with other resources. Furthermore, we show a general approach to implement the measurement of the coverage on FaaS platforms. Thus, developers have means to test the adequacy of their applications on any FaaS platform.},
  keywords={},
  doi={10.1109/SOSE49046.2020.00013},
  ISSN={2642-6587},
  month={Aug},}@INPROCEEDINGS{7288394,
  author={Xie, Xiongwei and Wang, Weichao and Qin, Tuanfa},
  booktitle={2015 24th International Conference on Computer Communication and Networks (ICCCN)}, 
  title={Detection of Service Level Agreement (SLA) Violation in Memory Management in Virtual Machines}, 
  year={2015},
  volume={},
  number={},
  pages={1-8},
  abstract={In cloud computing, quality of services is often enforced through Service Level Agreement (SLA) between end users and cloud providers. While SLAs on hardware resources such as CPU cycles or bandwidth can be monitored by low layer sensors, the enforcement of security SLAs stays a very challenging problem. Several high level architectures for security SLAs have been proposed. However, details still need to be filled before they can be deployed. In this paper, we propose to design mechanisms to detect violations of security SLAs. Specifically, we focus on unauthorized accesses to memory pages of a virtual machine and violation of the memory deduplication policies. Through measuring the accumulated memory access latency, we try to derive out whether or not the memory pages have been swapped out and the order of accesses to them. These events will then be compared to access commands issued by the local VM. In this way, unauthorized memory accesses or violation of deduplication policies can be detected. Compared to existing approaches, our mechanisms do not need explicit help from the hypervisor or third parties. Therefore, it can detect SLA violations even when they are initiated by the hypervisor. We implement our approaches under VMWare with Windows virtual machines. Our experiment results show that the VM can effectively detect the violations with small increases in overhead.},
  keywords={},
  doi={10.1109/ICCCN.2015.7288394},
  ISSN={1095-2055},
  month={Aug},}@INPROCEEDINGS{7435462,
  author={Chen, Wei and Chen, Jiming and Tang, Jine and Wang, Liangmin},
  booktitle={2015 Third International Conference on Advanced Cloud and Big Data}, 
  title={A QoS Guarantee Framework for Cloud Services Based on Bayesian Prediction}, 
  year={2015},
  volume={},
  number={},
  pages={117-124},
  abstract={With the quality of service (QoS) of cloud services becoming increasingly concerned, how to ensure that the QoS of cloud services can meet the users' QoS requirement has become a focus of the study on cloud computing. However, the QoS of cloud services is dynamic regularly, we propose a QoS guarantee framework for cloud services and the Bayesian prediction method is used to predict QoS of cloud service. In our framework, cloud system can monitor and predict the QoS of cloud services in real-time, not only during the selection of cloud services, but also during the execution of cloud services. Once QoS prediction results show that some QoS violations will occur, cloud system will take measures to avoid the occurrence of QoS violations. We use the cloud simulation software called CloudSim for the experiment and the results demonstrate that compared with ARIMA and other prediction methods, our Bayesian prediction method has higher accuracy. Moreover, our QoS guarantee framework can greatly reduce the probability of QoS violation.},
  keywords={},
  doi={10.1109/CBD.2015.28},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{7410295,
  author={Abtahizadeh, S. Amirhossein and Khomh, Foutse and Guéhéneuc, Yann-Gaël},
  booktitle={2015 IEEE 34th International Performance Computing and Communications Conference (IPCCC)}, 
  title={How green are cloud patterns?}, 
  year={2015},
  volume={},
  number={},
  pages={1-8},
  abstract={Cloud Patterns are abstract solutions to recurrent design problems in the cloud. Previous work has shown that these patterns can improve the Quality of Service (QoS) of cloud applications but their impact on energy consumption is still unknown. Yet, energy consumption is the biggest challenge that cloud computing systems (the backbone of today's high-tech economy) face today. In fact, 10% of the world's electricity is now being consumed by servers, laptops, tablets and smartphones. Energy consumption has complex dependencies on the hardware platform, and the multiple software layers. The hardware, its firmware, the operating system, and the various software components used by a cloud application, all contribute to determining the energy footprint. Hence, even though increasing a data center efficiency will eventually improve energy efficiency, the internal design of cloud-based applications can be improved to lower energy consumption. In this paper, we conduct an empirical study on a RESTful multi-threaded application deployed in the cloud, to investigate the individual and the combined impact of three cloud patterns (e.g., Local Database proxy, Local Sharding Based Router and Priority Queue) on the energy consumption of cloud based applications. We measure the energy consumption using Power-API; an application programming interface (API) written in Java to monitor the energy consumed at the process-level. Results show that cloud patterns can effectively reduce the energy consumption of a cloud application, but not in all cases. In general, there appear to be a trade-off between an improved response time of the application and the energy consumption. Developers and software architects can make use of these results to guide their design decisions.},
  keywords={},
  doi={10.1109/PCCC.2015.7410295},
  ISSN={2374-9628},
  month={Dec},}@INPROCEEDINGS{9084760,
  author={Shan, Nanliang and Cui, Xiaolong and Gao, Zhiqiang and Li, Yu},
  booktitle={2020 IEEE 4th Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)}, 
  title={Multi-User Multi-Server Multi-Channel Computation Offloading Strategy for Mobile Edge Computing}, 
  year={2020},
  volume={1},
  number={},
  pages={1389-1400},
  abstract={Mobile edge computing is a new computing paradigm that can extend cloud computing capabilities to the edge network, supporting computation-intensive applications such as face recognition, natural language processing, augmented reality. Notably, computation offloading is a key technology of mobile edge computing to improve mobile devices performance and user experience by offloading local tasks to edge servers. In this paper, we study the problem of computation offloading under multi-user, multi-server, and multi-channel scenarios, and propose a computation offloading strategy considering the quality of service (QoS) of users, server resources, and channel interference. This strategy consists of three stages: (1) In offloading decision stage, the offloading decision is made based on the beneficial degree of computation offloading, which is measured by the total cost of local computing of mobile device in comparison with the edge-side server. (2) In the server selection stage, the candidate is comprehensively evaluated and selected by a multi-objective decision based on Cov-AHP for computation offloading. (3) In the channel selection stage, a multi-user and multi-channel distributed computation offloading model based on potential game is proposed by considering the influence of channel interference on the user's overall overhead. The corresponding multi-user and multi-channel task scheduling algorithm is designed to maximize the overall benefit by finding the Nash equilibrium point of the potential game. Amounts of experimental results show that the proposed method can greatly increase the number of beneficial computation offloading users, and effectively reduce the energy consumption and time delay.},
  keywords={},
  doi={10.1109/ITNEC48623.2020.9084760},
  ISSN={},
  month={June},}@ARTICLE{6740925,
  author={Nam, Yunyoung and Park, Hyung Ju and Cho, Chae Ho and Park, Jong Hyuk},
  journal={IEEE Systems Journal}, 
  title={An Interactive IPTV System With Community Participation in Cloud Computing Environments}, 
  year={2014},
  volume={8},
  number={1},
  pages={174-183},
  abstract={This paper presents a video communication system that provides real-time participating services to audiences using Internet Protocol television (IPTV) and mobile devices on cloud computing environments. High-quality video processing and bidirectional multimedia communication technologies are combined for videoconferencing and interactive user participation. The P-module has been developed to encode and decode 1080i high-definition video data on a system simultaneously. A video communication protocol is applied to exchanging information between distributed and heterogeneous devices. The developed system has been deployed in a public service center in Seoul, Korea. In the experiments, we will show the implemented system using IPTV and a mobile phone, as well as the experiment results of the measured CPU overhead and mixing time in our system.},
  keywords={},
  doi={10.1109/JSYST.2013.2258745},
  ISSN={1937-9234},
  month={March},}@INPROCEEDINGS{8418099,
  author={Kyriazis, Dimosthenis},
  booktitle={2018 32nd International Conference on Advanced Information Networking and Applications Workshops (WAINA)}, 
  title={BYOS: Bring Your Own Security in Clouds and Service Oriented Infrastructures}, 
  year={2018},
  volume={},
  number={},
  pages={374-379},
  abstract={Cloud computing is widely being used by users, tenants and enterprises. However, the major concern and barrier for its adoption are the security and privacy concerns of end users. To this end, in this paper an approach is presented that proposes the use of security mechanisms, as plugins that are custom / tailored and potentially developed by the end users themselves. The latter is proposed as a means to overcome users concerns about the quality of security offered by the providers through their deployed security and privacy measures. As a concept, it builds on top of the well-established Bring Your Own Device (BYOD) paradigm and adopts it in the context of security and privacy. The potential challenges and an architecture with the corresponding key building blocks that address these challenges are presented.},
  keywords={},
  doi={10.1109/WAINA.2018.00114},
  ISSN={},
  month={May},}@INPROCEEDINGS{7391921,
  author={Sudipta Singha Roy and Tamjid Haque Sarker and Hashem, M. M. A.},
  booktitle={2015 2nd International Conference on Electrical Information and Communication Technologies (EICT)}, 
  title={A novel trust measurement system for cloud-based marketplace}, 
  year={2015},
  volume={},
  number={},
  pages={49-54},
  abstract={Cloud Computing is an enormously growing phenomenon in the present days enabling IT related services to run in a more dynamic and scalable way than the previous days and cloud marketplace is becoming more competitive with the entrance of new cloud service providers (CSP) offering similar functionalities. The basic obstacles in the way of success of cloud marketplace are the numerous shortcomings in reliable monitoring and identifying reliable cloud service provider based on consumers' preferred services. In this paper, a multi-faceted Entrusted Trust Management (ETM) system architecture is introduced that can support the customers in reliably choosing the trustworthy cloud service provider (CSP) as well as properly weight the information sources that provide feedbacks about the quality of services (QoS) of the CSPs. This ETM system works on several issues to measure the trust value of the providers on specific domain and overall trust value. Firstly, measurement of the trust value of the specific domain of provider on the basis of certainty and uncertainty. Secondly, measurement of overall trust value of the provider from these domain specific trust values. Thirdly, measurement of “Degree of Conflict” between the rating/feedback of consumers and experts. And finally, measurement of trustworthiness of the information sources which provide the rating of the provider on the basis of the SLA between the provider and the consumer. At last, our proposed system is experimented using real datasets.},
  keywords={},
  doi={10.1109/EICT.2015.7391921},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9569577,
  author={Li, Guo and Liu, Ling and Liang, Zhengping and Ma, Xiaoliang and Zhu, Zexuan},
  booktitle={2021 IEEE 32nd Annual International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC)}, 
  title={Memetic Algorithm Based on Community Detection for Energy-Efficient Service Migration Optimization in 5G Mobile Edge Computing}, 
  year={2021},
  volume={},
  number={},
  pages={1-7},
  abstract={Mobile edge computing (MEC) can supplement cloud computing by helping to overcome the limitations of long physical transmission distances and accelerating the responsiveness of edge computing servers. In 5G (fifth generation) cellular networks, adopting MEC can guarantee ultralow latency. To enhance the MEC quality, optimization of the user service profile migration according to the user mobility is essential. However, this optimization establishes an NP-hard problem. Moreover, high-speed 5G base stations with MEC servers often experience high energy consumption. As conventional service migration algorithms such as those based on profile tracking and game theory tend to fall in local optima and neglect energy consumption constraints, we propose a memetic algorithm based on community detection local search (MA-CDLS) to continuously optimize the service migration in 5G MEC scenarios. During busy periods or in crowded areas, MA-CDLS adopts a single-objective optimization of user-perceived latency to achieve high-performance 5G services. During light-load periods or in uncrowded areas, MA-CDLS uses two measures, namely the user-perceived latency and energy consumption, to realize energy-efficient 5G services. MA-CDLS effectively reduces the search space and speeds up the elite selection in the meme operator. Experiments in simulated scenarios show that MA-CDLS achieves a lower user-perceived latency and energy consumption, than the traditional profile tracking and game theory methods, especially during congestion.},
  keywords={},
  doi={10.1109/PIMRC50174.2021.9569577},
  ISSN={2166-9589},
  month={Sep.},}@INPROCEEDINGS{7983102,
  author={Ekanayake, Wijaya and Amarasinghe, Heli and Karmouch, Ahmed},
  booktitle={2017 14th IEEE Annual Consumer Communications & Networking Conference (CCNC)}, 
  title={SDN-based IaaS for mobile computing}, 
  year={2017},
  volume={},
  number={},
  pages={179-184},
  abstract={Mobile Cloud Computing enables resource limited mobile devices to support rich application services. Among three types of cloud services, Infrastructure-as-a-Service (IaaS) clouds provides compute infrastructure for mobile applications on demand. In IaaS-based mobile clouds, latency and bandwidth requirements can considered as critical factors impacting Quality of Service (QoS). Opposed to centralized clouds, geographically distributed clouds realize higher QoS benefiting the proximity to the end user. In this paper, we propose an IaaS framework with regional datacenters for mobile clouds. With the benefits of software-defined networking (SDN), we address impacts on QoS during mobility by serving mobile user via the optimum datacenter. A test-bed was developed to measure the performance of service allocation and relocation in proposed framework.},
  keywords={},
  doi={10.1109/CCNC.2017.7983102},
  ISSN={2331-9860},
  month={Jan},}@INPROCEEDINGS{7816920,
  author={Falasi, Asma Al and Serhani, Mohamed Adel},
  booktitle={2016 Intl IEEE Conferences on Ubiquitous Intelligence & Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People, and Smart World Congress (UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld)}, 
  title={SLA Specification and Negotiation Model for a Network of Federated Clouds: CloudLend}, 
  year={2016},
  volume={},
  number={},
  pages={772-779},
  abstract={The Cloud computing paradigm is remarkably evolving. Cloud customers have become more conscious about the QoS expectation from Cloud providers' services. Accordingly, Cloud providers are required to be responsive to customers' demands, be open to establishing federations with other providers in order to retain their shares in the competitive Cloud market. Cloud customers are always searching for optimized services, irrespective of which providers are taking part in a federation to deliver these services. They seek federated Cloud services to attain the maximum satisfaction level, which is measured by the degree of adherence to customers' quality of service (QoS). Such federations of Cloud services are typically governed by service level agreements (SLAs) that are negotiated between the Cloud customer, provider prior to service provisioning. This paper tackles the challenges related to SLA specification, negotiation in a federated network of Clouds, CloudLend. We first propose a weighted SLA specification model that captures customers' QoS, manages multi-level SLAs specification. We then introduce an autonomous SLA negotiation model that adopts an enhanced fair division game. The model enables federated Cloud services to examine SLAs, react to SLA offers, eventually sign an SLA contract. It autonomously detects changes in Clouds federations, revises SLA specifications accordingly. The proposed model is evaluated using a CloudLend simulator, which we developed for this purpose. Several test cases were executed,, the results we have achieved verified the fairness, efficiency of our proposed SLA specification, negotiation models in CloudLend.},
  keywords={},
  doi={10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0124},
  ISSN={},
  month={July},}@INPROCEEDINGS{9443978,
  author={Yu, Zhixing and He, Kejing and Chen, Chao and Wang, Jian},
  booktitle={2020 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)}, 
  title={Live Container Migration via Pre-restore and Random Access Memory}, 
  year={2020},
  volume={},
  number={},
  pages={102-109},
  abstract={Container technology is increasingly being used for virtualization due to its ability to isolate the operating environment of the program. In cloud computing environment, we need to migrate containers between different hosts for load balancing or downtime maintenance. However, during the migration process, the container will be temporarily shut down, and the service will be unavailable. Therefore, the time cost is an essential indicator to measure the quality of the migration process. To achieve live container migration, we propose a pre-restore method and a complete random access memory (RAM) based method to migrate containers. Extensive experiments validate the effectiveness of our methods in reducing downtime and improving the efficiency of container migration.},
  keywords={},
  doi={10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00039},
  ISSN={},
  month={Dec},}@ARTICLE{7343819,
  author={Liu, Jiangchuan and Zhu, Wenwu and Ebrahimi, Touradj and Apostolopoulos, John and Hua, Xian-Sheng and Wu, Chuan},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Introduction to the Special Section on Visual Computing in the Cloud: Fundamentals and Applications}, 
  year={2015},
  volume={25},
  number={12},
  pages={1885-1887},
  abstract={Cloud computing involves a large number of terminals connected through a real-time high-speed network (such as the Internet). The adoption rates for private and hybrid cloud services increased to 40% in 2013, with computing shifting from on-premise infrastructure to the cloud. To keep pace with the ever-accelerating rate of innovation, companies are moving to the cloud. However, visual computing in the cloud brings great challenges, such as how to measure and then improve the quality of experience in cloud computing. This Special Section provides the image/video community a forum to present new academic research and industrial development in running visual computing services in the cloud. This Special Section aims to address fundamental and practical aspects of visual computing in the cloud, such as how to build cloud platforms that can cope with seemingly unlimited supply of content coming from traditional media sources as well as new media uploaded to the Internet (YouTube, Facebook, etc.); how to leverage cloud technology to build high-quality image/video browsing and delivery experiences for a global audience; how to ingest, encode, process, adapt, as well as protect contents and privacy of users; how to provide both on-demand and live-streaming capabilities; how to tag image/video and allow consumers to access the image/video contents with high availability; how to support image/video services in mobile devices; and how to perform real-time image/video analytics in the cloud, to mention a few among a diverse range of challenges.},
  keywords={},
  doi={10.1109/TCSVT.2015.2472955},
  ISSN={1558-2205},
  month={Dec},}

@INPROCEEDINGS{10355514,
  author={Samarakoon, Sahan and Bandara, Shashika and Jayasanka, Nishan and Hettiarachchi, Chathuranga},
  booktitle={2023 Moratuwa Engineering Research Conference (MERCon)}, 
  title={Self-Healing and Self-Adaptive Management for IoT-Edge Computing Infrastructure}, 
  year={2023},
  volume={},
  number={},
  pages={473-478},
  abstract={Containerized micro-service oriented computing deployment strategies have proven to possess resilience, selfadaptive, and self-healing properties in cloud computing environments. The rapid growth of smart Internet of Things (IoT) deployments necessitates a similar approach to mitigate the challenges associated with manually managing large fleets of IoT devices. To address these challenges, we propose a novel software framework that extends Kubernetes(K8s) to collect and integrate IoT device performance metrics. By leveraging this framework, a set of self-healing and self-adaptive strategies can be deployed, taking into account the status of IoT devices. In our research, we evaluate the impact of IoT device-to-edge compute latency, bandwidth, and jitter information using the proposed software framework, including a metrics collection plugin and a custom scheduler. The results demonstrate significant enhancements in Quality of Service measures for a benchmark application scenario, emphasizing the framework’s ability to reduce manual intervention efforts through extended adaptation strategies.},
  keywords={},
  doi={10.1109/MERCon60487.2023.10355514},
  ISSN={2691-364X},
  month={Nov},}@INPROCEEDINGS{10329061,
  author={Nguyen, Michael and Sood, Kanika and Avery, Kenytt and Bein, Doina},
  booktitle={2023 5th International Conference on Robotics and Computer Vision (ICRCV)}, 
  title={Deep Learning-based Super-Resolution on the Cloud: Focus on Face and Text Enhancement}, 
  year={2023},
  volume={},
  number={},
  pages={124-129},
  abstract={Real-ESRGAN and SwinIR are two deep learning models for Single-Image Super-Resolution (SISR), which attempt to address real-world scenarios for image enhancement. However, the pre-trained models do not effectively handle LR images containing human faces and text. An experiment is conducted to expand upon the training performed in their respective studies and improve the image enhancement using a cloud computing environment. Traditional image quality metrics, Peak Signal-toNoise Ratio (PSNR), and Structural Similarity (SSIM), are used to objectively evaluate the image quality. Three learning-based perceptual metrics, the Blind / Referenceless Image Spatial Quality Evaluator (BRISQUE), Naturalness Image Quality Evaluator (NIQE), and the Learned Perceptual Image Patch Similarity (LPIPS), are also incorporated to assess how images would be subjectively perceived based on human perception. To evaluate the model performance of Real-ESRGAN and SwinIR, specifically for face and text images, both traditional and perceptual metrics are taken into consideration, in addition to the cost associated with model training using Microsoft Azure. The findings show that with additional fine-tuning, SwinIR has slightly improved PSNR and SSIM values while taking less training time compared to Real-ESRGAN at the cost of perceptual quality.},
  keywords={},
  doi={10.1109/ICRCV59470.2023.10329061},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9744289,
  author={Volkov, A. O. and Korobkina, A. V. and Stepanov, S. N.},
  booktitle={2022 Systems of Signals Generating and Processing in the Field of on Board Communications}, 
  title={Development of a Model and Algorithms for Servicing Real-Time and Data Traffic in a Cloud Computing System}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={Today, modern low earth orbit (LEO) mobile satellite systems require constant data exchange with cloud computing centers located on Earth to work correctly. Moreover, there is both real-time data transmission and data that allows for a delay, this, for example, may be telemetry data. In the described model the key performance features of the conjoint traffic processing were defined. They are defined using values of probabilities of the model’s stationary states. The numerical algorithm of measuring of designed performance metrics by solving the state equations system with the help of the Gauss-Zeidel algorithm is presented. The model and the resulting algorithms can be used to assess the service quality and load levels of a small cloud computing node. One of the possible options for future research on this topic may be to restrict the access of applications for data processing to prioritize the processing of real-time applications.},
  keywords={},
  doi={10.1109/IEEECONF53456.2022.9744289},
  ISSN={2768-0118},
  month={March},}@INPROCEEDINGS{9972509,
  author={Rajesh, K.N.V.S.S.K. and Redd, K. Thammi and Murthy, N.V.E.S. and Sarma, M. Subrahmanya},
  booktitle={2022 IEEE 2nd Mysore Sub Section International Conference (MysuruCon)}, 
  title={Augmenting Additional Quality of Services for Adaptability and Reliability of Cloud Infrastructure}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Adoption of Cloud computing has been increased by multi fold in the recent past in order to cope up with business requirements. There are few Quality of Service (QoS) metrics which augment the availability of cloud hosted applications. However, still there are quite a few challenges to be addressed in order to improve degree of trust in cloud computing. One of the key challenges observed is, there were no quality of services (QoS) metrics augmented with the PaaS which checks certain parameters covering Disk space utilization and Memory utilization etc., which are the root cause for any priority incidents pertaining to cloud hosted service availability. This paper aims to study the current quality of services available and augment additional quality of services to scale up the services for need of the hour requirements covering site reliability engineering (SRE). Experimentation has been done with the help of major cloud services platforms such as AWS and results were analyzed and attached to this paper.},
  keywords={},
  doi={10.1109/MysuruCon55714.2022.9972509},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10346675,
  author={Alkhazali, Abdel Rahman Mohammad and Khasawneh, Ahmad M. and Alzoubi, Sharaf and Magableh, Murad and Mohamed, Rajina R. and Pandey, Bishwajeet},
  booktitle={2023 International Conference on Computer Science and Emerging Technologies (CSET)}, 
  title={Cloud Computing in Smart Cities: Privacy, Ethical and Social Issues}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={The rapid development of cloud computing technologies has revolutionized various sectors, and smart cities are no exception. Smart cities leverage cloud computing to optimize urban services, enhance resource management, and improve the overall quality of life for their inhabitants. However, as these technological advancements proliferate, concerns about privacy, ethical considerations, and social implications have emerged. This research paper critically examines the multifaceted challenges associated with the integration of cloud computing in smart cities, shedding light on the potential risks and highlighting the need for comprehensive solutions. The research employs a mixed-methods approach, combining quantitative data analysis and qualitative case studies to offer a comprehensive perspective on the identified issues. The primary focus lies in identifying privacy risks, ethical dilemmas, and social disparities that arise due to the extensive use of cloud-based systems and data in smart cities. Furthermore, the study investigates the role of key stakeholders, including governments, technology providers, and citizens, in mitigating or exacerbating these challenges. Key findings reveal that while cloud computing empowers smart cities with unparalleled capabilities, it also exposes residents' personal information to potential breaches and misuse. Ethical concerns arise from the handling of sensitive data, data ownership, and algorithmic biases that could perpetuate discrimination. Moreover, social issues like the digital divide and access disparities may further exacerbate existing inequalities in smart city implementation. This research paper concludes by proposing a comprehensive framework of guidelines and best practices to address the identified issues effectively. These recommendations encompass enhanced data privacy measures, transparent and accountable data governance, the promotion of ethical data usage, and inclusive strategies to bridge social disparities. By adopting these measures, smart cities can harness the full potential of cloud computing while safeguarding individual rights and fostering a more equitable and inclusive urban environment. Overall, this study underscores the critical importance of addressing privacy, ethical, and social challenges in the context of cloud computing in smart cities. By adopting a holistic and proactive approach, city planners, policymakers, and technology providers can build sustainable and responsible smart cities that ensure the well-being and dignity of their residents in the digital era.},
  keywords={},
  doi={10.1109/CSET58993.2023.10346675},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10078974,
  author={Li, Qixiu},
  booktitle={2022 2nd International Conference on Networking, Communications and Information Technology (NetCIT)}, 
  title={Construction of Agricultural Economic Data Management and Service Platform Based on Improved Genetic Algorithm}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={As a large agricultural country, agriculture is the foundation of China's national economy. Agricultural informatization construction is a major measure to strengthen the basic position of agriculture and promote the new agricultural scientific and technological revolution. It is of great significance to develop agricultural economy and promote the construction of a new socialist countryside. With the rise and continuous improvement of cloud computing, it has brought new inspiration to the construction of agricultural informatization. Cloud computing is the latest network information technology at present. It creates a new model of serving computing resources, storage resources and information resources under the condition of rapid network development, so that information can spread at a high speed, so that farmers can get better agricultural technology and more agricultural information resources in the shortest time, so as to greatly improve the agricultural economy. In recent years, the new cloud computing technology provides a new method and feeling for the construction of agricultural economic management information service platform. In order to realize the rapid acquisition of a variety of information resources and the sharing of information data, and improve the service level and service quality of agricultural information, taking the new IT resource model “cloud computing” as the starting point, computing and big data are distributed on computers all over the country. People can easily obtain applications, data and resources through mobile phones, computers and other services. Relying on cloud computing technology, the agricultural economic management information service platform can not only give full play to the township Internet and call rate with high coverage in China, but also realize unlimited capacity storage, fast and high-speed operation and fast and efficient information transmission that cannot be realized by traditional technology without pressure. So as to realize the convenient access and comprehensive sharing of a variety of information resources, and improve the level and quality of agricultural information services.},
  keywords={},
  doi={10.1109/NetCIT57419.2022.00105},
  ISSN={},
  month={Dec},}@ARTICLE{8937836,
  author={Lin, Weiwei and Wu, Wentai and He, Ligang},
  journal={IEEE Transactions on Services Computing}, 
  title={An On-Line Virtual Machine Consolidation Strategy for Dual Improvement in Performance and Energy Conservation of Server Clusters in Cloud Data Centers}, 
  year={2022},
  volume={15},
  number={2},
  pages={766-777},
  abstract={As data centers are consuming massive amount of energy, improving the energy efficiency of cloud computing has emerged as a focus of research. However, it is challenging to reduce energy consumption while maintaining system performance without increasing the risk of Service Level Agreement violations. Most of the existing consolidation approaches for virtual machines (VMs) consider system performance and Quality of Service (QoS) metrics as constraints, which usually results in large scheduling overhead and impossibility to achieve effective improvement in energy efficiency without sacrificing some system performance and cloud service quality. In this article, we first define the metrics of peak power efficiency and optimal utilization for heterogeneous physical machines (PMs). Then we propose Peak Efficiency Aware Scheduling (PEAS), a novel strategy of VM placement and reallocation for achieving dual improvement in performance and energy conservation from the perspective of server clusters. PEAS allocates and reallocates VMs in an on-line manner and always attempts to maintain PMs working in their peak power efficiency via VM consolidation. Extensive experiments on Cloudsim show that PEAS outperforms several energy-aware consolidation algorithms with regard to energy consumption, system performance as well as multiple QoS metrics.},
  keywords={},
  doi={10.1109/TSC.2019.2961082},
  ISSN={1939-1374},
  month={March},}@INPROCEEDINGS{9964896,
  author={Jônatas dos Passos, Edenilson and Fiorese, Adriano},
  booktitle={2022 18th International Conference on Network and Service Management (CNSM)}, 
  title={Monitoring Metrics for Load Balancing over Video Content Distribution Servers}, 
  year={2022},
  volume={},
  number={},
  pages={247-253},
  abstract={Cloud computing and video streaming services have been in constant expansion in recent years. Along with it, the demand for computing resources has also increased significantly. In this context, monitoring the use of these resources is crucial to maintain a satisfactory level of Quality of Service and, consequently, Quality of Experience, especially in video transmission services. This work discusses a new method of monitoring resources and quality of service metrics on content servers involving CPU utilization and server throughput, which is obtained in a distributed way. For that, a distributed collector system that is based on a modified version of the ring election algorithm is developed to retrieve the Quality of Service metrics in each server. Evaluation experiment results show that there are no performance gains on the system such as the content loading faster for the user, there are however, improvements in terms of the whole system scalability. The greater the number of servers for monitoring, the better the approach is compared to the traditional method of monitoring resources through request and response.},
  keywords={},
  doi={10.23919/CNSM55787.2022.9964896},
  ISSN={2165-963X},
  month={Oct},}@INPROCEEDINGS{9793442,
  author={Mangalampalli, Sudheer and Pokkuluri, Kiran Sree and Satish, G. Naga and Swain, Sangram Keshari},
  booktitle={2022 International Conference on Computing, Communication and Power Technology (IC3P)}, 
  title={Effective VM Placement Mechanism in Cloud Computing using Cuckoo Search Optimization}, 
  year={2022},
  volume={},
  number={},
  pages={238-241},
  abstract={Effective VM placement mechanism is needed for Cloud Computing as incoming flow of tasks were dynamic when they are coming onto cloud console. Incoming requests for any cloud console were large in number then there is a chance of decay in quality of service. Quality of service will be degraded when these number of requests were not properly handled i.e. SLA violations and more number of migrations. Quality of Service will be directly affected by these parameters. Many of the authors addressed these metrics but still there is a chance to improve the VM placement in cloud computing. In this paper, we have used a nature inspired algorithm i.e. cuckoo search to design the VM placement strategy and we have used a threshold value to identify the physical host whet her it is overloaded, under loaded or balanced based on the utilization of CPU. Cloudsim toolkit is used as a simulator to conduct simulation and our proposed mechanism minimizes violation of SLA and there is a great improvement in makespan when it was compared with PSO and GA algorithms.},
  keywords={},
  doi={10.1109/IC3P52835.2022.00057},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{9779689,
  author={Vale, Guilherme and Correia, Filipe Figueiredo and Guerra, Eduardo Martins and de Oliveira Rosa, Thatiane and Fritzsch, Jonas and Bogner, Justus},
  booktitle={2022 IEEE 19th International Conference on Software Architecture (ICSA)}, 
  title={Designing Microservice Systems Using Patterns: An Empirical Study on Quality Trade-Offs}, 
  year={2022},
  volume={},
  number={},
  pages={69-79},
  abstract={The promise of increased agility, autonomy, scalability, and reusability has made the microservices architecture a de facto standard for the development of large-scale and cloud-native commercial applications. Software patterns are an important design tool, and often they are selected and combined with the goal of obtaining a set of desired quality attributes. However, from a research standpoint, many patterns have not been widely validated against industry practice, making them not much more than interesting theories. To address this, we investigated how practitioners perceive the impact of 14 patterns on 7 quality attributes. Hence, we conducted 9 semi-structured interviews to collect industry expertise regarding (1) knowledge and adoption of software patterns, (2) the perceived architectural trade-offs of patterns, and (3) metrics professionals use to measure quality attributes. We found that many of the trade-offs reported in our study matched the documentation of each respective pattern, and identified several gains and pains which have not yet been reported, leading to novel insight about microservice patterns.},
  keywords={},
  doi={10.1109/ICSA53651.2022.00015},
  ISSN={},
  month={March},}@ARTICLE{9238484,
  author={Mahmoudi, Nima and Khazaei, Hamzeh},
  journal={IEEE Transactions on Cloud Computing}, 
  title={Performance Modeling of Serverless Computing Platforms}, 
  year={2022},
  volume={10},
  number={4},
  pages={2834-2847},
  abstract={Analytical performance models have been leveraged extensively to analyze and improve the performance and cost of various cloud computing services. However, in the case of serverless computing, which is projected to be the dominant form of cloud computing in the future, we have not seen analytical performance models to help with the analysis and optimization of such platforms. In this work, we propose an analytical performance model that captures the unique details of serverless computing platforms. The model can be leveraged to improve the quality of service and resource utilization and reduce the operational cost of serverless platforms. Also, the proposed performance model provides a framework that enables serverless platforms to become workload-aware and operate differently for different workloads to provide a better trade-off between the cost and performance depending on the user's preferences. The current serverless offerings require the user to have extensive knowledge of the internals of the platform to perform efficient deployments. Using the proposed analytical model, the provider can simplify the deployment process by calculating the performance metrics for users even before physical deployments. We validate the applicability and accuracy of the proposed model by extensive experimentation on AWS Lambda. We show that the proposed model can calculate essential performance metrics such as average response time, probability of cold start, and the average number of function instances in the steady-state. Also, we show how the performance model can be used to tune the serverless platform for each workload, which will result in better performance or lower cost without scarifying the other. The presented model assumes no non-realistic restrictions, so that it offers a high degree of fidelity while maintaining tractability at large scale.},
  keywords={},
  doi={10.1109/TCC.2020.3033373},
  ISSN={2168-7161},
  month={Oct},}@INPROCEEDINGS{10294685,
  author={Bai, Yiming and Chen, Lei and Lei, Ying and Xie, Hongjuan},
  booktitle={2023 5th International Conference on Data-driven Optimization of Complex Systems (DOCS)}, 
  title={A Deep Learning Prediction Approach for Machine Workload in Cloud Computing}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={Accurate workload prediction for cloud computing clusters is essential to ensure Quality of Service (QoS), meet Service Level Agreements (SLAs), and minimize energy consumption. In a cloud computing environment, cloud servers collect and store large sets of time series data, including metrics such as CPU usage, network traffic, and disk I/O at each point in time. The fluctuations in these metrics show noticeable temporal correlations. Therefore, these data can be used in time series data prediction models to predict upcoming workload scenarios. However, traditional statistical methods have limitations such as requiring manual feature extraction, high data requirements, and limited generalizability, leading to inaccurate predictions. In addition, most standard deep learning models ignore the problem of sequence noise. To overcome these hurdles, we have created a hybrid deep learning model utilizing advanced techniques. This model integrates Time Convolutional Networks (TCN), Gated Recurrent Units (GRU), and self-attention mechanism to achieve a more accurate workload prediction. Additionally, we perform a comparative analysis of different methods during the preprocessing stage and select the optimal one to effectively remove noise from the original sequences. Experimental results demonstrate that our proposed model outperforms other workload prediction algorithms in terms of prediction accuracy.},
  keywords={},
  doi={10.1109/DOCS60977.2023.10294685},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10083635,
  author={S, Savitha and C, Sangana and K, Devendran and L, Pravin and M, Rajkumar and C, Nirmal},
  booktitle={2023 7th International Conference on Computing Methodologies and Communication (ICCMC)}, 
  title={Auto Scaling Infrastructure with Monitoring Tools using Linux Server on Cloud}, 
  year={2023},
  volume={},
  number={},
  pages={45-52},
  abstract={Cloud computing is the term that has gained widespread usage over these last few years. Due to the rapid increase in the use of information in the digital age of the 21st century, it is increasingly becoming a more attractive option for individuals and organizations to manage all their essential data, projects, and collaborations, rather than relying solely on in-house computers. The user's requirement for hardware and software is reduced via cloud computing. The interface software of cloud computing systems, typically as simple as a web browser, is the only thing the user must operate, and the Cloud network handles the rest. To decrease operational costs, both business and government organizations are adopting cloud computing, seeking a flexible and adaptable solution for the supply and delivery of their product services. Microservices and decoupled apps are becoming more popular. These container-based architectures make it easier to build sophisticated SaaS apps quickly, but managing and creating microservices can be a daunting task. Managing and creating microservices that involve a wide range of diverse functions, including handling and storing information, and performing predictive and prescriptive analysis, can be a challenging undertaking. Establishing auto scaling infrastructure on doud can be challenging due to several reasons, some of which are: understanding the application architecture, setting up monitoring, scaling policies, cost optimization and implementation complexity. Server farms include the tremendous and heterogeneous virtualized frameworks, which are continually extending and broadening after sometime are the essential starting point for registering specialized organizations. These solutions also need to be integrated into existing systems while adhering to Quality of Service (QoS) requirements. The principal objective of this work is to propose an on-premise design to leverage Kubernetes and Docker containers to improve the quality of service based on resource usage and Service Level Objectives (SLOs). The Prometheus Administrator set up is used to perform namespace checking. Normally, doud providers enable their own monitoring tools (like CloudWatch) for monitoring CPU, storage and network usage, service component, however these tools cannot monitor the service component. Additionally, the advancements have restricted the capacity to follow QoS highlights at the application level (like security and execution) since the main focus will be dedicated towards the equipment assets. These types of node-level monitoring make it difficult to scale requests and deploy pods to match the demand. Infrastructure monitoring should enable runtime changes to monitor the requirements or metric operationalization should be done on those criteria without modifying the underlying infrastructure.},
  keywords={},
  doi={10.1109/ICCMC56507.2023.10083635},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10140844,
  author={Mishra, Praveen Kumar and Chaturvedi, Amit Kumar},
  booktitle={2023 International Conference on Computational Intelligence, Communication Technology and Networking (CICTN)}, 
  title={Research Challenges in Job Scheduling and Resource Distribution Methodology for Cloud Fog Atmosphere: An Organized Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={292-299},
  abstract={The IoT technology applications have become the most important technologies used internationally to encourage communication between humans and objects and enhance quality of life in recent years. This will lead to an increase in the variety of devices used in such applications, which will produce massive amounts of data. In 2012, Cisco made the first mention of fog computing, which sits between individual consumers (IoT devices) and cloud computing. Fog computing enhances cloud computing’s effectiveness, lessens its drawbacks, and offers storage and processing capacities at the edge, despite the fact that it is not a cloud computing solution. Resource management has a significant role in determining how well fog computing performs. Scheduling is essential to manage supplies in fog layer, which is the capability to match jobs to the suitable useful resources. As we know that the job is a minor component with a bigger undertaking with a deadline. Fog computing leverages distributed and heterogeneous resources, making task scheduling challenging. Numerous recommended scheduling algorithms have been produced in previous years; the maximum of them were engaged in scalability to fog computing. This study’s major goal is to extensively examine and evaluate the most important existing scheduling approaches in terms of their main context, advantages, limitations and performance measures. The analysis is presented in proportion of categories of algorithm and usage of parameters for measure of performance in fog.},
  keywords={},
  doi={10.1109/CICTN57981.2023.10140844},
  ISSN={},
  month={April},}@INPROCEEDINGS{10196549,
  author={Mokhtari, Ali and Rawls, Drake and Huynh, Tony and Green, Jeremiah and Salehi, Mohsen Amini},
  booktitle={2023 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={E2C: A Visual Simulator to Reinforce Education of Heterogeneous Computing Systems}, 
  year={2023},
  volume={},
  number={},
  pages={270-277},
  abstract={Heterogeneity has been an indispensable aspect of distributed computing throughout the history of these systems. ln particular, with the increasing popularity of accelerator technologies (eg., GPUs and TPUs) and the emergence of domain-specific computing via ASlCs and FPGA, the matter of heterogeneity and understanding its ramifications on the system performance has become more critical than ever before. However, it is challenging to effectively educate students about the potential impacts of heterogeneity on: (a) the performance of distributed systems; and (b) the logic of resource allocation methods to efficiently utilize the resources. Making use of the real infrastructure (such as those offered by the public cloud providers) for benchmarking the performance of heterogeneous machines, for different applications, with respect to different obiectives, and under various workload intensities is cost- and time-prohibitive. Moreover, not all students (globally and nationally) have access or can afford such real infrastructure. To reinforce the quality of learning about various dimensions of heterogeneity, and to decrease the widening gap in education, we develop an open-source simulation tool, called E2C, that can help students researchers and practitioners to study any type of heterogeneous (or homogeneous) computing system and measure its performance under various system configurations. To make the learning curve shallow, E2C is equipped with an intuitive graphical user interface (GU1) that enables its users to easily examine system-level solutions (scheduling, load balancing, scalability, etc.) in a controlled environment within a short time and at no cost. In particular, E2C is a discrete event simulator that offers the following features: (i) simulating a heterogeneous computing system; (ii) implementing a newly developed scheduling method and plugging it into the system, (iii) measuring energy consumption and other output-related metrics; and (iv) powerful visual aspects to ease the learning curve for students. We used E2C as an assignment in the Distributed and Cloud Computing course. Our anonymous survey study indicates that students rated E2C with the score of 87 out of 10 for its usefulness in understanding the concepts of scheduling in heterogeneous computing. Moreover, our pre- and post-evaluations indicate that E2C has improved the students’ understanding of heterogeneous computing systems by around 18%.},
  keywords={},
  doi={10.1109/IPDPSW59300.2023.00052},
  ISSN={},
  month={May},}@INPROCEEDINGS{10008330,
  author={Al-Shammare, Haifa and Al-Otaiby, Nehal},
  booktitle={2022 14th International Conference on Computational Intelligence and Communication Networks (CICN)}, 
  title={An Implementation of a New Proposed Round-Robin Algorithm with Smart Time Quantum in Cloud Computing Environment}, 
  year={2022},
  volume={},
  number={},
  pages={289-296},
  abstract={The popularity of cloud computing platforms has risen dramatically in recent years. As cloud computing serves millions of users at the same time, it must be able to handle all those users' demands efficiently. Thus, choosing a suitable scheduling algorithm is crucial in the cloud computing environment in order to ensure efficient performance with a reasonable degree of quality of service (QoS). The primary goal of this research is to empirically implement and evaluate a recently proposed Round-Robin algorithm with smart time quantum (RR-STQ) in a cloud computing environment, as well as, to enhance the RR-STQ with a dynamic smart time quantum. The CloudSim tool was used to simulate the cloud computing platform to implement RR-STQ and evaluate it with several algorithms using different scenarios. In addition, three scheduling performance metrics were used in the evaluation process. In all comparison scenarios, the (RR-STQ) achieved a significant improvement rate in terms of average response time (RT). Moreover, (RR-STQ) has a better performance in the average turnaround time (TAT), waiting time (WT), and response time (RT) than the traditional RR algorithm. Also, the implemented algorithm (RR-STQ) with dynamic time quantum has a better performance than static time quantum. Based on the evaluation results, it is beneficial to integrate the RR algorithm with other scheduling models such as shortest job first (SJF) to enhance the WT and TAT. Furthermore, the investigations revealed that the dynamic time quantum improves the performance of the RR algorithm.},
  keywords={},
  doi={10.1109/CICN56167.2022.10008330},
  ISSN={2472-7555},
  month={Dec},}@ARTICLE{10274948,
  author={Al-Eidi, Shorouq and Amsaad, Fathi and Darwish, Omar and Tashtoush, Yahya and Alqahtani, Ali and Niveshitha, Niveshitha},
  journal={IEEE Access}, 
  title={Comparative Analysis Study for Air Quality Prediction in Smart Cities Using Regression Techniques}, 
  year={2023},
  volume={11},
  number={},
  pages={115140-115149},
  abstract={In smart cities, air pollution has detrimental impacts on human physical health and the quality of living environment. Therefore, correctly predicting air quality plays an important effective action plan to mitigate air pollution and create healthier and more sustainable environments. Monitoring and predicting air pollution is crucial to empower individuals to make informed decisions that protect their health. This research presents a comprehensive comparative analysis focused on air quality prediction using three distinct regression techniques- Random Forest regression, Linear regression, and Decision Tree regression. The main goal of this study is to discern the most effective model by considering a range of evaluation criteria, including Mean Absolute Error and  $R^{2}$  measures. Moreover, it considers the crucial aspects of minimizing prediction errors and enhancing computational efficiency by evaluating the regression models within two frameworks. The findings of this study underscore the superiority of the Decision Tree regression approach over the other models, demonstrating its exceptional accuracy with a high  $R^{2}$  score and a minimal error rate. Moreover, integrating cloud computing technology has resulted in substantial improvements in the execution time of these approaches. This technology enhancement significantly affects the overall efficiency of the air quality prediction process. By leveraging distributed computing resources, real-time air quality forecasting becomes feasible, enabling timely decision-making and proactive measures to address air pollution episodes effectively.},
  keywords={},
  doi={10.1109/ACCESS.2023.3323447},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10350465,
  author={Zhang, Yang and Li, Yang and Yang, Yilong and Chen, Shuang and Gao, Juntao and Wang, Weiru and Yin, Yongfeng},
  booktitle={2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)}, 
  title={RapidMS: A Tool for Supporting Rapid Microservices Generation and Refinement from Requirements Model}, 
  year={2023},
  volume={},
  number={},
  pages={45-49},
  abstract={Microservices is a crucial architecture design pat-tern for developing cloud-native applications, which focuses on decomposing a large and complex software system into autonomous components that can be independently developed and deployed. However, microservices design is not a trivial task, which highly depends on the profound knowledge and experience of system design and target domain. This is a challenge for novice software architects. In this paper, we propose a microservices design tool named RapidMS, which only requires architects to specify potential context boundaries on the requirements model. The microservices architecture design model with component structure and interaction views can be automatically generated without extra human effort. Moreover, the proposed tool can automatically calculate the characteristic metrics of the microservices, which indicate the quality of the different aspects of models to support rapid architecture refinements. We demonstrate the tool's effectiveness through five case studies. The experimental result shows that architects can get better decomposition of requirement model within four iterations and over 90% of microservice architecture diagrams can be correctly generated within 10 seconds. RapidMS can be further extended and applied in the software industry to reduce the cost and difficulty of microservices decomposition and design. The tool can be downloaded at https://rm2pt.com/advs/ rapidms, and a demo video casting its features is at https://youtu.be/AoIM41FTnFO},
  keywords={},
  doi={10.1109/MODELS-C59198.2023.00017},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10302780,
  author={Yιlmaz, Ömer Zekvan and Alagöz, Fatih},
  booktitle={2023 14th International Conference on Network of the Future (NoF)}, 
  title={Shared Network Function Placement for Cloud Native 5G Core Networks}, 
  year={2023},
  volume={},
  number={},
  pages={103-107},
  abstract={Providing adequate operating resources for Network Functions (NFs) with minimal costs has been one of the primary concerns for cloud providers. The adequate operating resources definition has to cover the quality of service (QoS) constraints, which result in ‘underutilized resources’. Studies in the NF placement domain that make use of these resources through sharing, employ NP-Hard algorithms. In this study, we propose an NF placement scheme called Cloud Native Network Function Sharing (CNFSH) using a priority-based load balancer and a polynomial time algorithm for dynamic 5G settings. Using CNFSH, the number of satisfied slice requests increases by 36%, and the average resource consumption per network slice drops by 28% compared to the NoShare model. Besides being dynamic and sustainable, CNFSH outperforms a previous sharing scheme [1], with 5% success rate for both of the metrics.},
  keywords={},
  doi={10.1109/NoF58724.2023.10302780},
  ISSN={2833-0072},
  month={Oct},}@ARTICLE{8758137,
  author={Azadi, Majid and Emrouznejad, Ali and Ramezani, Fahimeh and Hussain, Farookh Khadeer},
  journal={IEEE Transactions on Cloud Computing}, 
  title={Efficiency Measurement of Cloud Service Providers Using Network Data Envelopment Analysis}, 
  year={2022},
  volume={10},
  number={1},
  pages={348-355},
  abstract={An increasing number of organizations and businesses around the world use cloud computing services to improve their performance in the competitive marketplace. However, one of the biggest challenges in using cloud computing services is performance measurement and the selection of the best cloud service providers (CSPs) based on quality of service (QoS) requirements [13]. To address this shortcoming in this article we propose a network data envelopment analysis (DEA) method in measuring the efficiency of CSPs. When network dimensions are taken into consideration, a more comprehensive analysis is enabled where divisional efficiency is reflected in overall efficiency estimates. This helps managers and decision makers in organizations to make accurate decisions in selecting cloud services. In the current study, the non-oriented network slacks-based measure (SBM) model and conventional SBM model with the assumptions of constant returns to scale (CRS) and variable returns to scale (VRS) are applied to measure the performance of 18 CSPs. The obtained results show the superiority of the network DEA model and they also demonstrate that the proposed model can evaluate and rank CSPs much better than compared to traditional DEA models.},
  keywords={},
  doi={10.1109/TCC.2019.2927340},
  ISSN={2168-7161},
  month={Jan},}@INPROCEEDINGS{10176237,
  author={B K, Jeevitha and J, Thriveni},
  booktitle={2022 IEEE International Conference for Women in Innovation, Technology & Entrepreneurship (ICWITE)}, 
  title={Data Storage Security and Privacy in Cloud Computing}, 
  year={2022},
  volume={},
  number={},
  pages={1-10},
  abstract={The world has seen a quick transition from hard devices for local storage to massive virtual data centers, all possible because of cloud storage technology. Businesses have grown to be scalable, meeting consumer demands on every turn. Cloud computing has transforming the way we do business making IT more efficient and cost effective that leads to new types of cybercrimes. Securing the data in cloud is a challenging task. Cloud security is a mixture of art and science. Art is to create your own technique and technologies in such a way that the user should be authenticated. Science is because you have to come up with ways of securing your application. Data security refers to a broad set of policies, technologies and controls deployed to protect data application and the associated infrastructure of cloud computing. It ensures that the data has not been accessed by any unauthorized person. Cloud storage systems are considered to be a network of distributed data centers which typically uses cloud computing technologies like virtualization and offers some kind of interface for storing data. Virtualization is the process of grouping the physical storage from multiple network storage devices so that it looks like a single storage device.Storing the important data in the cloud has become an essential argument in the computer territory. The cloud enables the user to store the data efficiently and access the data securely. It avoids the basic expenditure on hardware, software and maintenance. Protecting the cloud data has become one of the burdensome tasks in today’s environment. Our proposed scheme "Certificateless Compressed Data Sharing in Cloud through Partial Decryption" (CCDSPD) makes use of Shared Secret Session (3S) key for encryption and double decryption process to secure the information in the cloud. CC does not use pairing concept to solve the key escrow problem. Our scheme provides an efficient secure way of sharing data to the cloud and reduces the time consumption nearly by 50 percent as compared to the existing mCL-PKE scheme in encryption and decryption process.Distributed Cloud Environment (DCE) has the ability to store the da-ta and share it with others. One of the main issues arises during this is, how safe the data in the cloud while storing and sharing. Therefore, the communication media should be safe from any intruders residing between the two entities. What if the key generator compromises with intruders and shares the keys used for both communication and data? Therefore, the proposed system makes use of the Station-to-Station (STS) protocol to make the channel safer. The concept of encrypting the secret key confuses the intruders. Duplicate File Detector (DFD) checks for any existence of the same file before uploading. The scheduler as-signs the work of generating keys to the key manager who has less task to complete or free of any task. By these techniques, the proposed system makes time-efficient, cost-efficient, and resource efficient compared to the existing system. The performance is analysed in terms of time, cost and resources. It is necessary to safeguard the communication channel between the entities before sharing the data. In this process of sharing, what if the key manager’s compromises with intruders and reveal the information of the user’s key that is used for encryption. The process of securing the key by using the user’s phrase is the key concept used in the proposed system "Secure Storing and Sharing of Data in Cloud Environment using User Phrase" (S3DCE). It does not rely on any key managers to generate the key instead the user himself generates the key. In order to provide double security, the encryption key is also encrypted by the public key derived from the user’s phrase. S3DCE guarantees privacy, confidentiality and integrity of the user data while storing and sharing. The proposed method S3DCE is more efficient in terms of time, cost and resource utilization compared to the existing algorithm DaSCE (Data Security for Cloud Environment with Semi Trusted Third Party) and DACESM (Data Security for Cloud Environment with Scheduled Key Managers).For a cloud to be secure, all of the participating entities must be secure. The security of the assets does not solely depend on an individual's security measures. The neighbouring entities may provide an opportunity to an attacker to bypass the user's defences. The data may compromise due to attacks by other users and nodes within the cloud. Therefore, high security measures are required to protect data within the cloud. Cloudsim allows to create a network that contains a set of Intelligent Sense Point (ISP) spread across an area. Each ISPs will have its own unique position and will be different from other ISPs. Cloud is a cost-efficient solution for the distribution of data but has the challenge of a data breach. The data can be compromised of attacks of ISPs. Therefore, in OSNQSC (Optimized Selection of Nodes for Enhanced in Cloud Environment), an optimized method is proposed to find the best ISPs to place the data fragments that considers the channel quality, distance and the remaining energy of the ISPs. The fragments are encrypted before storing. OSNQSC is more efficient in terms of total upload time, total download time, throughput, storage and memory consumption of the node with the existing Betweenness centrality, Eccentricity and Closeness centrality methods of DROPS (Division and Replication of Data in the Cloud for Optimal Performance and Security).},
  keywords={},
  doi={10.1109/ICWITE57052.2022.10176237},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9985529,
  author={Thirunavukkarasu, M. and Shanmugapriya, P.},
  booktitle={2022 4th International Conference on Inventive Research in Computing Applications (ICIRCA)}, 
  title={Energy Efficient Mobile Cloud offloading for Image Processing Applications using Transfer Learning}, 
  year={2022},
  volume={},
  number={},
  pages={910-916},
  abstract={Processing real-time images in the digital era is a complex task that requires the use of more sophisticated tools and consumes more energy. With the introduction of Hybrid model, Mobile and Cloud Computing, called as Mobile and Cloud Computing (MCC), this becomes an easy task in which the end user connects using the virtual instance in the Cloud environment. MCC enable the execution of cloud applications through mobile terminals. However, the mobile devices cannot process high end applications as they have limited energy. We propose Mobile Cloud offloading technique that excludes the execution on the Mobile terminal by deploying the applications on Cloud. Identification and decision on the energy aware applications are playing a vital role to improve Quality of Services (QoS). The proposed model introduces the Transfer Learning- based Energy efficient Mobile Cloud offloading framework. The proposed model predicts whether to move the applications towards the Mobile Cloud environment. The proposed model uses InceptionResNetV2 as pre-trained transfer learning approach.. The CNN based classifier used to classify the type of application and the respective energy consumption ratio based on the pre-trained model. The proposed model reduces training period to identify the application and effectively handle the offload process to improve the QoS metrics.},
  keywords={},
  doi={10.1109/ICIRCA54612.2022.9985529},
  ISSN={},
  month={Sep.},}@ARTICLE{10247345,
  author={Singh, Jaspreet and Walia, Navpreet Kaur},
  journal={IEEE Access}, 
  title={A Comprehensive Review of Cloud Computing Virtual Machine Consolidation}, 
  year={2023},
  volume={11},
  number={},
  pages={106190-106209},
  abstract={In the last decade, users have been able to access their applications, data, and services via the cloud from any location with an internet connection. The scale of heterogeneous cloud environments is continuously growing due to the development of computing-intensive smart devices. The cloud computing system is managed by a data center, which consists of physical machines (PMs) or servers and software-based emulation of PMs called virtual machines(VMs). The deployment of a huge number of physical servers as a result of the exponential development in demand for cloud services has resulted in high energy consumption and ineffective resource usage. Efficient utilization of resources and minimizing power consumption in any data center have become crucial challenges. Virtual machine consolidation (VMC) is a method of optimizing computing resources by consolidating multiple VMs onto a reduced number of PMs. By consolidating VMs and running fewer physical servers, VM consolidation can reduce power consumption and improve resource utilization. This review paper presents a comprehensive analysis of cloud computing virtual machine consolidation, exploring various strategies, benefits, challenges and future trends in this domain. By examining a wide range of literature from the year 2015 to 2023, this review attempts to provide insight into the current state of VM consolidation and its possible effects on the performance and sustainability of cloud computing. The main flaw in the articles is that the various authors focused on different assessment metrics when the emphasis should have been on increasing cloud system service quality and energy efficiency. Future research can be aimed at developing a multi-objective system that emphasizes minimizing cloud energy usage without sacrificing service quality and preventing service level agreements with cloud users from being compromised.},
  keywords={},
  doi={10.1109/ACCESS.2023.3314613},
  ISSN={2169-3536},
  month={},}@ARTICLE{9057418,
  author={Yu, Guangba and Chen, Pengfei and Zheng, Zibin},
  journal={IEEE Transactions on Cloud Computing}, 
  title={Microscaler: Cost-Effective Scaling for Microservice Applications in the Cloud With an Online Learning Approach}, 
  year={2022},
  volume={10},
  number={2},
  pages={1100-1116},
  abstract={Recently, the microservice becomes a popular architecture to construct cloud native systems due to its agility. In cloud native systems, autoscaling is a key enabling technique to adapt to workload changes by acquiring or releasing the right amount of computing resources. However, it becomes a challenging problem in microservice applications, since such an application usually comprises a large number of different microservices with complex interactions. When the performance decreases due to an unpredictable workload peak, it is difficult to pinpoint the scaling-needed services which need to scale out and evaluate how many resources they need. In this article, we present a novel system named Microscaler to automatically identify the scaling-needed services and scale them to meet the Service Level Agreement (SLA) with an optimal cost for microservice applications. Microscaler first collects the quality of service (QoS) metrics in the service mesh enabled microservice infrastructure. Then, it determines under-provisioning or over-provisioning service instances along the service dependency graph with a novel scaling-needed service criterion named service power. The service dependency graph could be obtained by correlating each request flow in the service mesh. By combining an online learning approach and a step-by-step heuristic approach, Microscaler can precisely reach the optimal service scale meeting the SLA requirements. The experimental evaluations in a microservice benchmark show that Microscaler achieves an average 93 percent precision in scaling-needed service determination and converges to the optimal service scale faster than several state-of-the-art methods. Moreover, Microscaler is lightweight and flexible enough to work in a large-scale microservice system.},
  keywords={},
  doi={10.1109/TCC.2020.2985352},
  ISSN={2168-7161},
  month={April},}@ARTICLE{9784409,
  author={Sebrechts, Merlijn and Volckaert, Bruno and De Turck, Filip and Yang, Kun and Al-Naday, Mays},
  journal={IEEE Communications Magazine}, 
  title={Fog Native Architecture: Intent-Based Workflows to Take Cloud Native toward the Edge}, 
  year={2022},
  volume={60},
  number={8},
  pages={44-50},
  abstract={The cloud native approach is rapidly transforming how applications are developed and operated, turning monolithic applications into microservice applications, allowing teams to release faster, increase reliability, and expedite operations by taking full advantage of cloud resources and their elasticity. At the same time, “fog computing” is emerging, bringing the cloud toward the edge, near the end user, in order to increase privacy, improve resource efficiency, and reduce latency. Combining these two trends, however, proves difficult because of four fundamental disconnects between the cloud native paradigm and fog computing. This article identifies these disconnects and proposes a fog native architecture along with a set of design patterns to take full advantage of the fog. Central to this approach is turning microservice applications into microservice workflows, constructed dynamically by the system using an intent-based approach taking into account a number of factors such as user requirements, request location, and available infrastructure and microservices. The architecture introduces a novel softwarized fog mesh facilitating both inter-microservice connectivity, external communication, and end-user aggregation. Our evaluation analyzes the impact of distributing microservice-based applications over a fog ecosystem, illustrating the impact of CPU and network latency and application metrics on perceived quality of service of fog native workflows compared to the cloud. The results show the fog can offer superior application performance given the right conditions.},
  keywords={},
  doi={10.1109/MCOM.003.2101075},
  ISSN={1558-1896},
  month={August},}@INPROCEEDINGS{9936294,
  author={Das, Souptik and Chakraborty, Sourish and Jana, Dipanjan and Nandy, Rahul and Bhattacharya, Srijan},
  booktitle={2022 Second International Conference on Computer Science, Engineering and Applications (ICCSEA)}, 
  title={IoT Based Industrial Air Quality Monitoring System}, 
  year={2022},
  volume={},
  number={},
  pages={1-4},
  abstract={In the past two decades, researchers have accelerated a number of different methods to monitor and reduce air contamination leading to the development of efficient and effective air quality measuring systems using air purifiers. Although, recent technological advancements such as IoT (Internet of Things) with Cloud Computing have allowed researchers to obtain and monitor real-time data. In this report, an IoT-enabled industrial air quality monitoring device is proposed. This device is enabled with an MQ-135 gas sensor for precisely monitoring the air quality and detecting the presence of foreign contaminants such as alcohol. The proposed device also uses a Node MCU ESP S266 Wi-Fi module to efficiently transmit real time data to a smart device (E.g. Smartphone) using an IoT platform.},
  keywords={},
  doi={10.1109/ICCSEA54677.2022.9936294},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9935836,
  author={Widodo, Doni Iksan and Hartono, Ambran and Yuniarti, Elvan},
  booktitle={2022 10th International Conference on Cyber and IT Service Management (CITSM)}, 
  title={Design and Build End-to-End Device as User Recommendations for Indoor Air Quality Monitoring}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={The development of integrated end-to-end technology is increasingly reaching all fields. The presence of this technology can answer one of the challenges discussed in this study, namely as a recommendation feature to users on indoor air quality and useful as an effort to prevent respiratory disease symptoms. This device is specially designed by implementing several technologies such as microcontrollers, sensors, internet of things, cloud computing, and progressive web apps. The parameters used to measure the level of indoor air quality are temperature, humidity, fine particles (PM10) and carbon monoxide with a predetermined range, if these parameters are outside the range then it is categorized as poor or unhealthy air, otherwise if the parameters are within range, the air is categorized as good or healthy air. Based on the collection and processing of data samples at several different locations, the air is in the good or healthy category and does not cause symptoms of respiratory disease. The results of this study also produced an end-to-end device that can monitor indoor air quality levels in real-time, as well as provide recommendations for making health efforts if the detected air quality parameters are outside the range that has been determined based on the Ministry of Health regulations Republic of Indonesia.},
  keywords={},
  doi={10.1109/CITSM56380.2022.9935836},
  ISSN={2770-159X},
  month={Sep.},}@INPROCEEDINGS{10047689,
  author={Vidhya, M. and Devi, R.},
  booktitle={2022 11th International Conference on System Modeling & Advancement in Research Trends (SMART)}, 
  title={Comparative Analysis of Scheduling Algorithms in Cloud Computing using CloudSim}, 
  year={2022},
  volume={},
  number={},
  pages={7-12},
  abstract={Cloud computing restructured the entire world of IT by providing shared scalable resources to the organization. Cloud establishes a huge path to find the solution for many major problems found in the industry. Cloud offers virtualized resources such as applications, software, networks, servers, and storage services. Cloud enables all the virtualized resources to clients on a pay-per-use basis. Because of handling the vast request sent by multiple clients and providing more versatile services to the organization, the cloud faces many critical problems such as security issues, dissatisfied Quality-Of-Services, and sometimes an unbalanced load arises. Among those, the most serious problem is balancing the load across the network. Load balancing issues can be handled by scheduling the work eventually to all nodes without overloading any single node. This paper gives an overview idea of different load balancing algorithms and provides comparative results on its quality metrics.},
  keywords={},
  doi={10.1109/SMART55829.2022.10047689},
  ISSN={2767-7362},
  month={Dec},}@INPROCEEDINGS{9995753,
  author={Al-Sit, Waleed T. and Ateeq, Karamath and Moinuddin, Syed Quadir and Aslam, Shoukat and Rehman, Abdur and Asgher, Tayba and Thawabeh, Ossma Ali},
  booktitle={2022 International Conference on Cyber Resilience (ICCR)}, 
  title={Direct Trust in Cloud Computing Based on Fuzzy Logic}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Trust is a powerful aspect, particularly for services using processes in the fields of cybersecurity and information technology. Concerns concerning the dependability of the cloud platform have been raised by individuals and creativity on a number of occasions. In cloud computing, it is advantageous for the customer to select a cloud provider's service for the storing and distribution of their thoughtful content. In this research, a trust model is put forth that evaluates trust using Quality of Service (QoS) metrics. The trust-fuzzy environment has inspired us to employ fuzzy logic to estimate a beneficiary's trustworthiness in a cloudy environment, hence increasing the scheme's effectiveness. Reliability, security, accessibility, response time, and cost make up Quality of Service. All work was completed in MATLAB.},
  keywords={},
  doi={10.1109/ICCR56254.2022.9995753},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9987392,
  author={Kumar, G Suvarna and Priyadarshini, R. and Parmenas, Naik Henokh and Tannady, Hendy and Rabbi, Fazle and Andiyan, Andiyan},
  booktitle={2022 Sixth International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)}, 
  title={Design of Optimal Service Scheduling based Task Allocation for Improving CRM in Cloud Computing}, 
  year={2022},
  volume={},
  number={},
  pages={438-445},
  abstract={Cloud computing is a service level computing that provide various service to the customers in order to establish an effective customer Relationship management (CRM). This offers various services like virtual machine, self-service provisioning, elasticity computing and storage (pay-as-you-go). Cloud computing provides shared services by enhancing resource management scalability, interoperability and prediction resources as a key to realize the resource utilization with high-performance management metrics. However, when the number of users increase, the process of task scheduling and service allocation using a traditional computing environment will degrade the CRM. In order to address this challenge, this research study proposes an Optimal Service Level Scheduling (OSLS) based task allocation design for improving CRM in cloud computing environment. The Adaptive Service Level Scheduling Algorithm (ASLSA) and the Support Level Load Balancer (SLLB) will reduce the workload in cloud computing environment in order to improve the Quality of Service (QoS) of CRM. This process will optimize the resource utilization in cloud platform based on the service requirement. It provides optimal scheduling features to CRM in order to improve the service optimality based on task and enhance the computational processes such as service load management, heterogeneous service delivery, pricing, resource pools and elasticity. The proposed system leverages high performance when compared to the existing models.},
  keywords={},
  doi={10.1109/I-SMAC55078.2022.9987392},
  ISSN={2768-0673},
  month={Nov},}@INPROCEEDINGS{10105030,
  author={Sandhiya, B and Canessane, R.Aroul},
  booktitle={2023 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)}, 
  title={An Extensive Study of Scheduling the Task using Load Balance in Fog Computing}, 
  year={2023},
  volume={},
  number={},
  pages={1586-1593},
  abstract={The proliferation of IoT has resulted in a rise in the demand for services provided by the fog layer, a novel dispersed computing pattern that supplements cloud computing. The fog system enables location awareness and mobility assistance by extending storage and multiplication to the network’s edge, dramatically reducing the issue of service computing in delay-sensitive applications. More requests from more users means more stress for the VMs running in the fog layer. When it comes to fog networks, Load Balancing (LB) is crucial since it prevents some fog nodes from being under- or overworked. Fairly dividing up the fog layer’s burden across the available virtual machines (VMs) is now an absolute must. LB can enhance quality-of-service metrics including cost, response time, performance, and energy ingesting. Although there has been limited investigation of load complementary techniques in fog networks in recent years, no comprehensive analysis has been conducted to compile this information. This article takes a systematic look at the various load-balancing procedures in fog computing, categorizing it as either approximate, precise, fundamental, or hybrid. In addition, the study explores (Load Balancing) LB metrics, including the benefits and drawbacks of the techniques used for fog networks. There is also an examination of the methods and instruments used in the aforementioned evaluations of each research under consideration. The most unanswered questions and emerging tendencies for these algorithms are also covered. In the final section, the study suggests potential avenues for further research.},
  keywords={},
  doi={10.1109/ICSCDS56580.2023.10105030},
  ISSN={},
  month={March},}@ARTICLE{10041775,
  author={Singh, Jagdeep and Singh, Parminder and Hedabou, Mustapha and Kumar, Neeraj},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={An Efficient Machine Learning-Based Resource Allocation Scheme for SDN-Enabled Fog Computing Environment}, 
  year={2023},
  volume={72},
  number={6},
  pages={8004-8017},
  abstract={Fog computing is an emerging technology which enables computing resources accessibility close to the end-users. It overcomes the drawbacks of available network bandwidth and delay in accessing the computing resources as observed in cloud computing environment. Resource allocation plays an important role in resource management in a fog computing environment. However, the existing traditional resource allocation techniques in fog computing do not guarantee less execution time, reduced energy consumption, and low latency requirements which is a pre-requisite for most of the modern fog computing-based applications. The complex fog computing environment requires a robust resource allocation technique to ensure the quality and optimal resource usage. Motivated from the aforementioned challenges and constraints, in this article, we propose a resource allocation technique for SDN-enabled fog computing with Collaborative Machine Learning (CML). The proposed CML model is integrated with the resource allocation technique for the SDN-enabled fog computing environment. The FogBus and iFogSim are deployed to test the results of the proposed technique using various performance evaluation metrics such as bandwidth usage, power consumption, latency, delay, and execution time. The results obtained are compared with other existing state-of-the-art techniques using the aforementioned performance evaluation metrics. The results obtained show that the proposed scheme reduces 19.35% processing time, 18.14% response time, and 25.29% time delay. Moreover, compared to the existing techniques, it reduces 21% execution time, 9% network usage, and 7% energy consumption.},
  keywords={},
  doi={10.1109/TVT.2023.3242585},
  ISSN={1939-9359},
  month={June},}@INPROCEEDINGS{10070735,
  author={Kong, Xiangyu and Gao, Xuesong and Pan, Shibao and Zhou, Yizhi and Yang, Yanan and Zhao, Laiping and Qi, Heng},
  booktitle={2022 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)}, 
  title={TailCmp - A Tail Latency Evaluation Solution of Public Cloud and Labeled von Neumann Architecture based Cloud Prototype}, 
  year={2022},
  volume={},
  number={},
  pages={888-895},
  abstract={Tail latency is the key performance metric for cloud computing systems (CCSs). When latency-critical (LC) applications and best-effort batch (BE) jobs are co-located on CCSs, the unmanaged contention for computing resources usually leads to significant fluctuations in tail latency, which have a severe negative impact to the end user experience. Therefore, some promising computing systems and effective scheduling solutions are proposed to guarantee better quality of service (QoS), e.g., La-beled von Neumann Architecture (LvNA) based cloud prototype system. However, relatively few work focuses on the tail latency observation and evaluation of public CCSs and newest prototype systems. Therefore, we introduce an evaluation framework named TailCmp which includes nine representative workloads ranging over different tail latency requirements and application domains. With the TailCmp, we can collect and analyze four evaluation metrics including tail latency entropy. In this paper, we conduct a large number of experiments with TailCmp on three CCSs (two public CCSs and one LvNA-based prototype system). The results show that the co-location on existing public CCSs can seriously affect the QoS of LC workloads, while the labeling mechanism in Lv Na - based prototype can improve the performance of LC workloads in co-location.},
  keywords={},
  doi={10.1109/ISPA-BDCloud-SocialCom-SustainCom57177.2022.00118},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10085328,
  author={Tiwana, Pardeep Singh and Singh, Jaspreet},
  booktitle={2023 International Conference on Artificial Intelligence and Smart Communication (AISC)}, 
  title={Load Optimization Accessions, Ramification the QoS in Software Defined Networking}, 
  year={2023},
  volume={},
  number={},
  pages={1013-1017},
  abstract={It is difficult to manage traditional networks due to network growth, an increase in user numbers, and the emergence of new technologies like big data and cloud computing. Consequently, it is required to alter the current network design. SDN is a well-liked architecture because it offers customizable control and centralized management in data centers. To achieve scalability and dependability, it was necessary to propose the geographical dispersal of a logically centralized control plane due to the huge scale of networks. Software-defined networking (SDN) load-balancing optimization has been studied for a long time. Many approaches to the load-balancing conundrum have been put forth by researchers, but very few have taken the impact of transmission delay between controllers and switches under heavy network load into account. In this article we elaborate the various techniques of load balancing in SDN those working on different areas like multi-controller, switch migration, multi-agent, strategy, time sharing, prediction, reinforcement learning etc. We discuss the methods used along with the advantages and disadvantages of various costs, service quality, and network performance metrics.},
  keywords={},
  doi={10.1109/AISC56616.2023.10085328},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10112423,
  author={Srivastava, Manoj Kumar and Joshi, Vijay K.},
  booktitle={2023 10th International Conference on Computing for Sustainable Global Development (INDIACom)}, 
  title={Efficient Consolidation of VMs Systems in the Cloud to Reduce Energy Use}, 
  year={2023},
  volume={},
  number={},
  pages={1510-1514},
  abstract={The energy needs of cloud computing systems are very high. Cloud suppliers, in order to keep their services available, need to reduce the amount of power their platforms need without sacrificing quality of service. As a result, studies have recommended a cloud-specific architecture that optimizes energy use throughout the whole computer infrastructure. The suggested method was developed in the CloudSim simulator, and the results of the associated simulations suggest that power consumption may be substantial and varies depending on parameters like the quantum variable, data size, and the number of VMs operating on a host. It is possible to establish a variety of resource allocation and planning methods for amassing virtual machines (VMs) on fewer hosts while still maintaining critical metrics, making cloud technology the first step towards sustainable energy. In this study, we first outline the taxonomy of VM placement approaches before proposing new iterative placement strategies that dynamically adjust their placement judgments based on host load Swarm Bee inspired improved Threshold.},
  keywords={},
  doi={},
  ISSN={},
  month={March},}@INPROCEEDINGS{10250648,
  author={Kavitha, J and Rao, P S V Srinivasa and Babu, G Charles},
  booktitle={2023 Second International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)}, 
  title={Energy Efficient Resource Utilization of Cloud Computing Environments for Deployment Models}, 
  year={2023},
  volume={},
  number={},
  pages={1111-1119},
  abstract={This research study focuses on optimizing resource allocation to reduce energy consumption in cloud-based systems. This study explores various techniques and algorithms employed to achieve energy efficiency, such as dynamic workload consolidation, virtual machine migration, and power-aware scheduling. This study emphasizes the importance of considering energy efficiency alongside performance metrics while making resource management decisions. The proposed methods intend to minimize energy wastage and carbon footprint while maintaining Quality of Service (QoS) and cost-effectiveness. Ultimately, this research contributes to the sustainable development and greener operation of cloud computing infrastructures.},
  keywords={},
  doi={10.1109/ICAISS58487.2023.10250648},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10366486,
  author={Saadouni, Rafika and Khacha, Amina and Harbi, Yasmine and Gherbi, Chirihane and Harous, Saad and Aliouat, Zibouda},
  booktitle={2023 15th International Conference on Innovations in Information Technology (IIT)}, 
  title={Secure IIoT networks with hybrid CNN-GRU model using Edge-IIoTset}, 
  year={2023},
  volume={},
  number={},
  pages={150-155},
  abstract={Industrial Internet of Things (IIoT), or Industry 4.0, is an application of IoT in the industrial sector. Its main objective is to enhance product quality and optimize production costs by leveraging advanced technologies such as edge/fog/cloud computing, 5G/6G, and artificial intelligence. In the context of Industry 4.0, numerous devices and systems are interconnected to provide seamless services to users. However, with this interconnection comes the need to protect these devices and the information they transmit from cyberthreats and intrusions. In order to tackle this challenge, our proposed solution involves the utilization of deep learning (DL) models to develop an anomaly-based detection system. Our approach involves two powerful DL models, namely Convolutional Neural Networks (CNN) and Gated Recurrent Units (GRU). The proposed model’s performance is studied within binary and multiclass classification using a new real-world industrial traffic dataset called Edge-IIoTset. The outcomes of our experiments showcased the efficacy of the CNN-GRU model that we proposed, surpassing the performance of recent related works in terms of performance metrics, including accuracy, precision, false positive rate, and detection cost. The combination of the two models CNN and GRU outperforms the GRU model with 88% of detection cost in multiclass classification for one traffic flow.},
  keywords={},
  doi={10.1109/IIT59782.2023.10366486},
  ISSN={2473-2052},
  month={Nov},}@INPROCEEDINGS{10087523,
  author={Khayyat, Mashael M. and Aboulola, Omar A.},
  booktitle={2023 International Conference on Smart Computing and Application (ICSCA)}, 
  title={Implementing an Ambient Air Quality Monitoring System in Spaces with Inadequate Ventilation using the Internet of Things}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Improving quality of life can be one of the most important outcomes of health care policies. Researchers have proven the role of technology in enhancing the quality of life. The Internet of Things (IoT) concept employs technology in an integrated manner by connecting smart devices, sensors, data, and channels, in order to enhance communication between things and to facilitate life in a smart way. Thus, IoT utilizes a great amount of data coming from these devices and produces stories and clear pictures about what is going on especially since the emergence of big data and cloud computing paradigms. The objective of this paper is to introduce IoT, explain how to calculate the Air Quality Index for Gulf Cooperation Council countries, and to provide evidence of the importance of implementing air quality monitoring systems in tunnels since their architecture limits airflow; therefore it can be assumed that pollutants are trapped. Results from the data generated by the system implemented measures air quality in the tunnel on King Abdulaziz Road in Makkah that shows air quality in such spaces should be monitored and proper actions need to be considered to avoid health problems to ensure quality of life.},
  keywords={},
  doi={10.1109/ICSCA57840.2023.10087523},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{9928755,
  author={Li, Shuo and Baştuğ, Ejder and Di Renzo, Marco},
  booktitle={2022 IEEE International Mediterranean Conference on Communications and Networking (MeditCom)}, 
  title={On the Modelling and Analysis of Edge-Serverless Computing}, 
  year={2022},
  volume={},
  number={},
  pages={250-254},
  abstract={The exponential increase in data generated by mobile devices and the rapid growth of cloud computing traffic are pushing services to the edge of the network. Serverless computing is an emerging cloud computing paradigm that provides stateless and event-driven services, called serverless services, independent of network infrastructure. Further improvements in quality of service (QoS) can be achieved by utilizing novel concepts like edge-serverless computing. Analyzing such systems as in existing works requires network-level simulations which could be costly and time-consuming, thus analytical models to obtain rapid insights are also needed. In this paper, we propose a stochastic geometry-based mathematical model in a tiered network, characterizing average end-to-end delay as performance measure, impacted by various crucial network parameters. The spatial distribution of server nodes, as well as computation requests are randomly and independently distributed according to homogeneous Poisson point processes (PPPs), allowing us to study the performance gains from multiple aspects. Two distinct network topologies are investigated numerically, namely communication and computation-oriented, validating the accuracy of our theoretical approximations.},
  keywords={},
  doi={10.1109/MeditCom55741.2022.9928755},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10326297,
  author={Yekta, Mohammad and Shahhoseini, Hadi Shahriar},
  booktitle={2023 13th International Conference on Computer and Knowledge Engineering (ICCKE)}, 
  title={A Review on Machine Learning Methods for Workload Prediction in Cloud Computing}, 
  year={2023},
  volume={},
  number={},
  pages={306-311},
  abstract={Workload prediction is one of the critical parts of resource provisioning in cloud computing and its evolved branches such as serverless and edge computing. Effective resource provisioning stands as a crucial element within the realm of edge-cloud computing. Accurate prediction of cloud workloads is essential for the effective allocation of resources. Workload prediction plays a crucial role in enhancing efficiency, reducing costs, optimizing cloud performance, maintaining a high level of quality of service, and minimizing energy consumption. In this paper, we conduct a comprehensive review of state-of-the-art Machine Learning (ML) and Deep Learning (DL) algorithms employed in workload prediction in cloud computing and other similar platforms such as edge computing. We compared the selected papers in terms of utilized methods and techniques, predicted factors, accuracy metrics, and the dataset. Additionally, to facilitate usability and comparison, articles sharing similar advantages and disadvantages are organized into a table. Finally, the paper concludes by addressing current challenges and future research directions.},
  keywords={},
  doi={10.1109/ICCKE60553.2023.10326297},
  ISSN={2643-279X},
  month={Nov},}@INPROCEEDINGS{10054247,
  author={M, Gayathri Hegde and M, Shrishti Bekal and Prasad, Srinidhi S and Shenoy, P Deepa and K R, Venugopal},
  booktitle={2022 IEEE 7th International Conference on Recent Advances and Innovations in Engineering (ICRAIE)}, 
  title={Analysis of Secure EHR Storage Methods on Blockchain and Integrating ML to Predict Chronic Kidney Disease}, 
  year={2022},
  volume={7},
  number={},
  pages={250-255},
  abstract={An Electronic Health Record(EHR) is the digital form of the patient’s health data, including vital signs, demographic details, clinical notes, X-rays, medical images, etc. When discussing EHR processing and management, storing this vast information is the main challenge. Although cloud computing’s centralized storage model is one of the best ways to store large amounts of data, it is not secure. Blockchain technology has the potential to revolutionize EHR storage systems and provide data security. Directly keeping the vast EHR data on blockchain may be costly and inefficient. The best method to store the data is off-chain in a Blockchain-based EHR system. Implementing machine learning (ML) in the healthcare industry aims to anticipate diseases earlier so patients can receive higher-quality medical care. Integrating these two disruptive data-driven technologies can highly improve the quality of healthcare. First, this paper analyzes three different off-chain EHR storage methods: Storj, InterPlanetary File System(IPFS), and CosmosDB, based on their Storage and Access Time. From the experimental results, IPFS has the fastest Storage and Access Time. Second, we integrate blockchain and ML technology to predict Chronic Kidney Disease(CKD) from the CKD dataset stored on the IPFS. Finally, using IPFS storage, a record is accessed, and the prediction time is 0.4 sec for detecting CKD or NOCKD is measured.},
  keywords={},
  doi={10.1109/ICRAIE56454.2022.10054247},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10176696,
  author={Sefati, Seyed Salar and Halunga, Simona},
  booktitle={2023 12th International Conference on Modern Circuits and Systems Technologies (MOCAST)}, 
  title={Service Recommendation for a Group of Users on the Internet of Things Using the Most Popular Service}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={With the emergence of the Internet of Things (IoT), advanced technologies like fog and cloud computing have been harnessed to create dynamic, real-time platforms addressing the needs of modern decision-makers. Crucial to this process is the recommendation of services tailored to each user's requirements in IoT settings, with the potential for improved Quality of Service (QoS) and Quality of Experience (QoE). The presented method in this paper leverages sensors, services, and fog computing within IoT systems to enhance QoS and adapt to user feedback. The approach involves ranking QoS of services based on Reliability, Availability, and Cost (RAC), and identifying the Most Popular Service (MPS) previously selected by the user. Comparison with Co-Scheduling System for Fog-node Recommendation and Load Management (CoS_FRLM) and User Characteristics-Collaborative Filtering (UCCF) demonstrates our method's effectiveness in maximizing recall, precision, and f-measure, as tested with the Network Simulator (NS3).},
  keywords={},
  doi={10.1109/MOCAST57943.2023.10176696},
  ISSN={},
  month={June},}@ARTICLE{9508125,
  author={Qin, Zhenquan and Ye, Jin and Meng, Jie and Lu, Bingxian and Wang, Lei},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Privacy-Preserving Blockchain-Based Federated Learning for Marine Internet of Things}, 
  year={2022},
  volume={9},
  number={1},
  pages={159-173},
  abstract={The marine Internet of things (MIoT) is the application of the Internet of things technology in the marine field. Nowadays, with the arrival of the era of big data, the MIoT architecture has been transformed from cloud computing architecture to edge computing architecture. However, due to the lack of trust among edge computing participants, new solutions with higher security need to be proposed. In the current solutions, some use blockchain technology to solve data security problems while some use federated learning technology to solve privacy problems, but these methods neither combine with the special environment of the ocean nor consider the security of task publishers. In this article, we propose a secure sharing method of MIoT data under an edge computing framework based on federated learning and blockchain technology. Combining its special distributed architecture with the MIoT edge computing architecture, federated learning ensures the privacy of nodes. The blockchain serves as a decentralized way, which stores federated learning workers to achieve nontampering and security. We propose a concept of quality and reputation as the metrics of selection for federated learning workers. Meanwhile, we design a quality proof mechanism [proof of quality (PoQ)] and apply it to the blockchain, making the edge nodes recorded in the blockchain more high-quality. In addition, a marine environment model is built in this article, and the analysis based on this model makes the method proposed in this article more applicable to the marine environment. The numerical results obtained from the simulation experiments clearly show that the proposed scheme can significantly improve the learning accuracy under the premise of ensuring the safety and reliability of the marine environment.},
  keywords={},
  doi={10.1109/TCSS.2021.3100258},
  ISSN={2329-924X},
  month={Feb},}@INPROCEEDINGS{10011594,
  author={Abbasi, Rabiya and Martinez, Pablo and Ahmad, Rafiq},
  booktitle={2022 10th International Conference on Control, Mechatronics and Automation (ICCMA)}, 
  title={Data Acquisition and Monitoring Dashboard for IoT Enabled Aquaponics Facility}, 
  year={2022},
  volume={},
  number={},
  pages={168-172},
  abstract={Aquaponics is an emerging field of agriculture that has great potential to ensure food security and sustainability. It presents a closed-loop ecosystem that synergizes fish farming (aquaculture) and soilless plant growing (hydroponics). As aquaponics is a simulation of a natural ecosystem, a significant number of factors are involved in its management. For instance, constant monitoring of water quality, environmental parameters, and illumination is required to achieve healthy growth of fish and plants. In combination with cloud computing technology, the internet of things (IoT) provides a platform to collect data, monitor systems, detect abnormal conditions, and rectify problems in the system without human intervention. This research project presents a framework that involves the development of a cloud-based dashboard for data acquisition and monitoring of an aquaponics facility. The data from a wireless sensing module (measuring pH, water temperature, electroconductivity, light intensity, air humidity, and air temperature) and several cameras installed in an aquaponics farm are uploaded wirelessly to the dashboard. These images are saved on the dashboard with their relevant sensor measurements. The user (farmer or aquaponics practitioner) can get real-time insights regarding the farm’s performance with this information. It can also be used for the creation of future smart applications that can perform and showcase short and long-term predictions.},
  keywords={},
  doi={10.1109/ICCMA56665.2022.10011594},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9820438,
  author={Chango - Cañaveral, Patricia Marisol and Esperanza Jaya- Jaramillo, Doris and Quezada- Sarmiento, Pablo Alejandro and Teodomiro Salas - Álvarez, Wilson},
  booktitle={2022 17th Iberian Conference on Information Systems and Technologies (CISTI)}, 
  title={Analysis of the Quality Service of the Hotel Villa Colonial through the Servqual method and Cloud Computing tools}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={The objective of this article was to analyze the quality service through the Servqual model at the Villa Colonial Hotel in the Malacatos parish. The methodology used established as an object of study the application of the Servqual model, which allowed measuring customer service satisfaction, which is made up of five dimensions such as: reliability, responsiveness, security, empathy, and tangible elements. The information was collected through the application of structured interviews to 218 guests in two phases: in the first phase, data was acquired regarding the expectation of the services offered by the hotel and in the second phase, data was collected on the perception of the services provided. In the evaluation of the gap, it was possible to identify 11 shortcomings in customer service, ¿the most punctuated deficiency is item 16 Does the staff care about satisfying the needs of the clients? the perception does not exceed the expectations of the client and is qualified as dissatisfied. The results obtained were used to design an improvement plan to overcome the shortcomings identified in the hotel. Finally, it should be noted that the entire development and implementation process was supported with cloud computing tools.},
  keywords={},
  doi={10.23919/CISTI54924.2022.9820438},
  ISSN={2166-0727},
  month={June},}@INPROCEEDINGS{9915888,
  author={Wen, Shilin and Deng, Hongjie and Qiu, Ke and Han, Rui},
  booktitle={2022 IEEE International Conference on Sensing, Diagnostics, Prognostics, and Control ( SDPC)}, 
  title={EdgeCloudBenchmark: A Benchmark Driven by Real Trace to Generate Cloud-Edge Workloads}, 
  year={2022},
  volume={},
  number={},
  pages={377-382},
  abstract={With the rapid development of 5G and IoT technology, edge computing, as an extension of the cloud computing paradigm, has been widely used to handle some latency-sensitive tasks. Due to insufficient and limited resource of edge devices, when the edge handles some complex tasks, it is often necessary to cooperate with the cloud, which forms the cloud-edge collaboration scenarios. In real cloud-edge collaboration cluster, different scheduling algorithms will greatly affect the resource allocation and workload completion time. Therefore, how to measure the quality of a scheduling algorithm has become critical. However, there is no existing benchmark test sets for such scenarios at present. Based on this problem, this paper proposes EdgeCloudBenchmark, which is a benchmark generation system driven by real Alibaba cluster trace. In this system, we can generate two different benchmark test sets for CPU cluster and GPU cluster, respectively. The experimental results show that these workloads generated from the proposed system can maintain the consistency with the characteristics of the real cluster workloads, and are highly available. Therefore, our proposed system has high concurrency, availability and fault tolerance.},
  keywords={},
  doi={10.1109/SDPC55702.2022.9915888},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9779020,
  author={Duan, Danping and Xiang, Chaoyang},
  booktitle={2022 10th International Conference on Information and Education Technology (ICIET)}, 
  title={The Design and Implementation of Virtual Simulation Teaching Resource Management and Sharing Platform}, 
  year={2022},
  volume={},
  number={},
  pages={11-15},
  abstract={In China, the construction and sharing of virtual simulation teaching resources is an important measure to improve the quality of practical teaching. However, due to various factors, there are still many difficulties in the integrated management and open sharing of virtual simulation teaching resources. Therefore, this paper analyzes the problems existing in the management and sharing of virtual simulation teaching resources, and puts forward the mode of virtual simulation teaching resources management and sharing based on the network support platform. Then, the design idea of virtual simulation teaching resource management sharing platform is elaborated, and the layered architecture is adopted, and the overall framework of the platform is designed by integrating virtual reality, cloud computing, big data and other technologies. Finally, the platform is realized and the functions and applications of the four core modules, portal service, VR resource service, VR project teaching and statistical analysis, are described in detail. This paper can provide reference for other universities to develop the sharing platform of virtual simulation teaching resources management.},
  keywords={},
  doi={10.1109/ICIET55102.2022.9779020},
  ISSN={},
  month={April},}@INPROCEEDINGS{10212187,
  author={Thakur, Rahul},
  booktitle={2023 2nd International Conference on Edge Computing and Applications (ICECAA)}, 
  title={Bioinspired Sensory Gating in the Artificial Vision System}, 
  year={2023},
  volume={},
  number={},
  pages={1163-1167},
  abstract={When viewed as an enterprise, the healthcare system has important security and privacy requirements, such as protecting patient medical records from unauthorized access, tracking protected drugs, securely connecting to transportation such as ambulances, and conducting secure and intelligent e-health surveillance. Blockchain has introduced new ideas in medical data security and safety, and with the right security measures, it may eliminate the tension between sharing data and maintaining anonymity. In this study, the benefits of cloud computing are integrated with blockchain to offer a secrecy technique for blockchain and IoT. In addition to incorporating IoT and providing IoT solutions to blockchain nodes, this method also collects, analyzes, uses, and maintains identity authentication for health information. Interface and overcomes the insufficient computer power of particular blockchain chain routers to verify the data's feasibility and authenticity order to verify the feasibility and authenticity of the data. The simulation experiment shows that the suggested technique is effective. It may handle problems like high computer intricacy, data interchange, and privacy protection while maintaining and confirming the quality of medical data.},
  keywords={},
  doi={10.1109/ICECAA58104.2023.10212187},
  ISSN={},
  month={July},}@INPROCEEDINGS{10263944,
  author={Srivastava, Arun Pratap and Madan, Parul and Sharma, Gunjan and Shrivastava, Anurag and Singh, Yograj and Salim, Mohd.},
  booktitle={2023 IEEE World Conference on Applied Intelligence and Computing (AIC)}, 
  title={Bioinspired Sensory Gating in the Artificial Vision System}, 
  year={2023},
  volume={},
  number={},
  pages={735-739},
  abstract={When viewed as an enterprise, the healthcare system has important security and privacy requirements, such as protecting patient medical records from unauthorized access, tracking protected drugs, connecting to transportation such as ambulances securely, and conducting secure and intelligent e-health surveillance. Block chain has introduced new ideas in medical data security and safety, and with the right security measures, it may eliminate the tension between sharing data and maintaining anonymity. In this study, we integrate the benefits of cloud computing with block chain to offer a secrecy technique for block chain and IoT. In addition to incorporating IoT and providing Iot solutions to block chain nodes, this method also collects, analyzes, uses, and maintains identity authentication for health information. Interface and overcomes the insufficient computer power of particular blockchainchain routers to verify the data's feasibility and authenticity order to verify the feasibility and authenticity of the data. The simulation experiment shows that the suggested technique is effective. It may handle problems like high computer intricacy, data interchange, and privacy protection while maintaining and confirming the quality of medical data.},
  keywords={},
  doi={10.1109/AIC57670.2023.10263944},
  ISSN={},
  month={July},}@ARTICLE{9707879,
  author={Huang, Siqi and Xie, Jiang and Muslam, Muhana Magboul Ali},
  journal={IEEE Transactions on Cloud Computing}, 
  title={A Cloud Computing Based Deep Compression Framework for UHD Video Delivery}, 
  year={2023},
  volume={11},
  number={2},
  pages={1562-1574},
  abstract={Ultra-high-definition (UHD) videos are enjoying increased popularity in people's daily usage because of the good visual experience. However, the data size of UHD videos is 4-16 times larger of HD videos. This will bring many challenges to existing video delivery systems, such as the shortage of network bandwidth resources and longer network transmission latency. In this article, we propose a cloud computing based deep compression framework named Pearl, which utilizes the power of deep learning and cloud computing to compress UHD videos. Pearl compresses UHD videos from two respects: the frame resolution and the colorful information. In pearl, an optimal compact representation of the original UHD video is learned with two deep convolutional neural networks (DCNNs): super resolution CNN (SR-CNN) and colorization CNN (CL-CNN). SR-CNN is used to reconstruct a high resolution video from a low resolution video while CL-CNN is adopted to preserve the color information of the video. Pearl focuses on video content compression in two new directions. Thus, it can be integrated with any existing video compression system. With Pearl, the data size of UHD videos can be significantly reduced. We evaluate the performance of Pearl with a wide variety of network conditions, quality of experience (QoE) metrics, and video properties. In all considered scenarios, Pearl can further compress 84% of video size and reduce 73% of network transmission latency.},
  keywords={},
  doi={10.1109/TCC.2022.3149420},
  ISSN={2168-7161},
  month={April},}@INPROCEEDINGS{10212311,
  author={Lokesh, Gudivada and Baseer, K. K.},
  booktitle={2023 2nd International Conference on Edge Computing and Applications (ICECAA)}, 
  title={An Architecture for Dynamic Load Balancing in Cloud Environment}, 
  year={2023},
  volume={},
  number={},
  pages={84-91},
  abstract={Clouds are highly customizable infrastructures that offer a platform as a service and let customers subscribe on a pay-as-you-go basis to their requirements. The straightforward service-oriented cloud computing model is gaining popularity around the world. The number of people using the Cloud is constantly growing. Clouds use modern data centers to manage a massive number of users. The reliability of the Cloud depends on load balancing. Balancing virtual machine loads lowers energy consumption and task rejections by optimizing resource utilization. One can increase performance while using fewer resources using load balancing, resource management, quality of service, etc. The difficulty of overloading and underloading virtual machines in cloud computing can be lessened by load balancing in the Cloud.This research study thoroughly examined the load-balancing algorithms found in the literature. First, the traditional approaches are analyzed before moving on to more recent work on load balancing with heterogeneous techniques. Along with the tools available for the current investigation, various metrics are used to evaluate the load-balancing algorithms. The proposed article will primarily serve to assist in the development of new algorithms in the future.},
  keywords={},
  doi={10.1109/ICECAA58104.2023.10212311},
  ISSN={},
  month={July},}@INPROCEEDINGS{10189468,
  author={Chen, Fan and Du, Yugen and Zhong, Wenhao and Wang, Hanting},
  booktitle={2022 IEEE Smartworld, Ubiquitous Intelligence & Computing, Scalable Computing & Communications, Digital Twin, Privacy Computing, Metaverse, Autonomous & Trusted Vehicles (SmartWorld/UIC/ScalCom/DigitalTwin/PriComp/Meta)}, 
  title={Web Service QoS Prediction Based on Reputation and Location Aware Matrix Factorization}, 
  year={2022},
  volume={},
  number={},
  pages={1722-1729},
  abstract={With the development of cloud computing and Internet technologies, the number of Web services has increased dramatically. It is increasingly difficult for users to locate applicable services among a large number of functionally equivalent candidates. Considering the high cost of time and resources, users cannot invoke all Web services to obtain the desired quality of service (QoS). Therefore, the problem of QoS prediction of Web services has attracted much attention in recent years. Although QoS is often used as a measure of Web service performance, the value of QoS may vary significantly between users depending on their network and geographical location. Furthermore, most traditional approaches perform QoS prediction directly based on historical QoS values provided by users. However, these historical QoS data may contain unreliable values from unreliable users, resulting in significantly lower prediction accuracy. To overcome the above limitations, we propose a reputation and location aware matrix factorization (RLMF) approach for QoS prediction of Web services in this paper. First, we cluster the users and calculate their reputation based on the clustering information through Dirichlet distribution. Then, we integrate the user’s reputation and location information into the matrix factorization model to obtain more accurate prediction results. Additionally, we use Cauchy loss to measure the difference between the observed and predicted QoS values, which makes our approach robust to even outliers. We conducted experiments on a largescale dataset of 1,974,675 QoS values to evaluate our approach. The experimental results show that our approach performs better than state-of-the-art baseline approaches.},
  keywords={},
  doi={10.1109/SmartWorld-UIC-ATC-ScalCom-DigitalTwin-PriComp-Metaverse56740.2022.00245},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10114347,
  author={Cao, Junling and Xu, Yichuan and Qian, Yuxuan and Chai, Tingyi and Liu, Chang},
  booktitle={2023 5th Asia Energy and Electrical Engineering Symposium (AEEES)}, 
  title={Multidimensional Full State Water Quality - Electrical Data Mining Method for Intelligent Fishing Grounds Based on Cloud Edge Collaboration}, 
  year={2023},
  volume={},
  number={},
  pages={1117-1123},
  abstract={Aiming at the problem that the intelligent analysis technology of aquaculture characteristics is difficult to meet the practical application needs of the market, a multi-dimensional full state water quality-electrical data mining method of intelligent fishing grounds based on cloud edge collaboration is proposed. First, based on the cloud edge collaboration architecture, an intelligent fishing ground awareness operation and maintenance system is designed. Through the collaboration of edge computing and cloud computing, the real-time performance of system data monitoring and processing is improved. Then, in the system edge layer, the weighted least square method and BP neural network are used for multidimensional data fusion to ensure the accuracy of monitoring data. Finally, the grey correlation analysis method is applied to the fuzzy comprehensive evaluation, and an improved fuzzy association rule analysis and evaluation model is constructed for the deep mining of full state data, so as to obtain the water quality and electrical safety level. Based on the experimental analysis of the proposed method in Taizhou Jiangyan Fishing Light Complementary Fishing Ground, the results show that the error of the heterogeneous data fusion method is smaller, and its water quality electrical comprehensive evaluation value is between 0.751-0.928, which is the closest to the measured value.},
  keywords={},
  doi={10.1109/AEEES56888.2023.10114347},
  ISSN={},
  month={March},}@ARTICLE{9645168,
  author={Balcão-Filho, Amandio and Ruiz, Natasha and Rosa, Ferrucio de Franco and Bonacin, Rodrigo and Jino, Mario},
  journal={IEEE Transactions on Services Computing}, 
  title={Applying a Consumer-Centric Framework for Trust Assessment of Cloud Computing Service Providers}, 
  year={2023},
  volume={16},
  number={1},
  pages={95-107},
  abstract={Cloud computing services consumers do not have enough reliable information about critical characteristics of their providers, such as performance, security, trust and privacy, compliance with laws and regulations, among others. Our proposal addresses these problems presenting a trust assessment framework that integrates three domains: Governance, Transparency, and Security Information. Our approach is consumer-centric and deals with trust aspects from the end-user’s perspective. We use Indicators to communicate the outcomes, which aim to represent the expression of cybersecurity, manageability, and transparency of services under assessment. This paper includes an implementation proposal, prototype, and proof of concept, in which the framework was applied in a real scenario and executed over a long-term (18 months) usage simulation to verify its applicability, sensitivity, and robustness. Our study is intended for use by consumers of cloud computing who seek to know and measure levels of cybersecurity, protection of privacy, transparency of security, and high levels of quality in their services and infrastructure.},
  keywords={},
  doi={10.1109/TSC.2021.3134125},
  ISSN={1939-1374},
  month={Jan},}@ARTICLE{10309856,
  author={Singhal, Saurabh and Gupta, Nakul and Berwal, Parveen and Naveed, Quadri Noorulhasan and Lasisi, Ayodele and Wodajo, Anteneh Wogasso},
  journal={IEEE Access}, 
  title={Energy Efficient Resource Allocation in Cloud Environment Using Metaheuristic Algorithm}, 
  year={2023},
  volume={11},
  number={},
  pages={126135-126146},
  abstract={Utility-based computing popularly known as “cloud computing” offers several computing services to the users. Due to the proliferation in the users of cloud computing, there is an unprecedented increase in the demand for computation resources to execute cloud services. Thus, there is a requirement to investigate currently available resources like virtual machines, CPU, RAM, and storage to allocate cloud services. The allocation and QoS of cloud services are highly dependent on allocation schemes. The optimized solutions allocate resources to submitted jobs to reduce the overall cost to the end-users/service provider without degrading the performance of virtual machines. The allocation techniques also consider the harvesting of energy consumption required for running the cloud services. In this paper, we have utilized a Rock Hyrax-based optimization technique to allocate resources to the submitted jobs with reduced energy consumption. The proposed Rock Hyrax algorithm has been simulated on the CloudSim simulator for various scenarios. The performance of the proposed algorithm has been measured over various Quality of Service (QoS) parameters such as makespan, energy efficiency, response time, throughput, and cost. The gathered results validate the proposed algorithm that improves the QoS parameters by 3%-8% as compared to algorithms when both jobs and resources are considered to be dynamic in nature.},
  keywords={},
  doi={10.1109/ACCESS.2023.3330434},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10051112,
  author={Zalokostas-Diplas, Vasileios and Makris, Nikos and Passas, Virgilios and Korakis, Thanasis},
  booktitle={2022 IEEE Conference on Standards for Communications and Networking (CSCN)}, 
  title={Experimental Evaluation of ML Models for Dynamic VNF Autoscaling}, 
  year={2022},
  volume={},
  number={},
  pages={157-162},
  abstract={Network Functions Virtualization (NFV) is a key aspect deeply integrated in the latest 5G networks, allowing for the provisioning of elastic resources that adapt in a flexible manner based on the overall network demand. The adoption of NFV architectures is empowered through the evolution of cloud-native and hypervisor tools to support service monitoring, and orchestrate the appropriate decisions for provisioning the scale of the network. Such decisions may directly impact the overall quality of service and experience for users, as well as the energy consumption that the resources use. To this aim, machine learning (ML) - driven optimization for these decisions, relying on inferring the values of future monitored metrics, can assist in deciding proactively on the network scale. In this work, we employ three different candidate solutions (statistical, tree- and CNN-based) for determining the scale of network functions deployed within a cluster of resources, subject to the user demand. We compare and evaluate the different schemes in a real testbed environment, and discuss the benefits of ML-driven optimizations against existing state-of-the-art approaches.},
  keywords={},
  doi={10.1109/CSCN57023.2022.10051112},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10151287,
  author={Pandey, Shivani and Mishra, Satanand and Jain, Ravi Kant},
  booktitle={2023 International Conference on Recent Advances in Electrical, Electronics & Digital Healthcare Technologies (REEDCON)}, 
  title={IoT Interface Device for Sensing Arsenic in Contaminated Water}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Water pollution is a serious problem in different parts of the world. In addition, water quality must be monitored to ensure that the water is provided safely for drinking and other purposes. Too high a concentration of Arsenic ions in drinking water is the cause of many health problems, including heart problems, neurological problems, etc. Water sampling and laboratory analysis are required for traditional water quality monitoring. In this paper, we discussed an IoT-based interfacing sensor device for sensing arsenic contaminants in water where IoT cloud computing networks enable the integration of a variety range of mechanical and electronic devices. A Node MCU device is used for data transmission which emphasizes on Wi-Fi-controlled interface devices and IoT-enabled communication protocol for the detection of water contaminants. This system is connected to an IoT cloud platform to store the data for analyzing purposes where Red-Green-Blue (RGB) color detection occurs by identifying the wavelength of contaminants. The system makes use of IoT to display the output in real-time for on-site and off-site monitoring via mobile phone. The system makes use of IoT to display the output in real-time for on-site and off-site monitoring via mobile phone, The major advantage of IoT technology is that it easily connects devices and stores the generated data in the cloud. With the help of command control systems, data can be used for appropriate applications to make human life easier and safer while considering Industry's impact. The acceptable limits set by WHO and the Bureau of Indian Standards for Arsenic are 0.05 mg/litres and 0.01 mg/l respectively. Therefore, a smart and intelligent device that can be used for measuring Arsenic content which is very necessary today to ensure the health of human life in society.},
  keywords={},
  doi={10.1109/REEDCON57544.2023.10151287},
  ISSN={},
  month={May},}@INPROCEEDINGS{9872806,
  author={Manova, Rd Yovi and Sukmadirana, Edi and Nurmanah, Nurma Siti},
  booktitle={2022 1st International Conference on Information System & Information Technology (ICISIT)}, 
  title={Comparative Analysis of Quality of Service and Performance of MPLS, EoIP and SD-WAN}, 
  year={2022},
  volume={},
  number={},
  pages={403-408},
  abstract={Software Defined – Wide Area Network (SDWAN) implementation is growing each year as one of the options for enterprise to have hybrid and redundant connection between traditional WAN and Internet. The cloud computing services, whether it is IaaS, PaaS, or SaaS has attracted most of enterprise to separate the corporate data connection from private WAN to public internet securely. This dual data traffic still can be managed by enterprise router, but it will require manual routing or at lease delay with complicated rule to mitigate any link problem. SD-WAN as the development of SDN in wide area network, have the solution to solve the manual routing data, by putting the control plane in a software environment to manage the data traffic virtually. In Indonesia, the SD-WAN technology has been introduced by several vendors and operators, some enterprise still reluctance considering the security of enterprise data through public internet service, and some of them still questioning the Quality of Services compare to legacy or traditional WAN services. Therefore, this research will perform the Quality of Service and Performance of SD-WAN, compare to traditional Multiprotocol Label Switching (MPLS) link and Ethernet over Internet Protocol (EoIP) as one of the contenders. The object of the research is an active WAN of one of Indonesian company, that having those three connections between Jakarta and Surabaya. The QoS and performance are measured using ITU- T G.1010 standard as the reference.},
  keywords={},
  doi={10.1109/ICISIT54091.2022.9872806},
  ISSN={},
  month={July},}@ARTICLE{9772936,
  author={Kashani, Mostafa Haghi and Mahdipour, Ebrahim},
  journal={IEEE Transactions on Services Computing}, 
  title={Load Balancing Algorithms in Fog Computing}, 
  year={2023},
  volume={16},
  number={2},
  pages={1505-1521},
  abstract={Recently, fog computing has been introduced as a modern distributed paradigm and complement to cloud computing to provide services. The fog system extends storing and computing to the edge of the network, which can remarkably solve the problem of service computing in delay-sensitive applications besides enabling location awareness and mobility support. Load balancing is an important aspect of fog networks that avoids a situation with some under-loaded or overloaded fog nodes. Quality of service parameters such as resource utilization, throughput, cost, response time, performance, and energy consumption can be improved by load balancing. In recent years, some research in load balancing algorithms in fog networks has been carried out, but there is no systematic study to consolidate these works. This article investigates the load-balancing algorithms systematically in fog computing in four classifications, including approximate, exact, fundamental, and hybrid algorithms. Also, this article investigates load balancing metrics with all advantages and disadvantages related to chosen load balancing algorithms in fog networks. The evaluation techniques and tools applied for each reviewed study are explored as well. Additionally, the essential open challenges and future trends of these algorithms are discussed.},
  keywords={},
  doi={10.1109/TSC.2022.3174475},
  ISSN={1939-1374},
  month={March},}@ARTICLE{9140382,
  author={Kong, Cuiyu and Rimal, Bhaskar Prasad and Reisslein, Martin and Maier, Martin and Bayram, Islam Safak and Devetsikiotis, Michael},
  journal={IEEE Transactions on Services Computing}, 
  title={Cloud-Based Charging Management of Heterogeneous Electric Vehicles in a Network of Charging Stations: Price Incentive Versus Capacity Expansion}, 
  year={2022},
  volume={15},
  number={3},
  pages={1693-1706},
  abstract={This article presents a novel cloud-based charging management system for electric vehicles (EVs). Two levels of cloud computing, i.e., local and remote clouds, are employed to meet the different latency requirements of the heterogeneous EVs while exploiting the lower-cost computing in remote clouds. Specifically, we consider time-sensitive EVs at highway exit charging stations and EVs with relaxed timing constraints at parking lot charging stations. We propose algorithms for the interplay among EVs, charging stations, system operator, and clouds. Considering the contention-based random access for EVs to a 4G Long-Term Evolution network, and the quality of service metrics (average waiting time and blocking probability), the model is composed of: queuing-based cloud server planning, capacity planning in charging stations, delay analysis, and profit maximization. We propose and analyze a price-incentive method that shifts heavy load from peak to off-peak hours, a capacity expansion method that accommodates the peak demand by purchasing additional electricity, and a hybrid method of price incentives and capacity expansion that balances the immediate charging needs of customers with the alleviation of the peak power grid load through price-incentive based demand control. Numerical results demonstrate the effectiveness of the proposed methods and elucidate the tradeoffs between the methods.},
  keywords={},
  doi={10.1109/TSC.2020.3009084},
  ISSN={1939-1374},
  month={May},}@ARTICLE{9760072,
  author={Okegbile, Samuel D. and Maharaj, Bodhaswar T. and Alfa, Attahiru S.},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={A Multi-User Tasks Offloading Scheme for Integrated Edge-Fog-Cloud Computing Environments}, 
  year={2022},
  volume={71},
  number={7},
  pages={7487-7502},
  abstract={This paper presents a multi-user, multi-class and multi-layer edge computing-based framework for effective task offloading and computation processes. Important system requirements that were not captured in the existing multi-layer solutions such as offloading, computations and deadline requirements were captured in the system modeling, while both wireless communications and task computation constraints were considered. We considered three layers system, where each device offloads its generated tasks in each time slot to any selected layer for computation. On its arrival at such a selected layer, the task is only accepted if the queue size is below the pre-defined threshold, otherwise, such a task is offloaded to the next layer. Tasks were classified into class 1 and class 2 tasks following tasks’ quality of service requirements. We adopted stochastic geometry, parallel computing and queueing theory techniques to model the performance of the considered integrated edge-fog-cloud computing environment and obtained analysis for various performance metrics of interest. The obtained analyses demonstrate the importance of multi-layer and multi-class edge computing systems towards improving the experience of both delay-sensitive and mission-critical applications in any task offloading environment.},
  keywords={},
  doi={10.1109/TVT.2022.3167892},
  ISSN={1939-9359},
  month={July},}@INPROCEEDINGS{10074183,
  author={Morel, Alicia Esquivel and Calyam, Prasad and Qu, Chengyi and Gafurov, Durbek and Wang, Cong and Thareja, Komal and Mandal, Anirban and Lyons, Eric and Zink, Michael and Papadimitriou, George and Deelman, Ewa},
  booktitle={2023 International Conference on Computing, Networking and Communications (ICNC)}, 
  title={Network Services Management using Programmable Data Planes for Visual Cloud Computing}, 
  year={2023},
  volume={},
  number={},
  pages={130-136},
  abstract={Visual Cloud Computing (VCC) applications provide highly efficient solutions in video data processing pipelines on edge/cloud infrastructures. These applications and their infrastructures demand end-to-end monitoring and fine-grained application traffic control to meet user quality of experience requirements. In this paper, we propose a novel network services management methodology for VCC applications by leveraging the advantages of programmable data planes enabled by Protocol-independent Packet Processors (P4). Specifically, we define a custom fixed-length application header and use it to improve the performance of a video streaming application through congestion avoidance using Multi-Hop Route Inspection (MRI), a variant of In-band Network Telemetry (INT), and switch port forwarding (tunneling) capabilities. For evaluation experiments, we use P4 per-packet telemetry metadata for routing paths, ingress/egress timestamps, queue occupancy in a given node, and egress port link utilization in a VCC testbed on the NSF-supported FABRIC infrastructure. Our experiment results demonstrate performance improvement obtained with our methodology in terms of both packet loss and throughput metrics.},
  keywords={},
  doi={10.1109/ICNC57223.2023.10074183},
  ISSN={},
  month={Feb},}@ARTICLE{9829255,
  author={Fu, Shaojing and Huang, XueLun and Liu, Lin and Luo, Yuchuan},
  journal={IEEE Transactions on Cloud Computing}, 
  title={BFCRI: A Blockchain-Based Framework for Crowdsourcing With Reputation and Incentive}, 
  year={2023},
  volume={11},
  number={2},
  pages={2158-2174},
  abstract={With the rapid development of cloud computing and the sharing economy, crowdsourcing aroused widespread interest and adoption in providing intelligent and efficient services for humans. The majority of existing works focus on effective crowdsourcing task assignment and privacy protection, mostly relying on central servers and assuming that participants are $honest$honest-$and$and-$curious$curious and proactive. However, in reality, workers may be unwilling to participate, and there may be malicious behavior among participants, thus harming the enthusiasm and interests of other participants. The central server has weaknesses such as single point of failure. To address above problems, we propose a blockchain-based framework for crowdsourcing with reputation and incentive. We first design a worker selection scheme to select credible and capable workers. We leverage reputation as a metric of workers’ credibility, which is calculated through the improved subjective logic model. Then we utilize contract theory to design incentive mechanisms to attract more workers, especially high-quality workers to participate. Experimental results show that our proposed method can detect and prevent malicious participants and resist malicious collusion when the proportion of malicious participants is no more than 1/3. And encourage more workers to actively, honestly and continuously participate in crowdsourcing.},
  keywords={},
  doi={10.1109/TCC.2022.3190275},
  ISSN={2168-7161},
  month={April},}@INPROCEEDINGS{10047622,
  author={Gritto, D. and Muthulakshmi, P.},
  booktitle={2022 11th International Conference on System Modeling & Advancement in Research Trends (SMART)}, 
  title={Scheduling Cloudlets in a Cloud Computing Environment: A Priority-based Cloudlet Scheduling Algorithm (PBCSA)}, 
  year={2022},
  volume={},
  number={},
  pages={80-86},
  abstract={Cloud computing is a service model that has evolved in its stature beyond its traditional bounds of infrastructure, platform and software as a service. As the surge in resource demand may hit the cloud service provider at any time, a ceaseless monitoring system is vital. The allocation of an appropriate virtual machine for the cloudlet i.e., the user workload and maintaining the work load equilibrium among the resources is the most challenging operation in the cloud environment. The proper utilization of the cloud resources can be ensured by selecting the right cloudlet scheduling and load balancing algorithm(s). The cloudlet scheduling algorithm selection is based on the combination of two or more Quality of Service (QoS) and performance metrics like makespan, throughput, cost, power consumption, virtual machine or resource utilization and load balancing etc. The load balancer module takes the responsibility of dispersing the cloudlets evenly among the virtual machines by considering various features like CPU utilization, number of processing elements, bandwidth, memory and the load limit of the virtual machines. In this paper, an effort has been made to comprehend the most persisting cloudlet scheduling and load balancing algorithms that have been proposed by the researchers. Compiling the load balancing technologies that are integrated with the contemporary cloud platforms such as Amazon Web Services (AWS), Microsoft Azure and Google Cloud Platform (GCP) has also been prioritized. This study suggests a Priority Based Cloudlet Scheduling Algorithm (PBCSA) that schedules the cloudlet according to the user priority. The Min-Min scheduler is used to schedule the high priority cloudlets and the Max-Min scheduler is used to schedule the low priority cloudlets. The experimental findings reveals that, in the majority of scenarios, the proposed algorithm outperforms the Min-Min and Max-Min scheduling in terms of makespan and virtual machine utilization ratio.},
  keywords={},
  doi={10.1109/SMART55829.2022.10047622},
  ISSN={2767-7362},
  month={Dec},}@ARTICLE{10172271,
  author={Chang, Jiaxin and Wang, Jian and Li, Bing and Zhao, Yuqi and Li, Duantengchuan},
  journal={IEEE Transactions on Network and Service Management}, 
  title={Attention-Based Deep Reinforcement Learning for Edge User Allocation}, 
  year={2023},
  volume={},
  number={},
  pages={1-1},
  abstract={Edge computing, a recently developed computing paradigm, seeks to extend cloud computing by providing users minimal latency. In a mobile edge computing (MEC) environment, edge servers are placed close to edge users to offer computing resources, and the coverage of adjacent edge servers may partially overlap. Because of the restricted resource and coverage of each edge server, edge user allocation (EUA), i.e., determining the optimal way to allocate users to different servers in the overlapping area, has emerged as a major challenge in edge computing. Despite the NP-hardness of obtaining an optimal solution, it is possible to evaluate the quality of a solution in a short amount of time with given metrics. Consequently, deep reinforcement learning (DRL) can be used to solve EUA by attempting numerous allocations and optimizing the allocation strategy depending on the rewards of those allocations. In this study, we propose the Dual-sequence Attention Model (DSAM) as the DRL agent, which encodes users using self-attention mechanisms and directly outputs the probability of matching between users and servers using an attention-based pointer mechanism, enabling the selection of the most suitable server for each user. Experimental results show that our method outperforms the baseline approaches in terms of allocated users, required servers, and resource utilization, and its running speed meets real-time requirements.},
  keywords={},
  doi={10.1109/TNSM.2023.3292272},
  ISSN={1932-4537},
  month={},}@INPROCEEDINGS{9900564,
  author={Sankaran, Lakshmi and Saleema, J S and Suleiman, Basem},
  booktitle={2022 IEEE/ACIS 7th International Conference on Big Data, Cloud Computing, and Data Science (BCD)}, 
  title={Analysis of Workloads for Cloud Services}, 
  year={2022},
  volume={},
  number={},
  pages={117-123},
  abstract={Capturing best quality datasets for a study is the first evidence for better outcomes of research. If the analysis are based on such datasets, then the metrics, the characteristics and few factors determines proof point for well proven theories. Hence it is obvious that we rely on the best possible ways to arrive at such data acquiring sources. It can be either based on historical techniques or from the innovations in application of it to industry. This paper introduces a mapping framework for analyzing, and characterizing data previously used by research community and how they are made to fit for Cloud systems, i.e. using “workloads” and “datasets” as the “refined definitions”. It was contributed in the past two decades within the scientific community setting their own workflow analysis mechanisms. The framework thus is validated by acquiring a sample workload per layer of cloud. The sources are form the literature that are available from existing scientific theories. These workloads are then experimented against the three tiers of the cloud computing ie., IaaS(Infrastructure as a Service), PaaS(Platform as a Service), & SaaS(Software as a Service). The selected data is analyzed by the authors for an offline model presented here based on the Machine Learning tool-kits. There are future studies planned for and to be experimented in a cloud auto scaled environment with online model as well.},
  keywords={},
  doi={10.1109/BCD54882.2022.9900564},
  ISSN={},
  month={Aug},}@ARTICLE{10227869,
  author={Deebak, Bakkiam David and Hwang, Seong Oun},
  journal={IEEE Systems Journal}, 
  title={A Cloud-Assisted Medical Cyber-Physical System Using a Privacy-Preserving Key Agreement Framework and a Chebyshev Chaotic Map}, 
  year={2023},
  volume={17},
  number={4},
  pages={5543-5554},
  abstract={At present, communication networks like the Internet of Things (IoT) are emerging with some of the latest technologies, such as artificial intelligence, big data, and cloud computing, to enable wireless edge infrastructures and seamless data migration. In particular, edge-based wireless communications help to gain new insights into the mitigation of potential communicable infections, e.g., COVID-19, via the use of IoT sensing devices. Of late, an evolving technology known as the cloud-assisted medical cyber-physical system (MCPS) has explored various key agreement protocols to examine security weaknesses between sensing devices and medical experts. Unfortunately, the existing schemes address vulnerabilities such as impersonation, privileged insider, and password guessing, whereby the behavior of the system becomes nondeterministic when guarding against malicious intent. Also, failures, faults, and attacks may vary in the characteristic forms of the IoT and the MCPS, causing unforeseen impairments in the system and for users. Thus, this article develops a privacy-preserving key agreement framework (PP-KAF) using the Chebyshev chaotic map mechanism to avoid privacy data disclosures and to protect session keys. The proposed PP-KAF exploits a strategy of two-way authentication not only to protect user identities but also to achieve untraceability from the remote server. Finally, a formal analytical model is applied to examine the properties of the key agreement protocol. Simulation results demonstrate that the proposed PP-KAF can offer better security efficiencies and can mitigate computation and communication overhead to guarantee improved quality metrics, namely, throughput rate and energy consumption.},
  keywords={},
  doi={10.1109/JSYST.2023.3303460},
  ISSN={1937-9234},
  month={Dec},}@INPROCEEDINGS{9860577,
  author={Tuli, Shreshth and Casale, Giuliano and Jennings, Nicholas R.},
  booktitle={2022 IEEE 15th International Conference on Cloud Computing (CLOUD)}, 
  title={MetaNet: Automated Dynamic Selection of Scheduling Policies in Cloud Environments}, 
  year={2022},
  volume={},
  number={},
  pages={331-341},
  abstract={Task scheduling is a well-studied problem in the context of optimizing the Quality of Service (QoS) of cloud computing environments. In order to sustain the rapid growth of computational demands, one of the most important QoS metrics for cloud schedulers is the execution cost. In this regard, several data-driven deep neural networks (DNNs) based schedulers have been proposed in recent years to allow scalable and efficient resource management in dynamic workload settings. However, optimal scheduling frequently relies on sophisticated DNNs with high computational needs implying higher execution costs. Further, even in non-stationary environments, sophisticated schedulers might not always be required and we could briefly rely on low-cost schedulers in the interest of cost-efficiency. Therefore, this work aims to solve the non-trivial meta problem of online dynamic selection of a scheduling policy using a surrogate model called MetaNet. Unlike traditional solutions with a fixed scheduling policy, MetaNet on-the-fly chooses a scheduler from a large set of DNN based methods to optimize task scheduling and execution costs in tandem. Compared to state-of-the-art DNN schedulers, this allows for improvement in execution costs, energy consumption, response time and service level agreement violations by up to 11, 43, 8 and 13 percent, respectively.},
  keywords={},
  doi={10.1109/CLOUD55607.2022.00056},
  ISSN={2159-6190},
  month={July},}@INPROCEEDINGS{10322008,
  author={Malti, Arslan Nedhir and Benmammar, Badr and Hakem, Mourad},
  booktitle={2023 5th International Conference on Pattern Analysis and Intelligent Systems (PAIS)}, 
  title={Task Scheduling Optimization in Cloud Computing: A Comparative Study Between Flower Pollination and Butterfly Optimization Algorithms}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={The No Free Lunch theorem states that no single algorithm can universally serve as the best solution for all optimization purposes. Consequently, it becomes imperative to adapt or combine the fundamental structures of metaheuristic optimization algorithms to fit with specific problem-solving requirements. In this paper, we conduct a comparative analysis of two widely recognized metaheuristic algorithms, namely the Butterfly Optimization Algorithm (BOA) and the Flower Pollination Algorithm (FPA) to deal with the task scheduling problem in cloud computing systems. Our objective is to orchestrate the most effective assignment of tasks across the available virtual machines in the system. Performance evaluation encompasses standard and synthetic workloads, focusing on conflicting quality of service metrics, namely time makespan or schedule length and resource utilization. The experiments conducted through the CloudSim framework demonstrate compelling outcomes, highlighting the importance of this study as a basis for future optimization research.},
  keywords={},
  doi={10.1109/PAIS60821.2023.10322008},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10254974,
  author={Caon, Cristiano E. and Li, Jie and Chen, Yong},
  booktitle={2023 IEEE 16th International Conference on Cloud Computing (CLOUD)}, 
  title={Effective Management of Time Series Data}, 
  year={2023},
  volume={},
  number={},
  pages={408-414},
  abstract={Cloud computing systems, consisting of numerous nodes and components, require constant monitoring to satisfy the Quality-of-Service (QoS), making the management of large-scale time series data challenging. To address this issue, age threshold retention policies have been implemented to remove historical data, but this eliminates valuable information from older periods. In this paper, we proposed an alternative approach that applies time series deduplication with metric-based tolerance to discard readings that stabilize within a calculated tolerance window. This approach can reduce the data volume by 70.38% on average. Once the data-reduced interval is queried, the readings can be reconstructed to retrieve the original granularity with low query runtime overhead and a Mean Absolute Percentage Error of 0.74%.},
  keywords={},
  doi={10.1109/CLOUD60044.2023.00055},
  ISSN={2159-6190},
  month={July},}@ARTICLE{10236903,
  author={Tuli, Shreshth and Casale, Giuliano and Jennings, Nicholas R.},
  journal={IEEE Transactions on Computers}, 
  title={SciNet: Codesign of Resource Management in Cloud Computing Environments}, 
  year={2023},
  volume={72},
  number={12},
  pages={3590-3602},
  abstract={The rise of distributed cloud computing technologies has been pivotal for the large-scale adoption of Artificial Intelligence (AI) based applications for high fidelity and scalable service delivery. Systematic resource management is central in maintaining optimal Quality of Service (QoS) in cloud platforms and is divided into three fundamental types: resource provisioning, AI model deployment and workload placement. To exploit the synergy among these decision types, it becomes imperative to concurrently design (co-design) the provisioning, deployment and placement decisions for optimal QoS. As users and cloud service providers shift to non-stationary AI-based workloads, frequent decision making imposes severe time constraints on the resource management models. Existing AI-based solutions often optimize decision types independently and tend to ignore the dependencies across various system performance aspects such as energy consumption and CPU utilization, making them perform poorly in large-scale cloud systems. To address this, we propose a novel method, called SciNet, that leverages a co-simulated digital-twin of the infrastructure to capture inter-metric dependencies and accurately estimate QoS scores. To avoid expensive simulation overheads at test time, SciNet trains a neural network based imitation learner that aims to mimic an oracle, which takes optimal decisions based on co-simulated QoS estimates. Offline model training and online decision making based on the imitation learner, enables SciNet to take optimal decisions while being time-efficient. Experiments with real-life AI-based benchmark applications on a public cloud testbed show that SciNet gives up to 48% lower execution cost, 79% higher inference accuracy, 71% lower energy consumption and 56% lower response times compared to the current state-of-the-art methods.},
  keywords={},
  doi={10.1109/TC.2023.3310678},
  ISSN={1557-9956},
  month={Dec},}@INPROCEEDINGS{9988009,
  author={Sripavithra, C K and Kirubanand, V B},
  booktitle={2022 International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME)}, 
  title={ESSA Scheduling Algorithm for Optimizing Budget-Constrained Workflows}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Workflows are a systematic approach for defining various scientific applications of distributed systems. They break down complicated, data-intensive processes into minor activities that can be executed serially or in parallel according to the type of application. Cloud systems need to allocate resources and schedule workflows efficiently. Despite many studies on job scheduling and resource provisioning, an efficient solution isn't found. Therefore, techniques are required to enhance resource utilization for optimal cloud computing platforms. Hence, user and provider quality of service (QoS) goals, like shortening workflows and ensuring budget limits with low energy utilization, must be considered. Enhanced Salp Swarm Optimization (ESSA) is designed to optimize makespan and QoS metrics in cloud systems. A Virtual Machine (VM's) compute capacity is related to Central Processing Unit (CPU) and memory. Size and memory demand is considered for tasks in the workflow, and task execution time is evaluated using both CPU and memory. The collated experimental outcomes convey that the newly presented technique boosts the workflows' energy utilization (up to 89%) and pushes the normalized makespan results to 3.2ms.},
  keywords={},
  doi={10.1109/ICECCME55909.2022.9988009},
  ISSN={},
  month={Nov},}@ARTICLE{8762170,
  author={Abdelbaky, Moustafa and Parashar, Manish},
  journal={IEEE Transactions on Services Computing}, 
  title={A General Performance and QoS Model for Distributed Software-Defined Environments}, 
  year={2022},
  volume={15},
  number={1},
  pages={228-240},
  abstract={The landscape for cloud services and cyberinfrastructure offerings has increased drastically over the past few years. Initially, users moved their applications to the cloud to take advantage of a pay-per-usage model and on-demand access. However, as more cloud providers joined the market, users shifted their goals for using cloud computing from cost reduction to resilience, agility, and optimization. These goals can be achieved by dynamically combining services from multiple providers, for example, to avoid data center or cloud zone outages or to take advantage of extensive offerings with different price points. However, to efficiently support application deployment in this dynamic environment, new models and tools that can measure the application performance and the Quality of Service (QoS) of different configurations are required. The goal of this work is to evaluate the application performance and the QoS of a distributed Software-Defined Environment as well as calculate the QoS of alternative configurations from the underlying pool of services. In particular, we present a mathematical model and a tool for evaluating the performance and QoS of batch application workflows in a distributed environment. We experimentally evaluate the proposed model using a bioinformatics workflow running on infrastructure services from multiple cloud providers.},
  keywords={},
  doi={10.1109/TSC.2019.2928300},
  ISSN={1939-1374},
  month={Jan},}@ARTICLE{9625857,
  author={Hidayetoğlu, Mert and Biçer, Tekin and de Gonzalo, Simon Garcia and Ren, Bin and Gürsoy, Doğa and Kettimuthu, Rajkumar and Foster, Ian T. and Hwu, Wen-Mei W.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={MemXCT: Design, Optimization, Scaling, and Reproducibility of X-Ray Tomography Imaging}, 
  year={2022},
  volume={33},
  number={9},
  pages={2014-2031},
  abstract={This work extends our previous research entitled “MemXCT: Memory-centric X-ray CT Reconstruction with Massive Parallelization” that was originally published at SC19 conference (Hidayetoğlu et al., 2019) with reproducibility of the computational imaging performance. X-ray computed tomography (XCT) is regularly used at synchrotron light sources to study the internal morphology of materials at high resolution. However, experimental constraints, such as radiation sensitivity, can result in noisy or undersampled measurements. Further, depending on the resolution, sample size and data acquisition rates, the resulting noisy dataset can be in the order of terabytes. Advanced iterative reconstruction techniques can produce high-quality images from noisy measurements, but their computational requirements have made their use an exception rather than the rule. We propose a novel memory-centric approach that avoids redundant computations at the expense of additional memory complexity. We develop a memory-centric iterative reconstruction system, MemXCT, that uses an optimized SpMV implementation with two-level pseudo-Hilbert ordering and multi-stage input buffering. We evaluate MemXCT on various supercomputer architectures involving KNL and GPU. MemXCT can reconstruct a large (11K×11K) mouse brain tomogram in 10 seconds using 4096 KNL nodes (256K cores). The results presented in our original article at the SC19 were based on large-scale supercomputing resources. The MemXCT application was selected for the Student Cluster Competition (SCC) Reproducibility Challenge and evaluated on a variety of cloud computing resources by universities around the world in the SC20 conference. We summarize the results of the top-ranked SCC Reproducibility Challenge teams and identify the most pertinent measures for ensuring the reproducibility of our experiments in this article.},
  keywords={},
  doi={10.1109/TPDS.2021.3128032},
  ISSN={1558-2183},
  month={Sep.},}@ARTICLE{9785848,
  author={Rui, Lanlan and Song, Dai and Chen, Shiyou and Yang, Yingtai and Yang, Yang and Gao, Zhipeng},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Content Collaborative Caching Strategy in the Edge Maintenance of Communication Network: A Joint Download Delay and Energy Consumption Method}, 
  year={2022},
  volume={33},
  number={12},
  pages={4148-4163},
  abstract={With the development of Big Data technology and Internet, the surge of data in the network will cause network congestion and untimely task processing. Additionally, caching content in the core network may cause redundant access of content and backhaul bottlenecks. Due to the increasing requirements of users for task processing efficiency, the centralized maintenance system based on traditional cloud computing cannot meet the current computing requirements. In view of these problems, we propose a content collaborative caching mechanism based on joint decision of download delay and energy consumption. By integrating network coding and content caching technology, the work content maintained in the communication network is deployed near the edge of the network in the form of coding to reduce the redundant transmission of content and acquisition time of content. This article establishes a user QoE satisfaction model, which consists of two indexes that measure time delay and energy consumption. This article proposes a $\varepsilon$ɛ-hybrid Q-learning algorithm to optimize the placement of cache files, and made the cache action selection based on the combination of improved heuristic greedy algorithm and simulated annealing algorithm. The experimental results show that the proposed cache strategy can reduce the delay of users downloading content and the energy consumption of content cache, so as to improve the quality of field maintenance work in communication network.},
  keywords={},
  doi={10.1109/TPDS.2022.3179271},
  ISSN={1558-2183},
  month={Dec},}@INPROCEEDINGS{10017214,
  author={Sharma, P. and Saini, K. S. and Sidhu, P. K.},
  booktitle={The 3rd International Conference on Distributed Sensing and Intelligent Systems (ICDSIS 2022)}, 
  title={Authentication mechanisms used in Wireless Body Area Networks: a study}, 
  year={2022},
  volume={2022},
  number={},
  pages={282-291},
  abstract={The WBANs (Collection of light-weight body sensor) of IOT and Cloud Computing provides a substantial ability to upgrade the quality of on-demand health care system. Body Sensors are implanted within or outside the human being body to remotely measure the real-time parameters such as physiology signal and activity. The biggest issue originates from obtaining imprecise and inconsistent measurements when collecting these data from sensor nodes. Moreover, Privacy and Security of human sensitive information are other biggest hurdles of WBANs. In this chapter we describe some wearable devices, security requirements and some security attacks. Moreover, we also discussed various existing authentication mechanisms. Different authentication mechanisms have their own Pros and Cons. Further, based on the study we will performed some comprehensive overview between all existing authentication mechanisms and find some future scope. We also highlight some future research scope in the last section.},
  keywords={},
  doi={10.1049/icp.2022.2478},
  ISSN={},
  month={Oct},}@ARTICLE{9933021,
  author={Lu, Ke and Du, Zhekai and Li, Jingjing and Min, Geyong},
  journal={IEEE Transactions on Network and Service Management}, 
  title={Resource-Efficient Distributed Deep Neural Networks Empowered by Intelligent Software-Defined Networking}, 
  year={2022},
  volume={19},
  number={4},
  pages={4069-4081},
  abstract={Contemporary machine learning methods have evolved from conventional algorithms to deep neural networks (DNNs) that are computation- and data- intensive. Thus, they are suitable to be deployed in the cloud that can offer high computational capacity and scalable resources. However, the cloud computing paradigm is not optimal for delay- and energy-sensitive applications. To mitigate these problems, a battery of distributed DNNs have been proposed to allow a fast inference with device-edge-cloud synergy. Furthermore, although distributed deployment of DNNs on real communication networks is an important research topic, the legacy network architecture cannot meet the requirements of these distributed deep neural networks due to the complicated management and manual configuration, etc. To cope with these requirements, we develop a novel and explicit Intelligent Software Defined Networking (ISDN) that aims to manage the bandwidth and computing resources across the network via the SDN paradigm. We first identify the difficulties of deploying distributed intelligent computing in the current network architecture. Then, we explain how to address these problems by introducing the ISDN architecture. Specifically, we develop a dynamic routing method to enable Quality-of-Service (QoS) communication based on the SDN paradigm and propose a Markov Decision Process (MDP) based dynamic task offloading model to achieve the optimal offloading policy of DNN tasks. We develop a simulation platform based on Mininet to measure its performance advantages over traditional architectures. Extensive experimental results show that compared with the traditional network architecture, our architecture based on the SDN paradigm can perform better in terms of both network throughput and resource utilization.},
  keywords={},
  doi={10.1109/TNSM.2022.3218173},
  ISSN={1932-4537},
  month={Dec},}@INPROCEEDINGS{10001602,
  author={Zhu, Jing and Wang, Dan and Qin, Shuxin and Tao, Gaofeng and Gui, Hongxin and Li, Fang and Ou, Liang},
  booktitle={GLOBECOM 2022 - 2022 IEEE Global Communications Conference}, 
  title={Towards Network Dynamics: Adaptive Buffer Management with Deep Reinforcement Learning}, 
  year={2022},
  volume={},
  number={},
  pages={4935-4940},
  abstract={The prosperity of cloud computing and 5G/B5G is bringing a wide range of delay jitter-sensitive applications (e.g., professional audio/video streaming and industrial automation) to large-scale IP networks. Although various network-side techniques have been proposed to guarantee the quality of service (QoS), the client-side technique by introducing a receive buffer should never be neglected from the applications' perspective. In this paper, we revisit the buffer management problem to address the disadvantages of state-of-the-art studies, which as-sumed network characteristics known a prior with simplified or inaccurate network models and failed to adapt to network dynamics. Specifically, we propose adaptive buffer management with deep reinforcement learning, i.e., DRL-ABM. We first define a tradeoff value to measure the buffer management performance in terms of the start-up delay, underflow frequency and packet losses. Then we formulate the DRL model and design deep neural networks (DNNs) based on the advantage actor critic (A2C) algorithm. To evaluate the performance of DRL-ABM, we perform extensive simulations. Simulation results show that D RL-ABM can achieve better buffer management performance, i.e., reducing the tradeoff value by at least 20% when compared with the benchmarks TBM and ABM. Moreover, DRL-ABM reduces packet losses to approximately 0, indicating that a smaller receive buffer is sufficient if managed with DRL-ABM.},
  keywords={},
  doi={10.1109/GLOBECOM48099.2022.10001602},
  ISSN={},
  month={Dec},}@ARTICLE{10192547,
  author={Zhou, Jun and Kondo, Masaaki},
  journal={IEEE Transactions on Emerging Topics in Computing}, 
  title={An Edge-Cloud Collaboration Framework for Graph Processing in Smart Society}, 
  year={2023},
  volume={11},
  number={4},
  pages={985-1001},
  abstract={Due to the limitations of cloud computing on latency, bandwidth and data confidentiality, edge computing has emerged as a novel location-aware way to provide the capacity-constrained portable terminals with more processing capacity to improve the computing performance and quality of service (QoS) in several typical domains of the human activity in smart society, such as social networks, medical diagnosis, telecommunications, recommendation systems, internal threat detection, transportation, Internet of Things (IoT), etc. These application domains often manage a vast collection of entities with various relationships, which can be naturally represented by the graph data structure. Graph processing is a powerful tool to model and optimize complex problems where graph-based data is involved. In consideration of the relatively insufficient resource provisioning of the edge devices, in this article, for the first time to our knowledge, we propose a reliable edge-cloud collaboration framework that facilitates the graph primitives based on a lightweight interactive graph processing library (GPL), especially for shortest path search (SPS) operations as the demonstrative example. Two types of different practical cases are also presented to show the typical application scenarios of our graph processing strategy. Experimental evaluations indicate that the acceleration rate of performance can reach 6.87x via graph reduction, and less than 3% and 20% extra latency is required for much better user experiences for navigation and pandemic control, respectively, while the online security measures merely consume about 1% extra time of the overall data transmission. Our framework can efficiently execute the applications with considering of user-friendliness, low-latency response, interactions among edge devices, collaboration between edge and cloud, and privacy protection at an acceptable overhead.},
  keywords={},
  doi={10.1109/TETC.2023.3297066},
  ISSN={2168-6750},
  month={Oct},}
