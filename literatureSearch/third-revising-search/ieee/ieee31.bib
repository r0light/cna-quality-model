@INPROCEEDINGS{10355514,
  author={Samarakoon, Sahan and Bandara, Shashika and Jayasanka, Nishan and Hettiarachchi, Chathuranga},
  booktitle={2023 Moratuwa Engineering Research Conference (MERCon)}, 
  title={Self-Healing and Self-Adaptive Management for IoT-Edge Computing Infrastructure}, 
  year={2023},
  volume={},
  number={},
  pages={473-478},
  abstract={Containerized micro-service oriented computing deployment strategies have proven to possess resilience, selfadaptive, and self-healing properties in cloud computing environments. The rapid growth of smart Internet of Things (IoT) deployments necessitates a similar approach to mitigate the challenges associated with manually managing large fleets of IoT devices. To address these challenges, we propose a novel software framework that extends Kubernetes(K8s) to collect and integrate IoT device performance metrics. By leveraging this framework, a set of self-healing and self-adaptive strategies can be deployed, taking into account the status of IoT devices. In our research, we evaluate the impact of IoT device-to-edge compute latency, bandwidth, and jitter information using the proposed software framework, including a metrics collection plugin and a custom scheduler. The results demonstrate significant enhancements in Quality of Service measures for a benchmark application scenario, emphasizing the framework’s ability to reduce manual intervention efforts through extended adaptation strategies.},
  keywords={},
  doi={10.1109/MERCon60487.2023.10355514},
  ISSN={2691-364X},
  month={Nov},}@INPROCEEDINGS{10329061,
  author={Nguyen, Michael and Sood, Kanika and Avery, Kenytt and Bein, Doina},
  booktitle={2023 5th International Conference on Robotics and Computer Vision (ICRCV)}, 
  title={Deep Learning-based Super-Resolution on the Cloud: Focus on Face and Text Enhancement}, 
  year={2023},
  volume={},
  number={},
  pages={124-129},
  abstract={Real-ESRGAN and SwinIR are two deep learning models for Single-Image Super-Resolution (SISR), which attempt to address real-world scenarios for image enhancement. However, the pre-trained models do not effectively handle LR images containing human faces and text. An experiment is conducted to expand upon the training performed in their respective studies and improve the image enhancement using a cloud computing environment. Traditional image quality metrics, Peak Signal-toNoise Ratio (PSNR), and Structural Similarity (SSIM), are used to objectively evaluate the image quality. Three learning-based perceptual metrics, the Blind / Referenceless Image Spatial Quality Evaluator (BRISQUE), Naturalness Image Quality Evaluator (NIQE), and the Learned Perceptual Image Patch Similarity (LPIPS), are also incorporated to assess how images would be subjectively perceived based on human perception. To evaluate the model performance of Real-ESRGAN and SwinIR, specifically for face and text images, both traditional and perceptual metrics are taken into consideration, in addition to the cost associated with model training using Microsoft Azure. The findings show that with additional fine-tuning, SwinIR has slightly improved PSNR and SSIM values while taking less training time compared to Real-ESRGAN at the cost of perceptual quality.},
  keywords={},
  doi={10.1109/ICRCV59470.2023.10329061},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9744289,
  author={Volkov, A. O. and Korobkina, A. V. and Stepanov, S. N.},
  booktitle={2022 Systems of Signals Generating and Processing in the Field of on Board Communications}, 
  title={Development of a Model and Algorithms for Servicing Real-Time and Data Traffic in a Cloud Computing System}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={Today, modern low earth orbit (LEO) mobile satellite systems require constant data exchange with cloud computing centers located on Earth to work correctly. Moreover, there is both real-time data transmission and data that allows for a delay, this, for example, may be telemetry data. In the described model the key performance features of the conjoint traffic processing were defined. They are defined using values of probabilities of the model’s stationary states. The numerical algorithm of measuring of designed performance metrics by solving the state equations system with the help of the Gauss-Zeidel algorithm is presented. The model and the resulting algorithms can be used to assess the service quality and load levels of a small cloud computing node. One of the possible options for future research on this topic may be to restrict the access of applications for data processing to prioritize the processing of real-time applications.},
  keywords={},
  doi={10.1109/IEEECONF53456.2022.9744289},
  ISSN={2768-0118},
  month={March},}@INPROCEEDINGS{9972509,
  author={Rajesh, K.N.V.S.S.K. and Redd, K. Thammi and Murthy, N.V.E.S. and Sarma, M. Subrahmanya},
  booktitle={2022 IEEE 2nd Mysore Sub Section International Conference (MysuruCon)}, 
  title={Augmenting Additional Quality of Services for Adaptability and Reliability of Cloud Infrastructure}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Adoption of Cloud computing has been increased by multi fold in the recent past in order to cope up with business requirements. There are few Quality of Service (QoS) metrics which augment the availability of cloud hosted applications. However, still there are quite a few challenges to be addressed in order to improve degree of trust in cloud computing. One of the key challenges observed is, there were no quality of services (QoS) metrics augmented with the PaaS which checks certain parameters covering Disk space utilization and Memory utilization etc., which are the root cause for any priority incidents pertaining to cloud hosted service availability. This paper aims to study the current quality of services available and augment additional quality of services to scale up the services for need of the hour requirements covering site reliability engineering (SRE). Experimentation has been done with the help of major cloud services platforms such as AWS and results were analyzed and attached to this paper.},
  keywords={},
  doi={10.1109/MysuruCon55714.2022.9972509},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10346675,
  author={Alkhazali, Abdel Rahman Mohammad and Khasawneh, Ahmad M. and Alzoubi, Sharaf and Magableh, Murad and Mohamed, Rajina R. and Pandey, Bishwajeet},
  booktitle={2023 International Conference on Computer Science and Emerging Technologies (CSET)}, 
  title={Cloud Computing in Smart Cities: Privacy, Ethical and Social Issues}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={The rapid development of cloud computing technologies has revolutionized various sectors, and smart cities are no exception. Smart cities leverage cloud computing to optimize urban services, enhance resource management, and improve the overall quality of life for their inhabitants. However, as these technological advancements proliferate, concerns about privacy, ethical considerations, and social implications have emerged. This research paper critically examines the multifaceted challenges associated with the integration of cloud computing in smart cities, shedding light on the potential risks and highlighting the need for comprehensive solutions. The research employs a mixed-methods approach, combining quantitative data analysis and qualitative case studies to offer a comprehensive perspective on the identified issues. The primary focus lies in identifying privacy risks, ethical dilemmas, and social disparities that arise due to the extensive use of cloud-based systems and data in smart cities. Furthermore, the study investigates the role of key stakeholders, including governments, technology providers, and citizens, in mitigating or exacerbating these challenges. Key findings reveal that while cloud computing empowers smart cities with unparalleled capabilities, it also exposes residents' personal information to potential breaches and misuse. Ethical concerns arise from the handling of sensitive data, data ownership, and algorithmic biases that could perpetuate discrimination. Moreover, social issues like the digital divide and access disparities may further exacerbate existing inequalities in smart city implementation. This research paper concludes by proposing a comprehensive framework of guidelines and best practices to address the identified issues effectively. These recommendations encompass enhanced data privacy measures, transparent and accountable data governance, the promotion of ethical data usage, and inclusive strategies to bridge social disparities. By adopting these measures, smart cities can harness the full potential of cloud computing while safeguarding individual rights and fostering a more equitable and inclusive urban environment. Overall, this study underscores the critical importance of addressing privacy, ethical, and social challenges in the context of cloud computing in smart cities. By adopting a holistic and proactive approach, city planners, policymakers, and technology providers can build sustainable and responsible smart cities that ensure the well-being and dignity of their residents in the digital era.},
  keywords={},
  doi={10.1109/CSET58993.2023.10346675},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10078974,
  author={Li, Qixiu},
  booktitle={2022 2nd International Conference on Networking, Communications and Information Technology (NetCIT)}, 
  title={Construction of Agricultural Economic Data Management and Service Platform Based on Improved Genetic Algorithm}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={As a large agricultural country, agriculture is the foundation of China's national economy. Agricultural informatization construction is a major measure to strengthen the basic position of agriculture and promote the new agricultural scientific and technological revolution. It is of great significance to develop agricultural economy and promote the construction of a new socialist countryside. With the rise and continuous improvement of cloud computing, it has brought new inspiration to the construction of agricultural informatization. Cloud computing is the latest network information technology at present. It creates a new model of serving computing resources, storage resources and information resources under the condition of rapid network development, so that information can spread at a high speed, so that farmers can get better agricultural technology and more agricultural information resources in the shortest time, so as to greatly improve the agricultural economy. In recent years, the new cloud computing technology provides a new method and feeling for the construction of agricultural economic management information service platform. In order to realize the rapid acquisition of a variety of information resources and the sharing of information data, and improve the service level and service quality of agricultural information, taking the new IT resource model “cloud computing” as the starting point, computing and big data are distributed on computers all over the country. People can easily obtain applications, data and resources through mobile phones, computers and other services. Relying on cloud computing technology, the agricultural economic management information service platform can not only give full play to the township Internet and call rate with high coverage in China, but also realize unlimited capacity storage, fast and high-speed operation and fast and efficient information transmission that cannot be realized by traditional technology without pressure. So as to realize the convenient access and comprehensive sharing of a variety of information resources, and improve the level and quality of agricultural information services.},
  keywords={},
  doi={10.1109/NetCIT57419.2022.00105},
  ISSN={},
  month={Dec},}@ARTICLE{8937836,
  author={Lin, Weiwei and Wu, Wentai and He, Ligang},
  journal={IEEE Transactions on Services Computing}, 
  title={An On-Line Virtual Machine Consolidation Strategy for Dual Improvement in Performance and Energy Conservation of Server Clusters in Cloud Data Centers}, 
  year={2022},
  volume={15},
  number={2},
  pages={766-777},
  abstract={As data centers are consuming massive amount of energy, improving the energy efficiency of cloud computing has emerged as a focus of research. However, it is challenging to reduce energy consumption while maintaining system performance without increasing the risk of Service Level Agreement violations. Most of the existing consolidation approaches for virtual machines (VMs) consider system performance and Quality of Service (QoS) metrics as constraints, which usually results in large scheduling overhead and impossibility to achieve effective improvement in energy efficiency without sacrificing some system performance and cloud service quality. In this article, we first define the metrics of peak power efficiency and optimal utilization for heterogeneous physical machines (PMs). Then we propose Peak Efficiency Aware Scheduling (PEAS), a novel strategy of VM placement and reallocation for achieving dual improvement in performance and energy conservation from the perspective of server clusters. PEAS allocates and reallocates VMs in an on-line manner and always attempts to maintain PMs working in their peak power efficiency via VM consolidation. Extensive experiments on Cloudsim show that PEAS outperforms several energy-aware consolidation algorithms with regard to energy consumption, system performance as well as multiple QoS metrics.},
  keywords={},
  doi={10.1109/TSC.2019.2961082},
  ISSN={1939-1374},
  month={March},}@INPROCEEDINGS{9964896,
  author={Jônatas dos Passos, Edenilson and Fiorese, Adriano},
  booktitle={2022 18th International Conference on Network and Service Management (CNSM)}, 
  title={Monitoring Metrics for Load Balancing over Video Content Distribution Servers}, 
  year={2022},
  volume={},
  number={},
  pages={247-253},
  abstract={Cloud computing and video streaming services have been in constant expansion in recent years. Along with it, the demand for computing resources has also increased significantly. In this context, monitoring the use of these resources is crucial to maintain a satisfactory level of Quality of Service and, consequently, Quality of Experience, especially in video transmission services. This work discusses a new method of monitoring resources and quality of service metrics on content servers involving CPU utilization and server throughput, which is obtained in a distributed way. For that, a distributed collector system that is based on a modified version of the ring election algorithm is developed to retrieve the Quality of Service metrics in each server. Evaluation experiment results show that there are no performance gains on the system such as the content loading faster for the user, there are however, improvements in terms of the whole system scalability. The greater the number of servers for monitoring, the better the approach is compared to the traditional method of monitoring resources through request and response.},
  keywords={},
  doi={10.23919/CNSM55787.2022.9964896},
  ISSN={2165-963X},
  month={Oct},}@INPROCEEDINGS{9793442,
  author={Mangalampalli, Sudheer and Pokkuluri, Kiran Sree and Satish, G. Naga and Swain, Sangram Keshari},
  booktitle={2022 International Conference on Computing, Communication and Power Technology (IC3P)}, 
  title={Effective VM Placement Mechanism in Cloud Computing using Cuckoo Search Optimization}, 
  year={2022},
  volume={},
  number={},
  pages={238-241},
  abstract={Effective VM placement mechanism is needed for Cloud Computing as incoming flow of tasks were dynamic when they are coming onto cloud console. Incoming requests for any cloud console were large in number then there is a chance of decay in quality of service. Quality of service will be degraded when these number of requests were not properly handled i.e. SLA violations and more number of migrations. Quality of Service will be directly affected by these parameters. Many of the authors addressed these metrics but still there is a chance to improve the VM placement in cloud computing. In this paper, we have used a nature inspired algorithm i.e. cuckoo search to design the VM placement strategy and we have used a threshold value to identify the physical host whet her it is overloaded, under loaded or balanced based on the utilization of CPU. Cloudsim toolkit is used as a simulator to conduct simulation and our proposed mechanism minimizes violation of SLA and there is a great improvement in makespan when it was compared with PSO and GA algorithms.},
  keywords={},
  doi={10.1109/IC3P52835.2022.00057},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{9779689,
  author={Vale, Guilherme and Correia, Filipe Figueiredo and Guerra, Eduardo Martins and de Oliveira Rosa, Thatiane and Fritzsch, Jonas and Bogner, Justus},
  booktitle={2022 IEEE 19th International Conference on Software Architecture (ICSA)}, 
  title={Designing Microservice Systems Using Patterns: An Empirical Study on Quality Trade-Offs}, 
  year={2022},
  volume={},
  number={},
  pages={69-79},
  abstract={The promise of increased agility, autonomy, scalability, and reusability has made the microservices architecture a de facto standard for the development of large-scale and cloud-native commercial applications. Software patterns are an important design tool, and often they are selected and combined with the goal of obtaining a set of desired quality attributes. However, from a research standpoint, many patterns have not been widely validated against industry practice, making them not much more than interesting theories. To address this, we investigated how practitioners perceive the impact of 14 patterns on 7 quality attributes. Hence, we conducted 9 semi-structured interviews to collect industry expertise regarding (1) knowledge and adoption of software patterns, (2) the perceived architectural trade-offs of patterns, and (3) metrics professionals use to measure quality attributes. We found that many of the trade-offs reported in our study matched the documentation of each respective pattern, and identified several gains and pains which have not yet been reported, leading to novel insight about microservice patterns.},
  keywords={},
  doi={10.1109/ICSA53651.2022.00015},
  ISSN={},
  month={March},}@ARTICLE{9238484,
  author={Mahmoudi, Nima and Khazaei, Hamzeh},
  journal={IEEE Transactions on Cloud Computing}, 
  title={Performance Modeling of Serverless Computing Platforms}, 
  year={2022},
  volume={10},
  number={4},
  pages={2834-2847},
  abstract={Analytical performance models have been leveraged extensively to analyze and improve the performance and cost of various cloud computing services. However, in the case of serverless computing, which is projected to be the dominant form of cloud computing in the future, we have not seen analytical performance models to help with the analysis and optimization of such platforms. In this work, we propose an analytical performance model that captures the unique details of serverless computing platforms. The model can be leveraged to improve the quality of service and resource utilization and reduce the operational cost of serverless platforms. Also, the proposed performance model provides a framework that enables serverless platforms to become workload-aware and operate differently for different workloads to provide a better trade-off between the cost and performance depending on the user's preferences. The current serverless offerings require the user to have extensive knowledge of the internals of the platform to perform efficient deployments. Using the proposed analytical model, the provider can simplify the deployment process by calculating the performance metrics for users even before physical deployments. We validate the applicability and accuracy of the proposed model by extensive experimentation on AWS Lambda. We show that the proposed model can calculate essential performance metrics such as average response time, probability of cold start, and the average number of function instances in the steady-state. Also, we show how the performance model can be used to tune the serverless platform for each workload, which will result in better performance or lower cost without scarifying the other. The presented model assumes no non-realistic restrictions, so that it offers a high degree of fidelity while maintaining tractability at large scale.},
  keywords={},
  doi={10.1109/TCC.2020.3033373},
  ISSN={2168-7161},
  month={Oct},}@INPROCEEDINGS{10294685,
  author={Bai, Yiming and Chen, Lei and Lei, Ying and Xie, Hongjuan},
  booktitle={2023 5th International Conference on Data-driven Optimization of Complex Systems (DOCS)}, 
  title={A Deep Learning Prediction Approach for Machine Workload in Cloud Computing}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={Accurate workload prediction for cloud computing clusters is essential to ensure Quality of Service (QoS), meet Service Level Agreements (SLAs), and minimize energy consumption. In a cloud computing environment, cloud servers collect and store large sets of time series data, including metrics such as CPU usage, network traffic, and disk I/O at each point in time. The fluctuations in these metrics show noticeable temporal correlations. Therefore, these data can be used in time series data prediction models to predict upcoming workload scenarios. However, traditional statistical methods have limitations such as requiring manual feature extraction, high data requirements, and limited generalizability, leading to inaccurate predictions. In addition, most standard deep learning models ignore the problem of sequence noise. To overcome these hurdles, we have created a hybrid deep learning model utilizing advanced techniques. This model integrates Time Convolutional Networks (TCN), Gated Recurrent Units (GRU), and self-attention mechanism to achieve a more accurate workload prediction. Additionally, we perform a comparative analysis of different methods during the preprocessing stage and select the optimal one to effectively remove noise from the original sequences. Experimental results demonstrate that our proposed model outperforms other workload prediction algorithms in terms of prediction accuracy.},
  keywords={},
  doi={10.1109/DOCS60977.2023.10294685},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10083635,
  author={S, Savitha and C, Sangana and K, Devendran and L, Pravin and M, Rajkumar and C, Nirmal},
  booktitle={2023 7th International Conference on Computing Methodologies and Communication (ICCMC)}, 
  title={Auto Scaling Infrastructure with Monitoring Tools using Linux Server on Cloud}, 
  year={2023},
  volume={},
  number={},
  pages={45-52},
  abstract={Cloud computing is the term that has gained widespread usage over these last few years. Due to the rapid increase in the use of information in the digital age of the 21st century, it is increasingly becoming a more attractive option for individuals and organizations to manage all their essential data, projects, and collaborations, rather than relying solely on in-house computers. The user's requirement for hardware and software is reduced via cloud computing. The interface software of cloud computing systems, typically as simple as a web browser, is the only thing the user must operate, and the Cloud network handles the rest. To decrease operational costs, both business and government organizations are adopting cloud computing, seeking a flexible and adaptable solution for the supply and delivery of their product services. Microservices and decoupled apps are becoming more popular. These container-based architectures make it easier to build sophisticated SaaS apps quickly, but managing and creating microservices can be a daunting task. Managing and creating microservices that involve a wide range of diverse functions, including handling and storing information, and performing predictive and prescriptive analysis, can be a challenging undertaking. Establishing auto scaling infrastructure on doud can be challenging due to several reasons, some of which are: understanding the application architecture, setting up monitoring, scaling policies, cost optimization and implementation complexity. Server farms include the tremendous and heterogeneous virtualized frameworks, which are continually extending and broadening after sometime are the essential starting point for registering specialized organizations. These solutions also need to be integrated into existing systems while adhering to Quality of Service (QoS) requirements. The principal objective of this work is to propose an on-premise design to leverage Kubernetes and Docker containers to improve the quality of service based on resource usage and Service Level Objectives (SLOs). The Prometheus Administrator set up is used to perform namespace checking. Normally, doud providers enable their own monitoring tools (like CloudWatch) for monitoring CPU, storage and network usage, service component, however these tools cannot monitor the service component. Additionally, the advancements have restricted the capacity to follow QoS highlights at the application level (like security and execution) since the main focus will be dedicated towards the equipment assets. These types of node-level monitoring make it difficult to scale requests and deploy pods to match the demand. Infrastructure monitoring should enable runtime changes to monitor the requirements or metric operationalization should be done on those criteria without modifying the underlying infrastructure.},
  keywords={},
  doi={10.1109/ICCMC56507.2023.10083635},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10140844,
  author={Mishra, Praveen Kumar and Chaturvedi, Amit Kumar},
  booktitle={2023 International Conference on Computational Intelligence, Communication Technology and Networking (CICTN)}, 
  title={Research Challenges in Job Scheduling and Resource Distribution Methodology for Cloud Fog Atmosphere: An Organized Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={292-299},
  abstract={The IoT technology applications have become the most important technologies used internationally to encourage communication between humans and objects and enhance quality of life in recent years. This will lead to an increase in the variety of devices used in such applications, which will produce massive amounts of data. In 2012, Cisco made the first mention of fog computing, which sits between individual consumers (IoT devices) and cloud computing. Fog computing enhances cloud computing’s effectiveness, lessens its drawbacks, and offers storage and processing capacities at the edge, despite the fact that it is not a cloud computing solution. Resource management has a significant role in determining how well fog computing performs. Scheduling is essential to manage supplies in fog layer, which is the capability to match jobs to the suitable useful resources. As we know that the job is a minor component with a bigger undertaking with a deadline. Fog computing leverages distributed and heterogeneous resources, making task scheduling challenging. Numerous recommended scheduling algorithms have been produced in previous years; the maximum of them were engaged in scalability to fog computing. This study’s major goal is to extensively examine and evaluate the most important existing scheduling approaches in terms of their main context, advantages, limitations and performance measures. The analysis is presented in proportion of categories of algorithm and usage of parameters for measure of performance in fog.},
  keywords={},
  doi={10.1109/CICTN57981.2023.10140844},
  ISSN={},
  month={April},}@INPROCEEDINGS{10196549,
  author={Mokhtari, Ali and Rawls, Drake and Huynh, Tony and Green, Jeremiah and Salehi, Mohsen Amini},
  booktitle={2023 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={E2C: A Visual Simulator to Reinforce Education of Heterogeneous Computing Systems}, 
  year={2023},
  volume={},
  number={},
  pages={270-277},
  abstract={Heterogeneity has been an indispensable aspect of distributed computing throughout the history of these systems. ln particular, with the increasing popularity of accelerator technologies (eg., GPUs and TPUs) and the emergence of domain-specific computing via ASlCs and FPGA, the matter of heterogeneity and understanding its ramifications on the system performance has become more critical than ever before. However, it is challenging to effectively educate students about the potential impacts of heterogeneity on: (a) the performance of distributed systems; and (b) the logic of resource allocation methods to efficiently utilize the resources. Making use of the real infrastructure (such as those offered by the public cloud providers) for benchmarking the performance of heterogeneous machines, for different applications, with respect to different obiectives, and under various workload intensities is cost- and time-prohibitive. Moreover, not all students (globally and nationally) have access or can afford such real infrastructure. To reinforce the quality of learning about various dimensions of heterogeneity, and to decrease the widening gap in education, we develop an open-source simulation tool, called E2C, that can help students researchers and practitioners to study any type of heterogeneous (or homogeneous) computing system and measure its performance under various system configurations. To make the learning curve shallow, E2C is equipped with an intuitive graphical user interface (GU1) that enables its users to easily examine system-level solutions (scheduling, load balancing, scalability, etc.) in a controlled environment within a short time and at no cost. In particular, E2C is a discrete event simulator that offers the following features: (i) simulating a heterogeneous computing system; (ii) implementing a newly developed scheduling method and plugging it into the system, (iii) measuring energy consumption and other output-related metrics; and (iv) powerful visual aspects to ease the learning curve for students. We used E2C as an assignment in the Distributed and Cloud Computing course. Our anonymous survey study indicates that students rated E2C with the score of 87 out of 10 for its usefulness in understanding the concepts of scheduling in heterogeneous computing. Moreover, our pre- and post-evaluations indicate that E2C has improved the students’ understanding of heterogeneous computing systems by around 18%.},
  keywords={},
  doi={10.1109/IPDPSW59300.2023.00052},
  ISSN={},
  month={May},}@INPROCEEDINGS{10008330,
  author={Al-Shammare, Haifa and Al-Otaiby, Nehal},
  booktitle={2022 14th International Conference on Computational Intelligence and Communication Networks (CICN)}, 
  title={An Implementation of a New Proposed Round-Robin Algorithm with Smart Time Quantum in Cloud Computing Environment}, 
  year={2022},
  volume={},
  number={},
  pages={289-296},
  abstract={The popularity of cloud computing platforms has risen dramatically in recent years. As cloud computing serves millions of users at the same time, it must be able to handle all those users' demands efficiently. Thus, choosing a suitable scheduling algorithm is crucial in the cloud computing environment in order to ensure efficient performance with a reasonable degree of quality of service (QoS). The primary goal of this research is to empirically implement and evaluate a recently proposed Round-Robin algorithm with smart time quantum (RR-STQ) in a cloud computing environment, as well as, to enhance the RR-STQ with a dynamic smart time quantum. The CloudSim tool was used to simulate the cloud computing platform to implement RR-STQ and evaluate it with several algorithms using different scenarios. In addition, three scheduling performance metrics were used in the evaluation process. In all comparison scenarios, the (RR-STQ) achieved a significant improvement rate in terms of average response time (RT). Moreover, (RR-STQ) has a better performance in the average turnaround time (TAT), waiting time (WT), and response time (RT) than the traditional RR algorithm. Also, the implemented algorithm (RR-STQ) with dynamic time quantum has a better performance than static time quantum. Based on the evaluation results, it is beneficial to integrate the RR algorithm with other scheduling models such as shortest job first (SJF) to enhance the WT and TAT. Furthermore, the investigations revealed that the dynamic time quantum improves the performance of the RR algorithm.},
  keywords={},
  doi={10.1109/CICN56167.2022.10008330},
  ISSN={2472-7555},
  month={Dec},}@ARTICLE{10274948,
  author={Al-Eidi, Shorouq and Amsaad, Fathi and Darwish, Omar and Tashtoush, Yahya and Alqahtani, Ali and Niveshitha, Niveshitha},
  journal={IEEE Access}, 
  title={Comparative Analysis Study for Air Quality Prediction in Smart Cities Using Regression Techniques}, 
  year={2023},
  volume={11},
  number={},
  pages={115140-115149},
  abstract={In smart cities, air pollution has detrimental impacts on human physical health and the quality of living environment. Therefore, correctly predicting air quality plays an important effective action plan to mitigate air pollution and create healthier and more sustainable environments. Monitoring and predicting air pollution is crucial to empower individuals to make informed decisions that protect their health. This research presents a comprehensive comparative analysis focused on air quality prediction using three distinct regression techniques- Random Forest regression, Linear regression, and Decision Tree regression. The main goal of this study is to discern the most effective model by considering a range of evaluation criteria, including Mean Absolute Error and  $R^{2}$  measures. Moreover, it considers the crucial aspects of minimizing prediction errors and enhancing computational efficiency by evaluating the regression models within two frameworks. The findings of this study underscore the superiority of the Decision Tree regression approach over the other models, demonstrating its exceptional accuracy with a high  $R^{2}$  score and a minimal error rate. Moreover, integrating cloud computing technology has resulted in substantial improvements in the execution time of these approaches. This technology enhancement significantly affects the overall efficiency of the air quality prediction process. By leveraging distributed computing resources, real-time air quality forecasting becomes feasible, enabling timely decision-making and proactive measures to address air pollution episodes effectively.},
  keywords={},
  doi={10.1109/ACCESS.2023.3323447},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10350465,
  author={Zhang, Yang and Li, Yang and Yang, Yilong and Chen, Shuang and Gao, Juntao and Wang, Weiru and Yin, Yongfeng},
  booktitle={2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)}, 
  title={RapidMS: A Tool for Supporting Rapid Microservices Generation and Refinement from Requirements Model}, 
  year={2023},
  volume={},
  number={},
  pages={45-49},
  abstract={Microservices is a crucial architecture design pat-tern for developing cloud-native applications, which focuses on decomposing a large and complex software system into autonomous components that can be independently developed and deployed. However, microservices design is not a trivial task, which highly depends on the profound knowledge and experience of system design and target domain. This is a challenge for novice software architects. In this paper, we propose a microservices design tool named RapidMS, which only requires architects to specify potential context boundaries on the requirements model. The microservices architecture design model with component structure and interaction views can be automatically generated without extra human effort. Moreover, the proposed tool can automatically calculate the characteristic metrics of the microservices, which indicate the quality of the different aspects of models to support rapid architecture refinements. We demonstrate the tool's effectiveness through five case studies. The experimental result shows that architects can get better decomposition of requirement model within four iterations and over 90% of microservice architecture diagrams can be correctly generated within 10 seconds. RapidMS can be further extended and applied in the software industry to reduce the cost and difficulty of microservices decomposition and design. The tool can be downloaded at https://rm2pt.com/advs/ rapidms, and a demo video casting its features is at https://youtu.be/AoIM41FTnFO},
  keywords={},
  doi={10.1109/MODELS-C59198.2023.00017},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10302780,
  author={Yιlmaz, Ömer Zekvan and Alagöz, Fatih},
  booktitle={2023 14th International Conference on Network of the Future (NoF)}, 
  title={Shared Network Function Placement for Cloud Native 5G Core Networks}, 
  year={2023},
  volume={},
  number={},
  pages={103-107},
  abstract={Providing adequate operating resources for Network Functions (NFs) with minimal costs has been one of the primary concerns for cloud providers. The adequate operating resources definition has to cover the quality of service (QoS) constraints, which result in ‘underutilized resources’. Studies in the NF placement domain that make use of these resources through sharing, employ NP-Hard algorithms. In this study, we propose an NF placement scheme called Cloud Native Network Function Sharing (CNFSH) using a priority-based load balancer and a polynomial time algorithm for dynamic 5G settings. Using CNFSH, the number of satisfied slice requests increases by 36%, and the average resource consumption per network slice drops by 28% compared to the NoShare model. Besides being dynamic and sustainable, CNFSH outperforms a previous sharing scheme [1], with 5% success rate for both of the metrics.},
  keywords={},
  doi={10.1109/NoF58724.2023.10302780},
  ISSN={2833-0072},
  month={Oct},}@ARTICLE{8758137,
  author={Azadi, Majid and Emrouznejad, Ali and Ramezani, Fahimeh and Hussain, Farookh Khadeer},
  journal={IEEE Transactions on Cloud Computing}, 
  title={Efficiency Measurement of Cloud Service Providers Using Network Data Envelopment Analysis}, 
  year={2022},
  volume={10},
  number={1},
  pages={348-355},
  abstract={An increasing number of organizations and businesses around the world use cloud computing services to improve their performance in the competitive marketplace. However, one of the biggest challenges in using cloud computing services is performance measurement and the selection of the best cloud service providers (CSPs) based on quality of service (QoS) requirements [13]. To address this shortcoming in this article we propose a network data envelopment analysis (DEA) method in measuring the efficiency of CSPs. When network dimensions are taken into consideration, a more comprehensive analysis is enabled where divisional efficiency is reflected in overall efficiency estimates. This helps managers and decision makers in organizations to make accurate decisions in selecting cloud services. In the current study, the non-oriented network slacks-based measure (SBM) model and conventional SBM model with the assumptions of constant returns to scale (CRS) and variable returns to scale (VRS) are applied to measure the performance of 18 CSPs. The obtained results show the superiority of the network DEA model and they also demonstrate that the proposed model can evaluate and rank CSPs much better than compared to traditional DEA models.},
  keywords={},
  doi={10.1109/TCC.2019.2927340},
  ISSN={2168-7161},
  month={Jan},}@INPROCEEDINGS{10176237,
  author={B K, Jeevitha and J, Thriveni},
  booktitle={2022 IEEE International Conference for Women in Innovation, Technology & Entrepreneurship (ICWITE)}, 
  title={Data Storage Security and Privacy in Cloud Computing}, 
  year={2022},
  volume={},
  number={},
  pages={1-10},
  abstract={The world has seen a quick transition from hard devices for local storage to massive virtual data centers, all possible because of cloud storage technology. Businesses have grown to be scalable, meeting consumer demands on every turn. Cloud computing has transforming the way we do business making IT more efficient and cost effective that leads to new types of cybercrimes. Securing the data in cloud is a challenging task. Cloud security is a mixture of art and science. Art is to create your own technique and technologies in such a way that the user should be authenticated. Science is because you have to come up with ways of securing your application. Data security refers to a broad set of policies, technologies and controls deployed to protect data application and the associated infrastructure of cloud computing. It ensures that the data has not been accessed by any unauthorized person. Cloud storage systems are considered to be a network of distributed data centers which typically uses cloud computing technologies like virtualization and offers some kind of interface for storing data. Virtualization is the process of grouping the physical storage from multiple network storage devices so that it looks like a single storage device.Storing the important data in the cloud has become an essential argument in the computer territory. The cloud enables the user to store the data efficiently and access the data securely. It avoids the basic expenditure on hardware, software and maintenance. Protecting the cloud data has become one of the burdensome tasks in today’s environment. Our proposed scheme "Certificateless Compressed Data Sharing in Cloud through Partial Decryption" (CCDSPD) makes use of Shared Secret Session (3S) key for encryption and double decryption process to secure the information in the cloud. CC does not use pairing concept to solve the key escrow problem. Our scheme provides an efficient secure way of sharing data to the cloud and reduces the time consumption nearly by 50 percent as compared to the existing mCL-PKE scheme in encryption and decryption process.Distributed Cloud Environment (DCE) has the ability to store the da-ta and share it with others. One of the main issues arises during this is, how safe the data in the cloud while storing and sharing. Therefore, the communication media should be safe from any intruders residing between the two entities. What if the key generator compromises with intruders and shares the keys used for both communication and data? Therefore, the proposed system makes use of the Station-to-Station (STS) protocol to make the channel safer. The concept of encrypting the secret key confuses the intruders. Duplicate File Detector (DFD) checks for any existence of the same file before uploading. The scheduler as-signs the work of generating keys to the key manager who has less task to complete or free of any task. By these techniques, the proposed system makes time-efficient, cost-efficient, and resource efficient compared to the existing system. The performance is analysed in terms of time, cost and resources. It is necessary to safeguard the communication channel between the entities before sharing the data. In this process of sharing, what if the key manager’s compromises with intruders and reveal the information of the user’s key that is used for encryption. The process of securing the key by using the user’s phrase is the key concept used in the proposed system "Secure Storing and Sharing of Data in Cloud Environment using User Phrase" (S3DCE). It does not rely on any key managers to generate the key instead the user himself generates the key. In order to provide double security, the encryption key is also encrypted by the public key derived from the user’s phrase. S3DCE guarantees privacy, confidentiality and integrity of the user data while storing and sharing. The proposed method S3DCE is more efficient in terms of time, cost and resource utilization compared to the existing algorithm DaSCE (Data Security for Cloud Environment with Semi Trusted Third Party) and DACESM (Data Security for Cloud Environment with Scheduled Key Managers).For a cloud to be secure, all of the participating entities must be secure. The security of the assets does not solely depend on an individual's security measures. The neighbouring entities may provide an opportunity to an attacker to bypass the user's defences. The data may compromise due to attacks by other users and nodes within the cloud. Therefore, high security measures are required to protect data within the cloud. Cloudsim allows to create a network that contains a set of Intelligent Sense Point (ISP) spread across an area. Each ISPs will have its own unique position and will be different from other ISPs. Cloud is a cost-efficient solution for the distribution of data but has the challenge of a data breach. The data can be compromised of attacks of ISPs. Therefore, in OSNQSC (Optimized Selection of Nodes for Enhanced in Cloud Environment), an optimized method is proposed to find the best ISPs to place the data fragments that considers the channel quality, distance and the remaining energy of the ISPs. The fragments are encrypted before storing. OSNQSC is more efficient in terms of total upload time, total download time, throughput, storage and memory consumption of the node with the existing Betweenness centrality, Eccentricity and Closeness centrality methods of DROPS (Division and Replication of Data in the Cloud for Optimal Performance and Security).},
  keywords={},
  doi={10.1109/ICWITE57052.2022.10176237},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9985529,
  author={Thirunavukkarasu, M. and Shanmugapriya, P.},
  booktitle={2022 4th International Conference on Inventive Research in Computing Applications (ICIRCA)}, 
  title={Energy Efficient Mobile Cloud offloading for Image Processing Applications using Transfer Learning}, 
  year={2022},
  volume={},
  number={},
  pages={910-916},
  abstract={Processing real-time images in the digital era is a complex task that requires the use of more sophisticated tools and consumes more energy. With the introduction of Hybrid model, Mobile and Cloud Computing, called as Mobile and Cloud Computing (MCC), this becomes an easy task in which the end user connects using the virtual instance in the Cloud environment. MCC enable the execution of cloud applications through mobile terminals. However, the mobile devices cannot process high end applications as they have limited energy. We propose Mobile Cloud offloading technique that excludes the execution on the Mobile terminal by deploying the applications on Cloud. Identification and decision on the energy aware applications are playing a vital role to improve Quality of Services (QoS). The proposed model introduces the Transfer Learning- based Energy efficient Mobile Cloud offloading framework. The proposed model predicts whether to move the applications towards the Mobile Cloud environment. The proposed model uses InceptionResNetV2 as pre-trained transfer learning approach.. The CNN based classifier used to classify the type of application and the respective energy consumption ratio based on the pre-trained model. The proposed model reduces training period to identify the application and effectively handle the offload process to improve the QoS metrics.},
  keywords={},
  doi={10.1109/ICIRCA54612.2022.9985529},
  ISSN={},
  month={Sep.},}@ARTICLE{10247345,
  author={Singh, Jaspreet and Walia, Navpreet Kaur},
  journal={IEEE Access}, 
  title={A Comprehensive Review of Cloud Computing Virtual Machine Consolidation}, 
  year={2023},
  volume={11},
  number={},
  pages={106190-106209},
  abstract={In the last decade, users have been able to access their applications, data, and services via the cloud from any location with an internet connection. The scale of heterogeneous cloud environments is continuously growing due to the development of computing-intensive smart devices. The cloud computing system is managed by a data center, which consists of physical machines (PMs) or servers and software-based emulation of PMs called virtual machines(VMs). The deployment of a huge number of physical servers as a result of the exponential development in demand for cloud services has resulted in high energy consumption and ineffective resource usage. Efficient utilization of resources and minimizing power consumption in any data center have become crucial challenges. Virtual machine consolidation (VMC) is a method of optimizing computing resources by consolidating multiple VMs onto a reduced number of PMs. By consolidating VMs and running fewer physical servers, VM consolidation can reduce power consumption and improve resource utilization. This review paper presents a comprehensive analysis of cloud computing virtual machine consolidation, exploring various strategies, benefits, challenges and future trends in this domain. By examining a wide range of literature from the year 2015 to 2023, this review attempts to provide insight into the current state of VM consolidation and its possible effects on the performance and sustainability of cloud computing. The main flaw in the articles is that the various authors focused on different assessment metrics when the emphasis should have been on increasing cloud system service quality and energy efficiency. Future research can be aimed at developing a multi-objective system that emphasizes minimizing cloud energy usage without sacrificing service quality and preventing service level agreements with cloud users from being compromised.},
  keywords={},
  doi={10.1109/ACCESS.2023.3314613},
  ISSN={2169-3536},
  month={},}@ARTICLE{9057418,
  author={Yu, Guangba and Chen, Pengfei and Zheng, Zibin},
  journal={IEEE Transactions on Cloud Computing}, 
  title={Microscaler: Cost-Effective Scaling for Microservice Applications in the Cloud With an Online Learning Approach}, 
  year={2022},
  volume={10},
  number={2},
  pages={1100-1116},
  abstract={Recently, the microservice becomes a popular architecture to construct cloud native systems due to its agility. In cloud native systems, autoscaling is a key enabling technique to adapt to workload changes by acquiring or releasing the right amount of computing resources. However, it becomes a challenging problem in microservice applications, since such an application usually comprises a large number of different microservices with complex interactions. When the performance decreases due to an unpredictable workload peak, it is difficult to pinpoint the scaling-needed services which need to scale out and evaluate how many resources they need. In this article, we present a novel system named Microscaler to automatically identify the scaling-needed services and scale them to meet the Service Level Agreement (SLA) with an optimal cost for microservice applications. Microscaler first collects the quality of service (QoS) metrics in the service mesh enabled microservice infrastructure. Then, it determines under-provisioning or over-provisioning service instances along the service dependency graph with a novel scaling-needed service criterion named service power. The service dependency graph could be obtained by correlating each request flow in the service mesh. By combining an online learning approach and a step-by-step heuristic approach, Microscaler can precisely reach the optimal service scale meeting the SLA requirements. The experimental evaluations in a microservice benchmark show that Microscaler achieves an average 93 percent precision in scaling-needed service determination and converges to the optimal service scale faster than several state-of-the-art methods. Moreover, Microscaler is lightweight and flexible enough to work in a large-scale microservice system.},
  keywords={},
  doi={10.1109/TCC.2020.2985352},
  ISSN={2168-7161},
  month={April},}@ARTICLE{9784409,
  author={Sebrechts, Merlijn and Volckaert, Bruno and De Turck, Filip and Yang, Kun and Al-Naday, Mays},
  journal={IEEE Communications Magazine}, 
  title={Fog Native Architecture: Intent-Based Workflows to Take Cloud Native toward the Edge}, 
  year={2022},
  volume={60},
  number={8},
  pages={44-50},
  abstract={The cloud native approach is rapidly transforming how applications are developed and operated, turning monolithic applications into microservice applications, allowing teams to release faster, increase reliability, and expedite operations by taking full advantage of cloud resources and their elasticity. At the same time, “fog computing” is emerging, bringing the cloud toward the edge, near the end user, in order to increase privacy, improve resource efficiency, and reduce latency. Combining these two trends, however, proves difficult because of four fundamental disconnects between the cloud native paradigm and fog computing. This article identifies these disconnects and proposes a fog native architecture along with a set of design patterns to take full advantage of the fog. Central to this approach is turning microservice applications into microservice workflows, constructed dynamically by the system using an intent-based approach taking into account a number of factors such as user requirements, request location, and available infrastructure and microservices. The architecture introduces a novel softwarized fog mesh facilitating both inter-microservice connectivity, external communication, and end-user aggregation. Our evaluation analyzes the impact of distributing microservice-based applications over a fog ecosystem, illustrating the impact of CPU and network latency and application metrics on perceived quality of service of fog native workflows compared to the cloud. The results show the fog can offer superior application performance given the right conditions.},
  keywords={},
  doi={10.1109/MCOM.003.2101075},
  ISSN={1558-1896},
  month={August},}@INPROCEEDINGS{9936294,
  author={Das, Souptik and Chakraborty, Sourish and Jana, Dipanjan and Nandy, Rahul and Bhattacharya, Srijan},
  booktitle={2022 Second International Conference on Computer Science, Engineering and Applications (ICCSEA)}, 
  title={IoT Based Industrial Air Quality Monitoring System}, 
  year={2022},
  volume={},
  number={},
  pages={1-4},
  abstract={In the past two decades, researchers have accelerated a number of different methods to monitor and reduce air contamination leading to the development of efficient and effective air quality measuring systems using air purifiers. Although, recent technological advancements such as IoT (Internet of Things) with Cloud Computing have allowed researchers to obtain and monitor real-time data. In this report, an IoT-enabled industrial air quality monitoring device is proposed. This device is enabled with an MQ-135 gas sensor for precisely monitoring the air quality and detecting the presence of foreign contaminants such as alcohol. The proposed device also uses a Node MCU ESP S266 Wi-Fi module to efficiently transmit real time data to a smart device (E.g. Smartphone) using an IoT platform.},
  keywords={},
  doi={10.1109/ICCSEA54677.2022.9936294},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9935836,
  author={Widodo, Doni Iksan and Hartono, Ambran and Yuniarti, Elvan},
  booktitle={2022 10th International Conference on Cyber and IT Service Management (CITSM)}, 
  title={Design and Build End-to-End Device as User Recommendations for Indoor Air Quality Monitoring}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={The development of integrated end-to-end technology is increasingly reaching all fields. The presence of this technology can answer one of the challenges discussed in this study, namely as a recommendation feature to users on indoor air quality and useful as an effort to prevent respiratory disease symptoms. This device is specially designed by implementing several technologies such as microcontrollers, sensors, internet of things, cloud computing, and progressive web apps. The parameters used to measure the level of indoor air quality are temperature, humidity, fine particles (PM10) and carbon monoxide with a predetermined range, if these parameters are outside the range then it is categorized as poor or unhealthy air, otherwise if the parameters are within range, the air is categorized as good or healthy air. Based on the collection and processing of data samples at several different locations, the air is in the good or healthy category and does not cause symptoms of respiratory disease. The results of this study also produced an end-to-end device that can monitor indoor air quality levels in real-time, as well as provide recommendations for making health efforts if the detected air quality parameters are outside the range that has been determined based on the Ministry of Health regulations Republic of Indonesia.},
  keywords={},
  doi={10.1109/CITSM56380.2022.9935836},
  ISSN={2770-159X},
  month={Sep.},}@INPROCEEDINGS{10047689,
  author={Vidhya, M. and Devi, R.},
  booktitle={2022 11th International Conference on System Modeling & Advancement in Research Trends (SMART)}, 
  title={Comparative Analysis of Scheduling Algorithms in Cloud Computing using CloudSim}, 
  year={2022},
  volume={},
  number={},
  pages={7-12},
  abstract={Cloud computing restructured the entire world of IT by providing shared scalable resources to the organization. Cloud establishes a huge path to find the solution for many major problems found in the industry. Cloud offers virtualized resources such as applications, software, networks, servers, and storage services. Cloud enables all the virtualized resources to clients on a pay-per-use basis. Because of handling the vast request sent by multiple clients and providing more versatile services to the organization, the cloud faces many critical problems such as security issues, dissatisfied Quality-Of-Services, and sometimes an unbalanced load arises. Among those, the most serious problem is balancing the load across the network. Load balancing issues can be handled by scheduling the work eventually to all nodes without overloading any single node. This paper gives an overview idea of different load balancing algorithms and provides comparative results on its quality metrics.},
  keywords={},
  doi={10.1109/SMART55829.2022.10047689},
  ISSN={2767-7362},
  month={Dec},}@INPROCEEDINGS{9995753,
  author={Al-Sit, Waleed T. and Ateeq, Karamath and Moinuddin, Syed Quadir and Aslam, Shoukat and Rehman, Abdur and Asgher, Tayba and Thawabeh, Ossma Ali},
  booktitle={2022 International Conference on Cyber Resilience (ICCR)}, 
  title={Direct Trust in Cloud Computing Based on Fuzzy Logic}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Trust is a powerful aspect, particularly for services using processes in the fields of cybersecurity and information technology. Concerns concerning the dependability of the cloud platform have been raised by individuals and creativity on a number of occasions. In cloud computing, it is advantageous for the customer to select a cloud provider's service for the storing and distribution of their thoughtful content. In this research, a trust model is put forth that evaluates trust using Quality of Service (QoS) metrics. The trust-fuzzy environment has inspired us to employ fuzzy logic to estimate a beneficiary's trustworthiness in a cloudy environment, hence increasing the scheme's effectiveness. Reliability, security, accessibility, response time, and cost make up Quality of Service. All work was completed in MATLAB.},
  keywords={},
  doi={10.1109/ICCR56254.2022.9995753},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9987392,
  author={Kumar, G Suvarna and Priyadarshini, R. and Parmenas, Naik Henokh and Tannady, Hendy and Rabbi, Fazle and Andiyan, Andiyan},
  booktitle={2022 Sixth International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)}, 
  title={Design of Optimal Service Scheduling based Task Allocation for Improving CRM in Cloud Computing}, 
  year={2022},
  volume={},
  number={},
  pages={438-445},
  abstract={Cloud computing is a service level computing that provide various service to the customers in order to establish an effective customer Relationship management (CRM). This offers various services like virtual machine, self-service provisioning, elasticity computing and storage (pay-as-you-go). Cloud computing provides shared services by enhancing resource management scalability, interoperability and prediction resources as a key to realize the resource utilization with high-performance management metrics. However, when the number of users increase, the process of task scheduling and service allocation using a traditional computing environment will degrade the CRM. In order to address this challenge, this research study proposes an Optimal Service Level Scheduling (OSLS) based task allocation design for improving CRM in cloud computing environment. The Adaptive Service Level Scheduling Algorithm (ASLSA) and the Support Level Load Balancer (SLLB) will reduce the workload in cloud computing environment in order to improve the Quality of Service (QoS) of CRM. This process will optimize the resource utilization in cloud platform based on the service requirement. It provides optimal scheduling features to CRM in order to improve the service optimality based on task and enhance the computational processes such as service load management, heterogeneous service delivery, pricing, resource pools and elasticity. The proposed system leverages high performance when compared to the existing models.},
  keywords={},
  doi={10.1109/I-SMAC55078.2022.9987392},
  ISSN={2768-0673},
  month={Nov},}@INPROCEEDINGS{10105030,
  author={Sandhiya, B and Canessane, R.Aroul},
  booktitle={2023 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)}, 
  title={An Extensive Study of Scheduling the Task using Load Balance in Fog Computing}, 
  year={2023},
  volume={},
  number={},
  pages={1586-1593},
  abstract={The proliferation of IoT has resulted in a rise in the demand for services provided by the fog layer, a novel dispersed computing pattern that supplements cloud computing. The fog system enables location awareness and mobility assistance by extending storage and multiplication to the network’s edge, dramatically reducing the issue of service computing in delay-sensitive applications. More requests from more users means more stress for the VMs running in the fog layer. When it comes to fog networks, Load Balancing (LB) is crucial since it prevents some fog nodes from being under- or overworked. Fairly dividing up the fog layer’s burden across the available virtual machines (VMs) is now an absolute must. LB can enhance quality-of-service metrics including cost, response time, performance, and energy ingesting. Although there has been limited investigation of load complementary techniques in fog networks in recent years, no comprehensive analysis has been conducted to compile this information. This article takes a systematic look at the various load-balancing procedures in fog computing, categorizing it as either approximate, precise, fundamental, or hybrid. In addition, the study explores (Load Balancing) LB metrics, including the benefits and drawbacks of the techniques used for fog networks. There is also an examination of the methods and instruments used in the aforementioned evaluations of each research under consideration. The most unanswered questions and emerging tendencies for these algorithms are also covered. In the final section, the study suggests potential avenues for further research.},
  keywords={},
  doi={10.1109/ICSCDS56580.2023.10105030},
  ISSN={},
  month={March},}@ARTICLE{10041775,
  author={Singh, Jagdeep and Singh, Parminder and Hedabou, Mustapha and Kumar, Neeraj},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={An Efficient Machine Learning-Based Resource Allocation Scheme for SDN-Enabled Fog Computing Environment}, 
  year={2023},
  volume={72},
  number={6},
  pages={8004-8017},
  abstract={Fog computing is an emerging technology which enables computing resources accessibility close to the end-users. It overcomes the drawbacks of available network bandwidth and delay in accessing the computing resources as observed in cloud computing environment. Resource allocation plays an important role in resource management in a fog computing environment. However, the existing traditional resource allocation techniques in fog computing do not guarantee less execution time, reduced energy consumption, and low latency requirements which is a pre-requisite for most of the modern fog computing-based applications. The complex fog computing environment requires a robust resource allocation technique to ensure the quality and optimal resource usage. Motivated from the aforementioned challenges and constraints, in this article, we propose a resource allocation technique for SDN-enabled fog computing with Collaborative Machine Learning (CML). The proposed CML model is integrated with the resource allocation technique for the SDN-enabled fog computing environment. The FogBus and iFogSim are deployed to test the results of the proposed technique using various performance evaluation metrics such as bandwidth usage, power consumption, latency, delay, and execution time. The results obtained are compared with other existing state-of-the-art techniques using the aforementioned performance evaluation metrics. The results obtained show that the proposed scheme reduces 19.35% processing time, 18.14% response time, and 25.29% time delay. Moreover, compared to the existing techniques, it reduces 21% execution time, 9% network usage, and 7% energy consumption.},
  keywords={},
  doi={10.1109/TVT.2023.3242585},
  ISSN={1939-9359},
  month={June},}@INPROCEEDINGS{10070735,
  author={Kong, Xiangyu and Gao, Xuesong and Pan, Shibao and Zhou, Yizhi and Yang, Yanan and Zhao, Laiping and Qi, Heng},
  booktitle={2022 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)}, 
  title={TailCmp - A Tail Latency Evaluation Solution of Public Cloud and Labeled von Neumann Architecture based Cloud Prototype}, 
  year={2022},
  volume={},
  number={},
  pages={888-895},
  abstract={Tail latency is the key performance metric for cloud computing systems (CCSs). When latency-critical (LC) applications and best-effort batch (BE) jobs are co-located on CCSs, the unmanaged contention for computing resources usually leads to significant fluctuations in tail latency, which have a severe negative impact to the end user experience. Therefore, some promising computing systems and effective scheduling solutions are proposed to guarantee better quality of service (QoS), e.g., La-beled von Neumann Architecture (LvNA) based cloud prototype system. However, relatively few work focuses on the tail latency observation and evaluation of public CCSs and newest prototype systems. Therefore, we introduce an evaluation framework named TailCmp which includes nine representative workloads ranging over different tail latency requirements and application domains. With the TailCmp, we can collect and analyze four evaluation metrics including tail latency entropy. In this paper, we conduct a large number of experiments with TailCmp on three CCSs (two public CCSs and one LvNA-based prototype system). The results show that the co-location on existing public CCSs can seriously affect the QoS of LC workloads, while the labeling mechanism in Lv Na - based prototype can improve the performance of LC workloads in co-location.},
  keywords={},
  doi={10.1109/ISPA-BDCloud-SocialCom-SustainCom57177.2022.00118},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10085328,
  author={Tiwana, Pardeep Singh and Singh, Jaspreet},
  booktitle={2023 International Conference on Artificial Intelligence and Smart Communication (AISC)}, 
  title={Load Optimization Accessions, Ramification the QoS in Software Defined Networking}, 
  year={2023},
  volume={},
  number={},
  pages={1013-1017},
  abstract={It is difficult to manage traditional networks due to network growth, an increase in user numbers, and the emergence of new technologies like big data and cloud computing. Consequently, it is required to alter the current network design. SDN is a well-liked architecture because it offers customizable control and centralized management in data centers. To achieve scalability and dependability, it was necessary to propose the geographical dispersal of a logically centralized control plane due to the huge scale of networks. Software-defined networking (SDN) load-balancing optimization has been studied for a long time. Many approaches to the load-balancing conundrum have been put forth by researchers, but very few have taken the impact of transmission delay between controllers and switches under heavy network load into account. In this article we elaborate the various techniques of load balancing in SDN those working on different areas like multi-controller, switch migration, multi-agent, strategy, time sharing, prediction, reinforcement learning etc. We discuss the methods used along with the advantages and disadvantages of various costs, service quality, and network performance metrics.},
  keywords={},
  doi={10.1109/AISC56616.2023.10085328},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10112423,
  author={Srivastava, Manoj Kumar and Joshi, Vijay K.},
  booktitle={2023 10th International Conference on Computing for Sustainable Global Development (INDIACom)}, 
  title={Efficient Consolidation of VMs Systems in the Cloud to Reduce Energy Use}, 
  year={2023},
  volume={},
  number={},
  pages={1510-1514},
  abstract={The energy needs of cloud computing systems are very high. Cloud suppliers, in order to keep their services available, need to reduce the amount of power their platforms need without sacrificing quality of service. As a result, studies have recommended a cloud-specific architecture that optimizes energy use throughout the whole computer infrastructure. The suggested method was developed in the CloudSim simulator, and the results of the associated simulations suggest that power consumption may be substantial and varies depending on parameters like the quantum variable, data size, and the number of VMs operating on a host. It is possible to establish a variety of resource allocation and planning methods for amassing virtual machines (VMs) on fewer hosts while still maintaining critical metrics, making cloud technology the first step towards sustainable energy. In this study, we first outline the taxonomy of VM placement approaches before proposing new iterative placement strategies that dynamically adjust their placement judgments based on host load Swarm Bee inspired improved Threshold.},
  keywords={},
  doi={},
  ISSN={},
  month={March},}@INPROCEEDINGS{10250648,
  author={Kavitha, J and Rao, P S V Srinivasa and Babu, G Charles},
  booktitle={2023 Second International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)}, 
  title={Energy Efficient Resource Utilization of Cloud Computing Environments for Deployment Models}, 
  year={2023},
  volume={},
  number={},
  pages={1111-1119},
  abstract={This research study focuses on optimizing resource allocation to reduce energy consumption in cloud-based systems. This study explores various techniques and algorithms employed to achieve energy efficiency, such as dynamic workload consolidation, virtual machine migration, and power-aware scheduling. This study emphasizes the importance of considering energy efficiency alongside performance metrics while making resource management decisions. The proposed methods intend to minimize energy wastage and carbon footprint while maintaining Quality of Service (QoS) and cost-effectiveness. Ultimately, this research contributes to the sustainable development and greener operation of cloud computing infrastructures.},
  keywords={},
  doi={10.1109/ICAISS58487.2023.10250648},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10366486,
  author={Saadouni, Rafika and Khacha, Amina and Harbi, Yasmine and Gherbi, Chirihane and Harous, Saad and Aliouat, Zibouda},
  booktitle={2023 15th International Conference on Innovations in Information Technology (IIT)}, 
  title={Secure IIoT networks with hybrid CNN-GRU model using Edge-IIoTset}, 
  year={2023},
  volume={},
  number={},
  pages={150-155},
  abstract={Industrial Internet of Things (IIoT), or Industry 4.0, is an application of IoT in the industrial sector. Its main objective is to enhance product quality and optimize production costs by leveraging advanced technologies such as edge/fog/cloud computing, 5G/6G, and artificial intelligence. In the context of Industry 4.0, numerous devices and systems are interconnected to provide seamless services to users. However, with this interconnection comes the need to protect these devices and the information they transmit from cyberthreats and intrusions. In order to tackle this challenge, our proposed solution involves the utilization of deep learning (DL) models to develop an anomaly-based detection system. Our approach involves two powerful DL models, namely Convolutional Neural Networks (CNN) and Gated Recurrent Units (GRU). The proposed model’s performance is studied within binary and multiclass classification using a new real-world industrial traffic dataset called Edge-IIoTset. The outcomes of our experiments showcased the efficacy of the CNN-GRU model that we proposed, surpassing the performance of recent related works in terms of performance metrics, including accuracy, precision, false positive rate, and detection cost. The combination of the two models CNN and GRU outperforms the GRU model with 88% of detection cost in multiclass classification for one traffic flow.},
  keywords={},
  doi={10.1109/IIT59782.2023.10366486},
  ISSN={2473-2052},
  month={Nov},}@INPROCEEDINGS{10087523,
  author={Khayyat, Mashael M. and Aboulola, Omar A.},
  booktitle={2023 International Conference on Smart Computing and Application (ICSCA)}, 
  title={Implementing an Ambient Air Quality Monitoring System in Spaces with Inadequate Ventilation using the Internet of Things}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Improving quality of life can be one of the most important outcomes of health care policies. Researchers have proven the role of technology in enhancing the quality of life. The Internet of Things (IoT) concept employs technology in an integrated manner by connecting smart devices, sensors, data, and channels, in order to enhance communication between things and to facilitate life in a smart way. Thus, IoT utilizes a great amount of data coming from these devices and produces stories and clear pictures about what is going on especially since the emergence of big data and cloud computing paradigms. The objective of this paper is to introduce IoT, explain how to calculate the Air Quality Index for Gulf Cooperation Council countries, and to provide evidence of the importance of implementing air quality monitoring systems in tunnels since their architecture limits airflow; therefore it can be assumed that pollutants are trapped. Results from the data generated by the system implemented measures air quality in the tunnel on King Abdulaziz Road in Makkah that shows air quality in such spaces should be monitored and proper actions need to be considered to avoid health problems to ensure quality of life.},
  keywords={},
  doi={10.1109/ICSCA57840.2023.10087523},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{9928755,
  author={Li, Shuo and Baştuğ, Ejder and Di Renzo, Marco},
  booktitle={2022 IEEE International Mediterranean Conference on Communications and Networking (MeditCom)}, 
  title={On the Modelling and Analysis of Edge-Serverless Computing}, 
  year={2022},
  volume={},
  number={},
  pages={250-254},
  abstract={The exponential increase in data generated by mobile devices and the rapid growth of cloud computing traffic are pushing services to the edge of the network. Serverless computing is an emerging cloud computing paradigm that provides stateless and event-driven services, called serverless services, independent of network infrastructure. Further improvements in quality of service (QoS) can be achieved by utilizing novel concepts like edge-serverless computing. Analyzing such systems as in existing works requires network-level simulations which could be costly and time-consuming, thus analytical models to obtain rapid insights are also needed. In this paper, we propose a stochastic geometry-based mathematical model in a tiered network, characterizing average end-to-end delay as performance measure, impacted by various crucial network parameters. The spatial distribution of server nodes, as well as computation requests are randomly and independently distributed according to homogeneous Poisson point processes (PPPs), allowing us to study the performance gains from multiple aspects. Two distinct network topologies are investigated numerically, namely communication and computation-oriented, validating the accuracy of our theoretical approximations.},
  keywords={},
  doi={10.1109/MeditCom55741.2022.9928755},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10326297,
  author={Yekta, Mohammad and Shahhoseini, Hadi Shahriar},
  booktitle={2023 13th International Conference on Computer and Knowledge Engineering (ICCKE)}, 
  title={A Review on Machine Learning Methods for Workload Prediction in Cloud Computing}, 
  year={2023},
  volume={},
  number={},
  pages={306-311},
  abstract={Workload prediction is one of the critical parts of resource provisioning in cloud computing and its evolved branches such as serverless and edge computing. Effective resource provisioning stands as a crucial element within the realm of edge-cloud computing. Accurate prediction of cloud workloads is essential for the effective allocation of resources. Workload prediction plays a crucial role in enhancing efficiency, reducing costs, optimizing cloud performance, maintaining a high level of quality of service, and minimizing energy consumption. In this paper, we conduct a comprehensive review of state-of-the-art Machine Learning (ML) and Deep Learning (DL) algorithms employed in workload prediction in cloud computing and other similar platforms such as edge computing. We compared the selected papers in terms of utilized methods and techniques, predicted factors, accuracy metrics, and the dataset. Additionally, to facilitate usability and comparison, articles sharing similar advantages and disadvantages are organized into a table. Finally, the paper concludes by addressing current challenges and future research directions.},
  keywords={},
  doi={10.1109/ICCKE60553.2023.10326297},
  ISSN={2643-279X},
  month={Nov},}@INPROCEEDINGS{10054247,
  author={M, Gayathri Hegde and M, Shrishti Bekal and Prasad, Srinidhi S and Shenoy, P Deepa and K R, Venugopal},
  booktitle={2022 IEEE 7th International Conference on Recent Advances and Innovations in Engineering (ICRAIE)}, 
  title={Analysis of Secure EHR Storage Methods on Blockchain and Integrating ML to Predict Chronic Kidney Disease}, 
  year={2022},
  volume={7},
  number={},
  pages={250-255},
  abstract={An Electronic Health Record(EHR) is the digital form of the patient’s health data, including vital signs, demographic details, clinical notes, X-rays, medical images, etc. When discussing EHR processing and management, storing this vast information is the main challenge. Although cloud computing’s centralized storage model is one of the best ways to store large amounts of data, it is not secure. Blockchain technology has the potential to revolutionize EHR storage systems and provide data security. Directly keeping the vast EHR data on blockchain may be costly and inefficient. The best method to store the data is off-chain in a Blockchain-based EHR system. Implementing machine learning (ML) in the healthcare industry aims to anticipate diseases earlier so patients can receive higher-quality medical care. Integrating these two disruptive data-driven technologies can highly improve the quality of healthcare. First, this paper analyzes three different off-chain EHR storage methods: Storj, InterPlanetary File System(IPFS), and CosmosDB, based on their Storage and Access Time. From the experimental results, IPFS has the fastest Storage and Access Time. Second, we integrate blockchain and ML technology to predict Chronic Kidney Disease(CKD) from the CKD dataset stored on the IPFS. Finally, using IPFS storage, a record is accessed, and the prediction time is 0.4 sec for detecting CKD or NOCKD is measured.},
  keywords={},
  doi={10.1109/ICRAIE56454.2022.10054247},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10176696,
  author={Sefati, Seyed Salar and Halunga, Simona},
  booktitle={2023 12th International Conference on Modern Circuits and Systems Technologies (MOCAST)}, 
  title={Service Recommendation for a Group of Users on the Internet of Things Using the Most Popular Service}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={With the emergence of the Internet of Things (IoT), advanced technologies like fog and cloud computing have been harnessed to create dynamic, real-time platforms addressing the needs of modern decision-makers. Crucial to this process is the recommendation of services tailored to each user's requirements in IoT settings, with the potential for improved Quality of Service (QoS) and Quality of Experience (QoE). The presented method in this paper leverages sensors, services, and fog computing within IoT systems to enhance QoS and adapt to user feedback. The approach involves ranking QoS of services based on Reliability, Availability, and Cost (RAC), and identifying the Most Popular Service (MPS) previously selected by the user. Comparison with Co-Scheduling System for Fog-node Recommendation and Load Management (CoS_FRLM) and User Characteristics-Collaborative Filtering (UCCF) demonstrates our method's effectiveness in maximizing recall, precision, and f-measure, as tested with the Network Simulator (NS3).},
  keywords={},
  doi={10.1109/MOCAST57943.2023.10176696},
  ISSN={},
  month={June},}@ARTICLE{9508125,
  author={Qin, Zhenquan and Ye, Jin and Meng, Jie and Lu, Bingxian and Wang, Lei},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Privacy-Preserving Blockchain-Based Federated Learning for Marine Internet of Things}, 
  year={2022},
  volume={9},
  number={1},
  pages={159-173},
  abstract={The marine Internet of things (MIoT) is the application of the Internet of things technology in the marine field. Nowadays, with the arrival of the era of big data, the MIoT architecture has been transformed from cloud computing architecture to edge computing architecture. However, due to the lack of trust among edge computing participants, new solutions with higher security need to be proposed. In the current solutions, some use blockchain technology to solve data security problems while some use federated learning technology to solve privacy problems, but these methods neither combine with the special environment of the ocean nor consider the security of task publishers. In this article, we propose a secure sharing method of MIoT data under an edge computing framework based on federated learning and blockchain technology. Combining its special distributed architecture with the MIoT edge computing architecture, federated learning ensures the privacy of nodes. The blockchain serves as a decentralized way, which stores federated learning workers to achieve nontampering and security. We propose a concept of quality and reputation as the metrics of selection for federated learning workers. Meanwhile, we design a quality proof mechanism [proof of quality (PoQ)] and apply it to the blockchain, making the edge nodes recorded in the blockchain more high-quality. In addition, a marine environment model is built in this article, and the analysis based on this model makes the method proposed in this article more applicable to the marine environment. The numerical results obtained from the simulation experiments clearly show that the proposed scheme can significantly improve the learning accuracy under the premise of ensuring the safety and reliability of the marine environment.},
  keywords={},
  doi={10.1109/TCSS.2021.3100258},
  ISSN={2329-924X},
  month={Feb},}@INPROCEEDINGS{10011594,
  author={Abbasi, Rabiya and Martinez, Pablo and Ahmad, Rafiq},
  booktitle={2022 10th International Conference on Control, Mechatronics and Automation (ICCMA)}, 
  title={Data Acquisition and Monitoring Dashboard for IoT Enabled Aquaponics Facility}, 
  year={2022},
  volume={},
  number={},
  pages={168-172},
  abstract={Aquaponics is an emerging field of agriculture that has great potential to ensure food security and sustainability. It presents a closed-loop ecosystem that synergizes fish farming (aquaculture) and soilless plant growing (hydroponics). As aquaponics is a simulation of a natural ecosystem, a significant number of factors are involved in its management. For instance, constant monitoring of water quality, environmental parameters, and illumination is required to achieve healthy growth of fish and plants. In combination with cloud computing technology, the internet of things (IoT) provides a platform to collect data, monitor systems, detect abnormal conditions, and rectify problems in the system without human intervention. This research project presents a framework that involves the development of a cloud-based dashboard for data acquisition and monitoring of an aquaponics facility. The data from a wireless sensing module (measuring pH, water temperature, electroconductivity, light intensity, air humidity, and air temperature) and several cameras installed in an aquaponics farm are uploaded wirelessly to the dashboard. These images are saved on the dashboard with their relevant sensor measurements. The user (farmer or aquaponics practitioner) can get real-time insights regarding the farm’s performance with this information. It can also be used for the creation of future smart applications that can perform and showcase short and long-term predictions.},
  keywords={},
  doi={10.1109/ICCMA56665.2022.10011594},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9820438,
  author={Chango - Cañaveral, Patricia Marisol and Esperanza Jaya- Jaramillo, Doris and Quezada- Sarmiento, Pablo Alejandro and Teodomiro Salas - Álvarez, Wilson},
  booktitle={2022 17th Iberian Conference on Information Systems and Technologies (CISTI)}, 
  title={Analysis of the Quality Service of the Hotel Villa Colonial through the Servqual method and Cloud Computing tools}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={The objective of this article was to analyze the quality service through the Servqual model at the Villa Colonial Hotel in the Malacatos parish. The methodology used established as an object of study the application of the Servqual model, which allowed measuring customer service satisfaction, which is made up of five dimensions such as: reliability, responsiveness, security, empathy, and tangible elements. The information was collected through the application of structured interviews to 218 guests in two phases: in the first phase, data was acquired regarding the expectation of the services offered by the hotel and in the second phase, data was collected on the perception of the services provided. In the evaluation of the gap, it was possible to identify 11 shortcomings in customer service, ¿the most punctuated deficiency is item 16 Does the staff care about satisfying the needs of the clients? the perception does not exceed the expectations of the client and is qualified as dissatisfied. The results obtained were used to design an improvement plan to overcome the shortcomings identified in the hotel. Finally, it should be noted that the entire development and implementation process was supported with cloud computing tools.},
  keywords={},
  doi={10.23919/CISTI54924.2022.9820438},
  ISSN={2166-0727},
  month={June},}@INPROCEEDINGS{9915888,
  author={Wen, Shilin and Deng, Hongjie and Qiu, Ke and Han, Rui},
  booktitle={2022 IEEE International Conference on Sensing, Diagnostics, Prognostics, and Control ( SDPC)}, 
  title={EdgeCloudBenchmark: A Benchmark Driven by Real Trace to Generate Cloud-Edge Workloads}, 
  year={2022},
  volume={},
  number={},
  pages={377-382},
  abstract={With the rapid development of 5G and IoT technology, edge computing, as an extension of the cloud computing paradigm, has been widely used to handle some latency-sensitive tasks. Due to insufficient and limited resource of edge devices, when the edge handles some complex tasks, it is often necessary to cooperate with the cloud, which forms the cloud-edge collaboration scenarios. In real cloud-edge collaboration cluster, different scheduling algorithms will greatly affect the resource allocation and workload completion time. Therefore, how to measure the quality of a scheduling algorithm has become critical. However, there is no existing benchmark test sets for such scenarios at present. Based on this problem, this paper proposes EdgeCloudBenchmark, which is a benchmark generation system driven by real Alibaba cluster trace. In this system, we can generate two different benchmark test sets for CPU cluster and GPU cluster, respectively. The experimental results show that these workloads generated from the proposed system can maintain the consistency with the characteristics of the real cluster workloads, and are highly available. Therefore, our proposed system has high concurrency, availability and fault tolerance.},
  keywords={},
  doi={10.1109/SDPC55702.2022.9915888},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9779020,
  author={Duan, Danping and Xiang, Chaoyang},
  booktitle={2022 10th International Conference on Information and Education Technology (ICIET)}, 
  title={The Design and Implementation of Virtual Simulation Teaching Resource Management and Sharing Platform}, 
  year={2022},
  volume={},
  number={},
  pages={11-15},
  abstract={In China, the construction and sharing of virtual simulation teaching resources is an important measure to improve the quality of practical teaching. However, due to various factors, there are still many difficulties in the integrated management and open sharing of virtual simulation teaching resources. Therefore, this paper analyzes the problems existing in the management and sharing of virtual simulation teaching resources, and puts forward the mode of virtual simulation teaching resources management and sharing based on the network support platform. Then, the design idea of virtual simulation teaching resource management sharing platform is elaborated, and the layered architecture is adopted, and the overall framework of the platform is designed by integrating virtual reality, cloud computing, big data and other technologies. Finally, the platform is realized and the functions and applications of the four core modules, portal service, VR resource service, VR project teaching and statistical analysis, are described in detail. This paper can provide reference for other universities to develop the sharing platform of virtual simulation teaching resources management.},
  keywords={},
  doi={10.1109/ICIET55102.2022.9779020},
  ISSN={},
  month={April},}@INPROCEEDINGS{10212187,
  author={Thakur, Rahul},
  booktitle={2023 2nd International Conference on Edge Computing and Applications (ICECAA)}, 
  title={Bioinspired Sensory Gating in the Artificial Vision System}, 
  year={2023},
  volume={},
  number={},
  pages={1163-1167},
  abstract={When viewed as an enterprise, the healthcare system has important security and privacy requirements, such as protecting patient medical records from unauthorized access, tracking protected drugs, securely connecting to transportation such as ambulances, and conducting secure and intelligent e-health surveillance. Blockchain has introduced new ideas in medical data security and safety, and with the right security measures, it may eliminate the tension between sharing data and maintaining anonymity. In this study, the benefits of cloud computing are integrated with blockchain to offer a secrecy technique for blockchain and IoT. In addition to incorporating IoT and providing IoT solutions to blockchain nodes, this method also collects, analyzes, uses, and maintains identity authentication for health information. Interface and overcomes the insufficient computer power of particular blockchain chain routers to verify the data's feasibility and authenticity order to verify the feasibility and authenticity of the data. The simulation experiment shows that the suggested technique is effective. It may handle problems like high computer intricacy, data interchange, and privacy protection while maintaining and confirming the quality of medical data.},
  keywords={},
  doi={10.1109/ICECAA58104.2023.10212187},
  ISSN={},
  month={July},}@INPROCEEDINGS{10263944,
  author={Srivastava, Arun Pratap and Madan, Parul and Sharma, Gunjan and Shrivastava, Anurag and Singh, Yograj and Salim, Mohd.},
  booktitle={2023 IEEE World Conference on Applied Intelligence and Computing (AIC)}, 
  title={Bioinspired Sensory Gating in the Artificial Vision System}, 
  year={2023},
  volume={},
  number={},
  pages={735-739},
  abstract={When viewed as an enterprise, the healthcare system has important security and privacy requirements, such as protecting patient medical records from unauthorized access, tracking protected drugs, connecting to transportation such as ambulances securely, and conducting secure and intelligent e-health surveillance. Block chain has introduced new ideas in medical data security and safety, and with the right security measures, it may eliminate the tension between sharing data and maintaining anonymity. In this study, we integrate the benefits of cloud computing with block chain to offer a secrecy technique for block chain and IoT. In addition to incorporating IoT and providing Iot solutions to block chain nodes, this method also collects, analyzes, uses, and maintains identity authentication for health information. Interface and overcomes the insufficient computer power of particular blockchainchain routers to verify the data's feasibility and authenticity order to verify the feasibility and authenticity of the data. The simulation experiment shows that the suggested technique is effective. It may handle problems like high computer intricacy, data interchange, and privacy protection while maintaining and confirming the quality of medical data.},
  keywords={},
  doi={10.1109/AIC57670.2023.10263944},
  ISSN={},
  month={July},}@ARTICLE{9707879,
  author={Huang, Siqi and Xie, Jiang and Muslam, Muhana Magboul Ali},
  journal={IEEE Transactions on Cloud Computing}, 
  title={A Cloud Computing Based Deep Compression Framework for UHD Video Delivery}, 
  year={2023},
  volume={11},
  number={2},
  pages={1562-1574},
  abstract={Ultra-high-definition (UHD) videos are enjoying increased popularity in people's daily usage because of the good visual experience. However, the data size of UHD videos is 4-16 times larger of HD videos. This will bring many challenges to existing video delivery systems, such as the shortage of network bandwidth resources and longer network transmission latency. In this article, we propose a cloud computing based deep compression framework named Pearl, which utilizes the power of deep learning and cloud computing to compress UHD videos. Pearl compresses UHD videos from two respects: the frame resolution and the colorful information. In pearl, an optimal compact representation of the original UHD video is learned with two deep convolutional neural networks (DCNNs): super resolution CNN (SR-CNN) and colorization CNN (CL-CNN). SR-CNN is used to reconstruct a high resolution video from a low resolution video while CL-CNN is adopted to preserve the color information of the video. Pearl focuses on video content compression in two new directions. Thus, it can be integrated with any existing video compression system. With Pearl, the data size of UHD videos can be significantly reduced. We evaluate the performance of Pearl with a wide variety of network conditions, quality of experience (QoE) metrics, and video properties. In all considered scenarios, Pearl can further compress 84% of video size and reduce 73% of network transmission latency.},
  keywords={},
  doi={10.1109/TCC.2022.3149420},
  ISSN={2168-7161},
  month={April},}@INPROCEEDINGS{10212311,
  author={Lokesh, Gudivada and Baseer, K. K.},
  booktitle={2023 2nd International Conference on Edge Computing and Applications (ICECAA)}, 
  title={An Architecture for Dynamic Load Balancing in Cloud Environment}, 
  year={2023},
  volume={},
  number={},
  pages={84-91},
  abstract={Clouds are highly customizable infrastructures that offer a platform as a service and let customers subscribe on a pay-as-you-go basis to their requirements. The straightforward service-oriented cloud computing model is gaining popularity around the world. The number of people using the Cloud is constantly growing. Clouds use modern data centers to manage a massive number of users. The reliability of the Cloud depends on load balancing. Balancing virtual machine loads lowers energy consumption and task rejections by optimizing resource utilization. One can increase performance while using fewer resources using load balancing, resource management, quality of service, etc. The difficulty of overloading and underloading virtual machines in cloud computing can be lessened by load balancing in the Cloud.This research study thoroughly examined the load-balancing algorithms found in the literature. First, the traditional approaches are analyzed before moving on to more recent work on load balancing with heterogeneous techniques. Along with the tools available for the current investigation, various metrics are used to evaluate the load-balancing algorithms. The proposed article will primarily serve to assist in the development of new algorithms in the future.},
  keywords={},
  doi={10.1109/ICECAA58104.2023.10212311},
  ISSN={},
  month={July},}@INPROCEEDINGS{10189468,
  author={Chen, Fan and Du, Yugen and Zhong, Wenhao and Wang, Hanting},
  booktitle={2022 IEEE Smartworld, Ubiquitous Intelligence & Computing, Scalable Computing & Communications, Digital Twin, Privacy Computing, Metaverse, Autonomous & Trusted Vehicles (SmartWorld/UIC/ScalCom/DigitalTwin/PriComp/Meta)}, 
  title={Web Service QoS Prediction Based on Reputation and Location Aware Matrix Factorization}, 
  year={2022},
  volume={},
  number={},
  pages={1722-1729},
  abstract={With the development of cloud computing and Internet technologies, the number of Web services has increased dramatically. It is increasingly difficult for users to locate applicable services among a large number of functionally equivalent candidates. Considering the high cost of time and resources, users cannot invoke all Web services to obtain the desired quality of service (QoS). Therefore, the problem of QoS prediction of Web services has attracted much attention in recent years. Although QoS is often used as a measure of Web service performance, the value of QoS may vary significantly between users depending on their network and geographical location. Furthermore, most traditional approaches perform QoS prediction directly based on historical QoS values provided by users. However, these historical QoS data may contain unreliable values from unreliable users, resulting in significantly lower prediction accuracy. To overcome the above limitations, we propose a reputation and location aware matrix factorization (RLMF) approach for QoS prediction of Web services in this paper. First, we cluster the users and calculate their reputation based on the clustering information through Dirichlet distribution. Then, we integrate the user’s reputation and location information into the matrix factorization model to obtain more accurate prediction results. Additionally, we use Cauchy loss to measure the difference between the observed and predicted QoS values, which makes our approach robust to even outliers. We conducted experiments on a largescale dataset of 1,974,675 QoS values to evaluate our approach. The experimental results show that our approach performs better than state-of-the-art baseline approaches.},
  keywords={},
  doi={10.1109/SmartWorld-UIC-ATC-ScalCom-DigitalTwin-PriComp-Metaverse56740.2022.00245},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10114347,
  author={Cao, Junling and Xu, Yichuan and Qian, Yuxuan and Chai, Tingyi and Liu, Chang},
  booktitle={2023 5th Asia Energy and Electrical Engineering Symposium (AEEES)}, 
  title={Multidimensional Full State Water Quality - Electrical Data Mining Method for Intelligent Fishing Grounds Based on Cloud Edge Collaboration}, 
  year={2023},
  volume={},
  number={},
  pages={1117-1123},
  abstract={Aiming at the problem that the intelligent analysis technology of aquaculture characteristics is difficult to meet the practical application needs of the market, a multi-dimensional full state water quality-electrical data mining method of intelligent fishing grounds based on cloud edge collaboration is proposed. First, based on the cloud edge collaboration architecture, an intelligent fishing ground awareness operation and maintenance system is designed. Through the collaboration of edge computing and cloud computing, the real-time performance of system data monitoring and processing is improved. Then, in the system edge layer, the weighted least square method and BP neural network are used for multidimensional data fusion to ensure the accuracy of monitoring data. Finally, the grey correlation analysis method is applied to the fuzzy comprehensive evaluation, and an improved fuzzy association rule analysis and evaluation model is constructed for the deep mining of full state data, so as to obtain the water quality and electrical safety level. Based on the experimental analysis of the proposed method in Taizhou Jiangyan Fishing Light Complementary Fishing Ground, the results show that the error of the heterogeneous data fusion method is smaller, and its water quality electrical comprehensive evaluation value is between 0.751-0.928, which is the closest to the measured value.},
  keywords={},
  doi={10.1109/AEEES56888.2023.10114347},
  ISSN={},
  month={March},}@ARTICLE{9645168,
  author={Balcão-Filho, Amandio and Ruiz, Natasha and Rosa, Ferrucio de Franco and Bonacin, Rodrigo and Jino, Mario},
  journal={IEEE Transactions on Services Computing}, 
  title={Applying a Consumer-Centric Framework for Trust Assessment of Cloud Computing Service Providers}, 
  year={2023},
  volume={16},
  number={1},
  pages={95-107},
  abstract={Cloud computing services consumers do not have enough reliable information about critical characteristics of their providers, such as performance, security, trust and privacy, compliance with laws and regulations, among others. Our proposal addresses these problems presenting a trust assessment framework that integrates three domains: Governance, Transparency, and Security Information. Our approach is consumer-centric and deals with trust aspects from the end-user’s perspective. We use Indicators to communicate the outcomes, which aim to represent the expression of cybersecurity, manageability, and transparency of services under assessment. This paper includes an implementation proposal, prototype, and proof of concept, in which the framework was applied in a real scenario and executed over a long-term (18 months) usage simulation to verify its applicability, sensitivity, and robustness. Our study is intended for use by consumers of cloud computing who seek to know and measure levels of cybersecurity, protection of privacy, transparency of security, and high levels of quality in their services and infrastructure.},
  keywords={},
  doi={10.1109/TSC.2021.3134125},
  ISSN={1939-1374},
  month={Jan},}@ARTICLE{10309856,
  author={Singhal, Saurabh and Gupta, Nakul and Berwal, Parveen and Naveed, Quadri Noorulhasan and Lasisi, Ayodele and Wodajo, Anteneh Wogasso},
  journal={IEEE Access}, 
  title={Energy Efficient Resource Allocation in Cloud Environment Using Metaheuristic Algorithm}, 
  year={2023},
  volume={11},
  number={},
  pages={126135-126146},
  abstract={Utility-based computing popularly known as “cloud computing” offers several computing services to the users. Due to the proliferation in the users of cloud computing, there is an unprecedented increase in the demand for computation resources to execute cloud services. Thus, there is a requirement to investigate currently available resources like virtual machines, CPU, RAM, and storage to allocate cloud services. The allocation and QoS of cloud services are highly dependent on allocation schemes. The optimized solutions allocate resources to submitted jobs to reduce the overall cost to the end-users/service provider without degrading the performance of virtual machines. The allocation techniques also consider the harvesting of energy consumption required for running the cloud services. In this paper, we have utilized a Rock Hyrax-based optimization technique to allocate resources to the submitted jobs with reduced energy consumption. The proposed Rock Hyrax algorithm has been simulated on the CloudSim simulator for various scenarios. The performance of the proposed algorithm has been measured over various Quality of Service (QoS) parameters such as makespan, energy efficiency, response time, throughput, and cost. The gathered results validate the proposed algorithm that improves the QoS parameters by 3%-8% as compared to algorithms when both jobs and resources are considered to be dynamic in nature.},
  keywords={},
  doi={10.1109/ACCESS.2023.3330434},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10051112,
  author={Zalokostas-Diplas, Vasileios and Makris, Nikos and Passas, Virgilios and Korakis, Thanasis},
  booktitle={2022 IEEE Conference on Standards for Communications and Networking (CSCN)}, 
  title={Experimental Evaluation of ML Models for Dynamic VNF Autoscaling}, 
  year={2022},
  volume={},
  number={},
  pages={157-162},
  abstract={Network Functions Virtualization (NFV) is a key aspect deeply integrated in the latest 5G networks, allowing for the provisioning of elastic resources that adapt in a flexible manner based on the overall network demand. The adoption of NFV architectures is empowered through the evolution of cloud-native and hypervisor tools to support service monitoring, and orchestrate the appropriate decisions for provisioning the scale of the network. Such decisions may directly impact the overall quality of service and experience for users, as well as the energy consumption that the resources use. To this aim, machine learning (ML) - driven optimization for these decisions, relying on inferring the values of future monitored metrics, can assist in deciding proactively on the network scale. In this work, we employ three different candidate solutions (statistical, tree- and CNN-based) for determining the scale of network functions deployed within a cluster of resources, subject to the user demand. We compare and evaluate the different schemes in a real testbed environment, and discuss the benefits of ML-driven optimizations against existing state-of-the-art approaches.},
  keywords={},
  doi={10.1109/CSCN57023.2022.10051112},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10151287,
  author={Pandey, Shivani and Mishra, Satanand and Jain, Ravi Kant},
  booktitle={2023 International Conference on Recent Advances in Electrical, Electronics & Digital Healthcare Technologies (REEDCON)}, 
  title={IoT Interface Device for Sensing Arsenic in Contaminated Water}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Water pollution is a serious problem in different parts of the world. In addition, water quality must be monitored to ensure that the water is provided safely for drinking and other purposes. Too high a concentration of Arsenic ions in drinking water is the cause of many health problems, including heart problems, neurological problems, etc. Water sampling and laboratory analysis are required for traditional water quality monitoring. In this paper, we discussed an IoT-based interfacing sensor device for sensing arsenic contaminants in water where IoT cloud computing networks enable the integration of a variety range of mechanical and electronic devices. A Node MCU device is used for data transmission which emphasizes on Wi-Fi-controlled interface devices and IoT-enabled communication protocol for the detection of water contaminants. This system is connected to an IoT cloud platform to store the data for analyzing purposes where Red-Green-Blue (RGB) color detection occurs by identifying the wavelength of contaminants. The system makes use of IoT to display the output in real-time for on-site and off-site monitoring via mobile phone. The system makes use of IoT to display the output in real-time for on-site and off-site monitoring via mobile phone, The major advantage of IoT technology is that it easily connects devices and stores the generated data in the cloud. With the help of command control systems, data can be used for appropriate applications to make human life easier and safer while considering Industry's impact. The acceptable limits set by WHO and the Bureau of Indian Standards for Arsenic are 0.05 mg/litres and 0.01 mg/l respectively. Therefore, a smart and intelligent device that can be used for measuring Arsenic content which is very necessary today to ensure the health of human life in society.},
  keywords={},
  doi={10.1109/REEDCON57544.2023.10151287},
  ISSN={},
  month={May},}@INPROCEEDINGS{9872806,
  author={Manova, Rd Yovi and Sukmadirana, Edi and Nurmanah, Nurma Siti},
  booktitle={2022 1st International Conference on Information System & Information Technology (ICISIT)}, 
  title={Comparative Analysis of Quality of Service and Performance of MPLS, EoIP and SD-WAN}, 
  year={2022},
  volume={},
  number={},
  pages={403-408},
  abstract={Software Defined – Wide Area Network (SDWAN) implementation is growing each year as one of the options for enterprise to have hybrid and redundant connection between traditional WAN and Internet. The cloud computing services, whether it is IaaS, PaaS, or SaaS has attracted most of enterprise to separate the corporate data connection from private WAN to public internet securely. This dual data traffic still can be managed by enterprise router, but it will require manual routing or at lease delay with complicated rule to mitigate any link problem. SD-WAN as the development of SDN in wide area network, have the solution to solve the manual routing data, by putting the control plane in a software environment to manage the data traffic virtually. In Indonesia, the SD-WAN technology has been introduced by several vendors and operators, some enterprise still reluctance considering the security of enterprise data through public internet service, and some of them still questioning the Quality of Services compare to legacy or traditional WAN services. Therefore, this research will perform the Quality of Service and Performance of SD-WAN, compare to traditional Multiprotocol Label Switching (MPLS) link and Ethernet over Internet Protocol (EoIP) as one of the contenders. The object of the research is an active WAN of one of Indonesian company, that having those three connections between Jakarta and Surabaya. The QoS and performance are measured using ITU- T G.1010 standard as the reference.},
  keywords={},
  doi={10.1109/ICISIT54091.2022.9872806},
  ISSN={},
  month={July},}@ARTICLE{9772936,
  author={Kashani, Mostafa Haghi and Mahdipour, Ebrahim},
  journal={IEEE Transactions on Services Computing}, 
  title={Load Balancing Algorithms in Fog Computing}, 
  year={2023},
  volume={16},
  number={2},
  pages={1505-1521},
  abstract={Recently, fog computing has been introduced as a modern distributed paradigm and complement to cloud computing to provide services. The fog system extends storing and computing to the edge of the network, which can remarkably solve the problem of service computing in delay-sensitive applications besides enabling location awareness and mobility support. Load balancing is an important aspect of fog networks that avoids a situation with some under-loaded or overloaded fog nodes. Quality of service parameters such as resource utilization, throughput, cost, response time, performance, and energy consumption can be improved by load balancing. In recent years, some research in load balancing algorithms in fog networks has been carried out, but there is no systematic study to consolidate these works. This article investigates the load-balancing algorithms systematically in fog computing in four classifications, including approximate, exact, fundamental, and hybrid algorithms. Also, this article investigates load balancing metrics with all advantages and disadvantages related to chosen load balancing algorithms in fog networks. The evaluation techniques and tools applied for each reviewed study are explored as well. Additionally, the essential open challenges and future trends of these algorithms are discussed.},
  keywords={},
  doi={10.1109/TSC.2022.3174475},
  ISSN={1939-1374},
  month={March},}@ARTICLE{9140382,
  author={Kong, Cuiyu and Rimal, Bhaskar Prasad and Reisslein, Martin and Maier, Martin and Bayram, Islam Safak and Devetsikiotis, Michael},
  journal={IEEE Transactions on Services Computing}, 
  title={Cloud-Based Charging Management of Heterogeneous Electric Vehicles in a Network of Charging Stations: Price Incentive Versus Capacity Expansion}, 
  year={2022},
  volume={15},
  number={3},
  pages={1693-1706},
  abstract={This article presents a novel cloud-based charging management system for electric vehicles (EVs). Two levels of cloud computing, i.e., local and remote clouds, are employed to meet the different latency requirements of the heterogeneous EVs while exploiting the lower-cost computing in remote clouds. Specifically, we consider time-sensitive EVs at highway exit charging stations and EVs with relaxed timing constraints at parking lot charging stations. We propose algorithms for the interplay among EVs, charging stations, system operator, and clouds. Considering the contention-based random access for EVs to a 4G Long-Term Evolution network, and the quality of service metrics (average waiting time and blocking probability), the model is composed of: queuing-based cloud server planning, capacity planning in charging stations, delay analysis, and profit maximization. We propose and analyze a price-incentive method that shifts heavy load from peak to off-peak hours, a capacity expansion method that accommodates the peak demand by purchasing additional electricity, and a hybrid method of price incentives and capacity expansion that balances the immediate charging needs of customers with the alleviation of the peak power grid load through price-incentive based demand control. Numerical results demonstrate the effectiveness of the proposed methods and elucidate the tradeoffs between the methods.},
  keywords={},
  doi={10.1109/TSC.2020.3009084},
  ISSN={1939-1374},
  month={May},}@ARTICLE{9760072,
  author={Okegbile, Samuel D. and Maharaj, Bodhaswar T. and Alfa, Attahiru S.},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={A Multi-User Tasks Offloading Scheme for Integrated Edge-Fog-Cloud Computing Environments}, 
  year={2022},
  volume={71},
  number={7},
  pages={7487-7502},
  abstract={This paper presents a multi-user, multi-class and multi-layer edge computing-based framework for effective task offloading and computation processes. Important system requirements that were not captured in the existing multi-layer solutions such as offloading, computations and deadline requirements were captured in the system modeling, while both wireless communications and task computation constraints were considered. We considered three layers system, where each device offloads its generated tasks in each time slot to any selected layer for computation. On its arrival at such a selected layer, the task is only accepted if the queue size is below the pre-defined threshold, otherwise, such a task is offloaded to the next layer. Tasks were classified into class 1 and class 2 tasks following tasks’ quality of service requirements. We adopted stochastic geometry, parallel computing and queueing theory techniques to model the performance of the considered integrated edge-fog-cloud computing environment and obtained analysis for various performance metrics of interest. The obtained analyses demonstrate the importance of multi-layer and multi-class edge computing systems towards improving the experience of both delay-sensitive and mission-critical applications in any task offloading environment.},
  keywords={},
  doi={10.1109/TVT.2022.3167892},
  ISSN={1939-9359},
  month={July},}@INPROCEEDINGS{10074183,
  author={Morel, Alicia Esquivel and Calyam, Prasad and Qu, Chengyi and Gafurov, Durbek and Wang, Cong and Thareja, Komal and Mandal, Anirban and Lyons, Eric and Zink, Michael and Papadimitriou, George and Deelman, Ewa},
  booktitle={2023 International Conference on Computing, Networking and Communications (ICNC)}, 
  title={Network Services Management using Programmable Data Planes for Visual Cloud Computing}, 
  year={2023},
  volume={},
  number={},
  pages={130-136},
  abstract={Visual Cloud Computing (VCC) applications provide highly efficient solutions in video data processing pipelines on edge/cloud infrastructures. These applications and their infrastructures demand end-to-end monitoring and fine-grained application traffic control to meet user quality of experience requirements. In this paper, we propose a novel network services management methodology for VCC applications by leveraging the advantages of programmable data planes enabled by Protocol-independent Packet Processors (P4). Specifically, we define a custom fixed-length application header and use it to improve the performance of a video streaming application through congestion avoidance using Multi-Hop Route Inspection (MRI), a variant of In-band Network Telemetry (INT), and switch port forwarding (tunneling) capabilities. For evaluation experiments, we use P4 per-packet telemetry metadata for routing paths, ingress/egress timestamps, queue occupancy in a given node, and egress port link utilization in a VCC testbed on the NSF-supported FABRIC infrastructure. Our experiment results demonstrate performance improvement obtained with our methodology in terms of both packet loss and throughput metrics.},
  keywords={},
  doi={10.1109/ICNC57223.2023.10074183},
  ISSN={},
  month={Feb},}@ARTICLE{9829255,
  author={Fu, Shaojing and Huang, XueLun and Liu, Lin and Luo, Yuchuan},
  journal={IEEE Transactions on Cloud Computing}, 
  title={BFCRI: A Blockchain-Based Framework for Crowdsourcing With Reputation and Incentive}, 
  year={2023},
  volume={11},
  number={2},
  pages={2158-2174},
  abstract={With the rapid development of cloud computing and the sharing economy, crowdsourcing aroused widespread interest and adoption in providing intelligent and efficient services for humans. The majority of existing works focus on effective crowdsourcing task assignment and privacy protection, mostly relying on central servers and assuming that participants are $honest$honest-$and$and-$curious$curious and proactive. However, in reality, workers may be unwilling to participate, and there may be malicious behavior among participants, thus harming the enthusiasm and interests of other participants. The central server has weaknesses such as single point of failure. To address above problems, we propose a blockchain-based framework for crowdsourcing with reputation and incentive. We first design a worker selection scheme to select credible and capable workers. We leverage reputation as a metric of workers’ credibility, which is calculated through the improved subjective logic model. Then we utilize contract theory to design incentive mechanisms to attract more workers, especially high-quality workers to participate. Experimental results show that our proposed method can detect and prevent malicious participants and resist malicious collusion when the proportion of malicious participants is no more than 1/3. And encourage more workers to actively, honestly and continuously participate in crowdsourcing.},
  keywords={},
  doi={10.1109/TCC.2022.3190275},
  ISSN={2168-7161},
  month={April},}@INPROCEEDINGS{10047622,
  author={Gritto, D. and Muthulakshmi, P.},
  booktitle={2022 11th International Conference on System Modeling & Advancement in Research Trends (SMART)}, 
  title={Scheduling Cloudlets in a Cloud Computing Environment: A Priority-based Cloudlet Scheduling Algorithm (PBCSA)}, 
  year={2022},
  volume={},
  number={},
  pages={80-86},
  abstract={Cloud computing is a service model that has evolved in its stature beyond its traditional bounds of infrastructure, platform and software as a service. As the surge in resource demand may hit the cloud service provider at any time, a ceaseless monitoring system is vital. The allocation of an appropriate virtual machine for the cloudlet i.e., the user workload and maintaining the work load equilibrium among the resources is the most challenging operation in the cloud environment. The proper utilization of the cloud resources can be ensured by selecting the right cloudlet scheduling and load balancing algorithm(s). The cloudlet scheduling algorithm selection is based on the combination of two or more Quality of Service (QoS) and performance metrics like makespan, throughput, cost, power consumption, virtual machine or resource utilization and load balancing etc. The load balancer module takes the responsibility of dispersing the cloudlets evenly among the virtual machines by considering various features like CPU utilization, number of processing elements, bandwidth, memory and the load limit of the virtual machines. In this paper, an effort has been made to comprehend the most persisting cloudlet scheduling and load balancing algorithms that have been proposed by the researchers. Compiling the load balancing technologies that are integrated with the contemporary cloud platforms such as Amazon Web Services (AWS), Microsoft Azure and Google Cloud Platform (GCP) has also been prioritized. This study suggests a Priority Based Cloudlet Scheduling Algorithm (PBCSA) that schedules the cloudlet according to the user priority. The Min-Min scheduler is used to schedule the high priority cloudlets and the Max-Min scheduler is used to schedule the low priority cloudlets. The experimental findings reveals that, in the majority of scenarios, the proposed algorithm outperforms the Min-Min and Max-Min scheduling in terms of makespan and virtual machine utilization ratio.},
  keywords={},
  doi={10.1109/SMART55829.2022.10047622},
  ISSN={2767-7362},
  month={Dec},}@ARTICLE{10172271,
  author={Chang, Jiaxin and Wang, Jian and Li, Bing and Zhao, Yuqi and Li, Duantengchuan},
  journal={IEEE Transactions on Network and Service Management}, 
  title={Attention-Based Deep Reinforcement Learning for Edge User Allocation}, 
  year={2023},
  volume={},
  number={},
  pages={1-1},
  abstract={Edge computing, a recently developed computing paradigm, seeks to extend cloud computing by providing users minimal latency. In a mobile edge computing (MEC) environment, edge servers are placed close to edge users to offer computing resources, and the coverage of adjacent edge servers may partially overlap. Because of the restricted resource and coverage of each edge server, edge user allocation (EUA), i.e., determining the optimal way to allocate users to different servers in the overlapping area, has emerged as a major challenge in edge computing. Despite the NP-hardness of obtaining an optimal solution, it is possible to evaluate the quality of a solution in a short amount of time with given metrics. Consequently, deep reinforcement learning (DRL) can be used to solve EUA by attempting numerous allocations and optimizing the allocation strategy depending on the rewards of those allocations. In this study, we propose the Dual-sequence Attention Model (DSAM) as the DRL agent, which encodes users using self-attention mechanisms and directly outputs the probability of matching between users and servers using an attention-based pointer mechanism, enabling the selection of the most suitable server for each user. Experimental results show that our method outperforms the baseline approaches in terms of allocated users, required servers, and resource utilization, and its running speed meets real-time requirements.},
  keywords={},
  doi={10.1109/TNSM.2023.3292272},
  ISSN={1932-4537},
  month={},}@INPROCEEDINGS{9900564,
  author={Sankaran, Lakshmi and Saleema, J S and Suleiman, Basem},
  booktitle={2022 IEEE/ACIS 7th International Conference on Big Data, Cloud Computing, and Data Science (BCD)}, 
  title={Analysis of Workloads for Cloud Services}, 
  year={2022},
  volume={},
  number={},
  pages={117-123},
  abstract={Capturing best quality datasets for a study is the first evidence for better outcomes of research. If the analysis are based on such datasets, then the metrics, the characteristics and few factors determines proof point for well proven theories. Hence it is obvious that we rely on the best possible ways to arrive at such data acquiring sources. It can be either based on historical techniques or from the innovations in application of it to industry. This paper introduces a mapping framework for analyzing, and characterizing data previously used by research community and how they are made to fit for Cloud systems, i.e. using “workloads” and “datasets” as the “refined definitions”. It was contributed in the past two decades within the scientific community setting their own workflow analysis mechanisms. The framework thus is validated by acquiring a sample workload per layer of cloud. The sources are form the literature that are available from existing scientific theories. These workloads are then experimented against the three tiers of the cloud computing ie., IaaS(Infrastructure as a Service), PaaS(Platform as a Service), & SaaS(Software as a Service). The selected data is analyzed by the authors for an offline model presented here based on the Machine Learning tool-kits. There are future studies planned for and to be experimented in a cloud auto scaled environment with online model as well.},
  keywords={},
  doi={10.1109/BCD54882.2022.9900564},
  ISSN={},
  month={Aug},}@ARTICLE{10227869,
  author={Deebak, Bakkiam David and Hwang, Seong Oun},
  journal={IEEE Systems Journal}, 
  title={A Cloud-Assisted Medical Cyber-Physical System Using a Privacy-Preserving Key Agreement Framework and a Chebyshev Chaotic Map}, 
  year={2023},
  volume={17},
  number={4},
  pages={5543-5554},
  abstract={At present, communication networks like the Internet of Things (IoT) are emerging with some of the latest technologies, such as artificial intelligence, big data, and cloud computing, to enable wireless edge infrastructures and seamless data migration. In particular, edge-based wireless communications help to gain new insights into the mitigation of potential communicable infections, e.g., COVID-19, via the use of IoT sensing devices. Of late, an evolving technology known as the cloud-assisted medical cyber-physical system (MCPS) has explored various key agreement protocols to examine security weaknesses between sensing devices and medical experts. Unfortunately, the existing schemes address vulnerabilities such as impersonation, privileged insider, and password guessing, whereby the behavior of the system becomes nondeterministic when guarding against malicious intent. Also, failures, faults, and attacks may vary in the characteristic forms of the IoT and the MCPS, causing unforeseen impairments in the system and for users. Thus, this article develops a privacy-preserving key agreement framework (PP-KAF) using the Chebyshev chaotic map mechanism to avoid privacy data disclosures and to protect session keys. The proposed PP-KAF exploits a strategy of two-way authentication not only to protect user identities but also to achieve untraceability from the remote server. Finally, a formal analytical model is applied to examine the properties of the key agreement protocol. Simulation results demonstrate that the proposed PP-KAF can offer better security efficiencies and can mitigate computation and communication overhead to guarantee improved quality metrics, namely, throughput rate and energy consumption.},
  keywords={},
  doi={10.1109/JSYST.2023.3303460},
  ISSN={1937-9234},
  month={Dec},}@INPROCEEDINGS{9860577,
  author={Tuli, Shreshth and Casale, Giuliano and Jennings, Nicholas R.},
  booktitle={2022 IEEE 15th International Conference on Cloud Computing (CLOUD)}, 
  title={MetaNet: Automated Dynamic Selection of Scheduling Policies in Cloud Environments}, 
  year={2022},
  volume={},
  number={},
  pages={331-341},
  abstract={Task scheduling is a well-studied problem in the context of optimizing the Quality of Service (QoS) of cloud computing environments. In order to sustain the rapid growth of computational demands, one of the most important QoS metrics for cloud schedulers is the execution cost. In this regard, several data-driven deep neural networks (DNNs) based schedulers have been proposed in recent years to allow scalable and efficient resource management in dynamic workload settings. However, optimal scheduling frequently relies on sophisticated DNNs with high computational needs implying higher execution costs. Further, even in non-stationary environments, sophisticated schedulers might not always be required and we could briefly rely on low-cost schedulers in the interest of cost-efficiency. Therefore, this work aims to solve the non-trivial meta problem of online dynamic selection of a scheduling policy using a surrogate model called MetaNet. Unlike traditional solutions with a fixed scheduling policy, MetaNet on-the-fly chooses a scheduler from a large set of DNN based methods to optimize task scheduling and execution costs in tandem. Compared to state-of-the-art DNN schedulers, this allows for improvement in execution costs, energy consumption, response time and service level agreement violations by up to 11, 43, 8 and 13 percent, respectively.},
  keywords={},
  doi={10.1109/CLOUD55607.2022.00056},
  ISSN={2159-6190},
  month={July},}@INPROCEEDINGS{10322008,
  author={Malti, Arslan Nedhir and Benmammar, Badr and Hakem, Mourad},
  booktitle={2023 5th International Conference on Pattern Analysis and Intelligent Systems (PAIS)}, 
  title={Task Scheduling Optimization in Cloud Computing: A Comparative Study Between Flower Pollination and Butterfly Optimization Algorithms}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={The No Free Lunch theorem states that no single algorithm can universally serve as the best solution for all optimization purposes. Consequently, it becomes imperative to adapt or combine the fundamental structures of metaheuristic optimization algorithms to fit with specific problem-solving requirements. In this paper, we conduct a comparative analysis of two widely recognized metaheuristic algorithms, namely the Butterfly Optimization Algorithm (BOA) and the Flower Pollination Algorithm (FPA) to deal with the task scheduling problem in cloud computing systems. Our objective is to orchestrate the most effective assignment of tasks across the available virtual machines in the system. Performance evaluation encompasses standard and synthetic workloads, focusing on conflicting quality of service metrics, namely time makespan or schedule length and resource utilization. The experiments conducted through the CloudSim framework demonstrate compelling outcomes, highlighting the importance of this study as a basis for future optimization research.},
  keywords={},
  doi={10.1109/PAIS60821.2023.10322008},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10254974,
  author={Caon, Cristiano E. and Li, Jie and Chen, Yong},
  booktitle={2023 IEEE 16th International Conference on Cloud Computing (CLOUD)}, 
  title={Effective Management of Time Series Data}, 
  year={2023},
  volume={},
  number={},
  pages={408-414},
  abstract={Cloud computing systems, consisting of numerous nodes and components, require constant monitoring to satisfy the Quality-of-Service (QoS), making the management of large-scale time series data challenging. To address this issue, age threshold retention policies have been implemented to remove historical data, but this eliminates valuable information from older periods. In this paper, we proposed an alternative approach that applies time series deduplication with metric-based tolerance to discard readings that stabilize within a calculated tolerance window. This approach can reduce the data volume by 70.38% on average. Once the data-reduced interval is queried, the readings can be reconstructed to retrieve the original granularity with low query runtime overhead and a Mean Absolute Percentage Error of 0.74%.},
  keywords={},
  doi={10.1109/CLOUD60044.2023.00055},
  ISSN={2159-6190},
  month={July},}@ARTICLE{10236903,
  author={Tuli, Shreshth and Casale, Giuliano and Jennings, Nicholas R.},
  journal={IEEE Transactions on Computers}, 
  title={SciNet: Codesign of Resource Management in Cloud Computing Environments}, 
  year={2023},
  volume={72},
  number={12},
  pages={3590-3602},
  abstract={The rise of distributed cloud computing technologies has been pivotal for the large-scale adoption of Artificial Intelligence (AI) based applications for high fidelity and scalable service delivery. Systematic resource management is central in maintaining optimal Quality of Service (QoS) in cloud platforms and is divided into three fundamental types: resource provisioning, AI model deployment and workload placement. To exploit the synergy among these decision types, it becomes imperative to concurrently design (co-design) the provisioning, deployment and placement decisions for optimal QoS. As users and cloud service providers shift to non-stationary AI-based workloads, frequent decision making imposes severe time constraints on the resource management models. Existing AI-based solutions often optimize decision types independently and tend to ignore the dependencies across various system performance aspects such as energy consumption and CPU utilization, making them perform poorly in large-scale cloud systems. To address this, we propose a novel method, called SciNet, that leverages a co-simulated digital-twin of the infrastructure to capture inter-metric dependencies and accurately estimate QoS scores. To avoid expensive simulation overheads at test time, SciNet trains a neural network based imitation learner that aims to mimic an oracle, which takes optimal decisions based on co-simulated QoS estimates. Offline model training and online decision making based on the imitation learner, enables SciNet to take optimal decisions while being time-efficient. Experiments with real-life AI-based benchmark applications on a public cloud testbed show that SciNet gives up to 48% lower execution cost, 79% higher inference accuracy, 71% lower energy consumption and 56% lower response times compared to the current state-of-the-art methods.},
  keywords={},
  doi={10.1109/TC.2023.3310678},
  ISSN={1557-9956},
  month={Dec},}@INPROCEEDINGS{9988009,
  author={Sripavithra, C K and Kirubanand, V B},
  booktitle={2022 International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME)}, 
  title={ESSA Scheduling Algorithm for Optimizing Budget-Constrained Workflows}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Workflows are a systematic approach for defining various scientific applications of distributed systems. They break down complicated, data-intensive processes into minor activities that can be executed serially or in parallel according to the type of application. Cloud systems need to allocate resources and schedule workflows efficiently. Despite many studies on job scheduling and resource provisioning, an efficient solution isn't found. Therefore, techniques are required to enhance resource utilization for optimal cloud computing platforms. Hence, user and provider quality of service (QoS) goals, like shortening workflows and ensuring budget limits with low energy utilization, must be considered. Enhanced Salp Swarm Optimization (ESSA) is designed to optimize makespan and QoS metrics in cloud systems. A Virtual Machine (VM's) compute capacity is related to Central Processing Unit (CPU) and memory. Size and memory demand is considered for tasks in the workflow, and task execution time is evaluated using both CPU and memory. The collated experimental outcomes convey that the newly presented technique boosts the workflows' energy utilization (up to 89%) and pushes the normalized makespan results to 3.2ms.},
  keywords={},
  doi={10.1109/ICECCME55909.2022.9988009},
  ISSN={},
  month={Nov},}@ARTICLE{8762170,
  author={Abdelbaky, Moustafa and Parashar, Manish},
  journal={IEEE Transactions on Services Computing}, 
  title={A General Performance and QoS Model for Distributed Software-Defined Environments}, 
  year={2022},
  volume={15},
  number={1},
  pages={228-240},
  abstract={The landscape for cloud services and cyberinfrastructure offerings has increased drastically over the past few years. Initially, users moved their applications to the cloud to take advantage of a pay-per-usage model and on-demand access. However, as more cloud providers joined the market, users shifted their goals for using cloud computing from cost reduction to resilience, agility, and optimization. These goals can be achieved by dynamically combining services from multiple providers, for example, to avoid data center or cloud zone outages or to take advantage of extensive offerings with different price points. However, to efficiently support application deployment in this dynamic environment, new models and tools that can measure the application performance and the Quality of Service (QoS) of different configurations are required. The goal of this work is to evaluate the application performance and the QoS of a distributed Software-Defined Environment as well as calculate the QoS of alternative configurations from the underlying pool of services. In particular, we present a mathematical model and a tool for evaluating the performance and QoS of batch application workflows in a distributed environment. We experimentally evaluate the proposed model using a bioinformatics workflow running on infrastructure services from multiple cloud providers.},
  keywords={},
  doi={10.1109/TSC.2019.2928300},
  ISSN={1939-1374},
  month={Jan},}@ARTICLE{9625857,
  author={Hidayetoğlu, Mert and Biçer, Tekin and de Gonzalo, Simon Garcia and Ren, Bin and Gürsoy, Doğa and Kettimuthu, Rajkumar and Foster, Ian T. and Hwu, Wen-Mei W.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={MemXCT: Design, Optimization, Scaling, and Reproducibility of X-Ray Tomography Imaging}, 
  year={2022},
  volume={33},
  number={9},
  pages={2014-2031},
  abstract={This work extends our previous research entitled “MemXCT: Memory-centric X-ray CT Reconstruction with Massive Parallelization” that was originally published at SC19 conference (Hidayetoğlu et al., 2019) with reproducibility of the computational imaging performance. X-ray computed tomography (XCT) is regularly used at synchrotron light sources to study the internal morphology of materials at high resolution. However, experimental constraints, such as radiation sensitivity, can result in noisy or undersampled measurements. Further, depending on the resolution, sample size and data acquisition rates, the resulting noisy dataset can be in the order of terabytes. Advanced iterative reconstruction techniques can produce high-quality images from noisy measurements, but their computational requirements have made their use an exception rather than the rule. We propose a novel memory-centric approach that avoids redundant computations at the expense of additional memory complexity. We develop a memory-centric iterative reconstruction system, MemXCT, that uses an optimized SpMV implementation with two-level pseudo-Hilbert ordering and multi-stage input buffering. We evaluate MemXCT on various supercomputer architectures involving KNL and GPU. MemXCT can reconstruct a large (11K×11K) mouse brain tomogram in 10 seconds using 4096 KNL nodes (256K cores). The results presented in our original article at the SC19 were based on large-scale supercomputing resources. The MemXCT application was selected for the Student Cluster Competition (SCC) Reproducibility Challenge and evaluated on a variety of cloud computing resources by universities around the world in the SC20 conference. We summarize the results of the top-ranked SCC Reproducibility Challenge teams and identify the most pertinent measures for ensuring the reproducibility of our experiments in this article.},
  keywords={},
  doi={10.1109/TPDS.2021.3128032},
  ISSN={1558-2183},
  month={Sep.},}@ARTICLE{9785848,
  author={Rui, Lanlan and Song, Dai and Chen, Shiyou and Yang, Yingtai and Yang, Yang and Gao, Zhipeng},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Content Collaborative Caching Strategy in the Edge Maintenance of Communication Network: A Joint Download Delay and Energy Consumption Method}, 
  year={2022},
  volume={33},
  number={12},
  pages={4148-4163},
  abstract={With the development of Big Data technology and Internet, the surge of data in the network will cause network congestion and untimely task processing. Additionally, caching content in the core network may cause redundant access of content and backhaul bottlenecks. Due to the increasing requirements of users for task processing efficiency, the centralized maintenance system based on traditional cloud computing cannot meet the current computing requirements. In view of these problems, we propose a content collaborative caching mechanism based on joint decision of download delay and energy consumption. By integrating network coding and content caching technology, the work content maintained in the communication network is deployed near the edge of the network in the form of coding to reduce the redundant transmission of content and acquisition time of content. This article establishes a user QoE satisfaction model, which consists of two indexes that measure time delay and energy consumption. This article proposes a $\varepsilon$ɛ-hybrid Q-learning algorithm to optimize the placement of cache files, and made the cache action selection based on the combination of improved heuristic greedy algorithm and simulated annealing algorithm. The experimental results show that the proposed cache strategy can reduce the delay of users downloading content and the energy consumption of content cache, so as to improve the quality of field maintenance work in communication network.},
  keywords={},
  doi={10.1109/TPDS.2022.3179271},
  ISSN={1558-2183},
  month={Dec},}@INPROCEEDINGS{10017214,
  author={Sharma, P. and Saini, K. S. and Sidhu, P. K.},
  booktitle={The 3rd International Conference on Distributed Sensing and Intelligent Systems (ICDSIS 2022)}, 
  title={Authentication mechanisms used in Wireless Body Area Networks: a study}, 
  year={2022},
  volume={2022},
  number={},
  pages={282-291},
  abstract={The WBANs (Collection of light-weight body sensor) of IOT and Cloud Computing provides a substantial ability to upgrade the quality of on-demand health care system. Body Sensors are implanted within or outside the human being body to remotely measure the real-time parameters such as physiology signal and activity. The biggest issue originates from obtaining imprecise and inconsistent measurements when collecting these data from sensor nodes. Moreover, Privacy and Security of human sensitive information are other biggest hurdles of WBANs. In this chapter we describe some wearable devices, security requirements and some security attacks. Moreover, we also discussed various existing authentication mechanisms. Different authentication mechanisms have their own Pros and Cons. Further, based on the study we will performed some comprehensive overview between all existing authentication mechanisms and find some future scope. We also highlight some future research scope in the last section.},
  keywords={},
  doi={10.1049/icp.2022.2478},
  ISSN={},
  month={Oct},}@ARTICLE{9933021,
  author={Lu, Ke and Du, Zhekai and Li, Jingjing and Min, Geyong},
  journal={IEEE Transactions on Network and Service Management}, 
  title={Resource-Efficient Distributed Deep Neural Networks Empowered by Intelligent Software-Defined Networking}, 
  year={2022},
  volume={19},
  number={4},
  pages={4069-4081},
  abstract={Contemporary machine learning methods have evolved from conventional algorithms to deep neural networks (DNNs) that are computation- and data- intensive. Thus, they are suitable to be deployed in the cloud that can offer high computational capacity and scalable resources. However, the cloud computing paradigm is not optimal for delay- and energy-sensitive applications. To mitigate these problems, a battery of distributed DNNs have been proposed to allow a fast inference with device-edge-cloud synergy. Furthermore, although distributed deployment of DNNs on real communication networks is an important research topic, the legacy network architecture cannot meet the requirements of these distributed deep neural networks due to the complicated management and manual configuration, etc. To cope with these requirements, we develop a novel and explicit Intelligent Software Defined Networking (ISDN) that aims to manage the bandwidth and computing resources across the network via the SDN paradigm. We first identify the difficulties of deploying distributed intelligent computing in the current network architecture. Then, we explain how to address these problems by introducing the ISDN architecture. Specifically, we develop a dynamic routing method to enable Quality-of-Service (QoS) communication based on the SDN paradigm and propose a Markov Decision Process (MDP) based dynamic task offloading model to achieve the optimal offloading policy of DNN tasks. We develop a simulation platform based on Mininet to measure its performance advantages over traditional architectures. Extensive experimental results show that compared with the traditional network architecture, our architecture based on the SDN paradigm can perform better in terms of both network throughput and resource utilization.},
  keywords={},
  doi={10.1109/TNSM.2022.3218173},
  ISSN={1932-4537},
  month={Dec},}@INPROCEEDINGS{10001602,
  author={Zhu, Jing and Wang, Dan and Qin, Shuxin and Tao, Gaofeng and Gui, Hongxin and Li, Fang and Ou, Liang},
  booktitle={GLOBECOM 2022 - 2022 IEEE Global Communications Conference}, 
  title={Towards Network Dynamics: Adaptive Buffer Management with Deep Reinforcement Learning}, 
  year={2022},
  volume={},
  number={},
  pages={4935-4940},
  abstract={The prosperity of cloud computing and 5G/B5G is bringing a wide range of delay jitter-sensitive applications (e.g., professional audio/video streaming and industrial automation) to large-scale IP networks. Although various network-side techniques have been proposed to guarantee the quality of service (QoS), the client-side technique by introducing a receive buffer should never be neglected from the applications' perspective. In this paper, we revisit the buffer management problem to address the disadvantages of state-of-the-art studies, which as-sumed network characteristics known a prior with simplified or inaccurate network models and failed to adapt to network dynamics. Specifically, we propose adaptive buffer management with deep reinforcement learning, i.e., DRL-ABM. We first define a tradeoff value to measure the buffer management performance in terms of the start-up delay, underflow frequency and packet losses. Then we formulate the DRL model and design deep neural networks (DNNs) based on the advantage actor critic (A2C) algorithm. To evaluate the performance of DRL-ABM, we perform extensive simulations. Simulation results show that D RL-ABM can achieve better buffer management performance, i.e., reducing the tradeoff value by at least 20% when compared with the benchmarks TBM and ABM. Moreover, DRL-ABM reduces packet losses to approximately 0, indicating that a smaller receive buffer is sufficient if managed with DRL-ABM.},
  keywords={},
  doi={10.1109/GLOBECOM48099.2022.10001602},
  ISSN={},
  month={Dec},}@ARTICLE{10192547,
  author={Zhou, Jun and Kondo, Masaaki},
  journal={IEEE Transactions on Emerging Topics in Computing}, 
  title={An Edge-Cloud Collaboration Framework for Graph Processing in Smart Society}, 
  year={2023},
  volume={11},
  number={4},
  pages={985-1001},
  abstract={Due to the limitations of cloud computing on latency, bandwidth and data confidentiality, edge computing has emerged as a novel location-aware way to provide the capacity-constrained portable terminals with more processing capacity to improve the computing performance and quality of service (QoS) in several typical domains of the human activity in smart society, such as social networks, medical diagnosis, telecommunications, recommendation systems, internal threat detection, transportation, Internet of Things (IoT), etc. These application domains often manage a vast collection of entities with various relationships, which can be naturally represented by the graph data structure. Graph processing is a powerful tool to model and optimize complex problems where graph-based data is involved. In consideration of the relatively insufficient resource provisioning of the edge devices, in this article, for the first time to our knowledge, we propose a reliable edge-cloud collaboration framework that facilitates the graph primitives based on a lightweight interactive graph processing library (GPL), especially for shortest path search (SPS) operations as the demonstrative example. Two types of different practical cases are also presented to show the typical application scenarios of our graph processing strategy. Experimental evaluations indicate that the acceleration rate of performance can reach 6.87x via graph reduction, and less than 3% and 20% extra latency is required for much better user experiences for navigation and pandemic control, respectively, while the online security measures merely consume about 1% extra time of the overall data transmission. Our framework can efficiently execute the applications with considering of user-friendliness, low-latency response, interactions among edge devices, collaboration between edge and cloud, and privacy protection at an acceptable overhead.},
  keywords={},
  doi={10.1109/TETC.2023.3297066},
  ISSN={2168-6750},
  month={Oct},}
