@InProceedings{Luo2018,
  author    = {Luo, Ning and Zhao, Jun},
  booktitle = {Proceedings of the 2nd International Conference on Computer Science and Application Engineering},
  title     = {Storage System Based on Norm and BPMN Mapping Research on Business Process Modeling},
  year      = {2018},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {CSAE '18},
  abstract  = {Aiming1 at the problems of large variety of goods, large quantities of materials, and non-standard procurement and transportation in warehousing enterprises, a modeling method based on the specification and BPMN2.0 mapping was proposed. Through the analysis of the actual warehousing business process management, the service-oriented system modeling based on the warehouse management requirements, the study of the warehousing management system architecture based on the specification, the implementation of the warehousing system specification to BPMN mapping, a better implementation the purpose of warehousing service flexibility.},
  articleno = {163},
  doi       = {10.1145/3207677.3277935},
  isbn      = {9781450365123},
  keywords  = {business process modeling, flexibility semantic loss, BPMN2, Norm},
  location  = {Hohhot, China},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3207677.3277935},
}

@InProceedings{Voegele2014,
  author    = {V\"{o}gele, Christian and Brunnert, Andreas and Danciu, Alexandru and Tertilt, Daniel and Krcmar, Helmut},
  booktitle = {Proceedings of the Third International Workshop on Large Scale Testing},
  title     = {Using Performance Models to Support Load Testing in a Large SOA Environment},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {5–6},
  publisher = {Association for Computing Machinery},
  series    = {LT '14},
  abstract  = {Load testing in large service-oriented architecture (SOA) environments is especially challenging when services are under the control of different teams. It gets even more difficult if services need to be scaled before a load test starts. It is thus important to estimate workloads for services involved in a load test. Service workloads can be specified by the amount of service operation invocations distributed over time. We propose the use of performance models to derive this information for SOA-based applications before executing load tests. In a first step, we use these models to select usage scenarios. Afterwards, these models are transformed in a way that each scenario can be simulated separately from each other. These simulations can predict service workloads for selected usage scenarios and different user counts.},
  doi       = {10.1145/2577036.2577038},
  isbn      = {9781450327626},
  keywords  = {performance models, service workload, usage scenario, service-oriented architecture, load testing},
  location  = {Dublin, Ireland},
  numpages  = {2},
  url       = {https://doi.org/10.1145/2577036.2577038},
}

@InProceedings{Chondrogiannis2016,
  author    = {Chondrogiannis, Theodoros and Gamper, Johann and Cavaliere, Roberto and Ohnewein, Patrick},
  booktitle = {Proceedings of the 24th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems},
  title     = {MoTrIS: A Framework for Route Planning on Multimodal Transportation Networks},
  year      = {2016},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {SIGSPACIAL '16},
  abstract  = {In this paper, we present MoTrIS, a service-oriented framework which enables spatio-temporal query processing on multimodal networks that are composed of a road network and one or more schedule-based transportation networks. MoTrIS provides a remote access API, which allows for the development of applications that require the processing of routing queries on multimodal networks. We discuss the architecture of MoTrIS and we elaborate on each of its individual components. The data input module allows for the import of data from various sources into a spatial-enabled relational database. The network module builds a multimodal network by combining a road network with one or more transportation networks. The timetable module stores and queries the schedule for each transportation mode. The query processing module enables the execution of queries over the multimodal network. The visualization module exports the results into a visualizable format. Finally, we present a web application which allows users to create, modify and test advanced spatio-temporal services, and we demonstrate all the necessary steps for a user to build such a new service.},
  articleno = {82},
  doi       = {10.1145/2996913.2997007},
  isbn      = {9781450345897},
  keywords  = {multimodal networks, route planning, query services},
  location  = {Burlingame, California},
  numpages  = {4},
  url       = {https://doi.org/10.1145/2996913.2997007},
}

@InProceedings{AmorimSilva2018,
  author    = {de Amorim Silva, Rafael and Braga, Rosana T. V.},
  booktitle = {Proceedings of the 12th European Conference on Software Architecture: Companion Proceedings},
  title     = {An Acknowledged System of Systems for Educational Internet of Everything Ecosystems},
  year      = {2018},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ECSA '18},
  abstract  = {Internet of Everything (IoE) is the next evolutionary step of Internet of Things (IoT). This paradigm evolves IoT by transforming it into an accessed, monitored and controlled global pervasive network for all the Internet. The IoE network must integrate embedded devices, people, processes and data in order to provide relevant information for various application areas such as medical, industry, aerospace, agrobusiness, automation, education, among others. In this paper, we propose an acknowledged System of Systems (SoS) to integrate IoE ecosystems that operate into educational environments. This SoS implements a service-oriented architecture to provide services as interfaces between constituent systems (CS). A CS is mediated by a negotiator agent that can be requested by the SoS coordinator agent to identify the availability of specific resources demanded by other CS. This coordinator agent is responsible for recommending the CS with the best available resource for the requester CS and providing information about how access it. All the IoE components also may be mediated by intelligent agents thus increasing the robustness of an IoE ecosystem.},
  articleno = {25},
  doi       = {10.1145/3241403.3241430},
  isbn      = {9781450364836},
  keywords  = {multi-agent systems, internet of everything, cyber-physical ecosystems, system of systems, service-oriented architecture},
  location  = {Madrid, Spain},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3241403.3241430},
}

@InProceedings{Dash2014,
  author    = {Dash, Shefali S. and Sethi, I. P. S. and Maurya, Ashutosh P.},
  booktitle = {Proceedings of the 8th International Conference on Theory and Practice of Electronic Governance},
  title     = {Government Initiative for Automation of Co-Operative Banks Structure through Core Banking Solution},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {478–479},
  publisher = {Association for Computing Machinery},
  series    = {ICEGOV '14},
  abstract  = {National Informatics Centre (NIC) has developed a core banking software with name Co-operative Core Banking Solution (CCBS), considering requirement of Indian co-operative banking sector. Along with software development, NIC also provide implementation and hosting service of this software for co-operative sector under Software as a Service Model. Due to latest Service Oriented Architecture of software, NIC-CCBS is able to integrate other central / state government software/applications and can generate meaningful MIS for decision / policy making for management level. This can also provide a good platform for other e-governance projects by establishing network connectivity, computer awareness and capacity building.NIC-CCBS is implemented at more than 100 co-operative bank locations across two states of India i.e. Chhattisgarh \&amp; Meghalaya and serving more than 20000 banking transactions on daily basis. NIC -- CCBS implementation has been implemented in step wise process which includes Business understanding, Process engineering, Data digitization, Data quality, Data Migration, hands hold support. On completion of CCBS application for State Co-operative Bank, District Central Co-operative Bank, Primary Agriculture Co-operative societies, NIC is moving ahead to serve to Agricultural Land Development Banks, Treasury Banks and State financial corporations.},
  doi       = {10.1145/2691195.2691236},
  isbn      = {9781605586113},
  keywords  = {cooperative, change process, banking solution, software, implementation},
  location  = {Guimaraes, Portugal},
  numpages  = {2},
  url       = {https://doi.org/10.1145/2691195.2691236},
}

@InProceedings{Lyons2015,
  author    = {Lyons, Kelly and Oh, Christie},
  booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
  title     = {SOA4DM: Applying an SOA Paradigm to Coordination in Humanitarian Disaster Response},
  year      = {2015},
  address   = {Florence, Italy},
  pages     = {519–522},
  publisher = {IEEE Press},
  series    = {ICSE '15},
  abstract  = {Despite efforts to achieve a sustainable state of control over the management of global crises, disasters are occurring with greater frequency, intensity, and affecting many more people than ever before while the resources to deal with them do not grow apace. As we enter 2015, with continued concerns that mega-crises may become the new normal, we need to develop novel methods to improve the efficiency and effectiveness of our management of disasters. Software engineering as a discipline has long had an impact on society beyond its role in the development of software systems. In fact, software engineers have been described as the developers of prototypes for future knowledge workers; tools such as Github and Stack Overflow have demonstrated applications beyond the domain of software engineering. In this paper, we take the potential influence of software engineering one-step further and propose using the software service engineering paradigm as a new approach to managing disasters. Specifically, we show how the underlying principles of service-oriented architectures (SOA) can be applied to the coordination of disaster response operations. We describe key challenges in coordinating disaster response and discuss how an SOA approach can address those challenges.},
  keywords  = {SOA, disaster response},
  numpages  = {4},
}

@InProceedings{Aue2018,
  author    = {Au\'{e}, Joop and Aniche, Maur\'{\i}cio and Lobbezoo, Maikel and van Deursen, Arie},
  booktitle = {Proceedings of the 40th International Conference on Software Engineering: Software Engineering in Practice},
  title     = {An Exploratory Study on Faults in Web API Integration in a Large-Scale Payment Company},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {13–22},
  publisher = {Association for Computing Machinery},
  series    = {ICSE-SEIP '18},
  abstract  = {Service-oriented architectures are more popular than ever, and increasingly companies and organizations depend on services offered through Web APIs. The capabilities and complexity of Web APIs differ from service to service, and therefore the impact of API errors varies. API problem cases related to Adyen's payment service were found to have direct considerable impact on API consumer applications. With more than 60,000 daily API errors, the potential impact is enormous. In an effort to reduce the impact of API related problems, we analyze 2.43 million API error responses to identify the underlying faults. We quantify the occurrence of faults in terms of the frequency and impacted API consumers. We also challenge our quantitative results by means of a survey with 40 API consumers. Our results show that 1) faults in API integration can be grouped into 11 general causes: invalid user input, missing user input, expired request data, invalid request data, missing request data, insufficient permissions, double processing, configuration, missing server data, internal and third party, 2) most faults can be attributed to the invalid or missing request data, and most API consumers seem to be impacted by faults caused by invalid request data and third party integration; and 3) insufficient guidance on certain aspects of the integration and on how to recover from errors is an important challenge to developers.},
  doi       = {10.1145/3183519.3183537},
  isbn      = {9781450356596},
  keywords  = {web engineering, web API integration, webservices},
  location  = {Gothenburg, Sweden},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3183519.3183537},
}

@InProceedings{Bause2017,
  author    = {Bause, Falko and Buchholz, Peter and May, Johannes},
  booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering},
  title     = {A Tool Supporting the Analytical Evaluation of Service Level Agreements},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {233–244},
  publisher = {Association for Computing Machinery},
  series    = {ICPE '17},
  abstract  = {Quantitative aspects of modern IT systems are often specified by service level agreements (SLAs) which relate the maximal load of a system with guaranteed bounds for response times and delays. These quantities are specified for single services which are combined in a service oriented architecture (SOA) to composed services offered to potential users or other service providers. To derive SLAs for composed services and to plan the required capacity to guarantee SLAs, appropriate methods and tools have to be used that compute results based on information given in SLAs. In this paper it is argued that most available approaches are not sufficient to analyze systems based on SLA information. A new method and a tool are presented that support the efficient calculation of bounds for delays in composed systems based on bounds for the load and the delay of the individual components which are specified in the SLAs of the components. Furthermore, the presented tool can be used to generate bounds for the required processing capacity which a provider has to provide in order to guarantee the quality of service defined in the SLAs.The presented approach is in some sense a counterpart to mean value analysis for queueing networks but rather than mean values, worst case bounds for different quantities like response times or departure processes are computed. Analysis is based on min/+ algebra but the mathematical approach is hidden from the user by a graphical interface allowing a simple graphical specification and result representation for networks of composed services.},
  doi       = {10.1145/3030207.3030215},
  isbn      = {9781450344043},
  keywords  = {analytical evaluation, performance modeling tools, service level agreements},
  location  = {L'Aquila, Italy},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3030207.3030215},
}

@InProceedings{Nemeth2015,
  author    = {N\'{e}meth, Botty\'{a}n},
  booktitle = {Proceedings of the 9th ACM Conference on Recommender Systems},
  title     = {Scaling Up Recommendation Services in Many Dimensions},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {233},
  publisher = {Association for Computing Machinery},
  series    = {RecSys '15},
  abstract  = {Gravity R&amp;D has been providing recommendation engines as SaaS solutions since 2009. The company has a strong research focus and recommendation quality has always been their primary differentiating factor. Widely used or open source recommendation algorithms are of little use to our technology team as a result of the superiority of our in-house developed, proprietary algorithms. Gravity R&amp;D experienced many challenges while scaling up their services. The sheer quantity of data handled on a daily basis increased exponentially. This presentation will cover how overcoming these challenges permanently shaped our algorithms and system architecture used to generate these recommendations. Serving personalized recommendations requires real-time computation and data access for every single request. To generate responses in real-time, current user inputs have to be compared against their history in order to deliver accurate recommendations. We then combine this user information with specific details about available items as the next step in the recommendation process. It becomes more difficult to provide accurate recommendations as the number of transactions and items increase. It also becomes difficult because this type of analysis requires the combination of multiple heterogeneous algorithms that all require different inputs. Initially, the architecture was designed for MF based models and serving huge numbers of requests but with a limited number of items. Now, Gravity is using MF, neighborhood based models and metadata based models to generate recommendations for millions of items within their databases. This required a shift from a monolithic architecture with in-process caching to a more service oriented architecture with multi-layer caching. As a result of an increase in the number of components and number of clients, managing the infrastructure can be quite difficult. Even with these challenges, we don't believe that it is worthwhile to use a fully distributed system. It adds unneeded complexity, resources, and overhead to the system. We prefer an approach of firstly optimizing current algorithms and architecture and only moving to a distributed system when no other options are left.},
  doi       = {10.1145/2792838.2799499},
  isbn      = {9781450336925},
  keywords  = {scalability, performance, recommendation engine},
  location  = {Vienna, Austria},
  numpages  = {1},
  url       = {https://doi.org/10.1145/2792838.2799499},
}

@InProceedings{Wei2021a,
  author    = {Wei, Yuyang and Yu, Yijun and Pan, Minxue and Zhang, Tian},
  booktitle = {Proceedings of the 12th Asia-Pacific Symposium on Internetware},
  title     = {A Feature Table Approach to Decomposing Monolithic Applications into Microservices},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {21–30},
  publisher = {Association for Computing Machinery},
  series    = {Internetware '20},
  abstract  = {Microservice architecture refers to the use of numerous small-scale and independently deployed services, instead of encapsulating all functions into one monolith. It has been a challenge in software engineering to decompose a monolithic system into smaller parts. In this paper, we propose the Feature Table approach, a structured approach to service decomposition based on the correlation between functional features and microservices: (1) we defined the concept of Feature Cards and 12 instances of such cards; (2) we formulated Decomposition Rules to decompose monolithic applications; (3) we designed the Feature Table Analysis Tool to provide semi-automatic analysis for identification of microservices; and (4) we formulated Mapping Rules to help developers implement microservice candidates. We performed a case study on Cargo Tracking System to validate our microservice-oriented decomposition approach. Cargo Tracking System is a typical case that has been decomposed by other related methods (dataflow-driven approach, Service Cutter, and API Analysis). Through comparison with the related methods in terms of specific coupling and cohesion metrics, the results show that the proposed Feature Table approach can deliver more reasonable microservice candidates, which are feasible in implementation with semi-automatic support.},
  doi       = {10.1145/3457913.3457939},
  isbn      = {9781450388191},
  keywords  = {monolith decomposition, Microservices, microservice architecture},
  location  = {Singapore, Singapore},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3457913.3457939},
}

@Article{Laigner2021,
  author     = {Laigner, Rodrigo and Zhou, Yongluan and Salles, Marcos Antonio Vaz and Liu, Yijian and Kalinowski, Marcos},
  journal    = {Proc. VLDB Endow.},
  title      = {Data Management in Microservices: State of the Practice, Challenges, and Research Directions},
  year       = {2021},
  issn       = {2150-8097},
  month      = {sep},
  number     = {13},
  pages      = {3348–3361},
  volume     = {14},
  abstract   = {Microservices have become a popular architectural style for data-driven applications, given their ability to functionally decompose an application into small and autonomous services to achieve scalability, strong isolation, and specialization of database systems to the workloads and data formats of each service. Despite the accelerating industrial adoption of this architectural style, an investigation of the state of the practice and challenges practitioners face regarding data management in microservices is lacking. To bridge this gap, we conducted a systematic literature review of representative articles reporting the adoption of microservices, we analyzed a set of popular open-source microservice applications, and we conducted an online survey to cross-validate the findings of the previous steps with the perceptions and experiences of over 120 experienced practitioners and researchers.Through this process, we were able to categorize the state of practice of data management in microservices and observe several foundational challenges that cannot be solved by software engineering practices alone, but rather require system-level support to alleviate the burden imposed on practitioners. We discuss the shortcomings of state-of-the-art database systems regarding microservices and we conclude by devising a set of features for microservice-oriented database systems.},
  doi        = {10.14778/3484224.3484232},
  issue_date = {September 2021},
  numpages   = {14},
  publisher  = {VLDB Endowment},
  url        = {https://doi.org/10.14778/3484224.3484232},
}

@InProceedings{Yuan2019,
  author    = {Yuan, Eric},
  booktitle = {Proceedings of the 2nd International Workshop on Establishing a Community-Wide Infrastructure for Architecture-Based Software Engineering},
  title     = {Architecture Interoperability and Repeatability with Microservices: An Industry Perspective},
  year      = {2019},
  address   = {Montreal, Quebec, Canada},
  pages     = {26–33},
  publisher = {IEEE Press},
  series    = {ECASE '19},
  abstract  = {Microservices, along with supporting technologies such as containers, have become a prevalent architecture approach for today's software systems, especially in enterprise environments. They represent the latest evolutionary step in the decades-old journey towards service- and component-based software architectures. Along with virtualization technologies, microservices have enabled the loose-coupling of both service interfaces (message passing) and service integration (form and fit). This paper attempts to explore the impact of microservices on software architecture interoperability and repeatability, based on our experiences in developing two microservice-based systems. Our central thesis is that, if we view software architecture as a set of principal design decisions, the microservices approach enable us to more elegantly separate these decisions from non-architectural, domain-specific ones, and thus make these decisions more interoperable, reusable, and repeatable across disparate problem domains. We therefore propose that a microservices based reference architecture (RA) and reference implementation (RI) be created for the community-wide infrastructure for software engineering and software architecture research, along with a set of detailed considerations.},
  doi       = {10.1109/ECASE.2019.00013},
  keywords  = {software architecture, DevOps, microservice, cloud computing},
  numpages  = {8},
  url       = {https://doi.org/10.1109/ECASE.2019.00013},
}

@InProceedings{Das2021,
  author    = {Das, Prangshuman and Laigner, Rodrigo and Zhou, Yongluan},
  booktitle = {Proceedings of the 15th ACM International Conference on Distributed and Event-Based Systems},
  title     = {HawkEDA: A Tool for Quantifying Data Integrity Violations in Event-Driven Microservices},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {176–179},
  publisher = {Association for Computing Machinery},
  series    = {DEBS '21},
  abstract  = {A microservice architecture advocates for subdividing an application into small and independent components, each communicating via well-defined APIs or asynchronous events, to allow for higher scalability, availability, and fault isolation. However, the implementation of substantial amount of data management logic at the application-tier and the existence of functional dependencies cutting across microservices create a great barrier for developers to reason about application safety and performance trade-offs.To fill this gap, this work presents HawkEDA, the first data management tool that allows practitioners to experiment their microservice applications with different real-world workloads to quantify the amount of data integrity anomalies. In our demonstration, we present a case study of a popular open-source event-driven microservice to showcase the interface through which developers specify application semantics and the flexibility of HawkEDA.},
  doi       = {10.1145/3465480.3467838},
  isbn      = {9781450385558},
  keywords  = {microservice, event-driven architecture, data integrity},
  location  = {Virtual Event, Italy},
  numpages  = {4},
  url       = {https://doi.org/10.1145/3465480.3467838},
}

@InProceedings{Santos2019,
  author    = {Santos, Nuno and Salgado, Carlos E. and Morais, Francisco and Melo, M\'{o}nica and Silva, Sara and Martins, Raquel and Pereira, Marco and Rodrigues, Helena and Machado, Ricardo J. and Ferreira, Nuno and Pereira, Manuel},
  booktitle = {Proceedings of the 13th European Conference on Software Architecture - Volume 2},
  title     = {A Logical Architecture Design Method for Microservices Architectures},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {145–151},
  publisher = {Association for Computing Machinery},
  series    = {ECSA '19},
  abstract  = {The use of microservices architectures has been widely adopted in software development, especially for cloud-based solutions. Developing such solutions faces several challenges beyond typical architecture and service design concerns, including service exposition (API), inter-service communication, and infrastructure deployment, among others. Although model-driven approaches allow abstracting microservices behavior from the business domain, there is a lack of proper methods for addressing the referred challenges. In this paper, the elicitation of microservices, their identification uses using functionally decomposed UML use cases as input within a logical architecture derivation method, namely an adapted version of the Four Step Rule Set (4SRS), using SoaML diagrams, that responds to microservices specific characteristics. We demonstrate the approach using a scenario within a live industrial project.},
  doi       = {10.1145/3344948.3344991},
  isbn      = {9781450371421},
  keywords  = {logical architectures, service participants, decomposition, SoaML, UML, microservices},
  location  = {Paris, France},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3344948.3344991},
}

@InProceedings{Aderaldo2017,
  author    = {Aderaldo, Carlos M. and Mendon\c{c}a, Nabor C. and Pahl, Claus and Jamshidi, Pooyan},
  booktitle = {Proceedings of the 1st International Workshop on Establishing the Community-Wide Infrastructure for Architecture-Based Software Engineering},
  title     = {Benchmark Requirements for Microservices Architecture Research},
  year      = {2017},
  address   = {Buenos Aires, Argentina},
  pages     = {8–13},
  publisher = {IEEE Press},
  series    = {ECASE '17},
  abstract  = {Microservices have recently emerged as a new architectural style in which distributed applications are broken up into small independently deployable services, each running in its own process and communicating via lightweight mechanisms. However, there is still a lack of repeatable empirical research on the design, development and evaluation of microservices applications. As a first step towards filling this gap, this paper proposes, discusses and illustrates the use of an initial set of requirements that may be useful in selecting a community-owned architecture benchmark to support repeatable microservices research.},
  isbn      = {9781538604175},
  keywords  = {software architecture, microservices, research benchmark},
  numpages  = {6},
}

@InProceedings{Avritzer2020a,
  author    = {Avritzer, Alberto},
  booktitle = {Companion of the ACM/SPEC International Conference on Performance Engineering},
  title     = {Automated Scalability Assessment in DevOps Environments},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {10},
  publisher = {Association for Computing Machinery},
  series    = {ICPE '20},
  abstract  = {In this extended abstract, we provide an outline of the presentation planned for WOSP-C 2020. The goal of the presentation is to provide an overview of the challenges and approaches for automated scalability assessment in the context of DevOps and microservices. The focus of this presentation is on approaches that employ automated identification of performance problems because these approaches can leverage performance anti-pattern[5] detection technology. In addition, we envision extending the approach to recommend component refactoring. In our previous work[1,2] we have designed a methodology and associated tool support for the automated scalability assessment of micro-service architectures, which included the automation of all the steps required for scalability assessment. The presentation starts with an introduction to dependability, operational Profile Data, and DevOps. Specifically, we provide an overview of the state of the art in continuous performance monitoring technologies[4] that are used for obtaining operational profile data using APM tools. We then present an overview of selected approaches for production and performance testing based on the application monitoring tool (PPTAM) as introduced in [1,2]. The presentation concludes by outlining a vision for automated performance anti-pattern[5] detection. Specifically, we present the approach introduced for automated anti-pattern detection based on load testing results and profiling introduced in[6] and provide recommendations for future research.},
  doi       = {10.1145/3375555.3384936},
  isbn      = {9781450371094},
  location  = {Edmonton AB, Canada},
  numpages  = {1},
  url       = {https://doi.org/10.1145/3375555.3384936},
}

@InProceedings{Spillner2019,
  author    = {Spillner, Josef},
  booktitle = {Proceedings of the 12th IEEE/ACM International Conference on Utility and Cloud Computing Companion},
  title     = {Serverless Computing and Cloud Function-Based Applications},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {177–178},
  publisher = {Association for Computing Machinery},
  series    = {UCC '19 Companion},
  abstract  = {Serverless computing is a growing industry trend with corresponding rise in interest by scholars and tinkerers. Increasingly, open source and academic system prototypes are being proposed especially in relation with cloud, edge and fog computing among other distributed computing specialisations. Due to the strict separation between elastically scalable stateless microservices bound to stateful backend services prevalent in this computing paradigm, the resulting applications are inherently distributed with favourable characteristics such as elastic scalability and disposability. Still, software application developers are confronted with a multitude of different methods and tools to build, test and deploy their function-based applications in today's serverless ecosystems. The logical next step is therefore a methodical development approach with key enablers based on a classification of languages, tools, systems, system behaviours, patterns, pitfalls, application architectures, compositions and cloud services around the serverless application development process.},
  doi       = {10.1145/3368235.3370269},
  isbn      = {9781450370448},
  keywords  = {tutorial, artefact quality, serverless computing, cloud functions},
  location  = {Auckland, New Zealand},
  numpages  = {2},
  url       = {https://doi.org/10.1145/3368235.3370269},
}

@InProceedings{Nguyen2020,
  author    = {Nguyen, Hoai Viet and Lo Iacono, Luigi},
  booktitle = {Proceedings of the Tenth ACM Conference on Data and Application Security and Privacy},
  title     = {CREHMA: Cache-Aware REST-Ful HTTP Message Authentication},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {49–60},
  publisher = {Association for Computing Machinery},
  series    = {CODASPY '20},
  abstract  = {Scalability and security are two important elements of contemporary distributed software systems. The Web vividly shows that while complying with the constraints defined by the architectural style REST, the layered design of software with intermediate systems enables to scale at large. Intermediaries such as caches, however, interfere with the security guarantees of the industry standard for protecting data in transit on the Web, TLS, as in these circumstances the TLS channel already terminates at the intermediate system's server. For more in-depth defense strategies, service providers require message-oriented security means in addition to TLS. These are hardly available and only in the form of HTTP signature schemes that do not take caches into account either. In this paper we introduce CREHMA, a REST-ful HTTP message signature scheme that guarantees the integrity and authenticity of Web assets from end-to-end while simultaneous allowing service providers to enjoy the benefits of Web caches. Decisively, CREHMA achieves these guarantees without having to trust on the integrity of the cache and without requiring making changes to existing Web caching systems. In extensive experiments we evaluated CREHMA and found that it only introduces marginal impacts on metrics such as latency and data expansion while providing integrity protection from end to end. CREHMA thus extends the possibilities of service providers to achieve an appropriate balance between scalability and security.},
  doi       = {10.1145/3374664.3375750},
  isbn      = {9781450371070},
  keywords  = {rest, web caching, http, end-to-end security, signature},
  location  = {New Orleans, LA, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3374664.3375750},
}

@InProceedings{Jiang2021,
  author    = {Jiang, Dongming and Jiang, Yuan and Li, Jinzi},
  booktitle = {Proceedings of the 2020 8th International Conference on Information Technology: IoT and Smart City},
  title     = {A Session-Based Interaction Model for Cloud Service},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {25–28},
  publisher = {Association for Computing Machinery},
  series    = {ICIT '20},
  abstract  = {Being executed in the Internet space, cloud services provide elastic computing resource to satisfy customers’ demand. Since single service usually can't suit their complex need, customers need to assemble multiple services into one service workflow which coordinates individual service to fulfill the specific task by means of service interaction. Obviously, the interaction mechanism of cloud service is the glue of workflow and plays an important role in service workflow. However, owing to the dynamic characteristic of the Internet, cloud service interaction is complicated and volatile. Hence, the question how to describe and formalize the complex interaction of cloud service workflow is a non-trivial work, which has directly influence on the overall design of cloud service architecture engineering and its performance.Consider the question above, this article put forward a session-based interaction model of cloud service. Regarding the complexity of service workflow, this paper applies the divide-and-conquer strategy to decompose the interaction of cloud services into session, then constructs the interaction model of cloud service. In the first step, we introduce and formalize the notion of session, so the complex interaction of cloud service workflow can be decomposed into hierarchical session pattern, which is easy to formalize by the guard automata. Next, using the session as the abstract data type, the session-based interaction model is proposed in order to facilitate the formalization of cloud service workflow. In addition, the model incorporates the notion of role and business protocol to strength the model flexibility. Like the role of object in object-oriented programming language, this model provides a new perspective for modelling the cloud service workflow and lay the solid foundation for its formal verification.},
  doi       = {10.1145/3446999.3447004},
  isbn      = {9781450388559},
  keywords  = {role, interface, session, service workflow, cloud service},
  location  = {Xi'an, China},
  numpages  = {4},
  url       = {https://doi.org/10.1145/3446999.3447004},
}

@InProceedings{Inci2017,
  author    = {Inci, Mehmet Sinan and Eisenbarth, Thomas and Sunar, Berk},
  booktitle = {Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security},
  title     = {Hit by the Bus: QoS Degradation Attack on Android},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {716–727},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '17},
  abstract  = {Mobile apps need optimal performance and responsiveness to rise amongst numerous rivals on the market. Further, some apps like media streaming or gaming apps cannot even function properly with a performance below a certain threshold. In this work, we present the first performance degradation attack on Android OS that can target rival apps using a combination of logical channel leakages and low-level architectural bottlenecks in the underlying hardware. To show the viability of the attack, we design a proof-of-concept app and test it on various mobile platforms. The attack runs covertly and brings the target to the level of unresponsiveness. With less than 10\% CPU time in the worst case, it requires minimal computational effort to run as a background service, and requires only the UsageStats permission from the user. We quantify the impact of our attack using 11 popular benchmark apps, running 44 different tests. The measured QoS degradation varies across platforms and applications, reaching a maximum of 90\% in some cases. The attack combines the leakage from logical channels with low-level architectural bottlenecks to design a malicious app that can covertly degrade Quality of Service (QoS) of any targeted app. Furthermore, our attack code has a small footprint and is not detected by the Android system as malicious. Finally, our app can pass the Google Play Store malware scanner, Google Bouncer, as well as the top malware scanners in the Play Store.},
  doi       = {10.1145/3052973.3053028},
  isbn      = {9781450349444},
  keywords  = {performance degradation, mobile security, mobile malware, QoS attack},
  location  = {Abu Dhabi, United Arab Emirates},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3052973.3053028},
}

@InProceedings{Liang2020,
  author    = {Liang, Yilei and O'Keeffe, Dan and Sastry, Nishanth},
  booktitle = {Proceedings of the Third ACM International Workshop on Edge Systems, Analytics and Networking},
  title     = {PAIGE: Towards a Hybrid-Edge Design for Privacy-Preserving Intelligent Personal Assistants},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {55–60},
  publisher = {Association for Computing Machinery},
  series    = {EdgeSys '20},
  abstract  = {Intelligent Personal Assistants (IPAs) such as Apple's Siri, Google Now, and Amazon Alexa are becoming an increasingly important class of web application. In contrast to previous keyword-oriented search applications, IPAs support a rich query interface that allows user interaction through images, audio, and natural language queries. However, modern IPAs rely heavily on compute-intensive machine-learning inference. To achieve acceptable performance, ML-driven IPAs increasingly depend on specialized hardware accelerators (e.g. GPUs, FPGAs or TPUs), increasing costs for IPA service providers. For end-users, IPAs also present considerable privacy risks given the sensitive nature of the data they capture.We present PAIGE, a hybrid edge-cloud architecture for privacy-preserving Intelligent Personal Assistants. PAIGE's design is founded on the assumption that recent advances in low-cost hardware for machine-learning inference offer an opportunity to offload compute-intensive IPA ML tasks to the network edge. To allow privacy-preserving access to large IPA databases for less compute-intensive pre-processed queries, PAIGE leverages trusted execution environments at the server side. PAIGE's hybrid design allows privacy-preserving hardware acceleration of compute-intensive tasks, while avoiding the need to move potentially large IPA question-answering databases to the edge. As a step towards realising PAIGE, we present a first systematic performance evaluation of existing edge accelerator hardware platforms for a subset of IPA workloads, and show they offer a competitive alternative to existing data-center alternatives.},
  doi       = {10.1145/3378679.3394536},
  isbn      = {9781450371322},
  keywords  = {intelligent personal assistants, edge computing, trusted execution environments},
  location  = {Heraklion, Greece},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3378679.3394536},
}

@InProceedings{Xu2017,
  author    = {Xu, Dawen and Liao, Yi and Wang, Ying and Li, Huawei and Li, Xiaowei},
  booktitle = {Proceedings of the Computing Frontiers Conference},
  title     = {Selective Off-Loading to Memory: Task Partitioning and Mapping for PIM-Enabled Heterogeneous Systems},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {255–258},
  publisher = {Association for Computing Machinery},
  series    = {CF'17},
  abstract  = {Processing-in-Memory (PIM) is returning as a promising solution to address the issue of memory wall as computing systems gradually step into the big data era. Researchers continually proposed various PIM architecture combined with novel memory device or 3D integration technology, but it is still a lack of universal task scheduling method in terms of the new heterogeneous platform. In this paper, we propose a formalized model to quantify the performance and energy of the PIM+CPU heterogeneous parallel system. In addition, we are the first to build a task partitioning and mapping framework to exploit different PIM engines. In this framework, an application is divided into subtasks and mapped onto appropriate execution units based on the proposed PIM-oriented Earliest-Finish-Time (PEFT) algorithm to maximize the performance gains brought by PIM. Experimental evaluations show our PIM-aware framework significantly improves the system performance compared to conventional processor architectures.},
  doi       = {10.1145/3075564.3075584},
  isbn      = {9781450344876},
  keywords  = {Mapping, Architecture, Memory Wall, PIM},
  location  = {Siena, Italy},
  numpages  = {4},
  url       = {https://doi.org/10.1145/3075564.3075584},
}

@InProceedings{Walter2015,
  author    = {Walter, Nadine and Altm\"{u}ller, Tobias and Bengler, Klaus},
  booktitle = {Adjunct Proceedings of the 7th International Conference on Automotive User Interfaces and Interactive Vehicular Applications},
  title     = {Concept of a Reference Architecture for an Extendable In-Vehicle Adaptive Recommendation Service},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {88–93},
  publisher = {Association for Computing Machinery},
  series    = {AutomotiveUI '15},
  abstract  = {An adaptive recommendation service can reduce driver distraction through reducing the amount of operation steps needed to call a function. It learns the routine user behavior of the driver related to a situation and supports the driver with this knowledge by giving proactive recommendations for preconfigured functions. An adaptive recommendation service is a complex system and the development includes several challenges. One is the development of an architecture which needs to be modular, extendible in regard to the support of different functions and integrated in an overall in-vehicle HMI architecture. This architecture describes the components and interfaces of an adaptive recommendation service which need to be researched and developed. It is a starting point for the implementation of realistic prototypes in a real vehicle or driving simulator which enables an extensive evaluation of the whole adaptive recommendation service.},
  doi       = {10.1145/2809730.2809749},
  isbn      = {9781450338585},
  keywords  = {software architecture, prototyping, driver distraction, recommendation system, adaptive system},
  location  = {Nottingham, United Kingdom},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2809730.2809749},
}

@InProceedings{Jia2016,
  author    = {Jia, Yaoqi and Chua, Zheng Leong and Hu, Hong and Chen, Shuo and Saxena, Prateek and Liang, Zhenkai},
  booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {"The Web/Local" Boundary Is Fuzzy: A Security Study of Chrome's Process-Based Sandboxing},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {791–804},
  publisher = {Association for Computing Machinery},
  series    = {CCS '16},
  abstract  = {Process-based isolation, suggested by several research prototypes, is a cornerstone of modern browser security architectures. Google Chrome is the first commercial browser that adopts this architecture. Unlike several research prototypes, Chrome's process-based design does not isolate different web origins, but primarily promises to protect "the local system" from "the web". However, as billions of users now use web-based cloud services (e.g., Dropbox and Google Drive), which are integrated into the local system, the premise that browsers can effectively isolate the web from the local system has become questionable. In this paper, we argue that, if the process-based isolation disregards the same-origin policy as one of its goals, then its promise of maintaining the "web/local system (local)" separation is doubtful. Specifically, we show that existing memory vulnerabilities in Chrome's renderer can be used as a stepping-stone to drop executables/scripts in the local file system, install unwanted applications and misuse system sensors. These attacks are purely data-oriented and do not alter any control flow or import foreign code. Thus, such attacks bypass binary-level protection mechanisms, including ASLR and in-memory partitioning. Finally, we discuss various full defenses and present a possible way to mitigate the attacks presented.},
  doi       = {10.1145/2976749.2978414},
  isbn      = {9781450341394},
  keywords  = {data-oriented attacks, browser design, browser security},
  location  = {Vienna, Austria},
  numpages  = {14},
  url       = {https://doi.org/10.1145/2976749.2978414},
}

@InProceedings{Daroshka2021,
  author    = {Daroshka, Vitali and Evgrafov, Arkady and Nikiforova, Jeanne and Chargazia, Grigory and Parshukov, Aleksey},
  booktitle = {Proceedings of the International Scientific Conference - Digital Transformation on Manufacturing, Infrastructure and Service},
  title     = {The Specific of Business Reputation Value Measurement in Transformational Economy (on Example of Economy of the Republic of Belarus)},
  year      = {2021},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {DTMIS '20},
  abstract  = {Globalization of economy and overcoming of the world economic crisis consequences increases the value of evidence-based suggestions to improve management in domestic industrial organizations. The increase of the competition from foreign business defines the need for justification of the adequate, complete concept of ensuring the stability of industrial enterprises' functioning that combines effective management of tangible and intangible assets. Looking at current trends of the world economic development, it's objectively seen that intangible competitive production components play an increasingly important role to preserve market leadership both for one organization and the entire national economy.Global trends in globalization dictate fundamentally new rules for the formation of the architecture of the business model of an industrial organization, which determine the transition from the production of products and services for the impersonal mass of consumers to the global scale of personalized service for each client. In other words, the current business environment requires the simultaneous realization of two trends that are opposite in nature: the global scale of activity (globalization) and the personal approach to each consumer (customization and personalization of products and services), which makes it necessary to create a system of criteria for assessing the technological transition.The main attention is given to an element of intangible assets that is one of the most difficult for value measurement and management, the business reputation of an organization. According to literature, there is no common opinion among the scientists as to what business reputation means and how it is linked to another subjective intangible asset, goodwill.},
  articleno = {89},
  doi       = {10.1145/3446434.3446523},
  isbn      = {9781450388900},
  keywords  = {transformational economy, risks, Business reputation, value-based management},
  location  = {Saint Petersburg, Russian Federation},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3446434.3446523},
}

@InProceedings{Spacek2014,
  author    = {Spacek, Petr and Dony, Christophe and Tibermacine, Chouki},
  booktitle = {Proceedings of the 17th International ACM Sigsoft Symposium on Component-Based Software Engineering},
  title     = {A Component-Based Meta-Level Architecture and Prototypical Implementation of a Reflective Component-Based Programming and Modeling Language},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {13–22},
  publisher = {Association for Computing Machinery},
  series    = {CBSE '14},
  abstract  = {Component-based Software Engineering studies the design, development and maintenance of software constructed upon sets of connected components. Using existing standard solutions, component-based models are frequently transformed into non-component-based programs, most of the time object-oriented, for run-time execution. As a consequence many component-level descriptions (part of code), e.g. explicit architectures or ports declarations, vanish at the implementation stage, making debugging, transformations or reverse-engineering difficult. It has been shown that component-based programming languages contribute to bridge this gap between design and implementation and to provide a conceptual and practical continuum to fully develop applications with components. In this paper we go one step further in this direction by making a component-oriented programming and modeling language truly reflective, thus making verification, evolution or transformation stages of software development part of this new continuum. The gained reflection capabilities indeed make it possible to perform architecture checking, code refactoring, model transformations or even to implement new languages constructs with and for components. The paper presents an original executable meta-level architecture achieving the vision that "everything is a component" and an operational implementation demonstrating its feasibility and effectiveness. Our system revisits some standard solutions for reification in the component's context and also handles new cases, such as ports reification, to allow for runtime introspection and intercession on components and on their descriptors. We validate these ideas in the context of an executable prototypical and minimal component-based language, named Compo, whose first goal is to help imagining the future.},
  doi       = {10.1145/2602458.2602476},
  isbn      = {9781450325776},
  keywords  = {component, reflection, architecture, programming, transformations, reflexive meta-model, modeling, constraints},
  location  = {Marcq-en-Bareul, France},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2602458.2602476},
}

@InProceedings{Blanc2018,
  author    = {Blanc, Gregory and Kheir, Nizar and Ayed, Dhouha and Lefebvre, Vincent and de Oca, Edgardo Montes and Bisson, Pascal},
  booktitle = {Proceedings of the 13th International Conference on Availability, Reliability and Security},
  title     = {Towards a 5G Security Architecture: Articulating Software-Defined Security and Security as a Service},
  year      = {2018},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ARES '18},
  abstract  = {5G is envisioned as a transformation of the communications architecture towards multi-tenant, scalable and flexible infrastructure, which heavily relies on virtualised network functions and programmable networks. In particular, orchestration will advance one step further in blending both compute and data resources, usually dedicated to virtualisation technologies, and network resources into so-called slices. Although 5G security is being developed in current working groups, slice security is seldom addressed.In this work, we propose to integrate security in the slice life cycle, impacting its management and orchestration that relies on the virtualization/softwarisation infrastructure. The proposed security architecture connects the demands specified by the tenants through as-a-service mechanisms with built-in security functions relying on the ability to combine enforcement and monitoring functions within the software-defined network infrastructure. The architecture exhibits desirable properties such as isolating slices down to the hardware resources or monitoring service-level performance.},
  articleno = {47},
  doi       = {10.1145/3230833.3233251},
  isbn      = {9781450364485},
  keywords  = {Security as a Service, Network Slicing, Software-Defined Security},
  location  = {Hamburg, Germany},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3230833.3233251},
}

@InProceedings{AdjeponYamoah2015,
  author    = {Adjepon-Yamoah, David and Romanovsky, Alexander and Iliasov, Alexei},
  booktitle = {Proceedings of the 2015 International Conference on Software and System Process},
  title     = {A Reactive Architecture for Cloud-Based System Engineering},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {77–81},
  publisher = {Association for Computing Machinery},
  series    = {ICSSP 2015},
  abstract  = {The paper introduces an architecture to support system engineering on the cloud. It employs the main benefits of the cloud: scalability, parallelism, cost-effectiveness, multi-user access and flexibility. The architecture includes an open toolbox which provides tools as a service to support various phases of system engineering. The architecture uses the Open Services for Life-cycle Collaboration (OSLC) technology to create a reactive middleware that informs all stakeholders about any changes in the development artefacts. It facilitates the interoperability of tools and enables the workflow of tools to support complex engineering steps. Another component of the architecture is a shared repository of artefacts. All the artefacts generated during a system engineering process are stored in the repository, and can be accessed by relevant stakeholders. The shared repository also serves as a platform to support a protocol for formal model decomposition and group work on the decomposed models. Finally, the architecture includes components for ensuring the dependability of the system engineering process.},
  doi       = {10.1145/2785592.2785611},
  isbn      = {9781450333467},
  keywords  = {dependability, artefact repository, reactive architecture, cloud computing, system engineering},
  location  = {Tallinn, Estonia},
  numpages  = {5},
  url       = {https://doi.org/10.1145/2785592.2785611},
}

@Article{Fernandes2016,
  author     = {Fernandes, Fernando and Weigel, Lucas and Jung, Claudio and Navaux, Philippe and Carro, Luigi and Rech, Paolo},
  journal    = {ACM Trans. Archit. Code Optim.},
  title      = {Evaluation of Histogram of Oriented Gradients Soft Errors Criticality for Automotive Applications},
  year       = {2016},
  issn       = {1544-3566},
  month      = {nov},
  number     = {4},
  volume     = {13},
  abstract   = {Pedestrian detection reliability is a key problem for autonomous or aided driving, and methods that use Histogram of Oriented Gradients (HOG) are very popular. Embedded Graphics Processing Units (GPUs) are exploited to run HOG in a very efficient manner. Unfortunately, GPUs architecture has been shown to be particularly vulnerable to radiation-induced failures. This article presents an experimental evaluation and analytical study of HOG reliability. We aim at quantifying and qualifying the radiation-induced errors on pedestrian detection applications executed in embedded GPUs.We analyze experimental results obtained executing HOG on embedded GPUs from two different vendors, exposed for about 100 hours to a controlled neutron beam at Los Alamos National Laboratory. We consider the number and position of detected objects as well as precision and recall to discriminate critical erroneous computations. The reported analysis shows that, while being intrinsically resilient (65\% to 85\% of output errors only slightly impact detection), HOG experienced some particularly critical errors that could result in undetected pedestrians or unnecessary vehicle stops.Additionally, we perform a fault-injection campaign to identify HOG critical procedures. We observe that Resize and Normalize are the most sensitive and critical phases, as about 20\% of injections generate an output error that significantly impacts HOG detection. With our insights, we are able to find those limited portions of HOG that, if hardened, are more likely to increase reliability without introducing unnecessary overhead.},
  address    = {New York, NY, USA},
  articleno  = {38},
  doi        = {10.1145/2998573},
  issue_date = {December 2016},
  keywords   = {pedestrian detection, HOG},
  numpages   = {25},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2998573},
}

@InProceedings{Lin2020,
  author    = {Lin, Huang and Diangang, Wang and Xiao, Liu and Yongning, Zhuo and Yong, Zeng},
  booktitle = {Proceedings of the 2020 6th International Conference on Computing and Artificial Intelligence},
  title     = {A Predictor Based on Parallel LSTM for Burst Network Traffic Flow},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {476–480},
  publisher = {Association for Computing Machinery},
  series    = {ICCAI '20},
  abstract  = {The network traffic prediction is a key step for service quality control in computer network. Aimed at the problem that the performance of the traditional prediction method significantly degrades for the burst short-term flow, this paper proposed a double LSTM architecture, one of which acts as the main flow predictor, another as the detector for the moment the burst flow starts. The two LSTM unit can exchange their internal state's information, and the predictor uses the detector's information to improve the accuracy of the prediction. To train the offline double LSTM architecture, a Depth-Backstep algorithm is put forward. To use the architecture to perform the online prediction, a pulse series is used as a simulant of the burst event. A simulation experiment is designed to test performance of the predictor. The results of the experiment show that the prediction accuracy of the double LSTM architecture is significantly improved, compared with the traditional single LSTM architecture.},
  doi       = {10.1145/3404555.3404632},
  isbn      = {9781450377089},
  keywords  = {computer network, Traffic prediction, machine learning, LSTM},
  location  = {Tianjin, China},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3404555.3404632},
}

@InProceedings{Salama2015,
  author    = {Salama, Maria},
  booktitle = {Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering},
  title     = {Stability of Self-Adaptive Software Architectures},
  year      = {2015},
  address   = {Lincoln, Nebraska},
  pages     = {886–889},
  publisher = {IEEE Press},
  series    = {ASE '15},
  abstract  = {Stakeholders and organisations are increasingly looking for long-lived software. As architectures have a profound effect on the operational life-time of the software and the quality of the service provision, architectural stability could be considered a primary criterion towards achieving the long-livety of the software. Architectural stability is envisioned as the next step in quality attributes, combining many inter-related qualities. This research suggests the notion of behavioural stability as a primary criterion for evaluating whether the architecture maintains achieving the expected quality attributes, maintaining architecture robustness, and evaluating how well the architecture accommodates run-time evolutionary changes. The research investigates the notion of architecture stability at run-time in the context of self-adaptive software architectures. We expect to define, characterise and analyse this intuitive concept, as well as identify the consequent trade-offs to be dynamically managed and enhance the self-adaptation process for a long-lived software.},
  doi       = {10.1109/ASE.2015.93},
  isbn      = {9781509000241},
  numpages  = {4},
  url       = {https://doi.org/10.1109/ASE.2015.93},
}

@InProceedings{Zhai2014,
  author    = {Zhai, Ennan and Chen, Ruichuan and Wolinsky, David Isaac and Ford, Bryan},
  booktitle = {Proceedings of the 11th USENIX Conference on Operating Systems Design and Implementation},
  title     = {Heading off Correlated Failures through Independence-as-a-Service},
  year      = {2014},
  address   = {USA},
  pages     = {317–334},
  publisher = {USENIX Association},
  series    = {OSDI'14},
  abstract  = {Today's systems pervasively rely on redundancy to ensure reliability. In complex multi-layered hardware/software stacks, however - especially in the clouds where many independent businesses deploy interacting services on common infrastructure - seemingly independent systems may share deep, hidden dependencies, undermining redundancy efforts and introducing unanticipated correlated failures. Complementing existing post-failure forensics, we propose Independence-as-a-Service (or INDaaS), an architecture to audit the independence of redundant systems proactively, thus avoiding correlated failures. INDaaS first utilizes pluggable dependency acquisition modules to collect the structural dependency information (including network, hardware, and software dependencies) from a variety of sources. With this information, INDaaS then quantifies the independence of systems of interest using pluggable auditing modules, offering various performance, precision, and data secrecy tradeoffs. While the most general and efficient auditing modules assume the auditor is able to obtain all required information, INDaaS can employ private set intersection cardinality protocols to quantify the independence even across businesses unwilling to share their full structural information with anyone. We evaluate the practicality of INDaaS with three case studies via auditing realistic network, hardware, and software dependency structures.},
  isbn      = {9781931971164},
  location  = {Broomfield, CO},
  numpages  = {18},
}

@InProceedings{Muthuraman2016,
  author    = {Muthuraman, Sangeetha and Venkatesan, V. Prasanna},
  booktitle = {Proceedings of the International Conference on Informatics and Analytics},
  title     = {Design of QOS Based Web Service Selection/Composition Hyper-Heuristic Model},
  year      = {2016},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ICIA-16},
  abstract  = {A web service selection/composition problem is a NP-complete problem that cannot be solved in polynomial time. An efficient solution is essential to solve this problem. This solution may be attained by following hyper-heuristic strategies. As a first step in addressing the problem, this paper presents a new web services selection/composition model which enables such a hyper-heuristic notion. Various parts of this proposed model can be implemented by using different algorithms thus enabling many hybrid implementations. In this paper the proposed model has been implemented by using a reference score and trust based service selection algorithm and a strategic tree based service composition algorithm. To realize this implementation agent based architecture has been proposed. A well defined QOS model has been used to accurately receive customer's request and update service specific quality values. The algorithms implemented are efficient as the computational complexities of these algorithms have been greatly reduced and also a fault tolerant approach has been adopted. The experimental results illustrate that the proposed model and algorithms have effectively solved the web services selection/composition problem.},
  articleno = {80},
  doi       = {10.1145/2980258.2980430},
  isbn      = {9781450347563},
  keywords  = {service composition, QOS based web service selection and composition, web services selection/composition model, Service selection, hyper-heuristic model},
  location  = {Pondicherry, India},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2980258.2980430},
}

@InProceedings{Poulo2014,
  author    = {Poulo, Lebeko and Phiri, Lighton and Suleman, Hussein},
  booktitle = {Proceedings of the Southern African Institute for Computer Scientist and Information Technologists Annual Conference 2014 on SAICSIT 2014 Empowered by Technology},
  title     = {Fine-Grained Scalability of Digital Library Services in the Cloud},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {157–165},
  publisher = {Association for Computing Machinery},
  series    = {SAICSIT '14},
  abstract  = {Modern digital library systems are increasingly handling massive data volumes; this content needs to be stored, indexed and made easily accessible to end users. Cloud computing promises to address some of these needs through a set of services that arguably support scalability of service provision. This paper discusses a set of experiments to assess the scalability of typical digital library services that use cloud computing facilities for core processing and storage. Horizontal scalability experiments were performed to benchmark the overall performance of the architecture with increasing load. The results of the experiments indicate that stable response times and some degree of variability are attainable due to multiple middleware servers when browsing and/or searching a collection of a fixed size. There is minimal variation in response times when varying collection sizes and equally after the caching phases. Most importantly, request sequencing proved that the quantity and age of requests have no impact on response times. The experimental results thus provide evidence to support the feasibility of building and deploying cloud-based Digital Libraries.},
  doi       = {10.1145/2664591.2664611},
  isbn      = {9781450332460},
  keywords  = {Scalability, Amazon AWS, Cloud Computing},
  location  = {Centurion, South Africa},
  numpages  = {9},
  url       = {https://doi.org/10.1145/2664591.2664611},
}

@InProceedings{Valadares2016,
  author    = {Valadares, Arthur and Lopes, Cristina V. and Achar, Rohan and Bowman, Mic},
  booktitle = {Proceedings of the 2016 Winter Simulation Conference},
  title     = {CADIS: Aspect-Oriented Architecture for Collaborative Modeling and Simulation},
  year      = {2016},
  address   = {Arlington, Virginia},
  pages     = {1024–1035},
  publisher = {IEEE Press},
  series    = {WSC '16},
  abstract  = {The development of large and complex simulated models often requires teams to collaborate. One approach is to break a large model into independently developed partial models that, when combined, capture the overall behavior. However, maintaining consistent world state across independently developed simulations is a challenge.In this paper, we introduce the Collaborative Aspect-Oriented Distributed Interactive Simulation (CADIS) architecture and development platform. CADIS embodies a new paradigm for integrating independently developed time-discrete partial models and simulations, focusing on transparently maintaining synchronized shared state. Data is pulled and instantiated in the beginning of each time step, and pushed at the end of each time step. An urban simulation is used to demonstrate CADIS capabilities and performance. We show how simple optimizations can bring the performance of the framework to acceptable levels, making CADIS a viable modeling and simulation methodology supporting separation of concerns.},
  isbn      = {9781509044849},
  numpages  = {12},
}

@InProceedings{Hartert2015,
  author    = {Hartert, Renaud and Vissicchio, Stefano and Schaus, Pierre and Bonaventure, Olivier and Filsfils, Clarence and Telkamp, Thomas and Francois, Pierre},
  booktitle = {Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication},
  title     = {A Declarative and Expressive Approach to Control Forwarding Paths in Carrier-Grade Networks},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {15–28},
  publisher = {Association for Computing Machinery},
  series    = {SIGCOMM '15},
  abstract  = {SDN simplifies network management by relying on declarativity (high-level interface) and expressiveness (network flexibility). We propose a solution to support those features while preserving high robustness and scalability as needed in carrier-grade networks. Our solution is based on (i) a two-layer architecture separating connectivity and optimization tasks; and (ii) a centralized optimizer called framework, which translates high-level goals expressed almost in natural language into compliant network configurations. Our evaluation on real and synthetic topologies shows that framework improves the state of the art by (i) achieving better trade-offs for classic goals covered by previous works, (ii) supporting a larger set of goals (refined traffic engineering and service chaining), and (iii) optimizing large ISP networks in few seconds. We also quantify the gains of our implementation, running Segment Routing on top of IS-IS, over possible alternatives (RSVP-TE and OpenFlow).},
  doi       = {10.1145/2785956.2787495},
  isbn      = {9781450335423},
  keywords  = {optimization, service chaining, mpls, isp, segment routing (sr), traffic engineering, software defined networking (sdn)},
  location  = {London, United Kingdom},
  numpages  = {14},
  url       = {https://doi.org/10.1145/2785956.2787495},
}

@Article{Hartert2015a,
  author     = {Hartert, Renaud and Vissicchio, Stefano and Schaus, Pierre and Bonaventure, Olivier and Filsfils, Clarence and Telkamp, Thomas and Francois, Pierre},
  journal    = {SIGCOMM Comput. Commun. Rev.},
  title      = {A Declarative and Expressive Approach to Control Forwarding Paths in Carrier-Grade Networks},
  year       = {2015},
  issn       = {0146-4833},
  month      = {aug},
  number     = {4},
  pages      = {15–28},
  volume     = {45},
  abstract   = {SDN simplifies network management by relying on declarativity (high-level interface) and expressiveness (network flexibility). We propose a solution to support those features while preserving high robustness and scalability as needed in carrier-grade networks. Our solution is based on (i) a two-layer architecture separating connectivity and optimization tasks; and (ii) a centralized optimizer called framework, which translates high-level goals expressed almost in natural language into compliant network configurations. Our evaluation on real and synthetic topologies shows that framework improves the state of the art by (i) achieving better trade-offs for classic goals covered by previous works, (ii) supporting a larger set of goals (refined traffic engineering and service chaining), and (iii) optimizing large ISP networks in few seconds. We also quantify the gains of our implementation, running Segment Routing on top of IS-IS, over possible alternatives (RSVP-TE and OpenFlow).},
  address    = {New York, NY, USA},
  doi        = {10.1145/2829988.2787495},
  issue_date = {October 2015},
  keywords   = {optimization, mpls, service chaining, isp, segment routing (sr), traffic engineering, software defined networking (sdn)},
  numpages   = {14},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2829988.2787495},
}

@InProceedings{Aghaei2019,
  author    = {Aghaei, Ehsan and Al-shaer, Ehab},
  booktitle = {Proceedings of the 6th Annual Symposium on Hot Topics in the Science of Security},
  title     = {ThreatZoom: Neural Network for Automated Vulnerability Mitigation},
  year      = {2019},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {HotSoS '19},
  abstract  = {Increasing the variety and quantity of cyber threats becoming the evident that traditional human-in-loop approaches are no longer sufficient to keep systems safe. To address this momentous moot point, forward-thinking pioneers propose new cyber security strategy using automation to build a more efficient and cheaper defense. Associating large number of unpatchable CVEs (vulnerability descriptions) generated everyday to appropriate CWE (weakness) and CAPEC (attack pattern) can be used to automatically infer the expected impact and corresponding mitigation course of actions for that new CVE. Routinely, adversary exploits a vulnerability to trigger a cyber attack where this vulnerability results from a product or system weakness. Hence, finding a common system weakness associated with a vulnerability within a particular product can help to identifying the software, system, or architecture flaw and the potential attack impacts. This identification leads to prevent, detect, and mitigate those flaws. On the other hand, after recognizing the cause and the effect of a vulnerability, discovering the procedural-oriented description of the attack to create behavioral observables for detection and mitigation is necessary that can be derived from CAPEC and ATTCK. Mapping the CWE to CAPEC and ATTCK which provides pre-TTP and post-TTP respectively where TTP stands for Tactics, Techniques, and Procedures. Having all CWE, CAPEC, and ATTCK in one hand enables us to find corresponding mitigation for each one. On the other hand, extracting threat actions provided by each of these concepts leads to find another type of mitigation coming from Critical Security Controls (CSC).In this proposal, the target is to do mapping all the way from CVE to CAPEC and ATTCk automatically using machine learning, deep learning, and natural language processing and find the appropriate mitigation for each one and then find a proper patch as course of action defense. So far, we have introduced a neural network model which successfully classifies CVE to CWE automatically and as working on a deep learning model to classify CWEs to CAPEC.},
  articleno = {24},
  doi       = {10.1145/3314058.3318167},
  isbn      = {9781450371476},
  keywords  = {CVE, CWE, cyber security, CAPEC},
  location  = {Nashville, Tennessee, USA},
  numpages  = {3},
  url       = {https://doi.org/10.1145/3314058.3318167},
}

@InProceedings{Alissandrakis2016,
  author    = {Alissandrakis, Aris and Nake, Isabella},
  booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct},
  title     = {A New Approach for Visualizing Quantified Self Data Using Avatars},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {522–527},
  publisher = {Association for Computing Machinery},
  series    = {UbiComp '16},
  abstract  = {In recent years, it is becoming more common for people to use applications or devices that keep track of their life and activities, such as physical fitness, places they visited, the music they listen to, or pictures they took. This generates data that are used by the service providers for a variety of (usually analytics) purposes, but commonly there are limitations on how the users themselves can also explore or interact with these data. Our position paper describes a new approach of visualizing such Quantified Self data, in a meaningful and enjoyable way that can give the users personal insights into their own data. The visualization of the information is proposed as an avatar that maps the different activities the user is engaged with, along with each such activity level, as graphical features. An initial prototype (both in terms of graphical design and software architecture) as well as possible future extensions are discussed.},
  doi       = {10.1145/2968219.2968315},
  isbn      = {9781450344623},
  keywords  = {quantified self, avatars, data visualization},
  location  = {Heidelberg, Germany},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2968219.2968315},
}

@InProceedings{Wang2015,
  author    = {Wang, Ying and Han, Yinhe and Wang, Cheng and Li, Huawei and Li, Xiaowei},
  booktitle = {Proceedings of the 52nd Annual Design Automation Conference},
  title     = {RADAR: A Case for Retention-Aware DRAM Assembly and Repair in Future FGR DRAM Memory},
  year      = {2015},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {DAC '15},
  abstract  = {Refresh operations consume substantial energy and bandwidth in high-density DRAM memory. To cope with this issue, Fine-Grained Refresh (FGR) is recently proposed to eliminate unnecessary refresh operations caused by minor weak cells. Even JEDEC's DDR4 DRAM specification announces the support of FGR to make DRAM refresh more scalable. Unfortunately, we observe that the effectiveness of FGR is greatly confined by the procedure of refresh-oblivious device integration because all memory devices within a module have to be controlled and refreshed in a lockstep way after the step of assembly. In this work, we firstly propose to intelligently integrate the "compatible" devices through a pre-assembly testing and retention-aware matching method. Second, we reuse the reconfiguration structure from yield-oriented remapping mechanism in memory chips and propose Microfix to create a balanced distribution of retention time in memory banks through fine-grained row-address tuning. With this optimization architecture, RADAR, we can eliminate the refresh overhead of produced memory modules by 28\% on average.},
  articleno = {19},
  doi       = {10.1145/2744769.2744897},
  isbn      = {9781450335201},
  location  = {San Francisco, California},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2744769.2744897},
}

@InProceedings{Savic2017,
  author    = {Savic, Selena and B\"{u}hlmann, Vera},
  booktitle = {Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems},
  title     = {Digital Literacy in Architecture: How Space is Organized by Computation},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {2909–2914},
  publisher = {Association for Computing Machinery},
  series    = {CHI EA '17},
  abstract  = {The integration of architecture and digital technologies happens on an instrumental level, where digital is associated with making the design process more efficient. Architects commonly report on interaction with computers describing the service software has provided. Computational procedures remain obscured by design outputs. In this project, we propose to critically study the relationship of architecture and technology from a perspective of interaction with digital tools. We propose the use of text-mining on a corpus of architectural discourse in social media. With concepts extracted from this initial step, we will conduct a series of experiments on collaborative qualification using a mobile application. We will show how the challenge of organizing a discourse on computational process in architectural design could involve computation in productive new ways. Finally, we will discuss how these insights could enrich the future development of computer-based tools for design.},
  doi       = {10.1145/3027063.3053237},
  isbn      = {9781450346566},
  keywords  = {collaborative qualification, digital literacy, computer-aided design, meaning-making, text-mining},
  location  = {<conf-loc>, <city>Denver</city>, <state>Colorado</state>, <country>USA</country>, </conf-loc>},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3027063.3053237},
}

@InProceedings{BarcelonaPons2019,
  author    = {Barcelona-Pons, Daniel and Garc\'{\i}a-L\'{o}pez, Pedro and Ruiz, \'{A}lvaro and G\'{o}mez-G\'{o}mez, Amanda and Par\'{\i}s, Gerard and S\'{a}nchez-Artigas, Marc},
  booktitle = {Proceedings of the 5th International Workshop on Serverless Computing},
  title     = {FaaS Orchestration of Parallel Workloads},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {25–30},
  publisher = {Association for Computing Machinery},
  series    = {WOSC '19},
  abstract  = {Function as a Service (FaaS) is based on a reactive programming model where functions are activated by triggers in response to cloud events (e.g., objects added to an object store). The inherent elasticity and the pay-per-use model of serverless functions make them very appropriate for embarrassingly parallel tasks like data preprocessing, or even the execution of MapReduce jobs in the cloud.But current Serverless orchestration systems are not designed for managing parallel fork-join workflows in a scalable and efficient way. We demonstrate in this paper that existing services like AWS Step Functions or Azure Durable Functions incur in considerable overheads, and only Composer at IBM Cloud provides suitable performance.Successively, we analyze the architecture of OpenWhisk as an open-source FaaS systems and its orchestration features (Composer). We outline its architecture problems and propose guidelines for orchestrating massively parallel workloads using serverless functions.},
  doi       = {10.1145/3366623.3368137},
  isbn      = {9781450370387},
  keywords  = {orchestration, FaaS, Serverless, event-based},
  location  = {Davis, CA, USA},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3366623.3368137},
}

@InProceedings{Yang2018,
  author    = {Yang, Haoyu and Li, Shuhe and Ma, Yuzhe and Yu, Bei and Young, Evangeline F. Y.},
  booktitle = {Proceedings of the 55th Annual Design Automation Conference},
  title     = {GAN-OPC: Mask Optimization with Lithography-Guided Generative Adversarial Nets},
  year      = {2018},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {DAC '18},
  abstract  = {Mask optimization has been a critical problem in the VLSI design flow due to the mismatch between the lithography system and the continuously shrinking feature sizes. Optical proximity correction (OPC) is one of the prevailing resolution enhancement techniques (RETs) that can significantly improve mask printability. However, in advanced technology nodes, the mask optimization process consumes more and more computational resources. In this paper, we develop a generative adversarial network (GAN) model to achieve better mask optimization performance. We first develop an OPC-oriented GAN flow that can learn target-mask mapping from the improved architecture and objectives, which leads to satisfactory mask optimization results. To facilitate the training process and ensure better convergence, we also propose a pre-training procedure that jointly trains the neural network with inverse lithography technique (ILT). At convergence, the generative network is able to create quasi-optimal masks for given target circuit patterns and fewer normal OPC steps are required to generate high quality masks. Experimental results show that our flow can facilitate the mask optimization process as well as ensure a better printability.},
  articleno = {131},
  doi       = {10.1145/3195970.3196056},
  isbn      = {9781450357005},
  location  = {San Francisco, California},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3195970.3196056},
}

@Article{Afek2016,
  author     = {Afek, Yehuda and Bremler-Barr, Anat and Harchol, Yotam and Hay, David and Koral, Yaron},
  journal    = {IEEE/ACM Trans. Netw.},
  title      = {Making DPI Engines Resilient to Algorithmic Complexity Attacks},
  year       = {2016},
  issn       = {1063-6692},
  month      = {dec},
  number     = {6},
  pages      = {3262–3275},
  volume     = {24},
  abstract   = {This paper starts by demonstrating the vulnerability of Deep Packet Inspection DPI mechanisms, which are at the core of security devices, to algorithmic complexity denial of service attacks, thus exposing a weakness in the first line of defense of enterprise networks and clouds. A system and a multi-core architecture to defend from these algorithmic complexity attacks is presented in the second part of the paper. The integration of this system with two different DPI engines is demonstrated and discussed. The vulnerability is exposed by showing how a simple low bandwidth cache-miss attack takes down the Aho-Corasick AC pattern matching algorithm that lies at the heart of most DPI engines. As a first step in the mitigation of the attack, we have developed a compressed variant of the AC algorithm that improves the worst case performance under an attack. Still, under normal traffic its running-time is worse than classical AC implementations. To overcome this problem, we introduce  ${rm MCA}^{2}$—Multi-Core Architecture to Mitigate Complexity Attacks, which dynamically combines the classical AC algorithm with our compressed implementation, to provide a robust solution to mitigate this cache-miss attack. We demonstrate the effectiveness of our architecture by examining cache-miss algorithmic complexity attacks against DPI engines and show a goodput boost of up to 73\%. Finally, we show that our architecture may be generalized to provide a principal solution to a wide variety of algorithmic complexity attacks.},
  doi        = {10.1109/TNET.2016.2518712},
  issue_date = {December 2016},
  numpages   = {14},
  publisher  = {IEEE Press},
  url        = {https://doi.org/10.1109/TNET.2016.2518712},
}

@InProceedings{Silva2015a,
  author    = {de Silva, Lavindra and Yan, Rongjie and Ingrand, Felix and Alami, Rachid and Bensalem, Saddek},
  booktitle = {Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts},
  title     = {A Verifiable and Correct-by-Construction Controller for Robots in Human Environments},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {281},
  publisher = {Association for Computing Machinery},
  series    = {HRI'15 Extended Abstracts},
  abstract  = {With the increasing use of domestic and service robots alongside humans, it is now becoming crucial to be able to verify whether robot-software is safe, dependable, and correct. Indeed, in the near future it may well be necessary for robot-software developers to provide safety certifications guaranteeing, e.g. that a hospital nursebot will not move too fast while a person is leaning on it, that the arm of a service robot will not unexpectedly open its gripper while holding a glass, or that there will never be a software deadlock while a robot is navigating in an office. To this end, we have provided a framework and software engineering methodology for developing safe and dependable real-world robotic architectures, with a focus on the functional level--the lowest level of a typical layered robotic architecture--which has all the basic action and perception capabilities such as image processing, obstacle avoidance, and motion control. Unlike past work we address the formal verification of the functional level, which allows providing guarantees that it will not do steps leading to undesirable/disastrous outcomes.},
  doi       = {10.1145/2701973.2702098},
  isbn      = {9781450333184},
  keywords  = {verification, reliability, human factors},
  location  = {Portland, Oregon, USA},
  numpages  = {1},
  url       = {https://doi.org/10.1145/2701973.2702098},
}

@InProceedings{Chevalier2015,
  author    = {Chevalier, Jules and Subercaze, Julien and Gravier, Christophe and Laforest, Fr\'{e}d\'{e}rique},
  booktitle = {Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data},
  title     = {Slider: An Efficient Incremental Reasoner},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {1081–1086},
  publisher = {Association for Computing Machinery},
  series    = {SIGMOD '15},
  abstract  = {The Semantic Web has gained substantial momentum over the last decade. It contributes to the manifestation of knowledge from data, and leverages implicit knowledge through reasoning algorithms. The main drawbacks of current reasoning methods over ontologies are two-fold: first they struggle to provide scalability for large datasets, and second, the batch processing reasoners who provide the best scalability so far are unable to infer knowledge from evolving data. We contribute to solving these problems by introducing Slider, an efficient incremental reasoner. Slider goes a significant step beyond existing system, including i) performance, by more than a 70\% improvement in average compared to the fastest reasoner available to the best of our knowledge, and ii) inferences on streams of semantic data, by using intrinsic features that are themselves streams-oriented. Slider is fragment agnostic and conceived to handle expanding data with a growing background knowledge base. It natively supports pdf and RDFS, and its architecture allows to extend it to more complex fragments with a minimal effort. In this demo a web-based interface allows the users to visualize the internal behaviour of Slider during the inference, to better understand its design and principles.},
  doi       = {10.1145/2723372.2735363},
  isbn      = {9781450327589},
  keywords  = {web of data, streamed reasoning, incremental reasoning},
  location  = {Melbourne, Victoria, Australia},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2723372.2735363},
}

@InProceedings{Pacheco2017,
  author    = {Pacheco, Fannia and Exposito, Ernesto and Gineste, Mathieu and Budoin, Cedric},
  booktitle = {Proceedings of the 9th International Conference on Management of Digital EcoSystems},
  title     = {An Autonomic Traffic Analysis Proposal Using Machine Learning Techniques},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {273–280},
  publisher = {Association for Computing Machinery},
  series    = {MEDES '17},
  abstract  = {Network analysis has recently become in one of the most challenging tasks to handle due to the rapid growth of communication technologies. For network management, accurate identification and classification of network traffic is a key task. For example, identifying traffic from different applications is critical to manage bandwidth resources and to ensure Quality of Service objectives. Machine learning emerges as a suitable tool for traffic classification; however, it requires several steps that must be followed adequately in order to achieve the goals. In this paper, we proposed an architecture to perform traffic analysis based on Machine Learning techniques and autonomic computing. We analyze the procedures to perform Machine Learning over traffic network classification, and at the same time we give guidelines to introduce all these procedures into the architecture proposed. The main contribution of our proposal is the reconfiguration of the traffic classifier that will change according to the knowledge acquired from the traffic analysis process.},
  doi       = {10.1145/3167020.3167061},
  isbn      = {9781450348959},
  keywords  = {traffic analysis, quality of service, autonomic computing, Machine Learning},
  location  = {Bangkok, Thailand},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3167020.3167061},
}

@InProceedings{Taguchi2020,
  author    = {Taguchi, Shuhei and Yamamura, Chigusa and Ohmata, Hisayuki and Sekine, Daisuke and Kajita, Kaisei and Fujii, Arisa},
  booktitle = {Proceedings of the 2020 ACM International Conference on Interactive Media Experiences},
  title     = {Sharing Same Elements in User Viewing History Data Securely Through Private Set Intersection Under User-Centric Data Control},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {138–142},
  publisher = {Association for Computing Machinery},
  series    = {IMX '20},
  abstract  = {Recently, various over-the-top (OTT) streaming services as well as traditional broadcasts distribute numerous content every day, allowing users to watch their favorite content at any time. While users can choose from a quantity of content, they often view the same content mainly because most OTT streaming services implement recommendation systems. However, it is often difficult for users to realize the same content they viewed and enjoy sharing their opinions or feelings because they do not know each other when and which content they viewed. For the purpose of encouraging such enjoyable experiences, we propose a system architecture that allows users to share the same content they viewed by using the user's viewing history data. Such viewing history data is currently collected and stored by hundreds of different services and companies. Therefore, our system architecture adopts a user-centric data control model that allows users to collect and store their data on their own online storages, and use it for their purposes. If users are asked to disclose all of the raw data of their viewing history to each other or to third party when sharing, most of them will feel anxiety because the data often contains sensitive personal information. Therefore, we introduce a method using private set intersection (PSI), a cryptographic technique that allows users to share the same elements in the users’ viewing history data without revealing anything to each other except the elements at the intersection. We also demonstrate the feasibility of the architecture through use cases.},
  doi       = {10.1145/3391614.3399389},
  isbn      = {9781450379762},
  keywords  = {Viewing history, Private set intersection, Personal data, Decentralization, User-centric, GDPR;},
  location  = {Cornella, Barcelona, Spain},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3391614.3399389},
}

@InProceedings{Ibrahim2020,
  author    = {Ibrahim, Seif and Harrison, Cyrus and Larsen, Matthew},
  booktitle = {ISAV'20 In Situ Infrastructures for Enabling Extreme-Scale Analysis and Visualization},
  title     = {JIT’s Complicated: A Comprehensive System For Derived Field Generation},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {27–31},
  publisher = {Association for Computing Machinery},
  series    = {ISAV'20},
  abstract  = {Derived field calculations are a vital part of the visualization and analysis workflow. These calculations allow simulation users to create important quantities of interest that are not generated by the simulation, and systems that calculate derived quantities must be flexible enough to accommodate a wide variety of user requests. In situ analysis imposes additional constraints on the system, and derived field calculations must be able to leverage the same resources as the simulation to minimize the runtime and memory usage. Just-in-time (JIT) compilation defers code creation until runtime, and a JIT based system is capable of fusing a complex expression into a single kernel invocation (i.e., kernel fusion). Without kernel fusion, the system would be forced to evaluate each piece of the expression (e.g., an operator or function call) as separate kernel invocations, which increases both runtime and memory pressure on the host simulation. In this paper, we present a production-oriented in situ derived field system that leverages JIT compilation to target heterogeneous HPC architectures. Additionally, we explore the runtime costs of using this system to calculate three expressions in three simulation codes.},
  doi       = {10.1145/3426462.3426467},
  isbn      = {9781450388122},
  location  = {Atlanta, GA, USA},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3426462.3426467},
}

@InProceedings{Holzinger2016,
  author    = {Holzinger, Philipp and Triller, Stefan and Bartel, Alexandre and Bodden, Eric},
  booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {An In-Depth Study of More Than Ten Years of Java Exploitation},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {779–790},
  publisher = {Association for Computing Machinery},
  series    = {CCS '16},
  abstract  = {When created, the Java platform was among the first runtimes designed with security in mind. Yet, numerous Java versions were shown to contain far-reaching vulnerabilities, permitting denial-of-service attacks or even worse allowing intruders to bypass the runtime's sandbox mechanisms, opening the host system up to many kinds of further attacks.This paper presents a systematic in-depth study of 87 publicly available Java exploits found in the wild. By collecting, minimizing and categorizing those exploits, we identify their commonalities and root causes, with the goal of determining the weak spots in the Java security architecture and possible countermeasures.Our findings reveal that the exploits heavily rely on a set of nine weaknesses, including unauthorized use of restricted classes and confused deputies in combination with caller-sensitive methods. We further show that all attack vectors implemented by the exploits belong to one of three categories: single-step attacks, restricted-class attacks, and information hiding attacks.The analysis allows us to propose ideas for improving the security architecture to spawn further research in this area.},
  doi       = {10.1145/2976749.2978361},
  isbn      = {9781450341394},
  keywords  = {java security, exploits, access control, security analysis},
  location  = {Vienna, Austria},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2976749.2978361},
}

@InProceedings{Urra2014,
  author    = {Urra, Enrique and Cabrera-Paniagua, Daniel and Cubillos, Claudio},
  booktitle = {Proceedings of the 7th Euro American Conference on Telematics and Information Systems},
  title     = {Towards a Distributed Hyperheuristic Deploy Architecture},
  year      = {2014},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {EATIS '14},
  abstract  = {The hyperheuristic term is known in the optimization field as an automated methodology for selecting or generating heuristics to solve hard computational search problems. From the design perspective, it is based on decoupling the solving intelligence from the domain expertise, allowing to reuse the same solver for multiple, usually related problem domains. There are few works in which hyperheuristics have been designed and evaluated in distributed environments. In this paper, we propose a conceptual design of a distributed hyperheuristic architecture, from the problem domain deploying perspective, which allows to communicate different optimization environments (such as solver and domain) and to offering a "solving service". Different problems domains could be addressed using an encapsulated hyperheuristic solver, and through well defined interfaces, users can provide different heuristic components to perform the optimization process. The proposed architecture is only an initial step for which different modeling, design and implementation issues must be addressed. Such research should be focused on defining how conceptual design contributions must be leveraged to implement well defined interfaces, capable of connecting hyperheuristic solvers and problem domains within distributed environments.},
  articleno = {31},
  doi       = {10.1145/2590651.2590682},
  isbn      = {9781450324359},
  keywords  = {hyperheuristics, optimization, distributed architecture},
  location  = {Valparaiso, Chile},
  numpages  = {4},
  url       = {https://doi.org/10.1145/2590651.2590682},
}

@InProceedings{Dev2020,
  author    = {Dev, Sundar and Lo, David and Cheng, Liqun and Ranganathan, Parthasarathy},
  booktitle = {Proceedings of the 57th ACM/EDAC/IEEE Design Automation Conference},
  title     = {Autonomous Warehouse-Scale Computers},
  year      = {2020},
  address   = {Virtual Event, USA},
  publisher = {IEEE Press},
  series    = {DAC '20},
  abstract  = {Modern Warehouse-Scale Computers (WSCs), composed of many generations of servers and a myriad of domain specific accelerators, are becoming increasingly heterogeneous. Meanwhile, WSC workloads are also becoming incredibly diverse with different communication patterns, latency requirements, and service level objectives (SLOs). Insufficient understanding of the interactions between workload characteristics and the underlying machine architecture leads to resource over-provisioning, thereby significantly impacting the utilization of WSCs.We present Autonomous Warehouse-Scale Computers, a new WSC design that leverages machine learning techniques and automation to improve job scheduling, resource management, and hardware-software co-optimization to address the increasing heterogeneity in WSC hardware and workloads. Our new design introduces two new layers in the WSC stack, namely: (a) a Software-Defined Server (SDS) Abstraction Layer which redefines the hardware-software boundary and provides greater control of the hardware to higher layers of the software stack through stable abstractions; and (b) a WSC Efficiency Layer which regularly monitors the resource usage of workloads on different hardware types, autonomously quantifies the performance sensitivity of workloads to key system configurations, and continuously improves scheduling decisions and hardware resource QoS policies to maximize cluster level performance. Our new WSC design has been successfully deployed across all WSCs at Google for several years now. The new WSC design improves throughput of workloads (by 7--10\%, on average), increases utilization of hardware resources (up to 2x), and reduces performance variance for critical workloads (up to 25\%).},
  articleno = {175},
  isbn      = {9781450367257},
  keywords  = {machine learning, heterogeneity, WSC, automation},
  numpages  = {6},
}

@Article{Chai2019,
  author     = {Chai, Guoshi and Yu, Min and Jiang, Lixu and Duan, Yaocong and Huang, Jian},
  journal    = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
  title      = {HMMCAS: A Web Tool for the Identification and Domain Annotations of CAS Proteins},
  year       = {2019},
  issn       = {1545-5963},
  month      = {jul},
  number     = {4},
  pages      = {1313–1315},
  volume     = {16},
  abstract   = {The CRISPR-Cas clustered regularly interspaced short palindromic repeats-CRISPR-associated proteins adaptive immune systems are discovered in many bacteria and most archaea. These systems are encoded by cas CRISPR-associated operons that have an extremely diverse architecture. The most crucial step in the depiction of cas operons composition is the identification of cas genes or Cas proteins. With the continuous increase of the newly sequenced archaeal and bacterial genomes, the recognition of new Cas proteins is becoming possible, which not only provides candidates for novel genome editing tools but also helps to understand the prokaryotic immune system better. Here, we describe HMMCAS, a web service for the detection of CRISPR-associated structural and functional domains in protein sequences. HMMCAS uses hmmscan similarity search algorithm in HMMER3.1 to provide a fast, interactive service based on a comprehensive collection of hidden Markov models of Cas protein family. It can accurately identify the Cas proteins including those fusion proteins, for example the Cas1-Cas4 fusion protein in Candidatus Chloracidobacterium thermophilum B Cab. thermophilum B. HMMCAS can also find putative cas operon and determine which type it belongs to. HMMCAS is freely available at http://i.uestc.edu.cn/hmmcas.},
  address    = {Washington, DC, USA},
  doi        = {10.1109/TCBB.2017.2665542},
  issue_date = {July 2019},
  numpages   = {3},
  publisher  = {IEEE Computer Society Press},
  url        = {https://doi.org/10.1109/TCBB.2017.2665542},
}

@InProceedings{Bacciu2017,
  author    = {Bacciu, Davide and Chessa, Stefano and Gallicchio, Claudio and Micheli, Alessio},
  booktitle = {Proceedings of the 1st International Conference on Internet of Things and Machine Learning},
  title     = {On the Need of Machine Learning as a Service for the Internet of Things},
  year      = {2017},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {IML '17},
  abstract  = {In recent years we are witnessing a rapid increase in the diffusion of the Internet of Things (IoT) technology, with a large scale adoption of interconnected heterogeneous devices that are pervasively collecting information through the interaction with humans in their environment. The adoption of Machine Learning (ML) methodologies can play a fundamental role, allowing smarter IoT applications to continuously adapt to evolving environmental conditions and user's needs. In this context, the time is now ripe for a decisive step forward in the direction of a systematic integration of ML functionalities within the IoT platform.In this paper, we outline the principles that should guide the realization of a ML service for the IoT, proposing a conceptual architecture of such a learning service, integrated within the IoT reference model. Our proposal leverages on the experience of recent successful European initiatives that led to the realization of intelligent sensor networks built on the synergy between resource efficient ML models for temporal data processing and wireless sensor networks. The relevant impact of ML in applicative domains of interest for the IoT is also enucleated through a brief summary of recent results.},
  articleno = {22},
  doi       = {10.1145/3109761.3109783},
  isbn      = {9781450352437},
  keywords  = {machine learning service, adaptive IoT applications, intelligent sensor networks, distributed learning service, internet of things},
  location  = {Liverpool, United Kingdom},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3109761.3109783},
}

@InProceedings{Dhawan2014,
  author    = {Dhawan, Udit and Vasilakis, Nikos and Rubin, Raphael and Chiricescu, Silviu and Smith, Jonathan M. and Knight, Thomas F. and Pierce, Benjamin C. and DeHon, Andr\'{e}},
  booktitle = {Proceedings of the Third Workshop on Hardware and Architectural Support for Security and Privacy},
  title     = {PUMP: A Programmable Unit for Metadata Processing},
  year      = {2014},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {HASP '14},
  abstract  = {We introduce the Programmable Unit for Metadata Processing (PUMP), a novel software-hardware element that allows flexible computation with uninterpreted metadata alongside the main computation with modest impact on runtime performance (typically 10--40\% for single policies, compared to metadata-free computation on 28 SPEC CPU2006 C, C++, and Fortran programs). While a host of prior work has illustrated the value of ad hoc metadata processing for specific policies, we introduce an architectural model for extensible, programmable metadata processing that can handle arbitrary metadata and arbitrary sets of software-defined rules in the spirit of the time-honored 0-1-∞ rule. Our results show that we can match or exceed the performance of dedicated hardware solutions that use metadata to enforce a single policy, while adding the ability to enforce multiple policies simultaneously and achieving flexibility comparable to software solutions for metadata processing. We demonstrate the PUMP by using it to support four diverse safety and security policies---spatial and temporal memory safety, code and data taint tracking, control-flow integrity including return-oriented-programming protection, and instruction/data separation---and quantify the performance they achieve, both singly and in combination.},
  articleno = {8},
  doi       = {10.1145/2611765.2611773},
  isbn      = {9781450327770},
  keywords  = {memory safety, taint tracking, tagged architecture, metadata, control-flow integrity, security},
  location  = {Minneapolis, Minnesota, USA},
  numpages  = {8},
  url       = {https://doi.org/10.1145/2611765.2611773},
}

@Article{To2016,
  author     = {To, Quoc-Cuong and Nguyen, Benjamin and Pucheral, Philippe},
  journal    = {ACM Trans. Database Syst.},
  title      = {Private and Scalable Execution of SQL Aggregates on a Secure Decentralized Architecture},
  year       = {2016},
  issn       = {0362-5915},
  month      = {aug},
  number     = {3},
  volume     = {41},
  abstract   = {Current applications, from complex sensor systems (e.g., quantified self) to online e-markets, acquire vast quantities of personal information that usually end up on central servers where they are exposed to prying eyes. Conversely, decentralized architectures that help individuals keep full control of their data complexify global treatments and queries, impeding the development of innovative services. This article aims precisely at reconciling individual's privacy on one side and global benefits for the community and business perspectives on the other. It promotes the idea of pushing the security to secure hardware devices controlling the data at the place of their acquisition. Thanks to these tangible physical elements of trust, secure distributed querying protocols can reestablish the capacity to perform global computations, such as Structured Query Language (SQL) aggregates, without revealing any sensitive information to central servers. This article studies how to secure the execution of such queries in the presence of honest-but-curious and malicious attackers. It also discusses how the resulting querying protocols can be integrated in a concrete decentralized architecture. Cost models and experiments on SQL/Asymmetric Architecture (AA), our distributed prototype running on real tamper-resistant hardware, demonstrate that this approach can scale to nationwide applications.},
  address    = {New York, NY, USA},
  articleno  = {16},
  doi        = {10.1145/2894750},
  issue_date = {August 2016},
  keywords   = {parallel computing, decentralized architecture, Trusted hardware},
  numpages   = {43},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2894750},
}

@Article{HabibiGharakheili2017,
  author     = {Habibi Gharakheili, Hassan and Sivaraman, Vijay and Moors, Tim and Vishwanath, Arun and Matthews, John and Russell, Craig},
  journal    = {IEEE/ACM Trans. Netw.},
  title      = {Enabling Fast and Slow Lanes for Content Providers Using Software Defined Networking},
  year       = {2017},
  issn       = {1063-6692},
  month      = {jun},
  number     = {3},
  pages      = {1373–1385},
  volume     = {25},
  abstract   = {Residential broadband consumption is growing rapidly, increasing the gap between Internet service provider ISP costs and revenues. Meanwhile, proliferation of Internet-enabled devices is congesting access networks, degrading end-user experience, and affecting content provider monetization. In this paper, we propose a new model whereby the content provider explicitly signals fast- and slow-lane requirements to the ISP on a per-flow basis, using open APIs supported through software defined networking SDN. Our first contribution is to develop an architecture that supports this model, presenting arguments on why this benefits consumers better user experience, ISPs two-sided revenue, and content providers fine-grained control over peering arrangement. Our second contribution is to evaluate our proposal using a real trace of over 10 million flows to show that video flow quality degradation can be nearly eliminated by the use of dynamic fast-lanes, and web-page load times can be hugely improved by the use of slow-lanes for bulk transfers. Our third contribution is to develop a fully functional prototype of our system using open-source SDN components Openflow switches and POX controller modules and instrumented video/file-transfer servers to demonstrate the feasibility and performance benefits of our approach. Our proposal is a first step towards the long-term goal of realizing open and agile access network service quality management that is acceptable to users, ISPs, and content providers alike.},
  doi        = {10.1109/TNET.2016.2627005},
  issue_date = {June 2017},
  numpages   = {13},
  publisher  = {IEEE Press},
  url        = {https://doi.org/10.1109/TNET.2016.2627005},
}

@InProceedings{Grosch2017,
  author    = {Grosch, Franz-Josef},
  booktitle = {Proceedings of the 15th ACM-IEEE International Conference on Formal Methods and Models for System Design},
  title     = {Elevate Embedded Real-Time Programming with a Synchronous Language},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {156},
  publisher = {Association for Computing Machinery},
  series    = {MEMOCODE '17},
  abstract  = {Product development at companies such as Bosch requires systems engineering for digital hardware and mechatronic components as well as software engineering for resource-constrained real-time applications cooperating with distributed server applications. While many of the involved engineering disciplines greatly benefit from model-based approaches and from advances in software infrastructures, deeply embedded software still is written in C since the seventies and runs on platforms designed in the nineties (e.g. OSEK). Simulation tools like Simulink or Modelica are used to test discrete code against continuous plant models or to generate code for certain aspects, but they do not really provide modern implementation technologies to address software architecture and qualities or to make embedded programming "attractive" for software professionals.We regard synchronous languages as suitable to solve many of the issues in the integration (causality) and synchronisation (clocks) of time-triggered and event-triggered embedded functions that exhibit their behaviour over time steps and are coordinated according to their mode-switching in a structured synchronous control flow. Searching for an imperative synchronous language (with deterministic concurrent composition, and synchronous control flow), equipped with features for encapsulation and composition (objects, packages, separate compilation) and supporting programming parallel tasks deployed to separate cores (clock refinement and deterministic inter-task communication), we ended up in designing our own language, suitable for resource-constrained, real-time applications running on multi-core controllers.We will explain the main requirements and features of this language, how they integrate with the principles of a synchronous language, how they can be applied to typical everyday problems in embedded development, and how such locally synchronous services may integrate in a globally asynchronous service architecture.},
  doi       = {10.1145/3127041.3131363},
  isbn      = {9781450350938},
  location  = {Vienna, Austria},
  numpages  = {1},
  url       = {https://doi.org/10.1145/3127041.3131363},
}

@InProceedings{Chen2021a,
  author    = {Chen, Ken and He, Jiabei},
  booktitle = {Proceedings of the 2021 9th International Conference on Communications and Broadband Networking},
  title     = {Big-Data-Based Research on the Architecture Design of University Hydropower Intelligent Decision Service Platform},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {1–5},
  publisher = {Association for Computing Machinery},
  series    = {ICCBN '21},
  abstract  = {With the continuous development and wide application of big data and artificial intelligence technology, how to efficiently use and mine the whole process data of university hydropower models, perception, business and flows, and realize the transformation of informationization of hydropower management to intelligentialize and wisdom, it has become one of the main tasks in the construction of universitiy informatization under the strategy of advocating energy conservation, lowcarbon sustainable development. Combining with the actual demand of university hydropower management, managing and serving the whole process of hydropower data collection, storage, analysis, monitoring and decision-making assistance, this paper proposes the architecture of an intelligent decision-making service platform for university hydropower on big data, and sorts out the core and key technologies in the platform development process and the current mainstream development frameworks and tools to provide technical references for the realization of intelligent hydropower management and application services in universities, and promote the overall planning and step-by-step implementation of smart campuses.},
  doi       = {10.1145/3456415.3456416},
  isbn      = {9781450389174},
  keywords  = {hydropower information, big data, intelligentization},
  location  = {Shanghai, China},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3456415.3456416},
}

@Article{Souza2015,
  author     = {Souza, Jeferson L. R. and Rufino, Jos\'{e}},
  journal    = {SIGBED Rev.},
  title      = {The Wi-STARK Architecture for Resilient Real-Time Wireless Communications},
  year       = {2015},
  month      = {jan},
  number     = {4},
  pages      = {61–66},
  volume     = {11},
  abstract   = {Networking communications play an important role to secure a dependable and timely operation of distributed and real-time embedded system applications; however, an effective real-time support is not yet properly addressed in the wireless realm. This paper presents Wi-STARK, a novel architecture for resilient and real-time wireless communications within an one-hop communication domain. Low level reliable (frame) communications, node failure detection, membership management, and networking partition control are provided; since these low level services extend and build upon the exposed interface offered by networking technologies, Wi-STARK is in strict compliance with wireless communication standards, such as IEEE 802.15.4 and IEEE 802.11p. The Wi-STARK service interface is then offered as operating system primitives, helpful for building distributed control applications. The one-hop dependability and timeliness guarantees offered by Wi-STARK are a fundamental step towards an effective design of real-time wireless networks with multiple hops, including end-to-end schedulability analysis of networking operations.},
  address    = {New York, NY, USA},
  doi        = {10.1145/2724942.2724952},
  issue_date = {December 2014},
  keywords   = {timeliness, Wi-STARK, fault tolerance, resilience, wireless communications, dependability, real-time},
  numpages   = {6},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2724942.2724952},
}

@InProceedings{Kaya2019,
  author    = {Kaya, M. Cagri and Karamanlioglu, Alper and \c{C}etinta\c{s}, undefined. \c{C}a\u{g}lar and \c{C}ilden, Erkin and Canberi, Haluk and O\u{g}uzt\"{u}z\"{u}n, Halit},
  booktitle = {Proceedings of the 2019 Summer Simulation Conference},
  title     = {A Configurable Gateway for DDS-HLA Interoperability},
  year      = {2019},
  address   = {San Diego, CA, USA},
  publisher = {Society for Computer Simulation International},
  series    = {SummerSim '19},
  abstract  = {Interoperability is a challenge for constructing Live-Virtual-Constructive (LVC) systems. This study is a step toward LVC interoperability adhering to a gateway-based approach with a particular focus on two standard middleware, namely, Data Distribution Service for Real-Time Systems (DDS) and High-Level Architecture (HLA) for distributed simulation. A gateway is designed and implemented to achieve DDS-HLA interoperability. This gateway has the ability to realize two-way data transfer between DDS and HLA systems. The gateway design is based on the idea of a configurable connector that is equipped with variability capabilities. It can perform data-type conversions between these two systems according to the mappings specified by the user. In a case study, the gateway is integrated into a distributed tactical environment simulation system.},
  articleno = {36},
  keywords  = {high-level architecture, data distribution service, gateway, interoperability},
  location  = {Berlin, Germany},
  numpages  = {11},
}

@InProceedings{Li2021a,
  author    = {Li, Houyi and Chen, Zhihong and Li, Chenliang and Xiao, Rong and Deng, Hongbo and Zhang, Peng and Liu, Yongchao and Tang, Haihong},
  booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  title     = {Path-Based Deep Network for Candidate Item Matching in Recommenders},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {1493–1502},
  publisher = {Association for Computing Machinery},
  series    = {SIGIR '21},
  abstract  = {The large-scale recommender system mainly consists of two stages: matching and ranking. The matching stage (also known as the retrieval step) identifies a small fraction of relevant items from billion-scale item corpus in low latency and computational cost. Item-to-item collaborative filtering (item-based CF) and embedding-based retrieval (EBR) have been long used in the industrial matching stage owing to its efficiency. However, item-based CF is hard to meet personalization, while EBR has difficulty in satisfying diversity. In this paper, we propose a novel matching architecture, Path-based Deep Network (named PDN), through incorporating both personalization and diversity to enhance matching performance. Specifically, PDN is comprised of two modules: Trigger Net and Similarity Net. PDN utilizes Trigger Net to capture the user's interest in each of his/her interacted item. Similarity Net is devised to evaluate the similarity between each interacted item and the target item based on these items' profile and CF information. The final relevance between the user and the target item is calculated by explicitly considering user's diverse interests, ie aggregating the relevance weights of the related two-hop paths (one hop of a path corresponds to user-item interaction and the other to item-item relevance). Furthermore, we describe the architecture design of the proposed PDN in a leading real-world E-Commerce service (Mobile Taobao App). Based on offline evaluations and online A/B test, we show that PDN outperforms the existing solutions for the same task. The online results also demonstrate that PDN can retrieve more personalized and more diverse items to significantly improve user engagement. Currently, PDN system has been successfully deployed at Mobile Taobao App and handling major online traffic.},
  doi       = {10.1145/3404835.3462878},
  isbn      = {9781450380379},
  keywords  = {recommendation systems, deep learning},
  location  = {<conf-loc>, <city>Virtual Event</city>, <country>Canada</country>, </conf-loc>},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3404835.3462878},
}

@InProceedings{Alonso2017,
  author    = {Alonso, Pedro and Catalan, Sandra and Herrero, Jos\'{e} R. and Quintana-Ort\'{\i}, Enrique S. and Rodr\'{\i}guez-S\'{a}nchez, Rafael},
  booktitle = {Proceedings of the 8th International Workshop on Programming Models and Applications for Multicores and Manycores},
  title     = {Reduction to Tridiagonal Form for Symmetric Eigenproblems on Asymmetric Multicore Processors},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {39–47},
  publisher = {Association for Computing Machinery},
  series    = {PMAM'17},
  abstract  = {Asymmetric multicore processors (AMPs), as those present in ARM big.LITTLE technology, have been proposed as a means to address the end of Dennard power scaling law. The idea of these architectures is to activate only the type (and number) of cores that satisfy the quality of service requested by the application(s) in execution while delivering high energy efficiency.For dense linear algebra problems though, performance is of paramount importance, asking for an efficient use of all computational resources in the AMP. In response to this, we investigate how to exploit the asymmetric cores of an ARMv7 big.LITTLE AMP in order to attain high performance for the reduction to tridiagonal form, an essential step towards the solution of dense symmetric eigenvalue problems. The routine for this purpose in LAPACK is especially challenging, since half of its floating-point arithmetic operations (flops) are cast in terms of compute-bound kernels while the remaining half correspond to memory-bound kernels. To deal with this scenario: 1) we leverage a tuned implementation of the compute-bound kernels for AMPs; 2) we develop and parallelize new architecture-aware micro-kernels for the memory-bound kernels; 3) and we carefully adjust the type and number of cores to use at each step of the reduction procedure.},
  doi       = {10.1145/3026937.3026938},
  isbn      = {9781450348836},
  keywords  = {symmetric eigenvalue problem, workload balancing, Condensed forms, asymmetric multicore processors, basic linear algebra subprograms (BLAS), multi-threading},
  location  = {Austin, TX, USA},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3026937.3026938},
}

@Article{Classen2018,
  author     = {Classen, Jiska and Wegemer, Daniel and Patras, Paul and Spink, Tom and Hollick, Matthias},
  journal    = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
  title      = {Anatomy of a Vulnerable Fitness Tracking System: Dissecting the Fitbit Cloud, App, and Firmware},
  year       = {2018},
  month      = {mar},
  number     = {1},
  volume     = {2},
  abstract   = {Fitbit fitness trackers record sensitive personal information, including daily step counts, heart rate profiles, and locations visited. By design, these devices gather and upload activity data to a cloud service, which provides aggregate statistics to mobile app users. The same principles govern numerous other Internet-of-Things (IoT) services that target different applications. As a market leader, Fitbit has developed perhaps the most secure wearables architecture that guards communication with end-to-end encryption. In this article, we analyze the complete Fitbit ecosystem and, despite the brand's continuous efforts to harden its products, we demonstrate a series of vulnerabilities with potentially severe implications to user privacy and device security. We employ a range of techniques, such as protocol analysis, software decompiling, and both static and dynamic embedded code analysis, to reverse engineer previously undocumented communication semantics, the official smartphone app, and the tracker firmware. Through this interplay and in-depth analysis, we reveal how attackers can exploit the Fitbit protocol to extract private information from victims without leaving a trace, and wirelessly flash malware without user consent. We demonstrate that users can tamper with both the app and firmware to selfishly manipulate records or circumvent Fitbit's walled garden business model, making the case for an independent, user-controlled, and more secure ecosystem. Finally, based on the insights gained, we make specific design recommendations that can not only mitigate the identified vulnerabilities, but are also broadly applicable to securing future wearable system architectures.},
  address    = {New York, NY, USA},
  articleno  = {5},
  doi        = {10.1145/3191737},
  issue_date = {March 2018},
  keywords   = {Wearables, firmware reverse engineering, Nexmon, health},
  numpages   = {24},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3191737},
}

@InProceedings{Avino2017,
  author    = {Avino, G. and Malinverno, M. and Malandrino, F. and Casetti, C. and Chiasserini, C. F.},
  booktitle = {Proceedings of the Workshop on Hot Topics in Container Networking and Networked Systems},
  title     = {Characterizing Docker Overhead in Mobile Edge Computing Scenarios},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {30–35},
  publisher = {Association for Computing Machinery},
  series    = {HotConNet '17},
  abstract  = {Mobile Edge Computing (MEC) is an emerging network paradigm that provides cloud and IT services at the point of access of the network. Such proximity to the end user translates into ultra-low latency and high bandwidth, while, at the same time, it alleviates traffic congestion in the network core. Due to the need to run servers on edge nodes (e.g., an LTE-A macro eNodeB), a key element of MEC architectures is to ensure server portability and low overhead. A possible tool that can be used for this purpose is Docker, a framework that allows easy, fast deployment of Linux containers. This paper addresses the suitability of Docker in MEC scenarios by quantifying the CPU consumed by Docker when running two different containerized services: multiplayer gaming and video streaming. Our tests, run with varying numbers of clients and servers, yield different results for the two case studies: for the gaming service, the overhead logged by Docker increases only with the number of servers; conversely, for the video streaming case, the overhead is not affected by the number of either clients or servers.},
  doi       = {10.1145/3094405.3094411},
  isbn      = {9781450350587},
  keywords  = {Mobile Edge Computing, 5G networks, Containers, Docker},
  location  = {Los Angeles, CA, USA},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3094405.3094411},
}

@InProceedings{Giovanetti2016,
  author    = {Giovanetti, Romain and Lancieri, Luigi},
  booktitle = {Proceedings of the 2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
  title     = {Model of Computer Architecture for Online Social Networks Flexible Data Analysis: The Case of Twitter Data},
  year      = {2016},
  address   = {Davis, California},
  pages     = {677–684},
  publisher = {IEEE Press},
  series    = {ASONAM '16},
  abstract  = {Since several years, there is an increasing interest for new services based on the analysis of data coming from online social networks. Such services can, for example, provide the e-reputation of a product or a company, detect new trends in a commercial, social or political context, etc. The huge quantity of data is an opportunity in term of representativeness but is also difficult to manage. Within Twitter, for example, it appears that the huge stream of data is, most of the time, incompatible with a flexible analysis unless to have high computer resources. The only practical solution is often to observe in a static way a limited portion of a phenomenon in a limited time slot. This paper is devoted to the study of necessary conditions to provide an equilibrium between the computer architecture complexity and the analysis flexibility.},
  isbn      = {9781509028467},
  keywords  = {computer architecture, platform, distributed database, flexible data analysis, online social network, Twitter},
  numpages  = {8},
}

@InProceedings{Schomp2020,
  author    = {Schomp, Kyle and Bhardwaj, Onkar and Kurdoglu, Eymen and Muhaimen, Mashooq and Sitaraman, Ramesh K.},
  booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
  title     = {Akamai DNS: Providing Authoritative Answers to the World's Queries},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {465–478},
  publisher = {Association for Computing Machinery},
  series    = {SIGCOMM '20},
  abstract  = {We present Akamai DNS, one of the largest authoritative DNS infrastructures in the world, that supports the Akamai content delivery network (CDN) as well as authoritative DNS hosting and DNS-based load balancing services for many enterprises. As the starting point for a significant fraction of the world's Internet interactions, Akamai DNS serves millions of queries each second and must be resilient to avoid disrupting myriad online services, scalable to meet the ever increasing volume of DNS queries, performant to prevent user-perceivable performance degradation, and reconfigurable to react quickly to shifts in network conditions and attacks. We outline the design principles and architecture used to achieve Akamai DNS's goals, relating the design choices to the system workload and quantifying the effectiveness of those designs. Further, we convey insights from operating the production system that are of value to the broader research community.},
  doi       = {10.1145/3387514.3405881},
  isbn      = {9781450379557},
  keywords  = {DNS, Distributed Systems},
  location  = {Virtual Event, USA},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3387514.3405881},
}

@InProceedings{DiStefano2019,
  author    = {Di Stefano, Alessandro and Scat\`{a}, Marialisa and La Corte, Aurelio and Das, Sajal K. and Li\`{o}, Pietro},
  booktitle = {Proceedings of the Fourth International Workshop on Social Sensing},
  title     = {Improving QoE in Multi-Layer Social Sensing: A Cognitive Architecture and Game Theoretic Model},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {18–23},
  publisher = {Association for Computing Machinery},
  series    = {SocialSense'19},
  abstract  = {This paper proposes a novel cognitive architecture and game-theoretic model for resource sharing among netizens, thus improving their quality of experience (QoE) in multi-layer social sensing environments. The underlying approach is to quantify micro-rewards and inequalities derived from social multi-layer interactions. Specifically, we model our society as a social multi-layer network of individuals or groups of individuals (nodes), where the layers represent multiple channels of interactions (on various services). The weighted edges correspond to the multiple social relationships between nodes participating in different services, reflecting the importance assigned to each of these edges and are defined based on the concepts of awareness and homophily. Heterogeneity, both interactions-wise on the multiple layers and related to homophily between individuals, on each node and layer of a weighted multiplex network produces a complex multi-scale interplay between nodes in the multi-layer structure. Applying game theory, we quantify the impact of heterogeneity on the evolutionary dynamics of social sensing through a data driven approach based on the propagation of individual-level micro-affirmations and micro-inequalities. The micro-packets of energy continuously exchanged between nodes may impact positively or negatively on their social behaviors, producing peaks of extreme dissatisfaction and in some cases a form of distress. Quantifying the evolutionary dynamics of human behaviors enables the detection of such peaks in the population and enable us design a targeted control mechanism, where social rewards and self-healing help improve the QoE of the netizens.},
  doi       = {10.1145/3313294.3313384},
  isbn      = {9781450367066},
  keywords  = {game theory, social sensing, Cognitive architecture, IoP, QoE, multi-layer networks},
  location  = {Montreal, QC, Canada},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3313294.3313384},
}

@Article{Chiosa2021,
  author     = {Chiosa, Monica and Preu\ss{}er, Thomas B. and Alonso, Gustavo},
  journal    = {Proc. VLDB Endow.},
  title      = {SKT: A One-Pass Multi-Sketch Data Analytics Accelerator},
  year       = {2021},
  issn       = {2150-8097},
  month      = {jul},
  number     = {11},
  pages      = {2369–2382},
  volume     = {14},
  abstract   = {Data analysts often need to characterize a data stream as a first step to its further processing. Some of the initial insights to be gained include, e.g., the cardinality of the data set and its frequency distribution. Such information is typically extracted by using sketch algorithms, now widely employed to process very large data sets in manageable space and in a single pass over the data. Often, analysts need more than one parameter to characterize the stream. However, computing multiple sketches becomes expensive even when using high-end CPUs. Exploiting the increasing adoption of hardware accelerators, this paper proposes SKT, an FPGA-based accelerator that can compute several sketches along with basic statistics (average, max, min, etc.) in a single pass over the data. SKT has been designed to characterize a data set by calculating its cardinality, its second frequency moment, and its frequency distribution. The design processes data streams coming either from PCIe or TCP/IP, and it is built to fit emerging cloud service architectures, such as Microsoft's Catapult or Amazon's AQUA. The paper explores the trade-offs of designing sketch algorithms on a spatial architecture and how to combine several sketch algorithms into a single design. The empirical evaluation shows how SKT on an FPGA offers a significant performance gain over high-end, server-class CPUs.},
  doi        = {10.14778/3476249.3476287},
  issue_date = {July 2021},
  numpages   = {14},
  publisher  = {VLDB Endowment},
  url        = {https://doi.org/10.14778/3476249.3476287},
}

@InProceedings{Mansour2016,
  author    = {Mansour, Ibrahim and Sahandi, Reza and Cooper, Kendra and Warman, Adrian},
  booktitle = {Proceedings of the International Conference on Internet of Things and Cloud Computing},
  title     = {Interoperability in the Heterogeneous Cloud Environment: A Survey of Recent User-Centric Approaches},
  year      = {2016},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ICC '16},
  abstract  = {Cloud computing provides users the ability to access shared, online computing resources. However, providers often offer their own proprietary applications, interfaces, APIs and infrastructures, resulting in a heterogeneous cloud environment. This heterogeneous environment makes it difficult for users to change cloud service providers; exploring capabilities to support the automated migration from one provider to another is an active, open research area. Many standards bodies (IEEE, NIST, DMTF and SNIA), industry (middleware) and academia have been pursuing approaches to reduce the impact of vendor lock-in by investigating the cloud migration problem at the level of the VM. However, the migration downtime, decoupling VM from underlying systems and security of live channels remain open issues. This paper focuses on analysing recently proposed live, cloud migration approaches for VMs at the infrastructure level in the cloud architecture. The analysis reveals issues with flexibility, performance, and security of the approaches, including additional loads to the CPU and disk I/O drivers of the physical machine where the VM initially resides. The next steps of this research are to develop and evaluate a new approach LibZam (Libya Zamzem) that will work towards addressing the identified limitations.},
  articleno = {62},
  doi       = {10.1145/2896387.2896447},
  isbn      = {9781450340632},
  keywords  = {Cloud Architecture, Software Defined Network, Cloud Computing, Cloud Migration, Network Function Virtualization, Cloud Interoperability, VM Live Migration, Cloud Infrastructure},
  location  = {Cambridge, United Kingdom},
  numpages  = {7},
  url       = {https://doi.org/10.1145/2896387.2896447},
}

@Article{Formiga2015,
  author     = {Formiga, Llu\'{\i}s and Barr\'{o}n-Cede\~{n}o, Alberto and M\`{a}rquez, Llu\'{\i}s and Henr\'{\i}quez, Carlos A. and Mari\~{n}o, Jos\'{e} B.},
  journal    = {J. Artif. Int. Res.},
  title      = {Leveraging Online User Feedback to Improve Statistical Machine Translation},
  year       = {2015},
  issn       = {1076-9757},
  month      = {sep},
  number     = {1},
  pages      = {159–192},
  volume     = {54},
  abstract   = {In this article we present a three-step methodology for dynamically improving a statistical machine translation (SMT) system by incorporating human feedback in the form of free edits on the system translations. We target at feedback provided by casual users, which is typically error-prone. Thus, we first propose a filtering step to automatically identify the better user-edited translations and discard the useless ones. A second step produces a pivot-based alignment between source and user-edited sentences, focusing on the errors made by the system. Finally, a third step produces a new translation model and combines it linearly with the one from the original system. We perform a thorough evaluation on a real-world dataset collected from the Reverso.net translation service and show that every step in our methodology contributes significantly to improve a general purpose SMT system. Interestingly, the quality improvement is not only due to the increase of lexical coverage, but to a better lexical selection, reordering, and morphology. Finally, we show the robustness of the methodology by applying it to a different scenario, in which the new examples come from an automatically Web-crawled parallel corpus. Using exactly the same architecture and models provides again a significant improvement of the translation quality of a general purpose baseline SMT system.},
  address    = {El Segundo, CA, USA},
  issue_date = {September 2015},
  numpages   = {34},
  publisher  = {AI Access Foundation},
}

@InProceedings{Landwehr2019,
  author    = {Landwehr, Marvin and Borning, Alan and Wulf, Volker},
  booktitle = {Proceedings of the Fifth Workshop on Computing within Limits},
  title     = {The High Cost of Free Services: Problems with Surveillance Capitalism and Possible Alternatives for IT Infrastructure},
  year      = {2019},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {LIMITS '19},
  abstract  = {A large portion of the software side of our information technology infrastructure, including web search, email, social media, transportation information, and much more, is provided "free" to the end users, although the corporations that provide this are often enormously profitable. The business model involves customized advertising and behavior manipulation, powered by intensive gathering and cross-correlation of personal information. Significant other parts of our IT infrastructure use fees-for-service but still involve intensive information gathering and behavior manipulation. There are significant indirect costs of these business models, including loss of privacy, supporting surveillance by both corporations and the state, automated manipulations of behavior, undermining the democratic process, and consumerism with its attendant environmental costs. In a recent book, Shoshana Zuboff terms this "surveillance capitalism." Our primary focus in this essay is how we could develop new models for providing these services. We describe some intermediate steps toward those models: education, regulation, and resistance. Following that, we discuss a partial solution, involving for-profit corporations that provide these services without tracking personal information. Finally, we describe desired characteristics for more comprehensive solutions, and outline a range of such solutions for different portions of the IT infrastructure that more truly return control to the end users. A common feature of several is the use of highly decentralized storage of information (either on the end user's own personal devices or on small servers), a modular architecture and interface to allow for customization of what information is to be shared, and a distributed ledger mechanism for authentication.},
  articleno = {3},
  doi       = {10.1145/3338103.3338106},
  isbn      = {9781450372817},
  keywords  = {economics, advertising, surveillance capitalism, political manipulation, manipulation of behavior, digital infrastructure, IT business models},
  location  = {Lappeenranta, Finland},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3338103.3338106},
}

@InProceedings{Zhang2021,
  author    = {Zhang, Zhi-Li and Dayalan, Udhaya Kumar and Ramadan, Eman and Salo, Timothy J.},
  booktitle = {Proceedings of the ACM SIGCOMM 2021 Workshop on Network-Application Integration},
  title     = {Towards a Software-Defined, Fine-Grained QoS Framework for 5G and Beyond Networks},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {7–13},
  publisher = {Association for Computing Machinery},
  series    = {NAI'21},
  abstract  = {5G offers a slew of new features and capabilities to support a whole gamut of new applications. On the other hand, 5G new radio (NR), especially, high-band mmWave radio, also poses new challenges, as shown by recent measurement studies of commercial 5G services. In order to effectively support new classes of application such as extra low-latency and/or high-bandwidth applications, we argue that truly cross-layer network-application integration that exposes application semantics to enable 5G and beyond 5G (B5G) networks to make intelligent decisions, e.g., for dynamic radio resource allocation, is needed. Unfortunately the existing 5G flow-based framework is inadequate to support such cross-layer integration. We therefore advocate a software-defined, fine-grained QoS framework. We use ultra-high resolution (UHR) volumetric video streaming as a use case and conduct very preliminary experiments to demonstrate the potential benefits of the proposed framework. This position paper serves as a strawman to call for new intelligent architectural designs for B5G networks and next-generation wireless systems.},
  doi       = {10.1145/3472727.3472798},
  isbn      = {9781450386333},
  keywords  = {software -defined, application semantics, fine-grained, 5G and beyond, QoS framework},
  location  = {Virtual Event, USA},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3472727.3472798},
}

@InProceedings{Jaradat2017,
  author    = {Jaradat, Shatha},
  booktitle = {Proceedings of the Eleventh ACM Conference on Recommender Systems},
  title     = {Deep Cross-Domain Fashion Recommendation},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {407–410},
  publisher = {Association for Computing Machinery},
  series    = {RecSys '17},
  abstract  = {With the increasing number of online shopping services, the number of users and the quantity of visual and textual information on the Internet, there is a pressing need for intelligent recommendation systems that analyze the user's behavior amongst multiple domains and help them to find the desirable information without the burden of search. However, there is little research that has been done on complex recommendation scenarios that involve knowledge transfer across multiple domains. This problem is especially challenging when the involved data sources are complex in terms of the limitations on the quantity and quality of data that can be crawled. The goal of this paper is studying the connection between visual and textual inputs for better analysis of a certain domain, and to examine the possibility of knowledge transfer from complex domains for the purpose of efficient recommendations. The methods employed to achieve this study include both design of architecture and algorithms using deep learning technologies to analyze the effect of deep pixel-wise semantic segmentation and text integration on the quality of recommendations. We plan to develop a practical testing environment in a fashion domain.},
  doi       = {10.1145/3109859.3109861},
  isbn      = {9781450346528},
  keywords  = {cnn, transfer learning, deep learning, fashion recommendation, domain adaptation, cross-domain knowledge transfer},
  location  = {Como, Italy},
  numpages  = {4},
  url       = {https://doi.org/10.1145/3109859.3109861},
}

@InProceedings{Edeline2020,
  author    = {Edeline, Korian and Donnet, Benoit},
  booktitle = {Proceedings of the Applied Networking Research Workshop},
  title     = {Evaluating the Impact of Path Brokenness on TCP Options},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {38–44},
  publisher = {Association for Computing Machinery},
  series    = {ANRW '20},
  abstract  = {In-path network functions enforcing policies like firewalls, IDSes, NATs, and TCP enhancing proxies are ubiquitous. They are deployed in various types of networks and bring obvious value to the Internet.Unfortunately, they also break important architectural principles and, consequently, make the Internet less flexible by preventing the use of advanced protocols, features, or options. In some scenarios, feature-disabling middlebox policies can lead to a performance shortfall. Moreover, middleboxes are also prone to enforce policies that disrupt transport control mechanisms, which can also have direct consequences in term of Quality-of-Service (QoS).In this paper, we investigate the impact of the most prevalent in-path impairments on the TCP protocol and its features. Using network experiments in a controlled environment, we quantify the QoS decreases and shortfall induced by feature-breaking middleboxes, and show that even in the presence of a fallback mechanism, TCP QoS remains affected.},
  doi       = {10.1145/3404868.3406662},
  isbn      = {9781450380393},
  location  = {Virtual Event, Spain},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3404868.3406662},
}

@InProceedings{Michalakis2017,
  author    = {Michalakis, Konstantinos and Aliprantis, John and Caridakis, George},
  booktitle = {Proceedings of the 2017 ACM Workshop on Interacting with Smart Objects},
  title     = {Intelligent Visual Interface with the Internet of Things},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {27–30},
  publisher = {Association for Computing Machinery},
  series    = {SmartObject '17},
  abstract  = {Communication between users and physical objects and sensors through the web within the Internet of Things framework, requires by definition the capability to perceive the sensors and the underlying information and services. Visualization of the Things in IoT is thus a requirement for natural interaction between users and IoT instances in the upcoming but steadily established computing paradigm. The immense quantity of sensors and variety of usable information introduces the need to intelligently filter and adapt the respective information sources and layers. Current work proposes an architecture that supports intelligent interaction between users and the IoT addressing the intelligent perception requirement described earlier. On the one hand, sensory visualization is tackled via Augmented Reality layers of sensors and information and on the other hand context and location awareness enhance the system by providing usable in the respective senses information.},
  doi       = {10.1145/3038450.3038452},
  isbn      = {9781450349024},
  keywords  = {context awareness, markerless tracking, natural interaction, augmented reality, internet of things},
  location  = {Limassol, Cyprus},
  numpages  = {4},
  url       = {https://doi.org/10.1145/3038450.3038452},
}

@Article{Yue2015,
  author     = {Yue, Tao and Briand, Lionel C. and Labiche, Yvan},
  journal    = {ACM Trans. Softw. Eng. Methodol.},
  title      = {AToucan: An Automated Framework to Derive UML Analysis Models from Use Case Models},
  year       = {2015},
  issn       = {1049-331X},
  month      = {may},
  number     = {3},
  volume     = {24},
  abstract   = {The transition from an informal requirements specification in natural language to a structured, precise specification is an important challenge in practice. It is particularly so for object-oriented methods, defined in the context of the OMG's Model Driven Architecture (MDA), where a key step is to transition from a use case model to an analysis model. However, providing automated support for this transition is challenging, mostly because, in practice, requirements are expressed in natural language and are much less structured than other kinds of development artifacts. Such an automated transformation would enable at least the generation of an initial, likely incomplete, analysis model and enable automated traceability from requirements to code, through various intermediate models. In this article, we propose a method and a tool called aToucan, building on existing work, to automatically generate a UML analysis model comprising class, sequence and activity diagrams from a use case model and to automatically establish traceability links between model elements of the use case model and the generated analysis model. Note that our goal is to save effort through automated support, not to replace human abstraction and decision making.Seven (six) case studies were performed to compare class (sequence) diagrams generated by aToucan to the ones created by experts, Masters students, and trained, fourth-year undergraduate students. Results show that aToucan performs well regarding consistency (e.g., 88\% class diagram consistency) and completeness (e.g., 80\% class completeness) when comparing generated class diagrams with reference class diagrams created by experts and Masters students. Similarly, sequence diagrams automatically generated by aToucan are highly consistent with the ones devised by experts and are also rather complete, for instance, 91\% and 97\% message consistency and completeness, respectively. Further, statistical tests show that aToucan significantly outperforms fourth-year engineering students in this respect, thus demonstrating the value of automation. We also conducted two industrial case studies demonstrating the applicability of aToucan in two different industrial domains. Results showed that the vast majority of model elements generated by aToucan are correct and that therefore, in practice, such models would be good initial models to refine and augment so as to converge towards to correct and complete analysis models. A performance analysis shows that the execution time of aToucan (when generating class and sequence diagrams) is dependent on the number of simple sentences contained in the use case model and remains within a range of a few minutes. Five different software system descriptions (18 use cases altogether) were performed to evaluate the generation of activity diagrams. Results show that aToucan can generate 100\% complete and correct control flow information of activity diagrams and on average 85\% data flAow information completeness. Moreover, we show that aToucan outperforms three commercial tools in terms of activity diagram generation.},
  address    = {New York, NY, USA},
  articleno  = {13},
  doi        = {10.1145/2699697},
  issue_date = {May 2015},
  keywords   = {sequence diagram, traceability, analysis model, automation, Use case modeling, class diagram, activity diagram, transformation, UML},
  numpages   = {52},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2699697},
}

@InProceedings{EspinhaGasiba2021,
  author    = {Espinha Gasiba, Tiago and Andrei-Cristian, Iosif and Lechner, Ulrike and Pinto-Albuquerque, Maria},
  booktitle = {Proceedings of the 16th International Conference on Availability, Reliability and Security},
  title     = {Raising Security Awareness of Cloud Deployments Using Infrastructure as Code through CyberSecurity Challenges},
  year      = {2021},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ARES '21},
  abstract  = {Improper deployment of software can have serious consequences, ranging from simple downtime to permanent data loss and data breaches. Infrastructure as Code tools serve to streamline delivery by promising consistency and speed, by abstracting away from the underlying actions. However, this simplicity may distract from architectural or configuration faults, potentially compromising the secure development lifecycle. One way to address this issue involves awareness training. Sifu is a platform that provides education on security through serious games, developed in the industry, for the industry. The presented work extends the Sifu platform with challenges addressing Terraform-aided cloud deployment on Amazon Web Services. This paper proposes an evaluation pipeline behind the challenges, and provides details of the vulnerability detection and feedback mechanisms, as well as a novel technique for detecting undesired differences between a given architecture and a target result. Furthermore, this paper quantifies the challenges’ perceived usefulness and impact, by evaluating the challenges among a total of twelve participants. Our preliminary results show that the challenges are suitable for education and the industry, with potential usage in internal training. A key finding is that, although the participants understand the importance of secure coding, their answers indicate that universities leave them unprepared in this area. Finally, our results are compared with related industry works, to extract and provide good practices and advice for practitioners.},
  articleno = {63},
  doi       = {10.1145/3465481.3470030},
  isbn      = {9781450390514},
  keywords  = {Serious Games, Secure Coding, Infrastructure as Code, Training, Awareness, DevSecOps, CyberSecurity Challenges},
  location  = {Vienna, Austria},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3465481.3470030},
}

@InProceedings{Llewellynn2017,
  author    = {Llewellynn, Tim and Fern\'{a}ndez-Carrobles, M. Milagro and Deniz, Oscar and Fricker, Samuel and Storkey, Amos and Pazos, Nuria and Velikic, Gordana and Leufgen, Kirsten and Dahyot, Rozenn and Koller, Sebastian and Goumas, Georgios and Leitner, Peter and Dasika, Ganesh and Wang, Lei and Tutschku, Kurt},
  booktitle = {Proceedings of the Computing Frontiers Conference},
  title     = {BONSEYES: Platform for Open Development of Systems of Artificial Intelligence: Invited Paper},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {299–304},
  publisher = {Association for Computing Machinery},
  series    = {CF'17},
  abstract  = {The Bonseyes EU H2020 collaborative project aims to develop a platform consisting of a Data Marketplace, a Deep Learning Toolbox, and Developer Reference Platforms for organizations wanting to adopt Artificial Intelligence. The project will be focused on using artificial intelligence in low power Internet of Things (IoT) devices ("edge computing"), embedded computing systems, and data center servers ("cloud computing"). It will bring about orders of magnitude improvements in efficiency, performance, reliability, security, and productivity in the design and programming of systems of artificial intelligence that incorporate Smart Cyber-Physical Systems (CPS). In addition, it will solve a causality problem for organizations who lack access to Data and Models. Its open software architecture will facilitate adoption of the whole concept on a wider scale. To evaluate the effectiveness, technical feasibility, and to quantify the real-world improvements in efficiency, security, performance, effort and cost of adding AI to products and services using the Bonseyes platform, four complementary demonstrators will be built. Bonseyes platform capabilities are aimed at being aligned with the European FI-PPP activities and take advantage of its flagship project FIWARE. This paper provides a description of the project motivation, goals and preliminary work.},
  doi       = {10.1145/3075564.3076259},
  isbn      = {9781450344876},
  keywords  = {Internet of things, Deep Learning, Smart Cyber-Physical Systems, Data marketplace},
  location  = {Siena, Italy},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3075564.3076259},
}

@InProceedings{Bokhari2015,
  author    = {Bokhari, Haseeb and Javaid, Haris and Shafique, Muhammad and Henkel, J\"{o}rg and Parameswaran, Sri},
  booktitle = {Proceedings of the 52nd Annual Design Automation Conference},
  title     = {SuperNet: Multimode Interconnect Architecture for Manycore Chips},
  year      = {2015},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {DAC '15},
  abstract  = {Designers of the on-chip interconnect for manycore chips are faced with the dilemma of meeting performance, power and reliability requirements for different operational scenarios. In this paper, we propose a multimode on-chip interconnect called SuperNet. This interconnect can be configured to run in three different modes: energy efficient mode; performance mode; and, reliability mode. Our proposed interconnect is based on two parallel multi-vt optimized packet switched network-on-chip (NoC) meshes. We describe the circuit design techniques and architectural modifications required to realize such a multimode interconnect. Our evaluation with diverse set of applications show that the energy efficient mode can save on average 40\% NoC power, whereas the performance mode can improve the core IPC by up to 13\% on selected high MPKI applications. The reliability mode provides protection against soft errors in the router's data path through byte oriented SECDED codes that can correct up to 8 bit errors and detect up to 16 bit errors in a 64 bit flit, whereas the router's control path is protected through DMR lock step execution.},
  articleno = {85},
  doi       = {10.1145/2744769.2744912},
  isbn      = {9781450335201},
  keywords  = {power optimization, fault tolerance, performance, network-on-chip, multimode},
  location  = {San Francisco, California},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2744769.2744912},
}

@InProceedings{Fang2017b,
  author    = {Fang, Yuanwei and Zou, Chen and Elmore, Aaron J. and Chien, Andrew A.},
  booktitle = {Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture},
  title     = {UDP: A Programmable Accelerator for Extract-Transform-Load Workloads and More},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {55–68},
  publisher = {Association for Computing Machinery},
  series    = {MICRO-50 '17},
  abstract  = {Big data analytic applications give rise to large-scale extract-transform-load (ETL) as a fundamental step to transform new data into a native representation. ETL workloads pose significant performance challenges on conventional architectures, so we propose the design of the unstructured data processor (UDP), a software programmable accelerator that includes multi-way dispatch, variable-size symbol support, Flexible-source dispatch (stream buffer and scalar registers), and memory addressing to accelerate ETL kernels both for current and novel future encoding and compression. Specifically, UDP excels at branch-intensive and symbol and pattern-oriented workloads, and can offload them from CPUs.To evaluate UDP, we use a broad set of data processing workloads inspired by ETL, but broad enough to also apply to query execution, stream processing, and intrusion detection/monitoring. A single UDP accelerates these data processing tasks 20-fold (geometric mean, largest increase from 0.4 GB/s to 40 GB/s) and performance per watt by a geomean of 1,900-fold. UDP ASIC implementation in 28nm CMOS shows UDP logic area of 3.82mm2 (8.69mm2 with 1MB local memory), and logic power of 0.149W (0.864W with 1MB local memory); both much smaller than a single core.},
  doi       = {10.1145/3123939.3123983},
  isbn      = {9781450349529},
  keywords  = {control-flow accelerator, data analytics, parsing, data encoding and transformation, compression},
  location  = {Cambridge, Massachusetts},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3123939.3123983},
}

@InProceedings{Lachmann2017,
  author    = {Lachmann, Remo and Beddig, Simon and Lity, Sascha and Schulze, Sandro and Schaefer, Ina},
  booktitle = {Proceedings of the 11th International Workshop on Variability Modelling of Software-Intensive Systems},
  title     = {Risk-Based Integration Testing of Software Product Lines},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {52–59},
  publisher = {Association for Computing Machinery},
  series    = {VaMoS '17},
  abstract  = {Software product lines (SPL) capture commonalities and variabilities of product families and, thus, enable mass customization of product variants according to customers desired configurations. However, they introduce new challenges to software testing due to a potentially large number of variants. While each variant should be tested, testing resources are limited and, thus, a retest of all, partially redundant, test cases for each variant is not feasible in SPL testing. Coping with these issues has been a major research focus in recent years, leading to different testing approaches. However, risk-based testing has not gained much attention in the SPL domain while being a successful approach for single-software systems. In this paper, we propose a novel risk-based testing approach for SPL integration testing. We incrementally test SPLs by stepping from one variant to the next. For each variant, we automatically compute failure probabilities and failure impacts for its architectural components. To avoid a computational overhead of generating and analyzing each variant, we exploit the variability between variants defined as deltas to focus on important changes. We evaluate our approach using an automotive case study, showing that the risk-based technique leads to positive results compared to random and delta-oriented testing.},
  doi       = {10.1145/3023956.3023958},
  isbn      = {9781450348119},
  keywords  = {model-based testing, risk-based testing, software product lines, test case prioritization},
  location  = {Eindhoven, Netherlands},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3023956.3023958},
}

@Article{Tang2019,
  author     = {Tang, Yibin and Wang, Ying and Li, Huawei and Li, Xiaowei},
  journal    = {J. Emerg. Technol. Comput. Syst.},
  title      = {MV-Net: Toward Real-Time Deep Learning on Mobile GPGPU Systems},
  year       = {2019},
  issn       = {1550-4832},
  month      = {oct},
  number     = {4},
  volume     = {15},
  abstract   = {Recently the development of deep learning has been propelling the sheer growth of vision and speech applications on lightweight embedded and mobile systems. However, the limitation of computation resource and power delivery capability in embedded platforms is recognized as a significant bottleneck that prevents the systems from providing real-time deep learning ability, since the inference of deep convolutional neural networks (CNNs) and recurrent neural networks (RNNs) involves large quantities of weights and operations. Particularly, how to provide quality-of-services (QoS)-guaranteed neural network inference ability in the multitask execution environment of multicore SoCs is even more complicated due to the existence of resource contention. In this article, we present a novel deep neural network architecture, MV-Net, which provides performance elasticity and contention-aware self-scheduling ability for QoS enhancement in mobile computing systems. When the constraints of QoS, output accuracy, and resource contention status of the system change, MV-Net can dynamically reconfigure the corresponding neural network propagation paths and thus achieves an effective tradeoff between neural network computational complexity and prediction accuracy via approximate computing. The experimental results show that (1) MV-Net significantly improves the performance flexibility of current CNN models and makes it possible to provide always-guaranteed QoS in a multitask environment, and (2) it satisfies the quality-of-results (QoR) requirement, outperforming the baseline implementation significantly, and improves the system energy efficiency at the same time.},
  address    = {New York, NY, USA},
  articleno  = {35},
  doi        = {10.1145/3358696},
  issue_date = {October 2019},
  keywords   = {deep learning, online scheduling, energy efficiency, approximate computing, Edge computing},
  numpages   = {25},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3358696},
}

@Article{Koutsoukos2021,
  author     = {Koutsoukos, Dimitrios and M\"{u}ller, Ingo and Marroqu\'{\i}n, Renato and Klimovic, Ana and Alonso, Gustavo},
  journal    = {Proc. VLDB Endow.},
  title      = {Modularis: Modular Relational Analytics over Heterogeneous Distributed Platforms},
  year       = {2021},
  issn       = {2150-8097},
  month      = {sep},
  number     = {13},
  pages      = {3308–3321},
  volume     = {14},
  abstract   = {The enormous quantity of data produced every day together with advances in data analytics has led to a proliferation of data management and analysis systems. Typically, these systems are built around highly specialized monolithic operators optimized for the underlying hardware. While effective in the short term, such an approach makes the operators cumbersome to port and adapt, which is increasingly required due to the speed at which algorithms and hardware evolve. To address this limitation, we present Modularis, an execution layer for data analytics based on sub-operators, i.e., composable building blocks resembling traditional database operators but at a finer granularity. To demonstrate the feasibility and advantages of our approach, we use Modularis to build a distributed query processing system supporting relational queries running on an RDMA cluster, a serverless cloud platform, and a smart storage engine. Modularis requires minimal code changes to execute queries across these three diverse hardware platforms, showing that the sub-operator approach reduces the amount and complexity of the code to maintain. In fact, changes in the platform affect only those sub-operators that depend on the underlying hardware (in our use cases, mainly the sub-operators related to network communication). We show the end-to-end performance of Modularis by comparing it with a framework for SQL processing (Presto), a commercial cluster database (SingleStore), as well as Query-as-a-Service systems (Athena, BigQuery). Modularis outperforms all these systems, proving that the design and architectural advantages of a modular design can be achieved without degrading performance. We also compare Modularis with a hand-optimized implementation of a join for RDMA clusters. We show that Modularis has the advantage of being easily extensible to a wider range of join variants and group by queries, all of which are not supported in the hand-tuned join.},
  doi        = {10.14778/3484224.3484229},
  issue_date = {September 2021},
  numpages   = {14},
  publisher  = {VLDB Endowment},
  url        = {https://doi.org/10.14778/3484224.3484229},
}

@InProceedings{Park2015,
  author    = {Park, Junseok and Choo, Sungji and Lee, Doheon},
  booktitle = {Proceedings of the ACM Ninth International Workshop on Data and Text Mining in Biomedical Informatics},
  title     = {Citizen Organization System for Advanced MEDical Research (COSAMED)},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {23},
  publisher = {Association for Computing Machinery},
  series    = {DTMBIO '15},
  abstract  = {Analyzing true effect of medicine or functional food is major issue in associated research area. In order to achieve that, gathering of massive clinical trial data is required. There are three major concepts for clinical trial data collection: Citizen Science, Health 2.0 and Crowdsourcing. Citizen Science, which uses web 2.0 technologies, is web-based service for health care. Health 2.0 uses non-professionally trained individuals to conduct science-related activities. Lastly, Crowdsourcing is an online distributed problem-solving and production model. Following systems have tried to process data based on above concepts. PatientsLikeme attempted to find potential benefits from clinical outcomes within longitudinal evaluation of online data-sharing platforms. ResearchKit is about to create apps that could revolutionize medical studies. However, these systems do not have reliable protocols to obtain credible results. In addition, they mainly focus on diseases with a medicine, not on effect with a functional food.Hereby, we are developing a novel system to solve the issues: Citizen Organization System for Advanced MEDical research(COSAMED). We are looking forward to find true effect information of a functional food with our new system. COSAMED is made of five steps to design a reliable protocol. (1) Target Item Selection, to select a target effect and effect related items. (2) Preparation of Research, to select designed clinical trial protocol on user demand with automated scientific criteria. (3) Recruiting Participants, to recruit participants from linked SNS friends or from other systems. (4) Data Collection, to collect effect information from various sources. (5) Analysis, to analyze the results by web-bases statistical tools, transfer results to a data warehouse and calculate credibility rate. Finally, the protocol is developed with product DB and clinical trial protocol snapshot DB on COSAMED. In future, we will integrate it with Openmhealth architecture to connect related systems easily and build it with user friendly interfaces to collect big data. COSAMED will be available at www.cosamed.org, and it will be a cornerstone of first citizen based clinical trial system.},
  doi       = {10.1145/2811163.2811174},
  isbn      = {9781450337878},
  keywords  = {web based system, functional food, clinical trial protocol, citizen science, open source, health 2.0, crowdsourcing},
  location  = {Melbourne, Australia},
  numpages  = {1},
  url       = {https://doi.org/10.1145/2811163.2811174},
}

@Article{Wang2015a,
  author     = {Wang, Jianxin and Zhong, Jiancheng and Chen, Gang and Li, Min and Wu, Fang-xiang and Pan, Yi},
  journal    = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
  title      = {ClusterViz: A Cytoscape APP for Cluster Analysis of Biological Network},
  year       = {2015},
  issn       = {1545-5963},
  month      = {jul},
  number     = {4},
  pages      = {815–822},
  volume     = {12},
  abstract   = {Cluster analysis of biological networks is one of the most important approaches for identifying functional modules and predicting protein functions. Furthermore, visualization of clustering results is crucial to uncover the structure of biological networks. In this paper, ClusterViz, an APP of Cytoscape 3 for cluster analysis and visualization, has been developed. In order to reduce complexity and enable extendibility for ClusterViz, we designed the architecture of ClusterViz based on the framework of Open Services Gateway Initiative. According to the architecture, the implementation of ClusterViz is partitioned into three modules including interface of ClusterViz, clustering algorithms and visualization and export. ClusterViz fascinates the comparison of the results of different algorithms to do further related analysis. Three commonly used clustering algorithms, FAG-EC, EAGLE and MCODE, are included in the current version. Due to adopting the abstract interface of algorithms in module of the clustering algorithms, more clustering algorithms can be included for the future use. To illustrate usability of ClusterViz, we provided three examples with detailed steps from the important scientific articles, which show that our tool has helped several research teams do their research work on the mechanism of the biological networks.},
  address    = {Washington, DC, USA},
  doi        = {10.1109/TCBB.2014.2361348},
  issue_date = {July/August 2015},
  keywords   = {cytoscape, biological networks, cluster, FAG-EC, EAGLE, visualization, MCODE},
  numpages   = {8},
  publisher  = {IEEE Computer Society Press},
  url        = {https://doi.org/10.1109/TCBB.2014.2361348},
}

@InProceedings{Petraki2015,
  author    = {Petraki, Eleni and Idreos, Stratos and Manegold, Stefan},
  booktitle = {Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data},
  title     = {Holistic Indexing in Main-Memory Column-Stores},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {1153–1166},
  publisher = {Association for Computing Machinery},
  series    = {SIGMOD '15},
  abstract  = {Great database systems performance relies heavily on index tuning, i.e., creating and utilizing the best indices depending on the workload. However, the complexity of the index tuning process has dramatically increased in recent years due to ad-hoc workloads and shortage of time and system resources to invest in tuning.This paper introduces holistic indexing, a new approach to automated index tuning in dynamic environments. Holistic indexing requires zero set-up and tuning effort, relying on adaptive index creation as a side-effect of query processing. Indices are created incrementally and partially;they are continuously refined as we process more and more queries. Holistic indexing takes the state-of-the-art adaptive indexing ideas a big step further by introducing the notion of a system which never stops refining the index space, taking educated decisions about which index we should incrementally refine next based on continuous knowledge acquisition about the running workload and resource utilization. When the system detects idle CPU cycles, it utilizes those extra cycles by refining the adaptive indices which are most likely to bring a benefit for future queries. Such idle CPU cycles occur when the system cannot exploit all available cores up to 100\%, i.e., either because the workload is not enough to saturate the CPUs or because the current tasks performed for query processing are not easy to parallelize to the point where all available CPU power is exploited.In this paper, we present the design of holistic indexing for column-oriented database architectures and we discuss a detailed analysis against parallel versions of state-of-the-art indexing and adaptive indexing approaches. Holistic indexing is implemented in an open-source column-store DBMS. Our detailed experiments on both synthetic and standard benchmarks (TPC-H) and workloads (SkyServer) demonstrate that holistic indexing brings significant performance gains by being able to continuously refine the physical design in parallel to query processing, exploiting any idle CPU resources.},
  doi       = {10.1145/2723372.2723719},
  isbn      = {9781450327589},
  keywords  = {self-organization, holistic indexing},
  location  = {Melbourne, Victoria, Australia},
  numpages  = {14},
  url       = {https://doi.org/10.1145/2723372.2723719},
}

@Article{Balakrishnan2021,
  author     = {Balakrishnan, Hari and Banerjee, Sujata and Cidon, Israel and Culler, David and Estrin, Deborah and Katz-Bassett, Ethan and Krishnamurthy, Arvind and McCauley, Murphy and McKeown, Nick and Panda, Aurojit and Ratnasamy, Sylvia and Rexford, Jennifer and Schapira, Michael and Shenker, Scott and Stoica, Ion and Tennenhouse, David and Vahdat, Amin and Zegura, Ellen},
  journal    = {SIGCOMM Comput. Commun. Rev.},
  title      = {Revitalizing the Public Internet by Making It Extensible},
  year       = {2021},
  issn       = {0146-4833},
  month      = {may},
  number     = {2},
  pages      = {18–24},
  volume     = {51},
  abstract   = {There is now a significant and growing functional gap between the public Internet, whose basic architecture has remained unchanged for several decades, and a new generation of more sophisticated private networks. To address this increasing divergence of functionality and overcome the Internet's architectural stagnation, we argue for the creation of an Extensible Internet (EI) that supports in-network services that go beyond best-effort packet delivery. To gain experience with this approach, we hope to soon deploy both an experimental version (for researchers) and a prototype version (for early adopters) of EI. In the longer term, making the Internet extensible will require a community to initiate and oversee the effort; this paper is the first step in creating such a community.},
  address    = {New York, NY, USA},
  doi        = {10.1145/3464994.3464998},
  issue_date = {April 2021},
  keywords   = {internet architecture},
  numpages   = {7},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3464994.3464998},
}

@InProceedings{Park2015a,
  author    = {Park, Joongsin and Jeong, Beomtaek and Jeon, Seungjai and Han, Sehyung and Cho, Jun-Dong and Ko, JeongGil},
  booktitle = {Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems},
  title     = {Understanding Interactive Interface Design Requirements for the Visually Impaired},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {881–886},
  publisher = {Association for Computing Machinery},
  series    = {CHI EA '15},
  abstract  = {While taxies are widely considered as an easily accessible form of transportation to many, for the visually impaired, utilizing taxi services can be a significant challenge. In this paper we envision a system architecture where visually impaired people use GPS-enabled mobile computing devices to easily reserve and access taxi services. Specifically, as the first step in designing such a system, we try to understand the preferred interaction interface requirements of the visually impaired population using a set of interviews conducted over 28 visually impaired participants. Our results show that the smartphone usage rate of our interview participants is ~60\%; thus, smartphone-based applications should not be considered as the "everyone-will-use-platform" when interacting with the visually impaired. Results from an extensive set of questions reveal that interaction interfaces in the form of key chains and wrist watches can also be effective for various interactive applications.},
  doi       = {10.1145/2702613.2732810},
  isbn      = {9781450331463},
  keywords  = {visually impaired interfaces, wireless interaction systems},
  location  = {<conf-loc>, <city>Seoul</city>, <country>Republic of Korea</country>, </conf-loc>},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2702613.2732810},
}

@InProceedings{Torre2015,
  author    = {Torre, Ilaria and Celik, Ilknur},
  booktitle = {Proceedings of the 26th ACM Conference on Hypertext \&amp; Social Media},
  title     = {User-Adapted Web of Things for Accessibility},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {341–344},
  publisher = {Association for Computing Machinery},
  series    = {HT '15},
  abstract  = {This paper describes a new wave of the Web that is the useradapted Web of Things. This is a new step in the evolution of the Web of Things and of adaptive web-based systems. The current proposals for the Web of Things focus on the augmentation of the physical objects in order to provide enhanced services. However, in our view, the Web of Things can also be a means to make physical objects accessible or more usable for people with special needs by exploiting adaptive and semantic techniques. The architecture presented in the paper describes the specific modules and components at the basis of this approach.},
  doi       = {10.1145/2700171.2804454},
  isbn      = {9781450333955},
  keywords  = {accessibility, user-adapted interaction, linked data, web of things, adaptation techniques, semantic web, special needs., adaptive web},
  location  = {Guzelyurt, Northern Cyprus},
  numpages  = {4},
  url       = {https://doi.org/10.1145/2700171.2804454},
}

@InProceedings{Johnson2014,
  author    = {Johnson, Kenneth and Calinescu, Radu},
  booktitle = {Proceedings of the 10th International ACM Sigsoft Conference on Quality of Software Architectures},
  title     = {Efficient Re-Resolution of SMT Specifications for Evolving Software Architectures},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {93–102},
  publisher = {Association for Computing Machinery},
  series    = {QoSA '14},
  abstract  = {We present a generic method for the efficient constraint re-resolution of a component-based software architecture after changes such as addition, removal and modification of components. Given a formal description of an evolving system as a constraint-specification problem, our method identifies and executes the re-resolution steps required to verify the system's compliance with constraints after each change. At each step, satisfiability modulo theory (SMT) techniques determine the satisfiability of component constraints expressed as logical formulae over suitably chosen theories of arithmetic, reusing results obtained in previous steps. We illustrate the application of the approach on a constraint-satisfaction problem arising from cloud-deployed software services. The incremental method is shown to re-resolve system constraints in a fraction of the time taken by standard SMT resolution.},
  doi       = {10.1145/2602576.2602578},
  isbn      = {9781450325769},
  keywords  = {incremental re-resolution, domain-specific languages, satisfiability modulo theory},
  location  = {Marcq-en-Bareul, France},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2602576.2602578},
}

@InProceedings{Cozzolino2017,
  author    = {Cozzolino, Vittorio and Ding, Aaron Yi and Ott, J\"{o}rg},
  booktitle = {Proceedings of the Workshop on Hot Topics in Container Networking and Networked Systems},
  title     = {FADES: Fine-Grained Edge Offloading with Unikernels},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {36–41},
  publisher = {Association for Computing Machinery},
  series    = {HotConNet '17},
  abstract  = {FADES is an edge offloading architecture that empowers us to run compact, single purpose tasks at the edge of the network to support a variety of IoT and cloud services. The design principle behind FADES is to efficiently exploit the resources of constrained edge devices through fine-grained computation offloading. FADES takes advantage of MirageOS unikernels to isolate and embed application logic in concise Xen-bootable images. We have implemented FADES and evaluated the system performance under various hardware and network conditions. Our results show that FADES can effectively strike a balance between running complex applications in the cloud and simple operations at the edge. As a solid step to enable fine-grained edge offloading, our experiments also reveal the limitation of existing IoT hardware and virtualization platforms, which shed light on future research to bring unikernel into IoT domain.},
  doi       = {10.1145/3094405.3094412},
  isbn      = {9781450350587},
  keywords  = {IoT, Edge Computing, Virtualization},
  location  = {Los Angeles, CA, USA},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3094405.3094412},
}

@InProceedings{Cabaj2018,
  author    = {Cabaj, Krzysztof and Gregorczyk, Marcin and Mazurczyk, Wojciech and Nowakowski, Piotr and \.{Z}\'{o}rawski, Piotr},
  booktitle = {Proceedings of the 13th International Conference on Availability, Reliability and Security},
  title     = {SDN-Based Mitigation of Scanning Attacks for the 5G Internet of Radio Light System},
  year      = {2018},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ARES '18},
  abstract  = {Currently 5G communication networks are gaining on importance among industry, academia, and governments worldwide as they are envisioned to offer wide range of high-quality services and unfaltering user experiences. However, certain security, privacy and trust challenges need to be addressed in order for the 5G networks to be widely welcomed and accepted. That is why in this paper, we take a step towards these requirements and we introduce a dedicated SDN-based integrated security framework for the Internet of Radio Light (IoRL) system that is following 5G architecture design. In particular, we present how TCP SYN-based scanning activities which typically comprise the first phase of the attack chain can be detected and mitigated using such an approach. Enclosed experimental results prove that the proposed security framework has potential to become an effective defensive solution.},
  articleno = {49},
  doi       = {10.1145/3230833.3233248},
  isbn      = {9781450364485},
  keywords  = {5G System Architecture, Network Function Virtualization, Visible Light Communications, mm Wave Communications, Integrated Security Framework, Software Defined Networks},
  location  = {Hamburg, Germany},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3230833.3233248},
}

@InProceedings{Dinechin2017,
  author    = {de Dinechin, Beno\^{\i}t Dupont and Graillat, Amaury},
  booktitle = {Proceedings of the 2nd International Workshop on Advanced Interconnect Solutions and Technologies for Emerging Computing Systems},
  title     = {Network-on-Chip Service Guarantees on the Kalray MPPA-256 Bostan Processor},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {35–40},
  publisher = {Association for Computing Machinery},
  series    = {AISTECS '17},
  abstract  = {The Kalray MPPA-256 Bostan manycore processor implements a clustered architecture, where clusters of cores share a local memory, and a DMA-capable network-on-chip (NoC) connects the clusters. The NoC implements wormhole switching without virtual channels, with source routing, and can be configured for maximum flow rate and burstiness at ingress. We describe and illustrate the techniques used to configure the MPPA NoC for guaranteed services. Our approach is based on three steps: global selection of routes between end-points and computation of flow rates, by solving the max-min fairness with unsplittable path problem; configuration of the flow burstiness parameters at ingress, by solving an acyclic set of linear inequalities; and end-to-end latency upper bound computation, based on the principles of separated flow analysis (SFA). In this paper, we develop the two last steps, taking advantage of the effects of NoC link shaping on the leaky-bucket arrival curves of flows.},
  doi       = {10.1145/3073763.3073770},
  isbn      = {9781450352260},
  keywords  = {network-on-chip, deterministic network calculus, separated flow analysis, link traffic shaping},
  location  = {Stockholm, Sweden},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3073763.3073770},
}

@InProceedings{Falcone2017,
  author    = {Falcone, Alberto and Garro, Alfredo and Anagnostou, Anastasia and Taylor, Simon J. E.},
  booktitle = {Proceedings of the 2017 Winter Simulation Conference},
  title     = {An Introduction to Developing Federations with the High Level Architecture (HLA)},
  year      = {2017},
  address   = {Las Vegas, Nevada},
  publisher = {IEEE Press},
  series    = {WSC '17},
  abstract  = {The IEEE 1516-2010 - High Level Architecture (HLA) for distributed simulation is growing in a variety of application domains due to its capabilities to enable the interoperability and reusability of distributed simulation components. However, the development of simulation models based on the HLA standard remains a challenging task that requires a considerable effort in terms of both time and cost. This paper provides an introduction tutorial on developing HLA-based simulations using the HLA Development Kit (DKF) framework. The tutorial guides developers through the necessary steps for defining and creating an HLA-based simulation, and explains how the HLA elements can be easily managed by using the DKF's services. The effectiveness of the DKF is proven by its concrete exploitation in the context of the Simulation Exploration Experience (SEE), a project led by NASA and which involves as partners several U.S. and European Institutions.},
  articleno = {43},
  isbn      = {9781538634271},
  numpages  = {15},
}

@Article{To2014,
  author     = {To, Quoc-Cuong and Nguyen, Benjamin and Pucheral, Philippe},
  journal    = {Proc. VLDB Endow.},
  title      = {SQL/AA: Executing SQL on an Asymmetric Architecture},
  year       = {2014},
  issn       = {2150-8097},
  month      = {aug},
  number     = {13},
  pages      = {1625–1628},
  volume     = {7},
  abstract   = {Current applications, from complex sensor systems (e.g. quantified self) to online e-markets acquire vast quantities of personal information which usually end-up on central servers. This information represents an unprecedented potential for user customized applications and business (e.g., car insurance billing, carbon tax, traffic decongestion, resource optimization in smart grids, healthcare surveillance, participatory sensing). However, the PRISM affair has shown that public opinion is starting to wonder whether these new services are not bringing us closer to science fiction dystopias. It has become clear that centralizing and processing all one's data on a single server is a major problem with regards to privacy concerns. Conversely, decentralized architectures, devised to help individuals keep full control of their data, complexify global treatments and queries, often impeding the development of innovative services and applications.},
  doi        = {10.14778/2733004.2733046},
  issue_date = {August 2014},
  numpages   = {4},
  publisher  = {VLDB Endowment},
  url        = {https://doi.org/10.14778/2733004.2733046},
}

@InProceedings{Romero2019,
  author    = {Romero, Eduardo and Stewart, Christopher and Morris, Nathaniel},
  booktitle = {Proceedings of the 4th ACM/IEEE Symposium on Edge Computing},
  title     = {Fast Inference Services for Alternative Deep Learning Structures},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {329–331},
  publisher = {Association for Computing Machinery},
  series    = {SEC '19},
  abstract  = {AI inference services receive requests, classify data and respond quickly. These services underlie AI-driven Internet of Things, recommendation engines and video analytics. Neural networks are widely used because they provide accurate results and fast inference, but it is hard to explain their classifications. Tree-based deep learning models can provide accuracy and are innately explainable. However, it is hard to achieve high inference rates because branch misprediction and cache misses produce inefficient executions. My research seeks to produce low latency inference services based on tree-based models. I will exploit the emergence of large L3 caches to convert tree-based model inference from sequential branching toward fast, in-cache lookups. Our approach begins with fully trained, accurate tree-based models, compiles them for inference on target processors and executes inference efficiently. If successful, our approach will enable qualitative advances in AI services. Tree-based models can report the most significant features in a classification in a single pass. In contrast, neural networks require iterative approaches to explain their results. Consider interactive AI recommendation services where users seek to explicitly order their instantaneous preferences to attract preferred content. Tree-based models can provide user feedback much more quickly than neural networks. Tree-based models also have less prediction variance than neural networks. Given the same training data, neural networks require many inferences to quantify variances of borderline classifications. Fast tree-based inference can explain variance in seconds (versus minutes). Our approach shows that competing machine learning approaches can provide comparable accuracy but desire wholly different architectural and platform support.},
  doi       = {10.1145/3318216.3363331},
  isbn      = {9781450367332},
  location  = {Arlington, Virginia},
  numpages  = {3},
  url       = {https://doi.org/10.1145/3318216.3363331},
}

@InProceedings{Ding2018,
  author    = {Ding, Aaron Yi and Janssen, Marijn},
  booktitle = {Proceedings of the Seventh International Conference on Telecommunications and Remote Sensing},
  title     = {Opportunities for Applications Using 5G Networks: Requirements, Challenges, and Outlook},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {27–34},
  publisher = {Association for Computing Machinery},
  series    = {ICTRS '18},
  abstract  = {The increasing demand for mobile network capacity driven by Internet of Things (IoT) applications results in the need for understanding better the potential and limitations of 5G networks. Vertical application areas like smart mobility, energy networks, industrial IoT applications, and AR/VR enhanced services all pose different requirements on the use of 5G networks. Some applications need low latency, whereas others need high bandwidth or security support. The goal of this paper is to identify the requirements and to understand the limitations for 5G driven applications. We review application areas and list the typical challenges and requirements posed on 5G networks. A main challenge will be to develop a network architecture being able to dynamically adapt to fluctuating traffic patterns and accommodating various technologies such as edge computing, blockchain based distributed ledger, software defined networking, and virtualization. To inspire future research, we reveal open problems and highlight the need for piloting with 5G applications, with tangible steps, to understand the configuration of 5G networks and the use of applications across multiple vertical industries.},
  doi       = {10.1145/3278161.3278166},
  isbn      = {9781450365802},
  keywords  = {edge computing, smart city, 5G systems, pilot, IoT},
  location  = {Barcelona, Spain},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3278161.3278166},
}

@InProceedings{Maccabe2017,
  author    = {Maccabe, Arthur B.},
  booktitle = {Proceedings of the 7th International Workshop on Runtime and Operating Systems for Supercomputers ROSS 2017},
  title     = {Operating and Runtime Systems Challenges for HPC Systems},
  year      = {2017},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ROSS '17},
  abstract  = {Future HPC systems will be characterized by extreme heterogeneity. We will see increasing heterogeneity in virtually every aspect of node architecture from computational engines to memory systems. We will see increasing heterogeneity in applications, including heterogeneity within applications (as previously independent applications are composed to build new applications). We will see increasing heterogeneity in system usage models; in some cases, the HPC system is not the most precious resource being managed. We will also see increasing heterogeneity in the shared services (e.g., storage and visualization systems) that are connected to HPC systems.All of this increasing heterogeneity is certain to create new challenges in the design and implementation of operating and runtime systems. There will be new kinds of resources to manage and many resource management tactics will be invented (and some re-discovered and adapted) to address the new heterogeneity. In essence, we will tacitly agree that the operating and runtime systems need to adapt to enable the inevitable integration of new technologies, applications, usage models, and shared services. While this agreement is critical for our ability to make incremental progress, we, as a community, must step back and ask the relevant question: Does the OS or runtime system bear the brunt of the adaptation, or will we be able to insist on changes in the technologies, applications, and environment? In the past decade, we have seen a similar tradeoff play out between the application teams and the architects of computational engines: how much floating point precision is required and how is this precision implemented? How can we define similar tradeoffs that are important in the design and implementation of operating and runtime systems?},
  articleno = {1},
  doi       = {10.1145/3095770.3095771},
  isbn      = {9781450350860},
  location  = {Washingon, DC, USA},
  numpages  = {1},
  url       = {https://doi.org/10.1145/3095770.3095771},
}

@InProceedings{Benchaib2015,
  author    = {Bencha\"{\i}b, Yacine and Secci, Stefano and Phung, Chi-Dung},
  booktitle = {Proceedings of the Eleventh ACM/IEEE Symposium on Architectures for Networking and Communications Systems},
  title     = {Transparent Cloud Access Performance Augmentation via an MPTCP-LISP Connection Proxy},
  year      = {2015},
  address   = {USA},
  pages     = {201–202},
  publisher = {IEEE Computer Society},
  series    = {ANCS '15},
  abstract  = {The use by a growing number of users of Cloud-based services requires an adaptation of the network technologies used to access them. We propose to combine two novel protocols at the state of the art at Cloud access middle-boxes to better profit from spare unused network path diversity. The first protocol, Multipath TCP, allows creating multiple TCP/IP subflows, as much as needed. The second, the Locator/Identifier Separation Protocol (LISP), can be used to route the subflows on different wide-area network paths, possibly disjoint, and also allows native support for seamless virtual machine migrations. In this paper we specify how we can combine these two protocols to increase the bandwidth available to access applications run in multi-homed data-centers. We describe how these protocols can be integrated into a Cloud access middle-box. By means of a combined MPTCP-LISP access proxy, the acceleration is transparent to the user terminal that does not necessitate any upgrade. We provide the detailed system-level architecture based on open source code, and we document results from preliminary experimentations on one of two targeted use-cases. The evaluations conducted show that the overhead generated by our solution remains moderate despite the various system-level steps required to translate incoming TCP packets into MPTCP-LISP packets then routed over different IP paths.},
  isbn      = {9781467366328},
  keywords  = {data-center networking, cloud access protocol},
  location  = {Oakland, California, USA},
  numpages  = {2},
}

@InProceedings{Lu2019,
  author    = {Lu, Yung-Feng and Chen, Hung-Ming and Kuo, Chin-Fu and Tseng, Bo-Kai and Chou, Shih-Chun},
  booktitle = {Proceedings of the Conference on Research in Adaptive and Convergent Systems},
  title     = {Container-Based Load Balancing for WebRTC Applications},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {20–26},
  publisher = {Association for Computing Machinery},
  series    = {RACS '19},
  abstract  = {Nowadays, the progress of the communication technology is fast. With the popularity of smart phones, tablets and computers, social networking sites or social software have also developed rapidly, changing the user's habit of using network communication software. The demand for streaming audio and video communication has increased dramatically, resulting in the maturity of the Internet today. At present, we can know that there are a variety of applications that can be talked on the market, such as LINE, Skype, Hangouts, etc., which can make instant calls. In the era of the Internet, the communication software has shortened the dispersion in the world. The distance between people everywhere.This research implements a web-based instant messaging architecture of WebRTC (Web Real-Time Communication, WebRTC) built on a container. We solved the concatenation problem caused by constructing WebRTC services on the container and sought to improve the performance. WebRTC can directly provide instant video and audio communication technology, and cooperate with ICE mechanism to communicate on different domains. No additional Plug-in is needed, only web browser can realize instant messaging function through web browser. It saves a lot of complicated steps, such as: install the user user, and so on. Our system also implements a load balancing mechanism that distributes traffic across the TURN Server, improving overall system performance.},
  doi       = {10.1145/3338840.3355655},
  isbn      = {9781450368438},
  keywords  = {web application, container, cloud, load balance},
  location  = {Chongqing, China},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3338840.3355655},
}

@InProceedings{Stubbs2021,
  author    = {Stubbs, Joe and Marru, Suresh and Mejia, Daniel and Navarro, John-Paul and Franz, Eric and Black, Steve and Wannipurage, Dimuthu and Pamidighantam, Sudhakar and Stirm, Claire and Dahan, Maytal and Pierce, Marlon and Zentner, Michael},
  booktitle = {Practice and Experience in Advanced Research Computing},
  title     = {Common Resource Descriptions for Interoperable Gateway Cyberinfrastructure},
  year      = {2021},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {PEARC '21},
  abstract  = {Science gateway projects face challenges utilizing the vast and heterogeneous landscape of powerful cyberinfrastructure available today, and interoperability across technologies remains poor. This interoperability issue leads to myriad problems: inability to bring multiple heterogeneous specialized resources together to solve problems where different resources are optimized for different facets of the problem; inability to choose from multiple resources on-the-fly as needed based on characteristics and available capacity; and ultimately a less than optimal application of nationally-funded resources toward advancing science. This paper presents version 1.0 of the Science Gateways Community Institute (SGCI) Resource Description Specification – a schema providing a common language for describing storage and computing resources utilized by science gateway technologies – as well as an Inventory API and software development kits for incorporating resource definitions into gateway projects. We discuss multiple gateway integration design options, with trade offs regarding robustness and availability. We detail the adoption to date of the SGCI Resource Specification by several prominent projects, including Apache Airavata, HUBzero®, Open OnDemand, Tapis, and XSEDE. The XSEDE adoption is worth highlighting explicitly as it has led to a new API within the XSEDE Information Services architecture which provides SGCI resource descriptions of all active XSEDE resources. Additionally, we show how the use of the SGCI Resource Specification provides interoperability across resource providers and projects that adopt it. Finally, as a proof of concept, we present a multi-step analysis that runs Quantum ESPRESSO and visualizes the energy band structures of a Gallium Arsenide (GaAs) crystal across multiple resource providers including the Halstead cluster at Purdue University and the Stampede2 supercomputer at TACC.},
  articleno = {20},
  doi       = {10.1145/3437359.3465576},
  isbn      = {9781450382922},
  keywords  = {science gateways community institute, Cyberinfrastructure, resource description, interoperability},
  location  = {Boston, MA, USA},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3437359.3465576},
}

@InProceedings{Magnani2018,
  author    = {Magnani, Antonio and D'Angelo, Gabriele and Ferretti, Stefano and Marzolla, Moreno},
  booktitle = {Proceedings of the 22nd International Symposium on Distributed Simulation and Real Time Applications},
  title     = {Anonymity and Confidentiality in Secure Distributed Simulation},
  year      = {2018},
  address   = {Madrid, Spain},
  pages     = {71–78},
  publisher = {IEEE Press},
  series    = {DS-RT '18},
  abstract  = {Research on data confidentiality, integrity and availability is gaining momentum in the ICT community, due to the intrinsically insecure nature of the Internet. While many distributed systems and services are now based on secure communication protocols to avoid eavesdropping and protect confidentiality, the techniques usually employed in distributed simulations do not consider these issues at all. This is probably due to the fact that many real-world simulators rely on monolithic, offline approaches and therefore the issues above do not apply. However, the complexity of the systems to be simulated, and the rise of distributed and cloud based simulation, now impose the adoption of secure simulation architectures. This paper presents a solution to ensure both anonymity and confidentiality in distributed simulations. A performance evaluation based on an anonymized distributed simulator is used for quantifying the performance penalty for being anonymous. The obtained results show that this is a viable solution.},
  isbn      = {9781538650486},
  keywords  = {secure simulation, distributed simulation, anonymity, confidentiality},
  numpages  = {8},
}

@InProceedings{Segura2018,
  author    = {Segura, Sergio and Parejo, Jos\'{e} A. and Troya, Javier and Ruiz-Cort\'{e}s, Antonio},
  booktitle = {Proceedings of the 40th International Conference on Software Engineering},
  title     = {Metamorphic Testing of RESTful Web APIs},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {882},
  publisher = {Association for Computing Machinery},
  series    = {ICSE '18},
  abstract  = {Web Application Programming Interfaces (APIs) specify how to access services and data over the network, typically using Web services. Web APIs are rapidly proliferating as a key element to foster reusability, integration, and innovation, enabling new consumption models such as mobile or smart TV apps. Companies such as Facebook, Twitter, Google, eBay or Netflix receive billions of API calls every day from thousands of different third-party applications and devices, which constitutes more than half of their total traffic.As Web APIs are progressively becoming the cornerstone of software integration, their validation is getting more critical. In this context, the fast detection of bugs is of utmost importance to increase the quality of internal products and third-party applications. However, testing Web APIs is challenging mainly due to the difficulty to assess whether the output of an API call is correct, i.e., the oracle problem. For instance, consider the Web API of the popular music streaming service Spotify. Suppose a search for albums with the query "redhouse" returning 21 total matches: Is this output correct? Do all the albums in the result set contain the keyword? Are there any albums containing the keyword not included in the result set? Answering these questions is difficult, even with small result sets, and often infeasible when the results are counted by thousands or millions.Metamorphic testing alleviates the oracle problem by providing an alternative when the expected output of a test execution is complex or unknown. Rather than checking the output of an individual program execution, metamorphic testing checks whether multiple executions of the program under test fulfil certain necessary properties called metamorphic relations. For instance, consider the following metamorphic relation in Spotify: two searches for albums with the same query should return the same number of total results regardless of the size of pagination. Suppose that a new Spotify search is performed using the exact same query as before and increasing the maximum number of results per page from 20 (default value) to 50: This search returns 27 total albums (6 more matches than in the previous search), which reveals a bug. This is an example of a real and reproducible fault detected using the approach presented in this paper and reported to Spotify. According to Spotify developers, it was a regression fault caused by a fix with undesired side effects.In this paper [1], we present a metamorphic testing approach for the automated detection of faults in RESTful Web APIs (henceforth also referred to as simply Web APIs). We introduce the concept of metamorphic relation output patterns. A Metamorphic Relation Output Pattern (MROP) defines an abstract output relation typically identified in Web APIs, regardless of their application domain. Each MROP is defined in terms of set operations among test outputs such as equality, union, subset, or intersection. MROPs provide a helpful guide for the identification of metamorphic relations, broadening the scope of our work beyond a particular Web API. Based on the notion of MROP, a methodology is proposed for the application of the approach to any Web API following the REST architectural pattern.The approach was evaluated in several steps. First, we used the proposed methodology to identify 33 metamorphic relations in four Web APIs developed by undergraduate students. All the relations are instances of the proposed MROPs. Then, we assessed the effectiveness of the identified relations at revealing 317 automatically seeded faults (i.e., mutants) in the APIs under test. As a result, 302 seeded faults were detected, achieving a mutation score of 95.3\%. Second, we evaluated the approach using real Web APIs and faults. In particular, we identified 20 metamorphic relations in the Web API of Spotify and 40 metamorphic relations in the Web API of YouTube. Each metamorphic relation was implemented and automatically executed using both random and manual test data. In total, 469K metamorphic tests were generated. As a result, 21 metamorphic relations were violated, and 11 issues revealed and reported (3 issues in Spotify and 8 issues in YouTube). To date, 10 of the reported issues have been either confirmed by the API developers or reproduced by other users supporting the effectiveness of our approach.},
  doi       = {10.1145/3180155.3182528},
  isbn      = {9781450356381},
  keywords  = {metamorphic testing, RESTful web services, web API, REST},
  location  = {Gothenburg, Sweden},
  numpages  = {1},
  url       = {https://doi.org/10.1145/3180155.3182528},
}

@InProceedings{Giacalone2014,
  author    = {Giacalone, Matteo and Paci, Federica and Mammoliti, Rocco and Perugino, Rodolfo and Massacci, Fabio and Selli, Claudio},
  booktitle = {Proceedings of the 8th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
  title     = {Security Triage: An Industrial Case Study on the Effectiveness of a Lean Methodology to Identify Security Requirements},
  year      = {2014},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ESEM '14},
  abstract  = {Context: Poste Italiane is a large corporation offering integrated services in banking and savings, postal services, and mobile communication. Every year, it receives thousands of change requests for its ICT services. Applying to each and every request a security assessment "by the book" is simply not possible. Goal: We report the experience by Poste Italiane of a lean methodology to identify security requirements that can be inserted in the production cycle of a normal company. Method: The process is based on surveying the overall IT architectures (Security Survey) and then a lean dynamic process (Security Triage) to evaluate individual change requests, so that important changes get the attention they need, minor changes can be quickly implemented, and compliance and security obligations are met. Results: The empirical evaluation conducted for over an year at Poste Italiane shows that the process significantly reduces the time to identify security requirements at the pace of change. Conclusions: The Security Survey and Triage process should thus be embedded in a company's production cycle as mandatory step to manage change requests so that security initiatives are prioritized based on the relevance of the assets and of the business objectives of the company.},
  articleno = {24},
  doi       = {10.1145/2652524.2652585},
  isbn      = {9781450327749},
  keywords  = {change requests, security requirements elicitation},
  location  = {Torino, Italy},
  numpages  = {8},
  url       = {https://doi.org/10.1145/2652524.2652585},
}

@InProceedings{Magalhaes2015,
  author    = {Magalh\~{a}es, Regis Pires and Coutinho, Gustavo and Mac\^{e}do, Jos\'{e} and Ferreira, Camila and Cruz, L\'{\i}via and Nascimento, Mario},
  booktitle = {Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems},
  title     = {Graphast: An Extensible Framework for Building Applications on Time-Dependent Networks},
  year      = {2015},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {SIGSPATIAL '15},
  abstract  = {Graphast is a framework tool that allows developers to compose a number of network models, data importing/exporting services as well as query services, in order to quickly build applications on time-dependent networks. The main goal is to allow developers to implement solutions to different types of problems on time-dependent networks using spatial queries, such as nearest neighbor queries, optimal sequenced routes, etc. Graphast allows the combination of facilities provided by the framework via a public API and/or the building of new facilities, e.g., a new query processing algorithm, and incorporate those into Graphast for others to use them as well. In this paper, we discuss Graphast's architectural components and how one can create/store instances of those components in order to build an application. The steps necessary for building a real world application are also presented.},
  articleno = {93},
  doi       = {10.1145/2820783.2820791},
  isbn      = {9781450339674},
  keywords  = {query services, time-dependent networks, framework},
  location  = {Seattle, Washington},
  numpages  = {4},
  url       = {https://doi.org/10.1145/2820783.2820791},
}

@Article{Michel2021,
  author     = {Michel, Oliver and Bifulco, Roberto and R\'{e}tv\'{a}ri, G\'{a}bor and Schmid, Stefan},
  journal    = {ACM Comput. Surv.},
  title      = {The Programmable Data Plane: Abstractions, Architectures, Algorithms, and Applications},
  year       = {2021},
  issn       = {0360-0300},
  month      = {may},
  number     = {4},
  volume     = {54},
  abstract   = {Programmable data plane technologies enable the systematic reconfiguration of the low-level processing steps applied to network packets and are key drivers toward realizing the next generation of network services and applications. This survey presents recent trends and issues in the design and implementation of programmable network devices, focusing on prominent abstractions, architectures, algorithms, and applications proposed, debated, and realized over the past years. We elaborate on the trends that led to the emergence of this technology and highlight the most important pointers from the literature, casting different taxonomies for the field, and identifying avenues for future research.},
  address    = {New York, NY, USA},
  articleno  = {82},
  doi        = {10.1145/3447868},
  issue_date = {May 2022},
  keywords   = {Programmable data planes, programmable switches, packet processing, in-network computation, network programmability},
  numpages   = {36},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3447868},
}

@InProceedings{Bagherzadeh2018,
  author    = {Bagherzadeh, Mojtaba and Kahani, Nafiseh and Bezemer, Cor-Paul and Hassan, Ahmed E. and Dingel, Juergen and Cordy, James R.},
  booktitle = {Proceedings of the 40th International Conference on Software Engineering},
  title     = {Analyzing a Decade of Linux System Calls},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {267},
  publisher = {Association for Computing Machinery},
  series    = {ICSE '18},
  abstract  = {The Linux kernel provides its services to the application layer using so-called system calls. All system calls combined form the Application Programming Interface (API) of the kernel. Hence, system calls provide us with a window into the development process and design decisions that are made for the Linux kernel. Our paper [1] presents the result of an empirical study of the changes (8,770) that were made to the system calls during the last decade (i.e., from April 2005 to December 2014). The main contributions and most important findings of our study are:(1) An overview of the Linux system calls. As of December 2014, 396 system calls existed in the Linux kernel. They can be categorized into 10 groups (process management, signal processing, and so on). 76 of the system calls were added over the last decade (new system calls). A new system call is usually not activated for all architectures at the same time. 40 out of 76 (53\%) new system calls and 102 of the 393 (26\%) existing system calls were sibling calls. A sibling call is a system call that is similar in functionality, and often in name, to another system call.(2) A study of the evolution of the Linux system calls over the last decade in terms of the size and type of changes that were made to the system calls. With an average growth of 25 LOC per day, the Linux system calls are relatively stable. The commits that are made to system calls are slightly more scattered than kernel commits. There exists a small group of very active system call developers. 8,288 of the 8,770 studied commits (95\%) were made to maintain, improve and fix bugs in system calls. 36\% of the system call-related commits were bug fixes. 4,498 (50\%) of the commits were made to only 25 (6\%) of the 393 system calls. 35\% of the system call-related commits were made to conduct code restructuring, and 36\% of the system call-related commits were made to fix bugs.(3) A study of the type of bug fixes that were made to the system calls over the last decade. Developers make mistakes in the seemingly trivial activation process of a system call. The steps that are required to activate a system call, such as assigning the unique number and updating the system call table, are performed manually. 58\% of the bug fix commits were made to fix semantic bugs. The proportion of bug fixes that fixed memory-related bugs remained constant throughout the last decade.(4) An analysis of the results and a discussion of their implications.Generalizability of results. We compared Linux system calls with FreeBSD system calls, to validate that our results are generalizable to other UNIX-based operating systems. Our findings for the FreeBSD operating system confirm that other UNIX-based operating systems use a system call mechanism that is similar to that of Linux. Therefore, we can safely assume that our findings are of value to other UNIX-based operating systems.Suggestion for automation. First, we suggest the automation of simple, reoccurring tasks in Linux, such as adding and removing system calls. Our study on FreeBSD shows that such tasks can successfully be automated. Second, we suggest that historical information about the evolution of a kernel API should be used to guide the testing process. Finally, we suggest that existing automated testing tools are extended to support testing system calls.Maintenance Effort. Compared to regular software systems, kernel APIs require an additional type of maintenance that involves adding and removing system calls. Also, approximately 11\% of the maintenance effort of a kernel API is assigned to the infrastructure for providing the API.Overall, the results of our study can be beneficial to practitioners, researchers, and more specifically kernel developers, by providing insights related to the challenges and problems that come with long term maintenance of a kernel API, such as the long-lived Linux kernel API. We have published our classification of 8,870 system call-related changes [1] so that it can be used to conduct further studies.The full paper is accepted for publication in the Empirical Software Engineering journal, and can be found at: https://link.springer.com/article/10.1007/s10664-017-9551-z.},
  doi       = {10.1145/3180155.3182518},
  isbn      = {9781450356381},
  keywords  = {software evolution, system calls, linux kernel, API evolution},
  location  = {Gothenburg, Sweden},
  numpages  = {1},
  url       = {https://doi.org/10.1145/3180155.3182518},
}

@InProceedings{Oramas2017,
  author    = {Oramas, Sergio and Nieto, Oriol and Sordo, Mohamed and Serra, Xavier},
  booktitle = {Proceedings of the 2nd Workshop on Deep Learning for Recommender Systems},
  title     = {A Deep Multimodal Approach for Cold-Start Music Recommendation},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {32–37},
  publisher = {Association for Computing Machinery},
  series    = {DLRS 2017},
  abstract  = {An increasing amount of digital music is being published daily. Music streaming services often ingest all available music, but this poses a challenge: how to recommend new artists for which prior knowledge is scarce? In this work we aim to address this so-called cold-start problem by combining text and audio information with user feedback data using deep network architectures. Our method is divided into three steps. First, artist embeddings are learned from biographies by combining semantics, text features, and aggregated usage data. Second, track embeddings are learned from the audio signal and available feedback data. Finally, artist and track embeddings are combined in a multimodal network. Results suggest that both splitting the recommendation problem between feature levels (i.e., artist metadata and audio track), and merging feature embeddings in a multimodal approach improve the accuracy of the recommendations.},
  doi       = {10.1145/3125486.3125492},
  isbn      = {9781450353533},
  keywords  = {semantics, multimodal, recommender systems, deep learning, music},
  location  = {Como, Italy},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3125486.3125492},
}

@InProceedings{Chen2023,
  author    = {Chen, Hui and Ye, Xingmao and Zhang, Libo and Bu, Qian},
  booktitle = {Proceedings of the 9th International Conference on Management of E-Commerce and e-Government},
  title     = {The Construction of Government Information Open Platform: Research and Practice of the Ministry of Natural Resources},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {1–6},
  publisher = {Association for Computing Machinery},
  series    = {ICMECG '22},
  abstract  = {The rapid development of information technology has provided strong technical support for China to promote the construction of service-oriented government. The government information open platform(GIOP) uses information technology to enable the public to obtain government information in the most convenient way and make government information better serve the public, which is an important measure to promote the construction of service-oriented and transparent government. The Ministry of Natural Resources (MNR), which was established in 2018, was studied to analyse the significance and construction requirements of the GIOP. The content system, functions, system architecture, key technical methods and achievements are described. Real-life cases are provided to illustrate the series of technological means and mechanism support for breaking the barriers between platforms, thereby promoting the innovation of government information services.},
  doi       = {10.1145/3549823.3549824},
  isbn      = {9781450397919},
  keywords  = {Ministry of Natural Resources, government information, open platform, policy document},
  location  = {<conf-loc>, <city>Seoul</city>, <country>Republic of Korea</country>, </conf-loc>},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3549823.3549824},
}

@Article{Renen2023,
  author     = {van Renen, Alexander and Leis, Viktor},
  journal    = {Proc. VLDB Endow.},
  title      = {Cloud Analytics Benchmark},
  year       = {2023},
  issn       = {2150-8097},
  month      = {feb},
  number     = {6},
  pages      = {1413–1425},
  volume     = {16},
  abstract   = {The cloud facilitates the transition to a service-oriented perspective. This affects cloud-native data management in general, and data analytics in particular. Instead of managing a multi-node database cluster on-premise, end users simply send queries to a managed cloud data warehouse and receive results. While this is obviously very attractive for end users, database system architects still have to engineer systems for this new service model. There are currently many competing architectures ranging from self-hosted (Presto, PostgreSQL), over managed (Snowflake, Amazon Redshift) to query-as-a-service (Amazon Athena, Google BigQuery) offerings. Benchmarking these architectural approaches is currently difficult, and it is not even clear what the metrics for a comparison should be.To overcome these challenges, we first analyze a real-world query trace from Snowflake and compare its properties to that of TPC-H and TPC-DS. Doing so, we identify important differences that distinguish traditional benchmarks from real-world cloud data warehouse workloads. Based on this analysis, we propose the Cloud Analytics Benchmark (CAB). By incorporating workload fluctuations and multi-tenancy, CAB allows evaluating different designs in terms of user-centered metrics such as cost and performance.},
  doi        = {10.14778/3583140.3583156},
  issue_date = {February 2023},
  numpages   = {13},
  publisher  = {VLDB Endowment},
  url        = {https://doi.org/10.14778/3583140.3583156},
}

@InProceedings{Roesch2022,
  author    = {R\"{o}sch, Tobias and Sommer, Martin and Sax, Eric},
  booktitle = {Proceedings of the 2022 8th International Conference on Computer Technology Applications},
  title     = {Adaptive Application Development and Integration Process for Modern Automotive Software},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {85–90},
  publisher = {Association for Computing Machinery},
  series    = {ICCTA '22},
  abstract  = {Due to fast progress in information technologies and long lifecycles of vehicles, there are ever-increasing expectations in modern automotive software development regarding the flexibility to integrate updates and new functions quickly into already existing systems. This paper proposes a process, that is especially suitable for the development of new functions in higher programming languages and the usage of machine learning models. When developed in a tool like MATLAB, code generators can be used to integrate the function step-by-step into a service-oriented automotive E/E-architecture. It is based on a classic V-model process and uses integration steps according to the XiL approach. The key aspect is the frontloading of verification and validation into the steps as early as possible to keep iteration cycles fast. The proposed process is applied to the development of a Neural Network Model Predictive Control (NNMPC) for a Heating, Ventilation and Air-Conditioning (HVAC) unit of a city bus. The resulting NNMPC is then integrated into a system based on the AUTOSAR adaptive platform. That allowed the function to be developed and integrated quickly and seems to be a promising approach to bring new functions into already existing automotive E/E-architectures.},
  doi       = {10.1145/3543712.3543718},
  isbn      = {9781450396226},
  keywords  = {software development process, AUTOSAR Adaptive, automotive software, service-oriented architecture},
  location  = {Vienna, Austria},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3543712.3543718},
}

@InProceedings{Santos2021,
  author    = {Santos, Ana and Paula, Hugo},
  booktitle = {Proceedings of the 15th Brazilian Symposium on Software Components, Architectures, and Reuse},
  title     = {Microservice Decomposition and Evaluation Using Dependency Graph and Silhouette Coefficient},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {51–60},
  publisher = {Association for Computing Machinery},
  series    = {SBCARS '21},
  abstract  = {The benefits provided by microservices architecture in some application scenarios are a motivating factor for organizations to migrate their monoliths to this architecture. Extracting microservices from existing monolithic code bases presents a key challenge in this context, and there is a lack of tools that automate not only the decomposition processes but also the evaluation of the resulting architecture. This work presents a new approach for microservice decomposition that analyzes source code of a monolithic application and, with the combined use of approaches in the literature, suggests parts to be extracted in microservices considering the artifacts: classes, methods and/or history of modifications. The quality of the microservices’ suggestions are assessed, quantitatively, through the silhouette coefficient, a quality metric used in clustering analysis, and the microservice granularity. A tool was developed to automate the process of microservice decomposition for Java repositories. As a result, it was observed that the tool generated clusters with satisfactory results and can be used as an auxiliary instrument by experts during the migration process from monolithic architecture to microservices.},
  doi       = {10.1145/3483899.3483908},
  isbn      = {9781450384193},
  keywords  = {monolithic application, microservices, decomposition},
  location  = {Joinville, Brazil},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3483899.3483908},
}

@InProceedings{Pearce2023,
  author    = {Pearce, Glen and Pflaum, Alexis and Balasoiu, Dumitru Alin and Szabo, Claudia},
  booktitle = {Proceedings of the Winter Simulation Conference},
  title     = {Jeopardy Assessment for Dynamic Configuration of Collaborative Microservice Architectures},
  year      = {2023},
  address   = {Singapore, Singapore},
  pages     = {2070–2081},
  publisher = {IEEE Press},
  series    = {WSC '22},
  abstract  = {Microservice architectures, which are lightweight, flexible, and adapt easily to changes, have recently been considered for system development in military operations in contested and dynamic environments. However, in a military setting, the dynamic configuration of collaborative microservices execution becomes critical, and testing that microservice configurations behave as expected becomes paramount. In this paper, we propose a complex jeopardy metric and reconfiguration process that dynamically configures collaborative algorithms running on multiple nodes. Our metric and proposed scenarios will allow for the automated evaluation of microservice configurations and their re-configuration to suit operational needs. We evaluate our proposed scenario, metric, and various reconfiguration algorithms to show the benefits of this approach.},
  numpages  = {12},
}

@Article{Zdun2023,
  author     = {Zdun, Uwe and Queval, Pierre-Jean and Simhandl, Georg and Scandariato, Riccardo and Chakravarty, Somik and Jelic, Marjan and Jovanovic, Aleksandar},
  journal    = {ACM Trans. Softw. Eng. Methodol.},
  title      = {Microservice Security Metrics for Secure Communication, Identity Management, and Observability},
  year       = {2023},
  issn       = {1049-331X},
  month      = {feb},
  number     = {1},
  volume     = {32},
  abstract   = {Microservice architectures are increasingly being used to develop application systems. Despite many guidelines and best practices being published, architecting microservice systems for security is challenging. Reasons are the size and complexity of microservice systems, their polyglot nature, and the demand for the continuous evolution of these systems. In this context, to manually validate that security architecture tactics are employed as intended throughout the system is a time-consuming and error-prone task. In this article, we present an approach to avoid such manual validation before each continuous evolution step in a microservice system, which we demonstrate using three widely used categories of security tactics: secure communication, identity management, and observability. Our approach is based on a review of existing security guidelines, the gray literature, and the scientific literature, from which we derived Architectural Design Decisions (ADDs) with the found security tactics as decision options. In our approach, we propose novel detectors to detect these decision options automatically and formally defined metrics to measure the conformance of a system to the different options of the ADDs. We apply the approach to a case study data set of 10 open source microservice systems, plus another 20 variants of these systems, for which we manually inspected the source code for security tactics. We demonstrate and assess the validity and appropriateness of our metrics by performing an assessment of their conformance to the ADDs in our systems’ dataset through statistical methods.},
  address    = {New York, NY, USA},
  articleno  = {16},
  doi        = {10.1145/3532183},
  issue_date = {January 2023},
  keywords   = {microservice security, software architecture metrics, software architecture detectors, Microservice architecture},
  numpages   = {34},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3532183},
}

@InProceedings{Baarzi2021,
  author    = {Baarzi, Ataollah Fatahi and Kesidis, George},
  booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
  title     = {SHOWAR: Right-Sizing And Efficient Scheduling of Microservices},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {427–441},
  publisher = {Association for Computing Machinery},
  series    = {SoCC '21},
  abstract  = {Microservices architecture have been widely adopted in designing distributed cloud applications where the application is decoupled into multiple small components (i.e. "microservices"). One of the challenges in deploying microservices is finding the optimal amount of resources (i.e. size) and the number of instances (i.e. replicas) for each microservice in order to maintain a good performance as well as prevent resource wastage and under-utilization which is not cost-effective. This paper presents SHOWAR, a framework that configures the resources by determining the number of replicas (horizontal scaling) and the amount of CPU and Memory for each microservice (vertical scaling). For vertical scaling, SHOWAR uses empirical variance in the historical resource usage to find the optimal size and mitigate resource wastage. For horizontal scaling, SHOWAR uses basic ideas from control theory along with kernel level performance metrics. Additionally, once the size for each microservice is found, SHOWAR bridges the gap between optimal resource allocation and scheduling by generating affinity rules (i.e. hints) for the scheduler to further improve the performance. Our experiments, using a variety of microservice applications and real-world workloads, show that, compared to the state-of-the-art autoscaling and scheduling systems, SHOWAR on average improves the resource allocation by up to 22\% while improving the 99th percentile end-to-end user request latency by 20\%.},
  doi       = {10.1145/3472883.3486999},
  isbn      = {9781450386388},
  keywords  = {autoscaling, cloud computing, microservices},
  location  = {Seattle, WA, USA},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3472883.3486999},
}

@InProceedings{Yoder2022,
  author    = {Yoder, Joseph W. and Merson, Paulo},
  booktitle = {Proceedings of the 27th Conference on Pattern Languages of Programs},
  title     = {Strangler Patterns},
  year      = {2022},
  address   = {USA},
  publisher = {The Hillside Group},
  series    = {PLoP '20},
  abstract  = {Martin Fowler coined the term "Strangler Application" as a metaphor to describe a way of doing an evolutionary rewrite of a system, keeping it working while you evolve it. The main idea is to gradually create a new system around the edges of the old, letting it grow slowly over several years until the old system is strangled. The microservices architecture style has become very popular, and has been used to apply the strangler application to monolithic service-based systems. This paper describes different strategies (patterns) for applying the strangler application while evolving a monolith to use the microservices architecture style. The main ideas are: Wrap the monolith and protect services and system from change, Start Small and gradually evolve the system (baby steps), Pave the Road making microservices easier to create; Macroservice first then split to Microservice, Add new functionality as microservices, Extract Module / Component to Microservice, and Replace functionality with Microservice. As the system evolve it is common to Proxy Monolith Components and Add Fa\c{c}ade to the microservices},
  articleno = {8},
  isbn      = {9781941652169},
  keywords  = {pattern sequences, patterns, architecture, evolutionary architecture, continuous integration, DevOps, strangler, software development, sustainable delivery, microservices, monolith, pattern scenarios},
  location  = {Virtual Event},
  numpages  = {25},
}

@InProceedings{Sellami2022,
  author    = {Sellami, Khaled and Saied, Mohamed Aymen and Ouni, Ali},
  booktitle = {Proceedings of the 26th International Conference on Evaluation and Assessment in Software Engineering},
  title     = {A Hierarchical DBSCAN Method for Extracting Microservices from Monolithic Applications},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {201–210},
  publisher = {Association for Computing Machinery},
  series    = {EASE '22},
  abstract  = {The microservices architectural style offers many advantages such as scalability, reusability and ease of maintainability. As such microservices has become a common architectural choice when developing new applications. Hence, to benefit from these advantages, monolithic applications need to be redesigned in order to migrate to a microservice based architecture. Due to the inherent complexity and high costs related to this process, it is crucial to automate this task. In this paper, we propose a method that can identify potential microservices from a given monolithic application. Our method takes as input the source code of the source application in order to measure the similarities and dependencies between all of the classes in the system using their interactions and the domain terminology employed within the code. These similarity values are then used with a variant of a density-based clustering algorithm to generate a hierarchical structure of the recommended microservices while identifying potential outlier classes. We provide an empirical evaluation of our approach through different experimental settings including a comparison with existing human-designed microservices and a comparison with 5 baselines. The results show that our method succeeds in generating microservices that are overall more cohesive and that have fewer interactions in-between them with up to 0.9 of precision score when compared to human-designed microservices.},
  doi       = {10.1145/3530019.3530040},
  isbn      = {9781450396134},
  keywords  = {Legacy decomposition, Static Analysis, Clustering, Microservices},
  location  = {Gothenburg, Sweden},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3530019.3530040},
}

@InProceedings{Luo2021a,
  author    = {Luo, Shutian and Xu, Huanle and Lu, Chengzhi and Ye, Kejiang and Xu, Guoyao and Zhang, Liping and Ding, Yu and He, Jian and Xu, Chengzhong},
  booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
  title     = {Characterizing Microservice Dependency and Performance: Alibaba Trace Analysis},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {412–426},
  publisher = {Association for Computing Machinery},
  series    = {SoCC '21},
  abstract  = {Loosely-coupled and light-weight microservices running in containers are replacing monolithic applications gradually. Understanding the characteristics of microservices is critical to make good use of microservice architectures. However, there is no comprehensive study about microservice and its related systems in production environments so far. In this paper, we present a solid analysis of large-scale deployments of microservices at Alibaba clusters. Our study focuses on the characterization of microservice dependency as well as its runtime performance. We conduct an in-depth anatomy of microservice call graphs to quantify the difference between them and traditional DAGs of data-parallel jobs. In particular, we observe that microservice call graphs are heavy-tail distributed and their topology is similar to a tree and moreover, many microservices are hot-spots. We reveal three types of meaningful call dependency that can be utilized to optimize microservice designs. Our investigation on microservice runtime performance indicates most microservices are much more sensitive to CPU interference than memory interference. To synthesize more representative microservice traces, we build a mathematical model to simulate call graphs. Experimental results demonstrate our model can well preserve those graph properties observed from Alibaba traces.},
  doi       = {10.1145/3472883.3487003},
  isbn      = {9781450386388},
  location  = {Seattle, WA, USA},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3472883.3487003},
}

@InProceedings{Lee2022,
  author    = {Lee, Chunghan and Yoshitani, Reina and Hirotsu, Toshio},
  booktitle = {Proceedings of the 17th Asian Internet Engineering Conference},
  title     = {Enhancing Packet Tracing of Microservices in Container Overlay Networks Using EBPF},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {53–61},
  publisher = {Association for Computing Machinery},
  series    = {AINTEC '22},
  abstract  = {The microservices architecture has been rapidly adopted to latency-sensitive applications. The architecture of these applications and the container overlay networks on servers are also complex. Distributed tracing is widely adopted in microservice applications; it suffers from the drawback of only focusing on service discovery and latency-based monitoring at an application layer, making it still challenging to monitor container overlay networks using distributed tracing. In this paper, we present an extended Berkeley Packet Filter (eBPF)-based packet tracing method using distributed tracing for latency measurement in the container overlay network. To efficiently detect the trace context on a HTTP payload, we moved the trace context position just behind the HTTP request line using sidecar proxy. Our tracing method gathered the HTTP packets that had the trace context and measured the latency using eBPF. Our evaluation was conducted using open-source benchmarks on Kubernetes; the results showed that the proposed tracing header format reduced the HTTP payload search space by up to approximately 80, and there was no significant change in end-to-end latency. Moreover, our eBPF-based tracing method presented similar latency characteristics on the overlay network in comparison with the characteristics of the packet-level traces obtained under tcpdump.},
  doi       = {10.1145/3570748.3570756},
  isbn      = {9781450399814},
  keywords  = {Sidecar, ServiceMesh, Kubernetes, Latency, Distributed tracing, Microservices, eBPF},
  location  = {<conf-loc>, <city>Hiroshima</city>, <country>Japan</country>, </conf-loc>},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3570748.3570756},
}

@InProceedings{Xie2023,
  author    = {Xie, Zhe and Pei, Changhua and Li, Wanxue and Jiang, Huai and Su, Liangfei and Li, Jianhui and Xie, Gaogang and Pei, Dan},
  booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  title     = {From Point-Wise to Group-Wise: A Fast and Accurate Microservice Trace Anomaly Detection Approach},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {1739–1749},
  publisher = {Association for Computing Machinery},
  series    = {ESEC/FSE 2023},
  abstract  = {As Internet applications continue to scale up, microservice architecture has become increasingly popular due to its flexibility and logical structure. Anomaly detection in traces that record inter-microservice invocations is essential for diagnosing system failures. Deep learning-based approaches allow for accurate modeling of structural features (i.e., call paths) and latency features (i.e., call response time), which can determine the anomaly of a particular trace sample. However, the point-wise manner employed by these methods results in substantial system detection overhead and impracticality, given the massive volume of traces (billion-level). Furthermore, the point-wise approach lacks high-level information, as identical sub-structures across multiple traces may be encoded differently. In this paper, we introduce the first Group-wise Trace anomaly detection algorithm, named GTrace. This method categorizes the traces into distinct groups based on their shared sub-structure, such as the entire tree or sub-tree structure. A group-wise Variational AutoEncoder (VAE) is then employed to obtain structural representations. Moreover, the innovative "predicting latency with structure" learning paradigm facilitates the association between the grouped structure and the latency distribution within each group. With the group-wise design, representation caching, and batched inference strategies can be implemented, which significantly reduces the burden of detection on the system. Our comprehensive evaluation reveals that GTrace outperforms state-of-the-art methods in both performances (2.64\% to 195.45\% improvement in AUC metrics and 2.31\% to 40.92\% improvement in best F-Score) and efficiency (21.9x to 28.2x speedup). We have deployed and assessed the proposed algorithm on eBay's microservices cluster, and our code is available at https://github.com/NetManAIOps/GTrace.git.},
  doi       = {10.1145/3611643.3613861},
  isbn      = {9798400703270},
  keywords  = {microservice trace, variational autoencoder, anomaly detection},
  location  = {<conf-loc>, <city>San Francisco</city>, <state>CA</state>, <country>USA</country>, </conf-loc>},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3611643.3613861},
}

@InProceedings{Wang2023,
  author    = {Wang, Lu and Zhang, Chaoyun and Ding, Ruomeng and Xu, Yong and Chen, Qihang and Zou, Wentao and Chen, Qingjun and Zhang, Meng and Gao, Xuedong and Fan, Hao and Rajmohan, Saravan and Lin, Qingwei and Zhang, Dongmei},
  booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  title     = {Root Cause Analysis for Microservice Systems via Hierarchical Reinforcement Learning from Human Feedback},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {5116–5125},
  publisher = {Association for Computing Machinery},
  series    = {KDD '23},
  abstract  = {In microservice systems, the identification of root causes of anomalies is imperative for service reliability and business impact. This process is typically divided into two phases: (i)constructing a service dependency graph that outlines the sequence and structure of system components that are invoked, and (ii) localizing the root cause components using the graph, traces, logs, and Key Performance Indicators (KPIs) such as latency. However, both phases are not straightforward due to the highly dynamic and complex nature of the system, particularly in large-scale commercial architectures like Microsoft Exchange.In this paper, we propose a new framework that employs Hierarchical Reinforcement Learning from Human Feedback (HRLHF) to address these challenges. Our framework leverages the static topology of the microservice system and efficiently employs the feedback of engineers to reduce uncertainty in the discovery of the service dependency graph. The framework utilizes reinforcement learning to reduce the number of queries required from O(N2) to O(1), enabling the construction of the dependency graph with high accuracy and minimal human effort. Additionally, we extend the discovered dependency graphs to window causal graphs that capture the characteristics of time series over a specified time period, resulting in improved root cause analysis accuracy and robustness. Evaluations on both real datasets from Microsoft Exchange and synthetic datasets with injected anomalies demonstrate superior performance on various metrics compared to state-of-the-art methods. It is worth mentioning that, our framework has been integrated as a crucial component in Microsoft M365 Exchange service.},
  doi       = {10.1145/3580305.3599934},
  isbn      = {9798400701030},
  keywords  = {root cause analysis, causal discovery, reinforcement learning from human feedback},
  location  = {<conf-loc>, <city>Long Beach</city>, <state>CA</state>, <country>USA</country>, </conf-loc>},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3580305.3599934},
}

@InProceedings{Gong2023,
  author    = {Gong, Shengbo and Zhou, Jiajun and Xie, Chenxuan and Xuan, Qi},
  booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
  title     = {Neighborhood Homophily-Based Graph Convolutional Network},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {3908–3912},
  publisher = {Association for Computing Machinery},
  series    = {CIKM '23},
  abstract  = {Graph neural networks (GNNs) have been proved powerful in graph-oriented tasks. However, many real-world graphs are heterophilous, challenging the homophily assumption of classical GNNs. To solve the universality problem, many studies deepen networks or concatenate intermediate representations, which does not inherently change neighbor aggregation and introduces noise. Recent studies propose new metrics to characterize the homophily, but rarely consider the correlation of the proposed metrics and models. In this paper, we first design a new metric, Neighborhood Homophily (NH), to measure the label complexity or purity in node neighborhoods. Furthermore, we incorporate the metric into the classical graph convolutional network (GCN) architecture and propose Neighborhood Homophily-based Graph Convolutional Network (NHGCN). In this framework, neighbors are grouped by estimated NH values and aggregated from different channels, and the resulting node predictions are then used in turn to estimate and update NH values. The two processes of metric estimation and model inference are alternately optimized to achieve better node classification. NHGCN achieves top overall performance on both homophilous and heterophilous benchmarks, with an improvement of up to 7.4\% compared to the current SOTA methods.},
  doi       = {10.1145/3583780.3615195},
  isbn      = {9798400701245},
  keywords  = {graph neural networks, homophily, node classification},
  location  = {<conf-loc>, <city>Birmingham</city>, <country>United Kingdom</country>, </conf-loc>},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3583780.3615195},
}

@InProceedings{Hrusto2022,
  author    = {Hrusto, Adha and Engstr\"{o}m, Emelie and Runeson, Per},
  booktitle = {Proceedings of the 10th IEEE/ACM International Workshop on Software Engineering for Systems-of-Systems and Software Ecosystems},
  title     = {Optimization of Anomaly Detection in a Microservice System through Continuous Feedback from Development},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {13–20},
  publisher = {Association for Computing Machinery},
  series    = {SESoS '22},
  abstract  = {Monitoring a microservice system may bring a lot of benefits to development teams such as early detection of run-time errors and various performance anomalies. In this study, we explore deep learning (DL) solutions for detection of anomalous system's behavior based on collected monitoring data that consists of applications' and systems' performance metrics. The study is conducted in a collaboration with a Swedish company responsible for ticket and payment management in public transportation. Moreover, we specifically address a shortage of approaches for evaluating DL models without any ground truth data. Hence, we propose a solution design for anomaly detection and reporting alerts inspired by state-of-the-art DL solutions. Furthermore, we propose a plan for its in-context implementation and evaluation empowered by feedback from the development team. Through continuous feedback from development, the labeled data is generated and used for optimization of the DL model. In this way, a microservice system may leverage DL solutions to address rising challenges within its architecture.},
  doi       = {10.1145/3528229.3529382},
  isbn      = {9781450393348},
  keywords  = {DevOps, anomaly detection, deep learning, microservices},
  location  = {Pittsburgh, Pennsylvania},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3528229.3529382},
}

@InProceedings{Zhang2021a,
  author    = {Zhang, Jun and Ferydouni, Robert and Montana, Aldrin and Bittman, Daniel and Alvaro, Peter},
  booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
  title     = {3MileBeach: A Tracer with Teeth},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {458–472},
  publisher = {Association for Computing Machinery},
  series    = {SoCC '21},
  abstract  = {We present 3MileBeach, a tracing and fault injection platform designed for microservice-based architectures. 3Mile-Beach interposes on the message serialization libraries that are ubiquitous in this environment, avoiding the application code instrumentation that tracing and fault injection infrastructures typically require. 3MileBeach provides message-level distributed tracing at less than 50\% of the overhead of the state-of-the-art tracing frameworks, and fault injection that allows higher precision experiments than existing solutions. We measure the overhead of 3MileBeach as a tracer and its efficacy as a fault injector. We qualitatively measure its promise as a platform for tuning and debugging by sharing concrete use cases in the context of bottleneck identification, performance tuning, and bug finding. Finally, we use 3MileBeach to perform a novel type of fault injection - Temporal Fault Injection (TFI), which more precisely controls individual inter-service message flow with temporal prerequisites, and makes it possible to catch an entirely new class of fault tolerance bugs.},
  doi       = {10.1145/3472883.3486986},
  isbn      = {9781450386388},
  keywords  = {Temporal Fault Injection, Chaos Engineering, Application Tuning, Tracing, Bug Finding},
  location  = {Seattle, WA, USA},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3472883.3486986},
}

@Article{Chen2023a,
  author     = {Chen, Jialuo and Wang, Jingyi and Ma, Xingjun and Sun, Youcheng and Sun, Jun and Zhang, Peixin and Cheng, Peng},
  journal    = {ACM Trans. Softw. Eng. Methodol.},
  title      = {QuoTe: Quality-Oriented Testing for Deep Learning Systems},
  year       = {2023},
  issn       = {1049-331X},
  month      = {jul},
  number     = {5},
  volume     = {32},
  abstract   = {Recently, there has been significant growth of interest in applying software engineering techniques for the quality assurance of deep learning (DL) systems. One popular direction is DL testing—that is, given a property of test, defects of DL systems are found either by fuzzing or guided search with the help of certain testing metrics. However, recent studies have revealed that the neuron coverage metrics, which are commonly used by most existing DL testing approaches, are not necessarily correlated with model quality (e.g., robustness, the most studied model property), and are also not an effective measurement on the confidence of the model quality after testing. In this work, we address this gap by proposing a novel testing framework called QuoTe (i.e., Quality-oriented Testing). A key part of QuoTe is a quantitative measurement on (1) the value of each test case in enhancing the model property of interest (often via retraining) and (2) the convergence quality of the model property improvement. QuoTe utilizes the proposed metric to automatically select or generate valuable test cases for improving model quality. The proposed metric is also a lightweight yet strong indicator of how well the improvement converged. Extensive experiments on both image and tabular datasets with a variety of model architectures confirm the effectiveness and efficiency of QuoTe in improving DL model quality—that is, robustness and fairness. As a generic quality-oriented testing framework, future adaptations can be made to other domains (e.g., text) as well as other model properties.},
  address    = {New York, NY, USA},
  articleno  = {125},
  doi        = {10.1145/3582573},
  issue_date = {September 2023},
  keywords   = {Deep learning, fairness, testing, robustness},
  numpages   = {33},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3582573},
}

@InProceedings{Somashekar2023,
  author    = {Somashekar, Gagan and Kumar, Rajat},
  booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
  title     = {Enhancing the Configuration Tuning Pipeline of Large-Scale Distributed Applications Using Large Language Models (Idea Paper)},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {39–44},
  publisher = {Association for Computing Machinery},
  series    = {ICPE '23 Companion},
  abstract  = {The performance of distributed applications implemented using microservice architecture depends heavily on the configuration of various parameters, which are hard to tune due to large configuration search space and inter-dependence of parameters. While the information in product manuals and technical documents guides the tuning process, manual collection of meta-data for all application parameters is laborious and not scalable. Prior works have largely overlooked the automated use of product manuals, technical documents and source code for extracting such meta-data. In the current work, we propose using large language models for automated meta-data extraction and enhancing the configuration tuning pipeline. We further ideate on building an in-house knowledge system using experimental data to learn important parameters in configuration tuning using historical data on parameter dependence, workload statistics, performance metrics and resource utilization. We expect productionizing the proposed system will reduce the total time and experimental iterations required for configuration tuning in new applications, saving an organization both developer time and money.},
  doi       = {10.1145/3578245.3585032},
  isbn      = {9798400700729},
  keywords  = {microservice architecture, information retrieval, parameter tuning, large language models},
  location  = {Coimbra, Portugal},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3578245.3585032},
}

@Article{Maschi2023,
  author    = {Maschi, Fabio and Alonso, Gustavo},
  journal   = {ACM Trans. Reconfigurable Technol. Syst.},
  title     = {Strega: An HTTP Server for FPGAs},
  year      = {2023},
  issn      = {1936-7406},
  month     = {oct},
  note      = {Just Accepted},
  abstract  = {The computer architecture landscape is being reshaped by the new opportunities, challenges and constraints brought by the cloud. On the one hand, high-level applications profit from specialised hardware to boost their performance and reduce deployment costs. On the other hand, cloud providers maximise the CPU time allocated to client applications by offloading infrastructure tasks to hardware accelerators. While it is well understood how to do this for, e.g., network function virtualisation and protocols such as TCP/IP, support for higher networking layers is still largely missing, limiting the potential of accelerators. In this paper, we present Strega, an open-source1 light-weight HTTP server that enables crucial functionality such as FPGA-accelerated functions being called through a RESTful protocol (FPGA-as-a-Function). Our experimental analysis shows that a single Strega node sustains a throughput of 1.7&nbsp;M HTTP requests per second with an end-to-end latency as low as 16μs, outperforming nginx running on 32 vCPUs in both metrics, and can even be an alternative to the traditional OpenCL flow over the PCIe bus. Through this work, we pave the way for running microservices directly on FPGAs, bypassing CPU overhead and realising the full potential of FPGA acceleration in distributed cloud applications.},
  address   = {New York, NY, USA},
  doi       = {10.1145/3611312},
  keywords  = {FPGA, distributed systems, HTTP, RESTful API, Network on chip, disaggregated accelerator, Webserver},
  publisher = {Association for Computing Machinery},
  url       = {https://doi.org/10.1145/3611312},
}

@Article{Camilli2023,
  author     = {Camilli, Matteo and Colarusso, Carmine and Russo, Barbara and Zimeo, Eugenio},
  journal    = {ACM Trans. Softw. Eng. Methodol.},
  title      = {Actor-Driven Decomposition of Microservices through Multi-Level Scalability Assessment},
  year       = {2023},
  issn       = {1049-331X},
  month      = {jul},
  number     = {5},
  volume     = {32},
  abstract   = {The microservices architectural style has gained widespread acceptance. However, designing applications according to this style is still challenging. Common difficulties concern finding clear boundaries that guide decomposition while ensuring performance and scalability. With the aim of providing software architects and engineers with a systematic methodology, we introduce a novel actor-driven decomposition strategy to complement the domain-driven design and overcome some of its limitations by reaching a finer modularization yet enforcing performance and scalability improvements. The methodology uses a multi-level scalability assessment framework that supports decision-making over iterative steps. At each iteration, architecture alternatives are quantitatively evaluated at multiple granularity levels. The assessment helps architects to understand the extent to which architecture alternatives increase or decrease performance and scalability. We applied the methodology to drive further decomposition of the core microservices of a real data-intensive smart mobility application and an existing open-source benchmark in the e-commerce domain. The results of an in-depth evaluation show that the approach can effectively support engineers in (i) decomposing monoliths or coarse-grained microservices into more scalable microservices and (ii) comparing among alternative architectures to guide decision-making for their deployment in modern infrastructures that orchestrate lightweight virtualized execution units.},
  address    = {New York, NY, USA},
  articleno  = {117},
  doi        = {10.1145/3583563},
  issue_date = {September 2023},
  keywords   = {performance analysis, scalability assessment, architectural patterns, decomposition process, Microservices},
  numpages   = {46},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3583563},
}

@InProceedings{LeThanh2023,
  author    = {Le-Thanh, Phuc and Le-Anh, Tuan and Le-Trung, Quan},
  booktitle = {Proceedings of the 12th International Symposium on Information and Communication Technology},
  title     = {Research and Development of a Smart Solution for Runtime Web Application Self-Protection},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {304–311},
  publisher = {Association for Computing Machinery},
  series    = {SOICT '23},
  abstract  = {In contemporary times, ensuring web application security is a critical concern for organizations due to the prevalence of numerous types of attacks that serve diverse purposes. While traditional security measures such as web application firewalls (WAF) and intrusion detection systems (IDS) can help mitigate attacks, there is still a possibility of them being circumvented or compromised. A more efficacious approach is to adopt runtime application self-protection (RASP) solutions integrated within the web application. This solution has demonstrated its effectiveness by aiding in early attack detection and rapid attack mitigation. In this research, we propose a smart solution for runtime web application self-protection (RASP) to protect against vulnerabilities, attacks, and common weaknesses that have been rated among the top ten web security risks in 2021 by the Open Web Application Security Project (OWASP). The proposed solution leverages convolutional neural network (CNN) and a family of recurrent neural network (RNN) techniques. It builds a deep learning model with deep neural network architectures that scrutinizes user requests, thereby detecting potential SQL injection (SQLi), Cross-Site scripting (XSS), command injection (CMDi), and other types of attacks. The solution is designed to dynamically adapt to the application’s behavior and traffic, with the goal of minimizing false positives and preventing the blocking of legitimate traffic. Furthermore, the proposed solution, based on a microservices architecture, enhances the flexibility of the prediction module during upgrades and automated deployment. It is integrated with MLOps and DevSecOps and is also designed to be compatible with RESTful API servers. Our results have validated the efficacy of this solution in providing real-time application protection.},
  doi       = {10.1145/3628797.3628901},
  isbn      = {9798400708916},
  keywords  = {Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU)., Deep Learning, Convolutional Neural Network (CNN), Web Application Security, Runtime Application Self-Protection (RASP)},
  location  = {<conf-loc>, <city>Ho Chi Minh</city>, <country>Vietnam</country>, </conf-loc>},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3628797.3628901},
}

@InProceedings{Thrivikraman2022,
  author    = {V, Thrivikraman and Dixit, Vishnu R. and S, Nikhil Ram and Gowda, Vikas K. and Vasudevan, Santhosh Kumar and Kalambur, Subramaniam},
  booktitle = {Companion of the 2022 ACM/SPEC International Conference on Performance Engineering},
  title     = {MiSeRTrace: Kernel-Level Request Tracing for Microservice Visibility},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {77–80},
  publisher = {Association for Computing Machinery},
  series    = {ICPE '22},
  abstract  = {With the evolution of microservice applications, the underlying architectures have become increasingly complex compared to their monolith counterparts. This mainly brings in the challenge of observability. By providing a deeper understanding into the functioning of distributed applications, observability enables improving the performance of the system by obtaining a view of the bottlenecks in the implementation. The observability provided by currently existing tools that perform dynamic tracing on distributed applications is limited to the user-space and requires the application to be instrumented to track request flows. In this paper, we present a new open-source framework MiSeRTrace that can trace the end-to-end path of requests entering a microservice application at the kernel space without requiring instrumentation or modification of the application. Observability at the comprehensiveness of the kernel space allows breaking down of various steps in activities such as network transfers and IO tasks, thus enabling root cause based performance analysis and accurate identification of hotspots. MiSeRTrace supports tracing user-enabled kernel events provided by frameworks such as bpftrace or ftrace and isolates kernel activity associated with each application request with minimal overheads. We then demonstrate the working of the solution with results on a benchmark microservice application.},
  doi       = {10.1145/3491204.3527462},
  isbn      = {9781450391597},
  keywords  = {thread state model, microservice, request tracing, misertrace, kernel tracing},
  location  = {Bejing, China},
  numpages  = {4},
  url       = {https://doi.org/10.1145/3491204.3527462},
}

@InProceedings{Hanzo2021,
  author    = {Hanzo, Lajos},
  booktitle = {Proceedings of the 24th International ACM Conference on Modeling, Analysis and Simulation of Wireless and Mobile Systems},
  title     = {Space-Air-Ground Integrated Networking: From Single- to Multi-Component Pareto Optimization},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {1},
  publisher = {Association for Computing Machinery},
  series    = {MSWiM '21},
  abstract  = {Thanks to the spectacular advances in signal processing and nano-technology, five wireless generations have been conceived over the past five decades. Indeed, near-capacity operation at an infinitesimally low error-rate has become feasible and flawless multimedia communications is supported in areas of high traffic-density, but how do we fill the huge coverage holes existing across the globe? As a promising system-architecture, the SAGIN concept constituted by an integrated terrestrial, UAV-aided, airplane-assisted as well as satellite-based global coverage-solution will be highlighted to pave the way for seamless next-generation service provision. However, these links exhibit strongly heterogeneous properties, hence requiring different enabling techniques. The joint optimization of the associated conflicting performance metrics of throughput, transmit power, latency, error probability, hand-over probability and link-lifetime poses an extremely challenging problem. Explicitly, sophisticated multi-component system optimization is required for finding the Pareto-front of all optimal solutions, where none of the above-mentioned metric can be improved without degrading at least one of the others [1] - [5]....},
  doi       = {10.1145/3479239.3485679},
  isbn      = {9781450390774},
  location  = {Alicante, Spain},
  numpages  = {1},
  url       = {https://doi.org/10.1145/3479239.3485679},
}

@InProceedings{Lanciano2021,
  author    = {Lanciano, Giacomo and Galli, Filippo and Cucinotta, Tommaso and Bacciu, Davide and Passarella, Andrea},
  booktitle = {Proceedings of the 14th IEEE/ACM International Conference on Utility and Cloud Computing},
  title     = {Predictive Auto-Scaling with OpenStack Monasca},
  year      = {2021},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {UCC '21},
  abstract  = {Cloud auto-scaling mechanisms are typically based on reactive automation rules that scale a cluster whenever some metric, e.g., the average CPU usage among instances, exceeds a predefined threshold. Tuning these rules becomes particularly cumbersome when scaling-up a cluster involves non-negligible times to bootstrap new instances, as it happens frequently in production cloud services.To deal with this problem, we propose an architecture for auto-scaling cloud services based on the status in which the system is expected to evolve in the near future. Our approach leverages on time-series forecasting techniques, like those based on machine learning and artificial neural networks, to predict the future dynamics of key metrics, e.g., resource consumption metrics, and apply a threshold-based scaling policy on them. The result is a predictive automation policy that is able, for instance, to automatically anticipate peaks in the load of a cloud application and trigger ahead of time appropriate scaling actions to accommodate the expected increase in traffic.We prototyped our approach as an open-source OpenStack component, which relies on, and extends, the monitoring capabilities offered by Monasca, resulting in the addition of predictive metrics that can be leveraged by orchestration components like Heat or Senlin. We show experimental results using a recurrent neural network and a multi-layer perceptron as predictor, which are compared with a simple linear regression and a traditional non-predictive auto-scaling policy. However, the proposed framework allows for the easy customization of the prediction policy as needed.},
  articleno = {20},
  doi       = {10.1145/3468737.3494104},
  isbn      = {9781450385640},
  keywords  = {elasticity auto-scaling, time-series forecasting, OpenStack, predictive operations},
  location  = {Leicester, United Kingdom},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3468737.3494104},
}

@InProceedings{Liu2022a,
  author    = {Liu, Wencong and Liu, Jiamou and Zhang, Zijian and Liu, Yiwei and Zhu, Liehuang},
  booktitle = {Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems},
  title     = {Residual Entropy-Based Graph Generative Algorithms},
  year      = {2022},
  address   = {Richland, SC},
  pages     = {816–824},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
  series    = {AAMAS '22},
  abstract  = {Classification and clustering are crucial tasks that recognize the identities and the communities of nodes in a graph. Several methods have been proposed to reduce the accuracy of node classification and clustering through graph neural networks (GNN). Existing defense methods usually modify the model architecture and adopt countermeasure training to enhance the robustness of the node classification and clustering. However, these defense methods are model-oriented and not robust.To alleviate the problem, this paper first proposes a robust node classification metric based on residual entropy. More concretely, we prove that maximizing the residual entropy helps to improve the robustness of the classification accuracy. We them propose two graph generative algorithms to resist against two kinds of GNN-based attacks, the untargeted and the targeted attacks. Finally, experimental analysis show that the proposed algorithms outperform the existing defense works under five classic datasets.},
  isbn      = {9781450392136},
  keywords  = {robustness, graph generative algorithm, graph adversarial learning, residual entropy, node classification},
  location  = {Virtual Event, New Zealand},
  numpages  = {9},
}

@InProceedings{Balaji2021,
  author    = {Balaji, Adarsha and Song, Shihao and Titirsha, Twisha and Das, Anup and Krichmar, Jeffrey and Dutt, Nikil and Shackleford, James and Kandasamy, Nagarajan and Catthoor, Francky},
  booktitle = {International Conference on Neuromorphic Systems 2021},
  title     = {NeuroXplorer 1.0: An Extensible Framework for Architectural Exploration with Spiking Neural Networks},
  year      = {2021},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ICONS 2021},
  abstract  = {Recently, both industry and academia have proposed many different neuromorphic architectures to execute applications that are designed with Spiking Neural Network (SNN). Consequently, there is a growing need for an extensible simulation framework that can perform architectural explorations with SNNs, including both platform-based design of today’s hardware, and hardware-software co-design and design-technology co-optimization of the future. We present NeuroXplorer, a fast and extensible framework that is based on a generalized template for modeling a neuromorphic architecture that can be infused with the specific details of a given hardware and/or technology. NeuroXplorer can perform both low-level cycle-accurate architectural simulations and high-level analysis with data-flow abstractions. NeuroXplorer’s optimization engine can incorporate hardware-oriented metrics such as energy, throughput, and latency, as well as SNN-oriented metrics such as inter-spike interval distortion and spike disorder, which directly impact SNN performance. We demonstrate the architectural exploration capabilities of NeuroXplorer through case studies with many state-of-the-art machine learning models.},
  articleno = {10},
  doi       = {10.1145/3477145.3477156},
  isbn      = {9781450386913},
  keywords  = {Spiking Neural Networks (SNN), Design-Technology Co-Optimization, Neuromorphic Computing, Platform-Based Design, Hardware-Software Co-Design, Non Volatile Memory (NVM)},
  location  = {Knoxville, TN, USA},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3477145.3477156},
}

@InProceedings{Ning2023,
  author    = {Ning, August and Tziantzioulis, Georgios and Wentzlaff, David},
  booktitle = {Proceedings of the 50th Annual International Symposium on Computer Architecture},
  title     = {Supply Chain Aware Computer Architecture},
  year      = {2023},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ISCA '23},
  abstract  = {Progressively and increasingly, our society has become more and more dependent on semiconductors and semiconductor-enabled products and services. The importance of chips and their supply chains has been highlighted during the 2020-present chip shortage caused by manufacturing disruptions and increased demand due to the COVID-19 pandemic. However, semiconductor supply chains are inherently vulnerable to disruptions and chip crises can easily recur in the future.We present the first work that elevates supply chain conditions to be a first-class design constraint for future computer architectures. We characterize and model the chip creation process from standard tapeout to packaging to provide a framework for architects to quickly assess the time-to-market of their chips depending on their architecture and the current market conditions. In addition, we propose a novel metric, the Chip Agility Score (CAS) - a way to quantify a chip architecture's resilience against production-side supply changes.We utilize our proposed time-to-market model, CAS, and chip design/manufacturing economic models to evaluate prominent architectures in the context of current and speculative supply chain changes. We find that using an older process node to re-release chips can decrease time-to-market by 73\%-116\% compared to using the most advanced processes. Also, mixed-process chiplet architectures can be 24\%-51\% more agile compared to equivalent single-process chiplet and monolithic designs respectively. Guided by our framework, we present an architectural design methodology that minimizes time-to-market and chip creation costs while maximizing agility for mass-produced legacy node chips.Our modeling framework and data sets are open-sourced to advance supply chain aware computer architecture research. https://github.com/PrincetonUniversity/ttm-cas},
  articleno = {17},
  doi       = {10.1145/3579371.3589052},
  isbn      = {9798400700958},
  keywords  = {chip shortage, semiconductor supply chain, economics, modeling},
  location  = {Orlando, FL, USA},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3579371.3589052},
}

@InProceedings{Victor2022,
  author    = {Victor, Carlos and Nguyen, Tuan Anh and Silva, Leonardo Augusto and Andrade, Ermeson and Santo, Guto Leoni and Min, Dugki and Lee, Jae Woo and Silva, Francisco Airton},
  booktitle = {Proceedings of the 2021 IEEE/ACM 25th International Symposium on Distributed Simulation and Real Time Applications},
  title     = {Performability Assessment and Sensitivity Analysis of a Home Automation System},
  year      = {2022},
  address   = {Valencia, Spain},
  publisher = {IEEE Press},
  series    = {DS-RT '21},
  abstract  = {Home automation or domotics is a typical representative of everything as a service (XaaS). Individual houses are equipped with Internet of Things (IoT) sensors and home facilities capable of self-assessment to offer comfortable, secure, and high-quality home services to their residents. However, assessing such systems with a high level of diversity is paramount of importance and challenging to assimilate. Domotics XaaS requires a high quality of service (QoS) in service performance and operational availability. In that regard, we propose, in this paper, a modeling approach based on stochastic Petri nets (SPN) for the performability quantification of domotics architectures. SPN performability models are developed following the architecture of a home automation system consisting of several IoT sensors/devices to evaluate the trade-offs between performance and availability of home automation services. The inter-dependency between performance and availability metrics is evaluated. The metrics include, for example, the mean response time (MRT) and the number of discarded packets. Sensitivity analysis using the design of experiments (DoE) is performed to identify the system's impacting components and performability bottleneck. Simulation results highlight the useful aspects of the proposed performability models for architectural and operational optimization of home automation XaaS infrastructures.},
  articleno = {18},
  doi       = {10.1109/DS-RT52167.2021.9576142},
  isbn      = {9781665433266},
  keywords  = {stochastic models, home automation, domotics},
  numpages  = {4},
  url       = {https://doi.org/10.1109/DS-RT52167.2021.9576142},
}

@InProceedings{Qazi2021,
  author    = {Qazi, Ihsan Ayyub and Qazi, Zafar Ayyub and Ali, Ayesha and Abdullah, Muhammad and Habib, Rumaisa},
  booktitle = {Proceedings of the 20th ACM Workshop on Hot Topics in Networks},
  title     = {Rethinking Web for Affordability and Inclusion},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {9–15},
  publisher = {Association for Computing Machinery},
  series    = {HotNets '21},
  abstract  = {Today's Web remains too expensive for many Internet users, especially in developing regions. Unfortunately, the rising complexity of the Web makes affordability an even bigger concern as it stands to limit users' access to Internet services. We propose a novel framework and fairness metric for rethinking Web architecture for affordability and inclusion. Our framework provides systematic guidelines for adapting Web complexity based on geographic variations in mobile broadband prices and income levels. Preliminary evaluation shows the resulting architecture can achieve a better balance between Web quality and affordability while preserving user privacy.},
  doi       = {10.1145/3484266.3487376},
  isbn      = {9781450390873},
  keywords  = {Inclusion, Web, Affordability, User Privacy},
  location  = {<conf-loc>, <city>Virtual Event</city>, <country>United Kingdom</country>, </conf-loc>},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3484266.3487376},
}

@InProceedings{Holzinger2021,
  author    = {Holzinger, Kilian and Stubbe, Henning and Biersack, Franz and Mari\~{n}o, Angela Gonzalez and Kane, Abdoul and Lluis, Francisco Fons and Haigang, Zhang and Wild, Thomas and Herkersdorf, Andreas and Carle, Georg},
  booktitle = {Proceedings of the 17th International Conference on Emerging Networking EXperiments and Technologies},
  title     = {Precise Real-Time Monitoring of Time-Critical Flows},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {489–490},
  publisher = {Association for Computing Machinery},
  series    = {CoNEXT '21},
  abstract  = {Ethernet is increasingly used in areas where time-critical and safety-relevant data are transported over the network along with best-effort flows, for example in intra vehicle networks or industrial networks. The resulting complex network architectures, time-sensitive networking configurations and system interactions are hard to foresee during the design phase. Therefore, it is hard to rule out any violations of flow specifications or timing and reliability requirements, especially in the presence of unpredictable failures.In this work, the design of a flow-oriented network monitoring system for time-sensitive applications is presented. It continuously supervises relevant performance metrics with high precision and short detection delay. Moreover, it allows to check compliance with flow specifications in real-time. Initial evaluations using intra vehicle network traffic yield a high measurement precision.},
  doi       = {10.1145/3485983.3493356},
  isbn      = {9781450390989},
  location  = {Virtual Event, Germany},
  numpages  = {2},
  url       = {https://doi.org/10.1145/3485983.3493356},
}

@InProceedings{Shan2022,
  author    = {Shan, Yizhou and Lin, Will and Guo, Zhiyuan and Zhang, Yiying},
  booktitle = {Proceedings of the 13th ACM SIGOPS Asia-Pacific Workshop on Systems},
  title     = {Towards a Fully Disaggregated and Programmable Data Center},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {18–28},
  publisher = {Association for Computing Machinery},
  series    = {APSys '22},
  abstract  = {Today, we are seeing two trends in the data center. On the one hand, applications are becoming more fine-grained, driven by the recent trend of serverless computing and microservices. On the other hand, data-center hardware is becoming more heterogeneous and customized to different computing needs. Because of these trends and for better manageability, several major data centers are moving towards a disaggregated architecture, where different hardware resources like storage and accelerators are organized as independent, network-attached pools. However, data centers today are still server-centric and relies heavily on traditional CPU-based servers.In this paper, we take a step further and explore the possibility of building a fully disaggregated data center, where every type of resource is disaggregated. Moreover, we explore the requirements and implications of making each of the disaggregated device programmable. We present guidelines and initial solutions for data center designers to navigate design trade-offs. Specifically, we decompose the overarching problem into four sub-problems and propose solutions to each of them. At the top layer, we explore two types of abstractions and propose a disaggregation-native design methodology. At the bottom layer, we describe the hardware and key features required to build disaggregated devices as well as the networking infrastructure to connect them. To bridge these two layers, we propose a static-time component that compiles different user programs into heterogeneous disaggregated devices through a disaggregation-native intermediate representation. We also propose a run-time system that manages hardware resources and schedules compiler generated execution units. We hope our proposal can pave the way for future disaggregated and programmable data center deployment.},
  doi       = {10.1145/3546591.3547527},
  isbn      = {9781450394413},
  keywords  = {data-center network, resource disaggregation, data-center hardware architecture},
  location  = {Virtual Event, Singapore},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3546591.3547527},
}

@InProceedings{Makama2023,
  author    = {Makama, Aliyu and Kuladinithi, Koojana and Timm-Giel, Andreas},
  booktitle = {Proceedings of the 19th ACM International Symposium on QoS and Security for Wireless and Mobile Networks},
  title     = {Evaluation of IEEE 802.11 Ad Hoc-Based Wireless Seismic Data Acquisition Networks},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {25–32},
  publisher = {Association for Computing Machinery},
  series    = {Q2SWinet '23},
  abstract  = {This paper investigates the performance of a proposed IEEE 802.11 ad hoc-based wireless seismic data acquisition (WSDA) network architecture. The study centers on examining the network performance in the 2.4 and 5 SI gigahertz bands with focus on addressing WSDA challenges such as scalability, reliability, self-configuration and organization, interference effects, and latency. Routing Protocol for Low-Power and Lossy Networks (RPL) is used as the enabling routing protocol employing the multiple Destination Oriented Directed Acyclic Graph (multi-DODAG) architecture. OMNeT++ discrete event simulator is used to evaluate the network performance, using metrics such as packet delivery ratio (PDR), end-to-end delay (E2ED), packet error rate (PER), retransmission ratio, packet dropped, etc. Results show that the proposed network architecture is scalable and reliable with large number of geophones in the network. In addition, Routing Protocol for Low-Power and Lossy Networks (RPL) proves to be a suitable candidate to enable self-configuration and organization in multi-hop ad hoc WSDA networks.},
  doi       = {10.1145/3616391.3622766},
  isbn      = {9798400703683},
  keywords  = {wireless gateway (gw), geophones, wireless geophone network (wgn), routing protocol for low-power and lossy networks (rpl), central control unit (ccu), wireless seismic data acquisition (wsda), destination oriented directed acyclic graph (dodag).},
  location  = {<conf-loc>, <city>Montreal</city>, <state>Quebec</state>, <country>Canada</country>, </conf-loc>},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3616391.3622766},
}

@InProceedings{Chancusig2022,
  author    = {Chancusig, Cristian and Tumbaco, Sergio and Alulema, Darwin and Iribarne, Luis and Criado, Javier},
  booktitle = {Proceedings of the 14th International Conference on Management of Digital EcoSystems},
  title     = {Binary Classification Architecture for Edge Computing Based on Cognitive Services and Deep Neural Networks},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {148–155},
  publisher = {Association for Computing Machinery},
  series    = {MEDES '22},
  abstract  = {Systems based on computer vision and artificial intelligence are an alternative for repetitive inspection processes. However, it is possible to extend the learning capacity of these systems to classify multiple objects using edge computing. This allows combining local processing with cloud processing to expand the possibilities and reduce the response time. In this work, a classification architecture based on remote web services and local neural networks is proposed. To test this architecture, Microsoft Azure cognitive web services and its Computer Vision API have been used, combined with the use of transfer learning and ResNet 50. The cloud service allows the identification and labelling of image content, while the Edge service, based on the neural network, allows the generation of classification models for those objects not identified or incorrectly identified by the remote service. The architecture allows to extend the possibility of image recognition by integrating web services that combined with edge processing accelerate the identification process. The proposed architecture is composed of three layers; (a) a physical layer, for the mechanical and electronic structure; (b) a logical layer, which defines the interaction of the remote and local image recognition web services, and (c) an application layer, for the integration of the monitoring and control interfaces. Finally, the architecture was evaluated through functionality testing and performance metrics of classification models, as well as load and usability testing.},
  doi       = {10.1145/3508397.3564828},
  isbn      = {9781450392198},
  keywords  = {edge computing, computer vision, cyber-physical systems, neural network, microservices},
  location  = {Venice, Italy},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3508397.3564828},
}

@InProceedings{Mwotil2022,
  author    = {Mwotil, Alex and Bainomugisha, Engineer and Araka, Stephen G.M.},
  booktitle = {Proceedings of the Federated Africa and Middle East Conference on Software Engineering},
  title     = {Mira: An Application Containerisation Pipeline for Small Software Development Teams in Low Resource Settings},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {31–38},
  publisher = {Association for Computing Machinery},
  series    = {FAMECSE '22},
  abstract  = {Cloud native applications leverage Development and Operation (DevOps), microservice architectures and containerisation for primarily availability, resilience and scalability reasons. Small developer teams in low resource settings have unique DevOps needs and harnessing its principles and practices is technically challenging and distinctly difficult in these contexts. We conducted a survey with professional developers, students and researchers situated and working in a low resource setting and the results indicate that these principles and practices are relatively new. In application containerisation, an operating system virtualisation method that can significantly optimize the use of computing resources, the respondents indicated challenges in the process steps. Particularly, small developer teams in low resource settings require custom tools and abstractions for software development and delivery automation. Informed by the developer needs, we designed and developed a custom automated containerisation pipeline, mira, for a managed cloud native platform situated in a low-resource setting. We validate mira against 6 major application frameworks, tools and/or languages and successful deployment of the resultant applications onto a cloud native platform.},
  doi       = {10.1145/3531056.3542769},
  isbn      = {9781450396639},
  keywords  = {cloud, cloud native, orchestration, automation, containers, docker},
  location  = {Cairo-Kampala, Egypt},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3531056.3542769},
}

@InProceedings{Habib2023,
  author    = {Habib, Rumaisa and Tanveer, Sarah and Inam, Aimen and Ahmed, Haseeb and Ali, Ayesha and Uzmi, Zartash Afzal and Qazi, Zafar Ayyub and Qazi, Ihsan Ayyub},
  booktitle = {Proceedings of the ACM SIGCOMM 2023 Conference},
  title     = {A Framework for Improving Web Affordability and Inclusiveness},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {592–607},
  publisher = {Association for Computing Machinery},
  series    = {ACM SIGCOMM '23},
  abstract  = {Today's Web remains too expensive for many Internet users, especially in developing regions. Unfortunately, the rising complexity of the Web makes affordability an even bigger concern as it stands to limit users' access to Internet services. We propose a novel framework and a fairness metric for rethinking Web architecture for affordability and inclusion. Our proposed framework systematically adapts Web complexity based on geographic variations in mobile broadband prices and income levels. We conduct a cross-country analysis of 99 countries, showing that our framework can better balance affordability and webpage quality while preserving user privacy. To adapt Web complexity, our framework solves an optimization problem to produce webpages that maximize page quality while reducing the webpage to a given target size.},
  doi       = {10.1145/3603269.3604872},
  isbn      = {9798400702365},
  keywords  = {inclusion, user privacy, transcoding service, web, affordability},
  location  = {New York, NY, USA},
  numpages  = {16},
  url       = {https://doi.org/10.1145/3603269.3604872},
}

@InProceedings{Li2022c,
  author    = {Li, Sen and Lv, Fuyu and Jin, Taiwei and Li, Guiyang and Zheng, Yukun and Zhuang, Tao and Liu, Qingwen and Zeng, Xiaoyi and Kwok, James and Ma, Qianli},
  booktitle = {Proceedings of the 31st ACM International Conference on Information \&amp; Knowledge Management},
  title     = {Query Rewriting in TaoBao Search},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {3262–3271},
  publisher = {Association for Computing Machinery},
  series    = {CIKM '22},
  abstract  = {In e-commerce search engines, query rewriting (QR) is a crucial technique that improves shopping experience by reducing the vocabulary gap between user queries and product catalog. Recent works have mainly adopted the generative paradigm. However, they hardly ensure high-quality generated rewrites and do not consider personalization, which leads to degraded search relevance. In this work, we present Contrastive Learning Enhanced Query Rewriting (CLE-QR), the solution used in Taobao product search. It uses a novel contrastive learning enhanced architecture based on "query retrieval-semantic relevance ranking-online ranking". It finds the rewrites from hundreds of millions of historical queries while considering relevance and personalization. Specifically, we first alleviate the representation degeneration problem during the query retrieval stage by using an unsupervised contrastive loss, and then further propose an interaction-aware matching method to find the beneficial and incremental candidates, thus improving the quality and relevance of candidate queries. We then present a relevance-oriented contrastive pre-training paradigm on the noisy user feedback data to improve semantic ranking performance. Finally, we rank these candidates online with the user profile to model personalization for the retrieval of more relevant products. We evaluate CLE-QR on Taobao Product Search, one of the largest e-commerce platforms in China. Significant metrics gains are observed in online A/B tests. CLE-QR has been deployed to our large-scale commercial retrieval system and serviced hundreds of millions of users since December 2021. We also introduce its online deployment scheme, and share practical lessons and optimization tricks of our lexical match system.},
  doi       = {10.1145/3511808.3557068},
  isbn      = {9781450392365},
  keywords  = {e-commerce search, query rewriting, lexical match},
  location  = {Atlanta, GA, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3511808.3557068},
}

@InProceedings{Gao2023,
  author    = {Gao, Qihong and Wu, Yuxuan and Hao, Yi},
  booktitle = {Proceedings of the 2022 10th International Conference on Information Technology: IoT and Smart City},
  title     = {Design and Implementation of an Edge Container Management Platform Based on Artificial Intelligence},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {257–261},
  publisher = {Association for Computing Machinery},
  series    = {ICIT '22},
  abstract  = {The deployment and maintenance of IoT applications require a lot of manual work. To reduce the workload of the operation and maintenance personnel of the edge IoT system and improve the efficiency of edge applications, containerization technology based on K3s is more and more widely used. However, the existing edge container management platforms are not convenient in terms of application deployment and overall maintenance. This paper designs and implements an edge container management platform that supports AI operation and maintenance. In terms of design concepts, the abstract concepts involved in containerization technology are embodied as projects, which are easy to understand. In terms of management and control subsystems, the construction of the overall architecture and the interaction of various modules have been completed, thus, users can conveniently deploy and schedule edge applications and services. In terms of operation and maintenance subsystems, real-time collection, persistence, and analysis of logs, metric data, and trace data at all levels of the system are realized. In terms of visualization, the front-end display and monitoring of the system status are completed, which is convenient for project developers and platform operators to understand the running status of the project and platform in real-time, and provides a better solution for deployment and maintenance of IoT applications.},
  doi       = {10.1145/3582197.3582240},
  isbn      = {9781450397438},
  keywords  = {AIOps, Containerization technology, Edge computing, K3s},
  location  = {<conf-loc>, <city>Shanghai</city>, <country>China</country>, </conf-loc>},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3582197.3582240},
}

@Article{Anzt2022,
  author     = {Anzt, Hartwig and Cojean, Terry and Flegar, Goran and G\"{o}bel, Fritz and Gr\"{u}tzmacher, Thomas and Nayak, Pratik and Ribizel, Tobias and Tsai, Yuhsiang Mike and Quintana-Ort\'{\i}, Enrique S.},
  journal    = {ACM Trans. Math. Softw.},
  title      = {Ginkgo: A Modern Linear Operator Algebra Framework for High Performance Computing},
  year       = {2022},
  issn       = {0098-3500},
  month      = {feb},
  number     = {1},
  volume     = {48},
  abstract   = {In this article, we present Ginkgo, a modern C++ math library for scientific high performance computing. While classical linear algebra libraries act on matrix and vector objects, Ginkgo’s design principle abstracts all functionality as “linear operators,” motivating the notation of a “linear operator algebra library.” Ginkgo’s current focus is oriented toward providing sparse linear algebra functionality for high performance graphics processing unit (GPU) architectures, but given the library design, this focus can be easily extended to accommodate other algorithms and hardware architectures. We introduce this sophisticated software architecture that separates core algorithms from architecture-specific backends and provide details on extensibility and sustainability measures. We also demonstrate Ginkgo’s usability by providing examples on how to use its functionality inside the MFEM and deal.ii finite element ecosystems. Finally, we offer a practical demonstration of Ginkgo’s high performance on state-of-the-art GPU architectures.},
  address    = {New York, NY, USA},
  articleno  = {2},
  doi        = {10.1145/3480935},
  issue_date = {March 2022},
  keywords   = {High performance computing, multi-core and manycore architectures, healthy software lifecycle},
  numpages   = {33},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3480935},
}

@InProceedings{Viegas2023,
  author    = {Viegas, Felipe and Canuto, Sergio and Cunha, Washington and Fran\c{c}a, Celso and Valiense, Claudio and Rocha, Leonardo and Gon\c{c}alves, Marcos Andr\'{e}},
  booktitle = {Proceedings of the 29th Brazilian Symposium on Multimedia and the Web},
  title     = {CluSent – Combining Semantic Expansion and De-Noising for Dataset-Oriented Sentiment Analysis of Short Texts},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {110–118},
  publisher = {Association for Computing Machinery},
  series    = {WebMedia '23},
  abstract  = {The lack of sufficient information, mainly in short texts, is a major challenge to building effective sentiment models. Short texts can be enriched with more complex semantic relationships that better capture affective information, with a potential undesired side effect of noise introduced into the data. This work proposes a new strategy for customized dataset-oriented sentiment analysis – CluSent – that exploits a powerful, recently proposed concept for representing semantically related words – CluWords. CluSent tackles the issues mentioned above of information shortage and noise by: (i) exploiting the semantic neighborhood of a given pre-trained word embedding to enrich document representation and (ii) introducing dataset-oriented filtering and weighting mechanisms to cope with noise, which takes advantage of the polarity and intensity information from lexicons. In our experimental evaluation, considering 19 datasets, five state-of-the-art baselines (including modern transformer architectures), and two metrics, CluSent was the best method in 30 out of 38 possibilities, with significant gains over the strongest baselines (over 14\%).},
  doi       = {10.1145/3617023.3617039},
  isbn      = {9798400709081},
  keywords  = {Sentiment Analysis, Classification, Natural Language Processing},
  location  = {<conf-loc>, <city>Ribeir\~{a}o Preto</city>, <country>Brazil</country>, </conf-loc>},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3617023.3617039},
}

@InProceedings{Li2022d,
  author    = {Li, Mingjie and Li, Zeyan and Yin, Kanglin and Nie, Xiaohui and Zhang, Wenchi and Sui, Kaixin and Pei, Dan},
  booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  title     = {Causal Inference-Based Root Cause Analysis for Online Service Systems with Intervention Recognition},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {3230–3240},
  publisher = {Association for Computing Machinery},
  series    = {KDD '22},
  abstract  = {Fault diagnosis is critical in many domains, as faults may lead to safety threats or economic losses. In the field of online service systems, operators rely on enormous monitoring data to detect and mitigate failures. Quickly recognizing a small set of root cause indicators for the underlying fault can save much time for failure mitigation. In this paper, we formulate the root cause analysis problem as a new causal inference task namedintervention recognition. We proposed a novel unsupervised causal inference-based method namedCausal Inference-based Root Cause Analysis (CIRCA). The core idea is a sufficient condition for a monitoring variable to be a root cause indicator,i.e., the change of probability distribution conditioned on the parents in the Causal Bayesian Network (CBN). Towards the application in online service systems, CIRCA constructs a graph among monitoring metrics based on the knowledge of system architecture and a set of causal assumptions. The simulation study illustrates the theoretical reliability of CIRCA. The performance on a real-world dataset further shows that CIRCA can improve the recall of the top-1 recommendation by 25\% over the best baseline method.},
  doi       = {10.1145/3534678.3539041},
  isbn      = {9781450393850},
  keywords  = {online service systems, causal inference, intervention recognition, root cause analysis},
  location  = {Washington DC, USA},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3534678.3539041},
}

@InProceedings{Hu2022,
  author    = {Hu, Wei},
  booktitle = {Proceedings of the 5th International Conference on Computer Science and Software Engineering},
  title     = {The Design and Implementation of Civil Aviation Meteorological Emergency Service Platform Based on 5G},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {691–694},
  publisher = {Association for Computing Machinery},
  series    = {CSSE '22},
  abstract  = {In view of the problem that users cannot obtain meteorological data in time due to the interruption of Internet line in the current civil aviation meteorological external service system. Designing and implementing a civil aviation meteorological emergency service platform based on 5G. The platform is built based on C/S architecture. Firstly, designing and implementing the whole business module of the platform, and then establishing the corresponding protective measures for the security of the platform. Finally, deploying the 5G module between the data upload and the client, meanwhile, realizing the underlying switching logic between the Internet and 5G line. The application result shows that due to the use of 5G technology, The platform can provide users with meteorological emergency service in case of Internet interruption},
  doi       = {10.1145/3569966.3571190},
  isbn      = {9781450397780},
  keywords  = {5G, meteorological service, emergency, civil aviation meteorological},
  location  = {<conf-loc>, <city>Guilin</city>, <country>China</country>, </conf-loc>},
  numpages  = {4},
  url       = {https://doi.org/10.1145/3569966.3571190},
}

@Article{Lee2023,
  author     = {Lee, JunKyu and Mukhanov, Lev and Molahosseini, Amir Sabbagh and Minhas, Umar and Hua, Yang and Martinez del Rincon, Jesus and Dichev, Kiril and Hong, Cheol-Ho and Vandierendonck, Hans},
  journal    = {ACM Comput. Surv.},
  title      = {Resource-Efficient Convolutional Networks: A Survey on Model-, Arithmetic-, and Implementation-Level Techniques},
  year       = {2023},
  issn       = {0360-0300},
  month      = {jul},
  number     = {13s},
  volume     = {55},
  abstract   = {Convolutional neural networks (CNNs) are used in our daily life, including self-driving cars, virtual assistants, social network services, healthcare services, and face recognition, among others. However, deep CNNs demand substantial compute resources during training and inference. The machine learning community has mainly focused on model-level optimizations such as architectural compression of CNNs, whereas the system community has focused on implementation-level optimization. In between, various arithmetic-level optimization techniques have been proposed in the arithmetic community. This article provides a survey on resource-efficient CNN techniques in terms of model-, arithmetic-, and implementation-level techniques, and identifies the research gaps for resource-efficient CNN techniques across the three different level techniques. Our survey clarifies the influence from higher- to lower-level techniques based on our resource efficiency metric definition and discusses the future trend for resource-efficient CNN research.},
  address    = {New York, NY, USA},
  articleno  = {276},
  doi        = {10.1145/3587095},
  issue_date = {December 2023},
  keywords   = {neural networks, arithmetic utilization, Convolutional neural networks, resource efficiency},
  numpages   = {36},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3587095},
}

@InProceedings{Zhang2022c,
  author    = {Zhang, Jingjing and Fang, Shancheng and Mao, Zhendong and Zhang, Zhiwei and Zhang, Yongdong},
  booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
  title     = {Fine-Tuning with Multi-Modal Entity Prompts for News Image Captioning},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {4365–4373},
  publisher = {Association for Computing Machinery},
  series    = {MM '22},
  abstract  = {News Image Captioning aims to generate descriptions for images embedded in news articles, including plentiful real-world concepts, especially about named entities. However, existing methods are limited in the entity-level template. Not only is it labor-intensive to craft the template, but it is error-prone due to local entity-aware, which solely constrains the prediction output at each language model decoding step with corrupted entity relationship. To overcome the problem, we investigate a concise and flexible paradigm to achieve global entity-aware by introducing a prompting mechanism with fine-tuning pre-trained models, named Fine-tuning with Multi-modal Entity Prompts for News Image Captioning (NewsMEP). Firstly, we incorporate two pre-trained models: (i) CLIP, translating the image with open-domain knowledge; (ii) BART, extended to encode article and image simultaneously. Moreover, leveraging the BART architecture, we can easily take the end-to-end fashion. Secondly, we prepend the target caption with two prompts to utilize entity-level lexical cohesion and inherent coherence in the pre-trained language model. Concretely, the visual prompts are obtained by mapping CLIP embeddings, and contextual vectors automatically construct the entity-oriented prompts. Thirdly, we provide an entity chain to control caption generation that focuses on entities of interest. Experiments results on two large-scale publicly available datasets, including detailed ablation studies, show that our NewsMEP not only outperforms state-of-the-art methods in general caption metrics but also achieves significant performance in precision and recall of various named entities.},
  doi       = {10.1145/3503161.3547883},
  isbn      = {9781450392037},
  keywords  = {fine-tuning, entity prompts, news image captioning, named entity},
  location  = {<conf-loc>, <city>Lisboa</city>, <country>Portugal</country>, </conf-loc>},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3503161.3547883},
}

@InProceedings{Li2023a,
  author    = {Li, Dejian and Cui, Bingrong and Li, Kaixin and Shen, Tianjun and Sun, Yi and Chang, Shaonan},
  booktitle = {Proceedings of the 2022 5th International Conference on Telecommunications and Communication Engineering},
  title     = {Energy Efficient Offloading Strategy Faced to Edge Computing-Enhanced Distributed Photovoltaic Smart Meter},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {161–164},
  publisher = {Association for Computing Machinery},
  series    = {ICTCE '22},
  abstract  = {With the rapid development of Power Internet of Things and the increase in the number of distributed photovoltaic smart meter (DPSM) technology, edge computing is required to support the low-latency computing service. Current works mainly focus on task offloading, the cooperation among smart meter devices is lack of attention. In order to reduce the task execution delay in of the network, a computing resource sharing architecture based on D2D is proposed. In order to reduce the processing delay and energy consumption of DPSM, we propose a task offloading model faced to DPSM. To minimize the total task execution delay, we formulate a Mixed-Integer Non-Linear Programming (MINLP) problem which optimizing task offloading and resource allocation jointly. Then, a generalized Benders decomposition algorithm combined with particle swarm optimization is proposed to solve the problem. Simulation results show that the proposed strategy can effectively improve the measurement efficiency and reduce the computational cost.},
  doi       = {10.1145/3577065.3577094},
  isbn      = {9781450397797},
  keywords  = {Edge computing, Cost optimization, Task offloading, Smart meter},
  location  = {<conf-loc>, <city>Chengdu</city>, <country>China</country>, </conf-loc>},
  numpages  = {4},
  url       = {https://doi.org/10.1145/3577065.3577094},
}

@InProceedings{Duraisamy2023,
  author    = {Duraisamy, Padmapriya and Xu, Wei and Hare, Scott and Rajwar, Ravi and Culler, David and Xu, Zhiyi and Fan, Jianing and Kennelly, Christopher and McCloskey, Bill and Mijailovic, Danijela and Morris, Brian and Mukherjee, Chiranjit and Ren, Jingliang and Thelen, Greg and Turner, Paul and Villavieja, Carlos and Ranganathan, Parthasarathy and Vahdat, Amin},
  booktitle = {Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
  title     = {Towards an Adaptable Systems Architecture for Memory Tiering at Warehouse-Scale},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {727–741},
  publisher = {Association for Computing Machinery},
  series    = {ASPLOS 2023},
  abstract  = {Fast DRAM increasingly dominates infrastructure spend in large scale computing environments and this trend will likely worsen without an architectural shift. The cost of deployed memory can be reduced by replacing part of the conventional DRAM with lower cost albeit slower memory media, thus creating a tiered memory system where both tiers are directly addressable and cached. But, this poses numerous challenges in a highly multi-tenant warehouse-scale computing setting. The diversity and scale of its applications motivates an application-transparent solution in the general case, adaptable to specific workload demands.  

This paper presents TMTS(Transparent Memory Tiering System), an application-transparent memory tiering management system that implements an adaptive, hardware-guided architecture to dynamically optimize access to the various directly-addressed memory tiers without faults. TMTS has been deployed at scale for two years serving thousands of production services, successfully meeting service level objectives (SLOs) across diverse application classes in the fleet. The solution is developed in terms of system level metrics it seeks to optimize and evaluated across the diverse workload mix to guide advanced policies embodied in a user-level agent. It sustains less than 5\% overall performance degradation while replacing 25\% of DRAM with a much slower medium.},
  doi       = {10.1145/3582016.3582031},
  isbn      = {9781450399180},
  keywords  = {Memory Tiering, Warehouse-Scale Computing, Memory Management},
  location  = {Vancouver, BC, Canada},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3582016.3582031},
}

@InProceedings{ArcelliFontana2023,
  author    = {Arcelli Fontana, Francesca and Camilli, Mateo and Rendina, Davide and Taraboi, Andrei Gabriel and Trubiani, Catia},
  booktitle = {Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering},
  title     = {Impact of Architectural Smells on Software Performance: An Exploratory Study},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {22–31},
  publisher = {Association for Computing Machinery},
  series    = {EASE '23},
  abstract  = {Architectural smells have been studied in the literature looking at several aspects, such as their impact on maintainability as a source of architectural debt, their correlations with code smells, and their evolution in the history of complex projects. The goal of this paper is to extend the study of architectural smells from a different perspective. We focus our attention on software performance, and we aim to quantify the impact of architectural smells as support to explain the root causes of system performance hindrances. Our method consists of a study design matching the occurrence of architectural smells with performance metrics. We exploit state-of-the-art tools for architectural smell detection, software performance profiling, and testing the systems under analysis. The removal of architectural smells generates new versions of systems from which we derive some observations on design changes improving/worsening performance metrics. Our experimentation considers two complex open-source projects, and results show that the detection and removal of two common types of architectural smells yield lower response time (up to ) with a large effect size, i.e., for - of the hotspot methods. The median memory consumption is also lower (up to ) with a large effect size for all the services.},
  doi       = {10.1145/3593434.3593442},
  isbn      = {9798400700446},
  keywords  = {Software Architecture, Software Performance, Architectural Smells},
  location  = {Oulu, Finland},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3593434.3593442},
}

@InProceedings{Mangrulkar2022,
  author    = {Mangrulkar, Sourab and M S, Ankith and Sembium, Vivek},
  booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  title     = {BE3R: BERT Based Early-Exit Using Expert Routing},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {3504–3512},
  publisher = {Association for Computing Machinery},
  series    = {KDD '22},
  abstract  = {Pre-trained language models like BERT have reported state-of-the-art performance on several Natural Language Processing (NLP) tasks, but high computational demands hinder its widespread adoption for large scale NLP tasks. In this work, we propose a novel routing based early exit model called BE3R (BERT based Early-Exit using Expert Routing), where we learn to dynamically exit in the earlier layers without needing to traverse through the entire model. Unlike the exiting early-exit methods, our approach can be extended to a batch inference setting. We consider the specific application of search relevance filtering in Amazon India marketplace services (a large e-commerce website). Our experimental results show that BE3R improves the batch inference throughput by 46.5\% over the BERT-Base model and 35.89\% over the DistilBERT-Base model on large dataset with 50 Million samples without any trade-off on the performance metric. We conduct thorough experimentation using various architectural choices, loss functions and perform qualitative analysis. We perform experiments on public GLUE Benchmark and demonstrate comparable performance to corresponding baseline models with 23\% average throughput improvement across tasks in batch inference setting.},
  doi       = {10.1145/3534678.3539132},
  isbn      = {9781450393850},
  keywords  = {attention models, transformers, relevance classification, natural language processing, deep learning, product search, e-commerce},
  location  = {Washington DC, USA},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3534678.3539132},
}

@InProceedings{Tiady2023,
  author    = {Tiady, Sambeet and Majumder, Anirban and Gupta, Deepak},
  booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
  title     = {PRODIGY: Product Design Guidance at Scale},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {4836–4842},
  publisher = {Association for Computing Machinery},
  series    = {CIKM '23},
  abstract  = {Growth of e-commerce has enabled the creation of thousands of small-scale brands. However, these brands lack information on a) what new products to develop and b) how to refine existing products to improve on business metrics. We present a comprehensive Product Design Insights and Guidance service (named PRODIGY) that mines product attributes data available on e-commerce platforms and surface insights on a) new product development and b) product refinement. Our core contribution is a novel demand forecasting model for product designs based on a notable extension of the recently proposed FTTransformer architecture combined with a self-supervised pre-training task, akin to Masked Language Modeling (MLM) objective. For the product refinement use-case, we present a novel algorithm by embedding the design search in a data-density approximator, namely Conditional Variational Autoencoder. We run a thorough and comprehensive set of experiments and establish that PRODIGY achieves significant improvement in demand prediction as compared to state-of-the-art alternatives. Finally, we present our findings from an online experiment where PRODIGY helps to launch new products with +20\% lift in sales and +1.3\% lift in product ratings.},
  doi       = {10.1145/3583780.3615494},
  isbn      = {9798400701245},
  location  = {<conf-loc>, <city>Birmingham</city>, <country>United Kingdom</country>, </conf-loc>},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3583780.3615494},
}

@InProceedings{Pouchard2023,
  author    = {Pouchard, Line C.},
  booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
  title     = {FAIR Enabling Re-Use of Data-Intensive Workflows and Scientific Reproducibility},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {329},
  publisher = {Association for Computing Machinery},
  series    = {ICPE '23 Companion},
  abstract  = {Scientific computing communities often run their experiments using complex data- and compute-intensive workflows that utilize high performance computing (HPC), distributed clusters and specialized architectures targeting machine learning and artificial intelligence. FAIR principles for data and software can be useful enablers for the reproducibility of performance (a key HPC metric) and that of scientific results (a crucial tenet of the scientific method) that are based in part on re-use, the R of FAIR principles. FAIR principles are under-used by HPC and data-intensive communities who have been slow to adopt them. This is due in part to the complexity of workflow life cycles, the numerous workflow management systems, the lack of integration of FAIR within existing technologies, and the specificity of managed systems that include rapidly evolving architectures and software stacks, and execution models that require resource managers and batch schedulers. Numerous challenges emerge for scientists attempting to publish FAIR datasets and software for the purpose of re-use and reproducibility, e.g. what data to publish and where due to sizes, how to "FAIRify" data subsetting, at what level of granularity to attribute persistent identifiers to software, what is the minimal amount of metadata needed to guarantee a certain level of reproducibility, what does reproducible AI actually mean? This talk will focus on such challenges and illustrate the negative impact of not applying FAIR on the reproducibility of experiments. We will introduce the notion of FAIR Digital Objects and present RECUP, a framework for data and metadata services for high performance workflows that proposes micro-solutions for adapting FAIR principles to HPC.},
  doi       = {10.1145/3578245.3586012},
  isbn      = {9798400700729},
  keywords  = {HPC, data intensive, reproducibility, FAIR, RECUP, FDO, high performance computing},
  location  = {Coimbra, Portugal},
  numpages  = {1},
  url       = {https://doi.org/10.1145/3578245.3586012},
}

@InProceedings{Kaven2023,
  author    = {Kaven, Sascha and Skwarek, Volker},
  booktitle = {Proceedings of the 28th ACM Symposium on Access Control Models and Technologies},
  title     = {Poster: Attribute Based Access Control for IoT Devices in 5G Networks},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {51–53},
  publisher = {Association for Computing Machinery},
  series    = {SACMAT '23},
  abstract  = {The deployment of 5G technology has the potential to usher in a new era for the internet of things (IoT). The introduction of new use cases, such as massive machine-type communications (mMTC), referring to a large number of IoT devices, resulting in the increasing importance of 5G as the basic communication infrastructure for IoT. However, the increasing connectivity of IoT devices coincides with a number of risks to security. Many IoT sensors have limited resources and, therefore, cannot perform the complex security measures required to protect them from attacks and data loss. Furthermore, IoT networks are very scattered, distributed and dynamic, so decentralised security measures are required. To address these challenges, this poster proposes the integration of attribute-based access control (ABAC) into the 5G service-based architecture. This approach aims to prevent unauthorized access to IoT devices at the network level, thereby alleviating the computational burden on resource-constrained IoT devices. By implementing ABAC, the proposed solution offers a more efficient method for managing access control within the IoT landscape in the context of 5G networks.},
  doi       = {10.1145/3589608.3595081},
  isbn      = {9798400701733},
  keywords  = {access control, abac, 5g},
  location  = {Trento, Italy},
  numpages  = {3},
  url       = {https://doi.org/10.1145/3589608.3595081},
}

@InProceedings{Cali2023,
  author    = {Cali, Umit and Dynge, Marthe Fogstad and Idries, Ahmed and Mishra, Sambeet and Dmytro, Ivanko and Hashemipour, Naser and Kuzlu, Murat},
  booktitle = {Proceedings of the 2023 European Interdisciplinary Cybersecurity Conference},
  title     = {Digital Energy Platforms Considering Digital Privacy and Security by Design Principles},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {167–173},
  publisher = {Association for Computing Machinery},
  series    = {EICC '23},
  abstract  = {The power system and markets have become increasingly complex, along with efforts to digitalize the energy sector. Accessing flexibility services, in particular, through digital energy platforms, has enabled communication between multiple entities within the energy system and streamlined flexibility market operations. However, digitalizing these vast and complex systems introduces new cybersecurity and privacy concerns, which must be properly addressed during the design of the digital energy platform ecosystems. More specifically, both privacy and cybersecurity measures should be embedded into all phases of the platform design and operation, based on the privacy and security by design principles. In this study, these principles are used to propose a holistic but generic architecture for digital energy platforms that are able to facilitate multiple use cases for flexibility services in the energy sector. A hybrid framework using both DLT and non-DLT solutions ensures trust throughout the layers of the platform architecture. Furthermore, an evaluation of numerous energy flexibility service use cases operating at various stages of the energy value chain is shown and graded in terms of digital energy platform technical maturity, privacy, and cybersecurity issues.},
  doi       = {10.1145/3590777.3591405},
  isbn      = {9781450398299},
  keywords  = {privacy., Flexibility markets, cybersecurity, distributed ledger technology, digitalization},
  location  = {Stavanger, Norway},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3590777.3591405},
}

@Article{Chacko2023,
  author     = {Chacko, Jeeta Ann and Mayer, Ruben and Jacobsen, Hans-Arno},
  journal    = {Proc. ACM Manag. Data},
  title      = {How To Optimize My Blockchain? A Multi-Level Recommendation Approach},
  year       = {2023},
  month      = {may},
  number     = {1},
  volume     = {1},
  abstract   = {Aside from the conception of new blockchain architectures, existing blockchain optimizations in the literature primarily focus on system or data-oriented optimizations within prevailing blockchains. However, since blockchains handle multiple aspects ranging from organizational governance to smart contract design, a holistic approach that encompasses all the different layers of a given blockchain system is required to ensure that all optimization opportunities are taken into consideration. In this vein, we define a multi-level optimization recommendation approach that identifies optimization opportunities within a blockchain at the system, data, and user level. Multiple metrics and attributes are derived from a blockchain log and nine optimization recommendations are formalized. We implement an automated optimization recommendation tool, BlockOptR, based on these concepts. The system is extensively evaluated with a wide range of workloads covering multiple real-world scenarios. After implementing the recommended optimizations, we observe an average of 20\% improvement in the success rate of transactions and an average of 40\% improvement in latency.},
  address    = {New York, NY, USA},
  articleno  = {24},
  doi        = {10.1145/3588704},
  issue_date = {May 2023},
  keywords   = {process mining, performance optimization, blockchains},
  numpages   = {27},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3588704},
}

@Article{Wang2023a,
  author     = {Wang, Yanfei and Yu, Zhiwen and Liu, Sicong and Zhou, Zimu and Guo, Bin},
  journal    = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
  title      = {Genie in the Model: Automatic Generation of Human-in-the-Loop Deep Neural Networks for Mobile Applications},
  year       = {2023},
  month      = {mar},
  number     = {1},
  volume     = {7},
  abstract   = {Advances in deep neural networks (DNNs) have fostered a wide spectrum of intelligent mobile applications ranging from voice assistants on smartphones to augmented reality with smart-glasses. To deliver high-quality services, these DNNs should operate on resource-constrained mobile platforms and yield consistent performance in open environments. However, DNNs are notoriously resource-intensive, and often suffer from performance degradation in real-world deployments. Existing research strives to optimize the resource-performance trade-off of DNNs by compressing the model without notably compromising its inference accuracy. Accordingly, the accuracy of these compressed DNNs is bounded by the original ones, leading to more severe accuracy drop in challenging yet common scenarios such as low-resolution, small-size, and motion-blur. In this paper, we propose to push forward the frontiers of the DNN performance-resource trade-off by introducing human intelligence as a new design dimension. To this end, we explore human-in-the-loop DNNs (H-DNNs) and their automatic performance-resource optimization. We present H-Gen, an automatic H-DNN compression framework that incorporates human participation as a new hyperparameter for accurate and efficient DNN generation. It involves novel hyperparameter formulation, metric calculation, and search strategy in the context of automatic H-DNN generation. We also propose human participation mechanisms for three common DNN architectures to showcase the feasibility of H-Gen. Extensive experiments on twelve categories of challenging samples with three common DNN structures demonstrate the superiority of H-Gen in terms of the overall trade-off between performance (accuracy, latency), and resource (storage, energy, human labour).},
  address    = {New York, NY, USA},
  articleno  = {36},
  doi        = {10.1145/3580815},
  issue_date = {March 2023},
  keywords   = {reinforcement Learning, model generation, neural networks, Human in the Loop},
  numpages   = {29},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3580815},
}

@InProceedings{Alahmadi2021,
  author    = {Alahmadi, Rawan and Almimony, Shoroog and Bahakeem, Rahaf and Alnahdi, Amany},
  booktitle = {Proceedings of the 5th International Conference on Medical and Health Informatics},
  title     = {Health Records Retrieval System: A Web-Service Approach},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {145–149},
  publisher = {Association for Computing Machinery},
  series    = {ICMHI '21},
  abstract  = {Patients’ electronic health records are archived and collected on data repositories of medical data systems. This research paper proposes a system based on web service architecture that allows retrieving medical records by health care centers associated to the system. There will be no need to open a file in every health care center associated to the system. In addition, the doctor can see the lab radiological results and medications from any hospital by considering security and privacy of medical data. The system will provide patients with urgent medical treatment when transferred to any hospital, as the hospital can access the patient's electronic health records to be informed with health status and diagnostic history. For example, a person had an accident and was transferred to any hospital; the hospital can access the patient's own electronic health records and find out his health status and medication the patient's uses. The built web service-based system will maintain privacy and security measures.},
  doi       = {10.1145/3472813.3473181},
  isbn      = {9781450389846},
  keywords  = {Health record, Medical record, Web service},
  location  = {Kyoto, Japan},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3472813.3473181},
}

@InProceedings{Zou2022,
  author    = {Zou, Xinyu and Hu, Zhi and Zhao, Yiming and Ding, Xuchu and Liu, Zhongyi and Li, Chenliang and Sun, Aixin},
  booktitle = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  title     = {Automatic Expert Selection for Multi-Scenario and Multi-Task Search},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {1535–1544},
  publisher = {Association for Computing Machinery},
  series    = {SIGIR '22},
  abstract  = {Multi-scenario learning (MSL) enables a service provider to cater for users' fine-grained demands by separating services for different user sectors, e.g., by user's geographical region. Under each scenario there is a need to optimize multiple task-specific targets e.g., click through rate and conversion rate, known as multi-task learning (MTL). Recent solutions for MSL and MTL are mostly based on the multi-gate mixture-of-experts (MMoE) architecture. MMoE structure is typically static and its design requires domain-specific knowledge, making it less effective in handling both MSL and MTL. In this paper, we propose a novel Automatic Expert Selection framework for Multi-scenario and Multi-task search, named AESM2. AESM2 integrates both MSL and MTL into a unified framework with an automatic structure learning. Specifically, AESM2 stacks multi-task layers over multi-scenario layers. This hierarchical design enables us to flexibly establish intrinsic connections between different scenarios, and at the same time also supports high-level feature extraction for different tasks. At each multi-scenario/multi-task layer, a novel expert selection algorithm is proposed to automatically identify scenario-/task-specific and shared experts for each input. Experiments over two real-world large-scale datasets demonstrate the effectiveness of AESM2 over a battery of strong baselines. Online A/B test also shows substantial performance gain on multiple metrics. Currently, AESM2 has been deployed online for serving major traffic.},
  doi       = {10.1145/3477495.3531942},
  isbn      = {9781450387323},
  keywords  = {search and ranking, multi-task learning, multi-scenario learning},
  location  = {<conf-loc>, <city>Madrid</city>, <country>Spain</country>, </conf-loc>},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3477495.3531942},
}

@InProceedings{Tocze2023,
  author    = {Tocz\'{e}, Klervie and Abad, Cristina L. and Herbst, Nikolas and Iosup, Alexandru},
  booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
  title     = {HotCloudPerf'23 Workshop Chairs' Welcome},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {257–258},
  publisher = {Association for Computing Machinery},
  series    = {ICPE '23 Companion},
  abstract  = {It is our great pleasure to welcome you to the 2023 edition of the Workshop on Hot Topics in Cloud Computing Performance - HotCloudPerf 2023.Cloud computing is emerging as one of the most profound changes in the way we build and use IT. The use of global services in public clouds is increasing, and the lucrative and rapidly growing global cloud market already supports over 1 million IT-related jobs. However, it is currently challenging to make the IT services offered by public and private clouds performant (in an extended sense) and efficient. Emerging architectures, techniques, and real-world systems include interactions with the computing continuum, serverless operation, everything as a service, complex workflows, auto-scaling and -tiering, etc. It is unclear to which extent traditional performance engineering, software engineering, and system design and analysis tools can help with understanding and engineering these emerging technologies. The community needs practical tools and powerful methods to address hot topics in cloud computing performance.Responding to this need, the HotCloudPerf workshop proposes a meeting venue for academics and practitioners, from experts to trainees, in the field of cloud computing performance. The workshop aims to engage this community and to lead to the development of new methodological aspects for gaining a deeper understanding not only of cloud performance, but also of cloud operation and behavior, through diverse quantitative evaluation tools, including benchmarks, metrics, and workload generators. The workshop focuses on novel cloud properties such as elasticity, performance isolation, dependability, and other non-functional system properties, in addition to classical performance-related metrics such as response time, throughput, scalability, and efficiency.},
  doi       = {10.1145/3578245.3584725},
  isbn      = {9798400700729},
  keywords  = {benchmarking, cloud/edge computing, performance},
  location  = {Coimbra, Portugal},
  numpages  = {2},
  url       = {https://doi.org/10.1145/3578245.3584725},
}

@InProceedings{Liu2022b,
  author    = {Liu, Yuli and Walder, Christian and Xie, Lexing},
  booktitle = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  title     = {Determinantal Point Process Likelihoods for Sequential Recommendation},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {1653–1663},
  publisher = {Association for Computing Machinery},
  series    = {SIGIR '22},
  abstract  = {Sequential recommendation is a popular task in academic research and close to real-world application scenarios, where the goal is to predict the next action(s) of the user based on his/her previous sequence of actions. In the training process of recommender systems, the loss function plays an essential role in guiding the optimization of recommendation models to generate accurate suggestions for users. However, most existing sequential recommendation tech- niques focus on designing algorithms or neural network architectures, and few efforts have been made to tailor loss functions that fit naturally into the practical application scenario of sequential recommender systems.  Ranking-based losses, such as cross-entropy and Bayesian Personalized Ranking (BPR) are widely used in the sequential recommendation area. We argue that such objective functions suffer from two inherent drawbacks: i) the dependencies among elements of a sequence are overlooked in these loss formulations; ii) instead of balancing accuracy (quality) and diversity, only generating accurate results has been over emphasized. We therefore propose two new loss functions based on the Determinantal Point Process (DPP) likelihood, that can be adaptively applied to estimate the subsequent item or items. The DPP-distributed item set captures natural dependencies among temporal actions, and a quality vs. diversity decomposition of the DPP kernel pushes us to go beyond accuracy-oriented loss functions. Experimental results using the proposed loss functions on three real-world datasets show marked improvements over state-of-the-art sequential recommendation methods in both quality and diversity metrics.},
  doi       = {10.1145/3477495.3531965},
  isbn      = {9781450387323},
  keywords  = {sequential recommendation, diversity, determinantal point process, loss function},
  location  = {<conf-loc>, <city>Madrid</city>, <country>Spain</country>, </conf-loc>},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3477495.3531965},
}

@InProceedings{Sandeepkumar2023,
  author    = {E V, Sandeepkumar and Jayavel, Kayalvizhi},
  booktitle = {Proceedings of the 4th International Conference on Information Management \&amp; Machine Intelligence},
  title     = {Effective and Light Weight Security System for Highly Confidential Cloud Data Such as PHR},
  year      = {2023},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ICIMMI '22},
  abstract  = {The server in a cloud storage system can hold a very large amount of Personal health records (PHR) data or information. The cloud platform's storage servers provide archival services for a lengthy time frame. The third party basically functions as an administrator for the efficiency of cloud storage. This is why we're starting up our cloud storage service. One of the biggest difficulties with the cloud is that it is vulnerable to hacking. Ordinary methods of encryption are used to safeguard the information from prying eyes. All of the secret messages' code words are kept in a system of varying symbols. Deletion coding is carried out in a manner analogous to that which is used to calculate the unequal code word cyphers required for a communication in a distributed setting. When the message symbols are stored in different servers in a dispersed environment, the cryptographic term signs are also calculated independently and stored. For this reason, we introduce and include a threshold proxy re-encryption scheme. Fully Homomorphic Encryption is a promising approach to securing sensitive PHR data by limiting who can view it. When sending encrypted PHR data, the proxy re-encryption mechanism re-encrypts the PHR data again before sending it on to the recipient or storage server. Allocation is completed when secure access control has maximised performance. In light of this, we expect to see the Schmidt-Samoa Public Key Encryption (SSPKE) method developed on the Enhanced v Boosting Algorithm (EBA) by PHR data Hiding Architecture. Additionally, in this initiative, we employ a procedure of multi-party protocol admission control to operate and access the user's PHR data without jeopardising the sensitive cloud PHR data privacy. The results of the experiments show the beneficial effect when various metrics, such as total processing time, server response time, and PHR data decomposition rate, are taken into account for the application of PHR.},
  articleno = {67},
  doi       = {10.1145/3590837.3590904},
  isbn      = {9781450399937},
  keywords  = {EBA, Re-encryption,Security, PHR, SSPKE},
  location  = {Jaipur, India},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3590837.3590904},
}

@InProceedings{Rocha2022,
  author    = {Rocha, Isabelly and Felber, Pascal and Schiavoni, Valerio and Chen, Lydia},
  booktitle = {Proceedings of the 23rd ACM/IFIP International Middleware Conference},
  title     = {EdgeTune: Inference-Aware Multi-Parameter Tuning},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {1–14},
  publisher = {Association for Computing Machinery},
  series    = {Middleware '22},
  abstract  = {Deep Neural Networks (DNNs) have demonstrated impressive performance on many machine-learning tasks such as image recognition and language modeling, and are becoming prevalent even on mobile platforms. Despite so, designing neural architectures still remains a manual, time-consuming process that requires profound domain knowledge. Recently, Parameter Tuning Servers have gathered the attention o industry and academia. Those systems allow users from all domains to automatically achieve the desired model accuracy for their applications. However, although the entire process of tuning and training models is performed solely to be deployed for inference, state-of-the-art approaches typically ignore system-oriented and inference-related objectives such as runtime, memory usage, and power consumption. This is a challenging problem: besides adding one more dimension to an already complex problem, the information about edge devices available to the user is rarely known or complete. To accommodate all these objectives together, it is crucial for tuning system to take a holistic approach to parameter tuning and consider all levels of parameters simultaneously into account. We present EdgeTune, a novel inference-aware parameter tuning server. It considers the tuning of parameters in all levels backed by an optimization function capturing multiple objectives. Our approach relies on inference estimated metrics collected from our emulation server running asynchronously from the main tuning process. The latter can then leverage the inference performance while still tuning the model. We propose a novel one-fold tuning algorithm that employs the principle of multi-fidelity and simultaneously explores multiple tuning budgets, which the prior art can only handle as suboptimal case of single type of budget. EdgeTune outputs inference recommendations to the user while improving tuning time and energy by at least 18\% and 53\% when compared to the baseline.},
  doi       = {10.1145/3528535.3533273},
  isbn      = {9781450393409},
  keywords  = {tuning, deep neural networks, training, inference},
  location  = {Quebec, QC, Canada},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3528535.3533273},
}

@InProceedings{Kong2022a,
  author    = {Kong, Xiangying and Kong, Xinran},
  booktitle = {Proceedings of the 6th International Conference on Computer Science and Application Engineering},
  title     = {Design of Embedded Trust Root Based on Dual-Kernel Architecture},
  year      = {2022},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {CSAE '22},
  abstract  = {Given the characteristics and design constraints of the embedded system, a software trust root construction method based on dual kernel architecture and composed of bootloader and trusted kernel and a stem branch trust chain transmission model are proposed ,aiming at the requirements of the trusted environment of embedded applications, The Bootloader, solidified in the boot FLASH, embeds the SHA-1 engine, to measure and load the trusted kernel. Meanwhile, the trusted kernel realizes the protection of the Bootloader by prohibiting the user kernel and upper-layer applications from writing access to the FLASH. The interaction between them, as the root of trust, can resist non-physical attacks; the trusted kernel provides password service-related functions for the user kernel; the application system and the user kernel where it is lockated run as a process of the trusted kernel. Finally, based on predicate logic, a formal proof of trusted boot is given, and a prototype system is built to verify the availability of the scheme.},
  articleno = {26},
  doi       = {10.1145/3565387.3565413},
  isbn      = {9781450396004},
  keywords  = {Embedded system, Trust root, Dual-kernel, Predicate logic},
  location  = {Virtual Event, China},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3565387.3565413},
}

@InProceedings{Mahenge2022,
  author    = {Mahenge, Shadrack Fred and Wambura, Stephen and Jiao, Licheng},
  booktitle = {Proceedings of the 8th International Conference on Computing and Artificial Intelligence},
  title     = {A Modified U-Net Architecture for Road Surfaces Cracks Detection},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {464–471},
  publisher = {Association for Computing Machinery},
  series    = {ICCAI '22},
  abstract  = {Cracks on road surfaces causes inconveniences to drivers and passengers and may cause mechanical failure or even accidents. Good Road condition plays an important role in quick transportation of goods and services from one place to another and acts as a catalyst for the economic development. Road surfaces need to be maintained in good condition to ensure the safety of road users. Road damage detection is important for Structural Health Monitoring (SHM). Traditional manual inspection is normally performed through human visualization which is time consuming, expensive, dangerous because of the passing vehicles, suffers from subjective judgment of the inspector and pose difficulties in keeping records for future road maintenance and repair. The rapid emergency and development of AI has stimulated many experts to automate the process of crack detection through computer vision (CV) technology, though most of these studies faces challenge on getting good detection accuracy. In this study a novel modified U-Net Architecture for image classification and segmentation is proposed to detect cracks on the road surfaces by using detection and classification of the road images to determine whether they represent cracks or not. Extensive experiments are conducted on three publicly available road crack datasets to evaluate the performance of our proposed model, The performance of the proposed Modified U-Net architecture was verified with respect to different performance metrics such as accuracy, precision, recall and f1 score. Qualitative and Quantitative comparisons experimental results of the proposed approach were also compared with existing state of the art U-Net architectures. It can be inferred from results that the proposed approach achieves superior performance in terms of detection accuracy.},
  doi       = {10.1145/3532213.3532283},
  isbn      = {9781450396110},
  keywords  = {object detection, deep learning, machine learning, Image processing, computer vision},
  location  = {Tianjin, China},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3532213.3532283},
}

@Article{kumari2023,
  author    = {kumari, Rani and Sah, Dinesh Kumar and Cengiz, Korhan and Ivkovi\'{c}, Nikola and Balaji, Prasanalakshmi},
  journal   = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
  title     = {Automatic Graph Construction and Exploring Different Types of LSTMs for Asian Hindi Languages for Medical Review Sentiment Analysis},
  year      = {2023},
  issn      = {2375-4699},
  month     = {oct},
  note      = {Just Accepted},
  abstract  = {Sentiment Analysis (SA) of medical reviews is crucial for improving healthcare outcomes. However, analyzing sentiment in low-resource languages such as Asian Hindi presents significant challenges. In this study, we propose an automatic graph construction approach to extract relevant features from medical reviews in Asian Hindi languages. We explore different types of Long Short-Term Memory (LSTMs), including traditional LSTMs, bidirectional LSTMs, and attention-based LSTMs, to classify the sentiment of medical reviews. Our proposed approach uses attention-based LSTM architecture and pre-trained Word2Vec embeddings to achieve high accuracy. We compare the proposed approach with existing models using various evaluation metrics, including accuracy, precision, recall, and F1-score. The results demonstrate that our proposed approach outperforms all existing models in terms of accuracy, achieving an accuracy score of 81\%. These findings could have implications for improving healthcare outcomes by enabling better monitoring of patient feedback and identifying areas for improvement in medical services.},
  address   = {New York, NY, USA},
  doi       = {10.1145/3626196},
  keywords  = {Long short-term memory, Graph construction, Deep learning, Hindi language},
  publisher = {Association for Computing Machinery},
  url       = {https://doi.org/10.1145/3626196},
}

@InProceedings{Zohaib2023,
  author    = {Zohaib, Ali and Sheffey, Jade and Houmansadr, Amir},
  booktitle = {Proceedings of the 2023 ACM Asia Conference on Computer and Communications Security},
  title     = {Investigating Traffic Analysis Attacks on Apple ICloud Private Relay},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {773–784},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '23},
  abstract  = {The iCloud Private Relay (PR) is a new feature introduced by Apple in June 2021 that aims to enhance online privacy by protecting a subset of web traffic from both local eavesdroppers and websites that use IP-based tracking. The service is integrated into Apple’s latest operating systems and uses a two-hop architecture where a user’s web traffic is relayed through two proxies run by disjoint entities. PR’s multi-hop architecture resembles traditional anonymity systems such as Tor and mix networks. Such systems, however, are known to be susceptible to a vulnerability known as traffic analysis: an intercepting adversary (e.g., a malicious router) can attempt to compromise the privacy promises of such systems by analyzing characteristics (e.g., packet timings and sizes) of their network traffic. In particular, previous works have widely studied the susceptibility of Tor to website fingerprinting and flow correlation, two major forms of traffic analysis. In this work, we are the first to investigate the threat of traffic analysis against the recently introduced PR. First, we explore PR’s current architecture to establish a comprehensive threat model of traffic analysis attacks against PR. Second, we quantify the potential likelihood of these attacks against PR by evaluating the risks imposed by real-world AS-level adversaries through empirical measurement of Internet routes. Our evaluations show that some autonomous systems are in a particularly strong position to perform traffic analysis on a large fraction of PR traffic. Finally, having demonstrated the potential for these attacks to occur, we evaluate the performance of several flow correlation and website fingerprinting attacks over PR traffic. Our evaluations show that PR is highly vulnerable to state-of-the-art website fingerprinting and flow correlation attacks, with both attacks achieving high success rates. We hope that our study will shed light on the significance of traffic analysis to the current PR deployment, convincing Apple to perform design adjustments to alleviate the risks.},
  doi       = {10.1145/3579856.3595793},
  isbn      = {9798400700989},
  keywords  = {Traffic Analysis, Anonymity Systems, iCloud Private Relay},
  location  = {Melbourne, VIC, Australia},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3579856.3595793},
}

@InProceedings{Anand2022,
  author    = {Anand, SVR and Arslan, Serhat and Chopra, Rajat and Katti, Sachin and Vaddiraju, Milind Kumar and Rana, Ranvir and Sheng, Peiyao and Tyagi, Himanshu and Viswanath, Pramod},
  booktitle = {Proceedings of the 21st ACM Workshop on Hot Topics in Networks},
  title     = {Trust-Free Service Measurement and Payments for Decentralized Cellular Networks},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {68–75},
  publisher = {Association for Computing Machinery},
  series    = {HotNets '22},
  abstract  = {Decentralized cellular networks have emerged to increase network accessibility by distributing infrastructure ownership over independent entities. Unlike the centralized setting, these architectures can allow users to connect to any untrusted base station without prior subscription. However, verification of the service is necessary in the absence of trust for commensurate payments by the user. Further, any method of verification must be non-intrusive and reliably agreed upon by the involved parties. To this end, we describe two-sided measurements where both the users and the providers independently assess the cellular service. We find that reconciling measurements from different layers of the cellular stack for a diverse set of matching observations is challenging but not impossible. Hence, new use cases such as a decentralized slicing marketplace, and contract-free roaming can be enabled by two-sided measurements. We envision applying two-sided measurements to real-time, on-demand network slicing and present an architecture that is capable of offering, as well as verifying, such slices in a scalable manner.},
  doi       = {10.1145/3563766.3564093},
  isbn      = {9781450398992},
  keywords  = {cellular architecture, decentralization},
  location  = {Austin, Texas},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3563766.3564093},
}

@Article{Ebrahimi2022,
  author     = {Ebrahimi, Maryam and Tadayon, Mohammad Hesam and Haghighi, Mohammad Sayad and Jolfaei, Alireza},
  journal    = {ACM Trans. Manage. Inf. Syst.},
  title      = {A Quantitative Comparative Study of Data-Oriented Trust Management Schemes in Internet of Things},
  year       = {2022},
  issn       = {2158-656X},
  month      = {apr},
  number     = {3},
  volume     = {13},
  abstract   = {In the Internet of Things (IoT) paradigm, all entities in the IoT network, whether home users or industrial things, receive data from other things to make decisions. However, in the decentralized, heterogeneous, and rapidly changing IoT network with billions of devices, deciding about where to get the services or information from is critical, especially because malicious entities can exist in such an unmanaged network. Security provisioning alone cannot solve the issue of service quality or reliability. One way to elevate security and reliability in the IoT network is to bridge the gap of trust between objects, and also between humans and objects, while taking into account the IoT network characteristics. Therefore, a proper trust management system must be established on top of the IoT network service architecture. Trust is related to the manner expected from objects in providing services and recommendations. Recommendations are the basis of decision making in every trust management system. Since trust management ideas in the IoT are still immature, the purpose of this article is to survey, analyze, and compare the approaches that have been taken in building trust management systems for the IoT. We break down the features of such systems by analysis and also do quantitative comparisons by simulation. This article is organized into two main parts. First, studies and approaches in this field are compared from four perspectives: (1) trust computation method, (2) resistance to attacks (3) adherence to the limitations of IoT networks and devices, and (4) performance of the trust management scheme. The second part is quantitative and simulates four major methods in this field and measures their performance. We also make extensive analytical comparisons to demonstrate the similarities and discrepancies of current IoT trust management schemes and extract the essence of a resilient trust management framework.},
  address    = {New York, NY, USA},
  articleno  = {24},
  doi        = {10.1145/3476248},
  issue_date = {September 2022},
  keywords   = {trust management, cyber security, data mining, recommender systems, Internet of things, decision making},
  numpages   = {30},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3476248},
}

@InProceedings{Cuza2022,
  author    = {Cuza, Carlos Enrique Muniz and Ho, Nguyen and Zacharatou, Eleni Tzirita and Pedersen, Torben Bach and Yang, Bin},
  booktitle = {Proceedings of the 30th International Conference on Advances in Geographic Information Systems},
  title     = {Spatio-Temporal Graph Convolutional Network for Stochastic Traffic Speed Imputation},
  year      = {2022},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {SIGSPATIAL '22},
  abstract  = {The rapid increase of traffic data generated by different sensing systems opens many opportunities to improve transportation services. An important opportunity is to enable stochastic routing that computes the arrival time probabilities for each suggested route instead of only the expected travel time. However, traffic datasets typically have many missing values, which prevents the construction of stochastic speeds. To address this limitation, we propose the Stochastic Spatio-Temporal Graph Convolutional Network (SST-GCN) architecture that accurately imputes missing speed distributions in a road network. SST-GCN combines Temporal Convolutional Networks and Graph Convolutional Networks into a single framework to capture both spatial and temporal correlations between road segments and time intervals. Moreover, to cope with datasets with many missing values, we propose a novel self-adaptive context-aware diffusion process that regulates the propagated information around the network, avoiding the spread of false information. We extensively evaluate the effectiveness of SST-GCN on real-world datasets, showing that it achieves from 4.6\% to 50\% higher accuracy than state-of-the-art baselines using three different evaluation metrics. Furthermore, multiple ablation studies confirm our design choices and scalability to large road networks.},
  articleno = {14},
  doi       = {10.1145/3557915.3560948},
  isbn      = {9781450395298},
  keywords  = {graph convolutional networks, spatio-temporal, data imputation},
  location  = {<conf-loc>, <city>Seattle</city>, <state>Washington</state>, </conf-loc>},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3557915.3560948},
}

@InProceedings{Oraby2022,
  author    = {Oraby, Shereen},
  booktitle = {Companion Proceedings of the Web Conference 2022},
  title     = {Stylistic Control for Neural Natural Language Generation},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {1179},
  publisher = {Association for Computing Machinery},
  series    = {WWW '22},
  abstract  = {With the rise of conversational assistants, it has become more critical for dialog systems to keep users engaged by responding in a natural, interesting, and often personalized way, even in a task-oriented setting. Recent work has thus focused on stylistic control for natural language generation (NLG) systems in order to jointly control response semantics and style. In this talk, I will describe our work on automatic data curation and modeling approaches to facilitate style control for both personality-specific attributes of style (based on Big-Five personality traits), and other style attributes that are helpful for personalization, e.g., response length, descriptiveness, point-of-view, and sentiment. I will present work that incorporates these attributes into the training and generation pipelines for different NLG architectures, and will show how our data curation and modeling approaches are generalizable to new domains and style choices. Finally, I will describe how we use a combination of automatic and human evaluation methods to measure how well models successfully hit multiple style targets without sacrificing semantics.},
  doi       = {10.1145/3487553.3527149},
  isbn      = {9781450391306},
  keywords  = {natural language generation, stylistic variation, dialog systems},
  location  = {Virtual Event, Lyon, France},
  numpages  = {1},
  url       = {https://doi.org/10.1145/3487553.3527149},
}

@InProceedings{Peniche2023,
  author    = {Peniche, Eduardo and Miranda, Leandro and Bernardini, Flavia and Viterbo, Jose},
  booktitle = {Proceedings of the 16th International Conference on Theory and Practice of Electronic Governance},
  title     = {FGT-SAMK-NN: Impact of the Right to Be Forgotten Using a Lazy Algorithm in Data Stream Learning},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {1–8},
  publisher = {Association for Computing Machinery},
  series    = {ICEGOV '23},
  abstract  = {“Right to Be Forgotten" is guaranteed by new international regulations on personal management data. This means that individuals can request the erasure of their data from third-party tools and services. However, this poses a challenge for machine learning estimators, who will need to forget parts of their knowledge. This paper examines the impact of learning and forgetting policies in Data Stream Learning. Storing data or retraining learning models from scratch in data stream mining is usually not feasible due to the large volume of instances. Therefore, more efficient solutions are necessary to deal with the dynamic nature of online machine learning. To address this issue, we implemented FGT-SAMK-NN, an incremental version of one of the most knowledgeable algorithms in Data Stream lazy algorithms: The SAMK-NN classifier. FGT-SAMK-NN can erase its past data, and we investigate the impact of data forgetting on predictive performance. Our proposal is compared to the original SAMK-NN algorithm using four non-stationary stream datasets. Our results demonstrate that evaluation metrics did not undergo significant changes, which may support the idea that has a good architecture for adaptations of the proposed nature. However, it was also noted that the processing time is very high for cases involving more forgettings, which may indicate that the high complexity of the model creates conflicts if the pattern of data streams, where the algorithm is used, involves a high forgetfulness rate.},
  doi       = {10.1145/3614321.3614322},
  isbn      = {9798400707421},
  keywords  = {Right to Be Forgotten, Lazy Learning, SamK-NN, Data Stream, Data Stream Learning},
  location  = {<conf-loc>, <city>Belo Horizonte</city>, <country>Brazil</country>, </conf-loc>},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3614321.3614322},
}

@InProceedings{Sattler2022,
  author    = {Sattler, Patrick and Aulbach, Juliane and Zirngibl, Johannes and Carle, Georg},
  booktitle = {Proceedings of the 22nd ACM Internet Measurement Conference},
  title     = {Towards a Tectonic Traffic Shift? Investigating Apple's New Relay Network},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {449–457},
  publisher = {Association for Computing Machinery},
  series    = {IMC '22},
  abstract  = {Apple recently published its first Beta of the iCloud Private Relay, a privacy protection service with promises resembling the ones of VPNs. The architecture consists of two layers (ingress and egress), operated by disjoint providers. The service is directly integrated into Apple's operating systems, providing a low entry-level barrier for a large user base. It seems to be set up for significant adoption with its relatively moderate entry-level price.This paper analyzes the iCloud Private Relay from a network perspective, its effect on the Internet, and future measurement-based research. We perform EDNS0 Client Subnet DNS queries to collect ingress relay addresses and find 1586 IPv4 addresses. Supplementary RIPE Atlas DNS measurements reveal 1575 IPv6 addresses. Knowing these addresses helps to detect clients communicating through the relay network passively. According to our scans, ingress addresses grew by 20\% from January through April. Moreover, according to our RIPE Atlas DNS measurements, 5.3\% of all probes use a resolver that blocks access to iCloud Private Relay.The analysis of our scans through the relay network verifies Apple's claim of rotating egress addresses. Nevertheless, it reveals that ingress and egress relays can be located in the same autonomous system, thus sharing similar routes, potentially allowing traffic correlation.},
  doi       = {10.1145/3517745.3561426},
  isbn      = {9781450392594},
  keywords  = {relay networks, DNS ECS enumeration, overlay networks},
  location  = {Nice, France},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3517745.3561426},
}

@InProceedings{Miao2022,
  author    = {Miao, Rui and Zhu, Lingjun and Ma, Shu and Qian, Kun and Zhuang, Shujun and Li, Bo and Cheng, Shuguang and Gao, Jiaqi and Zhuang, Yan and Zhang, Pengcheng and Liu, Rong and Shi, Chao and Fu, Binzhang and Zhu, Jiaji and Wu, Jiesheng and Cai, Dennis and Liu, Hongqiang Harry},
  booktitle = {Proceedings of the ACM SIGCOMM 2022 Conference},
  title     = {From Luna to Solar: The Evolutions of the Compute-to-Storage Networks in Alibaba Cloud},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {753–766},
  publisher = {Association for Computing Machinery},
  series    = {SIGCOMM '22},
  abstract  = {This paper presents the two generations of storage network stacks that reduced the average I/O latency of Alibaba Cloud's EBS service by 72\% in the last five years: Luna, a user-space TCP stack that corresponds the latency of network to the speed of SSD; and Solar, a storage-oriented UDP stack that enables both storage and network hardware accelerations.Luna is our first step towards a high-speed compute-to-storage network in the "storage disaggregation" architecture. Besides the tremendous performance gains and CPU savings compared with the legacy kernel TCP stack, more importantly, it teaches us the necessity of offloading both network and storage into hardware and the importance of recovering instantaneously from network failures.Solar provides a highly reliable and performant storage network running on hardware. For avoiding hardware's resource limitations and offloading storage's entire data path, Solar eliminates the superfluous complexity and the overfull states from the traditional architecture of the storage network. The core design of Solar is unifying the concepts of network packet and storage data block - each network packet is a self-contained storage data block. There are three remarkable advantages to doing so. First, it merges the packet processing and storage virtualization pipelines to bypass the CPU and PCIe; Second, since the storage processes data blocks independently, the packets in Solar become independent. Therefore, the storage (in hardware) does not need to maintain receiving buffers for assembling packets into blocks or handling packet reordering. Finally, due to the low resource requirement and the resilience to packet reordering, Solar inherently supports large-scale multi-path transport for fast failure recovery. Facing the future, Solar demonstrates that we can formalize the storage virtualization procedure into a P4-compatible packet processing pipeline. Hence, SOLAR's design perfectly applies to commodity DPUs (data processing units).},
  doi       = {10.1145/3544216.3544238},
  isbn      = {9781450394208},
  keywords  = {storage network, data processing unit, in-network acceleration},
  location  = {Amsterdam, Netherlands},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3544216.3544238},
}

@Article{Meneguette2021,
  author     = {Meneguette, Rodolfo and De Grande, Robson and Ueyama, Jo and Filho, Geraldo P. Rocha and Madeira, Edmundo},
  journal    = {ACM Comput. Surv.},
  title      = {Vehicular Edge Computing: Architecture, Resource Management, Security, and Challenges},
  year       = {2021},
  issn       = {0360-0300},
  month      = {nov},
  number     = {1},
  volume     = {55},
  abstract   = {Vehicular Edge Computing (VEC), based on the Edge Computing motivation and fundamentals, is a promising technology supporting Intelligent Transport Systems services, smart city applications, and urban computing. VEC can provide and manage computational resources closer to vehicles and end-users, providing access to services at lower latency and meeting the minimum execution requirements for each service type. This survey describes VEC’s concepts and technologies; we also present an overview of existing VEC architectures, discussing them and exemplifying them through layered designs. Besides, we describe the underlying vehicular communication in supporting resource allocation mechanisms. With the intent to overview the risks, breaches, and measures in VEC, we review related security approaches and methods. Finally, we conclude this survey work with an overview and study of VEC’s main challenges. Unlike other surveys in which they are focused on content caching and data offloading, this work proposes a taxonomy based on the architectures in which VEC serves as the central element. VEC supports such architectures in capturing and disseminating data and resources to offer services aimed at a smart city through their aggregation and the allocation in a secure manner.},
  address    = {New York, NY, USA},
  articleno  = {4},
  doi        = {10.1145/3485129},
  issue_date = {January 2023},
  keywords   = {Vehicular edge computer, architecture, resource management, security},
  numpages   = {46},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3485129},
}

@InProceedings{Ueda2021,
  author    = {Ueda, Kazuaki and Tagami, Atsushi},
  booktitle = {Proceedings of the Interdisciplinary Workshop on (de) Centralization in the Internet},
  title     = {Internet Flattening and Consolidation Considered Useful (for Deploying New Internet Architecture)},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {11–17},
  publisher = {Association for Computing Machinery},
  series    = {IWCI'21},
  abstract  = {Several new Internet architectures have been proposed to fill the gap between the original design of Internet and its current usage. These new architectures have been studied for more than 15 years, and their technical benefits have been widely validated. However, to date, these architectures have not been deployed in commercial networks. One of the reasons is that current Internet involves multiple players such as content providers and Internet Service Providers (ISPs), which makes it difficult to make significant changes. On the other hand, several studies have shown two trends of the current Internet, consolidation in web content delivery and flattening of the Internet topology. Web content delivery is dominated by the large Content Delivery Network (CDN) providers. Moreover, to improve communication quality, such providers connect directly to the eyeball ISPs, and this results in the flat topology. In this paper, we focus on whether these two trends, i.e., Internet flattening and consolidation, can ease the hurdle for deploying new architecture. Based on the measurements of DNS and network path, we verified the current trend of flattening and consolidation of content delivery on the Internet. We also investigated the incremental deployment scenario of new architecture under this environment. The results showed that a significant amount of traffic can be handled by a new architecture, if only a small set of autonomous systems cooperatively deploy it.},
  doi       = {10.1145/3488663.3493688},
  isbn      = {9781450391382},
  keywords  = {Future Internet Architecture, Internet consolidation},
  location  = {Virtual Event, Germany},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3488663.3493688},
}

@InProceedings{Zhang2021b,
  author    = {Zhang, Qingjun and Hu, Dong and Lin, Qiang},
  booktitle = {Proceedings of the 5th International Conference on Computer Science and Application Engineering},
  title     = {Design of High-Precision Island WebGIS Based on Cesium},
  year      = {2021},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {CSAE '21},
  abstract  = {In this paper, the design of a high-precision WebGIS system for island application is presented. The system is developed based on Cesium to support 2D, 2.5D and 3D map capabilities, and provide networked comprehensive geographic information service. Concerning the practical requirements for complicated configuration of island surface, improved methods for interpolation correction, data structure optimization, visible analysis and island path planning are introduced to improve system accuracy and performance. The system adopts B/S architecture and modular development ideas for easier access and further updates. The main functional modules of the island WebGIS provide basic operations, including multi-dimensional scene browsing, base map switching, multi-control operation, layer plotting, contour line, intervisibility and terrain factors measurement. Besides, the characteristic functions of key techniques such as profile analysis, viewshed analysis, and island path planning are implemented. The test examples show that the overall functional performance of the system is satisfactory for island 3D GIS service.},
  articleno = {71},
  doi       = {10.1145/3487075.3487146},
  isbn      = {9781450389853},
  keywords  = {WebGIS, Geographic information system, Cesium, Island},
  location  = {Sanya, China},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3487075.3487146},
}

@InProceedings{OfureEichie2022,
  author    = {Ofure Eichie, Julia and Oluwamayowa Agidi, Emmanuel and David Oyedum, Onyendi},
  booktitle = {The 5th International Conference on Future Networks \&amp; Distributed Systems},
  title     = {Atmospheric Temperature Prediction across Nigeria Using Artificial Neural Network},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {280–286},
  publisher = {Association for Computing Machinery},
  series    = {ICFNDS 2021},
  abstract  = {Atmospheric temperature is one of the dominating atmospheric parameters that impact on the propagation of radio waves through the troposphere. Adequate knowledge of the atmospheric temperature of an environment is therefore essential for radio wave propagation planning. In this study, thirty-four (34)-year (1981-2014) atmospheric temperature data of 10 selected weather stations across the climatic zones of Nigeria, obtained from the Nigerian Meteorological Agency (NIMET) through the data bank of the West African Science Service Centre on Climate Change and Adaptive Land Use (WASCAL) of the Federal University of Technology Minna, Nigeria was used in Artificial Neural Network (ANN) for the prediction of mean monthly atmospheric temperature. The ANN architecture comprised of 2 inputs (the climatic zones and the corresponding month for the mean monthly atmospheric temperature), 1 hidden layer and 1 output (atmospheric temperature). Levenberg-Marquardt algorithm was used with 9 different pairs of activation functions formed from 3 activation functions (logsig, purelin and tansig). The number of neurons in the hidden layer was varied from 33-39 with an increasing steps of 2 (33, 35, 37 and 39). The network architecture of 2-37-1 (2 inputs, 37 neurons in the hidden layer and 1 output), with tansig/tansig pair of activation functions had the least mean square error value of 2.2280, and was used for the prediction process. The computed correlation values for measured and predicted atmospheric temperature ranged from 0.9733 to 0.8787, depicting strong positive correlation and good accuracy of the developed model. Comparisons of the measured and the ANN predicted atmospheric temperature across selected stations in the climatic zones of Nigeria, showed that the developed model can effectively predict mean monthly atmospheric temperature, using month and climatic zone as input parameters.},
  doi       = {10.1145/3508072.3508114},
  isbn      = {9781450387347},
  keywords  = {Temperature, artificial neural network, refractive index, prediction},
  location  = {Dubai, United Arab Emirates},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3508072.3508114},
}

@Article{Viola2023,
  author     = {Viola, Roberto and Mart\'{\i}n, \'{A}ngel and Zorrilla, Mikel and Montalb\'{a}n, Jon and Angueira, Pablo and Muntean, Gabriel-Miro},
  journal    = {ACM Comput. Surv.},
  title      = {A Survey on Virtual Network Functions for Media Streaming: Solutions and Future Challenges},
  year       = {2023},
  issn       = {0360-0300},
  month      = {feb},
  number     = {11},
  volume     = {55},
  abstract   = {Media services must ensure an enhanced user’s perceived quality during content playback to attract and retain audiences, especially while the streams are distributed remotely via networks. Thus, media streaming services rely heavily on good and predictable network performance when delivered to a large number of people. Furthermore, as the quality of media content gets high, the network performance demands are also increasing, and meeting them is challenging. Network functions devoted to improving media streaming services become essential to cope with the high dynamics of network performance and user mobility. Furthermore, new networking paradigms and architectures under the 5G networks umbrella are bringing new possibilities to deploy smart network functions, which monitor the media streaming services through live and objective metrics and boost them in real-time. This survey overviews the state-of-the-art technologies and solutions proposed to apply new network functions for enhancing media streaming.},
  address    = {New York, NY, USA},
  articleno  = {221},
  doi        = {10.1145/3567826},
  issue_date = {November 2023},
  keywords   = {Media streaming, network virtualization, network functions},
  numpages   = {37},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3567826},
}

@InProceedings{Iosup2023,
  author    = {Iosup, Alexandru and Prodan, Radu},
  booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
  title     = {ICPE'23 GraphSys Workshop Chairs Introduction (Welcome)},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {207–208},
  publisher = {Association for Computing Machinery},
  series    = {ICPE '23 Companion},
  abstract  = {It is our great pleasure to welcome you to the 2023 ACM/SPEC Workshop on Serverless, Extreme-Scale, and Sustainable Graph Processing Systems. This is the first such workshop, aiming to facilitate the exchange of ideas and expertise in the broad field of high-performance large-scale graph processing.Graphs and GraphSys - The use, interoperability, and analytical exploitation of graph data are essential for modern digital economies. Today, thousands of computational methods (algorithms) and findable, accessible, interoperable, and reusable (FAIR) graph datasets exist. However, current computational capabilities lag when faced with the complex workflows involved in graph processing, the extreme scale of existing graph datasets, and the need to consider sustainability metrics in graph-processing operations. Needs are emerging for graph-processing platforms to provide multilingual information processing and reasoning based on the massive graph representation of extreme data in the form of general graphs, knowledge graphs, and property graphs. Because graph workloads and graph datasets are strongly irregular, and involve one or several big data "Vs" (e.g., volume, velocity, variability, vicissitude), the community needs to reconsider traditional approaches in performance analysis and modeling, system architectures and techniques, serverless and "as a service" operation, real-world and simulation-driven experimentation, etc., and provide new tools and instruments to address emerging challenges in graph processing.Graphs or linked data are crucial to innovation, competition, and prosperity and establish a strategic investment in technical processing and ecosystem enablers. Graphs are universal abstractions that capture, combine, model, analyze, and process knowledge about real and digital worlds into actionable insights through item representation and interconnectedness. For societally relevant problems, graphs are extreme data that require further technological innovations to meet the needs of the European data economy. Digital graphs help pursue the United Nations Sustainable Development Goals (UN SDG) by enabling better value chains, products, and services for more profitable or green investments in the financial sector and deriving trustworthy insight for creating sustainable communities. All science, engineering, industry, economy, and society-at-large domains can leverage graph data for unique analysis and insight, but only if graph processing becomes easy to use, fast, scalable, and sustainable.GraphSys is a cross-disciplinary meeting venue focusing on state-of-the-art and the emerging (future) graph processing systems. We invite experts and trainees in the field, across academia, industry, governance, and society, to share experience and expertise leading to a shared body of knowledge, to formulate together a vision for the field, and to engage with the topics to foster new approaches, techniques, and solutions.},
  doi       = {10.1145/3578245.3585328},
  isbn      = {9798400700729},
  keywords  = {workshop, graph processing, graphsys serverless, extreme-scale, and sustainable graph processing systems},
  location  = {Coimbra, Portugal},
  numpages  = {2},
  url       = {https://doi.org/10.1145/3578245.3585328},
}

@InProceedings{NarayananVenkit2023,
  author    = {Narayanan Venkit, Pranav},
  booktitle = {Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
  title     = {Towards a Holistic Approach: Understanding Sociodemographic Biases in NLP Models Using an Interdisciplinary Lens},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {1004–1005},
  publisher = {Association for Computing Machinery},
  series    = {AIES '23},
  abstract  = {The rapid growth in the usage and applications of Natural Language Processing (NLP) in various sociotechnical solutions has highlighted the need for a comprehensive understanding of bias and its impact on society. While research on bias in NLP has expanded, several challenges persist that require attention. These include the limited focus on sociodemographic biases beyond race and gender, the narrow scope of analysis predominantly centered on models, and the technocentric implementation approaches. This paper addresses these challenges and advocates for a more interdisciplinary approach to understanding bias in NLP. The work is structured into three facets, each exploring a specific aspect of bias in NLP. The first facet focuses on identifying sociodemographic bias in various NLP architectures, emphasizing the importance of considering both the models themselves and human computation to comprehensively understand and identify bias. In the second facet, we delve into the significance of establishing a shared vocabulary across different fields and disciplines involved in NLP. By highlighting the potential bias stemming from a lack of shared understanding, this facet emphasizes the need for interdisciplinary collaboration to bridge the gap and foster a more inclusive and accurate analysis of bias. Finally, the third facet investigates the development of a holistic solution by integrating frameworks from social science disciplines. This approach recognizes the complexity of bias in NLP and advocates for an interdisciplinary framework that goes beyond purely technical considerations, involving social and ethical perspectives to address bias effectively. The first facet includes the following of my published works [6, 7, 8, 9] to provide results into how the importance of understanding the presence of bias in various minority group that has not been in focus in the prior works of bias in NLP. The work also shows the need to create a method that considers both human and AI indicators of bias, showcasing the importance of the first facet of my research. In my study [9], I delve into sentiment analysis and toxicity detection models to identify explicit bias against race, gender, and people with disabilities (PWDs). Through statistical exploration of conversations on social media platforms such as Twitter and Reddit, I gain insights into how disability bias permeates real-world social settings. To quantify explicit sociodemographic bias in sentiment analysis and toxicity analysis models, I create the Bias Identification Test in Sentiment (BITS) corpus1. Applying BITS, I uncover significant biases in popular AIaaS sentiment analysis tools, including TextBlob, VADER, and Google Cloud Natural Language API, as well as toxicity analysis models like Toxic-BERT. Remarkably, all of these models exhibit statistically significant explicit bias against disability, underscoring the need for comprehensive understanding and mitigation of biases affecting such groups. The work also demonstrates the utility of BITS as a model-independent method of identifying bias by focusing on social groups instead. Expanding on this, my next work [8] delves into the realm of implicit bias in NLP models. While some models may not overtly exhibit bias, they can unintentionally perpetuate harmful stereotypes [4]. To measure and identify implicit bias in commonly used embedding and large language models, I propose a methodology to measure social biases in various NLP architectures. Focusing on people with disabilities (PWD) as a group with complex social dynamics, I analyze various word embedding-based and transformer-based LLMs, revealing significant biases against PWDs in all tested models. These findings expose how models trained on extensive corpora tend to favor ableist language, underscoring the urgency of detecting and addressing implicit bias. The above two works look at both the implicit and explicit nature of bias in NLP, showcasing the need to distinguish the efforts placed in understanding them. The results also demonstrate the utility of identifying such biases as it provides context to the black-box nature of such public models. As the field of NLP evolved from embedding-based models to large language models, the way these models are constructed underwent significant changes [5]. However, the concern arises from the fact that these models often reflect a populist viewpoint [1] that perpetuates majority-held ideas rather than objective truths. This difference in perception can lead to biases perpetuated by the majority’s worldview. To explore this aspect, I investigate how LLMs represent nationality and their impact on societal stereotypes [6]. By examining LLM-generated stories for various nationalities, I establish a correlation between sentiment and the population of internet users in a country. The study reveals the unintentional implicit and explicit nationality biases exhibited by GPT-2, with nations having lower internet representation and economic status generating negative sentiment stories and employing a greater number of negative adjectives. Additionally, I explore potential debiasing methods such as adversarial triggering and prompt engineering, demonstrating their efficacy in mitigating stereotype propagation through LLM models. While prior work predominantly relies on automatic indicators like sentiment scores or vector distances to identify bias [3], the next phase of my research emphasizes the importance of understanding biases through the lens of human readers [7], bringing to light the need for a human lens in understanding bias through human-aided indicators and mixed-method identification. By incorporating concepts of social computation, using human evaluation, we gain a better understanding of biases’ potential societal impact within the context of language models. To achieve this, I conduct open-ended interviews and employ qualitative coding and thematic analysis to comprehend the implications of biases on human readers. The findings demonstrate that biased NLP models tend to replicate and amplify existing societal biases, posing potential harm when utilized in sociotechnical settings. The qualitative analysis from the interviews provides valuable insights into readers’ experiences when encountering biased articles, highlighting the capacity to shift a reader’s perception of a country. These findings emphasize the critical role of public perception in shaping AI’s impact on society and the need to correct biases in AI systems. The second facet of my research aims to bridge the disparity between AI research and society. This disparity has resulted in a lack of shared understanding between these domains, leading to potential biases and harm toward specific groups. Employing an interdisciplinary approach that combines social informatics, philosophy, and AI, I will investigate the similarities and disparities in the concepts utilized by machine learning models. Existing research [2] highlights the insufficient interdisciplinary effort and motivation in comprehending social aspects of NLP. To commence this exploration, I will delve into the shared taxonomy of sentiment and fairness in natural language processing, sociology, and humanities. This research will first delve into the interdisciplinary nature of sentiment and its application in sentiment analysis models. Sentiment analysis, a popular machine learning application for text classification based on sentiment, opinion, and subjectivity, holds significant influence as a sociotechnical system that impacts both social and technical actors within a network. Nevertheless, the definition and connotation of sentiment vary vastly across different research fields, potentially leading to misconceptions regarding the utility of such systems. To address this issue, this study will examine how diverse fields, including psychology, sociology, and technology, define the concept of sentiment. By unraveling the divergent perspectives on sentiment within different fields, the paper will uncover discrepancies and varying applications of this interdisciplinary concept. Additionally, the research will survey commonly utilized sentiment analysis models, aiming to comprehend their standardized definitions and associated issues. Ultimately, the study will pose critical questions that should be considered during the development of social models to mitigate potential biases and harm stemming from an insufficiently defined comprehension of fundamental social concepts. Similar efforts will be dedicated to comprehending the disparity in bias and fairness as an interdisciplinary concept, shedding light on the imperative for inclusive research to cultivate superior AI models as sociotechnical solutions. The third facet of my study embarks upon an exploration of the intricate interplay between human and AI actors, employing the formidable theoretical lens of actor-network theory (ANT). Through the presentation of a robust framework, this facet aims to engender the formation of efficacious development networks that foster collaboration among developers, practitioners, and other essential stakeholders. Such inclusive networks serve as crucibles for the cultivation of holistic solutions that transcend the discriminatory trappings afflicting specific populations. A tangible outcome of this endeavor entails the creation of an all-encompassing bias analysis platform, poised to guide the discernment and amelioration of an array of sociodemographic biases manifesting within any machine-learning system. By catalyzing the development of socially aware and less pernicious technology, this research makes a substantial contribution to the realms of NLP and AI. The significance of this proposed research reverberates beyond the confines of NLP, resonating throughout the broader domain of AI, wherein analogous challenges about social biases loom large. Leveraging the proposed framework, developers, practitioners, and policymakers are empowered to forge practical solutions that embody inclusivity and reliability, especially when used as a service (AIaaS). Moreover, the platform serves as a centralized locus for the identification and rectification of social biases, irrespective of the underlying model or architecture. By furnishing a cogent narrative that underscores the imperative for a comprehensive and interdisciplinary approach, my work strives to propel the ongoing endeavors to comprehend and mitigate biases within the realm of NLP. With its potential to augment the equity, inclusivity, and societal ramifications of NLP technologies, the proposed framework catapults the field towards responsible and ethical practices.},
  doi       = {10.1145/3600211.3604754},
  isbn      = {9798400702310},
  location  = {<conf-loc>, <city>Montr\'{e}al</city>, <state>QC</state>, <country>Canada</country>, </conf-loc>},
  numpages  = {2},
  url       = {https://doi.org/10.1145/3600211.3604754},
}

@InProceedings{Fernandez2023,
  author    = {Fernandez, Sergi and Montagud, Mario and Rinc\'{o}n, David and Moragues, Juame and Cernigliaro, Gianluca},
  booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
  title     = {Addressing Scalability for Real-Time Multiuser Holo-Portation: Introducing and Assessing a Multipoint Control Unit (MCU) for Volumetric Video},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {9243–9251},
  publisher = {Association for Computing Machinery},
  series    = {MM '23},
  abstract  = {Scalability, interoperability, and cost efficiency are key remaining challenges to successfully providing real-time holo-portation (and Metaverse-like) services. This paper, for the first time, presents the design and integration of a Multipoint Control Unit (MCU) in a pioneering real-time holo-portation platform, supporting realistic and volumetric user representations (i.e., 3D holograms), with the aim of overcoming such challenges. The feasibility and implications of adopting such an MCU, in comparison with state-of-the-art architectural approaches, are assessed through experimentation in two different deployment setups, by iteratively increasing the number of concurrent users in shared sessions. The obtained results are promising, as it is empirically proved that the newly adopted stream multiplexing together with the novel per-client and per-frame Volumetric Video (VV) processing optimization features provided by the MCU allow increasing the number of concurrent users, while: (i) significantly reducing resources consumption metrics (e.g., CPU, GPU, bandwidth) and frame rate degradation on the client side; and (ii) keeping the end-to-end latency within acceptable limits.},
  doi       = {10.1145/3581783.3613777},
  isbn      = {9798400701085},
  keywords  = {multipoint control unit (mcu), social vr, virtual reality (vr), volumetric video, cloud computing, holo-portation},
  location  = {<conf-loc>, <city>Ottawa ON</city>, <country>Canada</country>, </conf-loc>},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3581783.3613777},
}

@InProceedings{Rehman2021,
  author    = {Rehman, Osama and Farrukh, Zaroon and Al-Busaidi, Asiya and Cha, Kyungjin and Park, Simon and Rahman, Ibrahim},
  booktitle = {The 9th International Conference on Smart Media and Applications},
  title     = {IoT Powered Cancer Observation System.},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {313–318},
  publisher = {Association for Computing Machinery},
  series    = {SMA 2020},
  abstract  = {Cancer is a global challenge and the second leading cause of death worldwide as reported by the World Health Organization. With the current global pandemic caused by the novel coronavirus, cancer patients are identified as having increased risk of mortality. With the growing number of cancer patients every year, the need for a continuous and round the clock observation system has become quite imperative. An Internet of Things (IoT) based system for monitoring cancer patients has the potential to timely detect cancer related symptoms in its early stages, to continuously monitor cancer diagnosed patients and to monitor those that got cured for post-treatment measures. This paper proposes a multi-layered architecture of an IoT-based cancer observation system that can be utilized as a platform to remotely diagnose and monitor cancer patients. An implementation framework of the proposed system is also presented is this work, along with a prototype design of a Patient Side Unit (PSU) represented by a wearable wrist band. The proposed system has the potential to be applied as a solution for reducing expensive and exhausting hospital visits, while gaining similar quality of medical services when residing at home.},
  doi       = {10.1145/3426020.3426111},
  isbn      = {9781450389259},
  location  = {Jeju, Republic of Korea},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3426020.3426111},
}

@InProceedings{Balsamo2022,
  author    = {Balsamo, Simonetta and Marin, Andrea and Mitrani, Isi},
  booktitle = {Proceedings of the 2022 ACM/SPEC on International Conference on Performance Engineering},
  title     = {A Mixed PS-FCFS Policy for CPU Intensive Workloads},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {199–210},
  publisher = {Association for Computing Machinery},
  series    = {ICPE '22},
  abstract  = {Round robin (RR) is a widely adopted scheduling policy in modern computer systems. The scheduler handles the concurrency by alternating the run processes in such a way that they can use the processor continuously for at most a quantum of time. When the processor is assigned to another process, a context switch occurs. Although modern architectures handle context switches quite efficiently, the processes may incur in some indirect costs mainly due to cache overwriting.RR is widely appreciated both in case of interactive and CPU intensive processes. In the latter case, with respect to the First-Come-First-Served approach (FCFS), RR does not penalise the small jobs.In this paper, we study a scheduling policy, namely PS-FCFS, that fixes a maximum level of parallelism N and leaves the remaining jobs in a FCFS queue. The idea is that of exploiting the advantages of RR without incurring in heavy slowdowns because of context switches.We propose a queueing model for PS-FCFS allowing us to: (i) find the optimal level of multiprogramming and (ii) study important properties of this policy such as the mean performance measures and results about its sensitivity to the moments of the jobs' service demands.},
  doi       = {10.1145/3489525.3511678},
  isbn      = {9781450391436},
  keywords  = {context switch, scheduling, response time optimisation, queueing systems},
  location  = {Beijing, China},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3489525.3511678},
}

@InProceedings{Ma2023,
  author    = {Ma, Ling and Zhang, Runting and Shi, Xiaohua},
  booktitle = {Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing \&amp; the 2023 ACM International Symposium on Wearable Computing},
  title     = {Experience: Large Scale Indoor Location-Based Service in Libraries},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {391–395},
  publisher = {Association for Computing Machinery},
  series    = {UbiComp/ISWC '23 Adjunct},
  abstract  = {This paper presents the experience in the implementation and application of a large-scale Indoor Location-Based Service (LBS) in an academic library. We deployed an indoor positioning system within the school library that leverages 550 Bluetooth beacons, covering an area of approximately 12,000 square meters. This system allows users to engage with location-aware book navigation services via a web interface on their mobile devices. Upon locating a book of interest, the system enters navigation mode, updating and guiding users based on their current location within the library. Utilizing the users’ positional data and borrowing history, the system is capable of recommending other potentially interesting books, exhibits, and library events. The system went live in February 2023, with a recorded usage sessions of 21,540 instances which includes 17,271 uses of the retrieval services and 2,065 indoor navigation services, as of May 2023. This paper outlines the system architecture of this large-scale indoor LBS, shares user engagement data, and after anonymization, makes this data publicly available for academic analysis and research. We are hoping that our experience can shed light on the understanding and future development of large-scale indoor LBS technologies.},
  doi       = {10.1145/3594739.3610725},
  isbn      = {9798400702006},
  keywords  = {location-based service, library},
  location  = {<conf-loc>, <city>Cancun, Quintana Roo</city>, <country>Mexico</country>, </conf-loc>},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3594739.3610725},
}

@InProceedings{Wang2021a,
  author    = {Wang, Sihan and Tu, Guan-Hua and Lei, Xinyu and Xie, Tian and Li, Chi-Yu and Chou, Po-Yi and Hsieh, Fucheng and Hu, Yiwen and Xiao, Li and Peng, Chunyi},
  booktitle = {Proceedings of the 27th Annual International Conference on Mobile Computing and Networking},
  title     = {Insecurity of Operational Cellular IoT Service: New Vulnerabilities, Attacks, and Countermeasures},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {437–450},
  publisher = {Association for Computing Machinery},
  series    = {MobiCom '21},
  abstract  = {More than 150 cellular networks worldwide have rolled out massive IoT services such as smart metering and environmental monitoring. Such cellular IoT services share the existing cellular network architecture with non-IoT (e.g., smartphone) ones. When they are newly integrated into the cellular network, new security vulnerabilities may happen from imprudent integration. In this work, we explore the security vulnerabilities of the cellular IoT from both system-integrated and service-integrated aspects. We discover five vulnerabilities spanning cellular standard design defects, network operation slips, and IoT device implementation flaws. Threateningly, they allow an adversary to remotely identify IP addresses and phone numbers assigned to cellular IoT devices and launch data/text spamming attacks against them. We experimentally validate these vulnerabilities and attacks with three major U.S. IoT carriers. The attack evaluation result shows that the adversary can raise an IoT data bill by up to $226 with less than 120 MB spam traffic and increase an IoT text bill at a rate of $5 per second; moreover, cellular IoT devices may suffer from denial of IoT services. We finally propose, prototype, and evaluate recommended solutions.},
  doi       = {10.1145/3447993.3483239},
  isbn      = {9781450383424},
  keywords  = {cellular IoT, security, service charging},
  location  = {New Orleans, Louisiana},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3447993.3483239},
}

@InProceedings{A.Alhamdi2021,
  author    = {A. Alhamdi, Nada and S. Ahmeda, Shubat},
  booktitle = {The 7th International Conference on Engineering \&amp; MIS 2021},
  title     = {Mobile WiMAX Network Optimization and Performance Analysis},
  year      = {2021},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ICEMIS'21},
  abstract  = {Mobile WiMAX is a fast growing Broadband Wireless Access (BWA) technology that gives a flexible and cost-effective solution to fixed broadband access problems such as the lacking of support for terminal mobility. Mobile WiMAX enables low-cost mobile internet applications, realizes the convergence of mobile and fixed broadband access in single air interface and network architecture. Although Mobile WiMAX has a lot of features such as high data rate, quality of service, scalability, high security and of course mobility, there are some problems that can be identified within the network; two major problems include signal interference and network coverage. In this paper, Mobile WiMAX Network Optimization is implemented to improve the interference control, enable effective coverage and enhance user experience to meet new business development needs and maximize profits. The paper is supported by measured real data captured in an urban environment using vehicular drive tests and other tools. Analysis shows that Mobile WiMAX is able to achieve a high-level improvement in network coverage and signal quality.},
  articleno = {18},
  doi       = {10.1145/3492547.3492589},
  isbn      = {9781450390446},
  location  = {Almaty, Kazakhstan},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3492547.3492589},
}

@InProceedings{Balsebre2022,
  author    = {Balsebre, Pasquale and Yao, Dezhong and Cong, Gao and Hai, Zhen},
  booktitle = {Proceedings of the ACM Web Conference 2022},
  title     = {Geospatial Entity Resolution},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {3061–3070},
  publisher = {Association for Computing Machinery},
  series    = {WWW '22},
  abstract  = {A geospatial database is today at the core of an ever increasing number of services. Building and maintaining it remains challenging due to the need to merge information from multiple providers. Entity Resolution (ER) consists of finding entity mentions from different sources that refer to the same real world entity. In geospatial ER, entities are often represented using different schemes and are subject to incomplete information and inaccurate location, making ER and deduplication daunting tasks. While tremendous advances have been made in traditional entity resolution and natural language processing, geospatial data integration approaches still heavily rely on static similarity measures and human-designed rules. In order to achieve automatic linking of geospatial data, a unified representation of entities with heterogeneous attributes and their geographical context, is needed. To this end, we propose Geo-ER1, a joint framework that combines Transformer-based language models, that have been successfully applied in ER, with a novel learning-based architecture to represent the geospatial character of the entity. Different from existing solutions, Geo-ER does not rely on pre-defined rules and is able to capture information from surrounding entities in order to make context-based, accurate predictions. Extensive experiments on eight real world datasets demonstrate the effectiveness of our solution over state-of-the-art methods. Moreover, Geo-ER proves to be robust in settings where there is no available training data for a specific city.},
  doi       = {10.1145/3485447.3512026},
  isbn      = {9781450390965},
  keywords  = {Entity resolution, neural networks, neighbourhood embedding, geospatial data, graph attention},
  location  = {Virtual Event, Lyon, France},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3485447.3512026},
}

@InProceedings{BirgeLee2022,
  author    = {Birge-Lee, Henry and Apostolaki, Maria and Rexford, Jennifer},
  booktitle = {Proceedings of the 21st ACM Workshop on Hot Topics in Networks},
  title     = {It Takes Two to Tango: Cooperative Edge-to-Edge Routing},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {174–180},
  publisher = {Association for Computing Machinery},
  series    = {HotNets '22},
  abstract  = {In their unrelenting quest for lower latency, cloud providers are deploying servers closer to their customers and enterprises are adopting paid Network-as-a-Service (NaaS) offerings with performance guarantees. Unfortunately, these trends contribute to greater industry consolidation, benefiting larger companies and well-served regions while leaving little room for smaller cloud providers and enterprises to flourish. Instead, we argue that the public Internet could offer good enough performance, if only edge networks could work together to achieve better visibility and control over wide-area routing. We present Tango, a cooperative architecture where pairs of edge networks (e.g., access, enterprise, and data-center networks) collaborate to expose more wide-area paths, collect more accurate measurements, and split traffic more intelligently over the paths. Tango leverages programmable switches at the borders of the edge networks, coupled with techniques to coax BGP into exposing more paths, without requiring support from end hosts or intermediate ASes. Experiments with our preliminary Tango deployment (using IPv6 addresses and the Vultr cloud provider) show that Tango could offer much greater visibility and control over wide-area routing, allowing the public Internet to meet the needs of many modern networked applications.},
  doi       = {10.1145/3563766.3564107},
  isbn      = {9781450398992},
  keywords  = {SDN, BGP, network measurement, multipath routing},
  location  = {Austin, Texas},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3563766.3564107},
}

@InProceedings{Quin2022,
  author    = {Quin, Federico and Weyns, Danny},
  booktitle = {Proceedings of the 17th Symposium on Software Engineering for Adaptive and Self-Managing Systems},
  title     = {SEAByTE: A Self-Adaptive Micro-Service System Artifact for Automating A/B Testing},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {77–83},
  publisher = {Association for Computing Machinery},
  series    = {SEAMS '22},
  abstract  = {Micro-services are a common architectural approach to software development today. An indispensable tool for evolving micro-service systems is A/B testing. In A/B testing, two variants, A and B, are applied in an experimental setting. By measuring the outcome of an evaluation criterion, developers can make evidence-based decisions to guide the evolution of their software. Recent studies highlight the need for enhancing the automation when such experiments are conducted in iterations. To that end, we contribute a novel artifact that aims at enhancing the automation of an experimentation pipeline of a micro-service system relying on the principles of self-adaptation. Concretely, we propose SEAByTE, an experimental framework for testing novel self-adaptation solutions to enhance the automation of continuous A/B testing of a micro-service based system. We illustrate the use of the SEAByTE artifact with a concrete example.},
  doi       = {10.1145/3524844.3528081},
  isbn      = {9781450393058},
  location  = {Pittsburgh, Pennsylvania},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3524844.3528081},
}

@InProceedings{Arhab2023,
  author    = {Arhab, Nabil and Oussalah, Mourad and Jutila, Johannes and Outila, Tarja},
  booktitle = {Adjunct Proceedings of the 2022 ACM International Joint Conference on Pervasive and Ubiquitous Computing and the 2022 ACM International Symposium on Wearable Computers},
  title     = {Toward Car Parking Wellbeing Index.},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {153–158},
  publisher = {Association for Computing Machinery},
  series    = {UbiComp/ISWC '22 Adjunct},
  abstract  = {With the actual development in urban life by the emerging trends around the smart city, along with cars yet considered as the primary source for commuting by city visitors, the parking infrastructures and parking lots management recreates a role in providing an easy mobility service with the sustainability of land use for the city. This ultimately impacted the driver well being. This work provides a foundation for measuring the Parking Wellbeing Index as a tailored refocus of the sustainability society index that takes into account the car parking experience. The framework makes use of the Occupancy rate of the parking site and traffic flow in the vicinity of the parking site, as well as the environmental aspect, which includes both the business/economical dimension and the Green (nature) dimension. We demonstrated how the developed index could be applied in Oulu City center, where a set of experiments have been conducted and tested. Especially, software architecture has been devised to automatically retrieve traffic and parking occupancy using the City of Oulu open data platform. While land use classification has been used to assess the Green and Business aspects of the parking area. The results could help the municipality better manage the buildings and the landscape in a way to maximize community wellbeing.},
  doi       = {10.1145/3544793.3563400},
  isbn      = {9781450394239},
  keywords  = {data analytic, wellbeing, car parking, land use},
  location  = {Cambridge, United Kingdom},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3544793.3563400},
}

@Article{Robol2023,
  author     = {Robol, Marco and Breaux, Travis D. and Paja, Elda and Giorgini, Paolo},
  journal    = {ACM Trans. Softw. Eng. Methodol.},
  title      = {Consent Verification Monitoring},
  year       = {2023},
  issn       = {1049-331X},
  month      = {feb},
  number     = {1},
  volume     = {32},
  abstract   = {Advances in personalization of digital services are driven by low-cost data collection and processing, in addition to the wide variety of third-party frameworks for authentication, storage, and marketing. New privacy regulations, such as the General Data Protection Regulation (GDPR) and the California Consumer Privacy Act, increasingly require organizations to explicitly state their data practices in privacy policies. When data practices change, a new version of the policy is released. This can occur a few times a year, when data collection or processing requirements are rapidly changing. Consent evolution raises specific challenges to ensuring GDPR compliance. We propose a formal consent framework to support organizations, data users, and data subjects in their understanding of policy evolution under a consent regime that supports both the retroactive and non-retroactive granting and withdrawal of consent. The contributions include (i) a formal framework to reason about data collection and access under multiple consent granting and revocation scenarios, (ii) a scripting language that implements the consent framework for encoding and executing different scenarios, (iii) five consent evolution use cases that illustrate how organizations would evolve their policies using this framework, and (iv) a scalability evaluation of the reasoning framework. The framework models are used to verify when user consent prevents or detects unauthorized data collection and access. The framework can be integrated into a runtime architecture to monitor policy violations as data practices evolve in real time. The framework was evaluated using the five use cases and a simulation to measure the framework scalability. The simulation results show that the approach is computationally scalable for use in runtime consent monitoring under a standard model of data collection and access and practice and policy evolution.},
  address    = {New York, NY, USA},
  articleno  = {2},
  doi        = {10.1145/3490754},
  issue_date = {January 2023},
  keywords   = {analysis, formal framework, retroactivity, logs, consent, verification, consent revocation, Privacy, GDPR, evolution, description logic},
  numpages   = {33},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3490754},
}

@InProceedings{Jeong2023,
  author    = {Jeong, Bomi and Lee, Sungwon and Siddiqa, Ayesha and Ajmal, Mahnoor and Seo, Junho and Kim, Dongkyun},
  booktitle = {Proceedings of the 2023 International Conference on Research in Adaptive and Convergent Systems},
  title     = {Experimental Analysis of Handover Process in Cell-Free Networks},
  year      = {2023},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {RACS '23},
  abstract  = {With the emergence of services that require a high level of data usage, wireless networks are required to support higher data rates and greater capacity. To satisfy these requests, 5G architecture supports a high-frequency band. However, a high frequency occurs small range resulting in a need for numerous base stations (BSs). Deploying numerous BSs can be considered practically impossible due to high costs. To address the cost issue, instead of BSs, access points (APs) are used in Cell-free networks. That is, Cell-free networks that offer promising coverage gain and enhanced data rates consist of multiple APs and a single central process unit (CPU). This coverage of multiple APs' is much smaller than BS's. As a result, this small coverage can lead to frequent handovers. To overcome this frequent handover, an optimized handover scheme for the Cell-free network is required. Despite this optimization requirement, many studies in the Cell-free network field remain at the physical layer stage. No basic handover process is optimized for Cell-free networks, and no protocol for upper layers is defined. We consider that existing technologies will continue to be used in Cell-free networks, even if the protocols optimized for Cellfree networks are developed and used. For these reasons, we construct a Cell-free network architecture similar to the 5G structure for the handover process. In this paper, we investigate the handover process in 5G architecture and extend it to a Cellfree network environment. In our simulations, APs initiate and perform the handover process based on measurement reports from users. We analyzed and discussed the performance matrices of the handover in a Cell-free network environment, such as handover delay and throughput.},
  articleno = {11},
  doi       = {10.1145/3599957.3606221},
  isbn      = {9798400702280},
  keywords  = {Cell-free networks, 5G networks, Handover},
  location  = {Gdansk, Poland},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3599957.3606221},
}

@InProceedings{Lin2022,
  author    = {Lin, Jingyu and Yan, Yan and Wang, Hanzi},
  booktitle = {Proceedings of the 4th ACM International Conference on Multimedia in Asia},
  title     = {An End-to-End Scene Text Detector with Dynamic Attention},
  year      = {2022},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {MMAsia '22},
  abstract  = {Detecting the arbitrarily oriented text in natural images is a challenging task in multimedia due to variations in text curvatures, orientations, and aspect ratios of natural scenes. Most previous scene text detectors often fail to locate the text instances which have a peculiar shape (an extreme aspect ratio) precisely. In this paper, we propose a dynamic end-to-end framework (DEF) which includes a convolution-based dynamic encoder (CDE) with various attention types to generate a deformable and dynamic view for multi-oriented text instances and curve ones. Different from previous methods that apply time-consuming post-processing steps like NMS, our method uses a Transformer-based decoder (TD) with a bipartite matching loss to model the relationship of corresponding queries and ground truths. As a result, by leveraging such a well-designed architecture, the receptive field will not be limited to a fixed shape, and a combination of global attention and local features provides a better representation for texts in natural scenes. We conduct extensive experiments qualitatively and quantitatively on several popular datasets. Experimental results show that the proposed method achieves superior performance compared with several state-of-the-art scene text detectors.},
  articleno = {9},
  doi       = {10.1145/3551626.3564980},
  isbn      = {9781450394789},
  keywords  = {scene text detection, transformer architecture, dynamic encoder},
  location  = {<conf-loc>, <city>Tokyo</city>, <country>Japan</country>, </conf-loc>},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3551626.3564980},
}

@InProceedings{Farah2022,
  author    = {Farah, Juan Carlos and Spaenlehauer, Basile and Ingram, Sandy and Gillet, Denis},
  booktitle = {Proceedings of the 4th Conference on Conversational User Interfaces},
  title     = {A Blueprint for Integrating Task-Oriented Conversational Agents in Education},
  year      = {2022},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {CUI '22},
  abstract  = {Over the past few years, there has been an increase in the use of chatbots for educational purposes. Nevertheless, the chatbot technologies and architectures that are often applied to educational contexts are not necessarily designed for such contexts. While general-purpose chatbot technologies can be used in educational contexts, there are some challenges specific to these contexts that need to be taken into consideration. Namely, chatbot technologies intended for education should, by design, integrate directly within online learning applications and focus on achieving learning goals by supporting learners with the task at hand. In this paper, we propose a blueprint for an architecture specifically aimed at integrating task-oriented chatbots to support learners in educational contexts. We then present a proof-of-concept implementation of our blueprint as a part of a code review application designed to teach programming best practices. Our blueprint could serve as a starting point for developers in education looking to build chatbot technologies targeting educational contexts and is a first step toward an open chatbot architecture explicitly tailored for learning applications.},
  articleno = {34},
  doi       = {10.1145/3543829.3544525},
  isbn      = {9781450397391},
  keywords  = {digital education, software architecture, task-oriented interactions, chatbots, online learning, conversational agents},
  location  = {Glasgow, United Kingdom},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3543829.3544525},
}

@InProceedings{Xu2021,
  author    = {Xu, Fenghao and Shen, Siyu and Diao, Wenrui and Li, Zhou and Chen, Yi and Li, Rui and Zhang, Kehuan},
  booktitle = {Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {Android on PC: On the Security of End-User Android Emulators},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {1566–1580},
  publisher = {Association for Computing Machinery},
  series    = {CCS '21},
  abstract  = {Android emulators today are not only acting as a debugging tool for developers but also serving the massive end-users. These end-user Android emulators have attracted millions of users due to their advantages of running mobile apps on desktops and are especially appealing for mobile game players who demand larger screens and better performance. Besides, they commonly provide some customized assistant functionalities to improve the user experience, such as keyboard mapping and app installation from the host. To implement these services, emulators inevitably introduce communication channels between host OS and Android OS (in the Virtual Machine), thus forming a unique architecture which mobile phone does not have. However, it is unknown whether this architecture brings any new security risks to emulators.This paper performed a systematic study on end-user Android emulators and discovered a series of security flaws on communication channel authentication, permission control, and open interfaces. Attackers could exploit these flaws to bypass Android security mechanisms and escalate their privileges inside emulators, ultimately invading users' privacy, such as stealing valuable game accounts and credentials. To understand the impact of our findings, we studied six popular emulators and measured their flaws. The results showed that the issues are pervasive and could cause severe security consequences. We believe our work just shows the tip of the iceberg, and further research can be done to improve the security of this ecosystem.},
  doi       = {10.1145/3460120.3484774},
  isbn      = {9781450384544},
  keywords  = {security assessment, android emulator},
  location  = {Virtual Event, Republic of Korea},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3460120.3484774},
}

@InProceedings{CastilloFernandez2023,
  author    = {Castillo-Fern\'{a}ndez, Elvira and D\'{\i}az-Verdejo, Jes\'{u}s and Estepa Alonso, Rafael and Estepa Alonso, Antonio and Mu\~{n}oz Calle, Javier and Mabinabeitia, Germ\'{a}n},
  booktitle = {Proceedings of the 2023 European Interdisciplinary Cybersecurity Conference},
  title     = {Multistep Cyberattacks Detection Using a Flexible Multilevel System for Alerts and Events Correlation},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {1–6},
  publisher = {Association for Computing Machinery},
  series    = {EICC '23},
  abstract  = {Current network monitoring systems tend to generate several alerts per attack, especially in multistep attacks. However, Cybersecurity Officers (CSO) would rather receive a single alert summarizing the entire incident. Triggering a single alert per attack is a challenge that requires developing and evaluating advanced event correlation techniques and models to determine the relationships between the different observed events/alerts. In this work, we propose a flexible architecture oriented toward the correlation and aggregation of events and alerts in a multilevel iterative approach. In our scheme, sensors generate events and alerts that are stored in a non-relational database queried by modules that create knowledge structured as meta-alerts that are also stored in the database. These meta-alerts (also called hyperalerts) are, in turn, used iteratively to create new knowledge. This iterative approach can be used to aggregate information at multiple levels or steps in complex attack models. Our architecture also allows the incorporation of additional sensors and the evaluation of various correlation techniques and multistage attack models. The capabilities of the system are assessed through three case studies.},
  doi       = {10.1145/3590777.3590778},
  isbn      = {9781450398299},
  keywords  = {Intrusion Detection Systems, cyberattacks models, attack models, alert correlation, network security monitoring},
  location  = {Stavanger, Norway},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3590777.3590778},
}

@InProceedings{Sahita2023,
  author    = {Sahita, Ravi and Shanbhogue, Vedvyas and Bresticker, Andrew and Khare, Atul and Patra, Atish and Ortiz, Samuel and Reid, Dylan and Kanwal, Rajnesh},
  booktitle = {Proceedings of the 20th ACM International Conference on Computing Frontiers},
  title     = {CoVE: Towards Confidential Computing on RISC-V Platforms},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {315–321},
  publisher = {Association for Computing Machinery},
  series    = {CF '23},
  abstract  = {Multi-tenant computing platforms are typically comprised of several software and hardware components including platform firmware, operating system, virtualization monitor, and tenant workloads (typically in a virtual machine, container, or application). This model is well established in large scale commercial deployments, but the downside is that all platform components and operators are in the Trusted Computing Base (TCB) of the tenant. This aspect is ill-suited for privacy-oriented workloads that aim to minimize the TCB. Confidential computing [1] presents a good stepping-stone towards providing a quantifiable TCB for computing. Confidential computing requires the use of a HW-attested Trusted Execution Environment for data-in-use protection. The RISC-V architecture presents a strong foundation for meeting the requirements for Confidential Computing in a clean slate manner. This paper describes a reference architecture and discusses ISA, non-ISA and System-on-Chip (SoC) requirements for confidential computing on RISC-V Platforms. It discusses proposed RISC-V ISA and non-ISA for Confidential Virtual-machine Extension, referred to as CoVE.},
  doi       = {10.1145/3587135.3592168},
  isbn      = {9798400701405},
  keywords  = {Confidential Computing, Attestation, Virtualization, Security},
  location  = {Bologna, Italy},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3587135.3592168},
}

@InProceedings{Kim2023,
  author    = {Kim, Jason and van Schaik, Stephan and Genkin, Daniel and Yarom, Yuval},
  booktitle = {Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {ILeakage: Browser-Based Timerless Speculative Execution Attacks on Apple Devices},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {2038–2052},
  publisher = {Association for Computing Machinery},
  series    = {CCS '23},
  abstract  = {Over the past few years, the high-end CPU market is undergoing a transformational change. Moving away from using x86 as the sole architecture for high performance devices, we have witnessed the introduction of heavy-weight Arm CPUs computing devices. Among these, perhaps the most influential was the introduction of Apple's M-series architecture, aimed at completely replacing Intel CPUs in the Apple ecosystem. However, while significant effort has been invested analyzing x86 CPUs, the Apple ecosystem remains largely unexplored.In this paper, we set out to investigate the resilience of the Apple ecosystem to speculative side-channel attacks. We first establish the basic toolkit needed for mounting side-channel attacks, such as the structure of caches and CPU speculation depth. We then tackle Apple's degradation of the timer resolution in both native and browser-based code. Remarkably, we show that distinguishing cache misses from cache hits can be done without time measurements, replacing timing based primitives with timerless counterparts based on race conditions. Finally, we use our distinguishing primitive to construct eviction sets and mount Spectre attacks, all while avoiding the use of timers.We then evaluate Safari's side-channel resilience. We bypass the compressed 35-bit addressing and the value poisoning countermeasures, creating a primitive that can speculatively read and leak any 64-bit address within Safari's rendering process. Combining this with a new method for consolidating websites from different domains into the same renderer process, we demonstrate end-to-end attacks leaking sensitive information, such as passwords, inbox content, and locations from popular services such as Google.},
  doi       = {10.1145/3576915.3616611},
  isbn      = {9798400700507},
  keywords  = {apple silicon, side-channel attacks, timerless channels, spectre},
  location  = {<conf-loc>, <city>Copenhagen</city>, <country>Denmark</country>, </conf-loc>},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3576915.3616611},
}

@InProceedings{Tedre2021,
  author    = {Tedre, Matti and Denning, Peter and Toivonen, Tapani},
  booktitle = {Proceedings of the 21st Koli Calling International Conference on Computing Education Research},
  title     = {CT 2.0},
  year      = {2021},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {Koli Calling '21},
  abstract  = {CT has been the central rallying point for K-12 computing education at least since the early 2010s. Many teachers, school administrators, and policymakers have joined the movement. A consensus has emerged over the conceptual landscape of CT. Meanwhile, machine learning (ML) has triggered some major changes in many sectors of computing. Children’s lives today are full of ML-driven services—take TikTok’s spot-on recommendations, social media’s automatic tagging of their friends in photos, and targeted personalized advertisement, just to mention a few. Children cannot learn to think about and design ML technology from learning classical programming. ML is poised to upend the CT consensus. Look at some of the changes ML has already triggered in computing. It has enabled greatly improved speech and image recognition, powerful recommendations on streaming services, autonomous navigation of cars, super-human performance in board and computer games, and even alternative-reality “deepfake” videos. Most advances in topics above are due to hardware evolution to non-traditional, special purpose architectures, new algorithms such as convolutional neural networks (CNN) or generative adversarial networks (GAN), and new objectives and measures of success. We will show that several key CT concepts, including debugging, problem-solving workflow, correctness, and notional machines, are insufficient for ML and need to be extended. Moreover, ML introduces new concepts including neural networks, curating and training data, and reinforcement learning that are not part of CT at all. All these changes challenge the traditional views related to teaching CT in K–12. ML is not the only emerging technology appearing in the computing landscape. Quantum computing and biological computing are not far behind. We need to start rethinking how CT must evolve to anticipate and meet these challenges.},
  articleno = {3},
  doi       = {10.1145/3488042.3488053},
  isbn      = {9781450384889},
  keywords  = {Artificial intelligence, School, Machine learning, Computational thinking, K-12},
  location  = {Joensuu, Finland},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3488042.3488053},
}

@InProceedings{Wang2023b,
  author    = {Wang, Shuke and Zhang, Mingxing and Yang, Ke and Chen, Kang and Ma, Shaonan and Jiang, Jinlei and Wu, Yongwei},
  booktitle = {Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
  title     = {NosWalker: A Decoupled Architecture for Out-of-Core Random Walk Processing},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {466–482},
  publisher = {Association for Computing Machinery},
  series    = {ASPLOS 2023},
  abstract  = {Out-of-core random walk system has recently attracted a lot of attention as an economical way to run billions of walkers over large graphs. However, existing out-of-core random walk systems are all built upon general out-of-core graph processing frameworks, and hence do not take advantage of the unique properties of random walk applications. Different from traditional graph analysis algorithms, the sampling process of random walk can be decoupled from the processing of the walkers. It enables the system to reserve only pre-sample results in memory, which are typically much smaller than the entire edge set. Moreover, in random walk, it is not the number of walkers but the number of steps moved per second that dominates the overall performance. Thus, with independent walkers, there is no need to process all the walkers simultaneously. In this paper, we present NosWalker, an out-of-core random walk system that replaces the graph oriented scheduling with a decoupled system architecture that provides walker oriented scheduling. NosWalker is able to adaptively generate walkers and flexibly adjust the distribution of reserved pre-sample results in memory. Instead of processing all the walkers at once, NosWalker only tries its best to keep a few walkers able to continuously move forward. Experimental results show that NosWalker can achieve up to two orders of magnitude speedup compared to state-of-the-art out-of-core random walk systems. In particular, NosWalker demonstrates superior performance when the memory capacity can only hold about 10\%-50\% of the graph data, which can be a common case when the user needs to run billions of walkers over large graphs.},
  doi       = {10.1145/3582016.3582025},
  isbn      = {9781450399180},
  keywords  = {out-of-core, graph processing, random walk},
  location  = {Vancouver, BC, Canada},
  numpages  = {17},
  url       = {https://doi.org/10.1145/3582016.3582025},
}

@InProceedings{ElDarieby2022,
  author    = {El-Darieby, Mohamed and Daoud, George and Patel, Monil},
  booktitle = {Proceedings of the 32nd Annual International Conference on Computer Science and Software Engineering},
  title     = {Autonomous Vehicles Technology Stack \&amp; Generated Data},
  year      = {2022},
  address   = {USA},
  pages     = {227–228},
  publisher = {IBM Corp.},
  series    = {CASCON '22},
  abstract  = {This workshop discusses, presents, and demos examples of how advances in Connected and Autonomous Vehicles (CAV) and in Information and Communications Technologies (ICT) will benefit Intelligent Transportation Systems (ITS). CAV technologies provide an enormous opportunity to generate and collect traffic datasets that directly impact Highway Traffic Management Operations (HTOps). CAV provides novel datasets in terms of types and pervasiveness of coverage of highway networks at a scale that we have not been exposed to before. This enables current HTOps for extensions in features and enhancements in accuracies. HTOps, as defined by Canadian ITS architecture [1], aims at managing traffic to enhance the efficiency of highways, avoid congestion, increase the safety of travelers, and enable more sustainable transportation. This workshop focuses on answering the following question “What (and How) are the features of CAV-generated data that can leverage (HTOps)?” We compare CAV-generated data to traditional traffic data (those collected from relatively “fixed location” sources such as CCTV, electronic loop detectors) and those collected from probe floating vehicles.Extensive research has been conducted into creating self-driving cars that can drive and maneuver on roads in a safe manner. This is embodied in the development of advanced safety features that include blind spot information, reversing/ parking/ lane change assistance, collision warning, and more. CAV can make movement actions based on knowledge of surroundings which relies on hundreds of thousands of data points collected from embedded sensors (LiDAR, cameras, radars, OBD unit, an IMU), (estimated at) a few Terabytes/Vehicle/Day. For example, Volvo’s Cirrus [2] and Lyft Level 5 [3] open-sourced datasets make use of high-resolution video cameras as well as LiDAR sensors to produce Gaussian points that monitor vehicle 3600 surroundings.As an example HTOPS service, we discuss in detail Variable Speed Limits (VSL) and how CAV data can be used to optimize maximum travel speed limit in a dynamic manner over different highway zones based on traffic, congestion, and weather. VSL helps achieve the objectives of HTOps, including devising premeditated plans for peak hours operations and controlling the travel speed in order to increase the throughput of vehicles. To increase safety and ensure compliance, gradual implementation through increments/ decrements of speed along highway zones is required. The extent, expressiveness and quality of CAV data can help achieve such advanced HTOps. For example, the nuScenes dataset [4] that uses linked data to break down and simplify data schema (with various objects such as Category, Ego Pose, Instance, Lidarseg, Map, Sample_annotation, and Sample Data.) With the help of distance measurements, space headings can be accurately defined for vehicles in front and behind the main car. In addition, current vehicle speed data can be obtained from onboard in real-time. This can also be extended to other HTOps services such as Dynamic Lane Management (DLM) which sets lane allocation rules based on the given traffic state, assigning a lane(s) to a prioritized class of vehicle or assigning variable travel speeds for each lane.CAV manufacturers and researchers have made significant progress in building a CAV technology stack that allows a vehicle to drive itself in a safe manner. The technology stack consists of sensing (described above), perception, prediction, and planning layers. The higher three layers use sophisticated deep learning machine learning to process collected data and produce further information on highway traffic conditions. For example, with camera footage, object (e.g. pedestrians, vehicles, traffic signs) detection software can be applied to identify, categorize and characterize surrounding objects. At the same time, LiDAR data can be mapped to provide a bird’s eye spatial view of the surrounding area. Such semantic object maps with binding boxes on objects and trajectory lines are valuable data that TMCs can use to understand the current roadway environment. This is important for understanding stopping time, and congestion levels between cars on the highway provided the current lane of the vehicle. However, due to how recent such developments are, the focus has been on developing the sensing and perception layers of that stack, with much less focus given to the prediction and planning layers.},
  keywords  = {microservices, cloud operations, Cloud computing, artificial intelligence},
  location  = {Toronto, Canada},
  numpages  = {2},
}

@InProceedings{Nie2022,
  author    = {Nie, Ping and Lu, Yujie and Zhang, Shengyu and Zhao, Ming and Xie, Ruobing and Wang, William Yang and Ren, Yi},
  booktitle = {Proceedings of the 31st ACM International Conference on Information \&amp; Knowledge Management},
  title     = {MIC: Model-Agnostic Integrated Cross-Channel Recommender},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {3400–3409},
  publisher = {Association for Computing Machinery},
  series    = {CIKM '22},
  abstract  = {Semantically connecting users and items is a fundamental problem for the matching stage of an industrial recommender system. Recent advances in this topic are based on multi-channel retrieval to efficiently measure users' interest on items from the massive candidate pool. However, existing studies are primarily built upon pre-defined retrieval channels, including User-CF (U2U), Item-CF (I2I), and Embedding-based Retrieval (U2I), thus access to the limited correlation between users and items which solely entail from partial information of latent interactions. In this paper, we propose a model-agnostic integrated cross-channel (MIC) approach for the large-scale recommendation, which maximally leverages the inherent multi-channel mutual information to enhance the matching performance. Specifically, MIC robustly models correlation within user-item, user-user, and item-item from latent interactions in a universal schema. For each channel, MIC naturally aligns pairs with semantic similarity and distinguishes them otherwise with more uniform anisotropic representation space. While state-of-the-art methods require specific architectural design, MIC intuitively considers them as a whole by enabling the complete information flow among users and items. Thus MIC can be easily plugged into other retrieval recommender systems. Extensive experiments show that our MIC helps several state-of-the-art models boost their performance on four real-world benchmarks. The satisfactory deployment of the proposed MIC on industrial online services empirically proves its scalability and flexibility.},
  doi       = {10.1145/3511808.3557081},
  isbn      = {9781450392365},
  keywords  = {model-agnostic, cross-channel contrastive, retrieval recommender},
  location  = {Atlanta, GA, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3511808.3557081},
}

@InProceedings{Bentaleb2023,
  author    = {Bentaleb, Abdelhak and Farahani, Reza and Tashtarian, Farzad and Hellwagner, Hermann and Zimmermann, Roger},
  booktitle = {Proceedings of the 2nd Mile-High Video Conference},
  title     = {Which CDN to Download From? A Client and Server Strategies},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {135–136},
  publisher = {Association for Computing Machinery},
  series    = {MHV '23},
  abstract  = {Content Delivery Networks (CDNs) has been evolved to enable different video streaming services to deliver media content over the Internet with less latency and improved quality. However, using only a single CDN is highly vulnerable to outages and crashes, resulting in a poor viewer experience. Regardless of viewers, traffic, or media content, a single CDN will be never sufficient to satisfy viewers' quality of experience (QoE) requirements. To avoid single CDN issues, leveraging multiple CDNs from multiple providers, refers to multi-CDN, helps in improving performance, increasing geographic coverage, and alleviating outages. An essential part in multi-CDN solutions is the decision to select the best performing CDN in real-time, depending on periodic measurements of CDNs and video players. While multi-CDN architecture provides tremendous benefits, it has not been well investigated and integrated with the industry. This paper highlights various decision strategies for real-time CDN selection that helps content providers select the right solution aligned with their goals and business.},
  doi       = {10.1145/3588444.3591030},
  isbn      = {9798400701603},
  keywords  = {multi-CDN, ABR, QoE, adaptive video streaming, HLS, DASH},
  location  = {Denver, CO, USA},
  numpages  = {2},
  url       = {https://doi.org/10.1145/3588444.3591030},
}

@InProceedings{Zeng2022a,
  author    = {Zeng, Liekang and Huang, Peng and Luo, Ke and Zhang, Xiaoxi and Zhou, Zhi and Chen, Xu},
  booktitle = {Proceedings of the ACM Web Conference 2022},
  title     = {Fograph: Enabling Real-Time Deep Graph Inference with Fog Computing},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {1774–1784},
  publisher = {Association for Computing Machinery},
  series    = {WWW '22},
  abstract  = {Graph Neural Networks (GNNs) have gained growing interest in miscellaneous applications owing to their outstanding ability in extracting latent representation on graph structures. To render GNN-based service for IoT-driven smart applications, the traditional model serving paradigm resorts to the cloud by fully uploading the geo-distributed input data to the remote datacenter. However, our empirical measurements reveal the significant communication overhead of such cloud-based serving and highlight the profound potential in applying the emerging fog computing. To maximize the architectural benefits brought by fog computing, in this paper, we present Fograph, a novel distributed real-time GNN inference framework that leverages diverse resources of multiple fog nodes in proximity to IoT data sources. By introducing heterogeneity-aware execution planning and GNN-specific compression techniques, Fograph tailors its design to well accommodate the unique characteristics of GNN serving in fog environment. Prototype-based evaluation and case study demonstrate that Fograph significantly outperforms the state-of-the-art cloud serving and vanilla fog deployment by up to 5.39 \texttimes{} execution speedup and 6.84 \texttimes{} throughput improvement.},
  doi       = {10.1145/3485447.3511982},
  isbn      = {9781450390965},
  keywords  = {graph neural networks, Fog computing, model serving, distributed processing},
  location  = {Virtual Event, Lyon, France},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3485447.3511982},
}

@InProceedings{Chen2022a,
  author    = {Chen, Yen-Jen and Lin, En-Cheng},
  booktitle = {Proceedings of the 2022 8th International Conference on Computer Technology Applications},
  title     = {Design and Implementation of Hardware and Peripheral System for IoT Gateway},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {268–274},
  publisher = {Association for Computing Machinery},
  series    = {ICCTA '22},
  abstract  = {This paper uses Linkit Smart 7688 Duo development board developed by MediaTek as the core of the overall IoT gateway system design, which compares other development boards and IoT gateways on the market. Smart 7688 Duo development board is about 40\% lower in price than Raspberry Pi, and the hardware CPU clock is higher than NEXCOM NIO 51 gateway. This implementation provides a low-cost and highly customizable solution that allows system integrators to more effectively provide their customers with the most appropriate IT services. The proposed IoT gateway design utilizes the Linkit Smart 7688 Duo with MIPS and MCU dual-core chip, Arduino development environment and industrial protocol Modbus to design the data transfer of each sensor in the peripheral system. The IoT gateway obtains the sensor data and transmits it to the server using Message Queuing Telemetry Transport (MQTT). The data acquisition accuracy of the developed MCU program was measured with 2 sensors of hydrogen sulfide (H2S) and methane (CH4). The overall system architecture and peripheral systems are designed to realize the IoT gateway taking into account the internal heat dissipation and module wiring, and also the appearance of the chassis is designed to carry the IoT gateway system, so as to achieve a high-quality product prototype that is accurate, economical, and customizable.},
  doi       = {10.1145/3543712.3543740},
  isbn      = {9781450396226},
  keywords  = {MQTT, Modbus, MCU, Gateway, IoT},
  location  = {Vienna, Austria},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3543712.3543740},
}

@Article{Cucchiara2022,
  author     = {Cucchiara, Rita and Fabbri, Matteo},
  journal    = {ACM Trans. Multimedia Comput. Commun. Appl.},
  title      = {Fine-Grained Human Analysis under Occlusions and Perspective Constraints in Multimedia Surveillance},
  year       = {2022},
  issn       = {1551-6857},
  month      = {jan},
  number     = {1s},
  volume     = {18},
  abstract   = {Human detection in the wild is a research topic of paramount importance in computer vision, and it is the starting step for designing intelligent systems oriented to human interaction that work in complete autonomy. To achieve this goal, computer vision and machine learning should aim at superhuman capabilities. In this work, we address the problem of fine-grained human analysis under occlusions and perspective constraints. More specifically, we discuss some issues and some possible solutions to effectively detect people using pose estimation methods and to detect humans under occlusions both in the two-dimensional (2D) image plane and in the 3D space exploiting single monocular cameras. Dealing with occlusion can be done at the joint level or pixel level: We discuss two different solutions, the former based on a supervised neural network architecture for detecting occluded joints and the latter based on a semi-supervised specialized GAN that exploits both appearance and human shape attributes to determine the missing parts of the visible shape. To deal with perspective constraints, we further discuss a neural approach based on a double architecture that learns to create an optimal neural representation, which is useful to reconstruct the 3D position of human keypoints starting with simple RGB images. All these approaches have a critical point in common: the need for large annotated datasets. To have large, fair, consistent, transparent, and ethical datasets, we propose the adoption of synthetic datasets as, for example, JTA and MOTSynth. In this article, we discuss the pros and cons of using synthetic datasets while tackling several human-centered AI issues with respect to European GDPR rules for privacy. We further explore and discuss an application in the field of risk assessment by space occupancy estimation during the COVID-19 pandemic called Inter-Homines.},
  address    = {New York, NY, USA},
  articleno  = {32},
  doi        = {10.1145/3476839},
  issue_date = {February 2022},
  keywords   = {3D localization, synthetic dataset, tracking, human pose estimation, People detection},
  numpages   = {23},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3476839},
}

@Article{Shapira2021,
  author     = {Shapira, Tal and Shavitt, Yuval},
  journal    = {IEEE/ACM Trans. Netw.},
  title      = {SASA: Source-Aware Self-Attention for IP Hijack Detection},
  year       = {2021},
  issn       = {1063-6692},
  month      = {oct},
  number     = {1},
  pages      = {437–449},
  volume     = {30},
  abstract   = {IP hijack attacks deflect traffic between endpoints through the attacker network, leading to man-in-the-middle attacks. Current detection solutions are only based on AS-level path analysis, while attacks that include data-plane manipulations may exhibit only geographic anomalies and preserve the AS-level route, or hide the problematic AS in the path. Thus, there is a need to develop data-plane analysis frameworks that examine the actual route packets traverse. We introduce here a deep learning system that examines the geography of traceroute measurements to detect malicious routes. We use multiple geolocation services, with various levels of confidence; each also suffers from location errors. Moreover, identifying a hijacked route is not sufficient since an operator presented with a hijack alert needs an indication of the cause for flagging out the problematic route. Thus, we introduce a novel deep learning layer, called Source-Aware Self-Attention (&lt;italic&gt;SASA&lt;/italic&gt;), which is an extension of the attention mechanism. &lt;italic&gt;SASA&lt;/italic&gt; learns each data source’s confidence and combines this score with the attention of each router in the route to point out the most problematic one. We validate our IP hijacking classification method using two router data types: coordinates and country location, and show that &lt;italic&gt;SASA&lt;/italic&gt; outperforms the regular self-attention layer, using the same neural network architecture, and achieves extremely high accuracy.},
  doi        = {10.1109/TNET.2021.3115935},
  issue_date = {Feb. 2022},
  numpages   = {13},
  publisher  = {IEEE Press},
  url        = {https://doi.org/10.1109/TNET.2021.3115935},
}

@Article{Cao2023,
  author    = {Cao, Yejun and Yu, Xiwen and Jiang, Fengling},
  journal   = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
  title     = {Application of 3D Image Technology in Rural Planning},
  year      = {2023},
  issn      = {2375-4699},
  month     = {oct},
  note      = {Just Accepted},
  abstract  = {The well-being of villages and villagers is directly related to the development of urban-rural relations. Rural development is an important part of poverty alleviation, as well as the main goal and means of rural rejuvenation, Because rural planning affects rural economic development and rural revitalization. Electronic imaging can improve the speed of rural area planning, and can also model the planned scheme. However, the current rural planning still lacks top-level design, which cannot improve the overall structural design of rural planning, and the data resources of rural planning are not perfect. Therefore, this paper studied the direction of rural planning and design by analyzing the focus, problems and external environment characteristics of rural planning, and then analyzed the application characteristics in rural planning according to the process of 3D image technology. By reducing the complex design links in rural planning, the office efficiency of planning and the 3D visualization of planning model can be promoted, so as to improve the effect of rural planning and the construction service of rural planning. The simulated annealing algorithm showed that the planning efficiency and average planning speed of 3D image application in rural planning were gradually increasing; the average planning efficiency was about 1.80, and the average planning speed was about 1.05. The planning efficiency increased by 1.20 in the whole process, while the average planning speed increased by 0.33 in the whole process. Through comparison, it can be seen that the planning rationality of rural planning under 3D image was 12.16\% higher than the original one, while the measurement error rate of some teachers was 47.28\% lower. In a word, 3D imaging and electronic imaging can improve the architectural design and layout planning of rural planning.},
  address   = {New York, NY, USA},
  doi       = {10.1145/3628448},
  keywords  = {Electronic Imaging, 3D Imaging, Planning Process Analysis, Rural Planning},
  publisher = {Association for Computing Machinery},
  url       = {https://doi.org/10.1145/3628448},
}

@InProceedings{Roeckl2021,
  author    = {R\"{o}ckl, Jonas and Protsenko, Mykolai and Huber, Monika and M\"{u}ller, Tilo and Freiling, Felix C.},
  booktitle = {Proceedings of the 37th Annual Computer Security Applications Conference},
  title     = {Advanced System Resiliency Based on Virtualization Techniques for IoT Devices},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {455–467},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC '21},
  abstract  = {An increasing number of powerful devices are equipped with network connectivity and are connected to the Internet of Things (IoT). Influenced by the steady growth of computing power of the devices, the paradigm of IoT-based service deployment is expected to change, following the example of cloud-based infrastructure: An embedded platform can be provided as-a-service to several independent application service suppliers. This fosters additional challenges concerning security and isolation. At the same time, recently revealed critical vulnerabilities like Ripple20 and Amnesia:33 show that embedded devices are not spared from wide-spread attacks. In this paper, we define new trusted computing concepts, focusing on privilege separation among several entities sharing one physical device. The concepts guarantee remote recovery capabilities within a bounded amount of time, even if notable portions of the software stack have been compromised. We derive a resilient system architecture suitable for the secure operation of multiple isolated services on one embedded device. We integrate an interface for detecting intrusions and anomalies to enable the automatic recovery of compromised devices and prototype our system on a Nitrogen8M development board. Our evaluation shows that the overhead in terms of network throughput and CPU performance is low so that we believe that our concept is a meaningful step towards more resilient future IoT devices.},
  doi       = {10.1145/3485832.3485836},
  isbn      = {9781450385794},
  keywords  = {virtualization, trusted computing, recovery, cyber resilience},
  location  = {<conf-loc>, <city>Virtual Event</city>, <country>USA</country>, </conf-loc>},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3485832.3485836},
}

@InProceedings{Malhotra2022,
  author    = {Malhotra, Ganeshan and Waheed, Abdul and Srivastava, Aseem and Akhtar, Md Shad and Chakraborty, Tanmoy},
  booktitle = {Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining},
  title     = {Speaker and Time-Aware Joint Contextual Learning for Dialogue-Act Classification in Counselling Conversations},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {735–745},
  publisher = {Association for Computing Machinery},
  series    = {WSDM '22},
  abstract  = {The onset of the COVID-19 pandemic has brought the mental health of people under risk. Social counselling has gained remarkable significance in this environment. Unlike general goal-oriented dialogues, a conversation between a patient and a therapist is considerably implicit, though the objective of the conversation is quite apparent. In such a case, understanding the intent of the patient is imperative in providing effective counselling in therapy sessions, and the same applies to a dialogue system as well. In this work, we take forward a small but an important step in the development of an automated dialogue system for mental-health counselling. We develop a novel dataset, named HOPE, to provide a platform for the dialogue-act classification in counselling conversations. We identify the requirement of such conversation and propose twelve domain-specific dialogue-act (DAC) labels. We collect ~ 12.9K utterances from publicly-available counselling session videos on YouTube, extract their transcripts, clean, and annotate them with DAC labels. Further, we propose SPARTA, a transformer-based architecture with a novel speaker- and time-aware contextual learning for the dialogue-act classification. Our evaluation shows convincing performance over several baselines, achieving state-of-the-art on HOPE. We also supplement our experiments with extensive empirical and qualitative analyses of SPARTA.},
  doi       = {10.1145/3488560.3498509},
  isbn      = {9781450391320},
  keywords  = {mental-health counselling, dialogue-act classification},
  location  = {Virtual Event, AZ, USA},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3488560.3498509},
}

@InProceedings{Kottmann2022,
  author    = {Kottmann, Felix and Ma, Richard},
  booktitle = {Proceedings of the 1st International Workshop on Data Economy},
  title     = {A Limit-Order Bandwidth Market Design for Data Delivery},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {21–26},
  publisher = {Association for Computing Machinery},
  series    = {DE '22},
  abstract  = {Data spaces are an emerging solution to address increasing challenges on privacy, data security, and data sovereignty. However, additional requirements to data delivery emerge, concerning path-awareness and Quality of Service. New internet architectures and their services enable path-aware routing and guaranteed bandwidth. Those features do not only enable the creation of new services but also enable the potential of trading resources such as bandwidth. We design a market mechanism that determines the bandwidth allocation and prices for buyers who express their service requirements in terms of limit orders. Our design builds a price-quantity allocation around a Fisher-market with Leontief utility functions, addressing directly the allocation of bandwidth along one route and allowing for partial filling of orders in the case of congestion using price-priority.},
  doi       = {10.1145/3565011.3569059},
  isbn      = {9781450399234},
  location  = {Rome, Italy},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3565011.3569059},
}

@InProceedings{Kulkarni2022,
  author    = {Kulkarni, Umakant and Sheoran, Amit and Fahmy, Sonia},
  booktitle = {Proceedings of the Symposium on Architectures for Networking and Communications Systems},
  title     = {The Cost of Stateless Network Functions in 5G},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {73–79},
  publisher = {Association for Computing Machinery},
  series    = {ANCS '21},
  abstract  = {The adoption of a cloud-native architecture in 5G networks has facilitated rapid deployment and update of cellular services. An important part of this architecture is the implementation of 5G network functions statelessly. However, statelessness and its associated serialization and de-serialization of data and database interaction significantly increase latency. In this work, we take the first steps towards quantifying the cost of statelessness in a cloud-native 5G system. We compare the cost of different state management paradigms, and propose a number of optimizations to reduce this cost. Our preliminary results indicate that sharing user state among 5G functions reduces the overall cost by on an average of 10\% in experiments with 100 to 1000 simultaneous requests. Optimizations such as non-blocking calls and custom database APIs also reduce cost, albeit to a lower extent. We believe that the paradigms proposed in this paper can aid operators and software vendors as they design cloud-native 5G networks.},
  doi       = {10.1145/3493425.3502749},
  isbn      = {9781450391689},
  keywords  = {Stateless Network Functions, 5G, Cellular networks, Cloud-native architectures},
  location  = {Layfette, IN, USA},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3493425.3502749},
}

@Article{Vijaykumar2022,
  author     = {Vijaykumar, Nandita and Olgun, Ataberk and Kanellopoulos, Konstantinos and Bostanci, F. Nisa and Hassan, Hasan and Lotfi, Mehrshad and Gibbons, Phillip B. and Mutlu, Onur},
  journal    = {ACM Trans. Archit. Code Optim.},
  title      = {MetaSys: A Practical Open-Source Metadata Management System to Implement and Evaluate Cross-Layer Optimizations},
  year       = {2022},
  issn       = {1544-3566},
  month      = {mar},
  number     = {2},
  volume     = {19},
  abstract   = {This article introduces the first open-source FPGA-based infrastructure, MetaSys, with a prototype in a RISC-V system, to enable the rapid implementation and evaluation of a wide range of cross-layer techniques in real hardware. Hardware-software cooperative techniques are powerful approaches to improving the performance, quality of service, and security of general-purpose processors. They are, however, typically challenging to rapidly implement and evaluate in real hardware as they require full-stack changes to the hardware, system software, and instruction-set architecture (ISA).MetaSys implements a rich hardware-software interface and lightweight metadata support that can be used as a common basis to rapidly implement and evaluate new cross-layer techniques. We demonstrate MetaSys’s versatility and ease-of-use by implementing and evaluating three cross-layer techniques for: (i) prefetching in graph analytics; (ii) bounds checking in memory unsafe languages, and (iii) return address protection in stack frames; each technique requiring only ~100 lines of Chisel code over MetaSys.Using MetaSys, we perform the first detailed experimental study to quantify the performance overheads of using a single metadata management system to enable multiple cross-layer optimizations in CPUs. We identify the key sources of bottlenecks and system inefficiency of a general metadata management system. We design MetaSys to minimize these inefficiencies and provide increased versatility compared to previously proposed metadata systems. Using three use cases and a detailed characterization, we demonstrate that a common metadata management system can be used to efficiently support diverse cross-layer techniques in CPUs. MetaSys is completely and freely available at .},
  address    = {New York, NY, USA},
  articleno  = {26},
  doi        = {10.1145/3505250},
  issue_date = {June 2022},
  keywords   = {metadata, open-source, Hardware-software cooperation, RISC-V, memory},
  numpages   = {29},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3505250},
}

@Article{Li2023b,
  author     = {Li, Chenghong and Jin, Leyang and Zheng, Yujian and Yu, Yizhou and Han, Xiaoguang},
  journal    = {ACM Trans. Graph.},
  title      = {EMS: 3D Eyebrow Modeling from Single-View Images},
  year       = {2023},
  issn       = {0730-0301},
  month      = {dec},
  number     = {6},
  volume     = {42},
  abstract   = {Eyebrows play a critical role in facial expression and appearance. Although the 3D digitization of faces is well explored, less attention has been drawn to 3D eyebrow modeling. In this work, we propose EMS, the first learning-based framework for single-view 3D eyebrow reconstruction. Following the methods of scalp hair reconstruction, we also represent the eyebrow as a set of fiber curves and convert the reconstruction to fibers growing problem. Three modules are then carefully designed: RootFinder firstly localizes the fiber root positions which indicate where to grow; OriPredictor predicts an orientation field in the 3D space to guide the growing of fibers; FiberEnder is designed to determine when to stop the growth of each fiber. Our OriPredictor directly borrows the method used in hair reconstruction. Considering the differences between hair and eyebrows, both RootFinder and FiberEnder are newly proposed. Specifically, to cope with the challenge that the root location is severely occluded, we formulate root localization as a density map estimation task. Given the predicted density map, a density-based clustering method is further used for finding the roots. For each fiber, the growth starts from the root point and moves step by step until the ending, where each step is defined as an oriented line segment with a constant length according to the predicted orientation field. To determine when to end, a pixel-aligned RNN architecture is designed to form a binary classifier, which outputs stop or not for each growing step. To support the training of all proposed networks, we build the first 3D synthetic eyebrow dataset that contains 400 high-quality eyebrow models manually created by artists. Extensive experiments have demonstrated the effectiveness of the proposed EMS pipeline on a variety of different eyebrow styles and lengths, ranging from short and sparse to long bushy eyebrows.},
  address    = {New York, NY, USA},
  articleno  = {269},
  doi        = {10.1145/3618323},
  issue_date = {December 2023},
  keywords   = {deep neural networks, dataset, single-view modeling, eyebrow},
  numpages   = {19},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3618323},
}

@InProceedings{Ardimento2022,
  author    = {Ardimento, Pasquale and Aversano, Lerina and Bernardi, Mario Luca and Cimitile, Marta},
  booktitle = {Proceedings of the 37th ACM/SIGAPP Symposium on Applied Computing},
  title     = {Design Patterns Mining Using Neural Sub-Graph Matching},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {1545–1553},
  publisher = {Association for Computing Machinery},
  series    = {SAC '22},
  abstract  = {Design Patterns detection in Object-Oriented software systems is essential for effectively supporting program comprehension and re-engineering tasks. It helps to recover, from source code, the developers' design decisions and trade-offs that could be not up-to-date or even not documented. Several approaches to mine design patterns from source code have been defined in the last twelve years and they are all based on the analysis of object-oriented systems components, their relationships, and behaviors to identify the roles played in the patterns. Both static and dynamic approaches need to perform matching between data captured from the system with the design patterns specification that encodes the structure and the behavior of the micro-architectural solution. The matching process, in principle, can be formulated as a sub-graph matching problem that is NP-complete. This problem has been addressed in the literature using heuristics designed to produce good solutions in an acceptable time, but the task is still expensive with a significant trade-off between accuracy and performance. This work proposes the adoption of a neural-based approach that exploits graph neural networks to perform detection using a more efficient sub-graph matching step outperforming existing heuristics proposed for this task. The pattern detection approach has been assessed on several open-source systems widely used to perform design pattern detection obtaining very good results for both detection performances and efficiency.},
  doi       = {10.1145/3477314.3507073},
  isbn      = {9781450387132},
  keywords  = {design patterns, sub-graph matching, graph neural networks},
  location  = {Virtual Event},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3477314.3507073},
}

@InProceedings{DerrowPinion2021,
  author    = {Derrow-Pinion, Austin and She, Jennifer and Wong, David and Lange, Oliver and Hester, Todd and Perez, Luis and Nunkesser, Marc and Lee, Seongjae and Guo, Xueying and Wiltshire, Brett and Battaglia, Peter W. and Gupta, Vishal and Li, Ang and Xu, Zhongwen and Sanchez-Gonzalez, Alvaro and Li, Yujia and Velickovic, Petar},
  booktitle = {Proceedings of the 30th ACM International Conference on Information \&amp; Knowledge Management},
  title     = {ETA Prediction with Graph Neural Networks in Google Maps},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {3767–3776},
  publisher = {Association for Computing Machinery},
  series    = {CIKM '21},
  abstract  = {Travel-time prediction constitutes a task of high importance in transportation networks, with web mapping services like Google Maps regularly serving vast quantities of travel time queries from users and enterprises alike. Further, such a task requires accounting for complex spatiotemporal interactions (modelling both the topological properties of the road network and anticipating events---such as rush hours---that may occur in the future). Hence, it is an ideal target for graph representation learning at scale. Here we present a graph neural network estimator for estimated time of arrival (ETA) which we have deployed in production at Google Maps. While our main architecture consists of standard GNN building blocks, we further detail the usage of training schedule methods such as MetaGradients in order to make our model robust and production-ready. We also provide prescriptive studies: ablating on various architectural decisions and training regimes, and qualitative analyses on real-world situations where our model provides a competitive edge. Our GNN proved powerful when deployed, significantly reducing negative ETA outcomes in several regions compared to the previous production baseline (40+\% in cities like Sydney).},
  doi       = {10.1145/3459637.3481916},
  isbn      = {9781450384469},
  keywords  = {graph neural networks, metagradients, google maps},
  location  = {Virtual Event, Queensland, Australia},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3459637.3481916},
}

@InProceedings{Zhang2021c,
  author    = {Zhang, Zesen and Marder, Alexander and Mok, Ricky and Huffaker, Bradley and Luckie, Matthew and Claffy, K C and Schulman, Aaron},
  booktitle = {Proceedings of the 21st ACM Internet Measurement Conference},
  title     = {Inferring Regional Access Network Topologies: Methods and Applications},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {720–738},
  publisher = {Association for Computing Machinery},
  series    = {IMC '21},
  abstract  = {Using a toolbox of Internet cartography methods, and new ways of applying them, we have undertaken a comprehensive active measurement-driven study of the topology of U.S. regional access ISPs. We used state-of-the-art approaches in various combinations to accommodate the geographic scope, scale, and architectural richness of U.S. regional access ISPs. In addition to vantage points from research platforms, we used public WiFi hotspots and public transit of mobile devices to acquire the visibility needed to thoroughly map access networks across regions. We observed many different approaches to aggregation and redundancy, across links, nodes, buildings, and at different levels of the hierarchy. One result is substantial disparity in latency from some Edge COs to their backbone COs, with implications for end users of cloud services. Our methods and results can inform future analysis of critical infrastructure, including resilience to disasters, persistence of the digital divide, and challenges for the future of 5G and edge computing.},
  doi       = {10.1145/3487552.3487812},
  isbn      = {9781450391290},
  keywords  = {access networks, mobile networks, internet topology, traceroute},
  location  = {Virtual Event},
  numpages  = {19},
  url       = {https://doi.org/10.1145/3487552.3487812},
}

@InProceedings{Gringoli2021,
  author    = {Gringoli, Francesco and Leith, Douglas J.},
  booktitle = {Proceedings of the 19th ACM International Symposium on Mobility Management and Wireless Access},
  title     = {Modelling Downlink Aggregation in Paced WLANs},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {137–140},
  publisher = {Association for Computing Machinery},
  series    = {MobiWac '21},
  abstract  = {We derive an analytic model of packet aggregation on the the downlink of an 802.11 WLAN when packet arrivals are paced. The model is closed-form and so suitable for both analysis and design. We validate the model against both simulations and experimental measurements and we show its remarkable accuracy despite its simplicity. With proposed next generation architectures for over-the-top services it is straightforward to introduce packet pacing at the network edge and indeed it is this observation that motivates the current work. With this in mind the model developed here provides a new basis for the analysis and design of next generation edge networks.},
  doi       = {10.1145/3479241.3486697},
  isbn      = {9781450390798},
  keywords  = {WLAN modelling, 802.11, aggregation},
  location  = {Alicante, Spain},
  numpages  = {4},
  url       = {https://doi.org/10.1145/3479241.3486697},
}

@InProceedings{Tao2023,
  author    = {Tao, Xuewen and Ha, Mingming and Ma, Qiongxu and Cheng, Hongwei and Lin, Wenfang and Guo, Xiaobo and Cheng, Linxun and Han, Bing},
  booktitle = {Proceedings of the 17th ACM Conference on Recommender Systems},
  title     = {Task Aware Feature Extraction Framework for Sequential Dependence Multi-Task Learning},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {151–160},
  publisher = {Association for Computing Machinery},
  series    = {RecSys '23},
  abstract  = {In online recommendation, financial service, etc., the most common application of multi-task learning (MTL) is the multi-step conversion estimations. A core property of the multi-step conversion is the sequential dependence among tasks. However, most existing works focus far more on the specific post-view click-through rate (CTR) and post-click conversion rate (CVR) estimations, which neglect the generalization of sequential dependence multi-task learning (SDMTL). Additionally, the performance of the SDMTL framework is also deteriorated by the interference derived from implicitly conflict information passing between adjacent tasks. In this paper, a systematic learning paradigm of the SDMTL problem is established for the first time, which can transform the SDMTL problem into a general MTL problem with constraints and be applicable to more general multi-step conversion scenarios with stronger task dependence. Also, the distribution dependence relationship between adjacent task spaces is illustrated from a theoretical point of view. On the other hand, an SDMTL architecture, named Task Aware Feature Extraction (TAFE), is developed to enable dynamic task representation learning from a sample-wise view. TAFE selectively reconstructs the implicit shared information corresponding to each sample case and performs explicit task-specific extraction under dependence constraints. Extensive experiments on offline public and real-world industrial datasets, and online A/B implementations demonstrate the effectiveness and applicability of proposed theoretical and implementation frameworks.},
  doi       = {10.1145/3604915.3608772},
  isbn      = {9798400702419},
  location  = {Singapore, Singapore},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3604915.3608772},
}

@InProceedings{Lebrun2022,
  author    = {Lebrun, Thomas and Boutet, Antoine and Aalmoes, Jan and Baud, Adrien},
  booktitle = {Proceedings of the 23rd ACM/IFIP International Middleware Conference},
  title     = {MixNN: Protection of Federated Learning against Inference Attacks by Mixing Neural Network Layers},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {135–147},
  publisher = {Association for Computing Machinery},
  series    = {Middleware '22},
  abstract  = {Machine Learning (ML) has emerged as a core technology to provide learning models to perform complex tasks. Boosted by Machine Learning as a Service (MLaaS), the number of applications relying on ML capabilities is ever increasing. However, ML models are the source of different privacy violations through passive or active attacks from different entities. In this paper, we present MixNN a proxy-based privacy-preserving system for federated learning to protect the privacy of participants against a curious or malicious aggregation server trying to infer sensitive information (i.e., membership and attribute inferences). MixNN receives the model updates from participants and mixes layers between participants before sending the mixed updates to the aggregation server. This mixing strategy drastically reduces privacy leaks without any trade-off with utility. Indeed, mixing the updates of the model has no impact on the result of the aggregation of the updates computed by the server. We report on an extensive evaluation of MixNN using several datasets and neural networks architectures to quantify privacy leakage through membership and attribute inference attacks as well the robustness of the protection. We show that MixNN significantly limits both the membership and attribute inferences compared to a baseline using model compression and noisy gradient (well known to damage the utility) while keeping the same level of utility as classic federated learning.},
  doi       = {10.1145/3528535.3565240},
  isbn      = {9781450393409},
  keywords  = {machine learning, privacy, inference attacks, federated learning},
  location  = {Quebec, QC, Canada},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3528535.3565240},
}

@InProceedings{Zheng2021,
  author    = {Zheng, Baolin and Jiang, Peipei and Wang, Qian and Li, Qi and Shen, Chao and Wang, Cong and Ge, Yunjie and Teng, Qingyang and Zhang, Shenyi},
  booktitle = {Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {Black-Box Adversarial Attacks on Commercial Speech Platforms with Minimal Information},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {86–107},
  publisher = {Association for Computing Machinery},
  series    = {CCS '21},
  abstract  = {Adversarial attacks against commercial black-box speech platforms, including cloud speech APIs and voice control devices, have received little attention until recent years. Constructing such attacks is difficult mainly due to the unique characteristics of time-domain speech signals and the much more complex architecture of acoustic systems. The current "black-box" attacks all heavily rely on the knowledge of prediction/confidence scores or other probability information to craft effective adversarial examples (AEs), which can be intuitively defended by service providers without returning these messages. In this paper, we take one more step forward and propose two novel adversarial attacks in more practical and rigorous scenarios. For commercial cloud speech APIs, we propose Occam, a decision-only black-box adversarial attack, where only final decisions are available to the adversary. In Occam, we formulate the decision-only AE generation as a discontinuous large-scale global optimization problem, and solve it by adaptively decomposing this complicated problem into a set of sub-problems and cooperatively optimizing each one. Our Occam is a one-size-fits-all approach, which achieves 100\% success rates of attacks (SRoA) with an average SNR of 14.23dB, on a wide range of popular speech and speaker recognition APIs, including Google, Alibaba, Microsoft, Tencent, iFlytek, and Jingdong, outperforming the state-of-the-art black-box attacks. For commercial voice control devices, we propose NI-Occam, the first non-interactive physical adversarial attack, where the adversary does not need to query the oracle and has no access to its internal information and training data. We, for the first time, combine adversarial attacks with model inversion attacks, and thus generate the physically-effective audio AEs with high transferability without any interaction with target devices. Our experimental results show that NI-Occam can successfully fool Apple Siri, Microsoft Cortana, Google Assistant, iFlytek and Amazon Echo with an average SRoA of 52\% and SNR of 9.65dB, shedding light on non-interactive physical attacks against voice control devices.},
  doi       = {10.1145/3460120.3485383},
  isbn      = {9781450384544},
  keywords  = {speaker recognition, adversarial attacks, black-box attacks, speech recognition},
  location  = {Virtual Event, Republic of Korea},
  numpages  = {22},
  url       = {https://doi.org/10.1145/3460120.3485383},
}

@InProceedings{Leiter2021,
  author    = {Leiter, \'{A}kos and Galambosi, N\'{a}ndor and Bokor, L\'{a}szl\'{o}},
  booktitle = {Proceedings of the 19th ACM International Symposium on Mobility Management and Wireless Access},
  title     = {An Evolution of Proxy Mobile IPv6 to the Cloud},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {107–115},
  publisher = {Association for Computing Machinery},
  series    = {MobiWac '21},
  abstract  = {Network Function Virtualization (NFV) and Software Defined Networks (SDN) do not leave any legacy network services untouched. This work will present how Proxy Mobile IPv6 (PMIPv6) can evolve to the cloud. Our approach is to introduce this evolution within a step-by-step architecture guideline while keeping standards compatibility. We also show how PMIPv6 can fit into a central cloud - edge cloud environment on the top of Kubernetes and Openstack under a unified orchestration umbrella. The proper integration of PMIPv6 into this new environment does not just enforce acquiring new capabilities, e.g., scaling PMIPv6 elements; it also can ensure closed-loop orchestration where PMIPv6 can be controlled continuously by the actual network needs.},
  doi       = {10.1145/3479241.3486684},
  isbn      = {9781450390798},
  keywords  = {kubernetes, cloud-native, CN-PMIPv6, openstack, ONAP, PMIPv6},
  location  = {Alicante, Spain},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3479241.3486684},
}

@InProceedings{Pontes2023,
  author    = {Pontes, Davi and Silva, Fernando and Falc\~{a}o, Eduardo and Brito, Andrey},
  booktitle = {Proceedings of the 12th Latin-American Symposium on Dependable and Secure Computing},
  title     = {Attesting AMD SEV-SNP Virtual Machines with SPIRE},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {1–10},
  publisher = {Association for Computing Machinery},
  series    = {LADC '23},
  abstract  = {SPIRE is an open-source project that enables the provisioning of verifiable identities to software components based on an attestation of the software properties, avoiding the leakage risks of pre-provisioned secrets. This paper presents an implementation of a SPIRE plugin that enables the attestation of AMD SEV-SNP confidential virtual machines. Our approach leverages the pluggable architecture from SPIRE and depends only on minor changes to QEMU, changes taken from its open-source community, and that should soon be merged. As a result, application providers can now use SPIRE to restrict sensitive credentials to be available only to services in environments protected from malicious hosts and cloud operators using AMD SEV-SNP technology. Our experiments show that the steps needed to create and attest the confidential VM do not prohibitively increase boot times (from 10.8 to 20.9 seconds) and that confidential VMs with encrypted disks only slightly degrade the CPU and RAM performance (about ) of unmodified applications.},
  doi       = {10.1145/3615366.3615419},
  isbn      = {9798400708442},
  keywords  = {AMD SEV-SNP, SPIRE, confidential computing},
  location  = {<conf-loc>, <city>La Paz</city>, <country>Bolivia</country>, </conf-loc>},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3615366.3615419},
}

@InProceedings{Seehofer2023,
  author    = {Seehofer, Paul and Mahrt, Hendrik and Bless, Roland and Zitterbart, Martina},
  booktitle = {Proceedings of the ACM SIGCOMM 2023 Conference},
  title     = {Demo: Enabling Autonomic Network Infrastructures with KIRA},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {1165–1167},
  publisher = {Association for Computing Machinery},
  series    = {ACM SIGCOMM '23},
  abstract  = {Increasing dynamics and an ever growing number of devices make current and future mobile network infrastructures more and more complex. Managing such networks thus becomes progressively challenging. Introducing more autonomic behavior in network management becomes indispensable to not only handle the growing complexity, but also to make these infrastructures more resilient as they constitute a critical component of overall public infrastructures. Autonomic control planes provide a fundamental set of resilient, autonomic infrastructure services (e.g., connectivity) for higher-level autonomic behavior to build upon. In this demo we show how a first real-world implementation of the routing architecture KIRA provides zero-touch control plane connectivity to enable an autonomic 5G network infrastructure. The demonstrator allows an in-depth view of each step in the process of bootstrapping a 5G infrastructure as well as of KIRA's resilience when challenged by failures and dynamics. Based on this autonomic connectivity solution we present our vision of more dynamic and resilient autonomic control networks toward the future design of 6G core networks.},
  doi       = {10.1145/3603269.3610864},
  isbn      = {9798400702365},
  keywords  = {network management, autonomic networks, resilience},
  location  = {New York, NY, USA},
  numpages  = {3},
  url       = {https://doi.org/10.1145/3603269.3610864},
}

@InProceedings{Sodagar2022,
  author    = {Sodagar, Iraj and Giladi, Alex},
  booktitle = {Proceedings of the 1st Mile-High Video Conference},
  title     = {Session-Based DASH Streaming: A New MPEG Standard for Customizing DASH Streaming per Session},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {110},
  publisher = {Association for Computing Machinery},
  series    = {MHV '22},
  abstract  = {The MPEG DASH standard is widely deployed in over-the-top streaming services. The standard defines two key components: a manifest format to describe the presentation and a set of segment formats to describe the media segments. While the DASH's manifest format, Media Presentation Document (MPD) provides a set of extensive tools to describe the presentation timeline, this document is usually created for a large set of DASH clients and therefore it can be cached in CDNs for a large population. If the MPD needs to be customized per client, the cache efficiency of storing a single MPD for all clients would be lost. Recently the MPEG Systems Working Group (ISO/IEC/SC29/WG3) developed a new standard that allows an MPD to be customized at each client using an external document and a set of processing rules. The first version of the Session-Based DASH standard (ISO/IEC 23009-8) was recently finalized and will be published in the upcoming months.ISO/IEC 23009-8 defines 3 components: 1) A Session-Based Document (SBD) which defines the MPD customization rules for a client for a given session, 2) A method of referencing the external Session-Based Document (SBD) in the DASH MPD, and finally, 3) a processing model for the client-side processing of SBDs. The SBD defines a post-processing procedure to customize each URL generated by the DASH client from an MPD. Before the DASH client requesting to download a resource using that URL, a process that is described in the SBD document is applied to the URL. The process can customize different parts of the URL, i.e. the host, path, port parts as well as its queries, using a template matching technique. The customization can be timed dependent, on the point in the media timeline that the URL corresponds to, or order dependent, i.e., on the location of the URL in the URL request orders. The result is a customized URL per client/session/URL that is produced from the given URL generated by the DASH client from MPD.The ISO/IEC 23009-8 standard defines an architecture for the session-based DASH streaming that has a few benefits: 1) From the content creation side, it separates the client-based and session-based customization from MPD and therefore maintains the MPD caching efficiency while allowing the customization. It also enables to produce customization after packaging of MPD which means that it can be added to the current workflows as a post-processing step. 2) From the client-side, it allows implementation of SBD client as a separate and independent process from the DASH client, and therefore it can be added to the current clients as a separate process. Furthermore, the SBD processing can occur on the device or a different network entity such as application servers. 3) From the content distribution side, the SBD creation or customization can occur at different nodes of the network, at the origin server, as distribution centers and CDNS, or even at the home network gateways. The standard also allows multiple SBDs to be applied to the URLs of an MPD, enabling the customization to be requested by one or multiple entities in the ingest or distribution chain.In this paper, we first describe the session-based DASH streaming architecture. Then the features of the SBD standard are outlined including the capabilities of customizing based on templates as well as the key-pair replacement and the possibilities of replacing various parts of a URL. Next, the SBD client processing model is described, and how the SBD client can be implemented on the device or as a network entity as a separate process. Finally, we demonstrate a forensic watermarking application using the SBD and demonstrate its capabilities and compare the efficiency of watermarking using the SBD standard vs the MPD customization per client/session.},
  doi       = {10.1145/3510450.3517280},
  isbn      = {9781450392228},
  keywords  = {DASH, session-based, MPEG},
  location  = {Denver, Colorado},
  numpages  = {1},
  url       = {https://doi.org/10.1145/3510450.3517280},
}

@InProceedings{Groelle2023,
  author    = {Gr\"{o}lle, David and Schulz, Lars-Christian and Wehner, Robin and Hausheer, David},
  booktitle = {Proceedings of the 6th on European P4 Workshop},
  title     = {Poster: High-Speed Per-Packet Checksums on the Intel Tofino},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {49–52},
  publisher = {Association for Computing Machinery},
  series    = {EuroP4 '23},
  abstract  = {Path-aware networking has introduced new possibilities to monitor and control network access and solved a multitude of modern-day Internet security issues. Being able to authorize usage of specific paths enables network operators to offer high-quality services to customers requiring highly reliable network access.Currently, securing a network path or an end host is only possible by using high-level solutions like VPNs. With EPIC-HP (Every Packet Is Checked - Hidden Path), it has been shown that it is possible to move this functionality down into the network itself. EPIC-HP extends the path-aware Internet architecture SCION by offering per-packet checksums, adding authentication to network traffic. This is used to combat DoS attacks on the network's end hosts and give high-priority access to specific end users. In this paper, we show that it is possible to implement the functionality of EPIC-HP along with SCION on the Intel Tofino 2 ASIC. EPIC-HP requires AES-based MAC verification with per-path keys in the data plane. By using the multi-pipeline structure of the Tofino, we implemented the required AES and AES-CMAC cryptography using three pipes of the switch's total four independent pipes.The throughput we achieve is an order of magnitude above the data rates previously achieved for EPIC-HP and is a significant step towards a more secure Internet.},
  doi       = {10.1145/3630047.3630192},
  isbn      = {9798400704468},
  keywords  = {aes, p4, tofino, future internet, scion},
  location  = {<conf-loc>, <city>Paris</city>, <country>France</country>, </conf-loc>},
  numpages  = {4},
  url       = {https://doi.org/10.1145/3630047.3630192},
}

@Article{Azizifard2022,
  author     = {Azizifard, Narges and Gelauff, Lodewijk and Gransard-Desmond, Jean-Olivier and Redi, Miriam and Schifanella, Rossano},
  journal    = {J. Comput. Cult. Herit.},
  title      = {Wiki Loves Monuments: Crowdsourcing the Collective Image of the Worldwide Built Heritage},
  year       = {2022},
  issn       = {1556-4673},
  month      = {dec},
  number     = {1},
  volume     = {16},
  abstract   = {The wide adoption of digital technologies in the cultural heritage sector has promoted the emergence of new, distributed ways of working, communicating, and investigating cultural products and services. In particular, collaborative online platforms and crowdsourcing mechanisms have been widely adopted in the effort to solicit input from the community and promote engagement. In this work, we provide an extensive analysis of the Wiki Loves Monuments initiative, an annual, international photography contest in which volunteers are invited to take pictures of the built cultural heritage and upload them to Wikimedia Commons. We explore the geographical, temporal, and topical dimensions across the 2010–2021 editions. We first adopt a set of CNN-based artificial systems that allow the learning of deep scene features for various scene recognition tasks, exploring cross-country (dis)similarities. To overcome the rigidity of the framework based on scene descriptors, we train a deep convolutional neural network model to label a photo with its country of origin. The resulting model captures the best representation of a heritage site uploaded in a country, and it allows the domain experts to explore the complexity of cross-national architectural styles. Finally, as a validation step, we explore the link between architectural heritage and intangible cultural values, operationalized using the framework developed within the World Value Survey research program. We observe that cross-country cultural similarities match to a fair extent the interrelations emerging in the architectural domain. We think this study contributes to highlighting the richness and the potential of the Wikimedia data and tools ecosystem to act as a scientific object for art historians, iconologists, and archaeologists.},
  address    = {New York, NY, USA},
  articleno  = {20},
  doi        = {10.1145/3569092},
  issue_date = {March 2023},
  keywords   = {Wiki Loves Monuments, Cultural heritage, cross-cultural study},
  numpages   = {27},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3569092},
}

@Article{Shen2023,
  author     = {Shen, Li-Hsiang and Feng, Kai-Ten and Hanzo, Lajos},
  journal    = {ACM Comput. Surv.},
  title      = {Five Facets of 6G: Research Challenges and Opportunities},
  year       = {2023},
  issn       = {0360-0300},
  month      = {feb},
  number     = {11},
  volume     = {55},
  abstract   = {While the fifth-generation systems are being rolled out across the globe, researchers have turned their attention to the exploration of radical next-generation solutions. At this early evolutionary stage, we survey five main research facets of this field, namely Facet&nbsp;1: next-generation architectures, spectrum, and services; Facet&nbsp;2: next-generation networking; Facet&nbsp;3: Internet of Things; Facet&nbsp;4: wireless positioning and sensing; and Facet&nbsp;5: applications of deep learning in 6G networks. In this article, we provide a critical appraisal of the literature of promising techniques ranging from the associated architectures, networking, and applications, as well as designs. We portray a plethora of heterogeneous architectures relying on cooperative hybrid networks supported by diverse access and transmission mechanisms. The vulnerabilities of these techniques are also addressed and carefully considered for highlighting the most of promising future research directions. Additionally, we list a rich suite of learning-driven optimization techniques. We conclude by observing the evolutionary paradigm shift that has taken place from pure single-component bandwidth efficiency, power efficiency, or delay optimization toward multi-component designs, as exemplified by the twin-component ultra-reliable low-latency mode of the fifth-generation system. We advocate a further evolutionary step toward multi-component Pareto optimization, which requires the exploration of the entire Pareto front of all optimal solutions, where none of the components of the objective function may be improved without degrading at least one of the other components.},
  address    = {New York, NY, USA},
  articleno  = {235},
  doi        = {10.1145/3571072},
  issue_date = {November 2023},
  keywords   = {deep learning, 5G, next-generation, 6G, IoT, communications and networking, positioning and sensing},
  numpages   = {39},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3571072},
}

@InProceedings{Yang2021,
  author    = {Yang, QiZhen and Xie, XiaoLan},
  booktitle = {Proceedings of the 2020 3rd International Conference on E-Business, Information Management and Computer Science},
  title     = {Research on Cloud Computing Task Scheduling Based on Improved Evolutionary Algorithm},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {566–572},
  publisher = {Association for Computing Machinery},
  series    = {EBIMCS '20},
  abstract  = {In the research of cloud computing, the advantages and disadvantages of cloud task scheduling algorithm will affect the operation efficiency and service quality of the whole cloud computing system. Evolutionary algorithm is the sum of a series of specific algorithms inspired by the phenomenon of biological evolution in nature. One of the common points of these algorithms is that individuals must be mutated according to certain rules in the running process, so as to avoid falling into local optimum. In order to improve the efficiency of cloud task scheduling in cloud computing, this paper proposes a new mutation strategy which changes the genetic algorithm in evolutionary algorithm. It uses cloudsim platform to simulate cloud task scheduling in cloud computing, and uses particle swarm optimization algorithm to optimize its parameters. The experimental results show that the proposed evolutionary algorithm with improved mutation strategy has the function of cloud task scheduling, and its performance is also improved after the parameters are optimized by particle swarm optimization algorithm. The proposed algorithm improves the mutation step and explores the essence of mutation in evolutionary algorithm, which provides a reference for other research.},
  doi       = {10.1145/3453187.3453396},
  isbn      = {9781450389099},
  keywords  = {Particle swarm optimization algorithm, Cloud computing, Task scheduling, Evolutionary algorithm, Cloudsim},
  location  = {Wuhan, China},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3453187.3453396},
}

@InProceedings{XIANZHI2021,
  author    = {WANG, XIANZHI and HUANG, PINGGUO and ISHIBASHI, YUTAKA and OKUDA, TAKASHI and WATANABE, HISTOSHI},
  booktitle = {Proceedings of the 2020 9th International Conference on Networks, Communication and Computing},
  title     = {Influence of Network Delay on QoS Control Using Neural Network in Remote Robot Systems with Force Feedback},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {104–111},
  publisher = {Association for Computing Machinery},
  series    = {ICNCC '20},
  abstract  = {In this paper, we focus on the application of big data, cloud computing, and AI (Artificial Intelligence) to QoS (Quality of Service) control to remote robot systems with force feedback. As the first step of our research, we investigate the influence of cloud delay on the remote robot systems while using big data, cloud computing, and AI technology by experiment. In the experiment, we deal with a task in which two robot arms of the two remote robot systems grasp an object and carry the object together. By using big data, cloud computing, and neural network, we predict the optimum value for the robot position control using force information, which we previously proposed as QoS control, in the system, and investigate the influence of cloud delay. Experimental results show that our method is effective, and the feedback force becomes larger as the delay increases.},
  doi       = {10.1145/3447654.3447669},
  isbn      = {9781450388566},
  keywords  = {QoS control, Experiment, Robot position control, Force feedback, Remote robot systems, Neural network},
  location  = {Tokyo, Japan},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3447654.3447669},
}

@InProceedings{Silva2015b,
  author    = {Silva, Francisco Airton and Maciel, Paulo and Filho, Gileno and Matos, Rubens},
  booktitle = {Proceedings of the 30th Annual ACM Symposium on Applied Computing},
  title     = {A Scheduler for Mobile Cloud Based on Weighted Metrics and Dynamic Context Evaluation},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {569–576},
  publisher = {Association for Computing Machinery},
  series    = {SAC '15},
  abstract  = {Resource scarcity is a major obstacle for many mobile applications, since devices have limited energy power and processing potential. As an example, there are applications that seamlessly augment human cognition and typically require resources that far outstrip mobile hardware's capabilities, such as language translation, speech recognition, and face recognition. The use of cloud computing may tackle this problem. This study presents SmartRank, a scheduling framework to perform load partitioning and offloading for mobile applications using cloud computing to increase performance in terms of response time. We first explore a benchmarking of face recognition application using mobile cloud and confirms its suitability to be used as case study with SmartRank. We have applied the approach to a face recognition process based on two strategies: cloudlet federation and resource ranking through balanced metrics (level of CPU utilization and round-trip time). Second, using a full factorial experimental design we tuned the SmartRank with the most suitable partitioning decision calibrating scheduling parameters. Nevertheless, SmartRank uses an equation that is extensible to include new parameters and make it applicable to other scenarios.},
  doi       = {10.1145/2695664.2695921},
  isbn      = {9781450331968},
  keywords  = {performance evaluation, mobile cloud computing, offloading, partitioning},
  location  = {Salamanca, Spain},
  numpages  = {8},
  url       = {https://doi.org/10.1145/2695664.2695921},
}

@InProceedings{Aladwani2017,
  author    = {Aladwani, Tahani},
  booktitle = {Proceedings of the 2nd International Conference on Big Data, Cloud and Applications},
  title     = {Impact of Selecting Virtual Machine with Least Load on Tasks Scheduling Algorithms in Cloud Computing},
  year      = {2017},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {BDCA'17},
  abstract  = {Tasks scheduling algorithms consider the first and basic factors in controlling the cloud computing performance. In this paper, we attempt to improve scheduling algorithm's performance by a focus on the load balance factor due to its impact on distributing tasks across multiple virtual machine (VMs) to get best resources utilization, reducing waiting and execution time and enhancing cloud computing performance. This attempt to improve scheduling algorithm's performance by proposing a new strategy called selecting VM with least load (SVLL) can be applied in conjunction with any task scheduling algorithm to improve algorithms performance and increase its load balance. SVLL based on calculating the total load in each VM without taking in consideration number of tasks assigned to it. In order to measure the performance achieved by this method, it will be applied on a set of simple scheduling algorithms, such as First Come First Service (FCFS), Shortest Job First (SJF), and Max-Min scheduling algorithms.},
  articleno = {13},
  doi       = {10.1145/3090354.3090367},
  isbn      = {9781450348522},
  keywords  = {Cloud Computing, load balance, Task scheduling algorithms},
  location  = {Tetouan, Morocco},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3090354.3090367},
}

@InProceedings{Xia2019,
  author    = {Xia, Qiufen and Bai, Luyao and Liang, Weifa and Xu, Zichuan and Yao, Lin and Wang, Lei},
  booktitle = {Workshop Proceedings of the 48th International Conference on Parallel Processing},
  title     = {QoS-Aware Proactive Data Replication for Big Data Analytics in Edge Clouds},
  year      = {2019},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ICPP Workshops '19},
  abstract  = {We are in the era of big data and cloud computing, large quantity of computing resource is desperately needed to detect invaluable information hidden in the coarse big data through query evaluation. Users demand big data analytic services with various Quality of Service (QoS) requirements. However, cloud computing is facing new challenges in meeting stringent QoS requirements of users due to the remoteness from its users. Edge computing has emerged as a new paradigm to address such shortcomings by bringing cloud services to the edge of the operation network in proximity of users for performance improvement. To satisfy the QoS requirements of users for big data analytics in edge computing, the data replication and placement problem must be properly dealt with such that user requests can be efficiently and promptly responded. In this paper, we consider data replication and placement for big data analytic query evaluation. We first cast a novel proactive data replication and placement problem of big data analytics in a two-tier edge cloud environment, we then devise an approximation algorithm with an approximation ratio for it, we finally evaluate the proposed algorithm against existing benchmarks, using both simulation and experiment in a testbed based on real datasets, the evaluation results show that the proposed algorithm is promising.},
  articleno = {26},
  doi       = {10.1145/3339186.3339207},
  isbn      = {9781450371964},
  keywords  = {Data replication and placement, query evaluation, big data analytics, edge clouds},
  location  = {Kyoto, Japan},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3339186.3339207},
}

@Article{Magrofuoco2019,
  author     = {Magrofuoco, Nathan and Vanderdonckt, Jean},
  journal    = {Proc. ACM Hum.-Comput. Interact.},
  title      = {Gelicit: A Cloud Platform for Distributed Gesture Elicitation Studies},
  year       = {2019},
  month      = {jun},
  number     = {EICS},
  volume     = {3},
  abstract   = {A gesture elicitation study, as originally defined, consists of gathering a sample of participants in a room, instructing them to produce gestures they would use for a particular set of tasks, materialized through a representation called referent, and asking them to fill in a series of tests, questionnaires, and feedback forms. Until now, this procedure is conducted manually in a single, physical, and synchronous setup. To relax the constraints imposed by this manual procedure and to support stakeholders in defining and conducting such studies in multiple contexts of use, this paper presents Gelicit, a cloud computing platform that supports gesture elicitation studies distributed in time and space structured into six stages: (1) define a study: a designer defines a set of tasks with their referents for eliciting gestures and specifies an experimental protocol by parameterizing its settings; (2) conduct a study: any participant receiving the invitation to join the study conducts the experiment anywhere, anytime, anyhow, by eliciting gestures and filling forms; (3) classify gestures: an experimenter classifies elicited gestures according to selected criteria and a vocabulary; (4) measure gestures: an experimenter computes gesture measures, like agreement, frequency, to understand their configuration; (5) discuss gestures: a designer discusses resulting gestures with the participants to reach a consensus; (6) export gestures: the consensus set of gestures resulting from the discussion is exported to be used with a gesture recognizer. The paper discusses Gelicit advantages and limitations with respect to three main contributions: as a conceptual model for gesture management, as a method for distributed gesture elicitation based on this model, and as a cloud computing platform supporting this distributed elicitation. We illustrate Gelicit through a study for eliciting 2D gestures executing Internet of Things tasks on a smartphone.},
  address    = {New York, NY, USA},
  articleno  = {6},
  doi        = {10.1145/3331148},
  issue_date = {June 2019},
  keywords   = {elicitation technique, workflow analysis, gesture elicitation study, gesture interaction},
  numpages   = {41},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3331148},
}

@InProceedings{Anand2016,
  author    = {Anand, Priya and Ryoo, Jungwoo and Kim, Hyoungshick and Kim, Eunhyun},
  booktitle = {Proceedings of the 10th International Conference on Ubiquitous Information Management and Communication},
  title     = {Threat Assessment in the Cloud Environment: A Quantitative Approach for Security Pattern Selection},
  year      = {2016},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {IMCOM '16},
  abstract  = {Cloud computing has emerged as a fast-growing technology in the past few years. It provides a great flexibility for storing, sharing and delivering data over the Internet without investing on new technology or resources. In spite of the development and wide array of cloud usage, security perspective of cloud computing still remains its infancy. Security challenges faced by cloud environment becomes more complicated when we include various stakeholders' perspectives. In a cloud environment, security perspectives and requirements are usually designed by software engineers or security experts. Sometimes clients' requirements are either ignored or given a very high importance. In order to implement cloud security by providing equal importance to client organizations, software engineers and security experts, we propose a new methodology in this paper. We use Microsoft's STRIDE-DREAD model to assess threats existing in the cloud environment and also to measure its consequences. Our aim is to rank the threats based on the nature of its severity, and also giving a significant importance for clients' requirements on security perspective. Our methodology would act as a guiding tool for security experts and software engineers to proceed with securing process especially for a private or a hybrid cloud. Once threats are ranked, we provide a link to a well-known security pattern classification. Although we have some security pattern classification schemes in the literature, we need a methodology to select a particular category of patterns. In this paper, we provide a novel methodology to select a set of security patterns for securing a cloud software. This methodology could aid a security expert or a software professional to assess the current vulnerability condition and prioritize by also including client's security requirements in a cloud environment.},
  articleno = {5},
  doi       = {10.1145/2857546.2857552},
  isbn      = {9781450341424},
  keywords  = {Cloud Computing, Risk Analysis, STRIDE-DREAD Model, Security Patterns, Threat Assessment},
  location  = {Danang, Viet Nam},
  numpages  = {8},
  url       = {https://doi.org/10.1145/2857546.2857552},
}

@Article{Herbst2018,
  author     = {Herbst, Nikolas and Bauer, Andr\'{e} and Kounev, Samuel and Oikonomou, Giorgos and Eyk, Erwin Van and Kousiouris, George and Evangelinou, Athanasia and Krebs, Rouven and Brecht, Tim and Abad, Cristina L. and Iosup, Alexandru},
  journal    = {ACM Trans. Model. Perform. Eval. Comput. Syst.},
  title      = {Quantifying Cloud Performance and Dependability: Taxonomy, Metric Design, and Emerging Challenges},
  year       = {2018},
  issn       = {2376-3639},
  month      = {aug},
  number     = {4},
  volume     = {3},
  abstract   = {In only a decade, cloud computing has emerged from a pursuit for a service-driven information and communication technology (ICT), becoming a significant fraction of the ICT market. Responding to the growth of the market, many alternative cloud services and their underlying systems are currently vying for the attention of cloud users and providers. To make informed choices between competing cloud service providers, permit the cost-benefit analysis of cloud-based systems, and enable system DevOps to evaluate and tune the performance of these complex ecosystems, appropriate performance metrics, benchmarks, tools, and methodologies are necessary. This requires re-examining old system properties and considering new system properties, possibly leading to the re-design of classic benchmarking metrics such as expressing performance as throughput and latency (response time). In this work, we address these requirements by focusing on four system properties: (i) elasticity of the cloud service, to accommodate large variations in the amount of service requested, (ii)&nbsp;performance isolation between the tenants of shared cloud systems and resulting performance variability, (iii)&nbsp;availability of cloud services and systems, and (iv) the operational risk of running a production system in a cloud environment. Focusing on key metrics for each of these properties, we review the state-of-the-art, then select or propose new metrics together with measurement approaches. We see the presented metrics as a foundation toward upcoming, future industry-standard cloud benchmarks.},
  address    = {New York, NY, USA},
  articleno  = {19},
  doi        = {10.1145/3236332},
  issue_date = {December 2018},
  keywords   = {Metrics, cloud, performance variability, performance isolation, elasticity, benchmarking, availability, operational risk},
  numpages   = {36},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3236332},
}

@InProceedings{Aman2016,
  author    = {Aman, Mortada A. and \c{C}etinkaya, Egemen K.},
  booktitle = {Proceedings of the 4th Workshop on Distributed Cloud Computing},
  title     = {DSB-SEIS: A Deduplicating Secure Backup System with Encryption Intensity Selection},
  year      = {2016},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {DCC '16},
  abstract  = {Cloud computing is an emerging service that enables users to store and manage their data easily at a low cost. We propose a Deduplicating Secure Backup System with Encryption Intensity Selection (DSB-SEIS) that combines features to amend security and performance of cloud-based backup services. Our scheme introduces the concept of encryption intensity selection to cloud backup systems, which allows users to select the encryption intensity of their files. We also combine features such as deduplication, assured deletion, and multi-aspect awareness to further enhance our scheme. The DSB-SEIS performance is measured over an OpenStack cloud installed on CloudLab resources demonstrating that DSB-SEIS can improve the backup service.},
  articleno = {11},
  doi       = {10.1145/2955193.2955208},
  isbn      = {9781450342209},
  keywords  = {security, cloud, deduplication, CloudLab, backup, integrity},
  location  = {Chicago, Illinois},
  numpages  = {1},
  url       = {https://doi.org/10.1145/2955193.2955208},
}

@Article{Nemati2021,
  author     = {Nemati, Hani and Azhari, Seyed Vahid and Shakeri, Mahsa and Dagenais, Michel},
  journal    = {ACM Trans. Model. Perform. Eval. Comput. Syst.},
  title      = {Host-Based Virtual Machine Workload Characterization Using Hypervisor Trace Mining},
  year       = {2021},
  issn       = {2376-3639},
  month      = {jun},
  number     = {1},
  volume     = {6},
  abstract   = {Cloud computing is a fast-growing technology that provides on-demand access to a pool of shared resources. This type of distributed and complex environment requires advanced resource management solutions that could model virtual machine (VM) behavior. Different workload measurements, such as CPU, memory, disk, and network usage, are usually derived from each VM to model resource utilization and group similar VMs. However, these course workload metrics require internal access to each VM with the available performance analysis toolkit, which is not feasible with many cloud environments privacy policies.In this article, we propose a non-intrusive host-based virtual machine workload characterization using hypervisor tracing. VM blockings duration, along with virtual interrupt injection rates, are derived as features to reveal multiple levels of resource intensiveness. In addition, the VM exit reason is considered, as well as the resource contention rate due to the host and other VMs. Moreover, the processes and threads preemption rates in each VM are extracted using the collected tracing logs. Our proposed approach further improves the selected features by exploiting a page ranking based algorithm to filter non-important processes running on each VM. Once the metric features are defined, a two-stage VM clustering technique is employed to perform both coarse- and fine-grain workload characterization. The inter-cluster and intra-cluster similarity metrics of the silhouette score is used to reveal distinct VM workload groups, as well as the ones with significant overlap. The proposed framework can provide a detailed vision of the underlying behavior of the running VMs. This can assist infrastructure administrators in efficient resource management, as well as root cause analysis.},
  address    = {New York, NY, USA},
  articleno  = {4},
  doi        = {10.1145/3460197},
  issue_date = {March 2021},
  keywords   = {machine learning, time series, workload characterization, PageRank, vCPU states, K-Means, performance analysis, VM clustering, tracing, virtual interrupts},
  numpages   = {25},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3460197},
}

@InProceedings{Evangelidis2017,
  author    = {Evangelidis, Alexandros and Parker, David and Bahsoon, Rami},
  booktitle = {Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
  title     = {Performance Modelling and Verification of Cloud-Based Auto-Scaling Policies},
  year      = {2017},
  address   = {Madrid, Spain},
  pages     = {355–364},
  publisher = {IEEE Press},
  series    = {CCGrid '17},
  abstract  = {Auto-scaling, a key property of cloud computing, allows application owners to acquire and release resources on demand. However, the shared environment, along with the exponentially large configuration space of available parameters, makes configuration of auto-scaling policies a challenging task. In particular, it is difficult to quantify, a priori, the impact of a policy on Quality of Service (QoS) provision. To address this problem, we propose a novel approach based on performance modelling and formal verification to produce performance guarantees on particular rule-based auto-scaling policies. We demonstrate the usefulness and efficiency of our model through a detailed validation process on the Amazon EC2 cloud, using two types of load patterns. Our experimental results show that it can be very effective in helping a cloud application owner configure an auto-scaling policy in order to minimise the QoS violations.},
  doi       = {10.1109/CCGRID.2017.39},
  isbn      = {9781509066100},
  numpages  = {10},
  url       = {https://doi.org/10.1109/CCGRID.2017.39},
}

@InProceedings{Mukerjee2016,
  author    = {Mukerjee, Matthew K. and Bozkurt, Ilker Nadi and Maggs, Bruce and Seshan, Srinivasan and Zhang, Hui},
  booktitle = {Proceedings of the 15th ACM Workshop on Hot Topics in Networks},
  title     = {The Impact of Brokers on the Future of Content Delivery},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {127–133},
  publisher = {Association for Computing Machinery},
  series    = {HotNets '16},
  abstract  = {Various trends are reshaping content delivery on the Internet: the explosive growth of traffic due to video, users' increasing expectations for higher quality of experience (QoE), and the proliferation of server capacity from a variety of sources (e.g., cloud computing, content provider-owned datacenters, and ISP-owned CDNs). In order to meet the scale and quality demands imposed by users, content providers have started to spread demand across a variety of CDNs using a broker. Brokers break many traditional CDN assumptions (e.g., unexpected traffic skew, significant variance in demand over short timescales, etc.). Through an analysis of data from a leading broker and a leading CDN, we show the potential challenges and opportunities that brokers impart on content delivery. We take the first steps towards improvement through a redesigned broker-CDN interface.},
  doi       = {10.1145/3005745.3005749},
  isbn      = {9781450346610},
  location  = {Atlanta, GA, USA},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3005745.3005749},
}

@InProceedings{Ahn2021,
  author    = {Ahn, Michael and Chu, Shengli},
  booktitle = {DG.O2021: The 22nd Annual International Conference on Digital Government Research},
  title     = {What Matters in Maintaining Effective Open Government Data Systems? The Role of Government Managerial Capacity, and Political and Legal Environment},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {444–457},
  publisher = {Association for Computing Machinery},
  series    = {DG.O'21},
  abstract  = {This paper aims to identify key institutional factors that contribute to effective open data systems. Rapid advancement in new technologies such as machine learning, algorithms, IoT, and Cloud Computing has amplified the importance of national open data systems. The availability of relevant public data has become a crucial factor in creating sophisticated machine learning platforms or algorithms that will have a considerable impact on national competitiveness. Effective national open data strategies will matter in shaping an environment that will facilitate data production, dissemination, and utilization. Using multiple sources of data that measure the qualities of open data systems and various political, governmental, and legal attributes at the national level, we seek to identify key institutional factors that contribute to robust open data policies and outcomes. Our findings point to the importance of the existence of a national open data strategy and support (especially "open by default" strategy), pre-existing e-government capability, and countries operating under full democracy with its guarantees to civil liberties and political freedom. In addition, the nature of the open data matters as different managerial, political, and demographic conditions affected the quality of different open data systems. Policy implications of our findings are discussed.},
  doi       = {10.1145/3463677.3463732},
  isbn      = {9781450384926},
  location  = {Omaha, NE, USA},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3463677.3463732},
}

@InProceedings{Naskos2015,
  author    = {Naskos, Athanasios and Stachtiari, Emmanouela and Gounaris, Anastasios and Katsaros, Panagiotis and Tsoumakos, Dimitrios and Konstantinou, Ioannis and Sioutas, Spyros},
  booktitle = {Proceedings of the 15th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
  title     = {Dependable Horizontal Scaling Based on Probabilistic Model Checking},
  year      = {2015},
  address   = {Shenzhen, China},
  pages     = {31–40},
  publisher = {IEEE Press},
  series    = {CCGRID '15},
  abstract  = {The focus of this work is the on-demand resource provisioning in cloud computing, which is commonly referred to as cloud elasticity. Although a lot of effort has been invested in developing systems and mechanisms that enable elasticity, the elasticity decision policies tend to be designed without quantifying or guaranteeing the quality of their operation. We present an approach towards the development of more formalized and dependable elasticity policies. We make two distinct contributions. First, we propose an extensible approach to enforcing elasticity through the dynamic instantiation and online quantitative verification of Markov Decision Processes (MDP) using probabilistic model checking. Second, various concrete elasticity models and elasticity policies are studied. We evaluate the decision policies using traces from a real NoSQL database cluster under constantly evolving external load. We reason about the behaviour of different modeling and elasticity policy options and we show that our proposal can improve upon the state-of-the-art in significantly decreasing under-provisioning while avoiding over-provisioning.},
  doi       = {10.1109/CCGrid.2015.91},
  isbn      = {9781479980062},
  numpages  = {10},
  url       = {https://doi.org/10.1109/CCGrid.2015.91},
}

@InProceedings{Shrimali2015,
  author    = {Shrimali, Bela and Patel, Hiren},
  booktitle = {Proceedings of the Third International Symposium on Women in Computing and Informatics},
  title     = {Performance Based Energy Efficient Techniques For VM Allocation In Cloud Environment},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {477–486},
  publisher = {Association for Computing Machinery},
  series    = {WCI '15},
  abstract  = {Cloud computing is emerging as a new paradigm for providing different services like platform, infrastructure and software as a large scale distributed computing applications via Internet. Computing resources are available in Cloud through virtualization. It divides a physical machine into many half or full isolated machines (known as Virtual Machines-VMs) using various allocation techniques. To identify a technique that can satisfy a quality of service in consideration of energy consumption in Cloud environment is one of the challenging issues for Virtual Machine allocation in Cloud as there are tradeoffs between energy consumption and performance. In the present research, we aim to survey various techniques that combine energy efficiency and performance. Hence, different real world virtual machine allocation policies are explored and the performance based energy efficient techniques for VM allocation are discussed. This survey may assist the researchers who wish to step in to the domain of performance based energy efficient VM techniques.},
  doi       = {10.1145/2791405.2791446},
  isbn      = {9781450333610},
  keywords  = {Virtual machine, Cloud computing, Energy efficient, Performance},
  location  = {Kochi, India},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2791405.2791446},
}

@InProceedings{Fujimoto2017,
  author    = {Fujimoto, Richard M. and Hunter, Michael and Biswas, Aradhya and Jackson, Mark and Neal, SaBra},
  booktitle = {Proceedings of the 2017 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
  title     = {Power Efficient Distributed Simulation},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {77–88},
  publisher = {Association for Computing Machinery},
  series    = {SIGSIM-PADS '17},
  abstract  = {Energy and power consumption have become important concerns for many computing systems ranging from embedded and mobile systems operating on battery-powered devices to high performance and cloud computing applications running on supercomputers and in data centers. To date, only a limited amount of work has considered power consumption in parallel and distributed simulations. A variety of options to analyze and explore power consumption in distributed simulations are discussed. These options range from design decisions in developing the simulation model to selection of algorithms in distributed simulation middleware to exploitation of hardware techniques. Work to characterize the power and energy consumed by different elements of parallel and distributed simulation systems are discussed and empirical measurements presented to quantify energy and power use, suggestive of directions for future research in this area.},
  doi       = {10.1145/3064911.3069397},
  isbn      = {9781450344890},
  keywords  = {power aware computing, distributed simulation, parallel discrete event simulation},
  location  = {Singapore, Republic of Singapore},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3064911.3069397},
}

@InProceedings{Zheng2018,
  author    = {Zheng, Wanwan and Jin, Mingzhe},
  booktitle = {Proceedings of the 2018 Artificial Intelligence and Cloud Computing Conference},
  title     = {Do We Need More Training Samples For Text Classification?},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {121–128},
  publisher = {Association for Computing Machinery},
  series    = {AICCC '18},
  abstract  = {In recent years, with the rise of exceptional cloud computing technologies, machine learning approach in solving complex problems has been greatly accelerated. In the field of text classification, machine learning is a technology of providing computers the ability to learn and predict tasks without being explicitly labeled, and it is said that enough data are needed in order to let a machine to learn. However, more data tend to cause overfitting in machine learning algorithms, and there is no object criteria in deciding how many samples are required to achieve a desired level of performance. This article addresses this problem by using feature selection method. In our experiments, feature selection is proved to be able to decrease 66.67\% at the largest of the required size of training dataset. Meanwhile, the kappa coefficient as a performance measure of classifiers could increase 11 points at the maximum. Furthermore, feature selection as a technology to remove irrelevant features was found be able to prevent overfitting to a great extent.},
  doi       = {10.1145/3299819.3299836},
  isbn      = {9781450366236},
  keywords  = {Size of Dataset, Text Classification, Feature Selection},
  location  = {Tokyo, Japan},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3299819.3299836},
}

@InProceedings{Zhu2017,
  author    = {Zhu, Yifei and Liu, Jiangchuan and Wang, Zhi and Zhang, Cong},
  booktitle = {Proceedings of the 25th ACM International Conference on Multimedia},
  title     = {When Cloud Meets Uncertain Crowd: An Auction Approach for Crowdsourced Livecast Transcoding},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {1372–1380},
  publisher = {Association for Computing Machinery},
  series    = {MM '17},
  abstract  = {In the emerging crowd sourced live cast services, numerous amateur broadcasters live stream their video contents to worldwide viewers and constantly interact with them through chat messages. Live video contents are transcoded into multiple quality versions to better service viewers with different network and device configurations. Cloud computing becomes a natural choice to handle these computational intensive tasks due to its elasticity and the "pay-as-you-go" billing model. However, given the significantly large number of concurrent channel numbers and the diverse viewer geo-distributions in this new crowd sourced live cast service, even the cloud becomes significantly expensive to cover the whole community and inadequate in fulfilling the latency requirement. In this paper, after observing the abundant computational resources residing in end viewers, we propose a Cloud-Crowd collaborative system, C2, which combines end viewers with cloud to perform video transcoding in a cost-efficient way. To quantify the heterogeneity and uncertainty of viewers and pass the asymmetric information barrier, we incorporate statistical descriptions into our bidding language and design truthful auctions to recruit stable viewers with appropriate incentives. We further tailor redundancy strategies for workloads with different Quality of Service requirements to improve the stability of our system. Desirable economic properties, like social efficiency, ex-post incentive compatibility, individual rationality, are proved to be guaranteed in our studied scenarios. Using traces captured from the popular Twitch platform, we show that C2 achieves up to 93\% more cost saving than a pure cloud-based solution, and significantly outperforms other baseline approaches in both social welfare and system stability.},
  doi       = {10.1145/3123266.3123384},
  isbn      = {9781450349062},
  keywords  = {cloud computing, auction mechanism, uncertainty, edge computing, crowdsourced livecast transcoding},
  location  = {Mountain View, California, USA},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3123266.3123384},
}

@InProceedings{Khidzir2017,
  author    = {Khidzir, Nik Zulkarnaen and Ghani, Wan Safra Diyana Wan Abdul and Guan, Tan Tse},
  booktitle = {Proceedings of the International Conference on High Performance Compilation, Computing and Communications},
  title     = {Cloud-Based Mobile-Retail Application for Textile Cyberpreneurs: Task-Technology Fit Perspective Analysis},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {65–70},
  publisher = {Association for Computing Machinery},
  series    = {HP3C-2017},
  abstract  = {Cloud computing and mobile computing paradigms have enhanced the usage of current technology among people from various sectors to perform certain required tasks. The combination of these two paradigms have also created the existence of cloud-based mobile applications that are designed to be useful in business environments, such as to be used by textile cyberpreneurs for m-retail transaction. As cloud adoption was previously low among Malaysian entrepreneurs, the usage intention factors of related cloud technology and services should be determined for better clarification and future technology enhancements. Besides, studies on m-retail or m-shopping adoption in Malaysia were merely focused on customer's perspectives rather than retailer's perspectives. In measuring the suitability of Cloud-based M-Retail (CBMR) application with the task requirements of textile cyberpreneurs, Task-Technology Fit (TTF) model is used as the basis of this research. Results from a pilot study, through a survey of selected group of textile cyberpreneurs shows instrument's reliability and positive feedbacks to support the intention to use the technology. The future direction of the study in which to apply the instruments to a larger group of respondents is also discussed along with its potential contribution.},
  doi       = {10.1145/3069593.3069609},
  isbn      = {9781450348683},
  keywords  = {mobile retail, cloud-based mobile application, cyberpreneurship, mobile shopping, behavioral intention, task-technology fit},
  location  = {Kuala Lumpur, Malaysia},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3069593.3069609},
}

@InProceedings{Castillo2018,
  author    = {Castillo, Alexy Gene and Telan, Sherwin M. and Palaoag, Thelma},
  booktitle = {Proceedings of the 2nd International Conference on Cryptography, Security and Privacy},
  title     = {Cloud-Based Data Mining Framework: A Model to Improve Maternal Healthcare},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {21–28},
  publisher = {Association for Computing Machinery},
  series    = {ICCSP 2018},
  abstract  = {The foundation of quality health care depends upon the presence of competent health personnel working in a situation where prescriptions and health supplies are accessible when required and in sufficient quantity and of guaranteed quality. This paper conduces to propound a decision support framework model for the Department of Health (DOH) which able to innovate the acquisition and allocation management of medicines and health supplies with the aim of improving the maternal healthcare in the Philippines.In-depth interviews were conducted to DOH officials and facility managers of Rural Health Units (RHU) and in the 3rd district of Albay, Bicol Philippines. Data triangulation and literature review are employed to design the framework. Finally to assess its applicability, a simulative-evaluation is conveyed.Respondents reported on the unreliability of obtaining healthcare supplies for RHU's, which results untimely and suboptimal rendering of healthcare services. Also, insufficient provision of medicines from the government and lack of accountability within the supply system due of inadequate and incoherent terminal reports were revealed to contribute to the current situation.To address the mentioned challenges, this study recommends the consideration of the proposed framework model employing cloud computing and data mining to remarkably improve the administration on the provision of medicines and health supplies, guaranteeing its auspicious accessibility for the benefit of Filipino pregnant women ensuring their health as carriers of the lives to be born as the future of the nation.},
  doi       = {10.1145/3199478.3199483},
  isbn      = {9781450363617},
  keywords  = {Maternal Health, Cloud Computing, Data Mining},
  location  = {Guiyang, China},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3199478.3199483},
}

@InProceedings{Liu2016,
  author    = {Liu, Longjun and Sun, Hongbin and Li, Chao and Hu, Yang and Zheng, Nanning and Li, Tao},
  booktitle = {Proceedings of the 2016 International Conference on Supercomputing},
  title     = {Towards an Adaptive Multi-Power-Source Datacenter},
  year      = {2016},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ICS '16},
  abstract  = {Big data and cloud computing are accelerating the capacity growth of datacenters all over the world. Their energy costs and environmental issues have pushed datacenter operators to explore and integrate alternative energy sources, such as various renewable energy supplies and energy storage devices. Designing datacenters powered by multi-power supplies in the smart grid environment is becoming a promising trend in the next few decades. However, gracefully provisioning various power sources and efficiently manage them in datacenter is a significant challenge.In this paper, we explore an unconventional fine-grained power distribution architecture for multi-source powered datacenters. We thoroughly investigate how to deliver and manage multiple power sources from the power generation plant outside of the datacenter to datacenter inside. We then propose a novel Power Switch Network (PSN) for datacenters. PSN is a reconfigurable multi-power-source distribution architecture which enables datacenter to distribute various power sources with a fine-grained manner. Moreover, a tailored machine learning based power sources management framework is proposed for PSN to dynamically select different power sources and optimize user-demanded performance metrics. Compared with the conventional single-switch system, evaluation results show that PSN could improve solar energy utilization by 39.6\%, reduce utility power cost by 11.1\% and improve workload performance by 33.8\%, meanwhile enhancing battery lifetime by 9.3\%. We expect that our work could provide valuable guidelines for the emerging multi-power-source datacenter to improve their efficiency, sustainability and economy.},
  articleno = {11},
  doi       = {10.1145/2925426.2926276},
  isbn      = {9781450343619},
  keywords  = {Power Distribution Architecture, Multi-Power-Source Management, Renewable Energy, Datacenters},
  location  = {Istanbul, Turkey},
  numpages  = {11},
  url       = {https://doi.org/10.1145/2925426.2926276},
}

@InProceedings{Cohen2017,
  author    = {Cohen, Maxime C. and Keller, Philipp and Mirrokni, Vahab and Zadimoghadddam, Morteza},
  booktitle = {Proceedings of the 2017 ACM SIGMETRICS / International Conference on Measurement and Modeling of Computer Systems},
  title     = {Overcommitment in Cloud Services Bin Packing with Chance Constraints},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {7},
  publisher = {Association for Computing Machinery},
  series    = {SIGMETRICS '17 Abstracts},
  abstract  = {This paper considers a traditional problem of resource allocation, scheduling jobs on machines. One such recent application is cloud computing, where jobs arrive in an online fashion with capacity requirements and need to be immediately scheduled on physical machines in data centers. It is often observed that the requested capacities are not fully utilized, hence offering an opportunity to employ an overcommitment policy, i.e., selling resources beyond capacity. Setting the right overcommitment level can induce a significant cost reduction for the cloud provider, while only inducing a very low risk of violating capacity constraints. We introduce and study a model that quantifies the value of overcommitment by modeling the problem as a bin packing with chance constraints. We then propose an alternative formulation that transforms each chance constraint into a submodular function. We show that our model captures the risk pooling effect and can guide scheduling and overcommitment decisions. We also develop a family of online algorithms that are intuitive, easy to implement and provide a constant factor guarantee from optimal. Finally, we calibrate our model using realistic workload data, and test our approach in a practical setting. Our analysis and experiments illustrate the benefit of overcommitment in cloud services, and suggest a cost reduction of 1.5\% to 17\% depending on the provider's risk tolerance.},
  doi       = {10.1145/3078505.3078530},
  isbn      = {9781450350327},
  keywords  = {bin packing, job scheduling, chance constraints},
  location  = {Urbana-Champaign, Illinois, USA},
  numpages  = {1},
  url       = {https://doi.org/10.1145/3078505.3078530},
}

@Article{Cohen2017a,
  author     = {Cohen, Maxime C. and Keller, Philipp and Mirrokni, Vahab and Zadimoghadddam, Morteza},
  journal    = {SIGMETRICS Perform. Eval. Rev.},
  title      = {Overcommitment in Cloud Services Bin Packing with Chance Constraints},
  year       = {2017},
  issn       = {0163-5999},
  month      = {jun},
  number     = {1},
  pages      = {7},
  volume     = {45},
  abstract   = {This paper considers a traditional problem of resource allocation, scheduling jobs on machines. One such recent application is cloud computing, where jobs arrive in an online fashion with capacity requirements and need to be immediately scheduled on physical machines in data centers. It is often observed that the requested capacities are not fully utilized, hence offering an opportunity to employ an overcommitment policy, i.e., selling resources beyond capacity. Setting the right overcommitment level can induce a significant cost reduction for the cloud provider, while only inducing a very low risk of violating capacity constraints. We introduce and study a model that quantifies the value of overcommitment by modeling the problem as a bin packing with chance constraints. We then propose an alternative formulation that transforms each chance constraint into a submodular function. We show that our model captures the risk pooling effect and can guide scheduling and overcommitment decisions. We also develop a family of online algorithms that are intuitive, easy to implement and provide a constant factor guarantee from optimal. Finally, we calibrate our model using realistic workload data, and test our approach in a practical setting. Our analysis and experiments illustrate the benefit of overcommitment in cloud services, and suggest a cost reduction of 1.5\% to 17\% depending on the provider's risk tolerance.},
  address    = {New York, NY, USA},
  doi        = {10.1145/3143314.3078530},
  issue_date = {June 2017},
  keywords   = {bin packing, job scheduling, chance constraints},
  numpages   = {1},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3143314.3078530},
}

@InProceedings{Wang2015b,
  author    = {Wang, Hui and Isci, Canturk and Subramanian, Lavanya and Choi, Jongmoo and Qian, Depei and Mutlu, Onur},
  booktitle = {Proceedings of the 11th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments},
  title     = {A-DRM: Architecture-Aware Distributed Resource Management of Virtualized Clusters},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {93–106},
  publisher = {Association for Computing Machinery},
  series    = {VEE '15},
  abstract  = {Virtualization technologies has been widely adopted by large-scale cloud computing platforms. These virtualized systems employ distributed resource management (DRM) to achieve high resource utilization and energy savings by dynamically migrating and consolidating virtual machines. DRM schemes usually use operating-system-level metrics, such as CPU utilization, memory capacity demand and I/O utilization, to detect and balance resource contention. However, they are oblivious to microarchitecture-level resource interference (e.g., memory bandwidth contention between different VMs running on a host), which is currently not exposed to the operating system.We observe that the lack of visibility into microarchitecture-level resource interference significantly impacts the performance of virtualized systems. Motivated by this observation, we propose a novel architecture-aware DRM scheme (ADRM), that takes into account microarchitecture-level resource interference when making migration decisions in a virtualized cluster. ADRM makes use of three core techniques: 1) a profiler to monitor the microarchitecture-level resource usage behavior online for each physical host, 2) a memory bandwidth interference model to assess the interference degree among virtual machines on a host, and 3) a cost-benefit analysis to determine a candidate virtual machine and a host for migration.Real system experiments on thirty randomly selected combinations of applications from the CPU2006, PARSEC, STREAM, NAS Parallel Benchmark suites in a four-host virtualized cluster show that ADRM can improve performance by up to 26.55\%, with an average of 9.67\%, compared to traditional DRM schemes that lack visibility into microarchitecture-level resource utilization and contention.},
  doi       = {10.1145/2731186.2731202},
  isbn      = {9781450334501},
  keywords  = {virtualization, microarchitecture, resource management, live migration, performance counters},
  location  = {Istanbul, Turkey},
  numpages  = {14},
  url       = {https://doi.org/10.1145/2731186.2731202},
}

@Article{Wang2015c,
  author     = {Wang, Hui and Isci, Canturk and Subramanian, Lavanya and Choi, Jongmoo and Qian, Depei and Mutlu, Onur},
  journal    = {SIGPLAN Not.},
  title      = {A-DRM: Architecture-Aware Distributed Resource Management of Virtualized Clusters},
  year       = {2015},
  issn       = {0362-1340},
  month      = {mar},
  number     = {7},
  pages      = {93–106},
  volume     = {50},
  abstract   = {Virtualization technologies has been widely adopted by large-scale cloud computing platforms. These virtualized systems employ distributed resource management (DRM) to achieve high resource utilization and energy savings by dynamically migrating and consolidating virtual machines. DRM schemes usually use operating-system-level metrics, such as CPU utilization, memory capacity demand and I/O utilization, to detect and balance resource contention. However, they are oblivious to microarchitecture-level resource interference (e.g., memory bandwidth contention between different VMs running on a host), which is currently not exposed to the operating system.We observe that the lack of visibility into microarchitecture-level resource interference significantly impacts the performance of virtualized systems. Motivated by this observation, we propose a novel architecture-aware DRM scheme (ADRM), that takes into account microarchitecture-level resource interference when making migration decisions in a virtualized cluster. ADRM makes use of three core techniques: 1) a profiler to monitor the microarchitecture-level resource usage behavior online for each physical host, 2) a memory bandwidth interference model to assess the interference degree among virtual machines on a host, and 3) a cost-benefit analysis to determine a candidate virtual machine and a host for migration.Real system experiments on thirty randomly selected combinations of applications from the CPU2006, PARSEC, STREAM, NAS Parallel Benchmark suites in a four-host virtualized cluster show that ADRM can improve performance by up to 26.55\%, with an average of 9.67\%, compared to traditional DRM schemes that lack visibility into microarchitecture-level resource utilization and contention.},
  address    = {New York, NY, USA},
  doi        = {10.1145/2817817.2731202},
  issue_date = {July 2015},
  keywords   = {performance counters, microarchitecture, live migration, virtualization, resource management},
  numpages   = {14},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2817817.2731202},
}

@InProceedings{Meloni2018,
  author    = {Meloni, P. and Loi, D. and Deriu, G. and Pimentel, A. D. and Sapra, D. and Moser, B. and Shepeleva, N. and Conti, F. and Benini, L. and Ripolles, O. and Solans, D. and Pintor, M. and Biggio, B. and Stefanov, T. and Minakova, S. and Fragoulis, N. and Theodorakopoulos, I. and Masin, M. and Palumbo, F.},
  booktitle = {Proceedings of the Workshop on INTelligent Embedded Systems Architectures and Applications},
  title     = {ALOHA: An Architectural-Aware Framework for Deep Learning at the Edge},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {19–26},
  publisher = {Association for Computing Machinery},
  series    = {INTESA '18},
  abstract  = {Novel Deep Learning (DL) algorithms show ever-increasing accuracy and precision in multiple application domains. However, some steps further are needed towards the ubiquitous adoption of this kind of instrument. First, effort and skills required to develop new DL models, or to adapt existing ones to new use-cases, are hardly available for small- and medium-sized businesses. Second, DL inference must be brought at the edge, to overcome limitations posed by the classically-used cloud computing paradigm. This requires implementation on low-energy computing nodes, often heterogenous and parallel, that are usually more complex to program and to manage. This work describes the ALOHA framework, that proposes a solution to these issue by means of an integrated tool flow that automates most phases of the development process. The framework introduces architecture-awareness, considering the target inference platform very early, already during algorithm selection, and driving the optimal porting of the resulting embedded application. Moreover it considers security, power efficiency and adaptiveness as main objectives during the whole development process.},
  doi       = {10.1145/3285017.3285019},
  isbn      = {9781450365987},
  keywords  = {convolutional neural networks, deep learning, computer aided design},
  location  = {Turin, Italy},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3285017.3285019},
}

@Article{Chen2014,
  author     = {Chen, Jinzhu and Tan, Rui and Wang, Yu and Xing, Guoliang and Wang, Xiaorui and Wang, Xiaodong and Punch, Bill and Colbry, Dirk},
  journal    = {ACM Trans. Sen. Netw.},
  title      = {A Sensor System for High-Fidelity Temperature Distribution Forecasting in Data Centers},
  year       = {2014},
  issn       = {1550-4859},
  month      = {dec},
  number     = {2},
  volume     = {11},
  abstract   = {Data centers have become a critical computing infrastructure in the era of cloud computing. Temperature monitoring and forecasting are essential for preventing server shutdowns because of overheating and improving a data center’s energy efficiency. This article presents a novel cyber-physical approach for temperature forecasting in data centers, one that integrates Computational Fluid Dynamics (CFD) modeling, in situ wireless sensing, and real-time data-driven prediction. To ensure forecasting fidelity, we leverage the realistic physical thermodynamic models of CFD to generate transient temperature distribution and calibrate it using sensor feedback. Both simulated temperature distribution and sensor measurements are then used to train a real-time prediction algorithm. As a result, our approach reduces not only the computational complexity of online temperature modeling and prediction, but also the number of deployed sensors, which enables a portable, noninvasive thermal monitoring solution that does not rely on the infrastructure of a monitored data center. We extensively evaluated the proposed system on a rack of 15 servers and a testbed of five racks and 229 servers in a small-scale production data center. Our results show that our system can predict the temperature evolution of servers with highly dynamic workloads at an average error of 0.52○C, within a duration up to 10 minutes. Moreover, our approach can reduce the required number of sensors by 67\% while maintaining desirable prediction fidelity.},
  address    = {New York, NY, USA},
  articleno  = {30},
  doi        = {10.1145/2675353},
  issue_date = {February 2015},
  keywords   = {computational fluid dynamics, cyber-physical system, temperature prediction, Data center, wireless sensor network},
  numpages   = {25},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2675353},
}

@InProceedings{Georgakopoulos2018,
  author    = {Georgakopoulos, Spiros V. and Tasoulis, Sotiris K. and Vrahatis, Aristidis G. and Plagianakos, Vassilis P.},
  booktitle = {Proceedings of the 10th Hellenic Conference on Artificial Intelligence},
  title     = {Convolutional Neural Networks for Toxic Comment Classification},
  year      = {2018},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {SETN '18},
  abstract  = {Flood of information is produced in a daily basis through the global internet usage arising from the online interactive communications among users. While this situation contributes significantly to the quality of human life, unfortunately it involves enormous dangers, since online texts with high toxicity can cause personal attacks, online harassment and bullying behaviors. This has triggered both industrial and research community in the last few years while there are several attempts to identify an efficient model for online toxic comment prediction. However, these steps are still in their infancy and new approaches and frameworks are required. On parallel, the data explosion that appears constantly, makes the construction of new machine learning computational tools for managing this information, an imperative need. Thankfully advances in hardware, cloud computing and big data management allow the development of Deep Learning approaches appearing very promising performance so far. For text classification in particular the use of Convolutional Neural Networks (CNN) have recently been proposed approaching text analytics in a modern manner emphasizing in the structure of words in a document. In this work, we employ this approach to discover toxic comments in a large pool of documents provided by a current Kaggle's competition regarding Wikipedia's talk page edits. To justify this decision we choose to compare CNNs against the traditional bag-of-words approach for text analysis combined with a selection of algorithms proven to be very effective in text classification. The reported results provide enough evidence that CNN enhance toxic comment classification reinforcing research interest towards this direction.},
  articleno = {35},
  doi       = {10.1145/3200947.3208069},
  isbn      = {9781450364331},
  keywords  = {CNN for Text Mining, Word Embeddings, word2vec, Text Classification, Text mining, Toxic Text Classification, Convolutional Neural Networks},
  location  = {Patras, Greece},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3200947.3208069},
}

@InProceedings{Tange2019,
  author    = {Tange, Koen and De Donno, Michele and Fafoutis, Xenofon and Dragoni, Nicola},
  booktitle = {Proceedings of the Workshop on Fog Computing and the IoT},
  title     = {Towards a Systematic Survey of Industrial IoT Security Requirements: Research Method and Quantitative Analysis},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {56–63},
  publisher = {Association for Computing Machinery},
  series    = {IoT-Fog '19},
  abstract  = {Industry 4.0 and, in particular, Industrial Internet of Things (IIoT) represent two of the major automation and data exchange trends of the 21st century, driving a steady increase in the number of smart embedded devices used by industrial applications. However, IoT devices suffer from numerous security flaws, resulting in a number of large scale cyber-attacks. In this light, Fog computing, a relatively new paradigm born from the necessity of bridging the gap between Cloud computing and IoT, can be used as a security solution for the IIoT. To achieve this, the first step is to clearly identify the security requirements of the IIoT that can be subsequently used to design security solutions based on Fog computing. With this in mind, our paper represents a preliminary work towards a systematic literature review of IIoT security requirements. We focus on two key steps of the review: (1) the research method that will be used in the systematic work and (2) a quantitative analysis of the results produced by the study selection process. This lays the necessary foundations to enable the use of Fog computing as a security solution for the IIoT.},
  doi       = {10.1145/3313150.3313228},
  isbn      = {9781450366984},
  keywords  = {industry 4.0, fog computing, security, systematic literature review, industrial internet of things, IIoT},
  location  = {Montreal, Quebec, Canada},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3313150.3313228},
}

@InProceedings{Norta2015,
  author    = {Norta, Alex and Othman, Anis Ben and Taveter, Kuldar},
  booktitle = {Proceedings of the 2015 2nd International Conference on Electronic Governance and Open Society: Challenges in Eurasia},
  title     = {Conflict-Resolution Lifecycles for Governed Decentralized Autonomous Organization Collaboration},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {244–257},
  publisher = {Association for Computing Machinery},
  series    = {EGOSE '15},
  abstract  = {Recent blockchain-technology related innovations enable the governance of collaborating decentralized autonomous organizations (DAO) to engage in agile business-network collaborations that are based on the novel concept of smart contracting. DAOs utilize service-oriented cloud computing in a loosely coupled collaboration lifecycle with the main steps of setup, enactment, possible rollbacks and finally, an orderly termination. This lifecycle supports the selection of services provided and used by DAOs, smart contract negotiations, and behavior monitoring during enactment with the potential for breach management. Based on a sound understanding of the collaboration lifecycle in a Governance- as-a-Service (GaaS)-platform, a new type of conflict management must safeguard business-semantics induced consistency rules. This conflict management involves breach detection with recovery aspects. To fill the detected gap, we employ a formal design-notation that comprises the definition of structural and behavioral properties for exploring conflict-related exception- and compensation management during a decentralized collaboration. With the formal approach, we generate a highly dependable DAO-GaaS conflict model that does not collapse under left-behind clutter such as orphaned processes and exponentially growing database entries that require an unacceptable periodic GaaS reset.},
  doi       = {10.1145/2846012.2846052},
  isbn      = {9781450340700},
  keywords  = {smart contract, business process, conflict resolution, service orientation, e-governance, Industry 4.0, open cloud ecosystem, Decentralized autonomous organization},
  location  = {St. Petersburg, Russian Federation},
  numpages  = {14},
  url       = {https://doi.org/10.1145/2846012.2846052},
}

@InProceedings{Siever2017,
  author    = {Siever, Bill and Rogers, Michael P.},
  booktitle = {Proceedings of the 2017 ACM SIGCSE Technical Symposium on Computer Science Education},
  title     = {An IoTa of IoT (Abstract Only)},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {742},
  publisher = {Association for Computing Machinery},
  series    = {SIGCSE '17},
  abstract  = {Internet of Things (IoT) devices -- networked microcontrollers with attached sensors and outputs (LEDs, actuators, etc.) -- are becoming ubiquitous in the home (e.g., smart light bulbs, security systems), on the road (e.g., smart parking meters, traffic control), in industry (e.g., equipment monitoring, asset tracking) and in healthcare (e.g., fitness monitors, drug monitors). Consequently, IoT provides an opportunity to demonstrate the pervasiveness and social relevance of computing. Moreover, today's hobbyist- oriented IoT platforms empower entry-level students to create meaningful, real-world IoT applications. This allows rich computer science topics, such as event driven programming, concurrency, networking, information representation, cloud computing, etc., to be introduced earlier in the curriculum. Most importantly, IoT examples provide a compelling context for students to hone their critical thinking skills while solving engaging, real-world problems. Faculty interested in including IoT topics face several challenges: selecting a suitable set of topics, identifying an appropriate pedagogical approach, and, perhaps most daunting, choosing a cost-effective platform that lends itself to classroom use. This workshop will introduce the basic terms and technologies in IoT, discuss issues that arise when including IoT topics in classes, compare and contrast the most popular platforms for IoT, and walk participants through several classroom-tested, hands-on examples using a classroom-friendly platform (Particle's Photon) where they create both Wi-Fi-based IoT devices and corresponding web apps. Participants will need a laptop (any OS) with Internet access.},
  doi       = {10.1145/3017680.3017820},
  isbn      = {9781450346986},
  keywords  = {CS1, IoT, intro. C.S.},
  location  = {Seattle, Washington, USA},
  numpages  = {1},
  url       = {https://doi.org/10.1145/3017680.3017820},
}

@InProceedings{Khandelwal2020,
  author    = {Khandelwal, Anurag and Kejariwal, Arun and Ramasamy, Karthikeyan},
  booktitle = {Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data},
  title     = {Le Taureau: Deconstructing the Serverless Landscape \&amp; A Look Forward},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {2641–2650},
  publisher = {Association for Computing Machinery},
  series    = {SIGMOD '20},
  abstract  = {Akin to the natural evolution of programming in assembly language to high-level languages, serverless computing represents the next frontier in the evolution of cloud computing: bare metal -&gt; virtual machines -&gt; containers -&gt; serverless. The genesis of serverless computing can be traced back to the fundamental need of enabling a programmer to singularly focus on writing application code in a high-level language and isolating all facets of system management (for example, but not limited to, instance selection, scaling, deployment, logging, monitoring, fault tolerance and so on). This is particularly critical in light of today's, increasingly tightening, time-to-market constraints. Currently, serverless computing is supported by leading public cloud vendors, such as AWS Lambda, Google Cloud Functions, Azure Cloud Functions and others. While this is an important step in the right direction, there are many challenges going forward. For instance, but not limited to, how to enable support for dynamic optimization, how to extend support for stateful computation, how to efficiently bin-pack applications, how to support hardware heterogeneity (this will be key especially in light of the emergence of hardware accelerators for deep learning workloads). Inspired by Picasso's Le Taureau, in the tutorial proposed herein, we shall deconstruct evolution of serverless --- the overarching intent being to facilitate better understanding of the serverless landscape. This, we hope, would help push the innovation frontier on both fronts, the paradigm itself and the applications built atop of it.},
  doi       = {10.1145/3318464.3383130},
  isbn      = {9781450367356},
  keywords  = {ephemeral storage, distributed systems, serverless computing, real-time streaming, data analytics, cloud computing},
  location  = {Portland, OR, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3318464.3383130},
}

@Article{Kistowski2017,
  author     = {Kistowski, J\'{o}akim Von and Herbst, Nikolas and Kounev, Samuel and Groenda, Henning and Stier, Christian and Lehrig, Sebastian},
  journal    = {ACM Trans. Auton. Adapt. Syst.},
  title      = {Modeling and Extracting Load Intensity Profiles},
  year       = {2017},
  issn       = {1556-4665},
  month      = {jan},
  number     = {4},
  volume     = {11},
  abstract   = {Today’s system developers and operators face the challenge of creating software systems that make efficient use of dynamically allocated resources under highly variable and dynamic load profiles, while at the same time delivering reliable performance. Autonomic controllers, for example, an advanced autoscaling mechanism in a cloud computing context, can benefit from an abstracted load model as knowledge to reconfigure on time and precisely. Existing workload characterization approaches have limited support to capture variations in the interarrival times of incoming work units over time (i.e., a variable load profile). For example, industrial and scientific benchmarks support constant or stepwise increasing load, or interarrival times defined by statistical distributions or recorded traces. These options show shortcomings either in representative character of load variation patterns or in abstraction and flexibility of their format.In this article, we present the Descartes Load Intensity Model (DLIM) approach addressing these issues. DLIM provides a modeling formalism for describing load intensity variations over time. A DLIM instance is a compact formal description of a load intensity trace. DLIM-based tools provide features for benchmarking, performance, and recorded load intensity trace analysis. As manually obtaining and maintaining DLIM instances becomes time consuming, we contribute three automated extraction methods and devised metrics for comparison and method selection. We discuss how these features are used to enhance system management approaches for adaptations during runtime, and how they are integrated into simulation contexts and enable benchmarking of elastic or adaptive behavior.We show that automatically extracted DLIM instances exhibit an average modeling error of 15.2\% over 10 different real-world traces that cover between 2 weeks and 7 months. These results underline DLIM model expressiveness. In terms of accuracy and processing speed, our proposed extraction methods for the descriptive models are comparable to existing time series decomposition methods. Additionally, we illustrate DLIM applicability by outlining approaches of workload modeling in systems engineering that employ or rely on our proposed load intensity modeling formalism.},
  address    = {New York, NY, USA},
  articleno  = {23},
  doi        = {10.1145/3019596},
  issue_date = {February 2017},
  keywords   = {load profile, model extraction, Load intensity variation, transformation, metamodeling, open workloads},
  numpages   = {28},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3019596},
}

@Article{Huang2021a,
  author     = {Huang, Chun-ying and Cheng, Yun-chen and Huang, Guan-zhang and Fan, Ching-ling and Hsu, Cheng-hsin},
  journal    = {ACM Trans. Multimedia Comput. Commun. Appl.},
  title      = {On the Performance Comparisons of Native and Clientless Real-Time Screen-Sharing Technologies},
  year       = {2021},
  issn       = {1551-6857},
  month      = {may},
  number     = {2},
  volume     = {17},
  abstract   = {Real-time screen-sharing provides users with ubiquitous access to remote applications, such as computer games, movie players, and desktop applications (apps), anywhere and anytime. In this article, we study the performance of different screen-sharing technologies, which can be classified into native and clientless ones. The native ones dictate that users install special-purpose software, while the clientless ones directly run in web browsers. In particular, we conduct extensive experiments in three steps. First, we identify a suite of the most representative native and clientless screen-sharing technologies. Second, we propose a systematic measurement methodology for comparing screen-sharing technologies under diverse and dynamic network conditions using different performance metrics. Last, we conduct extensive experiments and perform in-depth analysis to quantify the performance gap between clientless and native screen-sharing technologies. We found that our WebRTC-based implementation achieves the best overall performance. More precisely, it consumes a maximum of 3 Mbps bandwidth while reaching a high decoding ratio and delivering good video quality. Moreover, it leads to a steadily high decoding ratio and video quality under dynamic network conditions. By presenting the very first rigorous comparisons of the native and clientless screen-sharing technologies, this article will stimulate more exciting studies on the emerging clientless screen-sharing technologies.},
  address    = {New York, NY, USA},
  articleno  = {54},
  doi        = {10.1145/3437881},
  issue_date = {May 2021},
  keywords   = {performance optimization, performance evaluations, measurements, Live video streaming, real-time encoding},
  numpages   = {26},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3437881},
}

@InProceedings{Roloff2017,
  author    = {Roloff, Eduardo and Diener, Matthias and Carre\~{n}o, Emmanuell D. and Moreira, Francis B. and Gaspary, Luciano P. and Navaux, Philippe O.A.},
  booktitle = {Companion Proceedings of The10th International Conference on Utility and Cloud Computing},
  title     = {Exploiting Price and Performance Tradeoffs in Heterogeneous Clouds},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {71–76},
  publisher = {Association for Computing Machinery},
  series    = {UCC '17 Companion},
  abstract  = {Parallel applications are composed of several tasks, which have different computational demands among them. Moreover, most cloud providers offer multiple instance configurations, with large variations of computational power and cost. A combination between the application requirements and the variety of instance types of the cloud could be explored to improve the cost efficiency of the application execution. In this paper, we introduce the cost-delay product as a metric to measure the cost efficiency of cloud systems. With this metric, cloud tenants can evaluate different tradeoffs between cost and performance for their application, depending on their preferences. We explore the use of multiple instance types to create heterogeneous cluster systems in the cloud. Our results show that heterogeneous clouds can have a better cost efficiency than homogeneous systems, reducing the price of execution while maintaining a similar application performance. Furthermore, by comparing the cost-delay product, the user can select an instance mix that is most suitable for his needs.},
  doi       = {10.1145/3147234.3148103},
  isbn      = {9781450351959},
  keywords  = {cost efficiency, cloud computing, performance, heterogeneity},
  location  = {Austin, Texas, USA},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3147234.3148103},
}

@Article{Yoginath2015,
  author     = {Yoginath, Srikanth B. and Perumalla, Kalyan S.},
  journal    = {ACM Trans. Model. Comput. Simul.},
  title      = {Efficient Parallel Discrete Event Simulation on Cloud/Virtual Machine Platforms},
  year       = {2015},
  issn       = {1049-3301},
  month      = {jul},
  number     = {1},
  volume     = {26},
  abstract   = {Cloud and Virtual Machine (VM) technologies present new challenges with respect to performance and monetary cost in executing parallel discrete event simulation (PDES) applications. Due to the introduction of overall cost as a metric, the traditional use of the highest-end computing configuration is no longer the most obvious choice. Moreover, the unique runtime dynamics and configuration choices of Cloud and VM platforms introduce new design considerations and runtime characteristics specific to PDES over Cloud/VMs. Here, an empirical study is presented to help understand the dynamics, trends, and trade-offs in executing PDES on Cloud/VM platforms. Performance and cost measures obtained from multiple PDES applications executed on the Amazon EC2 Cloud and on a high-end VM host machine reveal new, counterintuitive VM--PDES dynamics and guidelines. One of the critical aspects uncovered is the fundamental mismatch in hypervisor scheduler policies designed for general Cloud workloads versus the virtual time ordering needed for PDES workloads. This insight is supported by experimental data revealing the gross deterioration in PDES performance traceable to VM scheduling policy. To overcome this fundamental problem, the design and implementation of a new deadlock-free scheduler algorithm are presented, optimized specifically for PDES applications on VMs. The scalability of our scheduler has been tested in up to 128 VMs multiplexed on 32 cores, showing significant improvement in the runtime relative to the default Cloud/VM scheduler. The observations, algorithmic design, and results are timely for emerging Cloud/VM-based installations, highlighting the need for PDES-specific support in high-performance discrete event simulations on Cloud/VM platforms.},
  address    = {New York, NY, USA},
  articleno  = {5},
  doi        = {10.1145/2746232},
  issue_date = {December 2015},
  keywords   = {scheduler, virtual machines, Parallel discrete event simulation, time warp, global virtual time},
  numpages   = {26},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2746232},
}

@InProceedings{Soltani2015,
  author    = {Soltani, Kiumars and Parameswaran, Aditya and Wang, Shaowen},
  booktitle = {Proceedings of the 2015 XSEDE Conference: Scientific Advancements Enabled by Enhanced Cyberinfrastructure},
  title     = {GeoHashViz: Interactive Analytics for Mapping Spatiotemporal Diffusion of Twitter Hashtags},
  year      = {2015},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {XSEDE '15},
  abstract  = {Since its birth in 2006, Twitter has evolved to a multi-purpose social media that attracts hundreds of millions of users to share their activities and ideas on a daily basis. The potential of capturing fine-grained activity log of users, combined with ever increasing geographical information derived from GPS-enabled devices, has made Twitter data a valuable source for spatiotemporal analysis of human activities. One of the early innovations of Twitter is the use of hashtag as a unique tagging mechanism to provide additional information about a user post. From its emergence in late 2007, hashtags have been used extensively to express ideas, group tweets and report events among Twitter users. The increasing popularity of hashtags, in addition to their simple and concise structure, has inspired multiple recent studies to propose hashtag as a medium to assess diffusion of ideas in a virtual world. Studying collective effort of users in making a hashtag go viral can shed light on the complex process of idea diffusion that involves psychological, sociological and geographical elements.Although most of the previous research on idea diffusion in virtual world purely focuses on the users social graph, recent studies have confirmed that the spatial relationship among users and regions also play a crucial role in its adoption patterns [1]. This comes back to First Law of Geography that was formulated by Waldo Tobler more than 40 years ago, as "everything is related to everything else, but near things are more related than distant things". However, previous work on designing an interactive visual analytical framework for hashtag diffusion (http://keyhole.co/, http://hashtracking.com/, https://tagboard.com/), lack in-depth spatial analysis capabilities, hence not well-suited to be used for studying diffusion patterns. This research aims to fill this gap by providing an interactive framework to offer visual analytics on geographical diffusion of hashtags over time. Our framework, called GeoHashViz, can provide both textual and visual analytics on the role of location in adoption of hashtags and offer insights on diffusion patterns among different hashtags. GeoHashViz processes large stream of incoming tweets using a Hadoop-based approach and calculates multiple measures that will be used to generate visual analytics for the user. Furthermore, it integrates online maps with a live animation tool to visualize both spatial and temporal diffusion of hashtags at the same time.Data Collection: we gather our data using the Twitter Streaming API (details in [3]).Since we are only interested in common hashtags, which have a certain level of popularity, we only keep the hashtags with more than 1000 appearances. Our unit of spatial resolution is set to cities in United States with a population larger than 60000 people that give us 645 unique locations. These locations will form our reference grid and every geographical point will be assigned to its nearest neighbor in the reference grid.Analytics: To formulate the problem of spatiotemporal analysis of hashtag diffusion, we recognized two main categories of hashtag-based and location-based analytics. In hashtag-based analytics we focus on specific hashtags and their associated diffusion patterns. On the other hand, location-based analytics study the similarity and closeness of locations in terms of their hashtag adoption. To evaluate the usability of the framework, we identify five core analytical features that cover wide ranges of research questions. However, our framework can be easily extended to include more analytical features. The five visual analytical capabilities are listed in Table 1. Spread and focus points (locations with highest occurrence of the hashtag [1]) provide users with a visual estimate of how the hashtag is diffused over time. However, we also provided four metrics that gives a user a more concrete sense of the diffusion patterns: a) Entropy: Measures the randomness of hashtag distribution [1] ;b) KL-divergence: Compare the geographical distribution of hashtag in consecutive time windows using KL-divergence method ;c) Spatial Dispersion: Measures how scattered is the hashtag from its geographical midpoint ;d) Count:. Plot the cumulative count of the hashtag over time.For location-based analytics we included two functions. Top-k hashtags calculate the most popular hashtags in a region and visualize that using a word cloud. However by simply looking at the counts, we may miss some locally significant due to their relative low count. To reduce the dominance of globally popular hashtags, we introduce another analytic that will visualize top-k locally significant hashtags. This analytic uses a Tf-idf like metric [5] to measure the local popularity of a hashtag in a specific region, hence assigning lower rank to the hashtags which are popular in other places as well. In addition, we provide two metrics for comparing two different regions in terms of hashtag adoption: a) Jaccard Similarity Compare the set of hashtag used in two different regions, with higher number assigned to more similar regions ;b) Adoption Lag This measure depicts how long it takes for a hashtag to travel between two region, by averaging the time difference between the first appearance of hashtags in two regions.Architecture: GeoHashViz framework follows a two-layer architecture: an offline-processing module and an interactive module. The offline-processing module, implemented entirely in Apache Hadoop and called periodically, processes the raw data and pre-computes measures related to spatiotemporal diffusion of hashtags. The interactive module on the other hand is called on demand and based on user requests. The two modules connect with each other through a distributed MongoDB database. The two-layer architecture enables a fast interactive final framework by reducing the data processing that interactive module is required to do.In the offline-processing module, significant hashtags are extracted and the points are laid on the geographical mesh that we defined above. Then two MapReduce jobs are executed: one for pre-computing measures related to hashtag-based analytics and one for location-based analytics. All the Hadoop experiments were conducted using XSEDE Gordon Hadoop cluster. The data-intensive nature of our problem, requiring aggregation of large number of tweets based on both hashtags and locations, make Hadoop an ideal choice for the offline-processing module. Using Hadoop, we distribute the tweets into multiple nodes, and then take advantage of MapReduce model to aggregate them based on their associated location on the mesh and their included hashtags. In the reduce step, having access to all the tweets for a certain location/hashtag, we can generate the analytics for different timestamps. In addition, since the nodes on Gordon Hadoop cluster have relatively high memory, we are able to store the geographical mesh in memory and quickly map the location of users to their closest point on the mesh (using kd-tree). The same technique is employed in the interactive module to find the set of mesh points which lies into the user-defined bounding box.The interactive module includes a web application and a Java Servlet. The web application is integrated into Cyber-GIS Gateway [2] to increase usability of the application and easier integration with other CyberGIS applications. Figure 1 shows a view of the application visualizing top 20 hashtags in the southern California region in September 2014.},
  articleno = {37},
  doi       = {10.1145/2792745.2792782},
  isbn      = {9781450337205},
  keywords  = {CyberGIS, interactive visualization, GeoHashViz, social media, Hadoop},
  location  = {St. Louis, Missouri},
  numpages  = {2},
  url       = {https://doi.org/10.1145/2792745.2792782},
}

@InProceedings{Raghavan2014,
  author    = {Raghavan, Ajaykrishna and Chandra, Abhishek and Weissman, Jon B.},
  booktitle = {Proceedings of the 15th International Middleware Conference},
  title     = {Tiera: Towards Flexible Multi-Tiered Cloud Storage Instances},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {1–12},
  publisher = {Association for Computing Machinery},
  series    = {Middleware '14},
  abstract  = {Cloud providers offer an array of storage services that represent different points along the performance, cost, and durability spectrum. If an application desires the composite benefits of multiple storage tiers, then it must manage the complexity of different interfaces to these storage services and their diverse policies. We believe that it is possible to provide the benefits of customized tiered cloud storage to applications without compromising simplicity using a lightweight middleware. In this paper, we introduce Tiera, a middleware that enables the provision of multi-tiered cloud storage instances that are easy to specify, flexible, and enable a rich array of storage policies and desired metrics to be realized. Tiera's novelty lies in the first-class support for encapsulated tiered cloud storage, ease of programmability of data management policies, and support for runtime replacement and addition of policies and tiers. Tiera enables an application to realize a desired metric (e.g., low latency or low cost) by selecting different storage services that constitute a Tiera instance, and easily specifying a policy, using event and response pairs, to manage the life cycle of data stored in the instance. We illustrate the benefits of Tiera through a prototype implemented on the Amazon cloud. By deploying unmodified MySQL database engine and a TPC-W Web bookstore application on Tiera, we are able to improve their respective throughputs by 47\% -- 125\% and 46\% -- 69\%, over standard deployments. We further show the flexibility of Tiera in achieving different desired application metrics with minimal overhead.},
  doi       = {10.1145/2663165.2663333},
  isbn      = {9781450327855},
  location  = {Bordeaux, France},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2663165.2663333},
}

@InProceedings{Yu2021,
  author    = {Yu, Minqi and Xie, Linjin and Huang, Rui and He, Xing and Yang, Maotao and Yang, Libin},
  booktitle = {Proceedings of the 3rd International Conference on Information Technologies and Electrical Engineering},
  title     = {Impedance Measurement of 0.4kV Power Supply Line in the Station Area Based on the Smart Energy Meter},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {255–260},
  publisher = {Association for Computing Machinery},
  series    = {ICITEE '20},
  abstract  = {Develop a monitoring and management system based on a cloud platform, and finally implement related applications such as abnormal monitoring of the electric energy meter wiring process, wiring fault diagnosis, line aging assessment, and power outage warning analysis on the cloud platform, which can promptly warn the occurrence of power outages and comprehensively improve high-quality power supply services Level. Therefore, this paper proposes a method for phase line and neutral line impedance estimation of 0.4kV low voltage distribution network based on intelligent electricity meters. In this paper, the voltage of each sequence, current of each sequence, and information of complex power of each sequence of each node are extracted by intelligent electricity meter, and then the measurement of line impedance is completed piecewise. Finally, the impedance measurement model of the 0.4kV low-voltage distribution network was built. The simulation verification of the line impedance measurement was completed through the effective cooperation with the high-precision and high-synchronous sampling smart electricity meter supporting the impedance measurement and the acquisition terminal supporting the of the impedance measurement. The simulation results show that the line impedance measurement error is small, and the prediction of line loss and impedance trend can be completed effectively.},
  doi       = {10.1145/3452940.3452990},
  isbn      = {9781450388665},
  keywords  = {Intelligent electric energy meter, Edge calculation, Line impedance measurement, Intelligent diagnosis},
  location  = {Changde City, Hunan, China},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3452940.3452990},
}

@InProceedings{Wade2017,
  author    = {Wade, April W. and Kulkarni, Prasad A. and Jantz, Michael R.},
  booktitle = {Proceedings of the 18th ACM SIGPLAN/SIGBED Conference on Languages, Compilers, and Tools for Embedded Systems},
  title     = {AOT vs. JIT: Impact of Profile Data on Code Quality},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {1–10},
  publisher = {Association for Computing Machinery},
  series    = {LCTES 2017},
  abstract  = {Just-in-time (JIT) compilation during program execution and ahead-of-time (AOT) compilation during software installation are alternate techniques used by managed language virtual machines (VM) to generate optimized native code while simultaneously achieving binary code portability and high execution performance. Profile data collected by JIT compilers at run-time can enable profile-guided optimizations (PGO) to customize the generated native code to different program inputs. AOT compilation removes the speed and energy overhead of online profile collection and dynamic compilation, but may not be able to achieve the quality and performance of customized native code. The goal of this work is to investigate and quantify the implications of the AOT compilation model on the quality of the generated native code for current VMs.  First, we quantify the quality of native code generated by the two compilation models for a state-of-the-art (HotSpot) Java VM. Second, we determine how the amount of profile data collected affects the quality of generated code. Third, we develop a mechanism to determine the accuracy or similarity for different profile data for a given program run, and investigate how the accuracy of profile data affects its ability to effectively guide PGOs. Finally, we categorize the profile data types in our VM and explore the contribution of each such category to performance.},
  doi       = {10.1145/3078633.3081037},
  isbn      = {9781450350303},
  keywords  = {Profile-guided optimizations, Program profiling},
  location  = {Barcelona, Spain},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3078633.3081037},
}

@Article{Wade2017a,
  author     = {Wade, April W. and Kulkarni, Prasad A. and Jantz, Michael R.},
  journal    = {SIGPLAN Not.},
  title      = {AOT vs. JIT: Impact of Profile Data on Code Quality},
  year       = {2017},
  issn       = {0362-1340},
  month      = {jun},
  number     = {5},
  pages      = {1–10},
  volume     = {52},
  abstract   = {Just-in-time (JIT) compilation during program execution and ahead-of-time (AOT) compilation during software installation are alternate techniques used by managed language virtual machines (VM) to generate optimized native code while simultaneously achieving binary code portability and high execution performance. Profile data collected by JIT compilers at run-time can enable profile-guided optimizations (PGO) to customize the generated native code to different program inputs. AOT compilation removes the speed and energy overhead of online profile collection and dynamic compilation, but may not be able to achieve the quality and performance of customized native code. The goal of this work is to investigate and quantify the implications of the AOT compilation model on the quality of the generated native code for current VMs.  First, we quantify the quality of native code generated by the two compilation models for a state-of-the-art (HotSpot) Java VM. Second, we determine how the amount of profile data collected affects the quality of generated code. Third, we develop a mechanism to determine the accuracy or similarity for different profile data for a given program run, and investigate how the accuracy of profile data affects its ability to effectively guide PGOs. Finally, we categorize the profile data types in our VM and explore the contribution of each such category to performance.},
  address    = {New York, NY, USA},
  doi        = {10.1145/3140582.3081037},
  issue_date = {May 2017},
  keywords   = {Program profiling, Profile-guided optimizations},
  numpages   = {10},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3140582.3081037},
}

@Article{Carlsson2016,
  author     = {Carlsson, Niklas and Liu, Zhenhua and Nguyen, Thu and Rosenberg, Catherine and Wierman, Adam},
  journal    = {SIGMETRICS Perform. Eval. Rev.},
  title      = {Session Details: Special Issue on the 2016 Greenmetrics Workshop},
  year       = {2016},
  issn       = {0163-5999},
  month      = {sep},
  number     = {2},
  volume     = {44},
  abstract   = {The seventh annual GreenMetrics Workshop was held on June 14, 2016 in Antibes Juan-les-Pins, France, in conjunction with the ACM SIGMETRICS/IFIP Performance 2016 conference. For the past five years the workshop has been expanded from topics on the energy and ecological impact of Information and Communication Technology (ICT) systems, to include emerging work on the Smart Grid. Topics of interest fall broadly into three main areas: designing sustainable ICT, ICT for sustainability, and building a smarter, more sustainable electricity grid. The workshop brought together researchers from the traditional SIGMETRICS and Performance communities with researchers and practitioners in the three areas above, to exchange technical ideas and experiences on issues related to sustainability and ICT.The workshop program included three 45-min keynote talks, and nine 20-min presentations of technical papers. All papers are included in this special issue and we briefly summarize the keynote talks here.In the first keynote "The New Sharing Economy for the Grid2050", Kameshwar Poolla from UC Berkeley discussed three sharing economy opportunities in the electricity sector- sharing storage, sharing PV generation, and sharing recruited demand flexibility. He also discussed regulatory and technical challenges to these opportunities. In addition, he presented a micro-economic analysis of decisions by firms, and quantify the benefits of sharing to various participants. Xue (Steve) Liu from McGill University presented the second keynote talk, titled "When Bits Meet Joules: A View from Data Center Operations' Perspective". He used data centers as an example to illustrate the importance of the codesign of information technologies and new energy technologies. Specifically, he focused on how to design cost-saving power management strategies for Internet data center operations.Our third keynote talk was by Florian D\"{o}rfler from ETH Z\"{u}rich, titled "Virtual Inertia Emulation and Placement in Power Grids". He presented a comprehensive analysis to address the optimal inertia placement problem, in particular, by providing a set of closed-form global optimality results for particular problem instances as well as a computational approach resulting in locally optimal solutions. He illustrated the results with a three-region power grid case study. The best student paper award was given to "Opportunities for Price Manipulation by Aggregators in Electricity Markets" by Ruhi et al. The award was determined by a committee of the invited speakers, chaired by Catherine Rosenberg, after considering both the papers and the presentations of the candidates. The authors quantified the profit an aggregator can obtain through strategic curtailment of generation in an electricity market. Efficient algorithms were shown to exist when the topology of the network is radial (acyclic). Further, significant increases in profit can be obtained through strategic curtailment in practical settings.Demand response is discussed in the following two papers. In "Optimizing the Level of Commitment in Demand Response", Comden et al. proposed a generalized demand response framework called Flexible Commitment Demand Response (FCDR) to allow for explicit choices of the level of commitment. Numerical simulations were conducted to demonstrate that FCDR brings in significant (around 50\%) social cost reductions and benefits both the LSE and customers simultaneously. In "An Emergency Demand Response Mechanism for Cloud Computing", Zhou et al. proposed an online auction for dynamic cloud resource provisioning under the emergency demand response program, which runs in polynomial time, achieves truthfulness and close-to-optimal social welfare for the cloud ecosystem.Geographical load balancing was examined by Neglia et al. in "Geographical Load Balancing Across Green Datacenters: a Mean Field Analysis". They modeled via a Markov Chain the problem of scheduling jobs by prioritizing datacenters where renewable energy is currently available. Mean field techniques were employed to derive an asymptotic approximate model and to investigate relationships and tradeoffs among the various system parameters. In "Emergence of Shared Behaviour in Distributed Scheduling Systems for Domestic Appliances", Facchini et al. showed social interaction can increase the flexibility of users and lower the peak power, resulting in a more smooth usage of energy throughout the day. Rossi et al. examined public lighting in "AURORA: an Energy Efficient Public Lighting IoT System for Smart Cities" by proposing Aurora: a low-budget, easy-to-deploy IoT control system. Aurora was deployed in a mid-size Italian municipality and its performance over 4 months was evaluated to quantify both the power and the economic saving.Wireless and wired network power consumption was studied in the following three papers. In "Radio Resource Management for Improving Energy Self-Sufficiency of Green Mobile Networks", Dalmasso et al. designed Resource on Demand strategies to reduce the base station cluster energy consumption and to adapt it to energy availability. Fan etal. also examined base stations in "Boosting Service Availability for Base Stations of Cellular Networks by Event-Driven Battery Profiling" by conducting a systematical analysis on a real world dataset and proposing an event-driven battery profiling approach to precisely extract the features that cause the working condition degradation of the battery group. Last but not least, in "Toward Power-Efficient Backbone Routers", Lu et al. studied how InTerFaces can distribute traffic flows to the Processing Engines (PEs) so that the offered loads on all active PEs are near-perfectly balanced over time, and kept close to a target load, so that the number of active PEs can be minimized.The papers presented at the workshop reflected a current concern of energy consumption associated with proliferating data centers, and other fundamental issues in green computing. The workshop incited interesting discussions and exchange among participants from North America, Europe, and Asia.},
  address    = {New York, NY, USA},
  doi        = {10.1145/3263878},
  issue_date = {September 2016},
  numpages   = {1},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3263878},
}

@InProceedings{Sastri2017,
  author    = {Sastri, Yedhu and Feldhoff, Kim and Starru\ss{}, J\"{o}rn and J\"{a}kel, Ren\'{e} and M\"{u}ller-Pfefferkorn, Ralph},
  booktitle = {Proceedings of the 2017 International Conference on Cloud and Big Data Computing},
  title     = {A Workflow for the Integral Performance Analysis of Cloud Applications Using Monitoring and Tracing Techniques},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {73–78},
  publisher = {Association for Computing Machinery},
  series    = {ICCBDC '17},
  abstract  = {Considering the cost effectiveness, elasticity, and flexibility of virtualized cloud environments, porting HPC applications to those environments and executing them within these settings is becoming more and more popular. For this purpose, traditional HPC applications have to be redesigned as cloud applications. An analysis of the performance of the redesigned applications within the cloud environment is in-dispensable, if the applications should be efficiently executed in the cloud environment.This paper proposes a workflow for the integral performance analysis of cloud applications within a cloud environment using monitoring and tracing techniques. For this, collectd acts as a lightweight monitoring daemon for recording performance data from outside of the applications, Score-P as a profiling and tracing tool for recording the performance data from the inside. Thus, this workflow will help in answering the question "How and why an application behaves like this within the cloud environment?".In order to show the usability of the proposed workflow, a parallel client server application was selected and adapted for the execution in a private OpenStack cloud. Performance measurements of the example running in the cloud environment could be successfully done according to the proposed workflow. In particular, performance metrics from both the outside and the inside of the application could be obtained to analyze and evaluate the performance of the application in detail.},
  doi       = {10.1145/3141128.3141132},
  isbn      = {9781450353434},
  keywords  = {Docker, Score-P, Container, Performance analysis, Micro services, Workflow, Tracing, Cloud application, Monitoring, collectd},
  location  = {London, United Kingdom},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3141128.3141132},
}

@Article{Wade2020,
  author     = {Wade, April W. and Kulkarni, Prasad A. and Jantz, Michael R.},
  journal    = {ACM Trans. Embed. Comput. Syst.},
  title      = {Exploring Impact of Profile Data on Code Quality in the HotSpot JVM},
  year       = {2020},
  issn       = {1539-9087},
  month      = {oct},
  number     = {6},
  volume     = {19},
  abstract   = {Managed language virtual machines (VM) rely on dynamic or just-in-time (JIT) compilation to generate optimized native code at run-time to deliver high execution performance. Many VMs and JIT compilers collect profile data at run-time to enable profile-guided optimizations (PGO) that customize the generated native code to different program inputs. PGOs are generally considered integral for VMs to produce high-quality and performant native code.In this work, we study and quantify the performance benefits of PGOs, understand the importance of profiling data quantity and quality/accuracy to effectively guide PGOs, and assess the impact of individual PGOs on VM performance. The insights obtained from this work can be used to understand the current state of PGOs, develop strategies to more efficiently balance the cost and exploit the potential of PGOs, and explore the implications of and challenges for the alternative ahead-of-time (AOT) compilation model used by VMs.},
  address    = {New York, NY, USA},
  articleno  = {48},
  doi        = {10.1145/3391894},
  issue_date = {November 2020},
  keywords   = {Program profiling, profile-guided optimizations},
  numpages   = {26},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3391894},
}

@InProceedings{Zouari2021,
  author    = {Zouari, Firas and Kabachi, Nadia and Boukadi, Khouloud and Ghedira Guegan, Chirine},
  booktitle = {Proceedings of the 25th International Database Engineering \&amp; Applications Symposium},
  title     = {Data Management in the Data Lake: A Systematic Mapping},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {280–284},
  publisher = {Association for Computing Machinery},
  series    = {IDEAS '21},
  abstract  = {The computer science community is paying more and more attention to data due to its crucial role in performing analysis and prediction. Researchers have proposed many data containers such as files, databases, data warehouses, cloud systems, and recently data lakes in the last decade. The latter enables holding data in its native format, making it suitable for performing massive data prediction, particularly for real-time application development. Although data lake is well adopted in the computer science industry, its acceptance by the research community is still in its infancy stage. This paper sheds light on existing works for performing analysis and predictions on data placed in data lakes. Our study reveals the necessary data management steps, which need to be followed in a decision process, and the requirements to be respected, namely curation, quality evaluation, privacy-preservation, and prediction. This study aims to categorize and analyze proposals related to each step mentioned above.},
  doi       = {10.1145/3472163.3472173},
  isbn      = {9781450389914},
  keywords  = {Data management, Data lake, Systematic mapping},
  location  = {Montreal, QC, Canada},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3472163.3472173},
}

@InProceedings{Balaji2014,
  author    = {Balaji, Mahesh and Rao, G Subrahmanya Vrk and Kumar, Ch. Aswani},
  booktitle = {Proceedings of the 14th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
  title     = {A Comparitive Study of Predictive Models for Cloud Infrastructure Management},
  year      = {2014},
  address   = {Chicago, Illinois},
  pages     = {923–926},
  publisher = {IEEE Press},
  series    = {CCGRID '14},
  abstract  = {Cloud service providers, monitor average resource (for e.g. CPU) consumption and based on predefined limits (for e.g. CPU-Idle-time &gt; 500 milliseconds), provision or de-provision resources. Traditionally this is a reactive approach and doesn't fully address the wide range of enterprise use cases. Implementation of predictive approach to resource management has been rarely reported even though they could perform potentially better than their counterpart. Identification of a suitable model for predicting the performance of the system under a load is an ideal precursor in managing resources on a cloud environment. The current study compares the performance of two such predictive models namely Holt-Winter and ARIMA using a public web server data set Request rate was used as the metric to monitor resource consumption. The experiment results show that Holt-Winter model performs better than a few selected ARIMA models, which could be subsequently used for managing resources on cloud if the data request rates follow a similar pattern},
  doi       = {10.1109/CCGrid.2014.32},
  isbn      = {9781479927838},
  keywords  = {holt-winter, resource management, cloud computing, ARIMA, predictive modeling},
  numpages  = {4},
  url       = {https://doi.org/10.1109/CCGrid.2014.32},
}

@InProceedings{Wang2018,
  author    = {Wang, Cong and Zink, Michael},
  booktitle = {Proceedings of Network and Operating System Support on Digital Audio and Video Workshop},
  title     = {On the Feasibility of DASH Streaming in the Cloud},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {49–54},
  publisher = {Association for Computing Machinery},
  series    = {NOSSDAV '14},
  abstract  = {As shown in recent studies, video streaming is by far the biggest category of backbone Internet traffic in the US. As a measure to reduce the cost of highly over-provisioned physical infrastructures while remaining the quality of video services, many streaming service providers started to use cloud services where physical resources can be dynamically allocated based on current demand. This paper characterizes the performance of Dynamic Adaptive Streaming over HTTP (DASH), a new MPEG standard on adaptive streaming, in the cloud. We seek to answer the following questions that are critical to content providers that are hosting video in clouds: Which data center is the best to host videos? Does geographical distance matter? What type of instance is best suitable depending on different needs? How to efficiently solve the trade-off between performance and cost? The measurement methods and results presented in this paper can be easily expanded into other VoD services, and they allow us to i) characterize DASH behavior when streaming from the cloud; ii) identify the key factors that influence the DASH performance; and iii) suggest improvements for related services.},
  doi       = {10.1145/2578260.2578273},
  isbn      = {9781450327060},
  keywords  = {HTTP adaptive streaming, Cloud computing, video-on-demand, quality of experience},
  location  = {Singapore, Singapore},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2578260.2578273},
}

@InProceedings{Wang2014,
  author    = {Wang, Cong and Zink, Michael},
  booktitle = {Proceedings of Network and Operating System Support on Digital Audio and Video Workshop},
  title     = {On the Feasibility of DASH Streaming in the Cloud},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {49–54},
  publisher = {Association for Computing Machinery},
  series    = {NOSSDAV '14},
  abstract  = {As shown in recent studies, video streaming is by far the biggest category of backbone Internet traffic in the US. As a measure to reduce the cost of highly over-provisioned physical infrastructures while remaining the quality of video services, many streaming service providers started to use cloud services where physical resources can be dynamically allocated based on current demand. This paper characterizes the performance of Dynamic Adaptive Streaming over HTTP (DASH), a new MPEG standard on adaptive streaming, in the cloud. We seek to answer the following questions that are critical to content providers that are hosting video in clouds: Which data center is the best to host videos? Does geographical distance matter? What type of instance is best suitable depending on different needs? How to efficiently solve the trade-off between performance and cost? The measurement methods and results presented in this paper can be easily expanded into other VoD services, and they allow us to i) characterize DASH behavior when streaming from the cloud; ii) identify the key factors that influence the DASH performance; and iii) suggest improvements for related services.},
  doi       = {10.1145/2597176.2578273},
  isbn      = {9781450327060},
  keywords  = {HTTP adaptive streaming, quality of experience, video-on-demand, Cloud computing},
  location  = {Singapore, Singapore},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2597176.2578273},
}

@InProceedings{Yadwadkar2017,
  author    = {Yadwadkar, Neeraja J. and Hariharan, Bharath and Gonzalez, Joseph E. and Smith, Burton and Katz, Randy H.},
  booktitle = {Proceedings of the 2017 Symposium on Cloud Computing},
  title     = {Selecting the Best VM across Multiple Public Clouds: A Data-Driven Performance Modeling Approach},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {452–465},
  publisher = {Association for Computing Machinery},
  series    = {SoCC '17},
  abstract  = {Users of cloud services are presented with a bewildering choice of VM types and the choice of VM can have significant implications on performance and cost. In this paper we address the fundamental problem of accurately and economically choosing the best VM for a given workload and user goals. To address the problem of optimal VM selection, we present PARIS, a data-driven system that uses a novel hybrid offline and online data collection and modeling framework to provide accurate performance estimates with minimal data collection. PARIS is able to predict workload performance for different user-specified metrics, and resulting costs for a wide range of VM types and workloads across multiple cloud providers. When compared to sophisticated baselines, including collaborative filtering and a linear interpolation model using measured workload performance on two VM types, PARIS produces significantly better estimates of performance. For instance, it reduces runtime prediction error by a factor of 4 for some workloads on both AWS and Azure. The increased accuracy translates into a 45\% reduction in user cost while maintaining performance.},
  doi       = {10.1145/3127479.3131614},
  isbn      = {9781450350280},
  keywords  = {cloud computing, data-driven modeling, resource allocation, performance prediction},
  location  = {Santa Clara, California},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3127479.3131614},
}

@InProceedings{Musto2016,
  author    = {Musto, Cataldo and Lops, Pasquale and Basile, Pierpaolo and de Gemmis, Marco and Semeraro, Giovanni},
  booktitle = {Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization},
  title     = {Semantics-Aware Graph-Based Recommender Systems Exploiting Linked Open Data},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {229–237},
  publisher = {Association for Computing Machinery},
  series    = {UMAP '16},
  abstract  = {The ever increasing interest in semantic technologies and the availability of several open knowledge sources have fueled recent progress in the field of recommender systems. In this paper we feed recommender systems with features coming from the Linked Open Data (LOD) cloud - a huge amount of machine-readable knowledge encoded as RDF statements - with the aim of improving recommender systems effectiveness. In order to exploit the natural graph-based structure of RDF data, we study the impact of the knowledge coming from the LOD cloud on the overall performance of a graph-based recommendation algorithm. In more detail, we investigate whether the integration of LOD-based features improves the effectiveness of the algorithm and to what extent the choice of different feature selection techniques influences its performance in terms of accuracy and diversity. The experimental evaluation on two state of the art datasets shows a clear correlation between the feature selection technique and the ability of the algorithm to maximize a specific evaluation metric. Moreover, the graph-based algorithm leveraging LOD-based features is able to overcome several state of the art baselines, such as collaborative filtering and matrix factorization, thus confirming the effectiveness of the proposed approach.},
  doi       = {10.1145/2930238.2930249},
  isbn      = {9781450343688},
  keywords  = {graphs, graph-based recommender systems, feature selection, diversity, linked open data, pagerank},
  location  = {Halifax, Nova Scotia, Canada},
  numpages  = {9},
  url       = {https://doi.org/10.1145/2930238.2930249},
}

@Article{Willnecker2018,
  author     = {Willnecker, Felix and Krcmar, Helmut},
  journal    = {ACM Trans. Internet Technol.},
  title      = {Multi-Objective Optimization of Deployment Topologies for Distributed Applications},
  year       = {2018},
  issn       = {1533-5399},
  month      = {jan},
  number     = {2},
  volume     = {18},
  abstract   = {Modern applications are typically implemented as distributed systems comprising several components. Deciding where to deploy which component is a difficult task that today is usually assisted by logical topology recommendations. Choosing inefficient topologies allocates the wrong amount of resources, leads to unnecessary operation costs, or results in poor performance. Testing different topologies to find good solutions takes a lot of time and might delay productive operations. Therefore, this work introduces a software-based deployment topology optimization approach for distributed applications. We use an enhanced performance model generator that extracts models from operational monitoring data of running applications. The extracted model is used to simulate performance metrics (e.g., resource utilization, response times, throughput) and runtime costs of distributed applications. Subsequently, we introduce a deployment topology optimizer, which selects an optimized topology for a specified workload and considers on-premise, cloud, and hybrid topologies. The following three optimization goals are presented in this work: (i) minimum response time for an optimized user experience, (ii) approximate resource utilization around certain peaks, and (iii) minimum cost for running the application. To evaluate the approach, we use the SPECjEnterpriseNEXT industry benchmark as distributed application in an on-premise and in a cloud/on-premise hybrid environment. The evaluation demonstrates the accuracy of the simulation compared to the actual deployment by deploying an optimized topology and comparing measurements with simulation results.},
  address    = {New York, NY, USA},
  articleno  = {21},
  doi        = {10.1145/3106158},
  issue_date = {May 2018},
  keywords   = {performance model, performance model generation, Deployment topology optimzation, distributed enterprise applications, memory simulation},
  numpages   = {21},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3106158},
}

@InProceedings{Pathania2021,
  author    = {Pathania, Priyavanshi and Mithani, Rajan Dilavar},
  booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
  title     = {Sustainability in Migrating Workloads to Public Clouds},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {166–169},
  publisher = {Association for Computing Machinery},
  series    = {ASE '20},
  abstract  = {In recent times, there has been a considerable increase in Cloud-Based applications and infrastructure. This has led to quicker innovations, agile businesses, availability of new services over the internet, improved collaboration, and better security. With the growth of new technologies like blockchain, quantum computing, mobility-focused applications, and edge computing, there has been an increased interest in adopting cloud services. In this paper, we highlight the different sustainability metrics and benefits while migrating workloads from the on-prem data center to the public clouds. Also, the clouds are elastic, scalable, cost-efficient, robust, and overall a better alternative to host the client applications and services. We present how the major Cloud Service Providers (CSPs) are continuously working on improving their infrastructure for a more energy efficient cloud. But with so many factors like the cost of cloud services, the location of the data center to name a few, it becomes quite a tedious task for the clients to select a cloud service provider when moving from their on-premise data center(s). Hence, we also briefly propose our solution that we are currently working on. The final goal is to have a cross-platform advisory that based on a wide-range of client-based inputs and a rich repository of current energy efficient clouds and their sustainability metrics, aims to provide them a detailed recommendation about their preferred cloud service provider. In case the client does not provide any such preference, the advisory should also recommend an ideal cloud service provider for their particular workload. This suggested action will be able to fulfill the client's constraints as well as provide them an energy efficient cloud along with a sustainability score. This score is indicative of how much improvement in the energy consumed and carbon footprint can be achieved through this migration to the suggested cloud.},
  doi       = {10.1145/3417113.3423001},
  isbn      = {9781450381284},
  keywords  = {pre-migration cloud sustainability, carbon footprint, cloud sustainability, cloud computing, energy efficient cloud},
  location  = {Virtual Event, Australia},
  numpages  = {4},
  url       = {https://doi.org/10.1145/3417113.3423001},
}

@InProceedings{Chow2017,
  author    = {Chow, Kingsum and Zhu, Wanyi},
  booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering},
  title     = {Software Performance Analytics in the Cloud},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {419–421},
  publisher = {Association for Computing Machinery},
  series    = {ICPE '17},
  abstract  = {The emergence of large-scale software deployments in the cloud has led to several challenges: (1) measuring software performance in the data center, and (2) optimizing software for resource management. This tutorial addresses the two challenges by bringing the knowledge of software performance monitoring in the data center to the world of applying performance analytics. It introduces data transformations for software performance metrics. The transformations enable effective applications of analytics. This tutorial starts with software performance in the small and ends with applying analytics to software performance in the large. In software performance in the small, it summarizes performance tools, data collection and manual analysis. Then it describes monitoring tools that are helpful in performance analysis in the large. The tutorial will guide the audience in applying analytics to performance data obtained by common tools. This tutorial describes how to select analytical methods and what precautions should be taken to get effective results.},
  doi       = {10.1145/3030207.3053676},
  isbn      = {9781450344043},
  keywords  = {analytics, datacenter efficiency, software performance, capacity planning},
  location  = {L'Aquila, Italy},
  numpages  = {3},
  url       = {https://doi.org/10.1145/3030207.3053676},
}

@InProceedings{RamosChavez2021,
  author    = {Ramos-Chavez, Roberto and Mekuria, Rufael and Karagkioules, Theo and Griffioen, Dirk and Wagenaar, Arjen and Ogle, Mark},
  booktitle = {Proceedings of the 12th ACM Multimedia Systems Conference},
  title     = {MPEG NBMP Testbed for Evaluation of Real-Time Distributed Media Processing Workflows at Scale},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {173–185},
  publisher = {Association for Computing Machinery},
  series    = {MMSys '21},
  abstract  = {Real-time Distributed Media Processing Workflows (DMPW) are popular for online media delivery. Combining distributed media sources and processing can reduce storage costs and increase flexibility. However, high request rates may result in unacceptable latency or even failures in incorrect configurations. Thus, testing DMPW deployments at scale is key, particularly for real-time cases. We propose the new MPEG Network Based Media Processing (NBMP) standard for this and present a testbed implementation that includes all the reference components. In addition, the testbed includes a set of configurable functions for load generation, monitoring, data-collection and visualization. The testbed is used to test Dynamic Adaptive HTTP streaming functions under different workloads in a standardized and reproducible manner. A total of 327 tests with different loads and Real-Time DMPW configurations were completed. The results provide insights in the performance, reliability and time-consistency of each configuration. Based on these tests, we selected the preferred cloud instance type, considering hypervisor options and different function implementation configurations. Further, we analyzed different processing tasks and options for distributed deployments on edge and centralized clouds. Last, a classifier was developed to detect if failures happen under a certain workload. Results also show that, normalized inter-experiment standard deviation of the metric means can be an indicator for unstable or incorrect configurations.},
  doi       = {10.1145/3458305.3463380},
  isbn      = {9781450384346},
  keywords  = {standards, experimentation},
  location  = {Istanbul, Turkey},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3458305.3463380},
}

@InProceedings{MuhammadBello2016,
  author    = {Muhammad-Bello, Bilkisu Larai and Aritsugi, Masayoshi},
  booktitle = {Proceedings of the 9th International Conference on Utility and Cloud Computing},
  title     = {TCloud: A Transparent Framework for Public Cloud Service Comparison},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {228–233},
  publisher = {Association for Computing Machinery},
  series    = {UCC '16},
  abstract  = {Whilst there are many attributes that need to be considered for cloud service selection, performance remains one of the most crucial aspects. Thus, we argue for a transparent cloud provider comparison framework in this study. We initiate the development of TCloud: a transparent framework for public cloud service comparison. Our framework helps prospective cloud users to decipher public cloud benchmarking data and appraise the performance of public cloud services relative to their performance goals. We carried out experiments on the real public cloud environment to implement our framework and demonstrated how prospective cloud users can use the TCloud framework in understanding how well virtualized public cloud resources meet their application requirements. Unlike previous studies, the TCloud framework presents a more realistic method of appraising the performance of virtualized resources in the public cloud. TCloud is unique in the sense that it collates public cloud benchmarking data and correlates the observed performance metrics to prospective cloud users' actual application workload requirements.},
  doi       = {10.1145/2996890.3007864},
  isbn      = {9781450346160},
  keywords  = {cloud service selection, workload-based performance analysis, cloud performance benchmarking},
  location  = {Shanghai, China},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2996890.3007864},
}

@InProceedings{Khan2018a,
  author    = {Khan, Jamal Ahmad and Shahzad, Muhammad and Butt, Ali R.},
  booktitle = {Proceedings of the 1st International Workshop on Edge Systems, Analytics and Networking},
  title     = {Sizing Buffers of IoT Edge Routers},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {55–60},
  publisher = {Association for Computing Machinery},
  series    = {EdgeSys'18},
  abstract  = {In typical IoT systems, sensors and actuators are connected to small embedded computers, called IoT devices, and the IoT devices are connected to one or more appropriate cloud services over the internet through an edge access router. A very important design aspect of an IoT edge router is the size of the output packet buffer of its interface that connects to the access link. Selecting an appropriate size for this buffer is crucial because it directly impacts two key performance metrics: 1) access link utilization and 2) latency. In this paper, we calculate the size of the output buffer that ensures that the access link stays highly utilized and at the same time, significantly lowers the average latency experienced by the packets. To calculate this buffer size, we theoretically model the average TCP congestion window size of all IoT devices while eliminating three key assumptions of prior art that do not hold true for IoT TCP traffic, as we will demonstrate through a measurement study. We show that for IoT traffic, buffer size calculated by our method results in 50\% lower queuing delay compared to the state of the art schemes while achieving similar access link utilization and loss-rate.},
  doi       = {10.1145/3213344.3213354},
  isbn      = {9781450358378},
  keywords  = {IoT, Buffers, Edge Routers},
  location  = {Munich, Germany},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3213344.3213354},
}

@InProceedings{Klugman2021,
  author    = {Klugman, Noah and Adkins, Joshua and Paszkiewicz, Emily and Hickman, Molly G. and Podolsky, Matthew and Taneja, Jay and Dutta, Prabal},
  booktitle = {Proceedings of the 20th International Conference on Information Processing in Sensor Networks (Co-Located with CPS-IoT Week 2021)},
  title     = {Watching the Grid: Utility-Independent Measurements of Electricity Reliability in Accra, Ghana},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {341–356},
  publisher = {Association for Computing Machinery},
  series    = {IPSN '21},
  abstract  = {In much of the world, electricity grids are not instrumented at the customer level, limiting insights into the power quality experienced by utility customers. Moreover, to understand grid performance, regulators and investors must depend on utilities to self-report reliability data. To address these challenges, we introduce PowerWatch, an agile methodology to directly measure customer experience and aggregated grid performance without relying on the utility for deployment or management. PowerWatch employs a system of distributed sensors coupled with cloud-based analytics. We evaluate the PowerWatch methodology by deploying 462 sensors in homes and businesses in Accra, Ghana for over a year, yielding the largest open-source data set on electricity reliability at the customer-level in the region. We describe the architecture, design, and performance of PowerWatch, as well as the data that are collected, explaining how we determine the accuracy and coverage of our methodology without ground truth. Finally, we report on grid performance issues, finding nearly twice as many outages as the utility observed, suggesting a need for better grid performance monitoring.},
  doi       = {10.1145/3412382.3458276},
  isbn      = {9781450380980},
  keywords  = {Sensor deployments, Grid reliability metering},
  location  = {Nashville, TN, USA},
  numpages  = {16},
  url       = {https://doi.org/10.1145/3412382.3458276},
}

@InProceedings{Patiniotakis2014,
  author    = {Patiniotakis, Ioannis and Verginadis, Yiannis and Mentzas, Gregoris},
  booktitle = {Proceedings of the 2nd International Workshop on CrossCloud Systems},
  title     = {Preference-Based Cloud Service Recommendation as a Brokerage Service},
  year      = {2014},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {CCB '14},
  abstract  = {As the multitude and complexity of cloud services increases, the role of cloud brokers in the cloud service ecosystems becomes increasingly important. In particular, the lack of standard mechanisms that allow for the comparison of cloud service specifications against user requirements taking into account the implicit uncertainty and vagueness is a major hindrance during the cloud service evaluation and selection. In this paper, we discuss the Preference-based cLoud Service Recommender (PuLSaR) that uses a holistic multi-criteria decision making (MCDM) approach for offering optimisation as brokerage service. The specification and implementation details of this dedicated software are thoroughly discussed while the background method used is summarised. Both method and brokerage service allow for the multi-objective assessment of cloud services in a unified way, taking into account precise and imprecise metrics and dealing with their fuzziness.},
  articleno = {5},
  doi       = {10.1145/2676662.2676677},
  isbn      = {9781450332330},
  keywords  = {cloud service broker, service ranking, MCDM, optimisation},
  location  = {Bordeaux, France},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2676662.2676677},
}

@InProceedings{Sabet2020,
  author    = {Sabet, Saeed Shafiee and Schmidt, Steven and Zadtootaghaj, Saman and Griwodz, Carsten and M\"{o}ller, Sebastian},
  booktitle = {Proceedings of the 12th ACM International Workshop on Immersive Mixed and Virtual Environment Systems},
  title     = {Delay Sensitivity Classification of Cloud Gaming Content},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {25–30},
  publisher = {Association for Computing Machinery},
  series    = {MMVE '20},
  abstract  = {Cloud Gaming is an emerging service that catches growing interest in the research community as well as industry. Cloud Gaming require a highly reliable and low latency network to achieve a satisfying Quality of Experience (QoE) for its users. Using a cloud gaming service with high latency would harm the interaction of the user with the game, leading to a decrease in playing performance and, thus players frustrations. However, the negative effect of delay on gaming QoE depends strongly on the game content. At a certain level of delay, a slow-paced card game is typically not as delay sensitive as a shooting game. For optimal resource allocation and quality estimation, it is highly important for cloud providers, game developers, and network planners to consider the impact of the game content. This paper contributes to a better understanding of the delay impact on QoE for cloud gaming applications by identifying game characteristics influencing the delay perception of the users. In addition, an expert evaluation methodology to quantify these characteristics as well as a delay sensitivity classification based on a decision tree are presented. The results indicated an excellent level of agreement, which demonstrates the reliability of the proposed method. Additionally, the decision tree reached an accuracy of 90\% on determining the delay sensitivity classes which were derived from a large dataset of subjective input quality ratings during a series of experiments.},
  doi       = {10.1145/3386293.3397116},
  isbn      = {9781450379472},
  keywords  = {cloud gaming, delay, QoE, content classification},
  location  = {Istanbul, Turkey},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3386293.3397116},
}

@InProceedings{Almanea2014,
  author    = {Almanea, Mohammed Ibrahim M.},
  booktitle = {Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing},
  title     = {Cloud Advisor - A Framework towards Assessing the Trustworthiness and Transparency of Cloud Providers},
  year      = {2014},
  address   = {USA},
  pages     = {1018–1019},
  publisher = {IEEE Computer Society},
  series    = {UCC '14},
  abstract  = {We propose a Cloud Advisor framework that couples two salient features: trustworthiness and transparency measurement. It provides a mechanism to measure trustworthiness based on the history of the cloud provider taking into account evidence support and to measure transparency based on the Cloud Controls Matrix (CCM) framework. The selection process is based on a set of assurance requirements that if are met by the cloud provider or if it has been considered in a tool it could bring assurance and confidence to cloud customers.},
  doi       = {10.1109/UCC.2014.168},
  isbn      = {9781479978816},
  keywords  = {framework, cloud computing, trustworthiness, measurement, cloud providers, transparency, assurance requirements},
  numpages  = {2},
  url       = {https://doi.org/10.1109/UCC.2014.168},
}

@InProceedings{Huang2014a,
  author    = {Huang, Chun-Ying and Hsu, Cheng-Hsin and Chen, De-Yu and Chen, Kuan-Ta},
  booktitle = {Proceedings of Workshop on Mobile Video Delivery},
  title     = {Quantifying User Satisfaction in Mobile Cloud Games},
  year      = {2014},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {MoViD'14},
  abstract  = {We conduct real experiments to quantify user satisfaction in mobile cloud games using a real cloud gaming system built on the open-sourced GamingAnywhere. We share our experiences in porting GamingAnywhere client to Android OS and perform extensive experiments on both the mobile and desktop clients. The experiment results reveal several new insights: (1) gamers are more satisfied with the graphics quality on mobile devices, while they are more satisfied with the control quality on desktops, (2) the bitrate, frame rate, and network delay significantly affect the graphics and smoothness quality, and (3) the control quality only depends on the client type (mobile versus desktop). To the best of our knowledge, such user studies have never been done in the literature.},
  articleno = {4},
  doi       = {10.1145/2594449.2579468},
  isbn      = {9781450327077},
  keywords  = {Cloud games, user studies, performance evaluation, mobile games},
  location  = {Singapore, Singapore},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2594449.2579468},
}

@InProceedings{Huang2018,
  author    = {Huang, Chun-Ying and Hsu, Cheng-Hsin and Chen, De-Yu and Chen, Kuan-Ta},
  booktitle = {Proceedings of Workshop on Mobile Video Delivery},
  title     = {Quantifying User Satisfaction in Mobile Cloud Games},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {1–6},
  publisher = {Association for Computing Machinery},
  series    = {MoViD'14},
  abstract  = {We conduct real experiments to quantify user satisfaction in mobile cloud games using a real cloud gaming system built on the open-sourced GamingAnywhere. We share our experiences in porting GamingAnywhere client to Android OS and perform extensive experiments on both the mobile and desktop clients. The experiment results reveal several new insights: (1) gamers are more satisfied with the graphics quality on mobile devices, while they are more satisfied with the control quality on desktops, (2) the bitrate, frame rate, and network delay significantly affect the graphics and smoothness quality, and (3) the control quality only depends on the client type (mobile versus desktop). To the best of our knowledge, such user studies have never been done in the literature.},
  doi       = {10.1145/2579465.2579468},
  isbn      = {9781450327077},
  keywords  = {mobile games, performance evaluation, user studies, Cloud games},
  location  = {Singapore, Singapore},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2579465.2579468},
}

@Article{Zhang2017a,
  author     = {Zhang, Gui-Jun and Zhou, Xiao-Gen and Yu, Xu-Feng and Hao, Xiao-Hu and Yu, Li},
  journal    = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
  title      = {Enhancing Protein Conformational Space Sampling Using Distance Profile-Guided Differential Evolution},
  year       = {2017},
  issn       = {1545-5963},
  month      = {nov},
  number     = {6},
  pages      = {1288–1301},
  volume     = {14},
  abstract   = {De novo protein structure prediction aims to search for low-energy conformations as it follows the thermodynamics hypothesis that places native conformations at the global minimum of the protein energy surface. However, the native conformation is not necessarily located in the lowest-energy regions owing to the inaccuracies of the energy model. This study presents a differential evolution algorithm using distance profile-based selection strategy to sample conformations with reasonable structure effectively. In the proposed algorithm, besides energy, the residue-residue distance is considered another measure of the conformation. The average distance errors of decoys between the distance of each residue pair and the corresponding distance in the distance profiles are first calculated when the trial conformation yields a larger energy value than that of the target. Then, the distance acceptance probability of the trial conformation is designed based on distance profiles if the trial conformation obtains a lower average distance error compared with that of the target conformation. The trial conformation is accepted to the next generation in accordance with its distance acceptance probability. By using the dual constraints of energy and distance in guiding sampling, the algorithm can sample conformations with lower energies and more reasonable structures. Experimental results of 28 benchmark proteins show that the proposed algorithm can effectively predict near-native protein structures.},
  address    = {Washington, DC, USA},
  doi        = {10.1109/TCBB.2016.2566617},
  issue_date = {November 2017},
  numpages   = {14},
  publisher  = {IEEE Computer Society Press},
  url        = {https://doi.org/10.1109/TCBB.2016.2566617},
}

@InProceedings{Kunde2015,
  author    = {Kunde, Shruti and Mukherjee, Tridib},
  booktitle = {Proceedings of the 30th Annual ACM Symposium on Applied Computing},
  title     = {Workload Characterization Model for Optimal Resource Allocation in Cloud Middleware},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {442–447},
  publisher = {Association for Computing Machinery},
  series    = {SAC '15},
  abstract  = {With increasing focus on inter-operability across cloud offerings to leverage their disparate capabilities, it has become more and more important to enable a flexible framework for sharing of heterogeneous resources in the cloud infrastructure. At the same time, it is imperative to be aware of the performance implications of hosting application workloads on different resources in order to guarantee Service Level Agreements (SLAs) to the applications. This paper focusses on experimental characterization of performance implications of different heterogeneous resources in hosting big-data analytics application workloads (one of the most critical applications in modern times). To create the knowledge, based on which the recommendations are provided, we benchmark the performance of big-data analytics applications, using a Hadoop cluster setup. Specifically, we study parameters of interest such as turnaround time and throughput, which are most likely to influence our choice of infrastructure for a particular application. Our experiments are conducted on varied platforms, both internal to Xerox and external cloud providers. We present a model based on our experiments, that facilitates the characterization of hetergeneous applications, thus enabling the cloud middleware to select an appropriate infrastructure and metrics in order to attain the desired SLA.},
  doi       = {10.1145/2695664.2695814},
  isbn      = {9781450331968},
  keywords  = {resource sharing, cloud middleware},
  location  = {Salamanca, Spain},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2695664.2695814},
}

@InProceedings{Davatz2017,
  author    = {Davatz, Christian and Inzinger, Christian and Scheuner, Joel and Leitner, Philipp},
  booktitle = {Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
  title     = {An Approach and Case Study of Cloud Instance Type Selection for Multi-Tier Web Applications},
  year      = {2017},
  address   = {Madrid, Spain},
  pages     = {534–543},
  publisher = {IEEE Press},
  series    = {CCGrid '17},
  abstract  = {A challenging problem for users of Infrastructure-as-a-Service (IaaS) clouds is selecting cloud providers, regions, and instance types cost-optimally for a given desired service level. Issues such as hardware heterogeneity, contention, and virtual machine (VM) placement can result in considerably differing performance across supposedly equivalent cloud resources. Existing research on cloud benchmarking helps, but often the focus is on providing low-level microbenchmarks (e.g., CPU or network speed), which are hard to map to concrete business metrics of enterprise cloud applications, such as request throughput of a multi-tier Web application. In this paper, we propose Okta, a general approach for fairly and comprehensively benchmarking the performance and cost of a multi-tier Web application hosted in an IaaS cloud. We exemplify our approach for a case study based on the two-tier AcmeAir application, which we evaluate for 11 real-life deployment configurations on Amazon EC2 and Google Compute Engine. Our results show that for this application, choosing compute-optimized instance types in the Web layer and small bursting instances for the database tier leads to the overall most cost-effective deployments. This result held true for both cloud providers. The least cost-effective configuration in our study provides only about 67\% of throughput per US dollar spent. Our case study can serve as a blueprint for future industrial or academic application benchmarking projects.},
  doi       = {10.1109/CCGRID.2017.12},
  isbn      = {9781509066100},
  numpages  = {10},
  url       = {https://doi.org/10.1109/CCGRID.2017.12},
}

@InProceedings{Pal2015,
  author    = {Pal, Yogendra and Iyer, Sridhar},
  booktitle = {Proceedings of the 2015 ACM Conference on Innovation and Technology in Computer Science Education},
  title     = {Classroom Versus Screencast for Native Language Learners: Effect of Medium of Instruction on Knowledge of Programming},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {290–295},
  publisher = {Association for Computing Machinery},
  series    = {ITiCSE '15},
  abstract  = {Students, who study in their native language in K-12 and go on to do their undergraduate education in English, have difficulty in acquiring programming knowledge. Solutions targeted towards improving their English proficiency take time, while those that continue with native language in the classroom limit the students' ability to compete in a global market. Another solution could be the use of video-based instructional material to empower a student for self-paced learning. In this paper, we present a comparative study of classroom instruction versus self-paced screencasts for native language learners' acquisition of programming concepts. We conducted four introductory programming workshops, each of six days duration. Two workshops were classroom based, one having Hindi (native language) as the medium of instruction and other in English. Two other workshops were screencast based, again one in Hindi and one in English. We measured differences between the groups using a post-test, across different content types such as fact, concepts and process. We found that when medium of instruction is different from language of K-12 instruction, there is an adverse impact on learning. However, when self-paced screencast is used instead of classroom environment, there is a statistically significant improvement in performance. Our work informs the choice of MoI and choice of environment for native language learners.},
  doi       = {10.1145/2729094.2742618},
  isbn      = {9781450334402},
  keywords  = {computer programming education, native language instruction, screencast},
  location  = {Vilnius, Lithuania},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2729094.2742618},
}

@InProceedings{Liu2019b,
  author    = {Liu, Yang and Xu, Huanle and Lau, Wing Cheong},
  booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
  title     = {Accordia: Adaptive Cloud Configuration Optimization for Recurring Data-Intensive Applications},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {479},
  publisher = {Association for Computing Machinery},
  series    = {SoCC '19},
  abstract  = {Recognizing the diversity of big data analytic jobs, cloud providers offer a wide range of virtual machine (VM) instances for different use cases. The choice of cloud instance configurations can have significant impact on the response time and running cost of data-intensive, recurring jobs for production. A poor choice of cloud instance-type/configuration can substantially degrade the response time by 5x, or increase the cost by 10x. Identifying the best cloud configuration under low search budget is a challenging problem due to i) the large and high-dimensional configuration-parameters space, ii) the dynamically varying price of some instance types, iii) job response time variation even given the same configuration, and iv) gradual drifts/ unexpected changes of the characteristics of the recurring jobs. To tackle this problem, we have designed and implemented Accordia, a system which enables Adaptive Cloud Configuration Optimization for Recurring Data-Intensive Applications.Accordia extends the Gaussian-Process Upper Confidence Bound (GP-UCB) approach in [3] to search for and track the potentially dynamic optimal cloud configuration within a high-dimensional para-meter-space. Unlike other state-of-the-art schemes, such as CherryPick[1] and Arrow[2], Accordia can handle time-varying instance pricing while providing a performance guarantee of sub-linear regret when comparing with the static, offline optimial solution.Figure 1 depicts the system architecture of our implementation of Accordia for Apache Spark running over Kubernetes. When a job is submitted, a Spark driver and multiple Spark executors are deployed as containers, each within its own Kubernetes pod. Accordia then dynamically adjusts the resource types/ allocation for the containers within their respective pods to minimize the job completion cost using the GP-UCB online-learning approach.To evaluate the performance of Accordia, we have run different mixes of recurring Spark jobs over the Google public cloud. In our experiments, Accordia dynamically learns the best cloud configuration from over 7000 candidate choices within a 5-dimensional parameter space, covering the number of executors, as well as the number of CPU cores and memory (RAM) allocation for the driver and the executor pods. Empirical measurements show that Accordia can find a near-cost-optimal configuration for a recurring job (i.e. within 10\% of the optimal cost) with fewer than 20 runs, which translates to a 2X-speedup and a 20.9\% cost-savings, when comparing to CherryPick. To highlight Accordia's capability to handle abrupt/unexpected changes of the characteristics of a recurring job, we even dynamically switch the type of a recurring job (without notifying Accordia) over exponentially-distributed time-intervals. Under such cases, Accordia can still achieve on average a cost-savings of 18.4\% over CherryPick. The full technical report is available at http://mobitec.ie.cuhk.edu.hk/cloudComputing/Accordia.pdf.},
  doi       = {10.1145/3357223.3365441},
  isbn      = {9781450369732},
  keywords  = {Cloud configuration, Big data analytics, Kubernetes, Gaussian-Process UCB},
  location  = {Santa Cruz, CA, USA},
  numpages  = {1},
  url       = {https://doi.org/10.1145/3357223.3365441},
}

@InProceedings{Ganihar2014,
  author    = {Ganihar, Syed Altaf and Joshi, Shreyas and Setty, Shankar and Mudenagudi, Uma},
  booktitle = {SIGGRAPH Asia 2014 Posters},
  title     = {3D Object Decomposition and Super Resolution},
  year      = {2014},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {SA '14},
  abstract  = {In this paper we propose to address the problem of 3D object decomposition and super resolution. We model the 3D object as a set of Riemannian manifolds and propose metric tensor and Christoffel symbols as a novel set of features for 3D object decomposition using polynomial kernel SVM classifier. The super resolution of the 3D point clouds is carried out using the decomposed object by using selective interpolation techniques. The effectiveness of the proposed framework is demonstrated on 3D objects obtained from different datasets and achieve comparable results.},
  articleno = {5},
  doi       = {10.1145/2668975.2669018},
  isbn      = {9781450327923},
  location  = {Shenzhen, China},
  numpages  = {1},
  url       = {https://doi.org/10.1145/2668975.2669018},
}

@InProceedings{Lee2020,
  author    = {Lee, Yena and An, Jae-Hoon and Kim, Younghwan},
  booktitle = {Proceedings of the International Conference on Research in Adaptive and Convergent Systems},
  title     = {Scheduler for Distributed and Collaborative Container Clusters Based on Multi-Resource Metric},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {279–281},
  publisher = {Association for Computing Machinery},
  series    = {RACS '20},
  abstract  = {With the development of cloud technology, distributed and collaborative container platform technology has emerged to overcome the limitations of the existing stand-alone container platform, which has limitations in the mobility and resource scalability of cloud services. Distributed and collaborative container platform technology enables flexible expansion of resources and maximization of service mobility between container platforms distributed locally.In this paper, we propose a two-stage scheduler based on multi-resource metrics. The proposed scheduler determines the proper federated cluster where the request deployment can be deployed in a distributed and collaborative cluster environment. In order to select an proper federated cluster, filtering to select candidate clusters to which the scheduling request deployment can be deployed and scoring to evaluate the preference of each filtered cluster are performed.},
  doi       = {10.1145/3400286.3418281},
  isbn      = {9781450380256},
  keywords  = {Distributed and Collaborative, Scheduling, Cloud Computing},
  location  = {Gwangju, Republic of Korea},
  numpages  = {3},
  url       = {https://doi.org/10.1145/3400286.3418281},
}

@InProceedings{Shen2016,
  author    = {Shen, Yilin and Jin, Hongxia},
  booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {EpicRec: Towards Practical Differentially Private Framework for Personalized Recommendation},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {180–191},
  publisher = {Association for Computing Machinery},
  series    = {CCS '16},
  abstract  = {Recommender systems typically require users' history data to provide a list of recommendations and such recommendations usually reside on the cloud/server. However, the release of such private data to the cloud has been shown to put users at risk. It is highly desirable to provide users high-quality personalized services while respecting their privacy. In this paper, we develop the first Enhanced Privacy-built-In Client for Personalized Recommendation (EpicRec) system that performs the data perturbation on the client side to protect users' privacy. Our system needs no assumption of trusted server and no change on the recommendation algorithms on the server side; and needs minimum user interaction in their preferred manner, which makes our solution fit very well into real world practical use.The design of EpicRec system incorporates three main modules: (1) usable privacy control interface that enables two user preferred privacy controls, overall and category-based controls, in the way they understand; (2) user privacy level quantification that automatically quantifies user privacy concern level from these user understandable inputs; (3) lightweight data perturbation algorithm that perturbs user private data with provable guarantees on both differential privacy and data utility.Using large-scale real world datasets, we show that, for both overall and category-based privacy controls, EpicRec performs best with respect to both perturbation quality and personalized recommendation, with negligible computational overhead. Therefore, EpicRec enables two contradictory goals, privacy preservation and recommendation accuracy. We also implement a proof-of-concept EpicRec system to demonstrate a privacy-preserving personal computer for movie recommendation with web-based privacy controls. We believe EpicRec is an important step towards designing a practical system that enables companies to monetize on user data using high quality personalized services with strong provable privacy protection to gain user acceptance and adoption of their services.},
  doi       = {10.1145/2976749.2978316},
  isbn      = {9781450341394},
  keywords  = {privacy paradox, privacy-preserving recommendation, differential privacy},
  location  = {Vienna, Austria},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2976749.2978316},
}

@InProceedings{Zheng2016,
  author    = {Zheng, Liang and Joe-Wong, Carlee and Brinton, Christopher G. and Tan, Chee Wei and Ha, Sangtae and Chiang, Mung},
  booktitle = {Proceedings of the 2016 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Science},
  title     = {On the Viability of a Cloud Virtual Service Provider},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {235–248},
  publisher = {Association for Computing Machinery},
  series    = {SIGMETRICS '16},
  abstract  = {Cloud service providers (CSPs) often face highly dynamic user demands for their resources, which can make it difficult for them to maintain consistent quality-of-service. Some CSPs try to stabilize user demands by offering sustained-use discounts to jobs that consume more instance-hours per month. These discounts present an opportunity for users to pool their usage together into a single ``job.'' In this paper, we examine the viability of a middleman, the cloud virtual service provider (CVSP), that rents cloud resources from a CSP and then resells them to users. We show that the CVSP's business model is only viable if the average job runtimes and thresholds for sustained-use discounts are sufficiently small; otherwise, the CVSP cannot simultaneously maintain low job waiting times while qualifying for a sustained-use discount. We quantify these viability conditions by modeling the CVSP's job scheduling and then use this model to derive users' utility-maximizing demands and the CVSP's profit-maximizing price, as well as the optimal number of instances that the CVSP should rent from the CSP. We verify our results on a one-month trace from Google's production compute cluster, through which we first validate our assumptions on the job arrival and runtime distributions, and then show that the CVSP is viable under these workload traces. Indeed, the CVSP can earn a positive profit without significantly impacting the CSP's revenue, indicating that the CSP and CVSP can coexist in the cloud market.},
  doi       = {10.1145/2896377.2901452},
  isbn      = {9781450342667},
  keywords  = {virtual service provider, cloud pricing, economic viability},
  location  = {Antibes Juan-les-Pins, France},
  numpages  = {14},
  url       = {https://doi.org/10.1145/2896377.2901452},
}

@Article{Zheng2016a,
  author     = {Zheng, Liang and Joe-Wong, Carlee and Brinton, Christopher G. and Tan, Chee Wei and Ha, Sangtae and Chiang, Mung},
  journal    = {SIGMETRICS Perform. Eval. Rev.},
  title      = {On the Viability of a Cloud Virtual Service Provider},
  year       = {2016},
  issn       = {0163-5999},
  month      = {jun},
  number     = {1},
  pages      = {235–248},
  volume     = {44},
  abstract   = {Cloud service providers (CSPs) often face highly dynamic user demands for their resources, which can make it difficult for them to maintain consistent quality-of-service. Some CSPs try to stabilize user demands by offering sustained-use discounts to jobs that consume more instance-hours per month. These discounts present an opportunity for users to pool their usage together into a single ``job.'' In this paper, we examine the viability of a middleman, the cloud virtual service provider (CVSP), that rents cloud resources from a CSP and then resells them to users. We show that the CVSP's business model is only viable if the average job runtimes and thresholds for sustained-use discounts are sufficiently small; otherwise, the CVSP cannot simultaneously maintain low job waiting times while qualifying for a sustained-use discount. We quantify these viability conditions by modeling the CVSP's job scheduling and then use this model to derive users' utility-maximizing demands and the CVSP's profit-maximizing price, as well as the optimal number of instances that the CVSP should rent from the CSP. We verify our results on a one-month trace from Google's production compute cluster, through which we first validate our assumptions on the job arrival and runtime distributions, and then show that the CVSP is viable under these workload traces. Indeed, the CVSP can earn a positive profit without significantly impacting the CSP's revenue, indicating that the CSP and CVSP can coexist in the cloud market.},
  address    = {New York, NY, USA},
  doi        = {10.1145/2964791.2901452},
  issue_date = {June 2016},
  keywords   = {cloud pricing, economic viability, virtual service provider},
  numpages   = {14},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2964791.2901452},
}

@InProceedings{Haslwanter2019,
  author    = {Haslwanter, Jean D. Hallewell and Heiml, Michael and Wolfartsberger, Josef},
  booktitle = {Proceedings of the 12th ACM International Conference on PErvasive Technologies Related to Assistive Environments},
  title     = {Lost in Translation: Machine Translation and Text-to-Speech in Industry 4.0},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {333–342},
  publisher = {Association for Computing Machinery},
  series    = {PETRA '19},
  abstract  = {Small lot sizes are becoming more common in modern manufacturing. Rather than automate every possible product variant, companies may rely on manual assembly to be more flexible. However, it can be difficult for people to remember the steps for every possible product variant. Assistive systems providing instructions can support workers. In this paper, we present a study investigating whether existing machine translation and text-to-speech engines provide sufficient quality to enable on-the-fly translations to provide assistance to workers in their native languages. The results of our tests indicate that machine translation is not yet sufficient for this application.},
  doi       = {10.1145/3316782.3322746},
  isbn      = {9781450362320},
  keywords  = {TTS, assistive systems, MT, text to speech, manual assembly, machine translation, computer-assisted instruction},
  location  = {Rhodes, Greece},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3316782.3322746},
}

@InProceedings{Bruechner2019,
  author    = {Bruechner, Dominik and Renz, Jan and Klingbeil, Mandy},
  booktitle = {Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale},
  title     = {Creating a Framework for User-Centered Development and Improvement of Digital Education},
  year      = {2019},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {L@S '19},
  abstract  = {We investigate how the technology acceptance and learning experience of the digital education platform HPI Schul-Cloud (HPI School Cloud) for German secondary school teachers can be improved by proposing a user-centered research and development framework. We highlight the importance of developing digital learning technologies in a user-centered way to take differences in the requirements of educators and students into account. We suggest applying qualitative and quantitative methods to build a solid understanding of a learning platform's users, their needs, requirements, and their context of use. After concept development and idea generation of features and areas of opportunity based on the user research, we emphasize on the application of a multi-attribute utility analysis decision-making framework to prioritize ideas rationally, taking results of user research into account. Afterward, we recommend applying the principle build-learn-iterate to build prototypes in different resolutions while learning from user tests and improving the selected opportunities. Last but not least, we propose an approach for continuous short- and long-term user experience controlling and monitoring, extending existing web- and learning analytics metrics.},
  articleno = {31},
  doi       = {10.1145/3330430.3333644},
  isbn      = {9781450368049},
  keywords  = {HPI Schul-Cloud, user-centered design, learning platform, user research framework, evaluation, user experience},
  location  = {Chicago, IL, USA},
  numpages  = {4},
  url       = {https://doi.org/10.1145/3330430.3333644},
}

@InProceedings{Jaiswal2017,
  author    = {Jaiswal, Akshay and Mishra, R. B.},
  booktitle = {Proceedings of the 2017 International Conference on Machine Learning and Soft Computing},
  title     = {Cloud Service Selection Using TOPSIS and Fuzzy TOPSIS with AHP and ANP},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {136–142},
  publisher = {Association for Computing Machinery},
  series    = {ICMLSC '17},
  abstract  = {The growing demand and availability of cloud services have triggered the need for comparison of their features available to customers at different prices and performance. It is necessary to be said that relevant and fair comparison is still challenging due to diverse deployment options and unique features of different services.The aim of this paper is to rank cloud services based on quantified QoS (Quality of Service) attributes using Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) and fuzzy TOPSIS, and comparing them to find out which method suits more in different scenarios.A comparative study of Analytic Hierarchy Process (AHP) and Analytic Network process (ANP) is also done while extracting the weights of criteria for TOPSIS and fuzzy TOPSIS.},
  doi       = {10.1145/3036290.3036312},
  isbn      = {9781450348287},
  keywords  = {AHP, TOPSIS, Cloud Computing, Multi Attribute Decision Making, ANP, Fuzzy set theory},
  location  = {Ho Chi Minh City, Vietnam},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3036290.3036312},
}

@Article{Setty2018,
  author     = {Setty, Shankar and Mudenagudi, Uma},
  journal    = {J. Comput. Cult. Herit.},
  title      = {Region of Interest-Based 3D Inpainting of Cultural Heritage Artifacts},
  year       = {2018},
  issn       = {1556-4673},
  month      = {may},
  number     = {2},
  volume     = {11},
  abstract   = {In this article, we address the problem of 3D inpainting using an exemplar-based method for point clouds. 3D inpainting is a process of filling holes or missing regions in the reconstructed 3D models. Typically, inpainting methods addressed in the literature fill missing regions due to occlusions or inaccurate scanning of 3D models. However, we focus on scenarios involving naturally existing damaged models, which are partly broken or incomplete in the artifacts at cultural heritage sites. We propose an exemplar-based inpainting technique using the region of interest (ROI)-based method to inpaint the missing regions of the damaged model. The ROI of a 3D model is represented as a set of Riemannian manifolds, and metric tensor and Christoffel symbols are used as geometric features to capture the inherent geometry. We then decompose the ROI into basic shape regions, namely, spherical, conical, and cylindrical components, and identify the best-fit match for inpainting. Instead of using a single similar exemplar for inpainting, we select the most relevant best-fit region to fill the missing region from the basic shape regions library obtained from n similar exemplars. We demonstrate the performance of the proposed inpainting method on artifacts at UNESCO World Heritage site Hampi temples, India with varying complexities and sizes for both synthetically generated holes and real missing regions in 3D objects.},
  address    = {New York, NY, USA},
  articleno  = {9},
  doi        = {10.1145/3131778},
  issue_date = {June 2018},
  keywords   = {point cloud data, region of interest, cultural heritage artifacts, geometric features, 3D inpainting, Riemannian manifolds},
  numpages   = {21},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3131778},
}

@InProceedings{Taheri2018,
  author    = {Taheri, Sajjad and Vedienbaum, Alexander and Nicolau, Alexandru and Hu, Ningxin and Haghighat, Mohammad R.},
  booktitle = {Proceedings of the 9th ACM Multimedia Systems Conference},
  title     = {OpenCV.Js: Computer Vision Processing for the Open Web Platform},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {478–483},
  publisher = {Association for Computing Machinery},
  series    = {MMSys '18},
  abstract  = {The Web is the world's most ubiquitous compute platform and the foundation of digital economy. Ever since its birth in early 1990's, web capabilities have been increasing in both quantity and quality. However, in spite of all such progress, computer vision is not mainstream on the web yet. The reasons are historical and include lack of sufficient performance of JavaScript, lack of camera support in the standard web APIs, and lack of comprehensive computer-vision libraries. These problems are about to get solved, resulting in the potential of an immersive and perceptual web with transformational effects including in online shopping, education, and entertainment among others. This work aims to enable web with computer vision by bringing hundreds of OpenCV functions to the open web platform. OpenCV is the most popular computer-vision library with a comprehensive set of vision functions and a large developer community. OpenCV is implemented in C++ and up until now, it was not available in the web browsers without the help of unpopular native plugins. This work leverage OpenCV efficiency, completeness, API maturity, and its communitys collective knowledge. It is provided in a format that is easy for JavaScript engines to highly optimize and has an API that is easy for the web programmers to adopt and develop applications. In addition, OpenCV parallel implementations that target SIMD units and multiprocessors can be ported to equivalent web primitives, providing better performance for real-time and interactive use cases.},
  doi       = {10.1145/3204949.3208126},
  isbn      = {9781450351928},
  keywords  = {multimedia, web, javascript, performance, computer vision, parallel processing},
  location  = {Amsterdam, Netherlands},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3204949.3208126},
}

@InProceedings{Vanderdonckt2018,
  author    = {Vanderdonckt, Jean and Bouzit, Sara and Calvary, Ga\"{e}lle and Ch\^{e}ne, Denis},
  booktitle = {23rd International Conference on Intelligent User Interfaces},
  title     = {Cloud Menus: A Circular Adaptive Menu for Small Screens},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {317–328},
  publisher = {Association for Computing Machinery},
  series    = {IUI '18},
  abstract  = {This paper presents Cloud Menus, a split adaptive menu for small screens where the predicted menu items are arranged in a circular tag cloud with a location consistent with their corresponding position in the static menu and a font size depending on their prediction level. This layout results from a 3-step design process: (i) defining an initial design space on Bertin's 8 visual variables and 4 quality properties, (ii) identifying the most preferred layout based on agreement rate, and (iii) implementing it into Cloud Menus, a new widget for Android with circular layout. An empirical study suggests that cloud menus reduce item selection time and error rate when prediction is correct without penalizing it when prediction is incorrect, compared to two baselines: a non-adaptive static menu and an adaptive linear menu. From this study, design guidelines for cloud menus are elaborated.},
  doi       = {10.1145/3172944.3172975},
  isbn      = {9781450349451},
  keywords  = {tag cloud, prediction window, split menu, adaptive menu},
  location  = {Tokyo, Japan},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3172944.3172975},
}

@InProceedings{Han2015,
  author    = {Han, Rui and Wang, Junwei and Ge, Fengming and Vazquez-Poletti, Jose Luis and Zhan, Jianfeng},
  booktitle = {Proceedings of the 12th ACM International Conference on Computing Frontiers},
  title     = {SARP: Producing Approximate Results with Small Correctness Losses for Cloud Interactive Services},
  year      = {2015},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {CF '15},
  abstract  = {Despite the importance of providing fluid responsiveness to user requests for interactive services, such request processing is very resource expensive when dealing with large-scale input data. These often exceed the application owners' budget when services are deployed on a cloud, in which resources are charged in monetary terms. Providing approximate processing results is a feasible solution for such problem that trades off request correctness (quantified by output quality) for response time reduction. However, existing techniques in this area either use partial input data or skip expensive computations to produce approximate results, thus resulting in large losses in output quality on a tight resource budget. In this paper, we propose SARP, a Synopsis-based Approximate Request Processing framework to produce approximate results with small correctness losses even using small amount of resources. To achieve this, SARP conducts full computations over the statistical aggregation of the entire input data using two key ideas: (1) offline synopsis management that generates and maintains a set of synopses that represent the statistical aggregation of original input data at different approximation levels. (2) Online synopsis selection that considers both the current resource allocation and the workload status so as to select the synopsis with the maximal length that can be processed within the required response time. We demonstrate the effectiveness of our approach by testing the recommendation services in E-commerce sites using a large, real-world dataset. Using prediction accuracy as the output quality, the results demonstrate: (i) SARP achieves significant response time reduction with very small quality losses compared to the exact processing results.(ii) Using the same processing time, SARP demonstrates a considerable reduction in quality loss compared to existing approximation techniques.},
  articleno = {22},
  doi       = {10.1145/2742854.2742858},
  isbn      = {9781450333580},
  keywords  = {synopsis, interactive service, output quality, approximate results, result correctness, cloud},
  location  = {Ischia, Italy},
  numpages  = {8},
  url       = {https://doi.org/10.1145/2742854.2742858},
}

@InProceedings{Chatterjee2018,
  author    = {Chatterjee, Subarna and Morin, Christine},
  booktitle = {Proceedings of the 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
  title     = {Experimental Study on the Performance and Resource Utilization of Data Streaming Frameworks},
  year      = {2018},
  address   = {Washington, District of Columbia},
  pages     = {143–152},
  publisher = {IEEE Press},
  series    = {CCGrid '18},
  abstract  = {With the advent of the Internet of Things (IoT), data stream processing have gained increased attention due to the ever-increasing need to process heterogeneous and voluminous data streams. This work addresses the problem of selecting a correct stream processing framework for a given application to be executed within a specific physical infrastructure. For this purpose, we focus on a thorough comparative analysis of three data stream processing platforms - Apache Flink, Apache Storm, and Twitter Heron (the enhanced version of Apache Storm), that are chosen based on their potential to process both streams and batches in real-time. The goal of the work is to enlighten the cloud-clients and the cloud-providers with the knowledge of the choice of the resource-efficient and requirement-adaptive streaming platform for a given application so that they can plan during allocation or assignment of Virtual Machines for application execution. For the comparative performance analysis of the chosen platforms, we have experimented using 8-node clusters on Grid5000 experimentation testbed and have selected a wide variety of applications ranging from a conventional benchmark to sensor-based IoT application and statistical batch processing application. In addition to the various performance metrics related to the elasticity and resource usage of the platforms, this work presents a comparative study of the "green-ness" of the streaming platforms by analyzing their power consumption - one of the first attempts of its kind. The obtained results are thoroughly analyzed to illustrate the functional behavior of these platforms under different computing scenarios.},
  doi       = {10.1109/CCGRID.2018.00029},
  isbn      = {9781538658154},
  keywords  = {Apache spark, stream processing, internet of things, Apache flink, Twitter heron},
  numpages  = {10},
  url       = {https://doi.org/10.1109/CCGRID.2018.00029},
}

@InProceedings{Murwantara2014,
  author    = {Murwantara, I Made and Bordbar, Behzad and Minku, Leandro L.},
  booktitle = {Proceedings of the 16th International Conference on Information Integration and Web-Based Applications \&amp; Services},
  title     = {Measuring Energy Consumption for Web Service Product Configuration},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {224–228},
  publisher = {Association for Computing Machinery},
  series    = {iiWAS '14},
  abstract  = {Because of the economies of scale that Cloud provides, there is great interest in hosting web services on the Cloud. Web services are created from components such as Database Management Systems and HTTP servers. There is a wide variety of components that can be used to configure a web service. The choice of components influences the performance and energy consumption. Most current research in the web service technologies focuses on system performance, and only small number of researchers give attention to energy consumption. In this paper, we propose a method to select the web service configurations which reduce energy consumption. Our method has capabilities to manage feature configuration and predict energy consumption of web service systems. To validate, we developed a technique to measure energy consumption of several web service configurations running in a Virtualized environment. Our approach allows Cloud companies to provide choices of web service technology that consumes less energy.},
  doi       = {10.1145/2684200.2684314},
  isbn      = {9781450330015},
  keywords  = {Software Product Line, Web System, Energy Aware, Machine Learning},
  location  = {Hanoi, Viet Nam},
  numpages  = {5},
  url       = {https://doi.org/10.1145/2684200.2684314},
}

@InProceedings{Li2019,
  author    = {Li, Yusen and Shan, Chuxu and Chen, Ruobing and Tang, Xueyan and Cai, Wentong and Tang, Shanjiang and Liu, Xiaoguang and Wang, Gang and Gong, Xiaoli and Zhang, Ying},
  booktitle = {Proceedings of the 28th International Symposium on High-Performance Parallel and Distributed Computing},
  title     = {GAugur: Quantifying Performance Interference of Colocated Games for Improving Resource Utilization in Cloud Gaming},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {231–242},
  publisher = {Association for Computing Machinery},
  series    = {HPDC '19},
  abstract  = {Cloud gaming has been very popular recently, but providing satisfactory gaming experiences to players at a modest cost is still challenging. Colocating several games onto one server could improve server utilization. To enable efficient colocations while providing Quality of Service (QoS) guarantees, a precise quantification of performance interference among colocated games is required. However, achieving such precise interference prediction is very challenging for games due to the complexity introduced by the contention on many shared resources across CPU and GPU. Moreover, the distinctive properties of cloud gaming require that the prediction model should be constructed beforehand and the prediction should be made instantaneously at request arrivals, which further increases the difficulty. The existing solutions are either not applicable or not effective due to many limitations. In this paper, we present GAugur, a novel methodology that enables highly accurate prediction of the performance interference among games arbitrarily colocated. By leveraging machine learning technologies, GAugur is able to capture the complex relationship between the interference and the contention features of colocated games. We evaluate GAugur through extensive experiments using a large number of real popular games. The results show that GAugur is able to identify whether a colocated game satisfies QoS requirement within an average error of 5\%, and is able to quantify the performance degradation of a colocated game within an average error of 7.9\%, which significantly outperforms the alternatives. Moreover, GAugur incurs an offline profiling cost linear to the number of games, and negligible overhead for online prediction. We apply GAugur to guiding efficient game colocations for cloud gaming. Experimental results show that GAugur is able to increase the resource utilization by 20\% to 60\%, and improve the overall performance by up to 15\%, compared to the state-of-the-art solutions.},
  doi       = {10.1145/3307681.3325409},
  isbn      = {9781450366700},
  keywords  = {machine learning, performance prediction, performance interference, game co-location, cloud gaming},
  location  = {Phoenix, AZ, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3307681.3325409},
}

@InProceedings{Maskat2021,
  author    = {Maskat, Ruhaila and Faizzuddin Zainal, Muhammad and Ismail, Nurrissammimayantie and Ardi, Norizah and Ahmad, Amirah and Daud, Noriza},
  booktitle = {Proceedings of the 2020 3rd International Conference on Algorithms, Computing and Artificial Intelligence},
  title     = {Automatic Labelling of Malay Cyberbullying Twitter Corpus Using Combinations of Sentiment, Emotion and Toxicity Polarities},
  year      = {2021},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ACAI '20},
  abstract  = {Automatic labelling is essential in large corpuses. Engaging in human experts to label can be challenging. Semantic understanding can differ from one labeler to another based on individual's language ability. Platforms such as AmazonTurk are not able to ensure the quality of annotations in every domain. Extensive steps such as qualification and counter checking of labels may be implemented which will increase the cost of data annotation. Thus, the higher quality of labelled data expected, the greater the cost that needs to be expended. This scenario is made worse when the language is of low resource where in this work is the Malay language. Malay is a language used mostly in Malaysia, Indonesia, Singapore and Brunei. Unlike English which has large resources to tap into the semantics of sentences, making automatic labelling faster to mature, resources in Malay language are still limited. Further compounded is the use of social media data where the text is short, unnormalized and the inherent presence of code switching. The availability of qualified native Malay labelers is also scarce. To overcome this, we devised a method to automatically label a total of 219,444 Malay tweets by using a combination of sentiment, emotion and toxicity polarities. We extend the work from Arslan et al. who proposed the use of sentiment and emotion to identify cyberbullying text. Our work added toxicity polarity in the context of automatic labelling of cyberbully tweets in Malay. We were able to employ 5 experts with formal degrees in Malay language to label our training set. We applied this method to Malay cyberbullying corpus to determine “bully” and “not bully” labels. We have tested our method on 54,867 manually labelled data and achieved high accuracy.},
  articleno = {85},
  doi       = {10.1145/3446132.3446412},
  isbn      = {9781450388115},
  keywords  = {Twitter, Cyberbullying, Malay language, Automatic labelling},
  location  = {Sanya, China},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3446132.3446412},
}

@InProceedings{Humphrey2019,
  author    = {Humphrey, Marty and Lin, Vincent and Notani, Shweta and Mattos, Jose},
  booktitle = {Proceedings of the 10th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
  title     = {Leveraging the Cloud for Intelligent Clinical Data Registries},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {675–682},
  publisher = {Association for Computing Machinery},
  series    = {BCB '19},
  abstract  = {Public cloud platforms provide an amazing set of capabilities, but it can be an overwhelming challenge to create a design, implementation, and deployment that properly leverages today's existing public cloud capabilities while not precluding the use of near-future new services and infrastructure. We tackle this challenge in the context of clinical data registries, and create Cloud-based Patient Outcomes Platform (CPOP), our scalable public cloud application for clinical patient data. Doctors are able to visualize collected medical data in different chart formats and patients are able to check their data and submit medical survey forms. The specific domain of interest in this paper is Chronic Rhinosinusitis (CRS), a largely under-recognized chronic disease in our society. The primary barrier to quality improvement in CRS is the difficulty in collecting data from patients, tracking appropriate follow-up time intervals, and analyzing outcomes results in a prospective and ongoing fashion. We describe key aspects and design experiences of CPOP-CRS in Amazon Web Services.We also provide quantitative evaluation of a key feature of CPOP-CRS, which is the ability of CRS doctors to upload an audio clip of a doctor-patient interaction, and have the cloud render a text-based representation, and show a word error rate of 15.6\%. We outline next steps in the development of the CPOP/CPOP-CRS, and provide guidance for other users considering the public cloud for their next parallel and cloud-based Bioinformatics and Biomedicine project.},
  doi       = {10.1145/3307339.3343464},
  isbn      = {9781450366663},
  keywords  = {cloud computing, amazon web services, clinical data registries},
  location  = {Niagara Falls, NY, USA},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3307339.3343464},
}

@InProceedings{Bersani2014,
  author    = {Bersani, Marcello M. and Bianculli, Domenico and Dustdar, Schahram and Gambi, Alessio and Ghezzi, Carlo and Krsti\'{c}, Sr\textcrd{}an},
  booktitle = {Proceedings of the 6th International Workshop on Principles of Engineering Service-Oriented and Cloud Systems},
  title     = {Towards the Formalization of Properties of Cloud-Based Elastic Systems},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {38–47},
  publisher = {Association for Computing Machinery},
  series    = {PESOS 2014},
  abstract  = {Cloud-based elastic systems run on a cloud infrastructure and have the capability of dynamically adjusting the allocation of their resources in response to changes in the workload, in a way that balances the trade-off between the desired quality-of-service and the operational costs. The actual elastic behavior of these systems is determined by a combination of factors, including the input workload, the logic of the elastic controller determining the type of resource adjustment, and the underlying technological platform implementing the cloud infrastructure. All these factors have to be taken into account to express the desired elastic behavior of a system, as well as to verify whether the system manifests or not such a behavior.  In this paper, we take a first step into these directions, by proposing a formalization, based on the CLTL^t(D) temporal logic, of several concepts and properties related to the behavior of cloud-based elastic systems. We also report on our preliminary evaluation of the feasibility to check the (formalized) properties on execution traces using an automated verification tool.},
  doi       = {10.1145/2593793.2593798},
  isbn      = {9781450328418},
  keywords  = {elastic systems, temporal logic, Cloud computing},
  location  = {Hyderabad, India},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2593793.2593798},
}

@InProceedings{Liu2015a,
  author    = {Liu, Zhiqing and Liu, Chuangwen and Young, Evangeline F. Y.},
  booktitle = {Proceedings of the 2015 Design, Automation \&amp; Test in Europe Conference \&amp; Exhibition},
  title     = {An Effective Triple Patterning Aware Grid-Based Detailed Routing Approach},
  year      = {2015},
  address   = {San Jose, CA, USA},
  pages     = {1641–1646},
  publisher = {EDA Consortium},
  series    = {DATE '15},
  abstract  = {Triple patterning lithography (TPL) is attracting more and more attention due to further scaling of the critical feature size. How fully the benefits of TPL can be utilized depends very much on both the decomposition and layout steps. However, it is non-trivial to perform detailed routing and layout decomposition simultaneously on a large-scale complicated circuit to achieve decomposability on one hand, and short wirelength, small number of stitches and small number of vias on the other hand. In our approach, routing and coloring are done iteratively but integrated closely to reduce the problem complexity. The routing step is able to detect and avoid native conflicts as much as possible. If any conflicts occur in the coloring step, the router will rip-up and re-route to get rid of them. This technique proves to be effective and efficient in improving the quality of the coloring assignment. Compared with previous works [1] on TPL using simultaneous routing and coloring, the number of stitches and the number of vias are reduced by 76.8\% and 2.1\% respectively while our running time is 36.6\% less and the wirelength is very comparable.},
  isbn      = {9783981537048},
  location  = {Grenoble, France},
  numpages  = {6},
}

@Article{Haller2020,
  author     = {Haller, Armin and Fern\'{a}ndez, Javier D. and Kamdar, Maulik R. and Polleres, Axel},
  journal    = {J. Data and Information Quality},
  title      = {What Are Links in Linked Open Data? A Characterization and Evaluation of Links between Knowledge Graphs on the Web},
  year       = {2020},
  issn       = {1936-1955},
  month      = {may},
  number     = {2},
  volume     = {12},
  abstract   = {Linked Open Data promises to provide guiding principles to publish interlinked knowledge graphs on the Web in the form of findable, accessible, interoperable, and reusable datasets. We argue that while as such, Linked Data may be viewed as a basis for instantiating the FAIR principles, there are still a number of open issues that cause significant data quality issues even when knowledge graphs are published as Linked Data. First, to define boundaries of single coherent knowledge graphs within Linked Data, a principled notion of what a dataset is, or, respectively, what links within and between datasets are, has been missing. Second, we argue that to enable FAIR knowledge graphs, Linked Data misses standardised findability and accessability mechanism via a single entry link. To address the first issue, we (i) propose a rigorous definition of a naming authority for a Linked Data dataset, (ii) define different link types for data in Linked datasets, (iii) provide an empirical analysis of linkage among the datasets of the Linked Open Data cloud, and (iv) analyse the dereferenceability of those links. We base our analyses and link computations on a scalable mechanism implemented on top of the HDT format, which allows us to analyse quantity and quality of different link types at scale.},
  address    = {New York, NY, USA},
  articleno  = {9},
  doi        = {10.1145/3369875},
  issue_date = {June 2020},
  keywords   = {RDF, Linked Data},
  numpages   = {34},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3369875},
}

@InProceedings{Oehmcke2020,
  author    = {Oehmcke, Stefan and Chen, Tzu-Hsin Karen and Prishchepov, Alexander V. and Gieseke, Fabian},
  booktitle = {Proceedings of the 9th ACM SIGSPATIAL International Workshop on Analytics for Big Geospatial Data},
  title     = {Creating Cloud-Free Satellite Imagery from Image Time Series with Deep Learning},
  year      = {2020},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {BigSpatial '20},
  abstract  = {Optical satellite images are important for environmental monitoring. Unfortunately, such images are often affected by distortions, such as clouds, shadows, or missing data. This work proposes a deep learning approach for cleaning and imputing satellite images, which could serve as a reliable preprocessing step for spatial and spatio-temporal analyzes. More specifically, a coherent and cloud-free image for a specific target date and region is created based on a sequence of images of that region obtained at previous dates. Our model first extracts information from the previous time steps via a special gating function and then resorts to a modified version of the well-known U-Net architecture to obtain the desired output image. The model uses supplementary data, namely the approximate cloud coverage of input images, the temporal distance to the target time, and a missing data mask for each input time step. During the training phase we condition our model with the targets cloud coverage and missing values (disabled in production), which allows us to use data afflicted by distortion during training and thus does not require pre-selection of distortion-free data. Our experimental evaluation, conducted on data of the Landsat missions, shows that our approach outperforms the commonly utilized approach that resorts to taking the median of cloud-free pixels for a given position. This is especially the case when the quality of the data for the considered period is poor (e.g., lack of cloud free-images during the winter/fall periods). Our deep learning approach allows to improve the utility of the entire Landsat archive, the only existing global medium-resolution free-access satellite archive dating back to the 1970s. It therefore holds scientific and societal potential for future analyses conducted on data from this and other satellite imagery repositories.},
  articleno = {3},
  doi       = {10.1145/3423336.3429345},
  isbn      = {9781450381628},
  keywords  = {satellite imagery, image reconstruction, remote sensing},
  location  = {Seattle, Washington},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3423336.3429345},
}

@InProceedings{Klomann2018,
  author    = {Klomann, Marcel and Englert, Michael and Weber, Kai and Grimm, Paul and Jung, Yvonne},
  booktitle = {Proceedings of the 23rd International ACM Conference on 3D Web Technology},
  title     = {Improving Mobile MR Applications Using a Cloud-Based Image Segmentation Approach with Synthetic Training Data},
  year      = {2018},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {Web3D '18},
  abstract  = {In this paper, we show how the quality of augmentation in mobile Mixed Reality applications can be improved using a cloud-based image segmentation approach with synthetic training data. Many modern Augmented Reality frameworks are based on visual inertial odometry on mobile devices and therefore have limited access to tracking hardware (e.g., depth sensor). Consequently, tracking still suffers from drift that makes it difficult to utilize in use cases that require a higher precision. To improve tracking quality, we propose a cloud tracking approach that uses machine learning based image segmentation to recognize known objects in a real scene, which allows us to estimate a precise camera pose. Augmented Reality applications that utilize our web service can use the resulting camera pose to correct drift from time to time, while still using local tracking between key frames. Moreover, the device's position in the real world, when starting the application, is usually used as reference coordinate system. Therefore, we simplify the authoring of MR applications significantly due to a well-defined coordinate system, which is context-based and not dependend on the starting position of a user. We present all steps from web-based initialization over the generation of synthetic training data up to usage in production. In addition, we describe the underlying algorithms in detail. Finally, we show a mobile Mixed Reality application, which is based on this novel approach and discuss its advantages.},
  articleno = {4},
  doi       = {10.1145/3208806.3208813},
  isbn      = {9781450358002},
  keywords  = {mobile mixed reality, AR authoring, computer vision, tracking, training data generation, image segmentation, machine learning},
  location  = {Pozna\'{n}, Poland},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3208806.3208813},
}

@InProceedings{Hanafy2021,
  author    = {Hanafy, Walid A. and Molom-Ochir, Tergel and Shenoy, Rohan},
  booktitle = {Proceedings of the Twelfth ACM International Conference on Future Energy Systems},
  title     = {Design Considerations for Energy-Efficient Inference on Edge Devices},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {302–308},
  publisher = {Association for Computing Machinery},
  series    = {e-Energy '21},
  abstract  = {The emergence of low-power accelerators has enabled deep learning models to be executed on mobile or embedded edge devices without relying on cloud resources. The energy-constrained nature of these devices requires a judicious choice of a deep learning model and system configuration parameter to meet application needs while optimizing energy used during deep learning inference.In this paper, we carry out an experimental evaluation of more than 40 popular pretrained deep learning models to characterize trends in their accuracy, latency, and energy when running on edge accelerators. Our results show that as models have grown in size, the marginal increase in their accuracy has come at a much higher energy cost. Consequently, simply choosing the most accurate model for an application task comes at a higher energy cost; the application designer needs to consider the tradeoff between latency, accuracy, and energy use to make an appropriate choice. Since the relation between these metrics is non-linear, we present a recommendation algorithm to enable application designers to choose the best deep learning model for an application that meets energy budget constraints. Our results show that our technique can provide recommendations that are within 3 to 7\% of the specified budget while maximizing accuracy and minimizing energy.},
  doi       = {10.1145/3447555.3465326},
  isbn      = {9781450383332},
  keywords  = {Deep learning Inference, Edge Computing, Energy-efficient Deep Learning},
  location  = {Virtual Event, Italy},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3447555.3465326},
}

@InProceedings{Baldoni2021,
  author    = {Baldoni, Gabriele and Loudet, Julien and Cominardi, Luca and Corsaro, Angelo and He, Yong},
  booktitle = {Proceedings of the 1st Workshop on Serverless Mobile Networking for 6G Communications},
  title     = {Facilitating Distributed Data-Flow Programming with Eclipse Zenoh: The ERDOS Case},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {13–18},
  publisher = {Association for Computing Machinery},
  series    = {MobileServerless'21},
  abstract  = {Data-flow programming is the computational model of choice for a large class of application domains, such as, real-time data processing, robotics platforms, and big-data analytics. Traditionally, dataflows are deployed and executed within well-defined system boundaries, such as robots, radars, or data-centers. These boundaries however are expected to blur with the advent of Edge Computing, which provides a multi-tier infrastructure spanning from the cloud to the things and enables for the distribution of applications across this continuum. In this paper we make a step towards the design of an Edge-native data-flow by mixing technologies coming from both worlds: ERDOS, a novel data-flow framework, and Eclipse Zenoh, a Named-Data-Networking built for the Edge Computing. More specifically, we (i) investigate how ERDOS can be expanded to cover Edge deployments by leveraging Zenoh, (ii) analyze the advantages provided by this integration, and (iii) evaluate the performance of a Zenoh-powered ERDOS. Our results show that ERDOS experiences a higher throughput and bounded latency when operating over Zenoh. Moreover, Zenoh enhances ERDOS with full location transparency, allowing developers and system designers to focus on the logic of their application as opposed to the topology deployment. Finally, our integration of Zenoh and ERDOS is available as open source at https://github.com/atolab/erdos-on-zenoh.},
  doi       = {10.1145/3469263.3469858},
  isbn      = {9781450386036},
  keywords  = {serverless, zenoh, ERDOS, data-flow, FaaS, NDN},
  location  = {Virtual, WI, USA},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3469263.3469858},
}

@Article{Zhang2021d,
  author     = {Zhang, Sheng and Wang, Can and Jin, Yibo and Wu, Jie and Qian, Zhuzhong and Xiao, Mingjun and Lu, Sanglu},
  journal    = {IEEE/ACM Trans. Netw.},
  title      = {Adaptive Configuration Selection and Bandwidth Allocation for Edge-Based Video Analytics},
  year       = {2021},
  issn       = {1063-6692},
  month      = {aug},
  number     = {1},
  pages      = {285–298},
  volume     = {30},
  abstract   = {Major cities worldwide have millions of cameras deployed for surveillance, business intelligence, traffic control, crime prevention, etc. Real-time analytics on video data demands intensive computation resources and high energy consumption. Traditional cloud-based video analytics relies on large centralized clusters to ingest video streams. With edge computing, we can offload compute-intensive analysis tasks to nearby servers, thus mitigating long latency incurred by data transmission via wide area networks. When offloading video frames from the front-end device to an edge server, the application configuration (i.e., frame sampling rate and frame resolution) will impact several metrics, such as energy consumption, analytics accuracy and user-perceived latency. In this paper, we study the configuration selection and bandwidth allocation for multiple video streams, which are connected to the same edge node sharing an upload link. We propose an efficient online algorithm, called JCAB, which jointly optimizes configuration adaption and bandwidth allocation to address a number of key challenges in edge-based video analytics systems, including edge capacity limitation, unknown network variation, intrusive dynamics of video contents. Our algorithm is developed based on Lyapunov optimization and Markov approximation, works online without requiring future information, and achieves a provable performance bound. We also extend the proposed algorithms to the multi-edge scenario in which each user or video stream has an additional choice about which edge server to connect. Extensive evaluation results show that the proposed solutions can effectively balance the analytics accuracy and energy consumption while keeping low system latency in a variety of settings.},
  doi        = {10.1109/TNET.2021.3106937},
  issue_date = {Feb. 2022},
  numpages   = {14},
  publisher  = {IEEE Press},
  url        = {https://doi.org/10.1109/TNET.2021.3106937},
}

@InProceedings{Arnold2019,
  author    = {Arnold, Todd and Calder, Matt and Cunha, Italo and Gupta, Arpit and Madhyastha, Harsha V. and Schapira, Michael and Katz-Bassett, Ethan},
  booktitle = {Proceedings of the 18th ACM Workshop on Hot Topics in Networks},
  title     = {Beating BGP is Harder than We Thought},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {9–16},
  publisher = {Association for Computing Machinery},
  series    = {HotNets '19},
  abstract  = {Online services all seek to provide their customers with the best Quality of Experience (QoE) possible. Milliseconds of delay can cause users to abandon a cat video or move onto a different shopping site, which translates into lost revenue. Thus, minimizing latency between users and content is crucial. To reduce latency, content and cloud providers have built massive, global networks. However, their networks must interact with customer ISPs via BGP, which has no concept of performance.The shortcomings of BGP are many and well documented, but in this paper we ask the community to take a step back and rethink what we know about BGP. We examine three separate studies of performance using large content and cloud provider networks and find that performance-aware routing schemes rarely achieve lower latency than BGP. We lay out a map for research to further study the idea that beating BGP may be more difficult than previously thought.},
  doi       = {10.1145/3365609.3365865},
  isbn      = {9781450370202},
  keywords  = {BGP, performance, content delivery, traffic engineering},
  location  = {Princeton, NJ, USA},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3365609.3365865},
}

@InProceedings{Mazumdar2017,
  author    = {Mazumdar, Amrita and Alaghi, Armin and Barron, Jonathan T. and Gallup, David and Ceze, Luis and Oskin, Mark and Seitz, Steven M.},
  booktitle = {Proceedings of High Performance Graphics},
  title     = {A Hardware-Friendly Bilateral Solver for Real-Time Virtual Reality Video},
  year      = {2017},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {HPG '17},
  abstract  = {Rendering 3D-360° VR video from a camera rig is computation-intensive and typically performed offline. In this paper, we target the most time-consuming step of the VR video creation process, high-quality flow estimation with the bilateral solver. We propose a new algorithm, the hardware-friendly bilateral solver, that enables faster runtimes than existing algorithms of similar quality. Our algorithm is easily parallelized, achieving a 4\texttimes{} speedup on CPU and 32\texttimes{} speedup on GPU over a baseline CPU implementation. We also design an FPGA-based hardware accelerator that utilizes reduced-precision computation and the parallelism inherent in our algorithm to achieve further speedups over our CPU and GPU implementations while consuming an order of magnitude less power. The FPGA design's power efficiency enables practical real-time VR video processing at the camera rig or in the cloud.},
  articleno = {13},
  doi       = {10.1145/3105762.3105772},
  isbn      = {9781450351010},
  keywords  = {hardware accelerators, parallelism, FPGA design, GPU algorithm, virtual reality, real-time image processing},
  location  = {Los Angeles, California},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3105762.3105772},
}

@InProceedings{Grassi2017,
  author    = {Grassi, Giulio and Jamieson, Kyle and Bahl, Paramvir and Pau, Giovanni},
  booktitle = {Proceedings of the Second ACM/IEEE Symposium on Edge Computing},
  title     = {Parkmaster: An in-Vehicle, Edge-Based Video Analytics Service for Detecting Open Parking Spaces in Urban Environments},
  year      = {2017},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {SEC '17},
  abstract  = {We present the design and implementation of ParkMaster, a system that leverages the ubiquitous smartphone to help drivers find parking spaces in the urban environment. ParkMaster estimates parking space availability using video gleaned from drivers' dash-mounted smartphones on the network's edge, uploading analytics about the street to the cloud in real time as participants drive. Novel lightweight parked-car localization algorithms enable the system to estimate each parked car's approximate location by fusing information from phone's camera, GPS, and inertial sensors, tracking and counting parked cars as they move through the driving car's camera frame of view. To visually calibrate the system, ParkMaster relies only on the size of well-known objects in the urban environment for on-the-go calibration. We implement and deploy ParkMaster on Android smartphones, uploading parking analytics to the Azure cloud. On-the-road experiments in three different environments comprising Los Angeles, Paris and an Italian village measure the end-to-end accuracy of the system's parking estimates (close to 90\%) as well as the amount of cellular data usage the system requires (less than one mega-byte per hour). Drill-down microbenchmarks then analyze the factors contributing to this end-to-end performance, as video resolution, vision algorithm parameters, and CPU resources.},
  articleno = {16},
  doi       = {10.1145/3132211.3134452},
  isbn      = {9781450350877},
  keywords  = {fog computing, mobile systems, edge computing, visual analytics},
  location  = {San Jose, California},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3132211.3134452},
}

@InProceedings{Zhang2021e,
  author    = {Zhang, Yuxi and Xie, Kexin},
  booktitle = {Proceedings of the 15th ACM Conference on Recommender Systems},
  title     = {Boosting Local Recommendations With Partially Trained Global Model},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {533–535},
  publisher = {Association for Computing Machinery},
  series    = {RecSys '21},
  abstract  = {Building recommendation systems for enterprise software has many unique challenges that are different from consumer-facing systems. When applied to different organizations, the data used to power those recommendation systems vary substantially in both quality and quantity due to differences in their operational practices, marketing strategies, and targeted audiences. At Salesforce, as a cloud provider of such a system with data across many different organizations, naturally, it makes sense to pool data from different organizations to build a model that combines all values from different brands. However, multiple issues like how do we make sure a model trained with pooled data can still capture customer specific characteristics, how do we design the system to handle those data responsibly and ethically, i.e., respecting contractual agreements with our clients, legal and compliance requirements, and the privacy of all the consumers. In this proposal, We present a framework that not only utilizes enriched user-level data across organizations, but also boosts business-specific characteristics in generating personal recommendations. We will also walk through key privacy considerations when designing such a system.},
  doi       = {10.1145/3460231.3474615},
  isbn      = {9781450384582},
  keywords  = {global model, recommendation system, privacy},
  location  = {Amsterdam, Netherlands},
  numpages  = {3},
  url       = {https://doi.org/10.1145/3460231.3474615},
}

@InProceedings{Kyzirakos2016,
  author    = {Kyzirakos, Kostis and Alvanaki, Foteini and Kersten, Martin},
  booktitle = {Proceedings of the 12th International Workshop on Data Management on New Hardware},
  title     = {In Memory Processing of Massive Point Clouds for Multi-Core Systems},
  year      = {2016},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {DaMoN '16},
  abstract  = {LIDAR is a popular remote sensing method used to examine the surface of the Earth. LIDAR instruments use light in the form of a pulsed laser to measure ranges (variable distances) and generate vast amounts of precise three dimensional point data describing the shape of the Earth. Processing large collections of point cloud data and combining them with auxiliary GIS data remain an open research problem.Past research in the area of geographic information systems focused on handling large collections of complex geometric objects stored on disk and most algorithms have been designed and studied in a single-thread setting even though multi-core systems are well established. In this paper, we describe parallel alternatives of known algorithms for evaluating spatial selections over point clouds and spatial joins between point clouds and rectangle collections.},
  articleno = {7},
  doi       = {10.1145/2933349.2933356},
  isbn      = {9781450343190},
  location  = {San Francisco, California},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2933349.2933356},
}

@InProceedings{Ullah2016,
  author    = {Ullah, Amjad},
  booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},
  title     = {Towards Workload-Aware Fine-Grained Control over Cloud Resources: Student Research Abstract},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {488–489},
  publisher = {Association for Computing Machinery},
  series    = {SAC '16},
  abstract  = {The systems deployed over cloud are subject to unpredictable workload conditions that vary from time to time, e.g. an ecommerce website may face higher workloads than normal during festivals or promotional schemes. In order to maintain the performance of such systems, an efficient elastic resource provisioning strategy is required. However, providing such a strategy that determines the right amount of cloud resources that fulfills the Quality of Service (QoS) demand is a challenging task. Over the period, many proposals have been introduced using techniques like threshold based rules, reinforcement learning and control theory, etc. The existing proposals, however, suffer from issues like lack of expertise to appropriately set the quantitative specification of thresholds, online training time overhead of the algorithm, too specific to work well in particular situation like when there is sudden burst in workload or work well in nominal conditions for stable workload, etc. Moreover, the existing approaches do not address uncertainty. Our proposed framework is a step forward to address the mentioned issues for systems that hold time varying workload conditions.},
  doi       = {10.1145/2851613.2852009},
  isbn      = {9781450337397},
  location  = {Pisa, Italy},
  numpages  = {2},
  url       = {https://doi.org/10.1145/2851613.2852009},
}

@InProceedings{Frieder2021,
  author    = {Frieder, Ophir},
  booktitle = {Proceedings of the 21st ACM Symposium on Document Engineering},
  title     = {Searching Harsh Documents},
  year      = {2021},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {DocEng '21},
  abstract  = {Conventional, textual document search is arguably well understood. Traditional and modern (neural) algorithms are available; benchmark collections and evaluation metrics are prevalent. However, not all documents are conventional or purely textual. We explore what is takes to search "harsh" document collections. Such collections comprise potentially of documents that are natively non-digital, are multilingual, include components that are not strictly textual, are corrupted, or are a combination thereof. We address machine readability and its implication on search. We overview component segmentation and integration as a search process. We describe the processing of search queries that are informationally deficient or corrupt. We then comment on the evaluation of the selected efforts presented and highlight their history from concept to practice. We conclude with a brief commentary on ongoing efforts.},
  articleno = {4},
  doi       = {10.1145/3469096.3469864},
  isbn      = {9781450385961},
  keywords  = {enhancement, non-digital text processing, benchmarks, corrupted text},
  location  = {Limerick, Ireland},
  numpages  = {1},
  url       = {https://doi.org/10.1145/3469096.3469864},
}

@InProceedings{Pravato2017,
  author    = {Pravato, Laura and Doyle, Thomas E.},
  booktitle = {Proceedings of the 27th Annual International Conference on Computer Science and Software Engineering},
  title     = {IoT for Remote Wireless Electrophysiological Monitoring: Proof of Concept},
  year      = {2017},
  address   = {USA},
  pages     = {254–258},
  publisher = {IBM Corp.},
  series    = {CASCON '17},
  abstract  = {The Internet of Things (IoT) offers integrated sensing of all aspects of daily life. The field of healthcare offers the greatest potential for IoT to benefit society, but also presents significant challenges. A key component of IoT is the development of intelligent ubiquitous sensing. Achieving this requires circuits and systems that require low power and efficient computation.As a proof of concept, we present a prototype design of a continuous wireless electrocardiogram (ECG) monitoring device that uses a small, low-cost IoT wi-fi module to upload real-time data to the cloud. Two IoT cloud services were evaluated to record and plot real-time ECG data: IBM Bluemix and ThingSpeak. Preliminary data quality was analyzed using kurtosis and spectral distribution ratio. Future development is necessary to improve battery power and to implement real-time data analysis.Remote medical and health monitoring is an important step in supporting personalized predictive analytics, smart homes, and chronic illness management. The presented device has the potential to provide health professionals with real-time ECG data allowing for diagnosis of cardiac pathologies, monitoring of patients suffering from heart disease and/or patients recovering from cardiac conditions.},
  keywords  = {electrocardiogram, wearables, ESP32, IBM watson, IBM Bluemix, ECG, ThingSpeak, ESP8266, IoT, internet of things},
  location  = {Markham, Ontario, Canada},
  numpages  = {5},
}

@InProceedings{CaballeroGil2018,
  author    = {Caballero-Gil, Pino and Caballero-Gil, C\'{a}ndido and Molina-Gil, Jezabel},
  booktitle = {Proceedings of the 15th ACM International Symposium on Performance Evaluation of Wireless Ad Hoc, Sensor, \&amp; Ubiquitous Networks},
  title     = {Ubiquitous System to Monitor Transport and Logistics},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {71–75},
  publisher = {Association for Computing Machinery},
  series    = {PE-WASUN'18},
  abstract  = {In the management of transport and logistics, which includes the delivery, movement and collection of goods through roads, ports and airports, participate, in general, many different actors. The most critical aspects of supply chain systems include time, space and interdependencies. Besides, there are several security challenges that can be caused both by unintentional and intentional errors. With all this in mind, this work proposes the combination of technologies such as RFID, GPS, WiFi Direct and LTE/3G to automate product authentication and merchandise tracking, reducing the negative effects caused either by mismanagement or attacks against the process of the supply chain. In this way, this work proposes a ubiquitous management scheme for the monitoring through the cloud of freight and logistics systems, including demand management, customization and automatic replenishment of out-of-stock goods. The proposal implies an improvement in the efficiency of the systems, which can be quantified in a reduction of time and cost in the inventory and distribution processes, and in a greater facility for the detection of counterfeit versions of branded articles. In addition, it can be used to create safer and more efficient schemes that help companies and organizations to improve the quality of the service and the traceability of the transported goods.},
  doi       = {10.1145/3243046.3243049},
  isbn      = {9781450359610},
  keywords  = {ubiquitous system, security, logistics, wireless technologies},
  location  = {Montreal, QC, Canada},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3243046.3243049},
}

@Article{Kaur2021,
  author     = {Kaur, Kuljeet and Garg, Sahil and Kaddoum, Georges and Kumar, Neeraj},
  journal    = {ACM Trans. Internet Technol.},
  title      = {Energy and SLA-Driven MapReduce Job Scheduling Framework for Cloud-Based Cyber-Physical Systems},
  year       = {2021},
  issn       = {1533-5399},
  month      = {may},
  number     = {2},
  volume     = {21},
  abstract   = {Energy consumption minimization of cloud data centers (DCs) has attracted much attention from the research community in the recent years; particularly due to the increasing dependence of emerging Cyber-Physical Systems on them. An effective way to improve the energy efficiency of DCs is by using efficient job scheduling strategies. However, the most challenging issue in selection of efficient job scheduling strategy is to ensure service-level agreement (SLA) bindings of the scheduled tasks. Hence, an energy-aware and SLA-driven job scheduling framework based on MapReduce is presented in this article. The primary aim of the proposed framework is to explore task-to-slot/container mapping problem as a special case of energy-aware scheduling in deadline-constrained scenario. Thus, this problem can be viewed as a complex multi-objective problem comprised of different constraints. To address this problem efficiently, it is segregated into three major subproblems (SPs), namely, deadline segregation, map and reduce phase energy-aware scheduling. These SPs are individually formulated using Integer Linear Programming. To solve these SPs effectively, heuristics based on Greedy strategy along with classical Hungarian algorithm for serial and serial-parallel systems are used. Moreover, the proposed scheme also explores the potential of splitting Map/Reduce phase(s) into multiple stages to achieve higher energy reductions. This is achieved by leveraging the concepts of classical Greedy approach and priority queues. The proposed scheme has been validated using real-time data traces acquired from OpenCloud. Moreover, the performance of the proposed scheme is compared with the existing schemes using different evaluation metrics, namely, number of stages, total energy consumption, total makespan, and SLA violated. The results obtained prove the efficacy of the proposed scheme in comparison to the other schemes under different workload scenarios.},
  address    = {New York, NY, USA},
  articleno  = {31},
  doi        = {10.1145/3409772},
  issue_date = {June 2021},
  keywords   = {energy optimization, and MapReduce, Hungarian algorithm, Cyber-physical systems, greedy approach, job scheduling},
  numpages   = {24},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3409772},
}

@InProceedings{Glatard2014,
  author    = {Glatard, Tristan and Rousseau, Marc-Etienne and Rioux, Pierre and Adalat, Reza and Evans, Alan C.},
  booktitle = {Proceedings of the 14th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
  title     = {Controlling the Deployment of Virtual Machines on Clusters and Clouds for Scientific Computing in CBRAIN},
  year      = {2014},
  address   = {Chicago, Illinois},
  pages     = {384–393},
  publisher = {IEEE Press},
  series    = {CCGRID '14},
  abstract  = {The emergence of hardware virtualization, notably exploited by cloud infrastructures, led to a paradigm shift in distributed computing by enabling complete software customization and elastic scaling of resources. However, new software architectures and deployment algorithms are still required to fully exploit virtualization in web platforms used for scientific computing, commonly called science gateways. We propose a software architecture and an algorithm to enable and optimize the deployment of virtual machines on clusters and clouds in science gateways. Our architecture is based on 3 design principles: (i) separation between resource provisioning and task scheduling (ii) encapsulation of VMs in regular computing tasks (iii) association of a virtual computing site to each disk image. Our algorithm submits and removes VMs on clusters and clouds based on the current system workload, the number of available job slots in active VMs, the cost and current performance of clouds clusters, and a parameter quantifying the performance-cost trade-off. To cope with variable queuing and booting times, it replicates VMs on independent computing sites selected from a minimization of a makespan-cost linear combination in the Pareto set of non-dominated solutions. Makespan and cost are estimated from the last measured queuing, booting, and task execution times, using an exponential model of the gain yielded by VM replication. We implement this algorithm in CBRAIN, a science gateway widely used for neuroimaging, and we evaluate it on an infrastructure of 2 clusters and 1 cloud. Results show that it is able to reach some points of the performance-cost trade-off associated to VM deployment.},
  doi       = {10.1109/CCGrid.2014.42},
  isbn      = {9781479927838},
  numpages  = {10},
  url       = {https://doi.org/10.1109/CCGrid.2014.42},
}

@InProceedings{Bondi2020,
  author    = {Bondi, Andr\'{e} B.},
  booktitle = {Companion of the ACM/SPEC International Conference on Performance Engineering},
  title     = {WOSP-C 2020: Workshop on Challenges and Opportunities in Large-Scale Performance: Welcoming Remarks},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {5–6},
  publisher = {Association for Computing Machinery},
  series    = {ICPE '20},
  abstract  = {It is my great pleasure to welcome you to WOSP-C 2020, the Workshop on Challenges and Opportunities in Large Scale Performance. Our theme this year relates to the use of analytics to interpret system performance and resource usage measurements that can now be gathered rapidly on a large scale. Our four invited speakers hail from industry. All three presentations in the first session and the last presentation in the second session deal with modeling and measurement to automate the making of decisions about system configuration or the recognition of anomalies, especially for cloud-based systems. The other two papers in the second session address measurement and modeling issues at a granular level. These topics are highly relevant to the issues systems architects and other stakeholders face when deploying systems in the cloud, because doing so need not guarantee good performance. The recent emergence of the ability to gather vast numbers of performance and resource usage measurements facilitates the informed choice of target cloud platforms and their configurations. The presentations in this workshop deal with various aspects of how this can be achieved.},
  doi       = {10.1145/3375555.3384939},
  isbn      = {9781450371094},
  keywords  = {cloud measurement, monitoring and tuning, software performance engineering, automated system performance modeling},
  location  = {Edmonton AB, Canada},
  numpages  = {2},
  url       = {https://doi.org/10.1145/3375555.3384939},
}

@InProceedings{Jin2019,
  author    = {Jin, Yuchen and Renganathan, Sundararajan and Ananthanarayanan, Ganesh and Jiang, Junchen and Padmanabhan, Venkata N. and Schroder, Manuel and Calder, Matt and Krishnamurthy, Arvind},
  booktitle = {Proceedings of the ACM Special Interest Group on Data Communication},
  title     = {Zooming in on Wide-Area Latencies to a Global Cloud Provider},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {104–116},
  publisher = {Association for Computing Machinery},
  series    = {SIGCOMM '19},
  abstract  = {The network communications between the cloud and the client have become the weak link for global cloud services that aim to provide low latency services to their clients. In this paper, we first characterize WAN latency from the viewpoint of a large cloud provider Azure, whose network edges serve hundreds of billions of TCP connections a day across hundreds of locations worldwide. In particular, we focus on instances of latency degradation and design a tool, BlameIt, that enables cloud operators to localize the cause (i.e., faulty AS) of such degradation. BlameIt uses passive diagnosis, using measurements of existing connections between clients and the cloud locations, to localize the cause to one of cloud, middle, or client segments. Then it invokes selective active probing (within a probing budget) to localize the cause more precisely. We validate BlameIt by comparing its automatic fault localization results with that arrived at by network engineers manually, and observe that BlameIt correctly localized the problem in all the 88 incidents. Further, BlameIt issues 72X fewer active probes than a solution relying on active probing alone, and is deployed in production at Azure.},
  doi       = {10.1145/3341302.3342073},
  isbn      = {9781450359566},
  keywords  = {networkfault localization, network diagnosis, tomography, active network probes, internet latency measurement, wide-area network},
  location  = {Beijing, China},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3341302.3342073},
}

@InProceedings{Devaux2016,
  author    = {Devaux, Alexandre and Br\'{e}dif, Mathieu},
  booktitle = {Proceedings of the 21st International Conference on Web3D Technology},
  title     = {Realtime Projective Multi-Texturing of Pointclouds and Meshes for a Realistic Street-View Web Navigation},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {105–108},
  publisher = {Association for Computing Machinery},
  series    = {Web3D '16},
  abstract  = {Street-view web applications have now gained widespread popularity. Targeting the general public, they offer ease of use, but while they allow efficient navigation from a pedestrian level, the immersive quality of such renderings is still low. The user is usually stuck at specific positions and transitions bring out artefacts, in particular parallax and aliasing. We propose a method to enhance the realism of street view navigation systems using a hybrid rendering based on realtime projective texturing on meshes and pointclouds with occlusion handling, requiring extremely minimized pre-processing steps allowing fast data update, progressive streaming (mesh-based approximation, with point cloud details) and unaltered raw data precise visualization.},
  doi       = {10.1145/2945292.2945311},
  isbn      = {9781450344289},
  keywords  = {image based rendering, GIS, projective texturing, WebGL, street-view, point based rendering},
  location  = {Anaheim, California},
  numpages  = {4},
  url       = {https://doi.org/10.1145/2945292.2945311},
}

@InProceedings{Mao2020,
  author    = {Mao, Deng and Jie, Liu},
  booktitle = {Proceedings of the 2020 International Conference on Aviation Safety and Information Technology},
  title     = {Streak Image Compression},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {450–454},
  publisher = {Association for Computing Machinery},
  series    = {ICASIT 2020},
  abstract  = {This Streak image contains a lot of noise signals and it is not easy to accurately detect the target signal position. This article gives a method of determining target signal region and achieving streak image compression, which uses multi-resolution wavelet denoising and detecting target signal considering its overall continuous distribution as a rule and using the stepped-like piecewise function of range as the detection object. In target signal region, convolution filtering is used to detect the peaks, and then the three-dimensional image is calculated. Experiments show that the method can reduce the scale of data for computing, improve the quality of generating point cloud data and reconstruct 3D images more accurately.},
  doi       = {10.1145/3434581.3434632},
  isbn      = {9781450375764},
  keywords  = {stepped-like piecewise function, overall continuous distribution, Streak image compression, target signal},
  location  = {Weihai City, China},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3434581.3434632},
}

@InProceedings{M.Pittman2021,
  author    = {M. Pittman, Jason},
  booktitle = {Proceedings of the 5th Conference on Computing Education Practice},
  title     = {DRAT - A Dynamic Resource Allocation Tool for Estimating Compute Power in a Cybersecurity Engineering Learning Facility},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {39},
  publisher = {Association for Computing Machinery},
  series    = {CEP '21},
  abstract  = {Cybersecurity laboratory infrastructure has direct impact on the quality of student learning experiences. Because of this, the computing education field has developed a variety of approaches to designing and implementing these learning facilities. Yet, little work has gone into how to properly size cybersecurity laboratory infrastructure relative to student population and curricular compute power demands. The result has been laboratory infrastructures that do not scale with degree programs. Consequently, laboratories are either underpowered, thus limiting learning experiences, or overpowered which wastes financial resources. Accordingly, this work presents DRAT, an open-source software tool, for estimating necessary compute power in a cybersecurity engineering learning facility. More specifically, DRAT is designed to estimate the required discrete compute power on a per exercise basis in a cybersecurity engineering learning facility operating in a private cloud model. Such discrete estimations are intended to communicate physical host hardware requirements such as physical CPU core count, virtual RAM, and total Hard Disk space. The first step in designing DRAT was to forge a model estimator function. Then, we identified a series of scalar abstractions representing learning facility hardware infrastructure and behaving as conversion factors between the model function and output. Because the goal of this work was to provide estimates for cloud compute power requirements, DRAT outputs the number of physical cores, total RAM, total Disk, and total (virtual or physical) Network interfaces required to run the indicated scenario. The implication is that such estimates can inform purchasing and configuration decisions which directly impact student learning outcomes.},
  doi       = {10.1145/3437914.3437980},
  isbn      = {9781450389594},
  location  = {<conf-loc>, <city>Durham</city>, <country>United Kingdom</country>, </conf-loc>},
  numpages  = {1},
  url       = {https://doi.org/10.1145/3437914.3437980},
}

@InProceedings{Xhagjika2017,
  author    = {Xhagjika, Vamis and Escoda, \`{O}scar Divorra and Navarro, Leandro and Vlassov, Vladimir},
  booktitle = {Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
  title     = {Load and Video Performance Patterns of a Cloud Based WebRTC Architecture},
  year      = {2017},
  address   = {Madrid, Spain},
  pages     = {739–744},
  publisher = {IEEE Press},
  series    = {CCGrid '17},
  abstract  = {Web Real-Time Communication or Realtime communication in the Web (WebRTC/RTCWeb) is a prolific new standard and technology stack, providing full audio/video agnostic communications for the Web. Service providers implementing such technology deal with various levels of complexity ranging anywhere from: high service distribution, multiclient integration, P2P and Cloud assisted communication backends, content delivery, real-time constraints and across clouds resource allocation. This work presents a study of the joint factors including multi-cloud distribution, network performance, media parameters and back-end resource loads, in Cloud based Media Selective Forwarding Units for WebRTC infrastructures. The monitored workload is sampled from a large population of real users of our testing infrastructure, additionally the performance data is sampled both by passive user measurements as well as server side measurements. Patterns correlating such factors enable designing adaptive resource allocation algorithms and defining media Service Level Objectives (SLO) spanning over multiple data-centers or servers. Based on our analysis, we discover strong periodical load patterns even though the nature of user interaction with the system is mostly not predetermined with variable user churn.},
  doi       = {10.1109/CCGRID.2017.118},
  isbn      = {9781509066100},
  keywords  = {media, webrtc, stream allocation, load measurements, bitrate, rtp/rtcp},
  numpages  = {6},
  url       = {https://doi.org/10.1109/CCGRID.2017.118},
}

@InProceedings{Silva2020a,
  author    = {da Silva, Gabriela Oliveira Mota and Dur\~{a}o, Frederico Ara\'{u}jo and Capretz, Miriam},
  booktitle = {Proceedings of the 21st International Conference on Information Integration and Web-Based Applications \&amp; Services},
  title     = {PLDSD: Personalized Linked Data Semantic Distance for LOD-Based Recommender Systems},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {294–303},
  publisher = {Association for Computing Machinery},
  series    = {iiWAS2019},
  abstract  = {A vast amount of data that can be easily read by machines have been published in freely accessible and interconnected datasets, creating the so-called Linked Open Data cloud. This phenomenon has opened opportunities for the development of semantic applications, including recommender systems. In this paper, we propose Personalized Linked Data Semantic Distance (PLDSD), a novel similarity measure for linked data that personalizes the RDF graph by adding weights to the edges, based on previous user's choices. Thus, our approach has the purpose of minimizing the sparsity problem by ranking the best features for a particular user, and also, of solving the item cold-start problem, since the feature ranking task is based on features shared between old items and the new item. We evaluate PLDSD in the context of a LOD-based Recommender System using mixed data from DBpedia and MovieLens, and the experimental results indicate better accuracy of recommendations compared to a non-personalized baseline similarity method.},
  doi       = {10.1145/3366030.3366041},
  isbn      = {9781450371797},
  keywords  = {Semantic Similarity, Linked Open Data, Feature Selection, Recommender Systems, Graph Personalization},
  location  = {Munich, Germany},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3366030.3366041},
}

@InProceedings{Kim2014,
  author    = {Kim, Suin and Weber, Ingmar and Wei, Li and Oh, Alice},
  booktitle = {Proceedings of the 25th ACM Conference on Hypertext and Social Media},
  title     = {Sociolinguistic Analysis of Twitter in Multilingual Societies},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {243–248},
  publisher = {Association for Computing Machinery},
  series    = {HT '14},
  abstract  = {In a multilingual society, language not only reflects culture and heritage, but also has implications for social status and the degree of integration in society. Different languages can be a barrier between monolingual communities, and the dynamics of language choice could explain the prosperity or demise of local languages in an international setting. We study this interplay of language and network structure in diverse, multi-lingual societies, using Twitter. In our analysis, we are particularly interested in the role of bilinguals. Concretely, we attempt to quantify the degree to which users are the "bridge-builders" between monolingual language groups, while monolingual users cluster together. Also, with the revalidation of English as a lingua franca on Twitter, we reveal users of the native non-English language have higher influence than English users, and the language convergence pattern is consistent across the regions. Furthermore, we explore for which topics these users prefer their native language rather than English. To the best of our knowledge, this is the largest sociolinguistic study in a network setting.},
  doi       = {10.1145/2631775.2631824},
  isbn      = {9781450329545},
  keywords  = {multilingualism, social media, topic modeling, sociolinguistics},
  location  = {Santiago, Chile},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2631775.2631824},
}

@InProceedings{Dall2014,
  author    = {Dall, Christoffer and Nieh, Jason},
  booktitle = {Proceedings of the 19th International Conference on Architectural Support for Programming Languages and Operating Systems},
  title     = {KVM/ARM: The Design and Implementation of the Linux ARM Hypervisor},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {333–348},
  publisher = {Association for Computing Machinery},
  series    = {ASPLOS '14},
  abstract  = {As ARM CPUs become increasingly common in mobile devices and servers, there is a growing demand for providing the benefits of virtualization for ARM-based devices. We present our experiences building the Linux ARM hypervisor, KVM/ARM, the first full system ARM virtualization solution that can run unmodified guest operating systems on ARM multicore hardware. KVM/ARM introduces split-mode virtualization, allowing a hypervisor to split its execution across CPU modes and be integrated into the Linux kernel. This allows KVM/ARM to leverage existing Linux hardware support and functionality to simplify hypervisor development and maintainability while utilizing recent ARM hardware virtualization extensions to run virtual machines with comparable performance to native execution. KVM/ARM has been successfully merged into the mainline Linux kernel, ensuring that it will gain wide adoption as the virtualization platform of choice for ARM. We provide the first measurements on real hardware of a complete hypervisor using ARM hardware virtualization support. Our results demonstrate that KVM/ARM has modest virtualization performance and power costs, and can achieve lower performance and power costs compared to x86-based Linux virtualization on multicore hardware.},
  doi       = {10.1145/2541940.2541946},
  isbn      = {9781450323055},
  keywords  = {multicore, virtualization, arm, operating systems, hypervisors, linux},
  location  = {Salt Lake City, Utah, USA},
  numpages  = {16},
  url       = {https://doi.org/10.1145/2541940.2541946},
}

@Article{Dall2014a,
  author     = {Dall, Christoffer and Nieh, Jason},
  journal    = {SIGPLAN Not.},
  title      = {KVM/ARM: The Design and Implementation of the Linux ARM Hypervisor},
  year       = {2014},
  issn       = {0362-1340},
  month      = {feb},
  number     = {4},
  pages      = {333–348},
  volume     = {49},
  abstract   = {As ARM CPUs become increasingly common in mobile devices and servers, there is a growing demand for providing the benefits of virtualization for ARM-based devices. We present our experiences building the Linux ARM hypervisor, KVM/ARM, the first full system ARM virtualization solution that can run unmodified guest operating systems on ARM multicore hardware. KVM/ARM introduces split-mode virtualization, allowing a hypervisor to split its execution across CPU modes and be integrated into the Linux kernel. This allows KVM/ARM to leverage existing Linux hardware support and functionality to simplify hypervisor development and maintainability while utilizing recent ARM hardware virtualization extensions to run virtual machines with comparable performance to native execution. KVM/ARM has been successfully merged into the mainline Linux kernel, ensuring that it will gain wide adoption as the virtualization platform of choice for ARM. We provide the first measurements on real hardware of a complete hypervisor using ARM hardware virtualization support. Our results demonstrate that KVM/ARM has modest virtualization performance and power costs, and can achieve lower performance and power costs compared to x86-based Linux virtualization on multicore hardware.},
  address    = {New York, NY, USA},
  doi        = {10.1145/2644865.2541946},
  issue_date = {April 2014},
  keywords   = {arm, multicore, hypervisors, linux, operating systems, virtualization},
  numpages   = {16},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2644865.2541946},
}

@Article{Dall2014b,
  author     = {Dall, Christoffer and Nieh, Jason},
  journal    = {SIGARCH Comput. Archit. News},
  title      = {KVM/ARM: The Design and Implementation of the Linux ARM Hypervisor},
  year       = {2014},
  issn       = {0163-5964},
  month      = {feb},
  number     = {1},
  pages      = {333–348},
  volume     = {42},
  abstract   = {As ARM CPUs become increasingly common in mobile devices and servers, there is a growing demand for providing the benefits of virtualization for ARM-based devices. We present our experiences building the Linux ARM hypervisor, KVM/ARM, the first full system ARM virtualization solution that can run unmodified guest operating systems on ARM multicore hardware. KVM/ARM introduces split-mode virtualization, allowing a hypervisor to split its execution across CPU modes and be integrated into the Linux kernel. This allows KVM/ARM to leverage existing Linux hardware support and functionality to simplify hypervisor development and maintainability while utilizing recent ARM hardware virtualization extensions to run virtual machines with comparable performance to native execution. KVM/ARM has been successfully merged into the mainline Linux kernel, ensuring that it will gain wide adoption as the virtualization platform of choice for ARM. We provide the first measurements on real hardware of a complete hypervisor using ARM hardware virtualization support. Our results demonstrate that KVM/ARM has modest virtualization performance and power costs, and can achieve lower performance and power costs compared to x86-based Linux virtualization on multicore hardware.},
  address    = {New York, NY, USA},
  doi        = {10.1145/2654822.2541946},
  issue_date = {March 2014},
  keywords   = {virtualization, linux, multicore, arm, operating systems, hypervisors},
  numpages   = {16},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2654822.2541946},
}

@InProceedings{Kempfle2018,
  author    = {Kempfle, Jochen and Van Laerhoven, Kristof},
  booktitle = {Proceedings of the 5th International Workshop on Sensor-Based Activity Recognition and Interaction},
  title     = {Respiration Rate Estimation with Depth Cameras: An Evaluation of Parameters},
  year      = {2018},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {iWOAR '18},
  abstract  = {Depth cameras have been known to be capable of picking up the small changes in distance from users' torsos, to estimate respiration rate. Several studies have shown that under certain conditions, the respiration rate from a non-mobile user facing the camera can be accurately estimated from parts of the depth data. It is however to date not clear, what factors might hinder the application of this technology in any setting, what areas of the torso need to be observed, and how readings are affected for persons at larger distances from the RGB-D camera. In this paper, we present a benchmark dataset that consists of the point cloud data from a depth camera, which monitors 7 volunteers at variable distances, for variable methods to pin-point the person's torso, and at variable breathing rates. Our findings show that the respiration signal's signal-to-noise ratio becomes debilitating as the distance to the person approaches 4 metres, and that bigger windows over the person's chest work particularly well. The sampling rate of the depth camera was also found to impact the signal's quality significantly.},
  articleno = {4},
  doi       = {10.1145/3266157.3266208},
  isbn      = {9781450364874},
  keywords  = {Kinect v2, non-contact measurement, respiration measurement, respiratory rate, ToF sensing},
  location  = {Berlin, Germany},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3266157.3266208},
}

@InProceedings{Zha2021,
  author    = {Zha, Yue and Li, Jing},
  booktitle = {Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
  title     = {When Application-Specific ISA Meets FPGAs: A Multi-Layer Virtualization Framework for Heterogeneous Cloud FPGAs},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {123–134},
  publisher = {Association for Computing Machinery},
  series    = {ASPLOS '21},
  abstract  = {While field-programmable gate arrays (FPGAs) have been widely deployed into cloud platforms, the high programming complexity and the inability to manage FPGA resources in an elastic/scalable manner largely limits the adoption of FPGA acceleration. Existing FPGA virtualization mechanisms partially address these limitations. Application-specific (AS) ISA provides a nice abstraction to enable a simple software programming flow that makes FPGA acceleration accessible by the mainstream software application developers. Nevertheless, existing AS ISA-based approaches can only manage FPGA resources at a per-device granularity, leading to a low resource utilization. Alternatively, hardware-specific (HS) abstraction improves the resource utilization by spatially sharing one FPGA among multiple applications. But it cannot reduce the programming complexity due to the lack of a high-level programming model. In this paper, we propose a virtualization mechanism for heterogeneous cloud FPGAs that combines AS ISA and HS abstraction to fully address aforementioned limitations. To efficiently combine these two abstractions, we provide a multi-layer virtualization framework with a new system abstraction as an indirection layer between them. This indirection layer hides the FPGA-specific resource constraints and leverages parallel pattern to effectively reduce the mapping complexity. It simplifies the mapping process into two steps, where the first step decomposes an AS ISA-based accelerator under no resource constraint to extract all fine-grained parallel patterns, and the second step leverages the extracted parallel patterns to simplify the process of mapping the decomposed accelerators onto the underlying HS abstraction. While system designers might be able to manually perform these steps for small accelerator designs, we develop a set of custom tools to automate this process and achieve a high mapping quality. By hiding FPGA-specific resource constraints, the proposed system abstraction provides a homogeneous view for the heterogeneous cloud FPGAs to simplify the runtime resource management. The extracted parallel patterns could also be leveraged by the runtime system to improve the performance of scale-out acceleration by maximally hiding the inter-FPGA communication latency. We use an AS ISA similar to the one proposed in BrainWave project and a recently proposed HS abstraction as a case study to demonstrate the effectiveness of the proposed virtualization framework. The performance is evaluated on a custom-built FPGA cluster with heterogeneous FPGA resources. Compared with the baseline system that only uses AS ISA, the proposed framework effectively combines these two abstractions and improves the aggregated system throughput by 2.54\texttimes{} with a marginal virtualization overhead.},
  doi       = {10.1145/3445814.3446699},
  isbn      = {9781450383172},
  keywords  = {Virtualization, Parallel patterns, Application-specific ISA, Heterogeneous cloud FPGAs},
  location  = {Virtual, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3445814.3446699},
}

@InProceedings{Wu2018b,
  author    = {Wu, Xuan and Zhao, Lingxiao and Akoglu, Leman},
  booktitle = {Proceedings of the 27th ACM International Conference on Information and Knowledge Management},
  title     = {A Quest for Structure: Jointly Learning the Graph Structure and Semi-Supervised Classification},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {87–96},
  publisher = {Association for Computing Machinery},
  series    = {CIKM '18},
  abstract  = {Semi-supervised learning (SSL) is effectively used for numerous classification problems, thanks to its ability to make use of abundant unlabeled data. The main assumption of various SSL algorithms is that the nearby points on the data manifold are likely to share a label. Graph-based SSL constructs a graph from point-cloud data as an approximation to the underlying manifold, followed by label inference. It is no surprise that the quality of the constructed graph in capturing the essential structure of the data is critical to the accuracy of the subsequent inference step [6].How should one construct a graph from the input point-cloud data for graph-based SSL? In this work we introduce a new, parallel graph learning framework (called PG-learn) for the graph construction step of SSL. Our solution has two main ingredients: (1) a gradient-based optimization of the edge weights (more specifically, different kernel bandwidths in each dimension) based on a validation loss function, and (2) a parallel hyperparameter search algorithm with an adaptive resource allocation scheme. In essence, (1) allows us to search around a (random) initial hyperparameter configuration for a better one with lower validation loss. Since the search space of hyperparameters is huge for high-dimensional problems, (2) empowers our gradient-based search to go through as many different initial configurations as possible, where runs for relatively unpromising starting configurations are terminated early to allocate the time for others. As such, PG-learn is a carefully-designed hybrid of random and adaptive search. Through experiments on multi-class classification problems, we show that PG-learn significantly outperforms a variety of existing graph construction schemes in accuracy (per fixed time budget for hyperparameter tuning), and scales more effectively to high dimensional problems.},
  doi       = {10.1145/3269206.3271692},
  isbn      = {9781450360142},
  keywords  = {hyperparamer optimization, hyperparamer inference, semi-supervised learning, graph learning, graph construction, parallel graph learning},
  location  = {Torino, Italy},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3269206.3271692},
}

@InProceedings{Blanchard2019,
  author    = {Blanchard, Sam and Huang, Jia-Bin and Williams, Christopher B. and Meenakshisundaram, Viswanath and Kubalak, Joseph and Lokegaonkar, Sanket},
  booktitle = {ACM SIGGRAPH 2019 Studio},
  title     = {Source Form an Automated Crowdsourced Object Generator},
  year      = {2019},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {SIGGRAPH '19},
  abstract  = {Source Form is a stand-alone device capable of collecting crowdsourced images of a user-defined object, stitching together available visual data (e.g., photos tagged with search term) through photogrammetry, creating watertight models from the resulting point cloud and 3D printing a physical form. This device works completely independent of subjective user input resulting in two possible outcomes:1. Produce iterative versions of a specific object (e.g., the Statue of Liberty) increasing in detail and accuracy over time as the collective dataset (e.g., uploaded images of the statue) grows.2. Produce democratized versions of common objects (e.g., an apple) by aggregating a spectrum of tagged image results.This project demonstrates that an increase in readily available image data closes the gap between physical and digital perceptions of form through time. For example, when Source Form is asked to print the Statue of Liberty today and then print again 6 months from now, the later result will be more accurate and detailed than the previous version. As people continue to take pictures of the monument and upload them to social media, blogs and photo sharing sites, the database of images grows in quantity and quality. Because Source Form gathers a new dataset with each print, the resulting forms will always be evolving. The collection of prints the machine produces over time are cataloged and displayed in linear groupings, providing viewers an opportunity to see growth and change in physical space.In addition to rendering change over time, a snapshot of a more common object's web perception could be created. For example, when an image search for "apple" is performed, the results are a spectrum of condition and species from rotting crab apples to gleaming Granny-Smith's. Source Form aggregates all of these images into one model and outputs the collective web presence of an "apple". Characteristics of the model are guided by the frequency and order in response to the image web search. The resulting democratized forms are emblematic of the web's collective and popular perceptions.},
  articleno = {13},
  doi       = {10.1145/3306306.3328001},
  isbn      = {9781450363167},
  keywords  = {3D printing, photogrammetry, hardware, sculpture, fine art, crowdsourcing, automation},
  location  = {Los Angeles, California},
  numpages  = {2},
  url       = {https://doi.org/10.1145/3306306.3328001},
}

@Article{Schertler2017,
  author     = {Schertler, Nico and Tarini, Marco and Jakob, Wenzel and Kazhdan, Misha and Gumhold, Stefan and Panozzo, Daniele},
  journal    = {ACM Trans. Graph.},
  title      = {Field-Aligned Online Surface Reconstruction},
  year       = {2017},
  issn       = {0730-0301},
  month      = {jul},
  number     = {4},
  volume     = {36},
  abstract   = {Today's 3D scanning pipelines can be classified into two overarching categories: offline, high accuracy methods that rely on global optimization to reconstruct complex scenes with hundreds of millions of samples, and online methods that produce real-time but low-quality output, usually from structure-from-motion or depth sensors. The method proposed in this paper is the first to combine the benefits of both approaches, supporting online reconstruction of scenes with hundreds of millions of samples from high-resolution sensing modalities such as structured light or laser scanners. The key property of our algorithm is that it sidesteps the signed-distance computation of classical reconstruction techniques in favor of direct filtering, parametrization, and mesh and texture extraction. All of these steps can be realized using only weak notions of spatial neighborhoods, which allows for an implementation that scales approximately linearly with the size of each dataset that is integrated into a partial reconstruction. Combined, these algorithmic differences enable a drastically more efficient output-driven interactive scanning and reconstruction workflow, where the user is able to see the final quality field-aligned textured mesh during the entirety of the scanning procedure. Holes or parts with registration problems are displayed in real-time to the user and can be easily resolved by adding further localized scans, or by adjusting the input point cloud using our interactive editing tools with immediate visual feedback on the output mesh. We demonstrate the effectiveness of our algorithm in conjunction with a state-of-the-art structured light scanner and optical tracking system and test it on a large variety of challenging models.},
  address    = {New York, NY, USA},
  articleno  = {77},
  doi        = {10.1145/3072959.3073635},
  issue_date = {August 2017},
  keywords   = {surface reconstruction, parameterization},
  numpages   = {13},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3072959.3073635},
}

@InProceedings{Wehrle2014,
  author    = {Wehrle, Dennis and Liebetraut, Thomas and Valizada, Isgandar and Rechert, Klaus},
  booktitle = {Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing},
  title     = {Emulation-as-a-Service - Workflows and Infrastructure to Support Recomputable Science},
  year      = {2014},
  address   = {USA},
  pages     = {962–967},
  publisher = {IEEE Computer Society},
  series    = {UCC '14},
  abstract  = {The computational age and its fast technological progress boosted research output of almost all disciplines. However, these early benefits come along with a burden: while the exchange of research data and ideas is easier and more effective than ever, assuring both short- and long-term access to fundamental scientific methods is more difficult than anticipated. In particular, functional access to data processing methods, tool-chains and scientific workflows is indispensable in order to verify and replicate research findings. This article is proposing emulation as a technique for generalization of data processing environments, serving as first step towards long-term accessibility of research data and associated methods. We present a Cloud-based emulation-as-a-service framework for publication and citation of scientific workflows and research data, since having re-usable processing environments, emulation can be used for technical verification of research data, i.e. Ensure minimal quality assurance like completeness and an explicit list of potential external dependencies, fundamental for future risk-assessment.},
  doi       = {10.1109/UCC.2014.157},
  isbn      = {9781479978816},
  keywords  = {long-term preservation, citing research data, workflows, re-use, verification, research data, replicability},
  numpages  = {6},
  url       = {https://doi.org/10.1109/UCC.2014.157},
}

@InProceedings{Matyunin2019,
  author    = {Matyunin, Nikolay and Wang, Yujue and Arul, Tolga and Kullmann, Kristian and Szefer, Jakub and Katzenbeisser, Stefan},
  booktitle = {Proceedings of the 18th ACM Workshop on Privacy in the Electronic Society},
  title     = {MagneticSpy: Exploiting Magnetometer in Mobile Devices for Website and Application Fingerprinting},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {135–149},
  publisher = {Association for Computing Machinery},
  series    = {WPES'19},
  abstract  = {Recent studies have shown that aggregate CPU usage and power consumption traces on smartphones can leak information about applications running on the system or websites visited. In response, access to such data has been blocked for mobile applications starting from Android 8. In this work, we explore a new source of side-channel leakage for this class of attacks. Our method is based on the fact that electromagnetic activity caused by mobile processors leads to noticeable disturbances in magnetic sensor measurements on mobile devices, with the amplitude being proportional to the CPU workload. Therefore, recorded sensor data can be analyzed to reveal information about ongoing activities. The attack works on a number of devices: we evaluated 80 models of modern smartphones and tablets and observed the reaction of the magnetometer to the CPU activity on 56 of them. On selected devices we were able to successfully identify which application has been opened (with up to 90\% accuracy) or which web page has been loaded (up to 91\% accuracy). The presented side channel poses a significant risk to end users' privacy, as the sensor data can be recorded from native apps or even from web pages without user permissions. Finally, we discuss possible countermeasures to prevent the presented information leakage.},
  doi       = {10.1145/3338498.3358650},
  isbn      = {9781450368308},
  keywords  = {magnetometer, hardware side channels, mobile security, smartphone sensors, information leakage, website fingerprinting, application fingerprinting},
  location  = {London, United Kingdom},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3338498.3358650},
}

@InProceedings{AlOmair2018,
  author    = {Al-Omair, Osamah M. and Huang, Shihong},
  booktitle = {Proceedings of the 2018 International Conference on Signal Processing and Machine Learning},
  title     = {A Comparative Study on Detection Accuracy of Cloud-Based Emotion Recognition Services},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {142–148},
  publisher = {Association for Computing Machinery},
  series    = {SPML '18},
  abstract  = {The ability of software systems adapting to human's input is a key element in the symbiosis of human-system co-adaptation, where human and software-based systems work together in a close partnership to achieve synergetic goals. This seamless integration will eliminate the barriers between human and machine. A critical requirement for co-adaptive systems is software system's ability to recognize human emotion, in which the system can detect and interpret users' emotions and adapt accordingly. There are numerous solutions that provide the technologies for emotion recognition. However, selecting an appropriate solution for a given task within a specific application domain can be challenging. The vast variation between these solutions makes the selecting task even more difficult. This paper compares cloud-based emotion recognition services offered by Amazon, Google, and Microsoft. These services detect human emotion through facial expression recognition with the utilization of computer vision. The focus of this paper is to measure the detection accuracy of these services. Accuracy is calculated based on the highest confidence rating returned by each service. All three services have been tested with the same dataset. This paper concludes with findings and recommendations based on our comparative analysis among these services.},
  doi       = {10.1145/3297067.3297079},
  isbn      = {9781450366052},
  keywords  = {Co-adaptive systems, Affective computing, Machine emotional intelligence, Machine learning, Facial expression recognition, Human-computer interaction, Emotion recognition},
  location  = {Shanghai, China},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3297067.3297079},
}

@InProceedings{Basios2018,
  author    = {Basios, Michail and Li, Lingbo and Wu, Fan and Kanthan, Leslie and Barr, Earl T.},
  booktitle = {Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  title     = {Darwinian Data Structure Selection},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {118–128},
  publisher = {Association for Computing Machinery},
  series    = {ESEC/FSE 2018},
  abstract  = {Data structure selection and tuning is laborious but can vastly improve an application’s performance and memory footprint. Some data structures share a common interface and enjoy multiple implementations. We call them Darwinian Data Structures (DDS), since we can subject their implementations to survival of the fittest. We introduce ARTEMIS a multi-objective, cloud-based search-based optimisation framework that automatically finds optimal, tuned DDS modulo a test suite, then changes an application to use that DDS. ARTEMIS achieves substantial performance improvements for every project in 5 Java projects from DaCapo benchmark, 8 popular projects and 30 uniformly sampled projects from GitHub. For execution time, CPU usage, and memory consumption, ARTEMIS finds at least one solution that improves all measures for 86\% (37/43) of the projects. The median improvement across the best solutions is 4.8\%, 10.1\%, 5.1\% for runtime, memory and CPU usage. These aggregate results understate ARTEMIS’s potential impact. Some of the benchmarks it improves are libraries or utility functions. Two examples are gson, a ubiquitous Java serialization framework, and xalan, Apache’s XML transformation tool. ARTEMIS improves gson by 16.5\%, 1\% and 2.2\% for memory, runtime, and CPU; ARTEMIS improves xalan’s memory consumption by 23.5\%. Every client of these projects will benefit from these performance improvements.},
  doi       = {10.1145/3236024.3236043},
  isbn      = {9781450355735},
  keywords  = {Search-based Software Engineering, Software Analysis and Optimisation, Data Structure Optimisation, Genetic Improvement},
  location  = {Lake Buena Vista, FL, USA},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3236024.3236043},
}

@InProceedings{Bachrach2020,
  author    = {Bachrach, Mayra and Morreale, Patricia and Verdi, Gail},
  booktitle = {Proceedings of the 51st ACM Technical Symposium on Computer Science Education},
  title     = {Improving the Outcomes of Hispanics in AP Computer Science},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {1411},
  publisher = {Association for Computing Machinery},
  series    = {SIGCSE '20},
  abstract  = {This lightning talk describes a proof of concept research project funded by a Google CS Education (CS-ER) Research grant. The project focuses on pedagogical interventions aimed at improving the outcomes of English Language Learners (ELLs) in Advanced Placement Computer Science. The research underway examines the use of Sheltered Instruction (SI), a model from English as a Second Language (ESL) and bilingual education, used in mainstream classrooms across other content areas, in the AP CSA and AP CSP classroom. Strategies and pedagogy from the Sheltered Instruction model are being infused into AP Computer Science curriculum and used in classrooms in participating districts. The districts have been selected to include a range of ELLs and native English speakers. The impact of this approach will be measured by comparing the AP CS exam scores of students in the participating districts with the national and state AP CS exam scores. This lightning talk will focus on the pedagogy development which has taken place and preliminary findings from two cohorts of AP CS and AP CSA teachers, in particular the impact and changes to the teacher's development of CS education lessons and in-class lesson delivery. The project is an interdisciplinary collaboration between faculty from the School of Computer Science and the School of Curriculum and Teaching.},
  doi       = {10.1145/3328778.3372567},
  isbn      = {9781450367936},
  keywords  = {academic-discourse, scaffolding, academic-language, equity, hispanics, pedagogy},
  location  = {Portland, OR, USA},
  numpages  = {1},
  url       = {https://doi.org/10.1145/3328778.3372567},
}

@InProceedings{Costa2019,
  author    = {Costa, Arthur F. da and D'Addio, Rafael M. and Fressato, Eduardo P. and Manzato, Marcelo G.},
  booktitle = {Proceedings of the 25th Brazillian Symposium on Multimedia and the Web},
  title     = {A Personalized Clustering-Based Approach Using Open Linked Data for Search Space Reduction in Recommender Systems},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {409–416},
  publisher = {Association for Computing Machinery},
  series    = {WebMedia '19},
  abstract  = {Recommender systems use information about the users' preferences to define relatedness scores towards items. Regardless of the method, a noticeable problem is that the system is required to compute scores for a large amount of unknown items in the database, even though these items may not be related to a determined user. In this manuscript, we propose a technique called search space reduction for recommender systems (SSR4Rec) that reduces the number of unknown pairs the recommender must process. As a pre-processing step, we cluster related items and assign only the closest group to each user, producing a reduced set of unknown pairs. The distance between items, and between clusters and users, is computed by comparing item representations and user profiles built based on attributes extracted from the Linked Open Data cloud. We assess the quality of SSR4Rec by applying it into two well-known RS and comparing the results against the same recommenders without our pre-processing step, as well as against other related baselines. Results show a significant improvement in both ranking accuracy and computational time.},
  doi       = {10.1145/3323503.3349543},
  isbn      = {9781450367639},
  keywords  = {recommender systems, search space reduction, clustering, linked open data},
  location  = {Rio de Janeiro, Brazil},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3323503.3349543},
}

@InProceedings{Zang2015,
  author    = {Zang, Andi and Chen, Xin and Trajcevski, Goce},
  booktitle = {Proceedings of the 1st International ACM SIGSPATIAL Workshop on Smart Cities and Urban Analytics},
  title     = {Digital Terrain Model Generation Using LiDAR Ground Points},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {9–15},
  publisher = {Association for Computing Machinery},
  series    = {UrbanGIS'15},
  abstract  = {As the trend of autonomous self-driving cars is becoming more of a reality, High-quality navigation methods and tools become a paramount. This, in turn, is crucially dependent on High-definition maps, for which one of the enabling tools is high resolution Digital Terrain Model (DTM) -- the role and values of which have already been demonstrated even in the settings of manned cars. Traditional DTM generation methods have insurmountable barriers in creating centimeter-level resolution. In this paper, we propose a novel method for fully-automated, high precision DTM generation using the database generated and maintained in our existed dataset, and with no additional overheads in terms of extract labor and equipment cost. The input data is a point cloud captured by the vehicle-mount LiDAR devices which, naturally, has extremely large volume. We show how with Ground Points Processing and DTM Generation steps, we can generate a centimeter-resolution DTM and, as our experiments demonstrate, when compared to DTM form U.S. Geological Survey (USGS) and altitude data from a third party surveying dataset, our proposed DTM indeed provides a higher precision.},
  doi       = {10.1145/2835022.2835024},
  isbn      = {9781450339735},
  keywords  = {LiDAR, GIS, Digital Terrain Model, Point cloud processing},
  location  = {Bellevue, WA, USA},
  numpages  = {7},
  url       = {https://doi.org/10.1145/2835022.2835024},
}

@InProceedings{Kim2016,
  author    = {Kim, Jungwoo and Kim, Hyesook and Choi, Jaeboong},
  booktitle = {Proceedings of HCI Korea},
  title     = {Development of Smart Product, DUET Using SQFD and Storytelling},
  year      = {2016},
  address   = {Seoul, KOR},
  pages     = {298–306},
  publisher = {Hanbit Media, Inc.},
  series    = {HCIK '16},
  abstract  = {This paper presents a smart product design process for a wearable device to provide empathy and fun to users. As the first step, keywords were extracted using open-coding methods from text WebData of online sites for wearable devices, Smardi, Sblog, and Wsite. The Smart Quality Function Deployment (SQFD) was then applied to prioritize the keywords and corresponding user requirements. The key user requirements such as 'separable band from core module' and 'function for media control' were then materialized into a wearable band, DUET, using rapid prototyping, and refined through three stages of user evaluation. DUET connectable to iOS and Android smartphones was introduced by a storytelling transmedia videoclip by experts with a theme of empathy and fun. It was also advertised on a cloud funding site, Indiegogo, and through a PPL in S entertainment program, and received positive responses. Further detailed analysis of user responses was performed for 72 days through the operation of facebook-DUET site and for 10 days through Google keyword marketing which derived various levels of user activities.},
  doi       = {10.17210/hcik.2016.01.298},
  isbn      = {9788968487910},
  keywords  = {RP, SQFD},
  location  = {Jeongseon, Republic of Korea},
  numpages  = {9},
  url       = {https://doi.org/10.17210/hcik.2016.01.298},
}

@InProceedings{Ibarz2020,
  author    = {Ibarz, Jean and Lauer, Micha\"{e}l and Roy, Matthieu and Fabre, Jean-Charles and Fl\'{e}bus, Olivier},
  booktitle = {Proceedings of the 28th International Conference on Real-Time Networks and Systems},
  title     = {Optimizing Vehicle-to-Cloud Data Transfers Using Soft Real-Time Scheduling Concepts},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {161–171},
  publisher = {Association for Computing Machinery},
  series    = {RTNS '20},
  abstract  = {The main promise of intelligent transportation systems (ITS) is that leveraging the information sensed by millions of vehicles will increase the quality of the user's experience. However, the unpredictable nature of road events, combined with a projected network overload, calls for a careful optimization of the vehicles' data transfers, taking into account spatio-temporal, safety and value constraints. In this article, we provide a methodical solution to optimize vehicle-to-cloud (V2C) data transfers, based on a series of steps. First, we show that this optimization problem can be modeled as a soft real-time scheduling problem. Second, we provide an extension of a classical algorithm for the generation of workloads, by increasing its coverage with regards to our use-case representation. Third, we estimate the bounds of an optimal clairvoyant algorithm in order to have a baseline for a fair comparison of existing scheduling algorithms. The results show that, within all these algorithms, one clearly outperforms the others regardless of the load rate. Interestingly, its performance gain increases when overload grows, and it can be implemented very efficiently, which makes it highly suitable for embedded systems.},
  doi       = {10.1145/3394810.3394818},
  isbn      = {9781450375931},
  keywords  = {data collection, event-based, reliability, embedded system, V2C, real-time, distributed sensing, IoT, mobile system},
  location  = {Paris, France},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3394810.3394818},
}

@InProceedings{Tahat2018,
  author    = {Tahat, Ashraf and Aburub, Ruba and Al-Zyoude, Aseel and Talhi, Chamseddine},
  booktitle = {Proceedings of the 2018 International Conference on Software Engineering and Information Management},
  title     = {A Smart City Environmental Monitoring Network and Analysis Relying on Big Data Techniques},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {82–86},
  publisher = {Association for Computing Machinery},
  series    = {ICSIM '18},
  abstract  = {A new integrated environmental monitoring system to carry-out real-time measurements on board a moving vehicle is presented. It is composed of an arbitrary number of Electronic Measurements Units (EMU), a smart phone application to relay collected data, and a cloud Central Processing Platform (CPP) to perform analysis utilizing big data techniques and algorithms. Each EMU consists of an electric circuit that incorporates an ultra violet (UV) sensor, an air particles concentration sensor, a temperature sensor and a humidity sensor that all interface to a microcontroller. Bluetooth is employed for communication between the EMU and the smart phone application, while a 3G/4G cellular communications network furnishes the wireless connectivity to the remote CPP. When the collected data reaches the designated cloud server (CPP), it is immediately stored for subsequent analysis. Finally, big data statistical analysis (clustering and classification), mapping and plotting are performed to deduce correlations and to facilitate inferencing. Moreover, the scalability and low-cost of selected components of this realistic system makes it very feasible for large scale deployments in the context of smart cities initiatives, ad-hoc designs, or educational projects.},
  doi       = {10.1145/3178461.3178464},
  isbn      = {9781450354387},
  keywords  = {environment, air particles, temperature sensor, smart phone, telemetry, Big data, UV index},
  location  = {Casablanca, Morocco},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3178461.3178464},
}

@InProceedings{Barajas2021,
  author    = {Barajas, Joel and Bhamidipati, Narayan and Shanahan, James G.},
  booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \&amp; Data Mining},
  title     = {Online Advertising Incrementality Testing And Experimentation: Industry Practical Lessons},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {4027–4028},
  publisher = {Association for Computing Machinery},
  series    = {KDD '21},
  abstract  = {Online advertising has historically been approached as user targeting and ad-to-user matching problems within sophisticated optimization algorithms. As the research area and ad tech industry have progressed over the last couple of decades, advertisers have increasingly emphasized the causal effect estimation of their ads (aka incrementality) using controlled experiments (or A/B testing). Even though observational approaches have been derived in marketing science since the 80s including media mix models, the availability of online advertising personalization has enabled the deployment of more rigorous randomized controlled experiments with millions of individuals. These evolutions in marketing science, online advertising, and the ad tech industry have posed incredible challenges for engineers, data scientists, and marketers alike. With low effect percentage differences (or lift) and often sparse conversion rates, the development of incrementality testing platforms at scale suggests tremendous engineering challenges in the measurement precision and detailed implementation. Similarly, the correct interpretation of results addressing a business goal within the marketing science domain requires significant data science and experimentation research expertise. All these challenges on the ongoing evolution of the online advertising industry and the heterogeneity of its sources (social, paid search, native, programmatic, etc). In the current tutorial, we propose a practical, grounded view in the incrementality testing landscape, including: The business need Solutions in the literature Design and choices in the development of incrementality testing platform The testing cycle, case studies, and recommendations to effective results delivery Incrementality testing evolution in the industry We will provide first-hand lessons on developing and operationalizing such a platform in a major combined DSP and ad network; these are based on running tens of experiments for up to two months each over the last couple of years.},
  doi       = {10.1145/3447548.3470819},
  isbn      = {9781450383325},
  location  = {Virtual Event, Singapore},
  numpages  = {2},
  url       = {https://doi.org/10.1145/3447548.3470819},
}

@InProceedings{Ahmed2020,
  author    = {Ahmed, Shamim and Bons, Marc},
  booktitle = {Proceedings of the 5th International Workshop on Non-Intrusive Load Monitoring},
  title     = {Edge Computed NILM: A Phone-Based Implementation Using MobileNet Compressed by Tensorflow Lite},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {44–48},
  publisher = {Association for Computing Machinery},
  series    = {NILM'20},
  abstract  = {In the context of residential Non-intrusive load monitoring (NILM), the usual service deployment process consists of collecting data from a metering device to the cloud, run algorithms on the cloud and then display results in a Web front or in an App. This approach comes with two major problems: on the one hand, important resources are allocated to the cloud process (including maintenance) while selling the solution on a substantial subscription basis is still a challenge. On the other hand, end-users are more and more reluctant to see their personal data being uploaded. In order to propose an alternative, this research has focused on edge computed NILM, namely the possibility to run NILM algorithms on existing devices on the end-user side, such as a smart phone. A two-stage model development has been carried out to obtain good disaggregation accuracy with lower model size. In the first stage, an efficient deep learning algorithm (MobileNet) has been adopted to obtain an accurate and light weight model. In the second stage, TensorFlow Lite has been used to compress further, in order to reduce edge device memory usage and computing time. To deal with real-life diversity, we have built large and diverse training and testing sets based on a combination of HES, UKDALE and REFIT datasets. Disaggregation performance has been assessed for both models: before and after TensorFlow Lite compression. Comparative analysis has been performed to facilitate implementation choices.},
  doi       = {10.1145/3427771.3427852},
  isbn      = {9781450381918},
  keywords  = {TensorFlow Lite, Energy Disaggregation, Deep Learning, MobileNet, NILM, Edge Computing},
  location  = {Virtual Event, Japan},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3427771.3427852},
}

@InProceedings{Murali2019,
  author    = {Murali, Prakash and Linke, Norbert Matthias and Martonosi, Margaret and Abhari, Ali Javadi and Nguyen, Nhung Hong and Alderete, Cinthia Huerta},
  booktitle = {Proceedings of the 46th International Symposium on Computer Architecture},
  title     = {Full-Stack, Real-System Quantum Computer Studies: Architectural Comparisons and Design Insights},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {527–540},
  publisher = {Association for Computing Machinery},
  series    = {ISCA '19},
  abstract  = {In recent years, Quantum Computing (QC) has progressed to the point where small working prototypes are available for use. Termed Noisy Intermediate-Scale Quantum (NISQ) computers, these prototypes are too small for large benchmarks or even for Quantum Error Correction (QEC), but they do have sufficient resources to run small benchmarks, particularly if compiled with optimizations to make use of scarce qubits and limited operation counts and coherence times. QC has not yet, however, settled on a particular preferred device implementation technology, and indeed different NISQ prototypes implement qubits with very different physical approaches and therefore widely-varying device and machine characteristics.Our work performs a full-stack, benchmark-driven hardware-software analysis of QC systems. We evaluate QC architectural possibilities, software-visible gates, and software optimizations to tackle fundamental design questions about gate set choices, communication topology, the factors affecting benchmark performance and compiler optimizations. In order to answer key cross-technology and cross-platform design questions, our work has built the first top-to-bottom toolflow to target different qubit device technologies, including superconducting and trapped ion qubits which are the current QC front-runners. We use our toolflow, TriQ, to conduct real-system measurements on seven running QC prototypes from three different groups, IBM, Rigetti, and University of Maryland. Overall, we demonstrate that leveraging microarchitecture details in the compiler improves program success rate up to 28x on IBM (geomean 3x), 2.3x on Rigetti (geomean 1.45x), and 1.47x on UMDTI (geomean 1.17x), compared to vendor toolflows. In addition, from these real-system experiences at QC's hardware-software interface, we make observations and recommendations about native and software-visible gates for different QC technologies, as well as communication topologies, and the value of noise-aware compilation even on lower-noise platforms. This is the largest cross-platform real-system QC study performed thus far; its results have the potential to inform both QC device and compiler design going forward.},
  doi       = {10.1145/3307650.3322273},
  isbn      = {9781450366694},
  location  = {Phoenix, Arizona},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3307650.3322273},
}

@InProceedings{Ellwein2019,
  author    = {Ellwein, Carsten and Schmidt, Alexander and Lechler, Armin and Riedel, Oliver},
  booktitle = {Proceedings of the 2019 3rd International Conference on Automation, Control and Robots},
  title     = {Distributed Manufacturing: A Vision about Shareconomy in the Manufacturing Industry},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {90–95},
  publisher = {Association for Computing Machinery},
  series    = {ICACR 2019},
  abstract  = {Four major trends in recent manufacturing technology have been identified and are introduced. Those trends are mass customization, shareconomy, digitalization and cloud manufacturing. The impact of those trends on manufacturing paradigms has been evaluated and three possible paradigms have been identified. Those manufacturing paradigms are separation of design and manufacturing, collaboration across company borders and on-site production. The separation of design and manufacturing does empower customers with regard to the product and does allow true mass customization where customers are included in the product description process. The collaboration across company borders does empower customers in regard of the process and lets them choose their contractual partner for every production step. The following on-site-production focuses on the throughput and thus on the delivery time by re-location of the production into the end-customers' daily field of action. Each paradigm is explained, the vision of possible future implementations is drawn and the possible benefits are outlined. However, the technical realization of those paradigms is yet not fully feasible due to still unsolved problems and challenges. Therefore, a research agenda has been composed to list and address those deficits. The main deficits that have been identified are the lack of standardized data models, an integrated and automated toolchain, the protection of intellectual property and the compliance with quality demands.},
  doi       = {10.1145/3365265.3365270},
  isbn      = {9781450372886},
  keywords  = {Distributed Manufacturing, Prosumption, Shareconomy, Manufacturing Access Point, Cloud Manufacturing, Mass Customization},
  location  = {Prague, Czech Republic},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3365265.3365270},
}

@Article{Seeger2020,
  author     = {Seeger, Jan and Br\"{o}ring, Arne and Carle, Georg},
  journal    = {ACM Trans. Internet Technol.},
  title      = {Optimally Self-Healing IoT Choreographies},
  year       = {2020},
  issn       = {1533-5399},
  month      = {jul},
  number     = {3},
  volume     = {20},
  abstract   = {In the industrial Internet of Things domain, applications are moving from the Cloud into the Edge, closer to the devices producing and consuming data. This means that applications move from the scalable and homogeneous Cloud environment into a potentially constrained heterogeneous Edge network. Making Edge applications reliable enough to fulfill Industry 4.0 use cases remains an open research challenge. Maintaining operation of an Edge system requires advanced management techniques to mitigate the failure of devices. This article tackles this challenge with a twofold approach: (1) a policy-enabled failure detector that enables adaptable failure detection and (2) an allocation component for the efficient selection of failure mitigation actions. The parameters and performance of the failure detection approach are evaluated, and the performance of an energy-efficient allocation technique is measured. Finally, a vision for a complete system and an example use case are presented.},
  address    = {New York, NY, USA},
  articleno  = {27},
  doi        = {10.1145/3386361},
  issue_date = {August 2020},
  keywords   = {optimization, IOT, failure detection},
  numpages   = {20},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3386361},
}

@InProceedings{Discher2018,
  author    = {Discher, S\"{o}ren and Richter, Rico and D\"{o}llner, J\"{u}rgen},
  booktitle = {Proceedings of the 23rd International ACM Conference on 3D Web Technology},
  title     = {A Scalable WebGL-Based Approach for Visualizing Massive 3D Point Clouds Using Semantics-Dependent Rendering Techniques},
  year      = {2018},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {Web3D '18},
  abstract  = {3D point cloud technology facilitates the automated and highly detailed digital acquisition of real-world environments such as assets, sites, cities, and countries; the acquired 3D point clouds represent an essential category of geodata used in a variety of geoinformation applications and systems. In this paper, we present a web-based system for the interactive and collaborative exploration and inspection of arbitrary large 3D point clouds. Our approach is based on standard WebGL on the client side and is able to render 3D point clouds with billions of points. It uses spatial data structures and level-of-detail representations to manage the 3D point cloud data and to deploy out-of-core and web-based rendering concepts. By providing functionality for both, thin-client and thick-client applications, the system scales for client devices that are vastly different in computing capabilities. Different 3D point-based rendering techniques and post-processing effects are provided to enable task-specific and data-specific filtering and highlighting, e.g., based on per-point surface categories or temporal information. A set of interaction techniques allows users to collaboratively work with the data, e.g., by measuring distances and areas, by annotating, or by selecting and extracting data subsets. Additional value is provided by the system's ability to display additional, context-providing geodata alongside 3D point clouds and to integrate task-specific processing and analysis operations. We have evaluated the presented techniques and the prototype system with different data sets from aerial, mobile, and terrestrial acquisition campaigns with up to 120 billion points to show their practicality and feasibility.},
  articleno = {19},
  doi       = {10.1145/3208806.3208816},
  isbn      = {9781450358002},
  keywords  = {point-based rendering, 3D point clouds, web-based rendering},
  location  = {Pozna\'{n}, Poland},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3208806.3208816},
}

@InProceedings{Rong2017,
  author    = {Rong, Yu and Cheng, Hong},
  booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
  title     = {Minimizing Dependence between Graphs},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {1827–1836},
  publisher = {Association for Computing Machinery},
  series    = {CIKM '17},
  abstract  = {In recent years, modeling the relation between two graphs has received unprecedented attention from researchers due to its wide applications in many areas, such as social analysis and bioinformatics. The nature of relations between two graphs can be divided into two categories: the vertex relation and the link relation. Many studies focus on modeling the vertex relation between graphs and try to find the vertex correspondence between two graphs. However, the link relation between graphs has not been fully studied. Specifically, we model the cross-graph link relation as cross-graph dependence, which reflects the dependence of a vertex in one graph on a vertex in the other graph. A generic problem, called Graph Dependence Minimization (GDM), is defined as: given two graphs with cross-graph dependence, how to select a subset of vertexes from one graph and copy them to the other, so as to minimize the cross-graph dependence. Many real applications can benefit from the solution to GDM. Examples include reducing the cross-language links in online encyclopedias, optimizing the cross-platform communication cost between different cloud services, and so on. This problem is trivial if we can select as many vertexes as we want to copy. But what if we can only choose a limited number of vertexes to copy so as to make the two graphs as independent as possible? We formulate GDM with a budget constraint into a combinatorial optimization problem, which is proven to be NP-hard. We propose two algorithms to solve GDM. Firstly, we prove the submodularity of the objective function of GDM and adopt the size-constrained submodular minimization (SSM) algorithm to solve it. Since the SSM-based algorithm cannot scale to large graphs, we design a heuristic algorithm with a provable approximation guarantee. We prove that the error achieved by the heuristic algorithm is bounded by an additive factor which is proportional to the square of the given budget. Extensive experiments on both synthetic and real-world graphs show that the proposed algorithms consistently outperform the well-studied graph centrality measure based solutions. Furthermore, we conduct a case study on the Wikipedia graphs with millions of vertexes and links to demonstrate the potential of GDM to solve real-world problems.},
  doi       = {10.1145/3132847.3132931},
  isbn      = {9781450349185},
  keywords  = {submodular minimization, graph analytics, graph dependence minimization},
  location  = {Singapore, Singapore},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3132847.3132931},
}

@InProceedings{Podhoranyi2019,
  author    = {Podhoranyi, Michal and Vojacek, Lukas},
  booktitle = {Proceedings of the 2019 4th International Conference on Cloud Computing and Internet of Things},
  title     = {Social Media Data Processing Infrastructure by Using Apache Spark Big Data Platform: Twitter Data Analysis},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {1–6},
  publisher = {Association for Computing Machinery},
  series    = {CCIOT '19},
  abstract  = {Social media provide continuous data streams that contain information with different level of sensitivity, validity and accuracy. Therefore, this type of information has to be properly filtered, extracted and processed to avoid noisy and inaccurate results. The main goal of this work is to propose architecture and workflow able to process Twitter social network data in near real-time. The primary design of the introduced modern architecture covers all processing aspects from data ingestion and storing to data processing and analysing. This paper presents Apache Spark and Hadoop implementation. The secondary objective is to analyse tweets with the defined topic --- floods. The word frequency method (Word Clouds) is shown as a major tool to analyse the content of the input dataset. The experimental architecture confirmed the usefulness of many well-known functions of Spark and Hadoop in the social data domain. The platforms which were used provided effective tools for optimal data ingesting, storing as well as processing and analysing. Based on the analytical part, it was observed that the word frequency method (n-grams) can effectively reveal the tweets content. According to the results of this study, the tweets proved their high informative potential regarding data quality and quantity.},
  doi       = {10.1145/3361821.3361825},
  isbn      = {9781450372411},
  keywords  = {Apache Spark, social network data, data processing architecture, Twitter},
  location  = {Tokyo, Japan},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3361821.3361825},
}

@InProceedings{Hogan2017,
  author    = {Hogan, Mary and Esposito, Flavio},
  booktitle = {Proceedings of the 23rd Annual International Conference on Mobile Computing and Networking},
  title     = {Poster: A Portfolio Theory Approach to Edge Traffic Engineering via Bayesian Networks},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {555–557},
  publisher = {Association for Computing Machinery},
  series    = {MobiCom '17},
  abstract  = {One of the main goals of mobile edge computing is to support new generation latency-sensitive networked applications. To manage such demanding applications, a fine-grained control of end-to-end paths is imperative. End-to-end delay estimation and forecast techniques were essential traffic engineering tools even before the mobile edge computing paradigm pushed the cloud closer to the end user. In this paper, we model the path selection problem for edge traffic engineering using a risk minimization technique inspired by portfolio theory in economics, and we use machine learning to estimate the risk of a path. In particular, using real latency time series measurements, collected with and without the GENI testbed, we compare four short-horizon latency estimation techniques, commonly used by the finance community to estimate prices of volatile financial instruments. Our initial results suggest that a Bayesian Network approach may lead to good latency estimation performance and open a few research questions that we are currently exploring.},
  doi       = {10.1145/3117811.3131250},
  isbn      = {9781450349161},
  keywords  = {Bayesian network, latency prediction, portfolio theory, machine learning, edge computing},
  location  = {Snowbird, Utah, USA},
  numpages  = {3},
  url       = {https://doi.org/10.1145/3117811.3131250},
}

@Article{Belson2019,
  author     = {Belson, Bruce and Holdsworth, Jason and Xiang, Wei and Philippa, Bronson},
  journal    = {ACM Trans. Embed. Comput. Syst.},
  title      = {A Survey of Asynchronous Programming Using Coroutines in the Internet of Things and Embedded Systems},
  year       = {2019},
  issn       = {1539-9087},
  month      = {jun},
  number     = {3},
  volume     = {18},
  abstract   = {Many Internet of Things and embedded projects are event driven, and therefore require asynchronous and concurrent programming. Current proposals for C++20 suggest that coroutines will have native language support. It is timely to survey the current use of coroutines in embedded systems development. This article investigates existing research which uses or describes coroutines on resource-constrained platforms. The existing research is analysed with regard to: software platform, hardware platform, and capacity; use cases and intended benefits; and the application programming interface design used for coroutines. A systematic mapping study was performed, to select studies published between 2007 and 2018 which contained original research into the application of coroutines on resource-constrained platforms. An initial set of 566 candidate papers, collated from on-line databases, were reduced to only 35 after filters were applied, revealing the following taxonomy. The C 8 C++ programming languages were used by 22 studies out of 35. As regards hardware, 16 studies used 8- or 16-bit processors while 13 used 32-bit processors. The four most common use cases were concurrency (17 papers), network communication (15), sensor readings (9), and data flow (7). The leading intended benefits were code style and simplicity (12 papers), scheduling (9), and efficiency (8). A wide variety of techniques have been used to implement coroutines, including native macros, additional tool chain steps, new language features, and non-portable assembly language. We conclude that there is widespread demand for coroutines on resource-constrained devices. Our findings suggest that there is significant demand for a formalised, stable, well-supported implementation of coroutines in C++, designed with consideration of the special needs of resource-constrained devices, and further that such an implementation would bring benefits specific to such devices.},
  address    = {New York, NY, USA},
  articleno  = {21},
  doi        = {10.1145/3319618},
  issue_date = {May 2019},
  keywords   = {asynchronous, scheduling, Embedded, direct style, resource-constrained},
  numpages   = {21},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3319618},
}

@InProceedings{Weyl2019,
  author    = {Weyl, Julius and Lenfers, Ulfia A. and Clemen, Thomas and Glake, Daniel and Panse, Fabian and Ritter, Norbert},
  booktitle = {Proceedings of the 2019 Summer Simulation Conference},
  title     = {Large-Scale Traffic Simulation for Smart City Planning with Mars},
  year      = {2019},
  address   = {San Diego, CA, USA},
  publisher = {Society for Computer Simulation International},
  series    = {SummerSim '19},
  abstract  = {Understanding individual mobility in larger cities is an important success factor for future smart cities. Related simulation scenarios incorporate enormous numbers of agents, with the disadvantage of long run times. In order to provide large-scale and multimodal traffic simulations, we developed MARS V3. Adapting the Modeling and Simulation as a Service (MSaaS) paradigm, a seamless workflow can be provided to the modeling community. An integrated domain-specific language allows model descriptions without a technical overhead. For this study, selected parts of an individual-based traffic model of the City of Hamburg, Germany, were taken as an example. The entire workflow from model development, open data integration, simulation, and result analysis will be described and evaluated. Performance was measured for local and cloud-based simulation execution for up to one million agents. First results show that this concept can be utilized for building decision support systems for smart cities in the near future.},
  articleno = {2},
  keywords  = {domain-specific-language, MSaaS, individual mobility, agent-based, large-scale traffic scenario},
  location  = {Berlin, Germany},
  numpages  = {12},
}

@Article{Sharma2020,
  author     = {Sharma, Pratima and Jindal, Rajni and Borah, Malaya Dutta},
  journal    = {ACM Comput. Surv.},
  title      = {Blockchain Technology for Cloud Storage: A Systematic Literature Review},
  year       = {2020},
  issn       = {0360-0300},
  month      = {aug},
  number     = {4},
  volume     = {53},
  abstract   = {The demand for Blockchain innovation and the significance of its application has inspired ever-progressing exploration in various scientific and practical areas. Even though it is still in the initial testing stage, the blockchain is being viewed as a progressive solution to address present-day technology concerns, such as decentralization, identity, trust, character, ownership of data, and information-driven choices. Simultaneously, the world is facing an increase in the diversity and quantity of digital information produced by machines and users. While effectively looking for the ideal approach to storing and processing cloud data, the blockchain innovation provides significant inputs. This article reviews the application of blockchain technology for securing cloud storage.},
  address    = {New York, NY, USA},
  articleno  = {89},
  doi        = {10.1145/3403954},
  issue_date = {July 2021},
  keywords   = {decentralization, cloud storage, Blockchain technology, cloud security, cloud computing},
  numpages   = {32},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3403954},
}

@InProceedings{Cheng2015,
  author    = {Cheng, Yue and Iqbal, M. Safdar and Gupta, Aayush and Butt, Ali R.},
  booktitle = {Proceedings of the 24th International Symposium on High-Performance Parallel and Distributed Computing},
  title     = {CAST: Tiering Storage for Data Analytics in the Cloud},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {45–56},
  publisher = {Association for Computing Machinery},
  series    = {HPDC '15},
  abstract  = {Enterprises are increasingly moving their big data analytics to the cloud with the goal of reducing costs without sacrificing application performance. Cloud service providers offer their tenants a myriad of storage options, which while flexible, makes the choice of storage deployment non trivial. Crafting deployment scenarios to leverage these choices in a cost-effective manner - under the unique pricing models and multi-tenancy dynamics of the cloud environment - presents unique challenges in designing cloud-based data analytics frameworks.In this paper, we propose CAST, a Cloud Analytics Storage Tiering solution that cloud tenants can use to reduce monetary cost and improve performance of analytics workloads. The approach takes the first step towards providing storage tiering support for data analytics in the cloud. CAST performs offline workload profiling to construct job performance prediction models on different cloud storage services, and combines these models with workload specifications and high-level tenant goals to generate a cost-effective data placement and storage provisioning plan. Furthermore, we build CAST++ to enhance CAST's optimization model by incorporating data reuse patterns and across-jobs interdependencies common in realistic analytics workloads. Tests with production workload traces from Facebook and a 400-core Google Cloud based Hadoop cluster demonstrate that CAST++ achieves 1.21X performance and reduces deployment costs by 51.4\% compared to local storage configuration.},
  doi       = {10.1145/2749246.2749252},
  isbn      = {9781450335508},
  keywords  = {big data analytics, cloud computing, mapreduce, storage tiering},
  location  = {Portland, Oregon, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2749246.2749252},
}

@InProceedings{Chen2019a,
  author    = {Chen, Qi and Ma, Xu and Tang, Sihai and Guo, Jingda and Yang, Qing and Fu, Song},
  booktitle = {Proceedings of the 4th ACM/IEEE Symposium on Edge Computing},
  title     = {F-Cooper: Feature Based Cooperative Perception for Autonomous Vehicle Edge Computing System Using 3D Point Clouds},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {88–100},
  publisher = {Association for Computing Machinery},
  series    = {SEC '19},
  abstract  = {Autonomous vehicles are heavily reliant upon their sensors to perfect the perception of surrounding environments, however, with the current state of technology, the data which a vehicle uses is confined to that from its own sensors. Data sharing between vehicles and/or edge servers is limited by the available network bandwidth and the stringent real-time constraints of autonomous driving applications. To address these issues, we propose a point cloud feature based cooperative perception framework (F-Cooper) for connected autonomous vehicles to achieve a better object detection precision. Not only will feature based data be sufficient for the training process, we also use the features' intrinsically small size to achieve real-time edge computing, without running the risk of congesting the network. Our experiment results show that by fusing features, we are able to achieve a better object detection result, around 10\% improvement for detection within 20 meters and 30\% for further distances, as well as achieve faster edge computing with a low communication delay, requiring 71 milliseconds in certain feature selections. To the best of our knowledge, we are the first to introduce feature-level data fusion to connected autonomous vehicles for the purpose of enhancing object detection and making real-time edge computing on inter-vehicle data feasible for autonomous vehicles.},
  doi       = {10.1145/3318216.3363300},
  isbn      = {9781450367332},
  keywords  = {feature fusion, edge computing, connected autonomous vehicle},
  location  = {Arlington, Virginia},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3318216.3363300},
}

@InProceedings{Hansen2020a,
  author    = {Hansen, Henry Haugsten and Muchallil, Sayed and Griwodz, Carsten and Sillerud, Vetle and Johanssen, Fredrik},
  booktitle = {Proceedings of the 11th ACM Multimedia Systems Conference},
  title     = {Dense LIDAR Point Clouds from Room-Scale Scans},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {88–98},
  publisher = {Association for Computing Machinery},
  series    = {MMSys '20},
  abstract  = {LiDARs can capture distances with high accuracy and should be very useful to create point clouds that provide highly detailed representations of an environment. If these reconstructions are meant as baseline or ground truth for other algorithms, they must have a high density and accuracy.Currently available LiDARs do still face some limitations. Either they have a limited range, or they have a rather limited resolution in one or more dimensions. As a consequence, all of them have to undergo motion to capture a larger environment. While some systems follow extremely well-predictable motion paths such as satellite trajectories or robotic arms, others require more spontaneous and flexible motion. These systems use either visual simultaneous localization and mapping (vSLAM), GPS or IMU to achieve this, but they are generally designed in such a way that human intervention is required during the creation of high-quality point clouds.In this paper, we make use of a rotating LiDAR with an attached IMU to create dense point clouds of room-scale environments with the base accuracy of the LiDAR by compensating for the various inaccuracies that are introduced by the LiDAR's motion. The resulting dense scans are suitable as ground truths for other techniques because we retain the error distribution of the LiDAR itself through the densification.In contrast to other works, we do not aim at a visually pleasing or easily meshable result and we can therefore avoid potentially inaccurate assumptions about the flatness of surfaces. We take a two-step approach. First, we densify from a stationary position changing only the LiDAR's pitch. Second, we add free motion to expose obstructed views. We show that motion paths determined by repeated Iterative Closest Point (ICP) as well as image matching on height maps can be used to create feasible priors for densification using ICP.},
  doi       = {10.1145/3339825.3391862},
  isbn      = {9781450368452},
  keywords  = {machine learning, point clouds, densification, height maps},
  location  = {Istanbul, Turkey},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3339825.3391862},
}

@InProceedings{Rewari2015,
  author    = {Rewari, Gaurav and Kapoor, Rahul},
  booktitle = {Proceedings of the 2nd Workshop on Parallel Programming for Analytics Applications},
  title     = {Analytics Applications on the Cloud: Business Potential, Solution Requirements, and Research Opportunities (Invited Talk)},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {3},
  publisher = {Association for Computing Machinery},
  series    = {PPAA 2015},
  abstract  = {The rapid adoption of cloud applications like SalesForce, ServiceNow, NetSuite, Marketo etc. has opened up an interesting opportunity for vendors of analytical applications and BI middleware as these modern cloud data sources are not well served by existing BI Tools and applications. For customers, part or all of their data moving to the cloud also means any existing on-premise warehouses and analytical applications are partially or fully defunct, and with the increased acceptance of moving application level functionality to the cloud there is little interest in upgrading the defunct on-premise offerings. A new class of software vendors, including Numerify, step into this gap by providing a cloud based, end-to-end solution for data extraction, transformation and warehouse based analytical applications, directly to the business user in select domains (e.g. IT Service Management, Human Resources and Financials). This talk summarizes the overall business potential for analytics on the cloud, expands on “analytical applications” with some examples, discusses engineering challenges in implementing cloud based analytics solutions highlighting some advances in ETL techniques, and points to potential research opportunities in this space.},
  doi       = {10.1145/2726935.2726938},
  isbn      = {9781450334051},
  keywords  = {MDM, Warehousing, Data Integration, Analytical Applications, Data Quality, Business Intelligence, ETL, Cloud Software},
  location  = {San Francisco, CA, USA},
  numpages  = {1},
  url       = {https://doi.org/10.1145/2726935.2726938},
}

@Article{Mencagli2016,
  author     = {Mencagli, Gabriele},
  journal    = {ACM Trans. Auton. Adapt. Syst.},
  title      = {A Game-Theoretic Approach for Elastic Distributed Data Stream Processing},
  year       = {2016},
  issn       = {1556-4665},
  month      = {jun},
  number     = {2},
  volume     = {11},
  abstract   = {Distributed data stream processing applications are structured as graphs of interconnected modules able to ingest high-speed data and to transform them in order to generate results of interest. Elasticity is one of the most appealing features of stream processing applications. It makes it possible to scale up/down the allocated computing resources on demand in response to fluctuations of the workload. On clouds, this represents a necessary feature to keep the operating cost at affordable levels while accommodating user-defined QoS requirements. In this article, we study this problem from a game-theoretic perspective. The control logic driving elasticity is distributed among local control agents capable of choosing the right amount of resources to use by each module. In a first step, we model the problem as a noncooperative game in which agents pursue their self-interest. We identify the Nash equilibria and we design a distributed procedure to reach the best equilibrium in the Pareto sense. As a second step, we extend the noncooperative formulation with a decentralized incentive-based mechanism in order to promote cooperation by moving the agreement point closer to the system optimum. Simulations confirm the results of our theoretical analysis and the quality of our strategies.},
  address    = {New York, NY, USA},
  articleno  = {13},
  doi        = {10.1145/2903146},
  issue_date = {July 2016},
  keywords   = {game theory, data stream processing, elasticity, Autonomic computing},
  numpages   = {34},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2903146},
}

@Article{Jones2020,
  author     = {Jones, R. Kenny and Barton, Theresa and Xu, Xianghao and Wang, Kai and Jiang, Ellen and Guerrero, Paul and Mitra, Niloy J. and Ritchie, Daniel},
  journal    = {ACM Trans. Graph.},
  title      = {ShapeAssembly: Learning to Generate Programs for 3D Shape Structure Synthesis},
  year       = {2020},
  issn       = {0730-0301},
  month      = {nov},
  number     = {6},
  volume     = {39},
  abstract   = {Manually authoring 3D shapes is difficult and time consuming; generative models of 3D shapes offer compelling alternatives. Procedural representations are one such possibility: they offer high-quality and editable results but are difficult to author and often produce outputs with limited diversity. On the other extreme are deep generative models: given enough data, they can learn to generate any class of shape but their outputs have artifacts and the representation is not editable.In this paper, we take a step towards achieving the best of both worlds for novel 3D shape synthesis. First, we propose ShapeAssembly, a domain-specific "assembly-language" for 3D shape structures. ShapeAssembly programs construct shape structures by declaring cuboid part proxies and attaching them to one another, in a hierarchical and symmetrical fashion. ShapeAssembly functions are parameterized with continuous free variables, so that one program structure is able to capture a family of related shapes.We show how to extract ShapeAssembly programs from existing shape structures in the PartNet dataset. Then, we train a deep generative model, a hierarchical sequence VAE, that learns to write novel ShapeAssembly programs. Our approach leverages the strengths of each representation: the program captures the subset of shape variability that is interpretable and editable, and the deep generative model captures variability and correlations across shape collections that is hard to express procedurally.We evaluate our approach by comparing the shapes output by our generated programs to those from other recent shape structure synthesis models. We find that our generated shapes are more plausible and physically-valid than those of other methods. Additionally, we assess the latent spaces of these models, and find that ours is better structured and produces smoother interpolations. As an application, we use our generative model and differentiable program interpreter to infer and fit shape programs to unstructured geometry, such as point clouds.},
  address    = {New York, NY, USA},
  articleno  = {234},
  doi        = {10.1145/3414685.3417812},
  issue_date = {December 2020},
  keywords   = {neurosymbolic models, procedural modeling, deep learning, shape synthesis, shape analysis, generative models},
  numpages   = {20},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3414685.3417812},
}

@Article{Qin2020,
  author     = {Qin, Xin and Chen, Yiqiang and Wang, Jindong and Yu, Chaohui},
  journal    = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
  title      = {Cross-Dataset Activity Recognition via Adaptive Spatial-Temporal Transfer Learning},
  year       = {2020},
  month      = {sep},
  number     = {4},
  volume     = {3},
  abstract   = {Human activity recognition (HAR) aims at recognizing activities by training models on the large quantity of sensor data. Since it is time-consuming and expensive to acquire abundant labeled data, transfer learning becomes necessary for HAR by transferring knowledge from existing domains. However, there are two challenges existing in cross-dataset activity recognition. The first challenge is source domain selection. Given a target task and several available source domains, it is difficult to determine how to select the most similar source domain to the target domain such that negative transfer can be avoided. The second one is accurately activity transfer. After source domain selection, how to achieve accurate knowledge transfer between the selected source and the target domain remains another challenge. In this paper, we propose an Adaptive Spatial-Temporal Transfer Learning (ASTTL) approach to tackle both of the above two challenges in cross-dataset HAR. ASTTL learns the spatial features in transfer learning by adaptively evaluating the relative importance between the marginal and conditional probability distributions. Besides, it captures the temporal features via incremental manifold learning. Therefore, ASTTL can learn the adaptive spatial-temporal features for cross-dataset HAR and can be used for both source domain selection and accurate activity transfer. We evaluate the performance of ASTTL through extensive experiments on 4 public HAR datasets, which demonstrates its effectiveness. Furthermore, based on ASTTL, we design and implement an adaptive cross-dataset HAR system called Client-Cloud Collaborative Adaptive Activity Recognition System (3C2ARS) to perform HAR in the real environment. By collecting activities in the smartphone and transferring knowledge in the cloud server, ASTTL can significantly improve the performance of source domain selection and accurate activity transfer.},
  address    = {New York, NY, USA},
  articleno  = {148},
  doi        = {10.1145/3369818},
  issue_date = {December 2019},
  keywords   = {Domain Adaptation, Transfer Learning, Human Activity Recognition, Cross-Dataset Recognition},
  numpages   = {25},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3369818},
}

@InProceedings{Jung2014,
  author    = {Jung, Seunghwan and Lee, Sejoon and Kim, Sangwoo and Nam, Hojung},
  booktitle = {Proceedings of the ACM 8th International Workshop on Data and Text Mining in Bioinformatics},
  title     = {Identification of Genomic Features in the Classification of Loss- and Gain-of-Function Mutation: [Extended Abstract]},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {23},
  publisher = {Association for Computing Machinery},
  series    = {DTMBIO '14},
  abstract  = {In this work, we propose a comprehensive analysis of the genomic features of the human in mutations to classify loss-of-function (LoF) and gain-of-function (GoF) mutations. Through these genetic mutations, a protein can lose its native function, or it can confer a new function. However, when a mutation occurs, it is difficult to determine whether it will result in a LoF or a GoF. Therefore, we propose a study that analyzes the human genomic features of LoF and GoF instances to find features that can be used to classify LoF and GoF mutations. In order to collect experimentally verified LoF and GoF mutational information, we obtained 816 LoF mutations and 474 GoF mutations from a literature text-mining process. Next, with data-preprocessing steps, 258 LoF and 129 GoF mutations remained for a further analysis. We analyzed the properties of these LoF and GoF mutations. Among the properties, we selected features which show different tendencies between the two groups. Finally, we implemented classifications using support vector machine, random forest, and logistic regression methods to confirm whether or not these features can identify LoF and GoF mutations. By implementing classifications with the selected features, it is demonstrated that the selected features have good discriminative power.},
  doi       = {10.1145/2665970.2665977},
  isbn      = {9781450312752},
  keywords  = {gain-of-function, loss-of-function},
  location  = {Shanghai, China},
  numpages  = {1},
  url       = {https://doi.org/10.1145/2665970.2665977},
}

@InProceedings{Ogden2021,
  author    = {Ogden, Samuel S. and Kong, Xiangnan and Guo, Tian},
  booktitle = {Proceedings of the ACM/SPEC International Conference on Performance Engineering},
  title     = {PieSlicer: Dynamically Improving Response Time for Cloud-Based CNN Inference},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {249–256},
  publisher = {Association for Computing Machinery},
  series    = {ICPE '21},
  abstract  = {Executing deep-learning inference on cloud servers enables the usage of high complexity models for mobile devices with limited resources. However, pre-execution time-the time it takes to prepare and transfer data to the cloud-is variable and can take orders of magnitude longer to complete than inference execution itself. This pre-execution time can be reduced by dynamically deciding the order of two essential steps, preprocessing and data transfer, to better take advantage of on-device resources and network conditions. In this work, we present PieSlicer, a system for making dynamic preprocessing decisions to improve cloud inference performance using linear regression models. PieSlicer then leverages these models to select the appropriate preprocessing location. We show that for image classification applications PieSlicer reduces median and 99th percentile pre-execution time by up to 50.2ms and 217.2ms respectively when compared to static preprocessing methods.},
  doi       = {10.1145/3427921.3450256},
  isbn      = {9781450381949},
  keywords  = {cloud inference, performance modeling, mobile deep learning},
  location  = {Virtual Event, France},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3427921.3450256},
}

@Article{Mailis2021,
  author     = {Mailis, Theofilos and Kotidis, Yannis and Christoforidis, Stamatis and Kharlamov, Evgeny and Ioannidis, Yannis},
  journal    = {Proc. VLDB Endow.},
  title      = {View Selection over Knowledge Graphs in Triple Stores},
  year       = {2021},
  issn       = {2150-8097},
  month      = {sep},
  number     = {13},
  pages      = {3281–3294},
  volume     = {14},
  abstract   = {Knowledge Graphs (KGs) are collections of interconnected and annotated entities that have become powerful assets for data integration, search enhancement, and other industrial applications. Knowledge Graphs such as DBPEDIA may contain billion of triple relations and are intensively queried with millions of queries per day. A prominent approach to enhance query answering on Knowledge Graph databases is View Materialization, ie., the materialization of an appropriate set of computations that will improve query performance.We study the problem of view materialization and propose a view selection methodology for processing query workloads with more than a million queries. Our approach heavily relies on subgraph pattern mining techniques that allow to create efficient summarizations of massive query workloads while also identifying the candidate views for materialization. In the core of our work is the correspondence between the view selection problem to that of Maximizing a Nondecreasing Submodular Set Function Subject to a Knapsack Constraint. The latter leads to a tractable view-selection process for native triple stores that allows a (1 - e---1)-approximation of the optimal selection of views. Our experimental evaluation shows that all the steps of the view-selection process are completed in a few minutes, while the corresponding rewritings accelerate 67.68\% of the queries in the DBPEDIA query workload. Those queries are executed in 2.19\% of their initial time on average.},
  doi        = {10.14778/3484224.3484227},
  issue_date = {September 2021},
  numpages   = {14},
  publisher  = {VLDB Endowment},
  url        = {https://doi.org/10.14778/3484224.3484227},
}

@Article{GarzaFabre2016,
  author     = {Garza-Fabre, Mario and Kandathil, Shaun M. and Handl, Julia and Knowles, Joshua and Lovell, Simon C.},
  journal    = {Evol. Comput.},
  title      = {Generating, Maintaining, and Exploiting Diversity in a Memetic Algorithm for Protein Structure Prediction},
  year       = {2016},
  issn       = {1063-6560},
  month      = {dec},
  number     = {4},
  pages      = {577–607},
  volume     = {24},
  abstract   = {Computational approaches to de novo protein tertiary structure prediction, including those based on the preeminent "fragment-assembly" technique, have failed to scale up fully to larger proteins on the order of 100 residues and above. A number of limiting factors are thought to contribute to the scaling problem over and above the simple combinatorial explosion, but the key ones relate to the lack of exploration of properly diverse protein folds, and to an acute form of "deception" in the energy function, whereby low-energy conformations do not reliably equate with native structures. In this article, solutions to both of these problems are investigated through a multistage memetic algorithm incorporating the successful Rosetta method as a local search routine. We found that specialised genetic operators significantly add to structural diversity and that this translates well to reaching low energies. The use of a generalised stochastic ranking procedure for selection enables the memetic algorithm to handle and traverse deep energy wells that can be considered deceptive, which further adds to the ability of the algorithm to obtain a much-improved diversity of folds. The results should translate to a tangible improvement in the performance of protein structure prediction algorithms in blind experiments such as CASP, and potentially to a further step towards the more challenging problem of predicting the three-dimensional shape of large proteins.},
  address    = {Cambridge, MA, USA},
  doi        = {10.1162/EVCO_a_00176},
  issue_date = {Winter 2016},
  keywords   = {Memetic algorithms., Protein structure prediction, Fragment assembly},
  numpages   = {31},
  publisher  = {MIT Press},
  url        = {https://doi.org/10.1162/EVCO_a_00176},
}

@InProceedings{Choi2020,
  author    = {Choi, In Kwon and Abeysinghe, Eroma and Coulter, Eric and Marru, Suresh and Pierce, Marlon and Liu, Xiaowen},
  booktitle = {Practice and Experience in Advanced Research Computing},
  title     = {TopPIC Gateway: A Web Gateway for Top-Down Mass Spectrometry Data Interpretation},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {461–464},
  publisher = {Association for Computing Machinery},
  series    = {PEARC '20},
  abstract  = {Top-down mass spectrometry-based proteomics has become the method of choice for identifying and quantifying intact proteoforms in biological samples. We present a web-based gateway for TopPIC suite, a widely used software suite consisting of four software tools for top-down mass spectrometry data interpretation: TopFD, TopPIC, TopMG, and TopDiff. The gateway enables the community to use heterogeneous collection of computing resources that includes high performance computing clusters at Indiana University and virtual clusters on XSEDE’s Jetstream Cloud resource for top-down mass spectral data analysis using TopPIC suite. The gateway will be a useful resource for proteomics researchers and students who have limited access to high-performance computing resources or who are not familiar with interacting with server-side supercomputers.},
  doi       = {10.1145/3311790.3400853},
  isbn      = {9781450366892},
  keywords  = {Proteomics, Apache Airavata, SciGaP, XSEDE, Top-down mass spectrometry, Science Gateways},
  location  = {Portland, OR, USA},
  numpages  = {4},
  url       = {https://doi.org/10.1145/3311790.3400853},
}

@InProceedings{Gulzar2016,
  author    = {Gulzar, Muhammad Ali and Interlandi, Matteo and Condie, Tyson and Kim, Miryung},
  booktitle = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  title     = {BigDebug: Interactive Debugger for Big Data Analytics in Apache Spark},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {1033–1037},
  publisher = {Association for Computing Machinery},
  series    = {FSE 2016},
  abstract  = {To process massive quantities of data, developers leverage data-intensive scalable computing (DISC) systems in the cloud, such as Google's MapReduce, Apache Hadoop, and Apache Spark. In terms of debugging, DISC systems support post-mortem log analysis but do not provide interactive debugging features in realtime. This tool demonstration paper showcases a set of concrete usecases on how BigDebug can help debug Big Data Applications by providing interactive, realtime debug primitives. To emulate interactive step-wise debugging without reducing throughput, BigDebug provides simulated breakpoints to enable a user to inspect a program without actually pausing the entire computation. To minimize unnecessary communication and data transfer, BigDebug provides on-demand watchpoints that enable a user to retrieve intermediate data using a guard and transfer the selected data on demand. To support systematic and efficient trial-and-error debugging, BigDebug also enables users to change program logic in response to an error at runtime and replay the execution from that step. BigDebug is available for download at http://web.cs.ucla.edu/~miryung/software.html},
  doi       = {10.1145/2950290.2983930},
  isbn      = {9781450342186},
  keywords  = {interactive tools, fault localization and recovery, big data analytics, data-intensive scalable computing (DISC), Debugging},
  location  = {Seattle, WA, USA},
  numpages  = {5},
  url       = {https://doi.org/10.1145/2950290.2983930},
}

@InProceedings{Cooke2020,
  author    = {Cooke, Ryan A. and Fahmy, Suhaib A.},
  booktitle = {Proceedings of the Third ACM International Workshop on Edge Systems, Analytics and Networking},
  title     = {Quantifying the Latency Benefits of Near-Edge and in-Network FPGA Acceleration},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {7–12},
  publisher = {Association for Computing Machinery},
  series    = {EdgeSys '20},
  abstract  = {Transmitting data to cloud datacenters in distributed IoT applications introduces significant communication latency, but is often the only feasible solution when source nodes are computationally limited. To address latency concerns, Cloudlets, in-network computing, and more capable edge nodes are all being explored as a way of moving processing capability towards the edge of the network. Hardware acceleration using Field programmable gate arrays (FPGAs) is also seeing increased interest due to reduced computation time and improved efficiency. This paper evaluates the the implications of these offloading approaches using a case study neural network based image classification application, quantifying both the computation and communication latency resulting from different platform choices. We demonstrate that emerging in-network accelerator approaches offer much improved and predictable performance as well as better scaling to support multiple data sources.},
  doi       = {10.1145/3378679.3394534},
  isbn      = {9781450371322},
  keywords  = {edge computing, hardware acceleration},
  location  = {Heraklion, Greece},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3378679.3394534},
}

@Article{Li2021b,
  author     = {Li, Side and Kumar, Arun},
  journal    = {Proc. VLDB Endow.},
  title      = {Towards an Optimized GROUP by Abstraction for Large-Scale Machine Learning},
  year       = {2021},
  issn       = {2150-8097},
  month      = {jul},
  number     = {11},
  pages      = {2327–2340},
  volume     = {14},
  abstract   = {Many applications that use large-scale machine learning (ML) increasingly prefer different models for subgroups (e.g., countries) to improve accuracy, fairness, or other desiderata. We call this emerging popular practice learning over groups, analogizing to GROUP BY in SQL, albeit for ML training instead of SQL aggregates. From the systems standpoint, this practice compounds the already data-intensive workload of ML model selection (e.g., hyperparameter tuning). Often, thousands of models may need to be trained, necessitating high-throughput parallel execution. Alas, most ML systems today focus on training one model at a time or at best, parallelizing hyperparameter tuning. This status quo leads to resource wastage, low throughput, and high runtimes. In this work, we take the first step towards enabling and optimizing learning over groups from the data systems standpoint for three popular classes of ML: linear models, neural networks, and gradient-boosted decision trees. Analytically and empirically, we compare standard approaches to execute this workload today: task-parallelism and data-parallelism. We find neither is universally dominant. We put forth a novel hybrid approach we call grouped learning that avoids redundancy in communications and I/O using a novel form of parallel gradient descent we call Gradient Accumulation Parallelism (GAP). We prototype our ideas into a system we call Kingpin built on top of existing ML tools and the flexible massively-parallel runtime Ray. An extensive empirical evaluation on large ML benchmark datasets shows that Kingpin matches or is 4x to 14x faster than state-of-the-art ML systems, including Ray's native execution and PyTorch DDP.},
  doi        = {10.14778/3476249.3476284},
  issue_date = {July 2021},
  numpages   = {14},
  publisher  = {VLDB Endowment},
  url        = {https://doi.org/10.14778/3476249.3476284},
}

@InProceedings{Guo2014,
  author    = {Guo, Yong and Varbanescu, Ana Lucia and Iosup, Alexandru and Martella, Claudio and Willke, Theodore L.},
  booktitle = {Proceedings of the 5th ACM/SPEC International Conference on Performance Engineering},
  title     = {Benchmarking Graph-Processing Platforms: A Vision},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {289–292},
  publisher = {Association for Computing Machinery},
  series    = {ICPE '14},
  abstract  = {Processing graphs, especially at large scale, is an increasingly useful activity in a variety of business, engineering, and scientific domains. Already, there are tens of graph-processing platforms, such as Hadoop, Giraph, GraphLab, etc., each with a different design and functionality. For graph-processing to continue to evolve, users have to find it easy to select a graph-processing platform, and developers and system integrators have to find it easy to quantify the performance and other non-functional aspects of interest. However, the state of performance analysis of graph-processing platforms is still immature: there are few studies and, for the few that exist, there are few similarities, and relatively little understanding of the impact of dataset and algorithm diversity on performance. Our vision is to develop, with the help of the performance-savvy community, a comprehensive benchmarking suite for graph-processing platforms. In this work, we take a step in this direction, by proposing a set of seven challenges, summarizing our previous work on performance evaluation of distributed graph-processing platforms, and introducing our on-going work within the SPEC Research Group's Cloud Working Group.},
  doi       = {10.1145/2568088.2576761},
  isbn      = {9781450327336},
  keywords  = {benchmarking, experimentation, performance, graph processing},
  location  = {Dublin, Ireland},
  numpages  = {4},
  url       = {https://doi.org/10.1145/2568088.2576761},
}

@InProceedings{Kuhlenkamp2020,
  author    = {Kuhlenkamp, J\"{o}rn and Werner, Sebastian and Borges, Maria C. and Ernst, Dominik and Wenzel, Daniel},
  booktitle = {Proceedings of the 35th Annual ACM Symposium on Applied Computing},
  title     = {Benchmarking Elasticity of FaaS Platforms as a Foundation for Objective-Driven Design of Serverless Applications},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {1576–1585},
  publisher = {Association for Computing Machinery},
  series    = {SAC '20},
  abstract  = {Application providers have to solve the trade-off between performance and deployment costs by selecting the "right" amount of provisioned computing resources for their application. The high value of changing this trade-off decision at runtime fueled a decade of combined efforts by industry and research to develop elastic applications. Despite these efforts, the development of elastic applications still demands significant time and expertise from application providers.To address this demand, FaaS platforms shift responsibilities associated with elasticity from the application developer to the cloud provider. While this shift is highly promising, FaaS platforms do not quantify elasticity; thus, application developers are unaware of how elastic FaaS platforms are. This lack of knowledge significantly impairs effective objective-driven design of serverless applications.In this paper, we present an experiment design and corresponding toolkit for quantifying elasticity and its associated trade-offs with latency, reliability, and execution costs. We present results for the evaluation of four popular FaaS platforms by AWS, Google, IBM, Microsoft, and show significant differences between the service offers. Based on our results, we assess the applicability of the individual FaaS platforms in three scenarios under different objectives: web serving, online data analysis, and offline batch processing.},
  doi       = {10.1145/3341105.3373948},
  isbn      = {9781450368667},
  keywords  = {serverless, experimentation, elasticity, benchmarking},
  location  = {Brno, Czech Republic},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3341105.3373948},
}

@InProceedings{Karthik2014,
  author    = {Karthik, M. Siva and Mittal, Sudhanshu and Krishna, K. Madhava},
  booktitle = {Proceedings of the 2014 Indian Conference on Computer Vision Graphics and Image Processing},
  title     = {Guess from Far, Recognize When Near: Searching the Floor for Small Objects},
  year      = {2014},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ICVGIP '14},
  abstract  = {In indoor environments, there would be several small objects lying around on the floor. In this work, we develop an efficient strategy to search for a set of queried objects amongst a large number of small objects lying around. Small objects of the order of 1cm – 5cm, appear very small, making it difficult for the present algorithms to recognize them from far away. A human like strategy in such cases is to infer each object's similarity to the queried objects, from far away. Subsequently, the objects of interest are approached and analyzed from a closer proximity through an optimal plan. We develop an optimal plan for the robot, to strategically visit a selected few among all the objects. From far away, we assign Existential Probabilities to the objects, indicating their similarity to queried objects. A Bayes' Net is constructed over the probabilities, to overlay and orient a Viewpoint Object Potential(VOP) map over potential search objects. VOP quantifies the probability of accurately recognizing an object through its RGB-D Point Cloud at various viewpoints. The belief from the Bayes' Net and the discriminative viewpoints from the VOP are utilized to formulate a Decision Tree which helps in building an optimal control plan. Hence, the robot reaches strategic viewpoints around potential objects, to recognize them through their RGB-D point clouds. The framework is experimentally evaluated using Kinect mounted on a Turtlebot using ROS platform.},
  articleno = {61},
  doi       = {10.1145/2683483.2683544},
  isbn      = {9781450330619},
  keywords  = {Mobile Robotics, Visual Object Search},
  location  = {Bangalore, India},
  numpages  = {8},
  url       = {https://doi.org/10.1145/2683483.2683544},
}

@InProceedings{Bondarenko2016,
  author    = {Bondarenko, Olga and De Schepper, Koen and Tsang, Ing-Jyh and Briscoe, Bob and Petlund, Andreas and Griwodz, Carsten},
  booktitle = {Proceedings of the 7th International Conference on Multimedia Systems},
  title     = {Ultra-Low Delay for All: Live Experience, Live Analysis},
  year      = {2016},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {MMSys '16},
  abstract  = {This demo dramatically illustrates how replacing 'Classic' TCP congestion control (Reno, Cubic, etc.) with a 'Scalable' alternative like Data Centre TCP (DCTCP) keeps queuing delay ultra-low; not just for a select few light applications like voice or gaming, but even when a variety of interactive applications all heavily load the same (emulated) Internet access. DCTCP has so far been confined to data centres because it is too aggressive---it starves Classic TCP flows. To allow DCTCP to be exploited on the public Internet, we developed DualQ Coupled Active Queue Management (AQM), which allows the two TCP types to safely co-exist. Visitors can test all these claims. As well as running Web-based apps, they can pan and zoom a panoramic video of a football stadium on a touch-screen, and experience how their personalized HD scene seems to stick to their finger, even though it is encoded on the fly on servers accessed via an emulated delay, representing 'the cloud'. A pair of VR goggles can be used at the same time, making a similar point. The demo provides a dashboard so that visitors can not only experience the interactivity of each application live, but they can also quantify it via a wide range of performance stats, updated live. It also includes controls so visitors can configure different TCP variants, AQMs, network parameters and background loads and immediately test the effect.},
  articleno = {33},
  doi       = {10.1145/2910017.2910633},
  isbn      = {9781450342971},
  location  = {Klagenfurt, Austria},
  numpages  = {4},
  url       = {https://doi.org/10.1145/2910017.2910633},
}

@InProceedings{Boutet2021,
  author    = {Boutet, Antoine and Frindel, Carole and Gambs, S\'{e}bastien and Jourdan, Th\'{e}o and Ngueveu, Rosin Claude},
  booktitle = {Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security},
  title     = {DySan: Dynamically Sanitizing Motion Sensor Data Against Sensitive Inferences through Adversarial Networks},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {672–686},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '21},
  abstract  = {With the widespread development of the quantified-self movement, an increasing number of users rely on mobile applications to monitor their physical activity through their smartphones. However, granting applications a direct access to sensor data exposes users to privacy risks. In particular, motion sensor data are usually transmitted to analytics applications hosted in the cloud, which leverages on machine learning models to provide feedback on their activity status to users. In this setting, nothing prevents the service provider to infer private and sensitive information about a user such as health or demographic attributes. To address this issue, we propose DySan, a privacy-preserving framework to sanitize motion sensor data against unwanted sensitive inferences (i.e., improving privacy) while limiting the loss of accuracy on the physical activity monitoring (i.e., maintaining data utility). Our approach is inspired from the framework of Generative Adversarial Networks to sanitize the sensor data for the purpose of ensuring a good trade-off between utility and privacy. More precisely, by learning in a competitive manner several networks, DySan is able to build models that sanitize motion data against inferences on a specified sensitive attribute (e.g., gender) while maintaining an accurate activity recognition. DySan builds various sanitizing models, characterized by different sets of hyperparameters in the global loss function, to propose a transfer learning scheme over time by dynamically selecting the model which provides the best utility and privacy trade-off according to the incoming data. Experiments conducted on real datasets demonstrate that DySan can drastically limit the gender inference up to 41\% (from 98\% with raw data to 57\% with sanitized data) while only reducing the accuracy of activity recognition by 3\% (from 95\% with raw data to 92\% with sanitized data).},
  doi       = {10.1145/3433210.3453095},
  isbn      = {9781450382878},
  keywords  = {gan, privacy, utility-privacy trade-off, activity detection},
  location  = {Virtual Event, Hong Kong},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3433210.3453095},
}

@InProceedings{Sianipar2017,
  author    = {Sianipar, Johannes and Willems, Christian and Meinel, Christoph},
  booktitle = {Proceedings of the 2017 International Conference on Cloud and Big Data Computing},
  title     = {Team Placement in Crowd-Resourcing Virtual Laboratory for IT Security e-Learning},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {60–66},
  publisher = {Association for Computing Machinery},
  series    = {ICCBDC '17},
  abstract  = {A crowd-resourcing virtual laboratory is a virtual laboratory in which some of the resources are obtained from the crowd. The virtual laboratory is for IT Security e-Learning, where a trainee needs an isolated laboratory environment to do the practical exercises. The isolated laboratory environment, which is called as a Team, consists of virtual machines (VMs) or containers and virtual network devices. The crowd contributes their resources such as virtual machines or physical machines, to the virtual laboratory. The virtual laboratory automatically occupies the contributed resources and uses them to create a Team. The team that consists of containers, will be run in a VM. Since there could be a lot of VMs available, the system needs to select the best VM to run a Team. We present CTPlace, an approach for Team Placement in crowd-resourcing virtual laboratory.CTPlace groups the VMs into tree hierarchical clusters based on the Geo-location of the VMs. CTPlace has two steps in the Team placement. First, it selects a nearest cluster to the trainee location to get the highest throughput. Second, it selects a VM inside the selected cluster. To select a VM inside a public cloud cluster, it uses Most-Full-First algorithm to reduce service cost by reducing the number of running VMs. To select a VM inside a private cloud or within contributed resources, it uses Least-Full-First and Tag-Pack to balance the load and try to place the same type of Teams on the same VM. We compare the CTPlace with three other placement algorithms in a simulated environment, to evaluate the performance of the CTPlace.},
  doi       = {10.1145/3141128.3141146},
  isbn      = {9781450353434},
  keywords  = {Virtual Laboratory, Cloud Computing, Placement Algorithm, Crowd-resourcing},
  location  = {London, United Kingdom},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3141128.3141146},
}

@InProceedings{Steinlechner2019,
  author    = {Steinlechner, Harald and Rainer, Bernhard and Schw\"{a}rzler, Michael and Haaser, Georg and Szabo, Attila and Maierhofer, Stefan and Wimmer, Michael},
  booktitle = {Proceedings of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games},
  title     = {Adaptive Pointcloud Segmentation for Assisted Interactions},
  year      = {2019},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {I3D '19},
  abstract  = {In this work, we propose an interaction-driven approach streamlined to support and improve a wide range of real-time 2D interaction metaphors for arbitrarily large pointclouds based on detected primitive shapes. Rather than performing shape detection as a costly pre-processing step on the entire point cloud at once, a user-controlled interaction determines the region that is to be segmented next. By keeping the size of the region and the number of points small, the algorithm produces meaningful results and therefore feedback on the local geometry within a fraction of a second. We can apply these finding for improved picking and selection metaphors in large point clouds, and propose further novel shape-assisted interactions that utilize this local semantic information to improve the user's workflow.},
  articleno = {14},
  doi       = {10.1145/3306131.3317023},
  isbn      = {9781450363105},
  keywords  = {interactive editing, shape detection, pointcloud segmentation},
  location  = {Montreal, Quebec, Canada},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3306131.3317023},
}

@Article{Butnaru2021,
  author     = {Butnaru, Andrei-M\u{a}d\u{a}lin},
  journal    = {SIGIR Forum},
  title      = {Machine Learning Applied in Natural Language Processing},
  year       = {2021},
  issn       = {0163-5840},
  month      = {feb},
  number     = {1},
  volume     = {54},
  abstract   = {Machine Learning is present in our lives now more than ever. One of the most researched areas in machine learning is focused on creating systems that are able to understand natural language. Natural language processing is a broad domain, having a vast number of applications with a significant impact in society. In our current era, we rely on tools that can ease our lives. We can search through thousands of documents to find something that we need, but this can take a lot of time. Having a system that can understand a simple query and return only relevant documents is more efficient. Although current approaches are well capable of understanding natural language, there is still space for improvement.This thesis studies multiple natural language processing tasks, presenting approaches on applications such as information retrieval, polarity detection, dialect identification [Butnaru and Ionescu, 2018], automatic essay scoring [Cozma et al., 2018], and methods that can help other systems to understand documents better. Part of the described approaches from this thesis are employing kernel methods, especially string kernels. A method based on string kernels that can determine in what dialect a document is written is presented in this thesis. The approach is treating texts at the character level, extracting features in the form of p-grams of characters, and combining several kernels, including presence bits kernel and intersection kernel. Kernel methods are also presented as a solution for defining the complexity of a specific word. By combining multiple low-level features and high-level semantic features, the approach can find if a non-native speaker of a language can see a word as complicated or not. With one focus on string kernels, this thesis proposes two transductive methods that can improve the results obtained by employing string kernels. One approach suggests using the pairwise string kernel similarities between samples from the training and test sets as features. The other method defines a simple self-training algorithm composed of two iterations. As usual, a classifier is trained over the training data, then is it used to predict the labels of the test samples. In the second iteration, the algorithm adds a predefined number of test samples to the training set for another round of training. These two transductive methods work by adapting the learning method to the test set.A novel cross-dialectal corpus is shown in this thesis. The Moldavian versus Romanian Corpus (MOROCO) [Butnaru and Ionescu, 2019a] contains over 30.000 samples collected from the news domain, split across six categories. Several studies can be employed over this corpus such as binary classification between Romanian and Moldavian samples, intra-dialect multi-class categorization by topic, and cross-dialect multi-class classification by topic. Two baseline approaches are presented for this collection of texts. One method is based on a simple string kernel model. The second approach consists of a character-level deep neural network, which includes several Squeeze-and-Excitation Blocks (SE-blocks). As known at this moment, this is the first time when a SE-block is employed in a natural language processing context. This thesis also presents a method for German Dialect Identification composed on a voting scheme that combines a Character-level Convolutional Neural Network, a Long Short-Term Memory Network, and a model based on String Kernels.Word sense disambiguation is still one of the challenges of the NLP domain. In this context, this thesis tackles this challenge and presents a novel disambiguation algorithm, known as ShowtgunWSD [Butnaru and Ionescu, 2019b]. By treating the global disambiguation problem as multiple local disambiguation problems, ShotgunWSD is capable of determining the sense of the words in an unsupervised and deterministic way, using WordNet as a resource. For this method to work, three functions that can compute the similarity between two words senses are defined. The disambiguation algorithm works as follows. The document is split into multiple windows of words of a specific size for each window. After that, a brute-force algorithm that computes every combination of senses for each word within that window is employed. For every window combination, a score is calculated using one of the three similarity functions. The last step merges the windows using a prefix and suffix matching to form more significant and relevant windows. In the end, the formed windows are ranked by the length and score, and the top ones, based on a voting scheme, will determine the sense for each word.Documents can contain a variable number of words, therefore employing them in machine learning may be hard at times. This thesis presents two novel approaches [Ionescu and Butnaru, 2019] that can represent documents using a finite number of features. Both methods are inspired by computer vision, and they work by first transforming the words within documents to a word representation, such as word2vec. Having words represented in this way, a k-means clustering algorithm can be applied over the words. The centroids of the formed clusters are gathered into a vocabulary. Each word from a document is then represented by the closest centroid from the previously formed vocabulary. To this point, both methods share the same steps. One approach is designed to compute the final representation of a document by calculating the frequency of each centroid found inside it. This method is named Bag of Super Word Embeddings (BOSWE) because each centroid can be viewed as a super word. The second approach presented in this thesis, known as Vector of Locally-Aggregated Word Embeddings (VLAWE), computes the document representation by accumulating the differences between each centroid and each word vector associated with the respective centroid. This thesis also describes a new way to score essays automatically by combining a low-level string kernel model with a high-level semantic feature representation, namely the BOSWE representation.The methods described in this thesis exhibit state-of-the-art performance levels over multiple tasks. One fact to support this claim is that the string kernel method employed for Arabic Dialect Identification obtained the first place, two years in a row at the Fourth and Fifth Workshop on NLP for Similar Languages, Varieties, and Dialects (VarDial). The same string kernel model obtained the fifth place at the German Dialect Identification Closed Shared Task at VarDial Workshop of EACL 2017. Second of all, the Complex Word Identification model scored a third-place at the CWI Shared Task of the BEA-13 of NAACL 2018. Third of all, it is worth to mention that the ShotgunWSD algorithm surpassed the MCS baseline on several datasets. Lastly, the model that combines string kernel and bag of super word embeddings obtained state-of-the-art performance over the Automated Student Assessment Prize dataset.},
  address    = {New York, NY, USA},
  articleno  = {15},
  doi        = {10.1145/3451964.3451979},
  issue_date = {June 2020},
  numpages   = {3},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3451964.3451979},
}

@InProceedings{Wang2021b,
  author    = {Wang, Shaomin},
  booktitle = {Proceedings of the 2020 4th International Conference on Electronic Information Technology and Computer Engineering},
  title     = {Sentiment Analysis of the Song "Mojito"},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {739–744},
  publisher = {Association for Computing Machinery},
  series    = {EITCE '20},
  abstract  = {With the development of the Internet, people share views and opinions on things anytime and anywhere. While receiving information, people also produce various information. Based on the evaluation of Jay Chou's new song mojito by different users on Douban, this paper uses Python's JSON tool to calculate the positive and negative probability value of each comment by setting the probability value of positive tendency greater than 0.5 as positive evaluation, otherwise as negative. In order to understand the reasons for user ratings directly, a word cloud map is drawn based on comment data.On the basis of determining the positive and negative emotional tags, the first step is data processing, such as data cleaning, Chinese word segmentation, removing stop words, text vectorization, etc. Then, three different models of naive Bayes, logistic regression and support vector machine are established for comparison. Finally, naive Bayes model is selected for prediction based on cross validation score. Through confusion matrix evaluation, it is found that the model is more accurate for negative evaluation classification results, but not accurate enough for positive evaluation prediction. This may be related to the expressions of irony and double negation in text reviews.},
  doi       = {10.1145/3443467.3443846},
  isbn      = {9781450387811},
  keywords  = {support vector machine, Sentiment analysis, logistic regression, naive Bayes, sentiment tendency probability},
  location  = {Xiamen, China},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3443467.3443846},
}

@InProceedings{Shah2021,
  author    = {Shah, Vraj and Lacanlale, Jonathan and Kumar, Premanand and Yang, Kevin and Kumar, Arun},
  booktitle = {Proceedings of the 2021 International Conference on Management of Data},
  title     = {Towards Benchmarking Feature Type Inference for AutoML Platforms},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {1584–1596},
  publisher = {Association for Computing Machinery},
  series    = {SIGMOD '21},
  abstract  = {The paradigm of AutoML has created an opportunity to enable ML for the masses. Emerging industrial-scale cloud AutoML platforms aim to automate the end-to-end ML workflow. While many works have looked into automated feature engineering, model selection, or hyper-parameter search in AutoML, little work has studied a crucial step that serves as an entry point to this workflow: ML feature type inference. The semantic gap between attribute types (e.g., strings, numbers) in databases/files and ML feature types (e.g., Numeric, Categorical) necessitates type inference. In this work, we formalize and standardize this task by creating the first ever benchmark labeled dataset, which we use to objectively evaluate existing AutoML tools. Our dataset has 9921 examples and a 9-class label vocabulary. Our labeled data also offers an alternative approach to automate this task than existing rule-based or syntax-based approaches: use ML itself to predict feature types. We collate a benchmark suite of 30 classification and regression tasks to assess the importance of type inference for downstream models. Empirical comparison on our labeled data shows that an ML-based approach delivers a lift of an average 14\% and up to 38\% in accuracy for identifying feature types compared to prominent industrial tools. Our downstream benchmark suite reveals that the ML-based approach outperforms existing industrial-strength tools for 47 out of 60 downstream models. We release our labeled dataset, models, and downstream benchmarks in a public repository with a leaderboard.},
  doi       = {10.1145/3448016.3457274},
  isbn      = {9781450383431},
  keywords  = {benchmark data, data preparation, ML feature type inference, labeled data, autoML},
  location  = {Virtual Event, China},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3448016.3457274},
}

@InProceedings{Du2018,
  author    = {Du, Yuntao and Zhang, Lu and Shi, Jiahao and Tang, Jingjuan and Yin, Ying},
  booktitle = {Proceedings of the 2nd International Conference on Advances in Image Processing},
  title     = {Feature-Grouping-Based Two Steps Feature Selection Algorithm in Software Defect Prediction},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {173–178},
  publisher = {Association for Computing Machinery},
  series    = {ICAIP '18},
  abstract  = {In order to improve the effect of software defect prediction, many algorithms including feature selection, have been proposed. Based on Wrapper and Filter hybrid framework, a feature-grouping-based feature selection algorithm is proposed in this paper. The algorithm is composed of two steps. In the first step, in order to remove the redundant features, we group the features according to the redundancy between the features. The symmetry uncertainty is used as the constant indicator of the correlation and the FCBF-based grouping algorithm is used to group the features. In the second step, a subset of the features are selected from each group to form the final subset of features. Many classical methods select the representative feature from each group. We consider that when the number of intra-group features is large, the representative features are not enough to reflect the information in this group. Therefore, we require that at least one feature be selected within each group, in this step, the PSO algorithm is used for Searching Randomly from each group. We tested on the open source NASA and PROMISE data sets. Using three kinds of classifier. Compared to the other methods tested in this article, our method resulted in 90\% improvement in the predictive performance of 30 sets of results on 10 data sets. Compared with the algorithms without feature selection, the AUC values of this method in the Logistic regression, Naive Bayesian, and K-neighbor classifiers are improved by 5.94\% and 4.69\% And 8.05\%. The FCBF algorithm can also be regarded as a kind of first performing feature grouping. Compared with the FCBF algorithm, the AUC values of this method are improved by 4.78\%, 6.41\% and 4.4\% on the basis of Logistic regression, Naive Bayes and K-neighbor. We can also see that for the FCBF-based grouping algorithm, it could be better to choose a characteristic cloud from each group than to choose a representative one.},
  doi       = {10.1145/3239576.3239607},
  isbn      = {9781450364607},
  keywords  = {FCBF-based grouping algorithm, PSO, Feature grouping, Software defect prediction, Intra-group feature selection},
  location  = {Chengdu, China},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3239576.3239607},
}

@InProceedings{Chourasia2017,
  author    = {Chourasia, A. and Nadeau, D. and Norman, M.},
  booktitle = {Proceedings of the Practice and Experience in Advanced Research Computing 2017 on Sustainability, Success and Impact},
  title     = {SeedMe: Data Sharing Building Blocks},
  year      = {2017},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {PEARC '17},
  abstract  = {Data sharing is essential and pervasive in scientific research. The requirements for data sharing vary as research projects mature and iterate through early designs and prototypes with a small number of collaborators, and develop into publishable results and larger collaborator teams. Along the way, preliminary and transient results often need to be shared, discussed, and visualized with a quick turn-around time in order to guide the next steps of the project. Data sharing throughout this process requires that the data itself be shared, along with essential context, such as descriptions, provenance, scripts, visualizations, and threaded discussions. However, current consumer-oriented data sharing solutions mainly rely on local or cloud file systems or web-based drop boxes. These mechanisms are rather basic and are largely focused on data storage for individual use, rather than data collaboration. Using them for scientific data sharing is cumbersome.SeedMe is a platform that enables easy sharing of transient and preliminary data for a broad research computing community by offering cyberinfrastructure as a service and a modular software stack that could be customized. SeedMe is based on Drupal content management system as a set of building blocks with additional PHP modules and web services clients.In this poster we present our progress on implementing a web based modular data sharing platform that collocates shared data, along with the data's context, including descriptions, discussion, light-weight visualizations, and support files. This project is an evolution of the earlier SeedMe[1, 2] project, which created prototype data sharing tools and garnered user feedback from realworld use. The new SeedMe platform is developing modular components for data sharing, light-weight visualization, collaboration, DOI registration, video encoding and playback, REST APIs, command-line data import/export tools, and more. These modules may be added to any web site based upon the widely-used open-source Drupal content management system.The new SeedMe modules allow extensive customization enabling the sites to select and enhance functionality to provide features specific to a research community or a project. The SeedMe modules are widely applicable to a broad research community. They will be released as a suite of open source extensible building blocks. With this poster we showcase current progress along with an interactive demonstration of the project and engage with the HPC community to get feedback.},
  articleno = {69},
  doi       = {10.1145/3093338.3104153},
  isbn      = {9781450352727},
  keywords  = {Data sharing, Cloud, CMS, Visualization, HPC, Collaboration},
  location  = {New Orleans, LA, USA},
  numpages  = {1},
  url       = {https://doi.org/10.1145/3093338.3104153},
}

@InProceedings{Carnevali2021,
  author    = {Carnevali, Laura and Reali, Riccardo and Vicario, Enrico},
  booktitle = {Proceedings of the ACM/SPEC International Conference on Performance Engineering},
  title     = {Compositional Evaluation of Stochastic Workflows for Response Time Analysis of Composite Web Services},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {177–188},
  publisher = {Association for Computing Machinery},
  series    = {ICPE '21},
  abstract  = {Workflows are patterns of orchestrated activities designed to deliver some specific output, with application in various relevant contexts including software services, business processes, supply chain management. In most of these scenarios, durational properties of individual activities can be identified from logged data and cast in stochastic models, enabling quantitative evaluation of time behavior for diagnostic and predictive analytics. However, effective fitting of observed durations commonly requires that distributions break the limits of memoryless behavior and unbounded support of Exponential distributions, casting the problem in the class of non-Markovian models. This results in a major hurdle for numerical solution, largely exacerbated by the concurrency structure of workflows, which natively subtend concurrent activities with overlapping execution intervals and a limited number of regeneration points, i.e., time points at which the Markov property is satisfied and analysis can be decomposed according to a renewal argument. We propose a compositional method for quantitative evaluation of end-to-end response time of complex workflows. The workflow is modeled through Stochastic Time Petri Nets (STPNs), associating activity durations with Exponential distributions truncated over bilateral firmly bounded supports that fit mean and coefficient of variation of real logged histograms. Based on the model structure, the workflow is decomposed into a hierarchy of subworkflows, each amenable to efficient numerical solution through Markov regenerative transient analysis. In this step, the grain of decomposition is driven by non-deterministic analysis of the space of feasible behaviors in the underlying Time Petri Net (TPN) model, which permits efficient characterization of the factors that affect behavior complexity between regeneration points. Duration distributions of the subworkflows obtained through separate analyses are then repeatedly recomposed in numerical form to compute the response time distribution of the overall workflow.Applicability is demonstrated on a case from the literature of composite web services, here extended in complexity to demonstrate scalability of the approach towards finer grain composition schemes, and associated with a variety of durations randomly selected from a data set in the literature of service oriented computing, so as to assess variability of accuracy and complexity of the overall approach with respect to specific timings.},
  doi       = {10.1145/3427921.3450250},
  isbn      = {9781450381949},
  keywords  = {Markov regenerative processes, regenerative transient analysis, composite web services, performance evaluation, stochastic workflows},
  location  = {Virtual Event, France},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3427921.3450250},
}

@InProceedings{Coetzee2019,
  author    = {Coetzee, Leon and Nitschke, Geoff},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
  title     = {Evolving Optimal Sun-Shading Building Fa\c{c}ades},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {393–394},
  publisher = {Association for Computing Machinery},
  series    = {GECCO '19},
  abstract  = {Evolutionary algorithms have been applied to numerous architectural design applications in what is popularly known as evolutionary design [3], [4], [6]. Such applications include architectural support [7] and structural design for buildings [5] and floor-plan layout design [8]. However, evolutionary design of optimally shaped building fa\c{c}ades is less explored in evolutionary architectural design applications [6], [12], [13].This research investigates the evolutionary design of building fa\c{c}ades, optimally shaped for a given climate. This study applies evolutionary methods to optimally design sun-shades (covering windows on building fa\c{c}ades). Ideally, sun-shades will maximally block direct sunlight but minimize window coverage, thus allowing unobstructed views out of the window and maximizing ambient natural lighting inside. Also, sun-shades help to passively control building climate and determine occupant comfort. Optimal sun-shade designs allow direct sunlight (solar penetration) to enter interior spaces in winter months, heating the building, and minimize solar penetration in summer months, cooling the building [11].This study applies an Evolutionary Strategy (ES) [1] to automate sun-shade design such that solar penetration is minimized for both east and west facing windows, given summer solstice daylight hours in various geographic locations. An ES was selected given the demonstrated effectiveness of such evolutionary optimization on a range of engineering design problems with various constraints [9]. We focus on sun-shade design for rectangular shaped windows (vertical Y axis is 1.5 times the length of the horizontal X axis), where we anticipate sun-shade design will be replicated for many identical windows comprising a building's fa\c{c}ade, as is the case for many modern tall buildings [14].The ES was initialized with 20000 uniform random [1] points in a continuous three-dimensional (1.0 x 1.0 x 1.0) space adjacent to the window (figure 1). These points were possible mesh vertices for sun-shade design and thus the design solution space. The fitness function computed sun-shade effectiveness via calculating how many sun-rays were blocked assuming an increasing or decreasing sun height above the horizontal plane (angle V in figure 1). Thus, we tested the portion of sun-rays blocked by an evolving sun-shade (mesh formed by 20000 vertices) over half of daylight hours (separate sun-shades were evolved for east and west facing fa\c{c}ades). In successive generations, sun-shade mesh vertices blocking sun-rays (at varying degrees of inclination and declination) aimed at the window were selected for as vertices in evolving designs.Evolving sun-shade effectiveness was computed as the intersection of sun-rays at 15 second intervals during simulated half-days. For east facing fa\c{c}ades, from the point where sun is on the horizontal plane (Y axis in figure 1) and incrementally increases until it is directly above the vertical axis of the building fa\c{c}ade (Y-Z plane in figure 1), and for west facing fa\c{c}ades where the sun starts at this midday point and incrementally declines. Sun-shades were evolved for east and west facing fa\c{c}ades given half of summer solstice daylight hours1 (for east versus west fa\c{c}ades) indicative of Cape Town, South Africa, and Amsterdam, the Netherlands (~ 14 hours, 25 minutes and 16 hours, 48 minutes, respectively).At these two geographic locations, 15 second intervals indicated incremental sun movements during day-light hours. For Cape Town, this was approximated as 0.052° increases and decreases and for Amsterdam, 0.045° increases and decreases (for east and west facing fa\c{c}ades, respectively). Half-day simulations thus tested, every 15 seconds, sun-ray intersection (vector: Xp, Yp, Zp at angle V from the horizontal or vertical plane) with any point in the sun-shade. This was a point-cloud in generation 1 and mesh-points in subsequent generations (figure 1). Points intersecting the sun-ray were given maximum (normalized) fitness of 1.0, and points within a given ray distance were assigned a logarithmically decreasing fitness that equalled 0.0 at the maximum ray distance. To account for random variation and diffusion of sun-ray light, each 15 seconds, a random angle (in the range: [-0.01°, +0.01°]) was added to the sun-ray's vector value V.Evolutionary design used a µ+λ ES [1], where (λ = 20000) off-spring were created per generation. This combined population was ranked by fitness and the least ft λ genotypes discarded. Each genotype encoded an (x, y, z) point in an N point-mesh (evolving sun-shade design), and corresponding σ mutation step-size for each coordinate. For simplicity, the X, Y, Z dimensions of the 3D solution space for evolving sun-shades (adjacent to the window) was normalized the range [0.0, 1.0] and the window dimensions normalized to the range [0.0, 1.5] for the X, Y window axes, respectively. Thus, sun-shades only evolved to cover the top two-thirds of a window, ensuring that sufficient ambient light still entered the building and that occupants have a view out of the window.One generation was the evaluation of all 20000 genotypes (in sun-ray simulations), where the fittest 10\% were selected, mutation operators: σxNx(0,1), σyNy(0, 1), σzNz(0,1) applied to permutate each genotype's coordinate and step-size values (p=1.0 and p=0.05, respectively), such that (λ=20000) offspring genotypes were created. All µ+λ genotypes were then evaluated and the fittest 20000 selected as survivors [1]. Sun-shade evolution for Cape Town and Amsterdam constituted experiment set 1 and 2, respectively. Each experiment set was 10 ES runs, for east and west facing fa\c{c}ades, and each run was 100 generations (ES run stopping condition).Sun-shade fitness was the portion of points (constituting a sunshade design) that blocked or partially blocked sun-rays during each half-day simulation. Points that intersected a sun-ray were assigned a maximum fitness of 1.0, and points close to a sun-ray (&lt; ray distance) were assigned a partial fitness in the range: (0.0, 1.0). In generation 1, all 20,000 possible points were considered for sun-shade design. In subsequent generations only points given a fitness value were considered part of the evolving sun-shade (point-mesh) design. For simplicity, sun-shade fitness was normalized to the range: [0.0, 1.0], where 0.0 indicated no sun-rays blocked and 1 indicated all sun-rays blocked (over all day-light hours tested).As a benchmark comparison for evolved sun-shade effectiveness, the fittest sun-shades evolved for east and west facing fa\c{c}ades (at both locations) were selected from each run and compared to ten heuristic design sun-shades (figure 1). The effectiveness of these sun-shades was similarly computed using sun-ray simulations of 15 second intervals during half-day periods for east and west facing fa\c{c}ades and a given number of day-light hours at both locations.Thus for each heuristic design sun-shade a fitness value was similarly calculated, normalized to the range: [0.0, 1.0], where 0 indicated no sun-rays were blocked and 1.0 indicated that all sun-rays were blocked during a sun-ray simulation.Results indicated that, on average, evolved sun-shades, for both shorter and longer day lengths and east versus west facing fa\c{c}ades, were significantly more effective (with statistical significance, two-tailed t-test, p &lt; 0.05, [2]) compared to the ten tested heuristic designed sun-shades. Results also indicated that evolutionary design is suitable for automating optimal sun-shade (and potentially building fa\c{c}ade) design and support current hypotheses on the efficacy of evolutionary design for improving current architectural designs and automating efficient and effective industrial design production [3], [4], [12]. Ongoing work is evaluating sun-shade evolution in comparison to other heuristic designs in various geographic locations, as well as evolving sun-shades that dynamically adapt their form to suit varying daylight lengths and sun intensity.},
  doi       = {10.1145/3319619.3321891},
  isbn      = {9781450367486},
  location  = {Prague, Czech Republic},
  numpages  = {2},
  url       = {https://doi.org/10.1145/3319619.3321891},
}

@InProceedings{Joydeep2023,
  author    = {Joydeep, Mukherjee and Sumona, Mukhopadhyay and Marin, Litoiu},
  booktitle = {Proceedings of the 33rd Annual International Conference on Computer Science and Software Engineering},
  title     = {Detecting Software Anomalies Using Spectrograms and Convolutional Neural Network},
  year      = {2023},
  address   = {USA},
  pages     = {44–53},
  publisher = {IBM Corp.},
  series    = {CASCON '23},
  abstract  = {Microservice applications are increasingly embracing cloud platforms to run their services. These applications can often be impacted by anomalies. Detecting anomalies at runtime is vital to ensure that cloud-native applications meet specified requirements and ensure good Quality-of-Service. However, this is challenging to do since application owners do not always have access to the underlying cloud infrastructure and hence can not use host level metrics and hardware counters as done in the past. One potential way to address this challenge is to use a machine learning based anomaly detection approach which uses metrics that can be easily collected from applications running on public cloud platforms. In this paper, we develop a classifier using deep learning for pattern recognition of anomalies for detecting runtime software anomalies in cloud-native applications. We use textured images known as spectrograms that are obtained from time series measurement readily available from cloud-native applications. These spectrogram images are used to train a Convolutional Neural Network (CNN) classifier for anomaly detection. We evaluate our approach on two real-world datasets that capture known software anomalies in public cloud platforms. Results show that the proposed spectrogram based CNN classifier yields detection accuracy of 99\% for both datasets at runtime and outperforms a competing non-image based classifier.},
  keywords  = {Cloud Computing, Deep Learning, Software Anomalies},
  location  = {Las Vegas, NV, USA},
  numpages  = {10},
}

@InProceedings{Feng2023,
  author    = {Feng, Binbin and Ding, Zhijun},
  booktitle = {Proceedings of the ACM Web Conference 2023},
  title     = {GROUP: An End-to-End Multi-Step-Ahead Workload Prediction Approach Focusing on Workload Group Behavior},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {3098–3108},
  publisher = {Association for Computing Machinery},
  series    = {WWW '23},
  abstract  = {Accurately forecasting workloads can enable web service providers to achieve proactive runtime management for applications and ensure service quality and cost efficiency. For cloud-native applications, multiple containers collaborate to handle user requests, making each container’s workload changes influenced by workload group behavior. However, existing approaches mainly analyze the individual changes of each container and do not explicitly model the workload group evolution of containers, resulting in sub-optimal results. Therefore, we propose a workload prediction method, GROUP, which implements the shifts of workload prediction focus from individual to group, workload group behavior representation from data similarity to data correlation, and workload group behavior evolution from implicit modeling to explicit modeling. First, we model the workload group behavior and its evolution from multiple perspectives. Second, we propose a container correlation calculation algorithm that considers static and dynamic container information to represent the workload group behavior. Third, we propose an end-to-end multi-step-ahead prediction method that explicitly portrays the complex relationship between the evolution of workload group behavior and the workload changes of each container. Lastly, enough experiments on public datasets show the advantages of GROUP, which provides an effective solution to achieve workload prediction for cloud-native applications.},
  doi       = {10.1145/3543507.3583460},
  isbn      = {9781450394161},
  keywords  = {deep learning., workload prediction, Cloud Computing},
  location  = {Austin, TX, USA},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3543507.3583460},
}

@InProceedings{Kousiouris2022,
  author    = {Kousiouris, George and Giannakos, Chris and Tserpes, Konstantinos and Stamati, Teta},
  booktitle = {Companion of the 2022 ACM/SPEC International Conference on Performance Engineering},
  title     = {Measuring Baseline Overheads in Different Orchestration Mechanisms for Large FaaS Workflows},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {61–68},
  publisher = {Association for Computing Machinery},
  series    = {ICPE '22},
  abstract  = {Serverless environments have attracted significant attention in recent years as a result of their agility in execution as well as inherent scaling capabilities as a cloud-native execution model. While extensive analysis has been performed in various critical performance aspects of these environments, such as cold start times, the aspect of workflow orchestration delays has been neglected. Given that this paradigm has become more mature in recent years and application complexity has started to rise from a few functions to more complex application structures, the issue of delays in orchestrating these functions may become severe. In this work, one of the main open source FaaS platforms, Openwhisk, is utilized in order to measure and investigate its orchestration delays for the main sequence operator of the platform. These are compared to delays included in orchestration of functions through two alternative means, including the execution of orchestrator logic functions in supporting runtimes based on Node-RED. The delays inserted by each different orchestration mode are measured and modeled, while boundary points of selection between each mode are presented, based on the number and expected delay of the functions that constitute the workflow. It is indicative that in certain cases, the orchestration overheads might range from 0.29\% to 235\% compared to the beneficial computational time needed for the workflow functions. The results can extend simulation and estimation mechanisms with information on the orchestration overheads.},
  doi       = {10.1145/3491204.3527467},
  isbn      = {9781450391597},
  keywords  = {performance, serverless, orchestration, faas, overhead, openwhisk},
  location  = {Bejing, China},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3491204.3527467},
}

@InProceedings{Andrade2023,
  author    = {Andrade, \'{A}lan J\'{u}nior da Cruz and Veloso, Ednilson and Santos, Gleison},
  booktitle = {Proceedings of the XXII Brazilian Symposium on Software Quality},
  title     = {What We Know About Software Dependability in DevOps - A Tertiary Study},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {178–187},
  publisher = {Association for Computing Machinery},
  series    = {SBQS '23},
  abstract  = {Background: DevOps is viewed as an alternative approach to achieving high-quality software products. Dependability is recognized as a crucial aspect of software product quality. Existing literature highlights the lack of established standards, models, or methods for evaluating product quality within the DevOps paradigm. This emphasizes the need for further research to investigate the impact of DevOps on software quality attributes, particularly in relation to dependability.Objective: Our objective is to evaluate the scope of research on dependability in DevOps and identify what is known about this context by relating DevOps practices with dependability attributes. Method: We conducted a tertiary study to enhance the understanding of dependability in the context of DevOps. Results: We found 13 secondary studies that address dependability in DevOps. Within these studies, we identified 16 DevOps practices that have an impact on dependability and 12 attributes that are affected by DevOps practices. Additionally, we identified 6 measures related to dependability in the context of DevOps. Among the DevOps practices, the most commonly reported ones that impact dependability are Automation Practices, including deployment, testing, and infrastructure automation, as well as Cloud Computing Implementation. Conclusions: The results show that DevOps practices contribute to improve software dependability, mainly due to the impacts of these practices on dependability attributes. However, even though the literature reports some measures related to dependability, there is still a gap in understanding how organizations can assess dependability in DevOps.},
  doi       = {10.1145/3629479.3629502},
  isbn      = {9798400707865},
  keywords  = {Dependability, Software Product Quality, DevOps},
  location  = {<conf-loc>, <city>Bras\'{\i}lia</city>, <country>Brazil</country>, </conf-loc>},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3629479.3629502},
}

@InProceedings{Saravanan2023,
  author    = {M, Saravanan and S, Shiva Prasad},
  booktitle = {Proceedings of the 4th International Conference on Information Management \&amp; Machine Intelligence},
  title     = {A Blockchain-Based, Distributed, Self Hosted And End To End Encrypted Cloud Storage System},
  year      = {2023},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ICIMMI '22},
  abstract  = {Cloud computing is fast taking over due to its convenience and greater safety. You may access your files anytime you need them by using the cloud. Having a large following makes things simpler for consumers. Computing makes phase, programming, and system structure all possible. With the aid of these components, increased cloud-based information and profits might be obtained. It is great to plan and arrange work based on data. The most difficult issue for people with a background in logical thinking is planning work procedures to achieve customer service goals while keeping expenses in control. Although leveraging cloud storage to reduce expenses has been suggested, doing so can be difficult. Although leveraging cloud storage to reduce expenses has been suggested, doing so can be difficult. To handle cloud resources efficiently, a modular infrastructure is needed. Utilizing standards and calculations, parallel resource and service management is maximized in the cloud. Using different work flows to structure work processes is the most entertaining activity in cloud computing. Timing and price have an influence on service quality (tasks). Workflow-based relocation of virtual machines is more effective. NP-hard algorithms for subset and choice issues. Making a choice allows the server to save time and money. PSO and GWO interactions that are advantageous. In this undertaking, both time and money are considerations. The new approach should be used. The study affects the validity of process parameters. intuition with a convex shape. utilizing the PEFT technique. GWO analyses the time and money spent on cloud processes. It is suggested that VMs be optimized as hybrid, both locally and globally. heuristic algorithm based on PEFT. Optimization reduces the likelihood of making a mistake right away. The Grey Wolf Optimization and Floral pollination algorithm outperforms genetic and flower pollination techniques. Biomimicry is compared with swarm intelligence. For our analysis, we use LIGO, GENOME, CYBER SHAKE, and SIPHT. The difficulty and quantity of the jobs have an impact on workflow. A bio-inspired GA, GWO, and FPA are used in the optimization process. In an experimental arrangement, time and cost analysis for two to twenty VMs and workflows may be done. Compared to FPA with PEFT, GWO requires less time and money. In hybrid optimization, GWO and FPA are combined. In this project, efficiency and speed are highly valued. GWO optimizes VM globally, whereas FPA concentrates on local enhancements. FPA GA uses the collective wisdom of the group to identify correlations. As labor prices grow, more virtual machines (VMs) are employed for processing and tasks. Wait times drop and costs rise. Local and global optimization have an impact on virtual machine (VM) and compute time. ACO and PSO are used to accomplish local and global optimization, however employing them requires more time.},
  articleno = {85},
  doi       = {10.1145/3590837.3590922},
  isbn      = {9781450399937},
  keywords  = {Cryptography, Cloud storage, Peer to Peer Network, Blockchain, IPFS},
  location  = {Jaipur, India},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3590837.3590922},
}

@Article{Pan2023,
  author     = {Pan, Zhicheng and Wang, Yihang and Zhang, Yingying and Yang, Sean Bin and Cheng, Yunyao and Chen, Peng and Guo, Chenjuan and Wen, Qingsong and Tian, Xiduo and Dou, Yunliang and Zhou, Zhiqiang and Yang, Chengcheng and Zhou, Aoying and Yang, Bin},
  journal    = {Proc. VLDB Endow.},
  title      = {MagicScaler: Uncertainty-Aware, Predictive Autoscaling},
  year       = {2023},
  issn       = {2150-8097},
  month      = {aug},
  number     = {12},
  pages      = {3808–3821},
  volume     = {16},
  abstract   = {Predictive autoscaling is a key enabler for optimizing cloud resource allocation in Alibaba Cloud's computing platforms, which dynamically adjust the Elastic Compute Service (ECS) instances based on predicted user demands to ensure Quality of Service (QoS). However, user demands in the cloud are often highly complex, with high uncertainty and scale-sensitive temporal dependencies, thus posing great challenges for accurate prediction of future demands. These in turn make autoscaling challenging---autoscaling needs to properly account for demand uncertainty while maintaining a reasonable trade-off between two contradictory factors, i.e., low instance running costs vs. low QoS violation risks.To address the above challenges, we propose a novel predictive autoscaling framework MagicScaler, consisting of a Multi-scale attentive Gaussian process based predictor and an uncertainty-aware scaler. First, the predictor carefully bridges the best of two successful prediction methodologies---multi-scale attention mechanisms, which are good at capturing complex, multi-scale features, and stochastic process regression, which can quantify prediction uncertainty, thus achieving accurate demand prediction with quantified uncertainty. Second, the scaler takes the quantified future demand uncertainty into a judiciously designed loss function with stochastic constraints, enabling flexible trade-off between running costs and QoS violation risks. Extensive experiments on three clusters of Alibaba Cloud in different Chinese cities demonstrate the effectiveness and efficiency of MagicScaler, which outperforms other commonly adopted scalers, thus justifying our design choices.},
  doi        = {10.14778/3611540.3611566},
  issue_date = {August 2023},
  numpages   = {14},
  publisher  = {VLDB Endowment},
  url        = {https://doi.org/10.14778/3611540.3611566},
}

@InProceedings{Zhao2022,
  author    = {Zhao, Yuhan and Chong, Zheng and Han, Xueying and Du, Zongpeng and Yu, Ke and Huang, Xiaohong},
  booktitle = {Proceedings of the 2021 10th International Conference on Networks, Communication and Computing},
  title     = {Simulation Study of Routing Mechanism in the Computing-Aware Network},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {126–134},
  publisher = {Association for Computing Machinery},
  series    = {ICNCC '21},
  abstract  = {Traditional routing algorithms select the path based on the cost, hop, or other network-related metrics. However, with cloud computing and edge computing development, it is essential to develop a computing-aware routing mechanism to distribute the task to the computing nodes with better capabilities. In order to achieve the combined scheduling of computing resources and network resources, Computing-aware Network (CAN) is proposed. The solution aims to comprehensively consider the computing resources and network resources existing when routing and forwarding user requests, which is essential to improve the current situation of uneven utilization of edge computing resources. As many theories and structures are proposed, the requirements for experimental verification of CAN are gradually increasing. However, there is still a lack of experimental simulation prototypes available for study. In this work, motivated by the gap, we propose a simulation prototype based on the idea of the CAN, where routing nodes can incorporate both the computing status and network status into routing and forward packets to an edge server according to the computing demand service type. We verified the effectiveness of the CAN prototype from simulation experiments on a cross-domain topology. From the results, we can conclude that the utilization rate of computing resources has been effectively improved compared to not considering computing status.},
  doi       = {10.1145/3510513.3510534},
  isbn      = {9781450385848},
  keywords  = {computing resources, utilization rate, Computing-aware Network, simulation prototype},
  location  = {Beijing, China},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3510513.3510534},
}

@InProceedings{Dang2021,
  author    = {Dang, The Khang and Mohan, Nitinder and Corneo, Lorenzo and Zavodovski, Aleksandr and Ott, J\"{o}rg and Kangasharju, Jussi},
  booktitle = {Proceedings of the 21st ACM Internet Measurement Conference},
  title     = {Cloudy with a Chance of Short RTTs: Analyzing Cloud Connectivity in the Internet},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {62–79},
  publisher = {Association for Computing Machinery},
  series    = {IMC '21},
  abstract  = {Cloud computing has seen continuous growth over the last decade. The recent rise in popularity of next-generation applications brings forth the question: "Can current cloud infrastructure support the low latency requirements of such apps?" Specifically, the interplay of wireless last-mile and investments of cloud operators in setting up direct peering agreements with ISPs globally to current cloud reachability and latency has remained largely unexplored.This paper investigates the state of end-user to cloud connectivity over wireless media through extensive measurements over six months. We leverage 115,000 wireless probes on the Speed-checker platform and 195 cloud regions from 9 well-established cloud providers. We evaluate the suitability of current cloud infrastructure to meet the needs of emerging applications and highlight various hindering pressure points. We also compare our results to a previous study over RIPE Atlas. Our key findings are: (i) the most impact on latency comes from the geographical distance to the datacenter; (ii) the choice of a measurement platform can significantly influence the results; (iii) wireless last-mile access contributes significantly to the overall latency, almost surpassing the impact of the geographical distance in many cases. We also observe that cloud providers with their own private network backbone and direct peering agreements with serving ISPs offer noticeable improvements in latency, especially in its consistency over longer distances.},
  doi       = {10.1145/3487552.3487854},
  isbn      = {9781450391290},
  keywords  = {cloud connectivity, edge computing, peering, last-mile latency},
  location  = {Virtual Event},
  numpages  = {18},
  url       = {https://doi.org/10.1145/3487552.3487854},
}

@Article{Huang2023a,
  author     = {Huang, Lihua and Zheng, Peng},
  journal    = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
  title      = {Human-Computer Collaborative Visual Design Creation Assisted by Artificial Intelligence},
  year       = {2023},
  issn       = {2375-4699},
  month      = {sep},
  number     = {9},
  volume     = {22},
  abstract   = {With the support and promotion of big data and cloud computing, AI has penetrated into every field of people's lives more and more deeply, with its characteristics of sustainable work, extremely fast computing speed, and a certain intelligence. This is an effective way to solve the general lack of demand and productivity of visual design, and relieve the pressure off designers to deal with relatively low-quality and high-demand designs. Therefore, the combination of design and artificial intelligence technology is a necessity. Research on the application of artificial intelligence technology for visual design is also in full swing at home and abroad However, at present, teams at home and abroad are in the exploratory stage. This paper considers whether it is possible to build an intelligent visual design and creation system by using artificial intelligence technology to help graphic communication designers achieve high-quality, high-efficiency, and high-quantity design output. Additionally, this paperexplores how to combine artificial intelligence technology with designers' design workflow so as to form a complementary human-computer cooperation mode. We will explore how to integrate AI technology with designers' design workflow and then create a human-machine collaboration model with complementary advantages to achieve the high quality, high efficiency, and high quantity of design output required by the intelligent visual design creation system being built. Finally, a basic framework of a generative smart human-computer collaborative visual design creation system based on a subset of neural network expert systems in multiple domains and an aggregate of different modules supported by the system is formed, and the working principle and usage process of the system are further elaborated with the example of packaging design.},
  address    = {New York, NY, USA},
  articleno  = {221},
  doi        = {10.1145/3554735},
  issue_date = {September 2023},
  keywords   = {cooperation mode, creation system, visual design creation, collaboration model, Artificial intelligence, packaging design, human-computer collaboration},
  numpages   = {21},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3554735},
}

@InProceedings{Vanjipriya2023,
  author    = {V, Vanjipriya and Annamalai, Suresh},
  booktitle = {Proceedings of the 4th International Conference on Information Management \&amp; Machine Intelligence},
  title     = {Machine Learning Technique for Energy, Performance and Cost-Effective Resource Management in Multi-Access Edge Computing},
  year      = {2023},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ICIMMI '22},
  abstract  = {Modern cloud interconnects on efficient resource allocation and provisioning to reduce their energy footprint. Resource management is complicated by factors such as data centre energy utilisation, virtual machine migration, operating expense, and overhead. Researchers have been using virtualized technologies and methods as optimal-Multi-objective particle swarm optimization, Dynamic Power Saving Resource Allocation (DPRA), Least Squares Regression, etc. to improve the management of their study. Accurately allocating resources to cloud users to meet their requests and offer QoS is a difficult task because of the preceding steps. Allocating cloud infrastructure's resources in the most efficient way possible benefits both users and service providers. The difficulties of resource management are tackled in this study by employing novel approaches, heuristics, authentication, and virtualization. In order to distribute workloads over several physical nodes, cloud computing relies on dynamic scheduling with load balancing. Using the help of host load prediction and a Markov chain model with Particle Swarm Optimization (PSO), VM resources are dynamically allocated to appropriate input requests. High quality of service (QoS) for cloud applications is achieved by SLA-based resource optimization with deadline, cost, storage, and bandwidth targets. Compliance with Service Level Agreements (SLAs), efficient use of resources, and low energy consumption are all achieved using a prioritisation technique based on SLAs. Scheduled users can receive resources in a predetermined order thanks to queuing. We developed the M/M/c/K queuing paradigm for numerous users per server to lessen the burden on data centres. Hardware resource models, such as CPU, I/O, and memory use, reveal VM resource allocation. Information gathering enhances resource utilisation and reduces energy consumption.},
  articleno = {113},
  doi       = {10.1145/3590837.3590950},
  isbn      = {9781450399937},
  keywords  = {Load balancing, Service Level Agreements, Quality of Service, Virtual machine, Dynamic Power Saving Resource Allocation},
  location  = {Jaipur, India},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3590837.3590950},
}

@InProceedings{Rochlin2022,
  author    = {Rochlin, Nick and Gardner, Jeff and Kinney, Elizabeth},
  booktitle = {Practice and Experience in Advanced Research Computing},
  title     = {Evaluating Research Computing Training and Support as Part of a Broader Digital Research Infrastructure Needs Assessment},
  year      = {2022},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {PEARC '22},
  abstract  = {Digital Research Infrastructure (DRI) refers to the suite of tools and services that enables the collection, processing, dissemination, and disposition of research data. This includes strategies for planning, organizing, storing, sharing, computing, and ultimately archiving or destroying one's research data.&nbsp; These services must be supported by highly qualified personnel with the appropriate expertise.&nbsp; From May 17 - June 12, 2021, the University of British Columbia (UBC) Advanced Research Computing (UBC ARC) and the UBC Library from both Vancouver and Okanagan Campuses launched the DRI Needs Assessment Survey to investigate UBC researchers’ needs in 25 distinct DRI tools and services.&nbsp; The survey received a total of 241 responses, and following the survey, three focus groups were conducted with survey respondents to gain additional insights.This paper outlines the DRI Needs Assessment Survey and its findings, focusing on those directly related to UBC ARC services and training in high-performance computing (HPC) and cloud computing (“Cloud”), and discusses next steps for implementing a more collaborative, comprehensive research computing training and support model. Key findings suggest that while advanced research computing infrastructure is a key pillar of DRI, researchers utilizing UBC ARC also rely on a number of other DRI tools and services to conduct their research.&nbsp; These services are widely scattered across various departments and groups within and outside the institution and are oftentimes not well communicated, impacting researchers’ ability to find them.&nbsp; Current research training and support has been found to be inadequate, and there are duplicated service efforts occurring in silos, resulting in an inefficient service model and wasted funds.},
  articleno = {28},
  doi       = {10.1145/3491418.3530295},
  isbn      = {9781450391610},
  keywords  = {advanced research computing, user community, training, hpc, education, collaboration, cloud, digital research infrastructure},
  location  = {Boston, MA, USA},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3491418.3530295},
}

@Article{Liu2023,
  author     = {Liu, Yipeng and Yang, Qi and Xu, Yiling and Yang, Le},
  journal    = {ACM Trans. Multimedia Comput. Commun. Appl.},
  title      = {Point Cloud Quality Assessment: Dataset Construction and Learning-Based No-Reference Metric},
  year       = {2023},
  issn       = {1551-6857},
  month      = {feb},
  number     = {2s},
  volume     = {19},
  abstract   = {Full-reference (FR) point cloud quality assessment (PCQA) has achieved impressive progress in recent years. However, in many cases, obtaining the reference point clouds is difficult, so no-reference (NR) metrics have become a research hotspot. Few researches about NR-PCQA are carried out due to the lack of a large-scale PCQA dataset. In this article, we first build a large-scale PCQA dataset named LS-PCQA, which includes 104 reference point clouds and more than 22,000 distorted samples. In the dataset, each reference point cloud is augmented with 31 types of impairments (e.g., Gaussian noise, contrast distortion, local missing, and compression loss) at 7 distortion levels. Besides, each distorted point cloud is assigned with a pseudo-quality score as its substitute of Mean Opinion Score. Inspired by the hierarchical perception system and considering the intrinsic attributes of point clouds, we propose a NR metric ResSCNN based on sparse convolutional neural network (CNN) to accurately estimate the subjective quality of point clouds. We conduct several experiments to evaluate the performance of the proposed NR metric. The results demonstrate that ResSCNN exhibits the state-of-the-art performance among all the existing NR-PCQA metrics and even outperforms some FR metrics. The dataset presented in this work will be made publicly accessible at . The source code for the proposed ResSCNN can be found at .},
  address    = {New York, NY, USA},
  articleno  = {80},
  doi        = {10.1145/3550274},
  issue_date = {April 2023},
  keywords   = {sparse convolution, large-scale dataset, point cloud, Blind quality assessment, learning-based metric},
  numpages   = {26},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3550274},
}

@InProceedings{Lee2023a,
  author    = {Lee, Kuan-Yu and Fang, Jia-Wei and Sun, Yuan-Chun and Hsu, Cheng-Hsin},
  booktitle = {Proceedings of the 15th International Workshop on Immersive Mixed and Virtual Environment Systems},
  title     = {Modeling Gamer Quality-of-Experience Using a Real Cloud VR Gaming Testbed},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {12–17},
  publisher = {Association for Computing Machinery},
  series    = {MMVE '23},
  abstract  = {Cloud Virtual Reality (VR) gaming offloads computationally-intensive VR games to resourceful data centers. Ensuring good Quality of Experience (QoE) in cloud VR gaming, however, is inherently challenging as VR gamers demand high visual quality, short response time, and low cybersickness. In this paper, we investigate the QoE of cloud VR gaming in multiple steps. First, we build a cloud VR gaming testbed, which allows us to measure various Quality of Service (QoS) metrics. Second, we carry out a user study to understand the effects of diverse factors, including encoding settings, network conditions, and game genres on gamer QoE, quantified by Mean Opinion Score (MOS). Using our user study results, we construct QoE models for cloud VR gaming, which to the best of our knowledge, has not been done in the literature. Last, we apply our QoE models to develop a bitrate allocation algorithm for multiple cloud VR gamers to achieve better overall QoE compared to the bandwidth-fair bitrate allocation.},
  doi       = {10.1145/3592834.3592877},
  isbn      = {9798400701894},
  keywords  = {QoE modeling, bitrate allocation, VR gaming, cloud gaming},
  location  = {Vancouver, BC, Canada},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3592834.3592877},
}

@InProceedings{Zhang2022d,
  author    = {Zhang, Ke-xin and Jiang, Gang-yi and Yu, Mei},
  booktitle = {Proceedings of the 3rd ACM International Conference on Multimedia in Asia},
  title     = {FQM-GC: Full-Reference Quality Metric for Colored Point Cloud Based on Graph Signal Features and Color Features},
  year      = {2022},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {MMAsia '21},
  abstract  = {Colored Point Cloud (CPC) is often distorted in the processes of its acquisition, processing, and compression, so reliable quality assessment metrics are required to estimate the perception of distortion of CPC. We propose a Full-reference Quality Metric for colored point cloud based on Graph signal features and Color features (FQM-GC). For geometric distortion, the normal and coordinate information of the sub-clouds divided via geometric segmentation is used to construct their underlying graphs, then, the geometric structure features are extracted. For color distortion, the corresponding color statistical features are extracted from regions divided with color attribution. Meanwhile, the color features of different regions are weighted to simulate the visual masking effect. Finally, all the extracted features are formed into a feature vector to estimate the quality of CPCs. Experimental results on three databases (CPCD2.0, IRPC and SJTU-PCQA) show that the proposed metric FQM-GC is more consistent with human visual perception.},
  articleno = {48},
  doi       = {10.1145/3469877.3490578},
  isbn      = {9781450386074},
  keywords  = {graph signal processing, visual quality assessment, Colored point cloud, point cloud segmentation},
  location  = {<conf-loc>, <city>Gold Coast</city>, <country>Australia</country>, </conf-loc>},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3469877.3490578},
}

@InProceedings{Freitas2022,
  author    = {Freitas, Pedro G. and Lucafo, Giovani D. and Gon\c{c}alves, Mateus and Homonnai, Johann and Diniz, Rafael and Farias, Myl\`{e}ne C.Q.},
  booktitle = {Proceedings of the 1st Workshop on Photorealistic Image and Environment Synthesis for Multimedia Experiments},
  title     = {Comparative Evaluation of Temporal Pooling Methods for No-Reference Quality Assessment of Dynamic Point Clouds},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {35–41},
  publisher = {Association for Computing Machinery},
  series    = {PIES-ME '22},
  abstract  = {Point Cloud Quality Assessment (PCQA) has become an important task in immersive multimedia since it is fundamental for improving computer graphics applications and ensuring the best Quality of Experience(QoE) for the end user. In recent years, the field of PCQA has made exemplary progress, with state-of-the-art methods achieving better predictive performance at lower computational complexity. However, most of this progress was made using Full Reference (FR) metrics. Since, in many cases, the reference point cloud is not available, the design of No-Reference (NR) methods has become increasingly important. In this paper, we investigate the suitability of geometric-aware texture descriptors to blindly assess the quality of colored Dynamic Point Cloud (DPC). The proposed metric first uses a descriptor to extract features of the assessed Point Cloud (PC) frames. Then, the descriptor statistics are used to extract quality-aware features. Finally, a machine learning algorithm is employed to regress the quality-aware features into visual quality scores, and these scores are aggregated using a temporal pooling function. Then we study the effects of different temporal pooling strategies on the performance of DPC quality assessment methods. Our experimental tests were carried out using the latest publicly available database and demonstrated the efficiency of the evaluated temporal pooling models. This work aims to provide a direction on how to apply a temporal pooling function to combine per-frame quality predictions generated with descriptor based PC quality assessment methods to estimate the quality of dynamic PCs. An implementation of the metric described in this paper can be found in https://gitlab.com/gpds-unb/no-referencedpcqa-temporal-pooling.},
  doi       = {10.1145/3552482.3556552},
  isbn      = {9781450395007},
  keywords  = {quality assessment, quality metric, qoe methods, point cloud},
  location  = {Lisboa, Portugal},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3552482.3556552},
}

@InProceedings{Tliba2022,
  author    = {Tliba, Marouane and Chetouani, Aladine and Valenzise, Giuseppe and Dufaux, Frederic},
  booktitle = {Proceedings of the 2nd Workshop on Quality of Experience in Visual Multimedia Applications},
  title     = {Point Cloud Quality Assessment Using Cross-Correlation of Deep Features},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {63–68},
  publisher = {Association for Computing Machinery},
  series    = {QoEVMA '22},
  abstract  = {3D point clouds have emerged as a preferred format for recent immersive communication systems, due to the six degrees of freedom they offer. The huge data size of point clouds, which consists of both geometry and color information, has motivated the development of efficient compression schemes recently. To support the optimization of these algorithms, adequate and efficient perceptual quality metrics are needed. In this paper we propose a novel end-to-end deep full-reference framework for 3D point cloud quality assessment, considering both the geometry and color information. We use two identical neural networks, based on a residual permutation-invariant architecture, for extracting local features from a sparse set of patches extracted from the point cloud. Afterwards, we measure the cross-correlation between the embedding of pristine and distorted point clouds to quantify the global shift in the features due to visual distortion. The proposed scheme achieves comparable results to state-of-the-art metrics even when a small number of centroids are used, reducing the computational complexity.},
  doi       = {10.1145/3552469.3555710},
  isbn      = {9781450394994},
  keywords  = {cross correlation, deep learning, point cloud, quality assessment},
  location  = {Lisboa, Portugal},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3552469.3555710},
}

@InProceedings{Hogan2023,
  author    = {Hogan, Taylor},
  booktitle = {Proceedings of the 2023 International Symposium on Physical Design},
  title     = {Goal Driven PCB Synthesis Using Machine Learning and CloudScale Compute},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {80},
  publisher = {Association for Computing Machinery},
  series    = {ISPD '23},
  abstract  = {X AI is a cloud-based system that leverages machine learning, and search to place and route printed circuit boards using physics-based analysis and high-level design. We propose a feedback-based Monte Carlo Tree Search (MCTS) algorithm to explore the space of possible designs. A metric, or metrics, is given to evaluate the quality of designs as MCTS learns about possible solutions. A policy and value network are trained during exploration to learn to accurately weight quality actions and identify useful design states. This is performed as a feedback loop in conjunction with other feedforward tools for placement and routing.},
  doi       = {10.1145/3569052.3578907},
  isbn      = {9781450399784},
  keywords  = {monte carlo tree search, si/pi driven synthesis, reinforcement learning, machine learning, pcb design},
  location  = {Virtual Event, USA},
  numpages  = {1},
  url       = {https://doi.org/10.1145/3569052.3578907},
}

@InProceedings{Zhang2023,
  author    = {Zhang, Junteng and Chen, Tong and Ding, Dandan and Ma, Zhan},
  booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
  title     = {YOGA: Yet Another Geometry-Based Point Cloud Compressor},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {9070–9081},
  publisher = {Association for Computing Machinery},
  series    = {MM '23},
  abstract  = {A learning-based YOGA (Yet Another Geometry-based Point Cloud Compressor) is proposed. It is flexible, allowing for the separable lossy compression of geometry and color attributes, and variable-rate coding using a single neural model; it is high-efficiency, significantly outperforming the latest G-PCC standard quantitatively and qualitatively, e.g., 25\% BD-BR gains using PCQM (Point Cloud Quality Metric) as the distortion assessment, and it is lightweight, e.g., similar runtime as the G-PCC codec, owing to the use of sparse convolution and parallel entropy coding. To this end, YOGA adopts a unified end-to-end learning-based backbone for separate geometry and attribute compression. The backbone uses a two-layer structure, where the downscaled thumbnail point cloud is encoded using G-PCC at the base layer, and upon G-PCC compressed priors, multiscale sparse convolutions are stacked at the enhancement layer to effectively characterize spatial correlations to compactly represent the full-resolution sample. In addition, YOGA integrates the adaptive quantization and entropy model group to enable variable-rate control, as well as adaptive filters for better quality restoration.},
  doi       = {10.1145/3581783.3613847},
  isbn      = {9798400701085},
  keywords  = {point cloud compression, layered coding, attribute, geometry},
  location  = {<conf-loc>, <city>Ottawa ON</city>, <country>Canada</country>, </conf-loc>},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3581783.3613847},
}

@InProceedings{Bhambani2022,
  author    = {Bhambani, Krisha and Takalikar, Mukta},
  booktitle = {Proceedings of the 2021 4th International Conference on Computational Intelligence and Intelligent Systems},
  title     = {DeCloud GAN: An Advanced Generative Adversarial Network for Removing Cloud Cover in Optical Remote Sensing Imagery},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {25–30},
  publisher = {Association for Computing Machinery},
  series    = {CIIS '21},
  abstract  = {Optical Remote Sensing imagery has several applications in monitoring the states of natural and man-made features around the globe. However, due to clouds and other climatic conditions, information extracted from the imagery retrieved is very limited. Deep learning has often been used in several image processing and remote sensing tasks. In this work, we propose the usage of generative adversarial networks to remove clouds and other climatic interference from high-resolution remote sensing imagery. We have trained and tested upon the Remote sensing Image Cloud rEmoving dataset (RICE). The novel network(DeCloud GAN) we propose, makes use of residual UNets and pixel shuffle layers in the generator, which yield high quality cloudless satellite images. We have tested 4 methods for comparison, and have found that DeCloudGAN achieves the best performance on two main metrics, peak signal to noise ratio (PSNR) and structural similarity index (SSIM), to measure similarity in visual perception of the produced and target images.},
  doi       = {10.1145/3507623.3507628},
  isbn      = {9781450385930},
  keywords  = {Remote Sensing, Generative Adversarial Networks, Image generation, Deep Learning, Optical Imagery},
  location  = {Tokyo, Japan},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3507623.3507628},
}

@InProceedings{Yin2023,
  author    = {Yin, Haofei and Xiao, Mengbai and Yu, Dongxiao},
  booktitle = {Proceedings of the 1st ACM Workshop on Mobile Immersive Computing, Networking, and Systems},
  title     = {Preserving High Quality in A Learning-Based Compression Model for Point Cloud Videos},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {215–221},
  publisher = {Association for Computing Machinery},
  series    = {ImmerCom '23},
  abstract  = {High-resolution point cloud videos combined with 3D scenes can create creative viewing modes. However, their enormous data volume demands effective compression techniques. In this work, we propose a deep learning-based model for compressing point cloud videos. Compared to D-PCC, the state-of-the-art model designed for preserving high quality after decompression, the reconstruction result of our method achieves up to a 29.73\% improvement in the density metric and a noticeable improvement in human visual perception. We also discuss extending our model to compress color information and effectively remove inter-frame redundancy.},
  doi       = {10.1145/3615452.3617942},
  isbn      = {9798400703393},
  location  = {Madrid, Spain},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3615452.3617942},
}

@InProceedings{Couto2021,
  author    = {Couto, Luis and Teixeira Lopes, Carla},
  booktitle = {Proceedings of the 17th International Symposium on Open Collaboration},
  title     = {Equal Opportunities in the Access to Quality Online Health Information? A Multi-Lingual Study on Wikipedia},
  year      = {2021},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {OpenSym '21},
  abstract  = {Wikipedia is a free, multilingual, and collaborative online encyclopedia. Nowadays, it is one of the largest sources of online knowledge, often appearing at the top of the results of the major search engines, being one of the most sought-after resources by the public searching for health information. The collaborative nature of Wikipedia raises security concerns since this information is used for decision-making, especially in the health area. Despite being available in hundreds of idioms, there are asymmetries between idioms, namely regarding their quality. In this work, we compare the quality of health information on Wikipedia between idioms with 100 million native speakers or more, and also in Greek, Italian, Korean, Turkish, Persian, Catalan and Hebrew, for historical tradition. Quality metrics are applied to health and medical articles in English, maintained by WikiProject Medicine, and their versions in the above idioms. With this, we contribute to a clarification of the role of Wikipedia in the access to health information. We demonstrate differences in both the quantity and quality of information available between idioms. English is the idiom with the highest quality in general. Urdu, Greek, Indonesian, and Hindi achieved lower values of quality.},
  articleno = {13},
  doi       = {10.1145/3479986.3480000},
  isbn      = {9781450385008},
  keywords  = {Information Quality, Health information, Wikipedia, Multilingual information access},
  location  = {Online, Spain},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3479986.3480000},
}

@InProceedings{Bourbia2022,
  author    = {Bourbia, Salima and Karine, Ayoub and Chetouani, Aladine and El Hassouni, Mohammed and Jridi, Maher},
  booktitle = {Proceedings of the 2nd Workshop on Quality of Experience in Visual Multimedia Applications},
  title     = {No-Reference Point Clouds Quality Assessment Using Transformer and Visual Saliency},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {57–62},
  publisher = {Association for Computing Machinery},
  series    = {QoEVMA '22},
  abstract  = {Quality estimation of 3D objects/scenes represented by cloud point is a crucial and challenging task in computer vision. In real-world applications, reference data is not always available, which motivates the development of new point cloud quality assessment (PCQA) metrics that do not require the original 3D point cloud (3DPC). This family of methods is called no-reference or blind PCQA. In this context, we propose a deep-learning-based approach that benefits from the advantage of the self-attention mechanism in transformers to accurately predict the perceptual quality score for each degraded 3DPC. Additionally, we introduce the use of saliency maps to reflect the human visual system behavior that is attracted to some specific regions compared to others during the evaluation. To this end, we first render 2D projections (i.e. views) of a 3DPC from different viewpoints. Then, we weight the obtained projected images with their corresponding saliency maps. After that, we discard the majority of the background information by extracting sub-salient images. The latter is introduced as a sequential input of the vision transformer in order to extract the global contextual information and to predict the quality scores of the sub-images. Finally, we average the scores of all the salient sub-images to obtain the perceptual 3DPC quality score. We evaluate the performance of our model on the ICIP2020 and SJTU point cloud quality assessment benchmarks. Experimental results show that our model achieves promising performance compared to the state-of-the-art point cloud quality assessment metrics.},
  doi       = {10.1145/3552469.3555713},
  isbn      = {9781450394994},
  keywords  = {attention, visual saliency, 3d point clouds, objective quality assessment, transformer},
  location  = {Lisboa, Portugal},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3552469.3555713},
}

@InProceedings{Prazeres2022,
  author    = {Prazeres, Joao and Rodrigues, Rafael and Pereira, Manuela and Pinheiro, Antonio M.G.},
  booktitle = {Proceedings of the 1st International Workshop on Advances in Point Cloud Compression, Processing and Analysis},
  title     = {Quality Evaluation of Machine Learning-Based Point Cloud Coding Solutions},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {57–65},
  publisher = {Association for Computing Machinery},
  series    = {APCCPA '22},
  abstract  = {In this paper, a quality evaluation of three point cloud coding solutions based on machine learning technology is presented, notably, ADLPCC, PCC_GEO_CNN, and PCGC, as well as LUT_SR, which uses multi-resolution Look-Up Tables. Moreover, the MPEG G-PCC was used as an anchor. A set of six point clouds, representing both landscapes and objects were coded using the five encoders at different bit rates, and a subjective test, where the distorted and reference point clouds were rotated in a video sequence side by side, is carried out to assess their performance. Furthermore, the performance of point cloud objective quality metrics that usually provide a good representation of the coded content is analyzed against the subjective evaluation results. The obtained results suggest that some of these metrics fail to provide a good representation of the perceived quality, and thus are not suitable to evaluate some distortions created by machine learning-based solutions. A comparison between the analyzed metrics and the type of represented scene or codec is also presented.},
  doi       = {10.1145/3552457.3555730},
  isbn      = {9781450394918},
  keywords  = {machine learning, point clouds, quality evaluation, coding},
  location  = {Lisboa, Portugal},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3552457.3555730},
}

@InProceedings{JamshidiAvanaki2022,
  author    = {Jamshidi Avanaki, Nasim and Schmidt, Steven and Michael, Thilo and Zadtootaghaj, Saman and M\"{o}ller, Sebastian},
  booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
  title     = {Deep-BVQM: A Deep-Learning Bitstream-Based Video Quality Model},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {915–923},
  publisher = {Association for Computing Machinery},
  series    = {MM '22},
  abstract  = {With the rapid increase of video streaming content, high-quality video quality metrics, mainly signal-based video quality metrics, are emerging, notably VMAF, SSIMPLUS, and AVQM. Besides signal-based video quality metrics, within the standardization body, ITU-T Study Group 12, two well-known bitstream-based video quality metrics are developed named P.1203 and P.1204.3. Due to the low complexity and low level of access to the bitstream data, these models gained attention from network providers and service providers. In this paper, we proposed a new bitstream-based model named Deep-BVQM, which outperforms the standard models on the tested datasets. While the model comes with slightly higher computational complexity, it offers a frame-level quality prediction which is essential diagnostic information for some video streaming services such as cloud gaming. Deep-BVQM is developed in two layers; first, the frame quality was predicted using a lightweight CNN model. Next, the latent features of the CNN were used to train an LSTM network to predict the video quality in a short-term duration.},
  doi       = {10.1145/3503161.3548374},
  isbn      = {9781450392037},
  keywords  = {bitstream-based quality model, quality of experience, video quality},
  location  = {<conf-loc>, <city>Lisboa</city>, <country>Portugal</country>, </conf-loc>},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3503161.3548374},
}

@InProceedings{Yayla2022,
  author    = {Yayla, Mikail and Chen, Jian-Jia},
  booktitle = {Proceedings of the 59th ACM/IEEE Design Automation Conference},
  title     = {Memory-Efficient Training of Binarized Neural Networks on the Edge},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {661–666},
  publisher = {Association for Computing Machinery},
  series    = {DAC '22},
  abstract  = {A visionary computing paradigm is to train resource efficient neural networks on the edge using dedicated low-power accelerators instead of cloud infrastructures, eliminating communication overheads and privacy concerns. One promising resource-efficient approach for inference is binarized neural networks (BNNs), which binarize parameters and activations. However, training BNNs remains resource demanding. State-of-the-art BNN training methods, such as the binary optimizer (Bop), require to store and update a large number of momentum values in the floating point (FP) format.In this work, we focus on memory-efficient FP encodings for the momentum values in Bop. To achieve this, we first investigate the impact of arbitrary FP encodings. When the FP format is not properly chosen, we prove that the updates of the momentum values can be lost and the quality of training is therefore dropped. With the insights, we formulate a metric to determine the number of unchanged momentum values in a training iteration due to the FP encoding. Based on the metric, we develop an algorithm to find FP encodings that are more memory-efficient than the standard FP encodings. In our experiments, the memory usage in BNN training is decreased by factors 2.47x, 2.43x, 2.04x, depending on the BNN model, with minimal accuracy cost (smaller than 1\%) compared to using 32-bit FP encoding.},
  doi       = {10.1145/3489517.3530496},
  isbn      = {9781450391429},
  location  = {San Francisco, California},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3489517.3530496},
}

@InProceedings{Bourbia2023,
  author    = {Bourbia, Salima and Karine, Ayoub and Chetouani, Aladine and El Hassouni, Mohammed and Jridi, Maher},
  booktitle = {Proceedings of the 20th International Conference on Content-Based Multimedia Indexing},
  title     = {Multi-Stream Point-Based Model for Blind Geometric Point Cloud Quality Assessment},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {224–228},
  publisher = {Association for Computing Machinery},
  series    = {CBMI '23},
  abstract  = {The evaluation of 3D point cloud quality is a critical component in the development of immersive multimedia systems for real-world applications. While perceptual quality evaluation technics for 2D images and videos have reached high performances, developing robust and efficient blind metrics for point cloud quality assessment is still challenging. In this paper, we propose a no-reference point cloud quality assessment method that evaluates the quality of degraded 3D objects using an end-to-end point-based multi-stream model. To capture the geometric degradation of the point cloud, we incorporate normals, curvatures and geometric coordinates. Then, we divide the distorted object into sub-objects, which are fed to a multi-stream network to extract significant features of the geometric degradation. Afterward, these features are used to predict the quality of each sub-object, and the perceptual quality score of the point cloud is obtained by averaging the quality scores of all sub-objects. Experimental results demonstrate that the proposed model achieves promising performance compared to state-of-the- art full and reduced methods.},
  doi       = {10.1145/3617233.3617247},
  isbn      = {9798400709128},
  keywords  = {Quality assessment, 3D point cloud, Multi-stream, Deep learning., Point-based model},
  location  = {<conf-loc>, <city>Orleans</city>, <country>France</country>, </conf-loc>},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3617233.3617247},
}

@InProceedings{Agarwal2023,
  author    = {Agarwal, Shubham and Chakraborty, Sarthak and Garg, Shaddy and Bisht, Sumit and Jain, Chahat and Gonuguntla, Ashritha and Saini, Shiv},
  booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  title     = {Outage-Watch: Early Prediction of Outages Using Extreme Event Regularizer},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {682–694},
  publisher = {Association for Computing Machinery},
  series    = {ESEC/FSE 2023},
  abstract  = {Cloud services are omnipresent and critical cloud service failure is a fact of life. In order to retain customers and prevent revenue loss, it is important to provide high reliability guarantees for these services. One way to do this is by predicting outages in advance, which can help in reducing the severity as well as time to recovery. It is difficult to forecast critical failures due to the rarity of these events. Moreover, critical failures are ill-defined in terms of observable data. Our proposed method, Outage-Watch, defines critical service outages as deteriorations in the Quality of Service (QoS) captured by a set of metrics. Outage-Watch detects such outages in advance by using current system state to predict whether the QoS metrics will cross a threshold and initiate an extreme event. A mixture of Gaussian is used to model the distribution of the QoS metrics for flexibility and an extreme event regularizer helps in improving learning in tail of the distribution. An outage is predicted if the probability of any one of the QoS metrics crossing threshold changes significantly. Our evaluation on a real-world SaaS company dataset shows that Outage-Watch significantly outperforms traditional methods with an average AUC of 0.98. Additionally, Outage-Watch detects all the outages exhibiting a change in service metrics and reduces the Mean Time To Detection (MTTD) of outages by up to 88\% when deployed in an enterprise cloud-service system, demonstrating efficacy of our proposed method.},
  doi       = {10.1145/3611643.3616316},
  isbn      = {9798400703270},
  keywords  = {Distribution Learning, Mixture Density Network, Outage Forecasting, System reliability and monitoring},
  location  = {<conf-loc>, <city>San Francisco</city>, <state>CA</state>, <country>USA</country>, </conf-loc>},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3611643.3616316},
}

@InProceedings{Zha2021a,
  author    = {Zha, Yue and Li, Jing},
  booktitle = {Proceedings of the 48th Annual International Symposium on Computer Architecture},
  title     = {Hetero-ViTAL: A Virtualization Stack for Heterogeneous FPGA Clusters},
  year      = {2021},
  address   = {Virtual Event, Spain},
  pages     = {470–483},
  publisher = {IEEE Press},
  series    = {ISCA '21},
  abstract  = {With field-programmable gate arrays (FPGAs) being widely deployed into data centers, an efficient virtualization support is required to fully unleash the potential of cloud FPGAs. Nevertheless, existing FPGA virtualization solutions only support a homogeneous FPGA cluster comprising identical FPGA devices. Representative work such as ViTAL provides sufficient system support for scale-out acceleration and improves the overall resource utilization through a fine-grained spatial sharing. While these existing solutions (including ViTAL) can efficiently virtualize a homogeneous cluster, it is hard to extend them to virtualizing a heterogeneous cluster which comprises multiple types of FPGAs. We expect the future cloud FPGAs are likely to be more heterogeneous due to hardware rolling upgrade.In this paper, we rethink FPGA virtualization from ground up and propose HETERO-VITAL to virtualize heterogeneous FPGA clusters. We identify the conflicting requirements of runtime management and offline compilation when designing the abstraction for a heterogeneous cluster, which is also the fundamental reason why the single-level abstraction as proposed in ViTAL (and other prior works) cannot be trivially extended to the heterogeneous case. To decouple these conflicting requirements, we provide a two-level system abstraction in HETERO-VITAL. Specifically, the high-level abstraction is FPGA-agnostic and provides a simple and homogeneous view of the FPGA resources to simplify the runtime management. On the contrary, the low-level abstraction is FPGA-specific and exposes sufficient spatial resource constraints to the compilation framework to ensure the mapping quality. Rather than simply adding a layer on top of the single-level abstraction as proposed in ViTAL and other prior work, we judiciously determine how much hardware details should be exposed at each level to balance the management complexity, mapping quality and compilation cost. We then develop a compilation framework to map applications onto this two-level abstraction with several optimization techniques to further improve the mapping quality. We also provide a runtime management policy to alleviate the fragmentation issue, which becomes more severe in a heterogeneous cluster due to the distinct resource capacities of diverse FPGAs.We evaluate HETERO-VITAL on a custom-built FPGA cluster and demonstrate its effectiveness using machine learning and image processing applications. Results show that HETERO-VITAL reduces the average response time (a critical metric for QoS) by 79.2\% for a heterogeneous cluster compared to the non-virtualized baseline. When virtualizing a homogeneous cluster, HETERO-VITAL also reduces the average response time by 42.0\% compared with ViTAL due to a better system design.},
  doi       = {10.1109/ISCA52012.2021.00044},
  isbn      = {9781450390866},
  numpages  = {14},
  url       = {https://doi.org/10.1109/ISCA52012.2021.00044},
}

@InProceedings{Zhang2021f,
  author    = {Zhang, Yujie and Yang, Qi and Xu, Yiling},
  booktitle = {Proceedings of the 29th ACM International Conference on Multimedia},
  title     = {MS-GraphSIM: Inferring Point Cloud Quality via Multiscale Graph Similarity},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {1230–1238},
  publisher = {Association for Computing Machinery},
  series    = {MM '21},
  abstract  = {To address the point cloud quality assessment (PCQA) problem, GraphSIM was proposed via jointly considering geometrical and color features, which shows compelling performance in multiple distortion detection. However, GraphSIM does not take into account the mutiscale characteristics of human perception. In this paper, we propose a multiscale PCQA model, called Multiscale Graph Similarity (MS-GraphSIM), that can better predict human subjective perception. First, exploring the multiscale processing method used in image processing, we introduce a multiscale representation of point clouds based on graph signal processing. Second, we extend GraphSIM into multiscale version based on the proposed multiscale representation. Specifically, MS-GraphSIM constructs a multiscale representation for each local patch extracted from the reference point cloud or the distorted point cloud, and then fuses GraphSIM at different scales to obtain an overall quality score. Experiment results demonstrate that the proposed MS-GraphSIM outperforms the state-of-the-art PCQA metrics over two fairly large and independent databases. Ablation studies further prove the proposed MS-GraphSIM is robust to different model hyperparameter settings. The code is available at https://github.com/zyj1318053/MS_GraphSIM.},
  doi       = {10.1145/3474085.3475294},
  isbn      = {9781450386517},
  keywords  = {graph signal processing, multiscale representation, quality assessment, point cloud},
  location  = {Virtual Event, China},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3474085.3475294},
}

@Article{Prakash2023,
  author     = {Prakash, R Sri and Karamchandani, Nikhil and Moharir, Sharayu},
  journal    = {SIGMETRICS Perform. Eval. Rev.},
  title      = {On the Regret of Online Edge Service Hosting},
  year       = {2023},
  issn       = {0163-5999},
  month      = {apr},
  number     = {4},
  pages      = {35–37},
  volume     = {50},
  abstract   = {We consider the problem of service hosting where a service provider can dynamically rent edge resources via short term contracts to ensure better quality of service to its customers. The total cost incurred by the system is modeled as a combination of the rent cost, the service cost incurred due to latency in serving customers, and the fetch cost incurred as a result of the bandwidth used to fetch the code/databases of the service from the cloud servers to host the service at the edge. In this paper, we compare multiple hosting policies with regret as a metric, defined as the difference in the cost incurred by the policy and the optimal policy over some time horizon T. In particular we consider the Retro Renting (RR) and Follow The Perturbed Leader (FTPL) policies proposed in the literature and provide performance guarantees on the regret of these policies. We show that under i.i.d Bernoulli arrivals, RR policy has linear regret while FTPL policy has constant regret. Next, we propose a variant of FTPL, namely Wait then FTPL (W-FTPL), which also has constant regret while demonstrating much better dependence on the fetch cost. We also show that under adversarial arrivals, RR policy has linear regret while both FTPL and W-FTPL have regret O(pT) which is order-optimal.},
  address    = {New York, NY, USA},
  doi        = {10.1145/3595244.3595257},
  issue_date = {March 2023},
  numpages   = {3},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3595244.3595257},
}

@Article{Zhong2022,
  author     = {Zhong, Zhiheng and Xu, Minxian and Rodriguez, Maria Alejandra and Xu, Chengzhong and Buyya, Rajkumar},
  journal    = {ACM Comput. Surv.},
  title      = {Machine Learning-Based Orchestration of Containers: A Taxonomy and Future Directions},
  year       = {2022},
  issn       = {0360-0300},
  month      = {sep},
  number     = {10s},
  volume     = {54},
  abstract   = {Containerization is a lightweight application virtualization technology, providing high environmental consistency, operating system distribution portability, and resource isolation. Existing mainstream cloud service providers have prevalently adopted container technologies in their distributed system infrastructures for automated application management. To handle the automation of deployment, maintenance, autoscaling, and networking of containerized applications, container orchestration is proposed as an essential research problem. However, the highly dynamic and diverse feature of cloud workloads and environments considerably raises the complexity of orchestration mechanisms. Machine learning algorithms are accordingly employed by container orchestration systems for behavior modeling and prediction of multi-dimensional performance metrics. Such insights could further improve the quality of resource provisioning decisions in response to the changing workloads under complex environments. In this article, we present a comprehensive literature review of existing machine learning-based container orchestration approaches. Detailed taxonomies are proposed to classify the current researches by their common features. Moreover, the evolution of machine learning-based container orchestration technologies from the year 2016 to 2021 has been designed based on objectives and metrics. A comparative analysis of the reviewed techniques is conducted according to the proposed taxonomies, with emphasis on their key characteristics. Finally, various open research challenges and potential future directions are highlighted.},
  address    = {New York, NY, USA},
  articleno  = {217},
  doi        = {10.1145/3510415},
  issue_date = {January 2022},
  keywords   = {machine learning, systematic review, Container orchestration, cloud computing, resource provisioning},
  numpages   = {35},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3510415},
}

@InProceedings{Makris2022,
  author    = {Makris, Antonios and Psomakelis, Evangelos and Theodoropoulos, Theodoros and Tserpes, Konstantinos},
  booktitle = {Proceedings of the 2nd Workshop on Flexible Resource and Application Management on the Edge},
  title     = {Towards a Distributed Storage Framework for Edge Computing Infrastructures},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {9–14},
  publisher = {Association for Computing Machinery},
  series    = {FRAME '22},
  abstract  = {Due to the continuous development of Internet of Things (IoT), the volume of the data these devices generate are expected to grow dramatically in the future. As a result, managing and processing such massive data amounts at the edge becomes a vital issue. Edge computing moves data and computation closer to the client enabling latency- and bandwidth-sensitive applications, that would not be feasible using cloud and remote processing alone. Nevertheless, implementing an efficient edge-enabled storage system is challenging due to the distributed and heterogeneous nature of the edge and its limited resource capabilities. To this end, we propose a lightweight hybrid distributed edge/cloud storage framework which aims to improve the Quality of Experience (QoE) of the end-users by migrating data close to them, thus reducing data transfers delays and network utilization. The proposed edge storage component (ESC) exploits the Dynamic Lifecycle Framework, in order to enable transparent and automated access for containerized applications to remote workloads. The effectiveness of the ESC is evaluated by employing a number of resource utilization and Quality of Service (QoS) metrics.},
  doi       = {10.1145/3526059.3533617},
  isbn      = {9781450393102},
  keywords  = {edge computing, edge storage, cloud computing, kubernetes, internet of things, container-based, minio, virtualization},
  location  = {Minneapolis, MN, USA},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3526059.3533617},
}

@InProceedings{Mok2021,
  author    = {Mok, Ricky K. P. and Zou, Hongyu and Yang, Rui and Koch, Tom and Katz-Bassett, Ethan and Claffy, K C},
  booktitle = {Proceedings of the 21st ACM Internet Measurement Conference},
  title     = {Measuring the Network Performance of Google Cloud Platform},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {54–61},
  publisher = {Association for Computing Machinery},
  series    = {IMC '21},
  abstract  = {Public cloud platforms are vital in supporting online applications for remote learning and telecommuting during the COVID-19 pandemic. The network performance between cloud regions and access networks directly impacts application performance and users' quality of experience (QoE). However, the location and network connectivity of vantage points often limits the visibility of edge-based measurement platforms (e.g., RIPE Atlas).We designed and implemented the CLoud-based Applications Speed Platform (CLASP) to measure performance to various networks from virtual machines in cloud regions with speed test servers that have been widely deployed on the Internet. In our five-month longitudinal measurements in Google Cloud Platform (GCP), we found that 30-70\% of ISPs we measured showed severe throughput degradation from the peak throughput of the day.},
  doi       = {10.1145/3487552.3487862},
  isbn      = {9781450391290},
  keywords  = {cloud networking, network throughput, speed test},
  location  = {Virtual Event},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3487552.3487862},
}

@InProceedings{Xie2023a,
  author    = {Xie, Wuyuan and Wang, Kaimin and Ju, Yakun and Wang, Miaohui},
  booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
  title     = {PmBQA: Projection-Based Blind Point Cloud Quality Assessment via Multimodal Learning},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {3250–3258},
  publisher = {Association for Computing Machinery},
  series    = {MM '23},
  abstract  = {With the increasing communication and storage of point cloud data, there is an urgent need for an effective objective method to measure the quality before and after processing. To address this difficulty, we propose a projection-based blind quality indicator via multimodal learning for point cloud data, which can perceive both geometric distortion and texture distortion by using four homogeneous modalities (i.e., texture, normal, depth and roughness). To fully exploit the multimodal information, we further develop a deformable convolutionbased alignment module and a graph-based feature fusion module, and investigate a graph node attention-based evaluation method to forecast the quality score. Extensive experimental results on three benchmark databases show that our method achieves more accurate evaluation performance in comparison with 12 competitive methods.},
  doi       = {10.1145/3581783.3611998},
  isbn      = {9798400701085},
  keywords  = {quality assessment, no reference, point cloud, multimodal information},
  location  = {<conf-loc>, <city>Ottawa ON</city>, <country>Canada</country>, </conf-loc>},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3581783.3611998},
}

@InProceedings{Mukhia2023,
  author    = {Mukhia, Raunak and Sarambage Jayarathna, Kalana Gayashan and Lertsinsrubtavee, Adisorn},
  booktitle = {Proceedings of the 18th Asian Internet Engineering Conference},
  title     = {Performance Evaluation of LoRaWAN Forest Fire Monitoring Network in the Wild},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {96–104},
  publisher = {Association for Computing Machinery},
  series    = {AINTEC '23},
  abstract  = {To leverage the potential of LoRaWAN, we have successfully developed a real-world field wireless sensor network dedicated to monitoring forest fires and air quality. This network operates across remote forested regions and semi-urban areas. The development effort encompasses the complete LoRaWAN network stack, including a tailored circuit board designed for LoRa communication and multi-sensor nodes, the establishment of network infrastructure, and a cloud-based data collection platform that strictly adheres to the LoRaWAN standard. In this context, we have introduced a retransmission mechanism in the LoRaWAN application layer for sensor data completeness, along with lorawanatd which operates the LoRaWAN hardware. This extension serves to enhance communication robustness between end nodes and the network cloud, ensuring a seamless and reliable data transmission. Our initiative also involved a comprehensive series of experiments, conducted using sensor nodes situated in proximity to forest fire-prone areas. These experiments were conducted to delve into optimal configurations and constraints related to radio wave propagation. Key performance metrics guiding these investigations include the Received Signal Strength Indicator (RSSI), Signal to Noise Ratio (SNR), Packet Delivery Ratio (PDR), and Data Completeness Ratio (DCR).},
  doi       = {10.1145/3630590.3630602},
  isbn      = {9798400709395},
  keywords  = {LoRaWAN, Low Power Wide Area Networks, Forest Fire, Wireless Sensor Network, Internet of Things},
  location  = {<conf-loc>, <city>Hanoi</city>, <country>Vietnam</country>, </conf-loc>},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3630590.3630602},
}

@Article{Dias2021,
  author     = {Dias, Alexandre H. T. and Correia, Luiz. H. A. and Malheiros, Neumar},
  journal    = {ACM Comput. Surv.},
  title      = {A Systematic Literature Review on Virtual Machine Consolidation},
  year       = {2021},
  issn       = {0360-0300},
  month      = {oct},
  number     = {8},
  volume     = {54},
  abstract   = {Virtual machine consolidation has been a widely explored topic in recent years due to Cloud Data Centers’ effect on global energy consumption. Thus, academia and companies made efforts to achieve green computing, reducing energy consumption to minimize environmental impact. By consolidating Virtual Machines into a fewer number of Physical Machines, resource provisioning mechanisms can shutdown idle Physical Machines to reduce energy consumption and improve resource utilization. However, there is a tradeoff between reducing energy consumption while assuring the Quality of Service established on the Service Level Agreement. This work introduces a Systematic Literature Review of one year of advances in virtual machine consolidation. It provides a discussion on methods used in each step of the virtual machine consolidation, a classification of papers according to their contribution, and a quantitative and qualitative analysis of datasets, scenarios, and metrics.},
  address    = {New York, NY, USA},
  articleno  = {176},
  doi        = {10.1145/3470972},
  issue_date = {November 2022},
  keywords   = {systematic literature review, virtual machines consolidation, Cloud computing, green computing},
  numpages   = {38},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3470972},
}

@InProceedings{Kak2023,
  author    = {Kak, A. and Thieu, H. -T. and Pham, V. -Q. and Sheshadri, R. K. and Choi, N. and Guan, Y. and Yin, M. and Han, T.},
  booktitle = {Proceedings of the 17th ACM Workshop on Wireless Network Testbeds, Experimental Evaluation \&amp; Characterization},
  title     = {AweRAN: Making a Case for Application-Aware Radio Access Network Slicing},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {41–48},
  publisher = {Association for Computing Machinery},
  series    = {WiNTECH '23},
  abstract  = {As communications service providers ponder ways to cater to the diverse traffic requirements of mobile applications that range from the classic telephony to modern augmented reality (AR)-related use cases, the traditional quality of service (QoS)-based radio resource management (RRM) techniques for RAN slicing that are agnostic to the intrinsic workings of applications can result in a poor quality of experience (QoE) for the end-user. We argue that in addition to QoS, RAN slicing strategies should also consider QoE for efficient resource utilization. However, without comprehensively understanding the interplay between QoS, QoE and how various RRM techniques can potentially influence them, it is impossible to incorporate QoE-driven feedback for resource allocation. Consequently, in this work, we conduct a first-of-its-kind in-depth experimental campaign on an O-RAN compliant 5G cellular testbed to evaluate the performance of the QoE metrics of three varied applications---video-enabled voice calling, cloud gaming, and AR---under various RAN slice configurations. We discuss the key findings of this elaborate study, and motivate the need for a QoE-aware RRM framework for RAN slicing.},
  doi       = {10.1145/3615453.3616511},
  isbn      = {9798400703409},
  keywords  = {Open RAN (O-RAN), Mobile Networks, Wireless Networks},
  location  = {Madrid, Spain},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3615453.3616511},
}

@Article{Duboc2022,
  author     = {Duboc, Leticia and Bahsoon, Rami and Alrebeish, Faisal and Mera-G\'{o}mez, Carlos and Nallur, Vivek and Kazman, Rick and Bianco, Philip and Babar, Ali and Buyya, Rajkumar},
  journal    = {ACM Trans. Auton. Adapt. Syst.},
  title      = {Systematic Scalability Modeling of QoS-Aware Dynamic Service Composition},
  year       = {2022},
  issn       = {1556-4665},
  month      = {nov},
  number     = {3–4},
  volume     = {16},
  abstract   = {In Dynamic Service Composition (DSC), an application can be dynamically composed using web services to achieve its functional and Quality of Services (QoS) goals. DSC is a relatively mature area of research that crosscuts autonomous and services computing. Complex autonomous and self-adaptive computing paradigms (e.g., multi-tenant cloud services, mobile/smart services, services discovery and composition in intelligent environments such as smart cities) have been leveraging DSC to dynamically and adaptively maintain the desired QoS, cost and to stabilize long-lived software systems. While DSC is fundamentally known to be an NP-hard problem, systematic attempts to analyze its scalability have been limited, if not absent, though such analysis is of a paramount importance for their effective, efficient, and stable operations.This article reports on a new application of goal-modeling, providing a systematic technique that can support DSC designers and architects in identifying DSC-relevant characteristics and metrics that can potentially affect the scalability goals of a system. The article then applies the technique to two different approaches for QoS-aware dynamic services composition, where the article describes two detailed exemplars that exemplify its application. The exemplars hope to provide researchers and practitioners with guidance and transferable knowledge in situations where the scalability analysis may not be straightforward. The contributions provide architects and designers for QoS-aware dynamic service composition with the fundamentals for assessing the scalability of their own solutions, along with goal models and a list of application domain characteristics and metrics that might be relevant to other solutions. Our experience has shown that the technique was able to identify in both exemplars application domain characteristics and metrics that had been overlooked in previous scalability analyses of these DSC, some of which indeed limited their scalability. It has also shown that the experiences and knowledge can be transferable: The first exemplar was used as an example to inform and ease the work of applying the technique in the second one, reducing the time to create the model, even for a non-expert.},
  address    = {New York, NY, USA},
  articleno  = {10},
  doi        = {10.1145/3529162},
  issue_date = {December 2021},
  keywords   = {Scalability modelling, autonomous and adaptive systems, dynamic service composition},
  numpages   = {39},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3529162},
}

@InProceedings{Wallis2021,
  author    = {Wallis, Kevin and Reich, Christoph and Varghese, Blesson and Schindelhauer, Christian},
  booktitle = {Proceedings of the 14th IEEE/ACM International Conference on Utility and Cloud Computing},
  title     = {QUDOS: Quorum-Based Cloud-Edge Distributed DNNs for Security Enhanced Industry 4.0},
  year      = {2021},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {UCC '21},
  abstract  = {Distributed machine learning algorithms that employ Deep Neural Networks (DNNs) are widely used in Industry 4.0 applications, such as smart manufacturing. The layers of a DNN can be mapped onto different nodes located in the cloud, edge and shop floor for preserving privacy. The quality of the data that is fed into and processed through the DNN is of utmost importance for critical tasks, such as inspection and quality control. Distributed Data Validation Networks (DDVNs) are used to validate the quality of the data. However, they are prone to single points of failure when an attack occurs. This paper proposes QUDOS, an approach that enhances the security of a distributed DNN that is supported by DDVNs using quorums. The proposed approach allows individual nodes that are corrupted due to an attack to be detected or excluded when the DNN produces an output. Metrics such as corruption factor and success probability of an attack are considered for evaluating the security aspects of DNNs. A simulation study demonstrates that if the number of corrupted nodes is less than a given threshold for decision-making in a quorum, the QUDOS approach always prevents attacks. Furthermore, the study shows that increasing the size of the quorum has a better impact on security than increasing the number of layers. One merit of QUDOS is that it enhances the security of DNNs without requiring any modifications to the algorithm and can therefore be applied to other classes of problems.},
  articleno = {5},
  doi       = {10.1145/3468737.3494094},
  isbn      = {9781450385640},
  keywords  = {industry 4.0, cloud-edge computing, distributed DNN, distributed data validation network, edge security},
  location  = {Leicester, United Kingdom},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3468737.3494094},
}

@InProceedings{Xu2022,
  author    = {Xu, Xiaokun and Claypool, Mark},
  booktitle = {Proceedings of the 22nd ACM Internet Measurement Conference},
  title     = {Measurement of Cloud-Based Game Streaming System Response to Competing TCP Cubic or TCP BBR Flows},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {305–316},
  publisher = {Association for Computing Machinery},
  series    = {IMC '22},
  abstract  = {Cloud-based game streaming is emerging as a convenient way to play games when clients have a good network connection. However, high-quality game streams need high bitrates and low latencies, a challenge when competing for network capacity with other flows. While some network aspects of cloud-based game streaming have been studied, missing are comparative performance and congestion responses to competing TCP flows. This paper presents results from experiments that measure how three popular commercial cloud-based game streaming systems - Google Stadia, NVidia GeForce Now, and Amazon Luna - respond and then recover to TCP Cubic and TCP BBR flows on a congested network link. Analysis of bitrates, loss rates and round-trip times show the three systems have markedly different responses to the arrival and departure of competing network traffic.},
  doi       = {10.1145/3517745.3561464},
  isbn      = {9781450392594},
  location  = {Nice, France},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3517745.3561464},
}

@InProceedings{Fang2021,
  author    = {Fang, Yuan and Fan, Lei},
  booktitle = {Proceedings of the 4th International Conference on Control and Computer Vision},
  title     = {Comparisons of Eight Simplification Methods for Data Reduction of Terrain Point Cloud},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {135–141},
  publisher = {Association for Computing Machinery},
  series    = {ICCCV '21},
  abstract  = {In recent years, the applications of 3D point cloud data representing terrain surfaces have been growing rapidly. Such data typically have a very fine spatial resolution, which can lead to computational and visualisation issues. To overcome these issues, it is a common practice to reduce the density of point cloud data during initial data processing. As such, various simplification methods had been developed and used in practice. The choice of those methods is crucial to preserve features and shapes of the terrain in the simplified point cloud data. Previous studies on this matter were focused mainly on the methods commonly used in geosciences, but did not consider those in computer graphics. In this study, a total of eight simplification methods that are used widely in both geosciences and computer graphics were compared and analyzed using four sets of terrain surface point cloud data. In addition, unlike previous studies where a global RMSE (root mean squared error) was used as the metric for comparing different methods, the standard deviation of local RMSEs (root mean squared errors) was also calculated in this study to check the uniformity of local RMSEs over the whole terrain areas considered. The results show that the adaptive sampling method yielded thinned point cloud data of higher overall accuracy and more consistent local RMSEs than those obtained using the other methods considered.},
  doi       = {10.1145/3484274.3484307},
  isbn      = {9781450390477},
  keywords  = {data density, computer graphics, terrain, simplification, sampling, point clouds},
  location  = {Macau, China},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3484274.3484307},
}

@Article{Bhuyan2022,
  author     = {Bhuyan, Sandeepa and Zhao, Shulin and Ying, Ziyu and Kandemir, Mahmut T. and Das, Chita R.},
  journal    = {Proc. ACM Meas. Anal. Comput. Syst.},
  title      = {End-to-End Characterization of Game Streaming Applications on Mobile Platforms},
  year       = {2022},
  month      = {feb},
  number     = {1},
  volume     = {6},
  abstract   = {With the advent of 5G, supporting high-quality game streaming applications on edge devices has become a reality. This is evidenced by a recent surge in cloud gaming applications on mobile devices. In contrast to video streaming applications, interactive games require much more compute power for supporting improved rendering (such as 4K streaming) with the stipulated frames-per second (FPS) constraints. This in turn consumes more battery power in a power-constrained mobile device. Thus, the state-of-the-art gaming applications suffer from lower video quality (QoS) and/or energy efficiency. While there has been a plethora of recent works on optimizing game streaming applications, to our knowledge, there is no study that systematically investigates the &lt;QoS, Energy&gt; design pairs on the end-to-end game streaming pipeline across the cloud, network, and edge devices to understand the individual contributions of the different stages of the pipeline for improving the overall QoS and energy efficiency. In this context, this paper presents a comprehensive performance and power analysis of the entire game streaming pipeline consisting of the server/cloud side, network, and edge. Through extensive measurements with a high-end workstation mimicking the cloud end, an open-source platform (Moonlight-GameStreaming) emulating the edge device/mobile platform, and two network settings (WiFi and 5G) we conduct a detailed measurement-based study with seven representative games with different characteristics. We characterize the performance in terms of frame latency, QoS, bitrate, and energy consumption for different stages of the gaming pipeline. Our study shows that the rendering stage and the encoding stage at the cloud end are the bottlenecks to support 4K streaming. While 5G is certainly more suitable for supporting enhanced video quality with 4K streaming, it is more expensive in terms of power consumption compared to WiFi. Further, fluctuations in 5G network quality can lead to huge frame drops thus affecting QoS, which needs to be addressed by a coordinated design between the edge device and the server. Finally, the network interface and the decoder units in a mobile platform need more energy-efficient design to support high quality games at a lower cost. These observations should help in designing more cost-effective future cloud gaming platforms.},
  address    = {New York, NY, USA},
  articleno  = {10},
  doi        = {10.1145/3508030},
  issue_date = {March 2022},
  keywords   = {energy efficiency, cloud gaming, smartphones, 5g, performance},
  numpages   = {25},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3508030},
}

@InProceedings{Xi2023,
  author    = {Xi, Yunjia and Liu, Weiwen and Wang, Yang and Tang, Ruiming and Zhang, Weinan and Zhu, Yue and Zhang, Rui and Yu, Yong},
  booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  title     = {On-Device Integrated Re-Ranking with Heterogeneous Behavior Modeling},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {5225–5236},
  publisher = {Association for Computing Machinery},
  series    = {KDD '23},
  abstract  = {As an emerging field driven by industrial applications, integrated re-ranking combines lists from upstream sources into a single list, and presents it to the user. The quality of integrated re-ranking is especially sensitive to real-time user behaviors and preferences. However, existing methods are all built on the cloud-to-edge framework, where mixed lists are generated by the cloud model and then sent to the devices. Despite its effectiveness, such a framework fails to capture users' real-time preferences due to the network bandwidth and latency. Hence, we propose to place the integrated re-ranking model on devices, allowing for the full exploitation of real-time behaviors. To achieve this, we need to address two key issues: first, how to extract users' preferences for different sources from heterogeneous and imbalanced user behaviors; second, how to explore the correlation between the extracted personalized preferences and the candidate items. In this work, we present the first on-Device Integrated Re-ranking framework, DIR, to avoid delays in processing real-time user behaviors. DIR includes a multi-sequence behavior modeling module to extract the user's source-level preferences, and a preference-adaptive re-ranking module to incorporate personalized source-level preferences into the re-ranking of candidate items. Besides, we design exposure loss and utility loss to jointly optimize exposure fairness and overall utility. Extensive experiments on three datasets show that DIR significantly outperforms the state-of-the-art baselines in utility-based and fairness-based metrics.},
  doi       = {10.1145/3580305.3599878},
  isbn      = {9798400701030},
  keywords  = {integrated re-ranking, edge computing, recommender system},
  location  = {<conf-loc>, <city>Long Beach</city>, <state>CA</state>, <country>USA</country>, </conf-loc>},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3580305.3599878},
}

@InProceedings{Yang2022a,
  author    = {Yang, Liu and Wang, Jian and Zhao, Zebin},
  booktitle = {Proceedings of the 5th International Conference on Information Management and Management Science},
  title     = {Quality Evaluation of Government Epidemic Data Openness Based on Cloud Model and PSR Theory},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {7–14},
  publisher = {Association for Computing Machinery},
  series    = {IMMS '22},
  abstract  = {Government data opening has become one of the key measures of government emergency management in the big data era. Investigating deeply the quality of government data opening under public health emergencies can help grasp the current situation and provide experience for future work. This paper evaluates the 31 regional health commissions’ epidemic data openness using a framework based on PSR theory in China, and the cloud model was used to evaluate the quality of government data opening at the national and regional levels. The comprehensive evaluation level of government data openness under the epidemic situation in China was ordinary level and the level of data openness varies greatly among regions. Data state is the main factor restricting the level of data openness.},
  doi       = {10.1145/3564858.3564860},
  isbn      = {9781450396721},
  keywords  = {public health emergencies, cloud model, open government data, PSR theory},
  location  = {Chengdu, China},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3564858.3564860},
}

@InProceedings{Li2023c,
  author    = {Li, Bolun and Su, Pengfei and Chabbi, Milind and Jiao, Shuyin and Liu, Xu},
  booktitle = {Proceedings of the 21st ACM/IEEE International Symposium on Code Generation and Optimization},
  title     = {DJXPerf: Identifying Memory Inefficiencies via Object-Centric Profiling for Java},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {81–94},
  publisher = {Association for Computing Machinery},
  series    = {CGO 2023},
  abstract  = {Java is the “go-to” programming language choice for developing scalable enterprise cloud applications. In such systems, even a few percent CPU time savings can offer a significant competitive advantage and cost savings. Although performance tools abound for Java, those that focus on the data locality in the memory hierarchy are rare.  

In this paper, we first categorize data locality issues in Java programs. We then present DJXPerf, a lightweight, object-centric memory profiler for Java, which associates memory-hierarchy performance metrics (e.g., cache/TLB misses) with Java objects. DJXPerf uses statistical sampling of hardware performance monitoring counters to attribute metrics to not only source code locations but also Java objects. DJXPerf presents Java object allocation contexts combined with their usage contexts and presents them ordered by the poor locality behaviors. DJXPerf’s performance measurement, object attribution, and presentation techniques guide optimizing object allocation, layout, and access patterns. DJXPerf incurs only ~8.5\% runtime overhead and ∼6\% memory overhead on average, requiring no modifications to hardware, OS, Java virtual machine, or application source code, which makes it attractive to use in production. Guided by DJXPerf, we study and optimize a number of Java and Scala programs, including well-known benchmarks and real-world applications, and demonstrate significant speedups.},
  doi       = {10.1145/3579990.3580010},
  isbn      = {9798400701016},
  keywords  = {performance optimization, Java, profiling, PMU},
  location  = {Montr\'{e}al, QC, Canada},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3579990.3580010},
}

@InProceedings{Bhuyan2022a,
  author    = {Bhuyan, Sandeepa and Zhao, Shulin and Ying, Ziyu and Kandemir, Mahmut T. and Das, Chita R.},
  booktitle = {Abstract Proceedings of the 2022 ACM SIGMETRICS/IFIP PERFORMANCE Joint International Conference on Measurement and Modeling of Computer Systems},
  title     = {End-to-End Characterization of Game Streaming Applications on Mobile Platforms},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {11–12},
  publisher = {Association for Computing Machinery},
  series    = {SIGMETRICS/PERFORMANCE '22},
  abstract  = {With the advent of 5G, hosting high-quality game streaming applications on mobile devices has become a reality. To our knowledge, no prior study systematically investigates the &lt; QoS, Energy &gt; tuple on the end-to-end game streaming pipeline across the cloud, network, and edge devices to understand the individual contributions of the different pipeline stages. In this paper, we present a comprehensive performance and power analysis of the entire game streaming pipeline through extensive measurements with a high-end workstation mimicking the cloud end, an open-source platform (Moonlight-GameStreaming) emulating the edge device/mobile platform, and two network settings (WiFi and 5G). Our study shows that the rendering stage and the encoding stage at the cloud end are the bottlenecks for 4K streaming. While 5G is certainly more suitable for supporting enhanced video quality with 4K streaming, it is more expensive in terms of power consumption compared to WiFi. Further, the network interface and the decoder units in mobile devices need more energy-efficient design to support high quality games at a lower cost. These observations should help in designing more cost-effective future cloud gaming platforms.},
  doi       = {10.1145/3489048.3522650},
  isbn      = {9781450391412},
  keywords  = {performance, energy efficiency, smartphones, 5g, cloud gaming},
  location  = {Mumbai, India},
  numpages  = {2},
  url       = {https://doi.org/10.1145/3489048.3522650},
}

@Article{Bhuyan2022b,
  author     = {Bhuyan, Sandeepa and Zhao, Shulin and Ying, Ziyu and Kandemir, Mahmut T. and Das, Chita R.},
  journal    = {SIGMETRICS Perform. Eval. Rev.},
  title      = {End-to-End Characterization of Game Streaming Applications on Mobile Platforms},
  year       = {2022},
  issn       = {0163-5999},
  month      = {jul},
  number     = {1},
  pages      = {11–12},
  volume     = {50},
  abstract   = {With the advent of 5G, hosting high-quality game streaming applications on mobile devices has become a reality. To our knowledge, no prior study systematically investigates the &lt; QoS, Energy &gt; tuple on the end-to-end game streaming pipeline across the cloud, network, and edge devices to understand the individual contributions of the different pipeline stages. In this paper, we present a comprehensive performance and power analysis of the entire game streaming pipeline through extensive measurements with a high-end workstation mimicking the cloud end, an open-source platform (Moonlight-GameStreaming) emulating the edge device/mobile platform, and two network settings (WiFi and 5G). Our study shows that the rendering stage and the encoding stage at the cloud end are the bottlenecks for 4K streaming. While 5G is certainly more suitable for supporting enhanced video quality with 4K streaming, it is more expensive in terms of power consumption compared to WiFi. Further, the network interface and the decoder units in mobile devices need more energy-efficient design to support high quality games at a lower cost. These observations should help in designing more cost-effective future cloud gaming platforms.},
  address    = {New York, NY, USA},
  doi        = {10.1145/3547353.3522650},
  issue_date = {June 2022},
  keywords   = {cloud gaming, energy efficiency, 5g, performance, smartphones},
  numpages   = {2},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3547353.3522650},
}

@Article{Min2021,
  author     = {Min, Xiongkuo and Gu, Ke and Zhai, Guangtao and Yang, Xiaokang and Zhang, Wenjun and Le Callet, Patrick and Chen, Chang Wen},
  journal    = {ACM Comput. Surv.},
  title      = {Screen Content Quality Assessment: Overview, Benchmark, and Beyond},
  year       = {2021},
  issn       = {0360-0300},
  month      = {oct},
  number     = {9},
  volume     = {54},
  abstract   = {Screen content, which is often computer-generated, has many characteristics distinctly different from conventional camera-captured natural scene content. Such characteristic differences impose major challenges to the corresponding content quality assessment, which plays a critical role to ensure and improve the final user-perceived quality of experience (QoE) in various screen content communication and networking systems. Quality assessment of such screen content has attracted much attention recently, primarily because the screen content grows explosively due to the prevalence of cloud and remote computing applications in recent years, and due to the fact that conventional quality assessment methods can not handle such content effectively. As the most technology-oriented part of QoE modeling, image/video content/media quality assessment has drawn wide attention from researchers, and a large amount of work has been carried out to tackle the problem of screen content quality assessment. This article is intended to provide a systematic and timely review on this emerging research field, including (1) background of natural scene vs. screen content quality assessment; (2) characteristics of natural scene vs. screen content; (3) overview of screen content quality assessment methodologies and measures; (4) relevant benchmarks and comprehensive evaluation of the state-of-the-art; (5) discussions on generalizations from screen content quality assessment to QoE assessment, and other techniques beyond QoE assessment; and (6) unresolved challenges and promising future research directions. Throughout this article, we focus on the differences and similarities between screen content and conventional natural scene content. We expect that this review article shall provide readers with an overview of the background, history, recent progress, and future of the emerging screen content quality assessment research.},
  address    = {New York, NY, USA},
  articleno  = {187},
  doi        = {10.1145/3470970},
  issue_date = {December 2022},
  keywords   = {natural scene, quality of experience, Screen content, quality assessment},
  numpages   = {36},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3470970},
}

@InProceedings{Cesar2023,
  author    = {Cesar, Pablo},
  booktitle = {Proceedings of the 29th Brazilian Symposium on Multimedia and the Web},
  title     = {Towards Volumetric Video Conferencing},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {5},
  publisher = {Association for Computing Machinery},
  series    = {WebMedia '23},
  abstract  = {With Social Extended Reality (XR) emerging as a new medium, where users can remotely experience immersive content with others, the vision of a true feeling of ‘being there together’ has become a realistic goal. This keynote will provide an overview about the challenges to achieve such a goal, based on results from practical case studies like the TRANSMIXR and MediaScape XR projects. We will discuss about different technologies, like point clouds, that can be used as the format for representing highly-realistic digital humans, and about metrics and protocols for quantifying the quality of experience. The final intention of the talk is to shed some light on social XR, as a new group of virtual reality experiences based on social photorealistic immersive content. We will discuss about the challenges regarding production and user-centric processes, and discover the new opportunities open by this new medium},
  doi       = {10.1145/3617023.3617068},
  isbn      = {9798400709081},
  keywords  = {social extended reality, quality of experience, Volumetric video},
  location  = {<conf-loc>, <city>Ribeir\~{a}o Preto</city>, <country>Brazil</country>, </conf-loc>},
  numpages  = {1},
  url       = {https://doi.org/10.1145/3617023.3617068},
}

@InProceedings{Alhilal2022,
  author    = {Alhilal, Ahmad and Braud, Tristan and Han, Bo and Hui, Pan},
  booktitle = {Proceedings of the ACM Web Conference 2022},
  title     = {Nebula: Reliable Low-Latency Video Transmission for Mobile Cloud Gaming},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {3407–3417},
  publisher = {Association for Computing Machinery},
  series    = {WWW '22},
  abstract  = {Mobile cloud gaming enables high-end games on constrained devices by streaming the game content from powerful servers through mobile networks. Mobile networks suffer from highly variable bandwidth, latency, and losses that affect the gaming experience. This paper introduces , an end-to-end cloud gaming framework to minimize the impact of network conditions on the user experience. relies on an end-to-end distortion model adapting the video source rate and the amount of frame-level redundancy based on the measured network conditions. As a result, it minimizes the motion-to-photon (MTP) latency while protecting the frames from losses. We fully implement and evaluate its performance against the state-of-the-art techniques and latest research in real-time mobile cloud gaming transmission on a physical testbed over emulated and real wireless networks. consistently balances MTP latency (&lt;140&nbsp;ms) and visual quality (&gt;31dB) even in highly variable environments. A user experiment confirms that maximizes the user experience with high perceived video quality, playability, and low user load.},
  doi       = {10.1145/3485447.3512276},
  isbn      = {9781450390965},
  keywords  = {Adaptive Rate., Forward Error Correction, Mobile Cloud Gaming},
  location  = {Virtual Event, Lyon, France},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3485447.3512276},
}

@Article{Wien2022,
  author     = {Wien, Mathias},
  journal    = {SIGMultimedia Rec.},
  title      = {MPEG Visual Quality Assessment Advisory Group: Overview and Perspectives},
  year       = {2022},
  month      = {dec},
  number     = {3},
  volume     = {13},
  abstract   = {The perceived visual quality is of utmost importance in the context of visual media compression, such as 2D, 3D, immersive video, and point clouds. The trade-off between compression efficiency and computational/implementation complexity has a crucial impact on the success of a compression scheme. This specifically holds for the development of visual media compression standards which typically aims at maximum compression efficiency using state-of-the-art coding technology. In MPEG, the subjective and objective assessment of visual quality has always been an integral part of the standards development process. Due to the significant effort of formal subjective evaluations, the standardization process typically relies on such formal tests in the starting phase and for verification while in the development phase objective metrics are used. In the new MPEG structure, established in 2020, a dedicated advisory group has been installed for the purpose of providing, maintaining, and developing visual quality assessment methods suitable for use in the standardization process.This column lays out the scope and tasks of this advisory group and reports on its first achievements and developments. After a brief overview of the organizational structure, current projects are presented, and initial results are presented.},
  address    = {New York, NY, USA},
  articleno  = {3},
  doi        = {10.1145/3578495.3578498},
  issue_date = {September 2021},
  numpages   = {1},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3578495.3578498},
}

@InProceedings{Slivar2022,
  author    = {Slivar, Ivan and Bacic, Kresimir and Orsolic, Irena and Skorin-Kapov, Lea and Suznjevic, Mirko},
  booktitle = {Proceedings of the 13th ACM Multimedia Systems Conference},
  title     = {CGD: A Cloud Gaming Dataset with Gameplay Video and Network Recordings},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {272–278},
  publisher = {Association for Computing Machinery},
  series    = {MMSys '22},
  abstract  = {With advances in network capabilities, the gaming industry is increasingly turning towards offering "gaming on demand" solutions, with cloud gaming services such as Sony PlayStation Now, Google Stadia, and NVIDIA GeForce NOW expanding their market offerings. Similar to adaptive video streaming services, cloud gaming services typically adapt the quality of game streams (e.g., bitrate, resolution, frame rate) in accordance with current network conditions. To select the most appropriate video encoding parameters given certain conditions, it is important to understand their impact on Quality of Experience (QoE). On the other hand, network operators are interested in understanding the relationships between parameters measurable in the network and cloud gaming QoE, to be able to invoke QoE-aware network management mechanisms. To encourage developments in these areas, comprehensive datasets are crucial, including both network and application layer data. This paper presents CGD, a dataset consisting of 600 game streaming sessions corresponding to 10 games of different genres being played and streamed using the following encoding parameters: bitrate (5, 10, 20 Mbps), resolution (720p, 1080p), and frame rate (30, 60 fps). For every combination repeated five times for each game, the dataset includes: 1) gameplay video recordings, 2) network traffic traces, 3) user input logs (mouse and keyboard), and 4) streaming performance logs.},
  doi       = {10.1145/3524273.3532898},
  isbn      = {9781450392839},
  keywords  = {network traffic, dataset, cloud gaming, video metrics, gameplay, user input, raw video},
  location  = {Athlone, Ireland},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3524273.3532898},
}

@InProceedings{Wu2023,
  author    = {Wu, Guofang and Dong, Guoliang and Xu, Shuquan},
  booktitle = {Proceedings of the 5th International Conference on Information Technologies and Electrical Engineering},
  title     = {Application of Personnel Safety Management System in Network Security Guarantee},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {714–718},
  publisher = {Association for Computing Machinery},
  series    = {ICITEE '22},
  abstract  = {The rapid development of cloud protection technology provides high-quality security protection barriers for the security of websites deployed on the Internet from a technical level. After the website administrators patch the relevant vulnerabilities in time, the occurrence of network security accidents can be greatly reduced at the technical level. However, cyber attackers take advantage of the negligence of the website's personnel management to launch attacks on the website, resulting in frequent network security incidents such as account theft, web page tampering, website downtime, and core data theft. As a major part of network security management, the formulation and implementation of personnel management systems are crucial to the security of websites. This paper summarizes the experience of network security management and security over the years, puts forward the requirements and methods of personnel management in network security security, and strengthens the management requirements of human factors in the network security system. These measures have played an effective role in network security assurance.},
  doi       = {10.1145/3582935.3583055},
  isbn      = {9781450396806},
  keywords  = {Network security, Permissions, Cloud computer room, Security awareness, Personnel management, Security administrator},
  location  = {Changsha, China},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3582935.3583055},
}

@InProceedings{Zhang2023a,
  author    = {Zhang, Junzhe and Chen, Tong and Ding, Dandan and Ma, Zhan},
  booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
  title     = {G-PCC++: Enhanced Geometry-Based Point Cloud Compression},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {1352–1363},
  publisher = {Association for Computing Machinery},
  series    = {MM '23},
  abstract  = {MPEG Geometry-based Point Cloud Compression (G-PCC) standard is developed for lossy encoding of point clouds to enable immersive services over the Internet. However, lossy G-PCC introduces superimposed distortions from both geometry and attribute information, seriously deteriorating the Quality of Experience (QoE). This paper thus proposes the Enhanced G-PCC (GPCC++), to effectively address the compression distortion and restore the quality. G-PCC++ separates the enhancement into two stages: it first enhances the geometry and then maps the decoded attribute to the enhanced geometry for refinement. As for geometry restoration, a k Nearest Neighbors (kNN)-based Linear Interpolation is first used to generate a denser geometry representation, on top of which GeoNet further generates sufficient candidates to restore geometry through probability-sorted selection. For attribute enhancement, a kNN-based Gaussian Distance Weighted Mapping is devised to re-colorize all points in enhanced geometry tensor, which are then refined by AttNet for the final reconstruction. G-PCC++ is the first solution addressing the geometry and attribute artifacts together. Extensive experiments on several public datasets demonstrate the superiority of G-PCC++, e.g., on the solid point cloud dataset 8iVFB, G-PCC++ outperforms G-PCC by 88.24\% (80.54\%) BD-BR in D1 (D2) measurement of geometry and by 14.64\% (13.09\%) BD-BR in Y (YUV) attribute. Moreover, when considering both geometry and attribute, G-PCC++ also largely surpasses G-PCC by 25.58\% BD-BR using PCQM assessment.},
  doi       = {10.1145/3581783.3613827},
  isbn      = {9798400701085},
  keywords  = {point cloud compression, quality enhancement, compression artifact},
  location  = {<conf-loc>, <city>Ottawa ON</city>, <country>Canada</country>, </conf-loc>},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3581783.3613827},
}

@Article{Zhang2022e,
  author     = {Zhang, Yongle and Asamoah Owusu, Dennis and Carpuat, Marine and Gao, Ge},
  journal    = {Proc. ACM Hum.-Comput. Interact.},
  title      = {Facilitating Global Team Meetings Between Language-Based Subgroups: When and How Can Machine Translation Help?},
  year       = {2022},
  month      = {apr},
  number     = {CSCW1},
  volume     = {6},
  abstract   = {Global teams frequently consist of language-based subgroups who put together complementary information to achieve common goals. Previous research outlines a two-step work communication flow in these teams. There are team meetings using a required common language (i.e., English); in preparation for those meetings, people have subgroup conversations in their native languages. Work communication at team meetings is often less effective than in subgroup conversations. In the current study, we investigate the idea of leveraging machine translation (MT) to facilitate global team meetings. We hypothesize that exchanging subgroup conversation logs before a team meeting offers contextual information that benefits teamwork at the meeting. MT can translate these logs, which enables comprehension at a low cost. To test our hypothesis, we conducted a between-subjects experiment where twenty quartets of participants performed a personnel selection task. Each quartet included two English native speakers (NS) and two non-native speakers (NNS) whose native language was Mandarin. All participants began the task with subgroup conversations in their native languages, then proceeded to team meetings in English. We manipulated the exchange of subgroup conversation logs prior to team meetings: with MT-mediated exchanges versus without. Analysis of participants' subjective experience, task performance, and depth of discussions as reflected through their conversational moves jointly indicates that team meeting quality improved when there were MT-mediated exchanges of subgroup conversation logs as opposed to no exchanges. We conclude with reflections on when and how MT could be applied to enhance global teamwork across a language barrier.},
  address    = {New York, NY, USA},
  articleno  = {90},
  doi        = {10.1145/3512937},
  issue_date = {April 2022},
  keywords   = {global teams, shared context, language choice, machine translation},
  numpages   = {26},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3512937},
}

@InProceedings{Hamadanian2023,
  author    = {Hamadanian, Pouya and Gallatin, Doug and Alizadeh, Mohammad and Chintalapudi, Krishna},
  booktitle = {Proceedings of the ACM SIGCOMM 2023 Conference},
  title     = {Ekho: Synchronizing Cloud Gaming Media across Multiple Endpoints},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {533–549},
  publisher = {Association for Computing Machinery},
  series    = {ACM SIGCOMM '23},
  abstract  = {Online cloud gaming platforms stream game media to multiple end-points (e.g., a television display and a controller-connected headset) via possibly different networks with considerably different latencies. This leads to the media being played out of sync with one another, and severely degrades user experience. Typical approaches that rely on network and software timing measurements fail to reach synchronization goals. In this work, we propose Ekho, a robust and efficient end-to-end approach for synchronizing streams transmitted to two devices. Ekho adds faint, human-inaudible pseudo-noise (PN) markers to the game audio, and listens for these markers in the chat audio captured by the player's microphone to measure inter-stream delay (ISD). The game server then compensates for the ISD to synchronize the streams. We evaluate Ekho in depth, with a corpus of audio samples from popular online games, and demonstrate that it calculates ISD with sub-millisecond accuracy, has low computational overhead, and is resilient to background chatter, compression and microphone quality. In end-to-end tests over WiFi and cellular links with frequent packet loss and playback disruption, Ekho maintains human-imperceptible ISD (&lt; 10 ms) 86.8\% of the time. Without Ekho, the ISD exceeds 50 ms at all times.},
  doi       = {10.1145/3603269.3604826},
  isbn      = {9798400702365},
  keywords  = {cloud gaming, inter-device synchronization, ITU-T P.808, media synchronization},
  location  = {New York, NY, USA},
  numpages  = {17},
  url       = {https://doi.org/10.1145/3603269.3604826},
}

@InProceedings{Zhang2022f,
  author    = {Zhang, Rui-Xiao and Yang, Changpeng and Wang, Xiaochan and Huang, Tianchi and Wu, Chenglei and Liu, Jiangchuan and Sun, Lifeng},
  booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
  title     = {AggCast: Practical Cost-Effective Scheduling for Large-Scale Cloud-Edge Crowdsourced Live Streaming},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {3026–3034},
  publisher = {Association for Computing Machinery},
  series    = {MM '22},
  abstract  = {Conventional wisdom claims that in order to improve viewer engagement, the cloud-edge providers should serve the viewers with the nearest edge nodes, however, we show that doing this for crowdsourced live streaming (CLS) services can introduce significant costs inefficiency. We observe that the massive number of channels has greatly burdened the operating expenditure of the cloud-edge providers, and most importantly, unbalanced viewer distribution makes the edge nodes suffer significant costs inefficiency. To tackle the above concerns, we propose AggCast, a novel CLS scheduling framework to optimize the edge node utilization for the cloud-edge provider. The core idea of AggCast is to aggregate some viewers who are initially scattered on different regions, and assign them to fewer pre-selected nodes, thereby reducing bandwidth costs. In particular, by leveraging the insights obtained from our large-scale measurement, AggCast can not only ensure quality of experience (QoS), but also satisfy the systematic requirements of CLS services. AggCast has been A/B tested and fully deployed in a top cloud-edge provider in China for over eight months. The online and trace-driven experiments show that, compared to the common practice, AggCast can save over 15\% back-to-source (BTS) bandwidth costs while having no negative impacts on QoS.},
  doi       = {10.1145/3503161.3547807},
  isbn      = {9781450392037},
  keywords  = {content delivery, cloud edge computing, live streaming},
  location  = {<conf-loc>, <city>Lisboa</city>, <country>Portugal</country>, </conf-loc>},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3503161.3547807},
}

@InProceedings{Bhore2021,
  author    = {Bhore, Sujoy and Ganian, Robert and Li, Guangping and N\"{o}llenburg, Martin and Wulms, Jules},
  booktitle = {Proceedings of the 29th International Conference on Advances in Geographic Information Systems},
  title     = {Worbel: Aggregating Point Labels into Word Clouds},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {256–267},
  publisher = {Association for Computing Machinery},
  series    = {SIGSPATIAL '21},
  abstract  = {Point feature labeling is a classical problem in cartography and GIS that has been extensively studied for geospatial point data. At the same time, word clouds are a popular visualization tool to show the most important words in text data which has also been extended to visualize geospatial data (Buchin et al. PacificVis 2016).In this paper, we study a hybrid visualization, which combines aspects of word clouds and point labeling. In the considered setting, the input data consists of a set of points grouped into categories and our aim is to place multiple disjoint and axis-aligned rectangles, each representing a category, such that they cover points of (mostly) the same category under some natural quality constraints.In our visualization, we then place category names inside the computed rectangles to produce a labeling of the covered points which summarizes the predominant categories globally (in a word-cloud-like fashion) while locally avoiding excessive misrepresentation of points (i.e., retaining the precision of point labeling).We show that computing a minimum set of such rectangles is NP-hard. Hence, we turn our attention to developing heuristics and exact SAT models to compute our visualizations. We evaluate our algorithms quantitatively, measuring running time and quality of the produced solutions, on several artificial and real-world data sets. Our experiments show that the heuristics produce solutions of comparable quality to the SAT models while running much faster.},
  doi       = {10.1145/3474717.3483959},
  isbn      = {9781450386647},
  keywords  = {labeling, categorical point data, word clouds},
  location  = {Beijing, China},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3474717.3483959},
}

@Article{Bhore2023,
  author     = {Bhore, Sujoy and Ganian, Robert and Li, Guangping and N\"{o}llenburg, Martin and Wulms, Jules},
  journal    = {ACM Trans. Spatial Algorithms Syst.},
  title      = {Worbel: Aggregating Point Labels into Word Clouds},
  year       = {2023},
  issn       = {2374-0353},
  month      = {aug},
  number     = {3},
  volume     = {9},
  abstract   = {Point feature labeling is a classical problem in cartography and GIS that has been extensively studied for geospatial point data. At the same time, word clouds are a popular visualization tool to show the most important words in text data which has also been extended to visualize geospatial data (Buchin et&nbsp;al. PacificVis 2016). In this article, we study a hybrid visualization, which combines aspects of word clouds and point labeling. In the considered setting, the input data consist of a set of points grouped into categories and our aim is to place multiple disjoint and axis-aligned rectangles, each representing a category, such that they cover points of (mostly) the same category under some natural quality constraints. In our visualization, we then place category names inside the computed rectangles to produce a labeling of the covered points which summarizes the predominant categories globally (in a word-cloud-like fashion) while locally avoiding excessive misrepresentation of points (i.e., retaining the precision of point labeling). We show that computing a minimum set of such rectangles is NP-hard. Hence, we turn our attention to developing a heuristic with (optional) exact components using SAT models to compute our visualizations. We evaluate our algorithms quantitatively, measuring running time and quality of the produced solutions, on several synthetic and real-world data sets. Our experiments show that the fully heuristic approach produces solutions of comparable quality to heuristics combined with exact SAT models, while running much faster.},
  address    = {New York, NY, USA},
  articleno  = {19},
  doi        = {10.1145/3603376},
  issue_date = {September 2023},
  keywords   = {word clouds, categorical point data, Labeling},
  numpages   = {32},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3603376},
}

@InProceedings{Lou2022,
  author    = {Lou, Ren and Zhang, Jiacheng and Zhang, Lei and Hong, Qiang and Zhou, Yueqi and Li, Xinghua},
  booktitle = {Proceedings of the 6th International Conference on High Performance Compilation, Computing and Communications},
  title     = {Research on Highway CPS-T of Wide Area Communication and Data Cloud},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {32–37},
  publisher = {Association for Computing Machinery},
  series    = {HP3C '22},
  abstract  = {Cyber physical transportation system (CPS-T) is a traffic perception, control and service system based on algorithm, model, data and computing power. With the help of radar point cloud, video image, GNSS, sensor and other types of monitoring equipment, the highway data can be collected with high quality and transmitted with high reliability under the condition of relatively complete communication conditions. This paper studies the technical application of CPS-T for highways. Through the deployment of communication technology and data cloud platform, it can intelligently perceive and analyze dynamic and static operation data, accurately identify or predict key ramps, bottleneck sections and mainstream traffic channels, and dynamically implement active control strategies such as ramp control, shoulder control, lane control and rate adjustment, so as to realize the advance guidance and control of highway traffic flow. The relevant research has been measured in the highway sections of Shanghai and Zhejiang Province, and the research results have strong engineering reference value.},
  doi       = {10.1145/3546000.3546005},
  isbn      = {9781450396295},
  location  = {Jilin, China},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3546000.3546005},
}

@Article{Tannu2023,
  author     = {Tannu, Swamit and Nair, Prashant J.},
  journal    = {SIGENERGY Energy Inform. Rev.},
  title      = {The Dirty Secret of SSDs: Embodied Carbon},
  year       = {2023},
  month      = {oct},
  number     = {3},
  pages      = {4–9},
  volume     = {3},
  abstract   = {Scalable Solid-State Drives (SSDs) have ushered in a transformative era in data storage and accessibility, spanning both data centers and portable devices. However, the strides made in scaling this technology can bear significant environmental consequences. On a global scale, a notable portion of semiconductor manufacturing relies on electricity derived from coal and natural gas sources. A striking example of this is the manufacturing process for a single Gigabyte of Flash memory, which emits approximately 0.16 Kg of CO2 - a considerable fraction of the total carbon emissions attributed to the system. Remarkably, the manufacturing of storage devices alone contributed to an estimated 20 million metric tonnes of CO2 emissions in the year 2021.In light of these environmental concerns, this paper delves into an analysis of the sustainability trade-offs inherent in Solid-State Drives (SSDs) when compared to traditional Hard Disk Drives (HDDs). Moreover, this study proposes methodologies to gauge the embodied carbon costs associated with storage systems effectively. The research encompasses four key strategies to enhance the sustainability of storage systems.Firstly, the paper offers insightful guidance for selecting the most suitable storage medium, be it SSDs or HDDs, considering the broader ecological impact. Secondly, the paper advocates for implementing techniques that extend the lifespan of SSDs, thereby mitigating premature replacements and their attendant environmental toll. Thirdly, the paper emphasizes the need for efficient recycling and reuse of high-density multi-level cell-based SSDs, underscoring the significance of minimizing electronic waste.Lastly, for handheld devices, the paper underscores the potential of harnessing the elasticity offered by cloud storage solutions as a means to curtail the ecological repercussions of localized data storage. In summation, this study critically addresses the embodied carbon issues associated with SSDs, comparing them with HDDs, and proposes a comprehensive framework of strategies to enhance the sustainability of storage systems.},
  address    = {New York, NY, USA},
  doi        = {10.1145/3630614.3630616},
  issue_date = {October 2023},
  keywords   = {sustainability, solid state drives, embodied carbon, hard disk drive},
  numpages   = {6},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3630614.3630616},
}

@InProceedings{Arora2023,
  author    = {Arora, Rohan and Devi, Umamaheswari and Eilam, Tamar and Goyal, Aanchal and Narayanaswami, Chandra and Parida, Pritish},
  booktitle = {Proceedings of the 2nd Workshop on Sustainable Computer Systems},
  title     = {Towards Carbon Footprint Management in Hybrid Multicloud},
  year      = {2023},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {HotCarbon '23},
  abstract  = {Enterprises today aspire to optimize the operating costs and carbon footprint (CFP) of their IT operations jointly without compromising their business imperatives. This has given rise to a hybrid approach in which enterprises retain the dynamic choice to leverage private data centers and one or more public clouds in conjunction. While cloud service providers (CSPs) have long provided APIs for estimating, reconciling, and optimizing operating costs, they have only recently started exposing APIs related to CFP.Indeed, this is a step in the right direction. Nevertheless, our analyses of these APIs reveals many gaps that need to be addressed to facilitate sizing and placement decisions that can factor in carbon. First, there is a lack of standardized, transparent methodology for CFP quantification across different CSPs. Second, the coarse granularity of the CFP data provided today can help with post-facto reporting but is not suitable for proactive fine-grained optimization. Last, enterprises themselves are unable to independently compute the current CFP or estimate potential CFP savings since CSPs do not share the required power usage data.To address these gaps, enterprises have started developing their own carbon assessment methodologies and tools to estimate the CFP of workloads running on public clouds using the available user-facing APIs. These systems hold the promise for an independent and unbiased evaluation and estimation of relative savings between different deployment options by cloud users. We describe and analyze the details of CSP-native carbon-reporting tools and their quantification methodology, and the "outside-of-the-cloud" estimation approaches. Finally, we present opportunities for future research in the direction of trustworthy, fine-grained, public cloud workload CFP estimation, which is a prerequisite for meaningful realization of carbon optimization.},
  articleno = {9},
  doi       = {10.1145/3604930.3605721},
  isbn      = {9798400702426},
  keywords  = {GHG accounting, data centers, carbon-aware optimization, sustainable computing, GHG emissions, cloud, carbon footprint},
  location  = {Boston, MA, USA},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3604930.3605721},
}

@InProceedings{Zhang2022g,
  author    = {Zhang, Tianze},
  booktitle = {2021 International Conference on Aviation Safety and Information Technology},
  title     = {An Optimal Grasping Point Identification Method Based on Deep Learning and Point Cloud Processing},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {667–671},
  publisher = {Association for Computing Machinery},
  series    = {ICASIT 2021},
  abstract  = {With the development of the field of robotics and the increasingly convenient acquisition of point cloud data, point cloud is widely used in robots to complete many tasks more accurately because of its rich three-dimensional information. In this paper, we propose a method based on PointNet++ combining deep learning and point cloud processing to extract the grasping points of the objects. This method selects YCB dataset. The grasping point pairs in each perspective are sampled by point cloud feature point detection and scored by Force Closure together with Shape of the grasp polygon metrics. The input of PointNet++ is the single-perspective field point cloud after the searching algorithm based on grasping point pairs and the final output classification results are divided into two classes. Experimental results conducted based on Kinect2 and UR5 mechanical arm show that our method can achieve 85\% accuracy in the two-class simulation experiment and 80.32\% average success rate in the real grasping tasks, whose robustness is also verified in this paper.},
  doi       = {10.1145/3510858.3511355},
  isbn      = {9781450390422},
  location  = {Changsha, China},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3510858.3511355},
}

@InProceedings{Yan2023,
  author    = {Yan, Xiaohan and Hsieh, Ken and Liyanage, Yasitha and Ma, Minghua and Chintalapati, Murali and Lin, Qingwei and Dang, Yingnong and Zhang, Dongmei},
  booktitle = {Proceedings of the 45th International Conference on Software Engineering: Software Engineering in Practice},
  title     = {Aegis: Attribution of Control Plane Change Impact across Layers and Components for Cloud Systems},
  year      = {2023},
  address   = {Melbourne, Australia},
  pages     = {222–233},
  publisher = {IEEE Press},
  series    = {ICSE-SEIP '23},
  abstract  = {Modern cloud control plane infrastructure like Microsoft Azure has evolved into a complex one to serve customer needs for diverse types of services and adequate cloud-based resources. On such interconnected system, implementing changes at one component can have an impact on other components, even across different hierarchical computing layers. As a result of the complexity and interconnected nature of the cloud-based services, it poses a challenge to correctly attribute service quality degradation to a control plane change, to infer causality between the two and to mitigate any negative impact. In this paper, we present Aegis, an end-to-end analytical service for attributing control plane change impact across computing layers and service components in large-scale real-world cloud systems. Aegis processes and correlates service health signals and control plane changes across components to construct the most probable causal relationship. Aegis at its core leverages a domain knowledge-driven correlation algorithm to attribute platform signals to changes, and a counterfactual projection model to quantify control plane change impact to customers. Aegis can mitigate the impact of bad changes by alerting service team and recommending pausing the bad ones. Since Aegis' inception in Azure Control Plane 12 months ago, it has caught several bad changes across service components and layers, and promptly paused them to guard the quality of service. Aegis achieves precision and recall around 80\% on real-world control plane deployments.},
  doi       = {10.1109/ICSE-SEIP58684.2023.00026},
  isbn      = {9798350300376},
  keywords  = {regression detection, counterfactual analysis, impact assessment, safe deployment, cloud computing},
  numpages  = {12},
  url       = {https://doi.org/10.1109/ICSE-SEIP58684.2023.00026},
}

@InProceedings{Zhao2023a,
  author    = {Zhao, Xinping and Zhang, Ying and Xiao, Qiang and Ren, Yuming and Yang, Yingchun},
  booktitle = {Companion Proceedings of the ACM Web Conference 2023},
  title     = {Bootstrapping Contrastive Learning Enhanced Music Cold-Start Matching},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {351–355},
  publisher = {Association for Computing Machinery},
  series    = {WWW '23 Companion},
  abstract  = {We study a particular matching task we call Music Cold-Start Matching. In short, given a cold-start song request, we expect to retrieve songs with similar audiences and then fastly push the cold-start song to the audiences of the retrieved songs to warm up it. However, there are hardly any studies done on this task. Therefore, in this paper, we will formalize the problem of Music Cold-Start Matching detailedly and give a scheme. During the offline training, we attempt to learn high-quality song representations based on song content features. But, we find supervision signals typically follow power-law distribution causing skewed representation learning. To address this issue, we propose a novel contrastive learning paradigm named Bootstrapping Contrastive Learning (BCL) to enhance the quality of learned representations by exerting contrastive regularization. During the online serving, to locate the target audiences more accurately, we propose Clustering-based Audience Targeting (CAT) that clusters audience representations to acquire a few cluster centroids and then locate the target audiences by measuring the relevance between the audience representations and the cluster centroids. Extensive experiments on the offline dataset and online system demonstrate the effectiveness and efficiency of our method. Currently, we have deployed it on NetEase Cloud Music, affecting millions of users.},
  doi       = {10.1145/3543873.3584626},
  isbn      = {9781450394192},
  keywords  = {Bootstrapping Contrastive Learning, Clustering-based Audience Targeting, Music Cold-Start Matching},
  location  = {Austin, TX, USA},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3543873.3584626},
}

@InProceedings{Rosendo2023,
  author    = {Rosendo, Daniel and Keahey, Kate and Costan, Alexandru and Simonin, Matthieu and Valduriez, Patrick and Antoniu, Gabriel},
  booktitle = {Proceedings of the 2023 ACM Conference on Reproducibility and Replicability},
  title     = {KheOps: Cost-Effective Repeatability, Reproducibility, and Replicability of Edge-to-Cloud Experiments},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {62–73},
  publisher = {Association for Computing Machinery},
  series    = {ACM REP '23},
  abstract  = {Distributed infrastructures for computation and analytics are now evolving towards an interconnected ecosystem allowing complex scientific workflows to be executed across hybrid systems spanning from IoT Edge devices to Clouds, and sometimes to supercomputers (the Computing Continuum). Understanding the performance trade-offs of large-scale workflows deployed on such complex Edge-to-Cloud Continuum is challenging. To achieve this, one needs to systematically perform experiments, to enable their reproducibility and allow other researchers to replicate the study and the obtained conclusions on different infrastructures. This breaks down to the tedious process of reconciling the numerous experimental requirements and constraints with low-level infrastructure design choices. To address the limitations of the main state-of-the-art approaches for distributed, collaborative experimentation, such as Google Colab, Kaggle, and Code Ocean, we propose KheOps, a collaborative environment specifically designed to enable cost-effective reproducibility and replicability of Edge-to-Cloud experiments. KheOps is composed of three core elements: (1) an experiment repository; (2) a notebook environment; and (3) a multi-platform experiment methodology. We illustrate KheOps with a real-life Edge-to-Cloud application. The evaluations explore the point of view of the authors of an experiment described in an article (who aim to make their experiments reproducible) and the perspective of their readers (who aim to replicate the experiment). The results show how KheOps helps authors to systematically perform repeatable and reproducible experiments on the Grid5000 + FIT IoT LAB testbeds. Furthermore, KheOps helps readers to cost-effectively replicate authors experiments in different infrastructures such as Chameleon Cloud + CHI@Edge testbeds, and obtain the same conclusions with high accuracies (&gt; 88\% for all performance metrics).},
  doi       = {10.1145/3589806.3600032},
  isbn      = {9798400701764},
  keywords  = {Computing Continuum, Reproducibility, Repeatability, Edge Computing, Cloud Computing, Workflows, Replicability},
  location  = {Santa Cruz, CA, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3589806.3600032},
}

@InProceedings{Chang2021,
  author    = {Chang, Hyunseok and Varvello, Matteo and Hao, Fang and Mukherjee, Sarit},
  booktitle = {Proceedings of the 21st ACM Internet Measurement Conference},
  title     = {Can You See Me Now? A Measurement Study of Zoom, Webex, and Meet},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {216–228},
  publisher = {Association for Computing Machinery},
  series    = {IMC '21},
  abstract  = {Since the outbreak of the COVID-19 pandemic, videoconferencing has become the default mode of communication in our daily lives at homes, workplaces and schools, and it is likely to remain an important part of our lives in the post-pandemic world. Despite its significance, there has not been any systematic study characterizing the user-perceived performance of existing videoconferencing systems other than anecdotal reports. In this paper, we present a detailed measurement study that compares three major videoconferencing systems: Zoom, Webex and Google Meet. Our study is based on 48 hours' worth of more than 700 videoconferencing sessions, which were created with a mix of emulated videoconferencing clients deployed in the cloud, as well as real mobile devices running from a residential network. We find that the existing videoconferencing systems vary in terms of geographic scope, which in turns determines streaming lag experienced by users. We also observe that streaming rate can change under different conditions (e.g., number of users in a session, mobile device status, etc), which affects user-perceived streaming quality. Beyond these findings, our measurement methodology can enable reproducible benchmark analysis for any types of comparative or longitudinal study on available videoconferencing systems.},
  doi       = {10.1145/3487552.3487847},
  isbn      = {9781450391290},
  location  = {Virtual Event},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3487552.3487847},
}

@InProceedings{Zhang2023b,
  author    = {Zhang, Wang and Shi, Zhan and Liao, Ziyi and Li, Yiling and Du, Yu and Wu, Yutong and Wang, Fang and Feng, Dan},
  booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  title     = {Graph3PO: A Temporal Graph Data Processing Method for Latency QoS Guarantee in Object Cloud Storage System},
  year      = {2023},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {SC '23},
  abstract  = {Object cloud storage systems are deployed with diverse applications that have varying latency service level objectives (SLOs), posting challenges for supporting quality of service with limited storage resources. Existing methods provide prediction-based recommendations for dispatching requests from applications to storage devices, but the prediction accuracy can be affected by complex system topology. To address this issue, Graph3PO is designed to combine storage device queue information with system topological information for forming a temporal graph, which can accurately predict device queue states. Additionally, Graph3PO contains the urgency degree model and cost model for measuring SLO violation risks and penalties of scheduling requests on storage device queues. When the urgency degree of a request exceeds a threshold, Graph3PO determines whether to schedule it in the queue or initiate a hedge request to another storage device. Experimental results show that Graph3PO outperforms its competitors, with SLO violation rates 2.8 to 201.1 times lower.},
  articleno = {23},
  doi       = {10.1145/3581784.3607075},
  isbn      = {9798400701092},
  keywords  = {latency QoS guarantee, object cloud storage system, temporal graph},
  location  = {<conf-loc>, <city>Denver</city>, <state>CO</state>, <country>USA</country>, </conf-loc>},
  numpages  = {16},
  url       = {https://doi.org/10.1145/3581784.3607075},
}

@Article{Herzog2022,
  author     = {Herzog, Benedict and Reif, Stefan and Hemp, Judith and H\"{o}nig, Timo and Schr\"{o}der-Preikschat, Wolfgang},
  journal    = {ACM Trans. Embed. Comput. Syst.},
  title      = {Resource-Demand Estimation for Edge Tensor Processing Units},
  year       = {2022},
  issn       = {1539-9087},
  month      = {oct},
  number     = {5},
  volume     = {21},
  abstract   = {Machine learning has shown tremendous success in a large variety of applications. The evolution of machine-learning applications from cloud-based systems to mobile and embedded devices has shifted the focus from only quality-related aspects towards the resource demand of machine learning. For embedded systems, dedicated accelerator hardware promises the energy-efficient execution of neural network inferences. Their precise resource demand in terms of execution time and power demand, however, is undocumented. Developers, therefore, face the challenge to fine-tune their neural networks such that their resource demand matches the available budgets. This article presents Precious, a comprehensive approach to estimate the resource demand of an embedded neural network accelerator. We generate randomised neural networks, analyse them statically, execute them on an embedded accelerator while measuring their actual power draw and execution time, and train estimators that map the statically analysed neural network properties to the measured resource demand. In addition, this article provides an in-depth analysis of the neural networks’ resource demands and the responsible network properties. We demonstrate that the estimation error of Precious can be below 1.5\% for both power draw and execution time. Furthermore, we discuss what estimator accuracy is practically achievable and how much effort is required to achieve sufficient accuracy.},
  address    = {New York, NY, USA},
  articleno  = {58},
  doi        = {10.1145/3520132},
  issue_date = {September 2022},
  keywords   = {resource awareness, Neural network accelerator},
  numpages   = {24},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3520132},
}

@Article{Chang2022,
  author     = {Chang, Hyunseok and Varvello, Matteo and Hao, Fang and Mukherjee, Sarit},
  journal    = {IEEE/ACM Trans. Netw.},
  title      = {A Tale of Three Videoconferencing Applications: Zoom, Webex, and Meet},
  year       = {2022},
  issn       = {1063-6692},
  month      = {may},
  number     = {5},
  pages      = {2343–2358},
  volume     = {30},
  abstract   = {Since the outbreak of the COVID-19 pandemic, videoconferencing has become the default mode of communication in our daily lives at homes, workplaces and schools, and it is likely to remain an important part of our lives in the post-pandemic world. Despite its significance, there has not been any systematic study characterizing the user-perceived performance of existing videoconferencing systems other than anecdotal reports. In this paper, we present a detailed measurement study that compares three major videoconferencing systems: Zoom, Webex and Google Meet. Our study is based on 62 hours’ worth of more than 1.1K videoconferencing sessions, which were created with a mix of emulated videoconferencing clients deployed in the cloud, as well as real mobile devices running from a residential network over two separate periods with nine months apart. We find that the existing videoconferencing systems vary in terms of geographic scope and resource provisioning strategies, which in turns determine streaming lag experienced by users. We also observe that streaming rate can change under different conditions (e.g., available bandwidth, number of users in a session, mobile device status), which affects user-perceived streaming quality. Beyond these findings, our measurement methodology enables reproducible benchmark analysis for any types of comparative or longitudinal study on available videoconferencing systems.},
  doi        = {10.1109/TNET.2022.3171467},
  issue_date = {Oct. 2022},
  numpages   = {16},
  publisher  = {IEEE Press},
  url        = {https://doi.org/10.1109/TNET.2022.3171467},
}

@Article{Martin2023,
  author     = {Martin, Noah and Dogar, Fahad},
  journal    = {Proc. ACM Netw.},
  title      = {Divided at the Edge - Measuring Performance and the Digital Divide of Cloud Edge Data Centers},
  year       = {2023},
  month      = {nov},
  number     = {CoNEXT3},
  volume     = {1},
  abstract   = {Cloud providers are highly incentivized to reduce latency. One way they do this is by locating data centers as close to users as possible. These “cloud edge” data centers are placed in metropolitan areas and enable edge computing for residents of these cities. Therefore, which cities are selected to host edge data centers determines who has the fastest access to applications requiring edge compute — creating a digital divide between those closest and furthest from the edge. In this study we measure latency to the current and predicted cloud edge of three major cloud providers around the world. Our measurements use the RIPE Atlas platform targeting cloud regions, AWS Local Zones, and network optimization services that minimize the path to the cloud edge. An analysis of the digital divide shows rising inequality as the relative difference between users closest and farthest from cloud compute increases. We also find this inequality unfairly affects lower income census tracts in the US. This result is extended globally using remotely sensed night time lights as a proxy for wealth. Finally, we demonstrate that low earth orbit satellite internet can help to close this digital divide and provide more fair access to the cloud edge.},
  address    = {New York, NY, USA},
  articleno  = {16},
  doi        = {10.1145/3629138},
  issue_date = {December 2023},
  keywords   = {networks, edge, measurement, digital divide, datacenter},
  numpages   = {23},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3629138},
}

@Article{Maalek2022,
  author     = {Maalek, Reza and Maalek, Shahrokh},
  journal    = {J. Comput. Cult. Herit.},
  title      = {Automatic Recognition and Digital Documentation of Cultural Heritage Hemispherical Domes Using Images},
  year       = {2022},
  issn       = {1556-4673},
  month      = {dec},
  number     = {1},
  volume     = {16},
  abstract   = {Recent advancements in optical metrology have enabled continuous documentation of dense 3-dimensional (3D) point clouds of construction projects, including cultural heritage preservation projects. These point clouds must then be further processed to generate semantic digital models, which is integral to the lifecycle management of heritage sites. For large-scale and continuous digital documentation, processing of dense 3D point clouds is computationally cumbersome, and consequentially requires additional hardware for data management and analysis, increasing the time, cost, and complexity of the project. Fast and reliable solutions for generating the geometric digital models is, hence, eminently desirable. This article presents an original approach to generate reliable semantic digital models of heritage hemispherical domes using only two images. New closed formulations were derived to establish the relationships between a sphere and its projected ellipse onto an image. These formulations were then utilised to create new methods for: (i) selecting the best pair of images from an image network; (ii) detecting ellipses corresponding to projection of spheres in images; (iii) matching of the detected ellipses between images; and (iv) generating the sphere's geometric digital models. The effectiveness of the proposed method was evaluated under both laboratory and real-world datasets. Laboratory experiments revealed that the proposed process using the best pair of images provided results as accurate as that achieved using eight randomly selected images, while improving computation time by a factor of 50. The results of the two real-world datasets showed that the digital model of a hemispherical dome was generated with 6.2 mm accuracy, while improving the total computation time of current best practice by a factor of 7. Real-world experimentation also showed that the proposed method can provide metric-scale definition for photogrammetric point clouds with 3 mm accuracy using spherical targets. The results suggest that the proposed method was successful in automatically generating fast and accurate geometric digital models of hemispherical domes.},
  address    = {New York, NY, USA},
  articleno  = {6},
  doi        = {10.1145/3528412},
  issue_date = {March 2023},
  keywords   = {spherical targets, metric scale definition, hemispherical domes, Sphere detection, sphere projection in images, digital documentation of spheres},
  numpages   = {21},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3528412},
}

@InProceedings{Pham2023,
  author    = {Pham, Stefan and Midoglu, Cise and Seeliger, Robert and Arbanowski, Stefan and Steglich, Stephan},
  booktitle = {Proceedings of the 12th International Symposium on Information and Communication Technology},
  title     = {A Novel Approach to Streaming QoE Score Calculation by Integrating Error Impacts},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {415–421},
  publisher = {Association for Computing Machinery},
  series    = {SOICT '23},
  abstract  = {Video streaming services have become prominent in the last decade. As any other cloud service, these services are error-prone, and the errors during startup and/or playback affect the viewing experience of end-users. Hence, the calculation of Quality-of-Experience (QoE) scores should also account for error impacts. In this paper, we introduce a player-based error classification scheme, which classifies errors based on origin and severity. We use this scheme to quantify the quality degradation due to errors, and propose to improve the QoE score by integrating these quality factors. We instrument the open-source media players dash.js and Exoplayer in our proposed system which follows the guidelines of various multimedia streaming standards. We define several scenarios focusing on different QoE influencing factors, and assess our proposed model’s performance. Comparisons with various state-of-the-art QoE models show that our model captures the effect on user experience better in scenarios induced with player-related errors.},
  doi       = {10.1145/3628797.3628985},
  isbn      = {9798400708916},
  keywords  = {streaming analytics, CMCD, video players, error classification, QoE, SAND},
  location  = {<conf-loc>, <city>Ho Chi Minh</city>, <country>Vietnam</country>, </conf-loc>},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3628797.3628985},
}

@InProceedings{Zhu2023,
  author    = {Zhu, Ligeng and Hu, Lanxiang and Lin, Ji and Chen, Wei-Ming and Wang, Wei-Chen and Gan, Chuang and Han, Song},
  booktitle = {Proceedings of the 56th Annual IEEE/ACM International Symposium on Microarchitecture},
  title     = {PockEngine: Sparse and Efficient Fine-Tuning in a Pocket},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {1381–1394},
  publisher = {Association for Computing Machinery},
  series    = {MICRO '23},
  abstract  = {On-device learning and efficient fine-tuning enable continuous and privacy-preserving customization (e.g., locally fine-tuning large language models on personalized data). However, existing training frameworks are designed for cloud servers with powerful accelerators (e.g., GPUs, TPUs) and lack the optimizations for learning on the edge, which faces challenges of resource limitations and edge hardware diversity. We introduce PockEngine: a tiny, sparse and efficient engine to enable fine-tuning on various edge devices. PockEngine supports sparse backpropagation: it prunes the backward graph and sparsely updates the model with measured memory saving and latency reduction while maintaining the model quality. Secondly, PockEngine is compilation first: the entire training graph (including forward, backward and optimization steps) is derived at compile-time, which reduces the runtime overhead and brings opportunities for graph transformations. PockEngine also integrates a rich set of training graph optimizations, thus can further accelerate the training cost, including operator reordering and backend switching. PockEngine supports diverse applications, frontends and hardware backends: it flexibly compiles and tunes models defined in PyTorch/TensorFlow/Jax and deploys binaries to mobile CPU/GPU/DSPs. We evaluated PockEngine on both vision models and large language models. PockEngine achieves up to 15 \texttimes{} speedup over off-the-shelf TensorFlow (Raspberry Pi), 5.6 \texttimes{} memory saving back-propagation (Jetson AGX Orin). Remarkably, PockEngine enables fine-tuning LLaMav2-7B on NVIDIA Jetson AGX Orin at 550 tokens/s, 7.9 \texttimes{} faster than the PyTorch.},
  doi       = {10.1145/3613424.3614307},
  isbn      = {9798400703294},
  keywords  = {neural network, on-device training, sparse update, efficient finetuning},
  location  = {<conf-loc>, <city>Toronto</city>, <state>ON</state>, <country>Canada</country>, </conf-loc>},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3613424.3614307},
}

@Article{Sangar2023,
  author     = {Sangar, Yaman and Biradavolu, Yoganand and Pederson, Kai and Ranganathan, Vaishnavi and Krishnaswamy, Bhuvana},
  journal    = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
  title      = {PACT: Scalable, Long-Range Communication for Monitoring and Tracking Systems Using Battery-Less Tags},
  year       = {2023},
  month      = {jan},
  number     = {4},
  volume     = {6},
  abstract   = {The food and drug industry is facing the need to monitor the quality and safety of their products. This has made them turn to low-cost solutions that can enable smart sensing and tracking without adding much overhead. One such popular low-power solution is backscatter-based sensing and communication system. While it offers the promise of battery-less tags, it does so at the cost of a reduced communication range. In this work, we propose PACT - a scalable communication system that leverages the knowledge asymmetry in the network to improve the communication range of the tags. Borrowing from the backscatter principles, we design custom PACT Tags that are battery-less but use an active radio to extend the communication range beyond standard passive tags. They operate using the energy harvested from the PACT Source. A wide-band Reader is used to receive multiple Tag responses concurrently and upload them to a cloud server, enabling real-time monitoring and tracking at a longer range. We identify and address the challenges in the practical design of battery-less PACT Tags using an active radio and prototype them using off-the-shelf components. We show experimentally that our Tag consumes only 23μJ energy, which is harvested from an excitation Source that is up to 24 meters away from the Tag. We show that in outdoor deployments, the responses from an estimated 520 Tags can be received by a Reader concurrently while being 400 meters away from the Tags.},
  address    = {New York, NY, USA},
  articleno  = {180},
  doi        = {10.1145/3569471},
  issue_date = {December 2022},
  keywords   = {passive tag, RF harvesting, backscatter, battery-less},
  numpages   = {27},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3569471},
}

@InProceedings{Zhang2021g,
  author    = {Zhang, Xiaoxiao},
  booktitle = {2021 4th International Conference on Information Systems and Computer Aided Education},
  title     = {Design and Implementation of College Physical Education Intelligent Management System Based on Big Data Cloud Platform},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {2958–2963},
  publisher = {Association for Computing Machinery},
  series    = {ICISCAE 2021},
  abstract  = {For the development of information education in Colleges and universities, the Ministry of education has proposed to adopt the teaching method of big data and cloud platform to improve the teaching level, promote the continuous renewal and development of the traditional education model and integrate the advantages and advantages of online teaching. Take the integrated "cloud platform education mode combining online and offline" as the current normal teaching mode. Based on modern high-tech microelectronics technology, intelligent IC card technology, database technology and network technology, this paper develops an intelligent management system of PE. Through practice, PE has been transformed from traditional decentralized management of teachers to systematic management of sports departments, and from simple qualitative management of objectives or processes to comprehensive management, thus avoiding the phenomenon of inconsistent scale and content of teacher management, getting rid of the defects of insufficient quantity and excessive quality, and strengthening the management level and improving the management efficiency in essence.},
  doi       = {10.1145/3482632.3487548},
  isbn      = {9781450390255},
  location  = {Dalian, China},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3482632.3487548},
}

@InProceedings{Zhang2022h,
  author    = {Zhang, Yaqiong and Zeng, Wenming and Li, Guanghui and Wen, Yixiao and Yu, Manjiang and Lu, Zhen and Ruan, Hongli and Li, Yuling},
  booktitle = {Proceedings of the 7th International Conference on Cyber Security and Information Engineering},
  title     = {Design and Development of Precise Mango Irrigation Decision-Making System Based on Lora},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {95–102},
  publisher = {Association for Computing Machinery},
  series    = {ICCSIE '22},
  abstract  = {Aiming at the waste of irrigation water resources caused by inaccurate irrigation in mango orchard, a mango accurate irrigation decision-making system based on Lora is designed and developed to improve the yield and quality of mango. The system forms a wireless transmission and remote control network by wireless soil moisture sensor, Lora data transmission terminal, PLC control center, plc4G gateway, etc. Soil moisture data is wirelessly transmitted to the cloud platform in real time, and then is transmitted to the precision irrigation decision-making system through OPC for analysis, processing and storage. The intelligent remote control of the start-stop operation of valves in the irrigation area is realized through the PLC control center. The experiment on system timeliness and accuracy is carried out in mango orchard. According to experimental results, the absolute error between the temperature and humidity data collected by soil moisture sensor and the standard value was small; the measured temperature and humidity data was more accurate, and the accuracy of the data collected by soil moisture sensor was higher; the irrigation decision-making system started quickly as a whole; the instruction delay was small, and the data reporting was relatively rapid; the system had good overall timeliness and accuracy. It could realize the precise irrigation of mango and achieve the purpose of water saving.},
  doi       = {10.1145/3558819.3558836},
  isbn      = {9781450397414},
  keywords  = {Lora, Precision irrigation, Cloud platform, Mango, Decision-making system},
  location  = {<conf-loc>, <city>Brisbane</city>, <state>QLD</state>, <country>Australia</country>, </conf-loc>},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3558819.3558836},
}

@Article{Wang2022a,
  author     = {Wang, Pengfei and Wang, Zixiong and Xin, Shiqing and Gao, Xifeng and Wang, Wenping and Tu, Changhe},
  journal    = {ACM Trans. Graph.},
  title      = {Restricted Delaunay Triangulation for Explicit Surface Reconstruction},
  year       = {2022},
  issn       = {0730-0301},
  month      = {oct},
  number     = {5},
  volume     = {41},
  abstract   = {The task of explicit surface reconstruction is to generate a surface mesh by interpolating a given point cloud. Explicit surface reconstruction is necessary when the point cloud is required to appear exactly on the surface. However, for a non-perfect input, such as lack of normals, low density, irregular distribution, thin and tiny parts, and high genus, a robust explicit reconstruction method that can generate a high-quality manifold triangulation is missing.We propose a robust explicit surface reconstruction method that starts from an initial simple surface mesh, alternately performs a Filmsticking step and a Sculpting step of the initial mesh, and converges when the surface mesh interpolates all input points (except outliers) and remains stable. The Filmsticking is to minimize the geometric distance between the surface mesh and the point cloud through iteratively performing a restricted Voronoi diagram technique on the surface mesh, whereas the Sculpting is to bootstrap the Filmsticking iteration from local minima by applying appropriate geometric and topological changes of the surface mesh.Our algorithm is fully automatic and produces high-quality surface meshes for non-perfect inputs that are typically considered to be challenging for prior state of the art. We conducted extensive experiments on simulated scans and real scans to validate the effectiveness of our approach.},
  address    = {New York, NY, USA},
  articleno  = {180},
  doi        = {10.1145/3533768},
  issue_date = {October 2022},
  keywords   = {watertight manifold, Surface reconstruction, winding number, restricted Voronoi diagram},
  numpages   = {20},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3533768},
}

@InProceedings{Wang2023c,
  author    = {Wang, Ziwei and Sun, Wei and Tian, Linyang},
  booktitle = {Proceedings of the 2022 5th International Conference on Artificial Intelligence and Pattern Recognition},
  title     = {3D Point Cloud Denoising Based on Hybrid Attention Mechanism and Score Matching},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {767–772},
  publisher = {Association for Computing Machinery},
  series    = {AIPR '22},
  abstract  = {Due to the limitations of the acquisition equipment, sensors, and the illumination or reflection characteristics of the ground, the acquired point clouds will inevitably be noisy. Noise degrades the quality of point clouds and hinders the subsequent point cloud processing tasks, so the denoising technique becomes a crucial step in point cloud processing. This paper proposes a point cloud denoising algorithm based on a hybrid attention mechanism, which takes into account the complexity of the internal features of point clouds and the randomness of point cloud transformations. Generates channel and spatial attention by parallel maximum pooling and average pooling of point cloud data, trains adaptive attention weights using a multilayer perceptron with shared weights, and serially fuses them, multiplies them with the input features to obtain more robust point cloud features, and connect to the score estimation module using the residuals. By studying and analyzing the mechanism proposed in this paper, it is experimentally demonstrated that the performance of the proposed model under various noise models is vastly improved over the baseline network and outperforms the advanced denoising methods without significantly increasing the network operation cost.},
  doi       = {10.1145/3573942.3574093},
  isbn      = {9781450396899},
  keywords  = {Point cloud, Hybrid attention module, Denoising, Filtering},
  location  = {Xiamen, China},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3573942.3574093},
}

@Article{Ulvi2022,
  author     = {Ulvi, Ali},
  journal    = {J. Comput. Cult. Herit.},
  title      = {Using UAV Photogrammetric Technique for Monitoring, Change Detection, and Analysis of Archeological Excavation Sites},
  year       = {2022},
  issn       = {1556-4673},
  month      = {sep},
  number     = {3},
  volume     = {15},
  abstract   = {The shrinkage of the sensors installed in unmanned aerial vehicles and the increase in data quality have provided great advantages to UAV users, especially in analysis and interpretation works. Archaeologists, in particular, can take full advantage of new opportunities to research and identify objects and artifacts, using remote sensing methods, by studying the past at excavation sites using modern technologies such as UAVs. These methods enable researchers to discover objects on the ground with the help of sensors. This study includes the UAV monitoring, documentation, and analyses of the excavation works that took place in 2014 (phase 1), 2017 (phase 2- phase 3), and 2020 (phase 4) at the Ancient Theatre of Uzuncabur\c{c} built in the Roman Empire. For this purpose, photos were taken with the UAV for each phase, and measurements were made from the excavation site's points with precision gauges (total-station and GNSS). 3D point cloud, orthophoto map, Digital Elevation Model (DEM) map, and 3D models of each phase were produced with the taken pictures. Since UAV photogrammetry was used in this study, each excavation phase was recorded precisely. This, unlike classical documentation techniques, enabled the deformations in the excavation areas to be revealed. The 3D position accuracy calculated for the control point (ChP) used in the four excavation phases ranges from 5.8 mm to 33.5 mm. The most important feature of this study is the sensitive examination of the changes in the excavation area for many years with the UAV photogrammetry technique. At the end of the study, the excavation phases and the determination of the deformation points in the excavation area were recorded digitally.},
  address    = {New York, NY, USA},
  articleno  = {58},
  doi        = {10.1145/3522742},
  issue_date = {September 2022},
  keywords   = {monitoring, excavation analyze, archeological excavation, UAV photogrammetry, Word},
  numpages   = {19},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3522742},
}

@InProceedings{Ning2022,
  author    = {Ning, YeYan and Wang, ChunLei and Zhang, ZhenYu and Li, YunJi},
  booktitle = {Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering},
  title     = {Precise Point Cloud Segmentation Method Based on Distance Judgment Function},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {895–900},
  publisher = {Association for Computing Machinery},
  series    = {EITCE '21},
  abstract  = {Effective segmentation of point cloud data is an important step in point cloud processing, and it is also a popular research direction in 3D point cloud processing. Traditional region growing algorithms are simple and easy to implement, and are widely used in 3D point cloud segmentation. However, the disorder and complexity of point cloud data and the uncertainty of initial seed node selection lead to over-segmentation and under-segmentation. This paper proposes a region growing algorithm based on distance judgment function calculation. First, we use the octree method to establish the topological relationship of the point cloud data, and construct local k neighborhoods, and eliminate outliers based on its density information; second, we perform k neighborhood search on the data points to obtain the covariance matrix of the neighborhood points, and use principal component analysis to calculate the eigenvalues and eigenvectors of the matrix; we use the minimum spanning tree method to compare the vector dot product, adjust the direction of the normal vector, and ensure the global consistency of the point cloud data; through the average curvature and Gaussian curvature Combined with calculation, the minimum curvature point is selected as the initial seed node, which improves the stability of seed node selection and avoids repeated segmentation; introduces a distance judgment function to judge the attributes of the seed point, calculates the normal distance from the selected seed point to its tangent plane, and passes the distance Threshold divides the point cloud data into flat points and sharp points to improve the efficiency of point cloud adjustment; filter the neighboring points according to the angle between the normal of the seed point and the normal of the neighboring point; finally set the curvature threshold reasonably and determine Guidelines for regional growth. According to the experimental results of segmentation, the region growing algorithm based on the distance judgment function improves the accuracy and stability of part segmentation, and improves the quality of segmentation.},
  doi       = {10.1145/3501409.3501571},
  isbn      = {9781450384322},
  keywords  = {Distance judgment function, Region growth, Principal component analysis, Three-dimensional point cloud},
  location  = {Xiamen, China},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3501409.3501571},
}

@Article{Wu2022,
  author     = {Wu, Chao and Horiuchi, Shingo and Murase, Kenji and Kikushima, Hiroaki and Tayama, Kenichi},
  journal    = {ACM Trans. Internet Technol.},
  title      = {An Intent-Driven DaaS Management Framework to Enhance User Quality of Experience},
  year       = {2022},
  issn       = {1533-5399},
  month      = {nov},
  number     = {4},
  volume     = {22},
  abstract   = {Desktop as a Service (DaaS) has become widely used by enterprises. In 2020, the use of DaaS increased dramatically due to the demand to work remotely from home during the COVID-19 pandemic. The DaaS market is expected to continue growing rapidly [1]. The quality of experience (QoE) of a DaaS service has been one of the main factors to enhance DaaS user satisfaction. To ensure user QoE, the amount of cloud computation resources for a DaaS service must be appropriately designed. We propose an Intent-driven DaaS Management (IDM) framework to autonomously determine the cloud-resource-amount configurations for a given DaaS QoE requirement. IDM enables autonomous resource design by abstracting the knowledge about the dependency between DaaS workload, resource configuration, and performance from previous DaaS performance log data. To ensure the IDM framework's applicability to actual DaaS services, we analyzed five main challenges in applying the IDM framework to actual DaaS services: identifying the resource-design objective, quantifying DaaS QoE, addressing low log data availability, designing performance-inference models, and addressing low resource variations in the log data. We addressed these challenges through detailed designing of IDM modules. The effectiveness of the IDM framework was assessed from the aspects of DaaS performance-inference precision, DaaS resource design, and time and human-resource cost reduction.},
  address    = {New York, NY, USA},
  articleno  = {98},
  doi        = {10.1145/3488586},
  issue_date = {November 2022},
  keywords   = {DaaS, intent-driven management, cloud resource design},
  numpages   = {25},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3488586},
}

@InProceedings{Feng2022,
  author    = {Feng, K. J. Kevin and Gao, Alice and Karras, Johanna Suvi},
  booktitle = {Adjunct Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology},
  title     = {Towards Semantically Aware Word Cloud Shape Generation},
  year      = {2022},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {UIST '22 Adjunct},
  abstract  = {Word clouds are a data visualization technique that showcases a subset of words from a body of text in a cluster form, where a word’s font size encodes some measure of its relative importance—typically frequency—in the text. This technique is primarily used to help viewers glean the most pertinent information from long text documents and to compare and contrast different pieces of text. Despite their popularity, previous research has shown that word cloud designs are often not optimally suited for analytical tasks such as summarization or topic understanding. We propose a solution for generating more effective visualization technique that shapes the word cloud to reflect the key topic(s) of the text. Our method automates the processes of manual image selection and masking required from current word cloud tools to generate shaped word clouds, better allowing for quick summarization. We showcase two approaches using classical and state-of-the-art methods. Upon successfully generating semantically shaped word clouds using both methods, we performed preliminary evaluations with 5 participants. We found that although most participants preferred shaped word clouds over regular ones, the shape can be distracting and detrimental to information extraction if it is not directly relevant to the text or contains graphical imperfections. Our work has implications on future semantically-aware word cloud generation tools as well as efforts to balance visual appeal of word clouds with their effectiveness in textual comprehension.},
  articleno = {35},
  doi       = {10.1145/3526114.3558724},
  isbn      = {9781450393218},
  keywords  = {Text visualization, word clouds, multimodal computer vision},
  location  = {Bend, OR, USA},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3526114.3558724},
}

@InProceedings{Cheng2021,
  author    = {Cheng, Weiku},
  booktitle = {2021 4th International Conference on Information Systems and Computer Aided Education},
  title     = {Research on the Value Core and Practice Path Selection of Curriculum Ideology Based on Education Cloud Platform},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {65–69},
  publisher = {Association for Computing Machinery},
  series    = {ICISCAE 2021},
  abstract  = {The progress of science and technology and the development of computer technology have led us into the information age, and information education has become an inevitable trend in the development of Chinese education. "Curriculum ideology" points to a new concept of ideology, which is an inevitable choice for higher education to realize the whole process and all-round education. The reform of higher vocational curriculum ideology is based on moral education, with the goal of realizing students' all-round growth, emphasizing the organic combination of moral education and intellectual education in the process of education, which is an important measure to solve the "isolated island" dilemma of higher vocational curriculum ideology, build a "great ideology" collaborative education pattern, and train socialist successors who are responsible for national rejuvenation. The emergence of educational cloud platform provides a direction for the reform of the teaching mode of "ideology", and the integration of educational resources is realized by using educational cloud platform to carry out online teaching of "ideology". This paper analyzes the core essence and internal mechanism of "Curriculum ideology" based on educational cloud platform, and puts forward the practical path of synergy effect of curriculum ideology.},
  doi       = {10.1145/3482632.3482646},
  isbn      = {9781450390255},
  location  = {Dalian, China},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3482632.3482646},
}

@InProceedings{Reznik2023,
  author    = {Reznik, Yuriy and Barman, Nabajeet and Wagstrom, Patrick},
  booktitle = {Proceedings of the 2nd Mile-High Video Conference},
  title     = {Improving the Performance of Web-Streaming by Super-Resolution Upscaling},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {8–13},
  publisher = {Association for Computing Machinery},
  series    = {MHV '23},
  abstract  = {In recent years, we have seen significant progress in advanced image and video upscaling techniques, sometimes called super-resolution, or AI-based upscaling. Such algorithms are now broadly available in the forms of software SDKs, as well as functions natively supported by modern graphics cards. However, to take advantage of such technologies in video streaming applications, one needs to (a) add support for super-resolution upscaling in the video rendering chain, (b) develop means for quantifying the effects of using different upscaling techniques on perceived quality, and c) modify streaming clients to use such more advanced scaling techniques in a way that leads to improvements in quality, efficiency, or both.In this paper, we discuss several techniques addressing these challenges. We first present an overview of super-resolution technology. We review available SDKs and libraries for adding super-resolution functionality in streaming players. We next propose a parametric quality model suitable for modeling the effects of different upscaling techniques. We validate it by using an existing widely used dataset with subjective scores. And finally, we present an improved adaptation logic for streaming clients, allowing them to save bandwidth while maintaining quality at the level achievable by standard scaling techniques. Our experiments show that this logic can reduce streaming bitrates by up to 38.9\%.},
  doi       = {10.1145/3588444.3590997},
  isbn      = {9798400701603},
  keywords  = {quality enhancement, super-resolution, video streaming, machine learning, deep learning, upsampling, adaptive streaming},
  location  = {Denver, CO, USA},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3588444.3590997},
}

@InProceedings{Christofidi2023,
  author    = {Christofidi, Georgia and Papaioannou, Konstantinos and Doudali, Thaleia Dimitra},
  booktitle = {Proceedings of the 3rd Workshop on Machine Learning and Systems},
  title     = {Toward Pattern-Based Model Selection for Cloud Resource Forecasting},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {115–122},
  publisher = {Association for Computing Machinery},
  series    = {EuroMLSys '23},
  abstract  = {Cloud resource management solutions, such as autoscaling and overcommitment policies, often leverage robust prediction models to forecast future resource utilization at the task-, job- and machine-level. Such solutions maintain a collection of different models and at decision time select to use the model that provides the best performance, typically minimizing a cost function. In this paper, we explore a more generalizable model selection approach, based on the patterns of resource usage that are common across the tasks of a job. To learn such patterns, we train a collection of Long Short Term Memory (LSTM) neural networks, at the granularity of a job. During inference, we select which model to use to predict the resource usage of a given task via distance-based time series comparisons. Our experimentation with various time series data representations and similarity metrics reveals cases where even sophisticated approaches, such as dynamic time warping, lead to suboptimal model selection and as a result significantly lower prediction accuracy. Our analysis establishes the importance and impact of pattern-based model selection, and discusses relevant challenges, opportunities and future directions based on our findings.},
  doi       = {10.1145/3578356.3592588},
  isbn      = {9798400700842},
  keywords  = {deep neural network, cloud resource forecasting, long short term memory, cloud computing, timeseries comparison, pattern matching, machine learning},
  location  = {Rome, Italy},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3578356.3592588},
}

@Article{Loureiro2022,
  author     = {Loureiro, J. and Cec\'{\i}lio, J.},
  journal    = {Ada Lett.},
  title      = {Deep Learning for Reliable Communication Optimization on Autonomous Vehicles},
  year       = {2022},
  issn       = {1094-3641},
  month      = {dec},
  number     = {1},
  pages      = {90–94},
  volume     = {42},
  abstract   = {Recent breakthroughs in the autonomous vehicle industry have brought this technology closer to consumers. However, the cost of self-driving solutions still constitutes an entry barrier to many potential users due to its reliance on powerful onboard computers. As an alternative, autonomous driving algorithm processing may be offloaded to remote machines, which requires a reliable connection to the cloud servers. However, despite significant 5G coverage in many countries, mobile network reliability and latency are still inadequate for this purpose. This work explores deep learning concepts to forecast signal quality as a vehicle moves, predicting when periods of degraded network quality will occur. We develop a Long Short-Term Memory (LSTM)-based neural network, trained on multivariate time series containing historical data on several mobile network parameters, and evaluate the results of multi-step Reference Signal Received Power (RSRP) prediction. Results show that our model achieves a rapidly increasing Root-Mean-Square Error (RMSE), reaching over 8 dBm after 25-time steps. This error does not allow for the accurate prediction of future signal quality.},
  address    = {New York, NY, USA},
  doi        = {10.1145/3577949.3577967},
  issue_date = {June 2022},
  keywords   = {deep learning, signal quality, autonomous vehicle, forecasting},
  numpages   = {5},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3577949.3577967},
}

@InProceedings{Pasupuleti2022,
  author    = {Pasupuleti, Krishna Kantikiran and Das, Dinesh and Valluri, Satyanarayana R and Zait, Mohamed},
  booktitle = {Proceedings of the 31st ACM International Conference on Information \&amp; Knowledge Management},
  title     = {Observability of SQL Hints in Oracle},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {3441–3450},
  publisher = {Association for Computing Machinery},
  series    = {CIKM '22},
  abstract  = {Observability is a critical requirement of increasingly complex and cloud-first data management systems. In most commercial databases, this relies on telemetry like logs, traces, and metrics, which helps to identify, mitigate, and resolve issues expeditiously. SQL monitoring tools, for example, can show how a query is performing. One area that has received comparatively less attention is the observability of the query optimizer whose inner workings are often shrouded in mystery. Optimizer traces can illuminate the plan selection process for a query, but they are comprehensible only to human experts and are not easily machine-parsable to remediate sub-optimal plans. Hints are directives that guide the optimizer toward specific directions. While hints can be used manually, they are often used by automatic SQL plan management tools that can quickly identify and resolve regressions by selecting alternate plans. It is important to know when input hints are inapplicable so that the tools can try other strategies. For example, a manual hint may have syntax errors, or an index in an automatic hint may have been accidentally dropped. In this paper, we describe the design and implementation of Oracle's hint observability framework which provides a comprehensive usage report of all hints, manual or otherwise, used to compile a query. The report, which is available directly in the execution plan in a human-understandable and machine-readable format, can be used to automate any necessary corrective actions. This feature is available in Oracle Autonomous Database 19c.},
  doi       = {10.1145/3511808.3557124},
  isbn      = {9781450392365},
  keywords  = {SQL plan management, SQL hints, autonomous database administration, observability, query optimization},
  location  = {Atlanta, GA, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3511808.3557124},
}

@Article{Xu2022a,
  author     = {Xu, Rui and Wang, Zixiong and Dou, Zhiyang and Zong, Chen and Xin, Shiqing and Jiang, Mingyan and Ju, Tao and Tu, Changhe},
  journal    = {ACM Trans. Graph.},
  title      = {RFEPS: Reconstructing Feature-Line Equipped Polygonal Surface},
  year       = {2022},
  issn       = {0730-0301},
  month      = {nov},
  number     = {6},
  volume     = {41},
  abstract   = {Feature lines are important geometric cues in characterizing the structure of a CAD model. Despite great progress in both explicit reconstruction and implicit reconstruction, it remains a challenging task to reconstruct a polygonal surface equipped with feature lines, especially when the input point cloud is noisy and lacks faithful normal vectors. In this paper, we develop a multistage algorithm, named RFEPS, to address this challenge. The key steps include (1) denoising the point cloud based on the assumption of local planarity, (2) identifying the feature-line zone by optimization of discrete optimal transport, (3) augmenting the point set so that sufficiently many additional points are generated on potential geometry edges, and (4) generating a polygonal surface that interpolates the augmented point set based on restricted power diagram. We demonstrate through extensive experiments that RFEPS, benefiting from the edge-point augmentation and the feature preserving explicit reconstruction, outperforms state of the art methods in terms of the reconstruction quality, especially in terms of the ability to reconstruct missing feature lines.},
  address    = {New York, NY, USA},
  articleno  = {228},
  doi        = {10.1145/3550454.3555443},
  issue_date = {December 2022},
  keywords   = {feature line, point cloud, restricted power diagram, computer-aided design, surface reconstruction},
  numpages   = {15},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3550454.3555443},
}

@InProceedings{Tang2023,
  author    = {Tang, Sheng-Ming and Sun, Yuan-Chun and Hsu, Cheng-Hsin},
  booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
  title     = {A Blind Streaming System for Multi-Client Online 6-DoF View Touring},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {9124–9133},
  publisher = {Association for Computing Machinery},
  series    = {MM '23},
  abstract  = {Online 6-DoF view touring has become increasingly popular due to hardware advances and the recent pandemic. One way for content creators to support many 6-DoF clients is by transmitting 3D content to them, which leads to content leakage. Another way for content creators is to render and stream novel views for 6-DoF clients, which incurs staggering computational and networking workloads. In this paper, we develop a blind streaming system that leverages cloud service providers between content creators and 6-DoF clients. Our system has two core design objectives: (i) to generate high-quality novel views for 6-DoF clients without retrieving 3D content from content creators, (ii) to support many 6-DoF clients without overloading the content creators. We achieve these two goals in the following steps. First, we design a source view request/response interface between cloud service providers and content creators for efficient communications. Second, we design novel view optimization algorithms for cloud service providers to intelligently select the minimal set of source views while considering the workload of content creators. Third, we employ scalable client side view synthesis for 6-DoF clients with heterogeneous device capabilities and personalized 6-DoF client poses and preferences. Our evaluation results demonstrate the merits of our solution, compared to the state-of-the-arts, our system: (i) improves synthesized novel views by 2.27 dB in PSNR and 12 in VMAF on average and (ii) reduces the bandwidth consumption by 94\% on average. In fact, our solution approaches the performance of an unrealistic optimal solution with unlimited source views, achieving performance gaps as small as 0.75 dB in PSNR and 3.8 in VMAF.},
  doi       = {10.1145/3581783.3612257},
  isbn      = {9798400701085},
  keywords  = {system design, discrete optimization, content privacy, computer graphics, view synthesis},
  location  = {<conf-loc>, <city>Ottawa ON</city>, <country>Canada</country>, </conf-loc>},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3581783.3612257},
}

@InProceedings{Hadar2022,
  author    = {Hadar, Ravid and Schapira, Michael},
  booktitle = {Proceedings of the 1st Mile-High Video Conference},
  title     = {Network Congestion Control and Its Impact on Video Streaming QoE},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {111},
  publisher = {Association for Computing Machinery},
  series    = {MHV '22},
  abstract  = {Congestion control plays a crucial role in Internet-based content delivery. Congestion control brings order to the Internet's crowded traffic system by sharing the scarce network bandwidth between competing services and users. Congestion control algorithms continuously modulate the rate at which data packets are injected into the network by traffic sources in response to network conditions.Congestion control immensely impacts quality of experience (QoE) for services like video streaming, video conferencing, and cloud gaming; sending packets too slowly prevents supporting high video quality (HD/UHD); sending too fast can overwhelm the network, resulting in data being lost or delayed, leading to phenomena such as video rebuffering.While congestion control has been a key focus for both academic and industrial research for decades, the exact correlation between the performance of the congestion control algorithms employed by video servers and the QoE experienced by video clients remains poorly understood. We will report on our experimental results along these lines.We evaluated and contrasted three dominant congestion control schemes: TCP Cubic [3], which is the default for many operating systems, and two recently proposed congestion control schemes, namely, Google's Bottleneck-Bandwidth-and-RTT (BBR) [1] protocol, and Performance-oriented Congestion Control (PCC) [2].Our experimental setup consisted of a video cache that sends http-based video traffic across an emulated network environment towards a video client. We took into consideration both MPEG-DASH and HLS-based video streaming and both wired and wireless networks. We ran multiple experiments for varying network conditions (e.g., the available bandwidth, non-congestion-related packet loss, network latency, and depth of in-network buffers, etc.).By monitoring the behavior of the congestion controller and examining the QoE data from the video player (e.g., video start-time, average bitrate, rebuffering ratio, etc.), we have been able to draw meaningful conclusions. Specifically, our results shed light on the features of network-level performance that most impact user-perceived QoE, quantify the benefits for performance of employing modern congestion control protocols, and provide insights into the interplay between congestion control, the network environment, and the video player.Below is a diagram describing the experiment setup:},
  doi       = {10.1145/3510450.3517285},
  isbn      = {9781450392228},
  keywords  = {quality of experience, online learning, congestion control, transport protocols, QoE, video streaming},
  location  = {Denver, Colorado},
  numpages  = {1},
  url       = {https://doi.org/10.1145/3510450.3517285},
}

@InProceedings{Gregoriadis2022,
  author    = {Gregoriadis, Marcel and Muth, Robert and Florian, Martin},
  booktitle = {Companion Proceedings of the Web Conference 2022},
  title     = {Analysis of Arbitrary Content on Blockchain-Based Systems Using BigQuery},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {478–487},
  publisher = {Association for Computing Machinery},
  series    = {WWW '22},
  abstract  = {Blockchain-based systems have gained immense popularity as enablers of independent asset transfers and smart contract functionality. They have also, since as early as the first Bitcoin blocks, been used for storing arbitrary contents such as texts and images. On-chain data storage functionality is useful for a variety of legitimate use cases. It does, however, also pose a systematic risk. If abused, for example by posting illegal contents on a public blockchain, data storage functionality can lead to legal consequences for operators and users that need to store and distribute the blockchain, thereby threatening the operational availability of entire blockchain ecosystems. In this paper, we develop and apply a cloud-based approach for quickly discovering and classifying content on public blockchains. Our method can be adapted to different blockchain systems and offers insights into content-related usage patterns and potential cases of abuse. We apply our method on the two most prominent public blockchain systems—Bitcoin and Ethereum—and discuss our results. To the best of our knowledge, the presented study is the first to systematically analyze non-financial content stored on the Ethereum blockchain and the first to present a side-by-side comparison between different blockchains in terms of the quality and quantity of stored data.},
  doi       = {10.1145/3487553.3524628},
  isbn      = {9781450391306},
  keywords  = {Cryptocurrency, BigQuery, Blockchain, Ethereum, Bitcoin},
  location  = {Virtual Event, Lyon, France},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3487553.3524628},
}

@InProceedings{Zhang2023c,
  author    = {Zhang, Songli and Zheng, Zhenzhe and Wu, Fan and Li, Bingshuai and Shao, Yunfeng and Chen, Guihai},
  booktitle = {Proceedings of the 52nd International Conference on Parallel Processing},
  title     = {Learning From Your Neighbours: Mobility-Driven Device-Edge-Cloud Federated Learning},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {462–471},
  publisher = {Association for Computing Machinery},
  series    = {ICPP '23},
  abstract  = {Federated learning (FL) in large-scale wireless networks is implemented in a hierarchical way by introducing edge servers as relays between the cloud server and devices, where devices are dispersed within multiple clusters coordinated by edges. However, the devices are usually mobile users with unpredictable mobile trajectories, whose effects on the model training process are still less studied. In this work, we propose a new MobIlity-Driven feDerated LEarning framework, namely MIDDLE in wireless networks, which can relieve unbalanced and biased model updates by leveraging the new model aggregation opportunities on mobile devices due to their mobility across edges. Specifically, mobile devices can have different models while traversing across edges, and adequately aggregate these models on the device. By theoretical analysis, we can show that this on-device model aggregation can reduce the bias of model updating on edges and cloud, and then accelerate the convergence of model training in FL. Then, we define a model similarity utility to measure the difference in gradient updates among various models, which guides the adaptive on-device model aggregation and in-edge device selection to facilitate the comprehensive information sharing between edges. Extensive experiment results validate that MIDDLE can achieve 1.51 \texttimes{} −6.85 \texttimes{} speedup on the model training, compared with the state-of-the-art model training approaches in hierarchical FL.},
  doi       = {10.1145/3605573.3605643},
  isbn      = {9798400708435},
  keywords  = {Device Mobility., Device-Edge-Cloud Cooperation, Federated Learning},
  location  = {<conf-loc>, <city>Salt Lake City</city>, <state>UT</state>, <country>USA</country>, </conf-loc>},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3605573.3605643},
}

@Article{Kopanas2022,
  author     = {Kopanas, Georgios and Leimk\"{u}hler, Thomas and Rainer, Gilles and Jambon, Cl\'{e}ment and Drettakis, George},
  journal    = {ACM Trans. Graph.},
  title      = {Neural Point Catacaustics for Novel-View Synthesis of Reflections},
  year       = {2022},
  issn       = {0730-0301},
  month      = {nov},
  number     = {6},
  volume     = {41},
  abstract   = {View-dependent effects such as reflections pose a substantial challenge for image-based and neural rendering algorithms. Above all, curved reflectors are particularly hard, as they lead to highly non-linear reflection flows as the camera moves. We introduce a new point-based representation to compute Neural Point Catacaustics allowing novel-view synthesis of scenes with curved reflectors, from a set of casually-captured input photos. At the core of our method is a neural warp field that models catacaustic trajectories of reflections, so complex specular effects can be rendered using efficient point splatting in conjunction with a neural renderer. One of our key contributions is the explicit representation of reflections with a reflection point cloud which is displaced by the neural warp field, and a primary point cloud which is optimized to represent the rest of the scene. After a short manual annotation step, our approach allows interactive high-quality renderings of novel views with accurate reflection flow. Additionally, the explicit representation of reflection flow supports several forms of scene manipulation in captured scenes, such as reflection editing, cloning of specular objects, reflection tracking across views, and comfortable stereo viewing. We provide the source code and other supplemental material on https://repo-sam.inria.fr/fungraph/neural_catacaustics/},
  address    = {New York, NY, USA},
  articleno  = {201},
  doi        = {10.1145/3550454.3555497},
  issue_date = {December 2022},
  keywords   = {neural rendering, catacaustics, point-based rendering, differentiable rasterization, reflections},
  numpages   = {15},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3550454.3555497},
}

@Article{Ma2021a,
  author     = {Ma, Richard T. B.},
  journal    = {IEEE/ACM Trans. Netw.},
  title      = {Internet Transport Economics: Model and Analysis},
  year       = {2021},
  issn       = {1063-6692},
  month      = {dec},
  number     = {6},
  pages      = {2843–2854},
  volume     = {29},
  abstract   = {With the rise of video streaming and cloud services, the Internet has evolved into a content-centric service platform. Due to the best-effort service model of the Internet, the quality of service (QoS) of Internet services however cannot be guaranteed. Furthermore, characterizing QoS is challenging since it depends on the autonomous business decisions such as capacity planning, routing strategies and peering agreements of network providers. To quantify the QoS for Internet-based services, we regard the Internet infrastructure as a transport system for data packets and study the Internet ecosystem and the economics of transport services collectively provided by the autonomous network providers. In contrast to the traditional transport economics that studies the movement of people and goods over space and time, our focus in the &lt;italic&gt;Internet transport economics&lt;/italic&gt; is the movement of streams of data packets that create information services. In particular, we model the supply of network capacities and demands of throughput driven by network protocols and establish a macroscopic network equilibrium under which both the end-to-end delays and drop rates of Internet routes can be derived. We show that this equilibrium solution always exists and its uniqueness can be guaranteed under various realistic scenarios. We analyze the impacts of user demands and resource capacities on the network equilibrium and provide implications of Netflix-Comcast type of peering on the QoS of users. We demonstrate that our framework can be used as a building block to understand the routing strategies under a Wardrop equilibrium and to enable further studies such as Internet peering and in-network caching.},
  doi        = {10.1109/TNET.2021.3103796},
  issue_date = {Dec. 2021},
  numpages   = {12},
  publisher  = {IEEE Press},
  url        = {https://doi.org/10.1109/TNET.2021.3103796},
}

@InProceedings{Wang2022b,
  author    = {Wang, Haodong and Du, Kuntai and Jiang, Junchen},
  booktitle = {Proceedings of the 13th Symposium on Cloud Computing},
  title     = {Minimizing Packet Retransmission for Real-Time Video Analytics},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {340–347},
  publisher = {Association for Computing Machinery},
  series    = {SoCC '22},
  abstract  = {In smart-city and video analytics (VA) applications, high-quality data streams (video frames) must be accurately analyzed with a low delay. Since maintaining high accuracy requires compute-intensive deep neural nets (DNNs), these applications often stream massive video data to remote, more powerful cloud servers, giving rise to a strong need for low streaming delay between video sensors and cloud servers while still delivering enough data for accurate DNN inference. In response, many recent efforts have proposed distributed VA systems that aggressively compress/prune video frames deemed less important to DNN inference, with the underlying assumptions being that (1) without increasing available bandwidth, reducing delays means sending fewer bits, and (2) the most important frames can be precisely determined before streaming. This short paper challenges both views. First, in high-bandwidth networks, the delay of real-time videos is primarily bounded by packet losses and delay jitters, so reducing bitrate is not always as effective as reducing packet retransmissions. Second, for many DNNs, the impact of missing a video frame depends not only on itself but also on which other frames have been received or lost. We argue that some changes must be made in the transport layer, to determine whether to resend a packet based on the packet's impact on DNN's inference dependent on which packets have been received. While much research is needed toward an optimal design of DNN-driven transport layer, we believe that we have taken the first step in reducing streaming delay while maintaining a high inference accuracy.},
  doi       = {10.1145/3542929.3563502},
  isbn      = {9781450394147},
  keywords  = {systems for machine learning, action recognition, transport layer protocol, video analytics},
  location  = {San Francisco, California},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3542929.3563502},
}

@InProceedings{Guo2022,
  author    = {Guo, Shaogang and Xu, Yunfei and Li, Wang},
  booktitle = {Proceedings of the 2022 5th International Conference on Image and Graphics Processing},
  title     = {Spatial Non-Cooperative Target Point Cloud Reconstruction},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {84–88},
  publisher = {Association for Computing Machinery},
  series    = {ICIGP '22},
  abstract  = {Due to the inherent defects of laser sensors, the original point cloud of non-cooperate targets are usually irregularly distributed, which brings great challenges to high-quality 3D surface reconstruction of non-cooperate targets. In this paper, we leverage a method based local hierarchical clustering (LHC) to improve the consistency of point distribution. Specifically, our method includes two main steps. The first one is the adaptive octree-based 3D spatial decomposition and the second one is hierarchical clustering. The main purpose of the former one is to reduce the complexity of the algorithm, and the later aims to convert the non-uniform point set to uniform one. We carried out experiments on three non-cooperative target models. The results of visualization and quantitative calculation verify the effectiveness of our method.},
  doi       = {10.1145/3512388.3512401},
  isbn      = {9781450395465},
  keywords  = {Point cloud, Non-cooperative target, 3D reconstruction},
  location  = {Beijing, China},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3512388.3512401},
}

@Article{Yinying2022,
  author     = {Yinying, Cai and Li, Juan and Wang, Bo},
  journal    = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
  title      = {Data Mining Techniques and Machine Learning Algorithms in the Multimedia System to Enhance Engineering Education},
  year       = {2022},
  issn       = {2375-4699},
  month      = {dec},
  number     = {6},
  volume     = {21},
  abstract   = {In the current digital era, engineering education worldwide faces a massive challenge in education and career development. By authorizing educators and administrators to migrate to the actions, cloud services technology has transformed into the educational environment. A Multimedia assisted smart learning system (MSLS) has been suggested in this paper where universities/colleges will advocate future development and begin skill-set enhancement courses by e-learning. To classify their employment prospects at the early stage of graduation, this proposed system measures learners' academic/skill data. Machine learning and Data mining are advanced research fields whose accelerated advancement is attributable to developments in data processing research, database industry growth, and business requirements for methods capable of extracting useful information from massive data stores. In addition, for skill set evaluation, a practical algorithm is suggested to find different groups of students that lack the appropriate skill set. The anticipated student groups can be provided with opportunities by e-learning to enhance their required skill set. The findings suggest that more critical choices can boost employment prospects and overall educational development by implementing the new engineering education system.},
  address    = {New York, NY, USA},
  articleno  = {112},
  doi        = {10.1145/3517805},
  issue_date = {November 2022},
  keywords   = {multimedia system, Machine learning, data mining, engineering education},
  numpages   = {21},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3517805},
}

@InProceedings{Baeurle2022,
  author    = {B\"{a}urle, Simon and Mohan, Nitinder},
  booktitle = {Proceedings of the 5th International Workshop on Edge Systems, Analytics and Networking},
  title     = {ComB: A Flexible, Application-Oriented Benchmark for Edge Computing},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {19–24},
  publisher = {Association for Computing Machinery},
  series    = {EdgeSys '22},
  abstract  = {Edge computing is an attractive platform where applications, previously hosted in the cloud, shift parts of their workload on resources closer to the users. The field is still in its nascent stages with significant ongoing innovation in small form-factor hardware designed to operate at the edge. However, the increased hardware heterogeneity at the edge makes it difficult for application developers to determine if their workloads will operate as desired. Simultaneously, edge providers have to make expensive deployment choices for the "correct" hardware that will remain suitable for the near future. We present ComB, an application-oriented benchmarking suite for edge that assists early adopters in evaluating the suitability of an edge deployment. ComB is flexible, extensible, and incorporates a microservice-based video analytics pipeline as default workload to measure underlying hardware's compute and networking capabilities accurately. Our evaluation on a heterogeneous testbed shows that ComB enables both providers and developers to understand better the runtime capabilities of different hardware configurations for supporting operations of applications designed for the edge.},
  doi       = {10.1145/3517206.3526269},
  isbn      = {9781450392532},
  keywords  = {edge computing, benchmarking, next-generation applications},
  location  = {Rennes, France},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3517206.3526269},
}

@InProceedings{Ardagna2022,
  author    = {Ardagna, Claudio A. and Bena, Nicola and de Pozuelo, Ramon Mart\'{\i}n},
  booktitle = {Proceedings of the 17th International Conference on Availability, Reliability and Security},
  title     = {Bridging the Gap Between Certification and Software Development},
  year      = {2022},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ARES '22},
  abstract  = {While certification is widely recognized as a means to increase system trustworthiness and reduce uncertainty in decision making, it faces severe challenges preventing a wider adoption thereof. Certification is not adequately planned and integrated within the development process, leading to suboptimal scenarios where certification introduces the need to further modify the developed system with high costs. We propose a methodology that bridges the gap between software development and certification processes. Our methodology automatically produces the certification requirements driving all steps of the development process, and maximizes the strength of certificates while taking costs under control. We formalize the above problem as a multi-objective mathematical program and solve it through a genetic algorithm. The proposed approach is tested in a real-world, cloud-based financial scenario at CaixaBank and its performance and quality is evaluated in a simulated scenario.},
  articleno = {19},
  doi       = {10.1145/3538969.3539012},
  isbn      = {9781450396707},
  keywords  = {Software Development, Security, Certification},
  location  = {Vienna, Austria},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3538969.3539012},
}

@InProceedings{Maji2023,
  author    = {Maji, Diptyaroop and Pfaff, Ben and P R, Vipin and Sreenivasan, Rajagopal and Firoiu, Victor and Iyer, Sreeram and Josephson, Colleen and Pan, Zhelong and Sitaraman, Ramesh K},
  booktitle = {Proceedings of the 2nd Workshop on Sustainable Computer Systems},
  title     = {Bringing Carbon Awareness to Multi-Cloud Application Delivery},
  year      = {2023},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {HotCarbon '23},
  abstract  = {Data centers consume roughly 1--2\% of the world's electricity, with the majority of it attributed to compute, making the computing industry a substantial source of greenhouse gas emissions. Resources in data centers typically focus on providing high performance and availability, but the question of sustainability in managing these distributed resources often goes unnoticed over these other metrics. This problem will only exacerbate as the data center computing demand continues to increase.In this paper, we address the sustainability aspect of load balancing in VMware's Avi Global Server Load Balancer (GSLB). Our GSLB deployment spans data centers across geographies and clouds and relies on geographical proximity to shift client application requests to the closest data center. In this work, we enhance the GSLB service to additionally consider the real-time carbon intensity at each data center as a factor in making a load-balancing choice. Our carbon-aware prototype shows an average of 21\% and a maximum of 51\% reduction in carbon emissions while operating with an acceptable latency.},
  articleno = {6},
  doi       = {10.1145/3604930.3605711},
  isbn      = {9798400702426},
  keywords  = {marginal carbon intensity, data center computing, spatial load balancing, stateless workloads},
  location  = {Boston, MA, USA},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3604930.3605711},
}

@InProceedings{Shetty2022,
  author    = {Shetty, Manish and Bansal, Chetan and Upadhyayula, Sai Pramod and Radhakrishna, Arjun and Gupta, Anurag},
  booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  title     = {AutoTSG: Learning and Synthesis for Incident Troubleshooting},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {1477–1488},
  publisher = {Association for Computing Machinery},
  series    = {ESEC/FSE 2022},
  abstract  = {Incident management is a key aspect of operating large-scale cloud services. To aid with faster and efficient resolution of incidents, engineering teams document frequent troubleshooting steps in the form of Troubleshooting Guides (TSGs), to be used by on-call engineers (OCEs). However, TSGs are siloed, unstructured, and often incomplete, requiring developers to manually understand and execute necessary steps. This results in a plethora of issues such as on-call fatigue, reduced productivity, and human errors. In this work, we conduct a large-scale empirical study of over 4K+ TSGs mapped to incidents and find that TSGs are widely used and help significantly reduce mitigation efforts. We then analyze feedback on TSGs provided by 400+ OCEs and propose a taxonomy of issues that highlights significant gaps in TSG quality. To alleviate these gaps, we investigate the automation of TSGs and propose AutoTSG -- a novel framework for automation of TSGs to executable workflows by combining machine learning and program synthesis. Our evaluation of AutoTSG on 50 TSGs shows the effectiveness in both identifying TSG statements (accuracy 0.89) and parsing them for execution (precision 0.94 and recall 0.91). Lastly, we survey ten Microsoft engineers and show the importance of TSG automation and the usefulness of AutoTSG.},
  doi       = {10.1145/3540250.3558958},
  isbn      = {9781450394130},
  keywords  = {Meta Learning, Incident Management, Troubleshooting, Program Synthesis, Cloud Reliability},
  location  = {<conf-loc>, <city>Singapore</city>, <country>Singapore</country>, </conf-loc>},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3540250.3558958},
}

@InProceedings{OSullivan2022,
  author    = {O'Sullivan, Samantha and Murray, Niall and Rodrigues, Thiago Braga},
  booktitle = {Proceedings of the 13th ACM Multimedia Systems Conference},
  title     = {A Telehealth and Sensor-Based System for User-Centered Physical Therapy in Parkinson's Disease: Research Proposal},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {383–387},
  publisher = {Association for Computing Machinery},
  series    = {MMSys '22},
  abstract  = {This paper contains the research proposal of Samantha O'Sullivan that was presented at the MMSys 2022 doctoral symposium. The use of wearable sensors for the understanding and quantification of movement within research communities working on Parkinson's Disease (PD) has increased significantly in recent years with a motivation to objectively diagnose, assess and then understand the progression of the disease. Most studies taking this approach for PD have stated that there is a need for a long-term solution, due to varying symptoms at different stages of the disease. COVID-19 has brought further limitations in the delivery of clinical care, reducing time with therapists and doctors whilst increasing the preference for at-home care. The necessity for a system for patients with PD is extremely significant. There is no clinically available long-term assessment for tremors, which is an issue highlighted in the literature. By using wireless sensors to track tremor severity continuously, and telehealth to create communication between patient and clinician, this proposed system will allow for better targeted therapy, accurate statistics, and constant accessible data. In this context, this work will design, build, and evaluate a novel system that would allow for constant monitoring of a patient with tremors. By using wireless sensors and telehealth, it will provide more detailed data that may enable directed and informed physical therapy. It will also improve communication creating a data flow constantly between clinician and patient to improve person-centered feedback, and aid towards the diagnosis and assessment of disease progression. The incorporation of a mobile/cloud-based application to assist this is due to the current heightened preference for home-based healthcare, long-term evaluation of tremors and personalized physical therapy. The primary focus of the PhD will be on capturing tremor activity and progression through a telehealth-based system. This proposed system will obtain real-time readings of tremors using wireless sensors and an application that will communicate consistently with healthcare professionals. The aim will be to provide better home-based care, person-centered physical therapy and improve quality of life.},
  doi       = {10.1145/3524273.3535781},
  isbn      = {9781450392839},
  keywords  = {sensors, rehabilitation, quantitative motor assessment, telehealth, Parkinson's disease},
  location  = {Athlone, Ireland},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3524273.3535781},
}

@InProceedings{Bimenyimana2023,
  author    = {Bimenyimana, Emmanuel and Nsengiyumva, Philibert and Ngoga, Said Rutabayiro},
  booktitle = {Proceedings of the 2023 12th International Conference on Software and Computer Applications},
  title     = {IoT Monitoring and Control System of Distribution Transformers in Rwanda},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {253–259},
  publisher = {Association for Computing Machinery},
  series    = {ICSCA '23},
  abstract  = {In developing countries, many customers do not get good quality of electricity power supply due to frequent and prolonged power fluctuations/cuts. Distribution transformer&nbsp;(DT) is a&nbsp;service transformer&nbsp;that provides the final&nbsp;voltage&nbsp;transformation in the&nbsp;electric power distribution&nbsp;system, stepping down the voltage to the level used by the customers. Monitoring and control of DT (as a crucial and expensive asset in the network) is a key enabler of power stability to consumers. A power utility is said to be a business oriented with good image representation if it delivers a reliable and affordable electricity. Modern technologies such as the Internet of Things (IoT) offer a wide range of applications in the energy sector to smoothly monitor, control and optimize processes. Currently, many energy companies in developing countries are not yet implementing the remote system to control and monitor the secondary side of DTs and timely get the notifications of fluctuations/abnormalities occurred on those DTs. That is why it is still challenging and time consuming to intervene urgently and do the necessary actions to prevent severe and prolonged power cuts/fluctuations and safeguard the damage of DTs themselves with customer's appliances connected on those DTs. The secondary side of DT is the one connected directly and supply power to the customers. For this reason, we developed an affordable IoT system that automatically detects the abnormalities/fluctuations of three core technical parameters of DT (which are voltage, current and temperature) using current sensors, voltage sensors, and temperature sensor with ATmega 328P Microcontroller to collect and process data from sensors connected to DT system. Once one or all of those technical parameters become abnormal, the system cut off automatically the secondary side of DT in 2 seconds to isolate and protect the customers’ load with safeguarding DT itself using a power relay. At the same time, GSM/GPRS module uploads the sensed abnormal data to the cloud storage, displays them on web-based application for visualization, and sends the corresponding short message service (sms) to notify the issue to the authorized person in 5 seconds for speeding up the interventions and power restoration. In case there is a movement related to the vandalism in the compound of DT, a PIR sensor detects the human motion then a camera takes the related picture and send it to the utility with the corresponding sms. A buzzer generates an audio signaling to warn the culprit/criminal until he left the site. If there is no abnormality detected, the system keeps sensing without sending the data to the cloud. We can open and close remotely the secondary side of DT and buzzer. This system is powered using a rechargeable battery.},
  doi       = {10.1145/3587828.3587866},
  isbn      = {9781450398589},
  keywords  = {voltage, Internet of Things (IoT), current, temperature, distribution transformer},
  location  = {<conf-loc>, <city>Kuantan</city>, <country>Malaysia</country>, </conf-loc>},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3587828.3587866},
}

@InProceedings{SilvaJunior2023,
  author    = {Silva J\'{u}nior, Paulo Freitas and Fran\c{c}a, Tiago Cruz and Sampaio, Jonice Oliveira},
  booktitle = {Proceedings of the XIX Brazilian Symposium on Information Systems},
  title     = {CARAMEL: Ecosystem for Big Social Data},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {136–142},
  publisher = {Association for Computing Machinery},
  series    = {SBSI '23},
  abstract  = {Context: A large volume of data produced in social media is analyzed through different perspectives. Much effort goes into retrieving and processing the data, maintaining the necessary infrastructure, and building and sharing the foundation between actors with different roles. These challenges are observed in data ecosystems. Problem: The central systems to support data analysis from social networks have some restrictions (data collection, sharing, reuse, etc.). Data collection and analysis require technical skills that some users need and do not have, impacting the quality of inferences, accounting, and conclusions. Solution: We propose an architecture for “Big Social Data” ecosystems considering the collaborative construction of data extraction and sharing mechanisms. IS Theory: This proposal is related to “knowledge-based theory,” as much knowledge can be inferred from social data. It also supports the Externalization and Combination steps of the Organizational knowledge creation model. Method: We observe aspects related to data analysis, considering the reuse of the mechanisms created and the sharing of bases that can run and be stored in a distributed way to meet even instantaneous analysis. Results: The architecture was implemented to work in a distributed way, contains a collector and a filter and allows data sharing. A data collection test was conducted during the 2022 presidential elections in Brazil. Contributions: The main contribution is the architecture of a Big Social Data Ecosystem, focused on the evolution of social data analysis that also observes the interoperability between distributed solutions. The technological contributions are an instance of this architecture for the cloud, social media data collectors, and datasets of the 2022 election in Brazil.},
  doi       = {10.1145/3592813.3592898},
  isbn      = {9798400707599},
  keywords  = {Social networks., Social data analysis, Microservices, Data ecosystem, Cloud computing},
  location  = {<conf-loc>, <city>Macei\'{o}</city>, <country>Brazil</country>, </conf-loc>},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3592813.3592898},
}

@InProceedings{Syu2023,
  author    = {Syu, Yang and Fanjiang, Yong-Yi},
  booktitle = {Proceedings of the Companion Conference on Genetic and Evolutionary Computation},
  title     = {Multi-Step-Ahead Web Service QoS Time Series Forecasting: A Multi-Predictor-Based Genetic Programming Approach},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {43–44},
  publisher = {Association for Computing Machinery},
  series    = {GECCO '23 Companion},
  abstract  = {Previously, in a GECCO 2022 Hot-off-the-Press paper [1], we presented a comprehensive survey of the modeling and prediction of Web service (WS) quality of service (QoS) time series [2]. Based on the exhaustive investigation in [2], this research subject has already been deeply and widely studied for over a decade; for the one-step-ahead version of this problem, which can be considered its most primitive problem form, overall, our proposed and developed genetic programming (GP)-based solution outperforms competitors in terms of both modeling and forecasting accuracy, according to our ongoing study, which has been reported in [3] [4] [5]. Nevertheless, as argued in [6], for the long-term use and rental of cloud-based WSs, multi-step-ahead QoS time series prediction of these services is needed. Thus, the authors employed and revised the two most widely used single-predictor-based time series methods, namely, autoregressive integrated moving average (ARIMA) models and exponential smoothing (ES), to address this latest version of the problem.For this multi-step-ahead variant of the problem, in Y. Y. Fanjiang, Y. Syu and W. L. Huang, "Time Series QoS Forecasting for Web Services Using Multi-Predictor-based Genetic Programming", IEEE Transactions on Services Computing (TSC), Vol. 15, P.P. 1423--1435, 2022, we devise and employ a multipredictor-based approach to genetic programming. First, due to its superiority in our past work for the basic (i.e., one-step-ahead) version of the problem, we investigate the performance of GP on this newly emerged (multi-step-ahead) form of the problem. Second, instead of using a single model for predictions regarding multiple future time points, which is the method commonly adopted in prior research [2], we evolve and apply a dedicated GP-generated predictor for each targeted future time point and its projection. Furthermore, two different strategies for the consumed predictor inputs are tested to determine their differences and influence on accuracy so that a better strategy can be empirically determined. In addition, we propose in the reported paper [7] two disparate techniques to further enhance the resulting performance of our multi-predictor-based GP method.As in our previous GECCO Hot-off-the-Press paper [1], this abstract paper presents to the GECCO community a verified application of GP on a more difficult and challenging type of WS QoS time series forecasting. Our purpose is to enable the GECCO community to use this application of GP, to try to improve GP to obtain more accurate and better results, and to investigate other potential evolutionary paradigms and techniques for this issue.},
  doi       = {10.1145/3583133.3595841},
  isbn      = {9798400701207},
  keywords  = {genetic programming, time series forecasting, service-oriented software engineering, machine learning, web services},
  location  = {Lisbon, Portugal},
  numpages  = {2},
  url       = {https://doi.org/10.1145/3583133.3595841},
}

@InProceedings{Lin2022a,
  author    = {Lin, Hai and Chen, Xianfu},
  booktitle = {Proceedings of the 1st Workshop on Digital Twin \&amp; Edge AI for Industrial IoT},
  title     = {Transformer-Driven Multi-Agent Deep Reinforcement Learning Based Point Cloud Video Transmissions},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {25–30},
  publisher = {Association for Computing Machinery},
  series    = {AIIOT '22},
  abstract  = {The point cloud videos, a medium for representing natural content in AR/VR with point clouds, have attracted a wide range of attention for its characteristics and have the potential to be the next generation of video technology. Given the high data volume, the point cloud video raises the challenge of intelligent transmission and resource scheduling in multi-user scenarios under time-varying system conditions. In this paper, we propose a multi-agent deep reinforcement learning (DRL) approach to optimize the expected long-term multi-user QoE and adopt a Field of View (FoV) prediction model with Transformer for high-accuracy FoV prediction. Over the time horizon, the proposed approach learns to select the tiles of the corresponding video in accordance with a proposed well-defined QoE model capable of quantifying users' satisfaction for transmissions in an iterative way. Under various settings, extensive numerical experiments based on real throughput data traces and different computation capabilities data demonstrate that the proposed approach is effective for long-term multi-agent point cloud video transmissions.},
  doi       = {10.1145/3566099.3569006},
  isbn      = {9781450397841},
  keywords  = {quality of experience, point cloud video, deep reinforcement learning, transformer},
  location  = {Sydney, NSW, Australia},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3566099.3569006},
}

@Article{Liu2021,
  author     = {Liu, Yanchao and Guo, Jianwei and Benes, Bedrich and Deussen, Oliver and Zhang, Xiaopeng and Huang, Hui},
  journal    = {ACM Trans. Graph.},
  title      = {TreePartNet: Neural Decomposition of Point Clouds for 3D Tree Reconstruction},
  year       = {2021},
  issn       = {0730-0301},
  month      = {dec},
  number     = {6},
  volume     = {40},
  abstract   = {We present TreePartNet, a neural network aimed at reconstructing tree geometry from point clouds obtained by scanning real trees. Our key idea is to learn a natural neural decomposition exploiting the assumption that a tree comprises locally cylindrical shapes. In particular, reconstruction is a two-step process. First, two networks are used to detect priors from the point clouds. One detects semantic branching points, and the other network is trained to learn a cylindrical representation of the branches. In the second step, we apply a neural merging module to reduce the cylindrical representation to a final set of generalized cylinders combined by branches. We demonstrate results of reconstructing realistic tree geometry for a variety of input models and with varying input point quality, e.g., noise, outliers, and incompleteness. We evaluate our approach extensively by using data from both synthetic and real trees and comparing it with alternative methods.},
  address    = {New York, NY, USA},
  articleno  = {232},
  doi        = {10.1145/3478513.3480486},
  issue_date = {December 2021},
  keywords   = {optimization, deep learning, procedural generation, geometric modeling, procedural modeling, 3D reconstruction},
  numpages   = {16},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3478513.3480486},
}

@InProceedings{Zhou2023,
  author    = {Zhou, Ruiting and Yu, Jieling},
  booktitle = {Proceedings of the ACM Turing Award Celebration Conference - China 2023},
  title     = {A Reinforcement Learning Approach for Minimizing Job Completion Time in Clustered Federated Learning},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {55–56},
  publisher = {Association for Computing Machinery},
  series    = {ACM TURC '23},
  abstract  = {Federated Learning (FL) enables potentially a large number of clients to collaboratively train a global model with the coordination of a central cloud server without exposing client raw data. However, the FL model convergence performance, often measured by the job completion time, is hindered by two critical factors: non independent and identically distributed (non-IID) data across clients and the straggler effect. In this work, we propose a clustered FL framework, MCFL, to minimize the job completion time by mitigating the influence of non-IID data and the straggler effect while guaranteeing the FL model convergence performance. MCFL builds upon a two-stage operation: i) a clustering algorithm constructs clusters, each containing clients with similar computing and communications capabilities to combat the straggler effect within a cluster; ii) a deep reinforcement learning (DRL) algorithm based on soft actor-critic with discrete actions intelligently selects a subset of clients from each cluster to mitigate the impact of non-IID data, and derives the number of intra-cluster aggregation iterations for each cluster to reduce the straggler effect among clusters. Extensive testbed experiments are conducted under various configurations to verify the efficacy of MCFL. The results show that MCFL can reduce the job completion time by up to compared with three state-of-the-art FL frameworks.},
  doi       = {10.1145/3603165.3607394},
  isbn      = {9798400702334},
  location  = {Wuhan, China},
  numpages  = {2},
  url       = {https://doi.org/10.1145/3603165.3607394},
}

@Article{Bhimani2022,
  author     = {Bhimani, Janki and Yang, Zhengyu and Yang, Jingpei and Maruf, Adnan and Mi, Ningfang and Pandurangan, Rajinikanth and Choi, Changho and Balakrishnan, Vijay},
  journal    = {ACM Trans. Storage},
  title      = {Automatic Stream Identification to Improve Flash Endurance in Data Centers},
  year       = {2022},
  issn       = {1553-3077},
  month      = {apr},
  number     = {2},
  volume     = {18},
  abstract   = {The demand for high performance I/O in Storage-as-a-Service (SaaS) is increasing day by day. To address this demand, NAND Flash-based Solid-state Drives (SSDs) are commonly used in data centers as cache- or top-tiers in the storage rack ascribe to their superior performance compared to traditional hard disk drives (HDDs). Meanwhile, with the capital expenditure of SSDs declining and the storage capacity of SSDs increasing, all-flash data centers are evolving to serve cloud services better than SSD-HDD hybrid data centers. During this transition, the biggest challenge is how to reduce the Write Amplification Factor (WAF) as well as to improve the endurance of SSD since this device has a limited program/erase cycles. A specified case is that storing data with different lifetimes (i.e., I/O streams with similar temporal fetching patterns such as reaccess frequency) in one single SSD can cause high WAF, reduce the endurance, and downgrade the performance of SSDs. Motivated by this, multi-stream SSDs have been developed to enable data with a different lifetime to be stored in different SSD regions. The logic behind this is to reduce the internal movement of data—when garbage collection is triggered, there are high chances of having data blocks with either all the pages being invalid or valid. However, the limitation of this technology is that the system needs to manually assign the same streamID to data with a similar lifetime. Unfortunately, when data arrives, it is not known how important this data is and how long this data will stay unmodified. Moreover, according to our observation, with different definitions of a lifetime (i.e., different calculation formulas based on selected features previously exhibited by data, such as sequentiality, and frequency), streamID identification may have varying impacts on the final WAF of multi-stream SSDs. Thus, in this article, we first develop a portable and adaptable framework to study the impacts of different workload features and their combinations on write amplification. We then propose a feature-based stream identification approach, which automatically co-relates the measurable workload attributes (such as I/O size, I/O rate, and so on.) with high-level workload features (such as frequency, sequentiality, and so on.) and determines a right combination of workload features for assigning streamIDs. Finally, we develop an adaptable stream assignment technique to assign streamID for changing workloads dynamically. Our evaluation results show that our automation approach of stream detection and separation can effectively reduce the WAF by using appropriate features for stream assignment with minimal implementation overhead.},
  address    = {New York, NY, USA},
  articleno  = {17},
  doi        = {10.1145/3470007},
  issue_date = {May 2022},
  keywords   = {coherency, write amplification factor, NAND flash endurance, I/O workload characterization, multi-streaming, Solid state drives, I/O stream detection},
  numpages   = {29},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3470007},
}

@InProceedings{Nouma2023,
  author    = {Nouma, Saif E. and Yavuz, Attila A.},
  booktitle = {Proceedings of the 8th ACM/IEEE Conference on Internet of Things Design and Implementation},
  title     = {Practical Cryptographic Forensic Tools for Lightweight Internet of Things and Cold Storage Systems},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {340–353},
  publisher = {Association for Computing Machinery},
  series    = {IoTDI '23},
  abstract  = {Internet of Things (IoT) and Storage-as-a-Service (STaaS) continuum permit cost-effective maintenance of security-sensitive information collected by IoT devices over cloud systems. It is necessary to guarantee the security of sensitive data in IoT-STaaS applications. Especially, log entries trace critical events in computer systems and play a vital role in the trustworthiness of IoT-STaaS. An ideal log protection tool must be scalable and lightweight for vast quantities of resource-limited IoT devices while permitting efficient and public verification at STaaS. However, the existing cryptographic logging schemes either incur significant computation/signature overhead to the logger or extreme storage and verification costs to the cloud. There is a critical need for a cryptographic forensic log tool that respects the efficiency requirements of the IoT-STaaS continuum. In this paper, we created novel digital signatures for logs called Optimal Signatures for secure Logging (), which are the first (to the best of our knowledge) to offer both small-constant signature and public key sizes with near-optimal signing and batch verification via various granularities. We introduce new design features such as one-time randomness management, flexible aggregation along with various optimizations to attain these seemingly conflicting properties simultaneously. Our experiments show that &nbsp;offers 50 \texttimes{} faster verification (for 235 entries) than the most compact alternative with equal signature sizes, while also being several magnitudes of more compact than its most logger efficient counterparts. These properties make &nbsp;an ideal choice for the IoT-STaaS, wherein lightweight logging and efficient batch verification of massive-size logs are vital for the IoT edge and cold storage servers, respectively.},
  doi       = {10.1145/3576842.3582376},
  isbn      = {9798400700378},
  keywords  = {secure logs, cold storage, digital signatures, Authentication},
  location  = {<conf-loc>, <city>San Antonio</city>, <state>TX</state>, <country>USA</country>, </conf-loc>},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3576842.3582376},
}

@InProceedings{Qlu2022,
  author    = {Qlu, Ye},
  booktitle = {Proceedings of the 6th International Conference on High Performance Compilation, Computing and Communications},
  title     = {Secure Mechanism of Intelligent Urban Railway Cloud Platform Based on Zero-Trust Security Architecture},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {99–105},
  publisher = {Association for Computing Machinery},
  series    = {HP3C '22},
  abstract  = {Aiming to strengthen the stability of operation and maintenance of the urban rail transit network cloud platform at this stage, it is emerging to solve the security mechanism of the intelligent urban railway cloud platform. In this paper, we proposed a zero-trust network security solution for the rail transit system network construction. First, we built a zero-trust network construction for smart city rail transit at the architecture level, it can break the phenomenon of information security silo of rail transit line platform and minimize the system security risk based on a zero-trust network. Next, we focus on building a cloud security brain for urban rail transit networks and proposed the self-learning trust algorithm for a zero-trust network. Specifically, we illustrated the modified network model and constructed a dynamic updating user trust profile as the trustworthy access list. The parameters of the self-learning trust algorithm consist of the state, available chain road bandwidth, waiting for queue state of network traffic, linkage actions, and so on. We adopted a dynamic self-learning strategy for adjusting mitigation policy, the learning step predicted the state of the predetermined congestion and selected the rich links for execution. Finally, experiments show the efficiency of our secure mechanism of railway cloud platform based on zero-trust security architecture.},
  doi       = {10.1145/3546000.3546015},
  isbn      = {9781450396295},
  keywords  = {cloud platform, Zero-trust security mechanism, simulation analysis},
  location  = {Jilin, China},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3546000.3546015},
}

@InProceedings{AbdurRahman2023,
  author    = {Abdur Rahman, Lubnaa and Papathanail, Ioannis and Brigato, Lorenzo and Mougiakakou, Stavroula},
  booktitle = {Proceedings of the 8th International Workshop on Multimedia Assisted Dietary Management},
  title     = {A Comparative Analysis of Sensor-, Geometry-, and Neural-Based Methods for Food Volume Estimation},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {21–29},
  publisher = {Association for Computing Machinery},
  series    = {MADiMa '23},
  abstract  = {With the rapid advancements in artificial intelligence and computer vision within health and nutrition fields, image-based automatic dietary assessment is gaining popularity. This automation involves food segmentation, recognition, volume estimation, and estimation of nutritional content. While considerable progress has been made in food segmentation and recognition, accurate volume estimation remains challenging. Measuring food volume is crucial in many fields, even thought this is difficult to automate precisely. This is hampering progress, and is leading to continued reliance on time-consuming traditional methods, such as manual computation of food volume through water displacement. The manuscript presents a comparative analysis of sensor-, geometry-, and neural-based methods for computing food volume. We have performed multiple experiments using 20 meal images captured under different settings, with reliable measurements of ground-truth volume obtained by capturing 360-degree views of the food items and computing their volumes in a 3D space. An extensive analysis of our results then serves to identify the strengths and limitations of each approach, and offers valuable insights for selecting the most suitable method in specific settings. Moreover, we have made the collected data (including RGB images, ground-truth point clouds, volumes, etc.) open-source. We intend this as a contribution to the research community and to address the scarcity of food datasets with depth-related information.},
  doi       = {10.1145/3607828.3617794},
  isbn      = {9798400702846},
  keywords  = {image-based food volume estimation, multimedia systems, computer vision, sensor-based volume estimation, stereo vision, depth prediction, artificial intelligence},
  location  = {<conf-loc>, <city>Ottawa ON</city>, <country>Canada</country>, </conf-loc>},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3607828.3617794},
}

@InProceedings{Asvadishirehjini2022,
  author    = {Asvadishirehjini, Aref and Kantarcioglu, Murat and Malin, Bradley},
  booktitle = {Proceedings of the Twelfth ACM Conference on Data and Application Security and Privacy},
  title     = {GINN: Fast GPU-TEE Based Integrity for Neural Network Training},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {4–15},
  publisher = {Association for Computing Machinery},
  series    = {CODASPY '22},
  abstract  = {Machine learning models based on Deep Neural Networks (DNNs) are increasingly deployed in a wide variety of applications, ranging from self-driving cars to COVID-19 diagnosis. To support the computational power necessary to train a DNN, cloud environments with dedicated Graphical Processing Unit (GPU) hardware support have emerged as critical infrastructure. However, there are many integrity challenges associated with outsourcing the computation to use GPU power, due to its inherent lack of safeguards to ensure computational integrity. Various approaches have been developed to address these challenges, building on trusted execution environments (TEE). Yet, no existing approach scales up to support realistic integrity-preserving DNN model training for heavy workloads (e.g., deep architectures and millions of training examples) without sustaining a significant performance hit. To mitigate the running time difference between pure TEE (i.e., full integrity) and pure GPU (i.e., no integrity) , we combine random verification of selected computation steps with systematic adjustments of DNN hyperparameters (e.g., a narrow gradient clipping range), which limits the attacker's ability to shift the model parameters arbitrarily. Experimental analysis shows that the new approach can achieve a 2X to 20X performance improvement over a pure TEE-based solution while guaranteeing an extremely high probability of integrity (e.g., 0.999) with respect to state-of-the-art DNN backdoor attacks.},
  doi       = {10.1145/3508398.3511503},
  isbn      = {9781450392204},
  keywords  = {intel sgx, trusted exexution environments, deep learning, integrity preserving deep learning training},
  location  = {Baltimore, MD, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3508398.3511503},
}

@Article{AlDebagy2020,
  author   = {Al-Debagy, O. and Martinek, P.},
  journal  = {Journal of Web Engineering},
  title    = {A Metrics Framework for Evaluating Microservices Architecture Designs},
  year     = {2020},
  issn     = {1544-5976},
  month    = {June},
  number   = {3–4},
  pages    = {341-370},
  volume   = {19},
  abstract = {Microservices are becoming a more popular software architecture among companies and developers. Therefore, there is a need to develop methods for quantifying the process of measuring the quality of microservices design. This paper has created a novel set of metrics for microservices architecture applications. The proposed metrics are the Service Granularity Metric “SGM”, the Lack of Cohesion Metric “LCOM”, and the Number of Operations “NOO”. The proposed metrics measure the granularity, cohesion, and complexity of individual microservices through analyzing the application programming interface “API”. Using these metrics, it is possible to evaluate the overall quality of the design of microservices applications. The proposed metrics were measured on 5 applications with different sizes and business cases. This research found that the value for the SGM metric needs to be between 0.2 and 0.6. Besides, the value of LCOM metric for a microservice needs to be between 0 and 0.8 with less than ten operations per microservice. These findings can be applied in the decomposition process of monolithic applications as well.},
  doi      = {10.13052/jwe1540-9589.19341},
}

@InProceedings{Levin2020,
  author    = {Levin, Joshua and Benson, Theophilus A.},
  booktitle = {2020 IEEE 9th International Conference on Cloud Networking (CloudNet)},
  title     = {ViperProbe: Rethinking Microservice Observability with eBPF},
  year      = {2020},
  month     = {Nov},
  pages     = {1-8},
  abstract  = {Recent shifts to microservice-based architectures and the supporting servicemesh radically disrupt the landscape of performance-oriented management tasks. While the adoption of frameworks like Istio and Kubernetes ease the management and organization of such systems, they do not themselves provide strong observability. Microservice observability requires diverse, highly specialized, and often adaptive, metrics and algorithms to monitor both the health of individual services and the larger application. However, modern metrics collection frameworks are relatively static and rigid. We introduce ViperProbe, an eBPF-based microservices collection framework that provides (1) dynamic sampling and (2) collection of deep, diverse, and precise system metrics. Viper-Probe builds on the observation that the adoption of a common set of design patterns, e.g., servicemesh, enables offline analysis. By examining the performance profile of these patterns before deploying on production, ViperProbe can effectively reduce the set of collected metrics, thereby improving the efficiency and effectiveness of those metrics. To the best of our knowledge, ViperProbe is the first scalable eBPF-based dynamic and adaptive microservices metrics collection framework. Our results show ViperProbe has limited overhead, while significantly more effective for traditional management tasks, e.g., horizontal autoscaling.},
  doi       = {10.1109/CloudNet51028.2020.9335808},
}

@InProceedings{Perera2018,
  author    = {Perera, K. J. P. G. and Perera, I.},
  booktitle = {2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS)},
  title     = {TheArchitect: A Serverless-Microservices Based High-level Architecture Generation Tool},
  year      = {2018},
  month     = {June},
  pages     = {204-210},
  abstract  = {Software is ubiquitous in today's systems and business operations. Most importantly the architecture of a software system determines its quality and longevity, because the development work related to the software system will be carried out to be in line with its architecture design. Hence, it's highly important to structure the high-level software architecture accordingly to deliver the expected customer requirements while accounting for quality measures such as scalability, high availability and high performance. We propose TheArchitect, a serverless-microservices based high-level architecture generation tool, which will auto generate serverless-microservices based high-level architecture for a given business application, preserving the highlighted quality measures providing a tool based support for the software architect with respect to designing the high-level architecture. TheArchitect will provide any software developer to generate a proper architecture minimizing the involvement of an experienced software architect. Furthermore, the positives that microservices and serverless technologies has brought to the world of software engineering has made the software engineering community shift from the era of building large monolith applications containing overly complex designs, to microservices and serverless based technologies. Hence TheArchitect focuses on generating best fitted microservices and serverless based high-level architecture for a given application.},
  doi       = {10.1109/ICIS.2018.8466390},
}

@InProceedings{Perera2018a,
  author    = {Perera, K. J. P. G. and Perera, I.},
  booktitle = {2018 IEEE International Systems Engineering Symposium (ISSE)},
  title     = {A Rule-based System for Automated Generation of Serverless-Microservices Architecture},
  year      = {2018},
  month     = {Oct},
  pages     = {1-8},
  abstract  = {Software being ubiquitous in today's systems and business operations, it's highly important to structure the high-level architecture of a software application accordingly to deliver the expected customer requirements while accounting for quality measures such as scalability, high availability and high performance. We propose The Architect, a rule-based system for serverless-microservices based high-level architecture generation. In the process of auto generating serverless-microservices high-level architecture, TheArchitect will preserve the highlighted quality measures. It will also provide a tool based support for the high-level architecture designing process of the software architect. Any software developer will be able to use TheArchitect to generate a proper architecture minimizing the involvement of a software architect. Furthermore, the positives of microservices and serverless technologies have made a significant impact on the software engineering community in terms of shifting from the era of building large monolith applications containing overly complex designs, to microservices and serverless based technologies. Hence The Architect focuses on generating best fitted microservices and serverless based high-level architecture for a given application.},
  doi       = {10.1109/SysEng.2018.8544423},
}

@InProceedings{Asik2017,
  author    = {Asik, Tugrul and Selcuk, Yunus Emre},
  booktitle = {2017 IEEE 15th International Conference on Software Engineering Research, Management and Applications (SERA)},
  title     = {Policy enforcement upon software based on microservice architecture},
  year      = {2017},
  month     = {June},
  pages     = {283-287},
  abstract  = {Microservice is an architectural style that has recently started gaining popularity to become a new architectural phenomenon. Microservice architecture provides new opportunities to deploy scalable, language free and dynamically adjustable applications. This type of applications consist of hundreds or more of service instances. So that, management, monitoring, refactoring and testing of applications are more complex than monolithic applications. Therefore, some metrics and policies for measuring the quality of an application which is based on microservice architecture is needed. Moreover, automated tools are needed to carry out those tasks and enforce those policies. This work represents such metrics and policies. Additionally, an automated tool is implemented for automatic analysis of those metrics and policies upon software.},
  doi       = {10.1109/SERA.2017.7965739},
}

@InProceedings{Weng2021,
  author    = {Weng, Tianjun and Yang, Wanqi and Yu, Guangba and Chen, Pengfei and Cui, Jieqi and Zhang, Chuanfu},
  booktitle = {2021 IEEE/ACM International Workshop on Cloud Intelligence (CloudIntelligence)},
  title     = {Kmon: An In-kernel Transparent Monitoring System for Microservice Systems with eBPF},
  year      = {2021},
  month     = {May},
  pages     = {25-30},
  abstract  = {Currently, the architecture of software systems is shifting from “monolith” to “microservice” which is an important enabling technology of cloud native systems. Since the advantages of microservice in agility, efficiency, and scaling, it has become the most popular architecture in the industry. However, as the increase of microservice complexity and scale, it becomes challenging to monitor such a large number of microservices. Traditional monitoring techniques such as end-to-end tracing cannot well fit microservice environment, because they need code instrumentation with great effort. Moreover, they cannot explore the fine-grained internal states of microservice instances. To tackle this problem, we propose Kmon, which is an In-kernel transparent monitoring system for microservice systems with extended Berkeley Packet Filter (eBPF). Kmon can provide multiple kinds of run-time information of micrservices such as latency, topology, performance metrics with a low overhead.},
  doi       = {10.1109/CloudIntelligence52565.2021.00014},
}

@InProceedings{Cui2020,
  author    = {Cui, Jieqi and Chen, Pengfei and Yu, Guangba},
  booktitle = {2020 IEEE 26th International Conference on Parallel and Distributed Systems (ICPADS)},
  title     = {A Learning-based Dynamic Load Balancing Approach for Microservice Systems in Multi-cloud Environment},
  year      = {2020},
  month     = {Dec},
  pages     = {334-341},
  abstract  = {Multi-cloud environment has become common since companies manage to prevent cloud vendor lock-in for security and cost concerns. Meanwhile, the microservice architecture is often considered for its flexibility. Combining multi-cloud with microservice, the problem of routing requests among all possible microservice instances in multi-cloud environment arises. This paper presents a learning-based approach to route requests in order to balance the load. In our approach, the performance of microservice is modeled explicitly through machine learning models. The model can derive the response time from request volume, route decision, and other cloud metrics. Then the balanced route decision is obtained from optimizing the model with Bayesian Optimization. With this approach, the request route decision can adjust to dynamic runtime metrics instead of remaining static for all different circumstances. Explicit performance modeling avoids searching on an actual microservice system which is time-consuming. Experiments show that our approach reduces average response time by 10% at least.},
  doi       = {10.1109/ICPADS51040.2020.00052},
  issn      = {2690-5965},
}

@InProceedings{Zhang2020b,
  author    = {Zhang, Yukun and Liu, Bo and Dai, Liyun and Chen, Kang and Cao, Xuelian},
  booktitle = {2020 IEEE International Conference on Software Architecture (ICSA)},
  title     = {Automated Microservice Identification in Legacy Systems with Functional and Non-Functional Metrics},
  year      = {2020},
  month     = {March},
  pages     = {135-145},
  abstract  = {Since microservice has merged as a promising architectural style with advantages in maintainability, scalability, evolvability, etc., increasing companies choose to restructure their legacy monolithic software systems as the microservice architecture. However, it is quite a challenge to properly partitioning the systems into suitable parts as microservices. Most approaches perform microservices identification from a function-splitting perspective and with sufficient legacy software artifacts. That may be not realistic in industrial practices and possibly results in generating unexpected microservices. To address this, we proposed an automated microservice identification (AMI) approach that extracts microservices from the execution and performance logs without providing documentation, models or source codes, while taking both functional and non-functional metrics into considerations. Our work firstly collects logs from the executable legacy system. Then, controller objects (COs) are identified as the key objects to converge strongly related subordinate objects (SOs). Subsequently, the relation between each pair of CO and SO is evaluated by a relation matrix from both the functional and non-functional perspective. We ultimately cluster classes(objects) into the microservices by optimizing the multi-objective of high-cohesion-low-coupling and load balance. The usefulness of the proposed approach is illustrated by applying to a case study.},
  doi       = {10.1109/ICSA47634.2020.00021},
}

@InProceedings{Lin2020a,
  author    = {Lin, Thomas and Leon-Garcia, Alberto},
  booktitle = {NOMS 2020 - 2020 IEEE/IFIP Network Operations and Management Symposium},
  title     = {Towards a Client-Centric QoS Auto-Scaling System},
  year      = {2020},
  month     = {April},
  pages     = {1-9},
  abstract  = {Many modern day cloud services are composites of multiple smaller services working correctly together. This design has become increasingly prevalent due to the rise of the microservices application architecture, as well as service chaining in Network Function Virtualization (NFV). Future composite applications and services will be deployed on multi-tier clouds where their constituent microservices may be geographically spread over different regions. To optimize the delivery of such composites, the constituent microservices must be placed in locations where their clients, which may be other microservices, are able to meet certain QoS constraints. We propose an architecture and present a prototype system for incorporating network metrics into the auto-scaling and scheduling decisions of cloud management systems. Given a service with QoS constraints, our system monitors the network metrics (e.g. latency and bandwidth) of their clients. If a particular client is unable to receive the required latency or bandwidth of the service, our system auto-scales the service and strategically places the new instance(s) in a location capable of meeting the service quality, and re-directs traffic to the new instance.},
  doi       = {10.1109/NOMS47738.2020.9110450},
  issn      = {2374-9709},
}

@InProceedings{Selmadji2020,
  author    = {Selmadji, Anfel and Seriai, Abdelhak-Djamel and Bouziane, Hinde Lilia and Oumarou Mahamane, Rahina and Zaragoza, Pascal and Dony, Christophe},
  booktitle = {2020 IEEE International Conference on Software Architecture (ICSA)},
  title     = {From Monolithic Architecture Style to Microservice one Based on a Semi-Automatic Approach},
  year      = {2020},
  month     = {March},
  pages     = {157-168},
  abstract  = {Due to its tremendous advantages, microservice architectural style has become an essential element for the development of applications deployed on the cloud and for those adopting the DevOps practices. Nevertheless, while microservices can be used to develop new applications, there are monolithic ones, that are not well adapted neither to the cloud nor to DevOps. Migrating these applications towards microservices appears as a solution to adapt them to both. In this context, we propose an approach aiming to achieve this objective by focusing on the step of microservices identification. The proposed identification, in this paper, is based on an analysis of the relationships between source code elements, their relationships with the persistent data manipulated in this code and finally the knowledge, often partial, of the architect concerning the system to migrate. A function that measures the quality of a microservice based on its ability to provide consistent service and its interdependence with others microservice in the resulting architecture was defined. Moreover, the architect recommendations are used, when available, to guide the identification process. The conducted experiment shows the relevance of the obtained microservices by our approach.},
  doi       = {10.1109/ICSA47634.2020.00023},
}

@InProceedings{Shiraishi2020,
  author    = {Shiraishi, Takashi and Noro, Masaaki and Kondo, Reiko and Takano, Yosuke and Oguchi, Naoki},
  booktitle = {2020 21st Asia-Pacific Network Operations and Management Symposium (APNOMS)},
  title     = {Real-time Monitoring System for Container Networks in the Era of Microservices},
  year      = {2020},
  month     = {Sep.},
  pages     = {161-166},
  abstract  = {Large-scale web services are increasingly adopting the microservice architecture that mainly utilizes container technologies. Microservices are operated on complex configured infrastructures, such as containers, virtual machines, and physical machines. To ensure service quality of microservices, it is important to monitor not only the quality of services but also the quality of the infrastructures utilized by the services. Therefore, the metrics of the infrastructure related with the services should be traced. An extended Berkeley Packet Filter (eBPF) is a relatively new Linux's function, which is effectively used as a sensor of container-network metrics. There are two key challenges in realizing the service-linked monitoring system. One challenge is making the full-stack topology between microservices, containers, and machines visible to set the sensor related with the services. Another challenge is dynamic sensor management that can relocate the sensor quickly after the topology's change. In this paper, we propose a real-time monitoring system that creates a full-stack topology and relocates the sensor in conjunction with events from a container orchestrator. The system enables a dynamic deployment of the sensors related with the monitored services.},
  doi       = {10.23919/APNOMS50412.2020.9237055},
  issn      = {2576-8565},
}

@InProceedings{Rossi2020,
  author    = {Rossi, Fabiana and Cardellini, Valeria and Presti, Francesco Lo},
  booktitle = {2020 28th International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems (MASCOTS)},
  title     = {Self-adaptive Threshold-based Policy for Microservices Elasticity},
  year      = {2020},
  month     = {Nov},
  pages     = {1-8},
  abstract  = {The microservice architecture structures an application as a collection of loosely coupled and distributed services. Since application workloads usually change over time, the number of replicas per microservice should be accordingly scaled at run-time. The most widely adopted scaling policy relies on statically defined thresholds, expressed in terms of system-oriented metrics. This policy might not be well-suited to scale multi-component and latency-sensitive applications, which express requirements in terms of response time. In this paper, we present a two-layered hierarchical solution for controlling the elasticity of microservice-based applications. The higher-level controller estimates the microservice contribution to the application performance, and informs the lower-level components. The latter accordingly scale the single microservices using a dynamic threshold-based policy. So, we propose MB Threshold and QL Threshold, two policies that employ respectively model-based and model-free reinforcement learning approaches to learn threshold update strategies. These policies can compute different thresholds for the different application components, according to the desired deployment objectives. A wide set of simulation results shows the benefits and flexibility of the proposed solution, emphasizing the advantages of using dynamic thresholds over the most adopted policy that uses static thresholds.},
  doi       = {10.1109/MASCOTS50786.2020.9285951},
  issn      = {2375-0227},
}

@InProceedings{Agarwal2021,
  author    = {Agarwal, Shivali and Sinha, Raunak and Sridhara, Giriprasad and Das, Pratap and Desai, Utkarsh and Tamilselvam, Srikanth and Singhee, Amith and Nakamuro, Hiroaki},
  booktitle = {2021 IEEE International Conference on Web Services (ICWS)},
  title     = {Monolith to Microservice Candidates using Business Functionality Inference},
  year      = {2021},
  month     = {Sep.},
  pages     = {758-763},
  abstract  = {In this paper, we propose a novel approach for monolith decomposition, that maps the implementation structure of a monolith application to a functional structure that in turn can be mapped to business functionality. First, we infer the classes in the monolith application that are distinctively representative of the business functionality in the application domain. This is done using formal concept analysis on statically determined code flow structures in a completely automated manner. Then, we apply a clustering technique, guided by the inferred representatives, on the classes belonging to the monolith to group them into different types of partitions, mainly: 1) functional groups representing microservice candidates, 2) a utility class group, and 3) a group of classes that require significant refactoring to enable a clean microservice architecture. This results in microservice candidates that are naturally aligned with the different business functions exposed by the application. A detailed evaluation on four publicly available applications show that our approach is able to determine better quality microservice candidates when compared to other existing state of the art techniques. We also conclusively show that clustering quality metrics like modularity are not reliable indicators of microservice candidate goodness.},
  doi       = {10.1109/ICWS53863.2021.00104},
}

@InProceedings{Ramesh2021,
  author    = {Ramesh, Srinivasan and Malony, Allen D. and Carns, Philip and Ross, Robert B. and Dorier, Matthieu and Soumagne, Jerome and Snyder, Shane},
  booktitle = {2021 IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  title     = {SYMBIOSYS: A Methodology for Performance Analysis of Composable HPC Data Services},
  year      = {2021},
  month     = {May},
  pages     = {35-45},
  abstract  = {Microservices are a powerful new way of building, customizing, and deploying distributed services owing to their flexibility and maintainability. Several large-scale distributed platforms have emerged to serve the growing needs of data-centric workloads and services in commercial computing. Concurrently, high-performance computing (HPC) systems and software are rapidly evolving to meet the demands of diversified applications and heterogeneity. The interplay of hardware factors, software configuration parameters, and the flexibility offered with a microservice architecture makes it nontrivial to estimate the optimal service instantiation for a given application workload. Further, this problem is exacerbated when considering that these services operate in a dynamic and heterogeneous HPC environment. An optimally integrated service can be vastly more performant than a haphazardly integrated one. Existing performance tools for HPC either fail to understand the request-response model of communication inherent to microservices or they operate within a narrow scope, limiting the insight that can be gleaned from employing them in isolation.We propose a methodology for integrated performance analysis of HPC microservices frameworks and applications called SYMBIOSYS. We describe its design and implementation within the context of the Mochi framework. This integration is achieved by combining distributed callpath profiling and tracing with a performance data exchange strategy that collects fine-grained, low-level metrics from the RPC communication library and network layers. The result is a portable, low-overhead performance analysis setup that provides a holistic profile of the dependencies among microservices and how they interact with the Mochi RPC software stack. Using HEPnOS, a production-quality Mochi data service, we demonstrate the low-overhead operation of SYMBIOSYS at scale and use it to identify the root causes of poorly performing service configurations.},
  doi       = {10.1109/IPDPS49936.2021.00013},
  issn      = {1530-2075},
}

@InProceedings{Tang2021,
  author    = {Tang, Ming and Xia, Fei and Zou, Haodong and Hu, Youjun and Liu, Jun and Liu, Sai},
  booktitle = {2021 IEEE 4th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)},
  title     = {Cloud platform load balancing mechanism for microservice architecture},
  year      = {2021},
  month     = {June},
  pages     = {435-439},
  volume    = {4},
  abstract  = {In response to the increase in request response latency under the microservice architecture, from the perspective of cloud platform load balancing, the average request latency and host load on the microservice chain are used as metrics to formalize the latency and problem environment. A request load balancing algorithm perceived by the microservice chain is proposed as the load balancing strategy of the load balancer. Simulation experiments prove that the algorithm in this paper can effectively reduce request latency in a complex microservice chain environment, and it can also maintain relatively good performance in an environment where instances are unevenly distributed, and for workloads between hosts.},
  doi       = {10.1109/IMCEC51613.2021.9482273},
  issn      = {2693-2776},
}

@InProceedings{Alipour2017,
  author    = {Alipour, Hanieh and Liu, Yan},
  booktitle = {2017 IEEE International Conference on Big Data (Big Data)},
  title     = {Online machine learning for cloud resource provisioning of microservice backend systems},
  year      = {2017},
  month     = {Dec},
  pages     = {2433-2441},
  abstract  = {Microservices are bundled and generating traffic on the backend systems that need to scale on demand. When microservices generate variant and unexpected, the challenge is to classify the workload on the backend systems and adjust the scaling policy to reflect the resource demand timely and accurately. In this paper, we propose a microservice architecture that encapsulates functions of monitoring metrics and learning workload pattern. Then this service architecture is used to predict the future workload for decision making on resource provisioning. We deploy two machine learning algorithms and predict the resource demand of the backend systems of microservices emulated by a Netflix workload benchmark application. This service architecture presents an integrated solution of implementing self-managing cloud data services under variant workload.},
  doi       = {10.1109/BigData.2017.8258201},
}

@InProceedings{Behrad2021,
  author    = {Behrad, Shanay and Espes, David and Bertin, Philippe and Phan, Cao-Thanh},
  booktitle = {2021 IEEE 7th International Conference on Network Softwarization (NetSoft)},
  title     = {Impacts of Service Decomposition Models on Security Attributes: A Case Study with 5G Network Repository Function},
  year      = {2021},
  month     = {June},
  pages     = {470-476},
  abstract  = {Microservices-based architectures gain more and more attention in industry and academia due to their tremendous advantages such as providing resiliency, scalability, composability, etc. To benefit from these advantages, a proper architectural design is very important. The decomposition model of services into microservices and the granularity of these microservices affect the different aspects of the system such as flexibility, maintainability, performance, and security. An inappropriate service decomposition into microservices (improper granularity) may increase the attack surface of the system and lower its security level. In this paper, first, we study the probability of compromising services before and after decomposition. Then we formulate the impacts of possible service decomposition models on confidentiality, integrity, and availability attributes of the system. To do so, we provide equations for measuring confidentiality, integrity, and availability risks of the decomposed services in the system. It is also shown that the number of entry points to the decomposed services and the size of the microservices affect the security attributes of the system. As a use case, we propose three different service decomposition models for the 5G NRF (Network Repository Function) and calculate the impacts of these decomposition models on the confidentiality, integrity, and availability of the system using the provided equations.},
  doi       = {10.1109/NetSoft51509.2021.9492620},
  issn      = {2693-9789},
}

@InProceedings{Toledo2021,
  author    = {de Toledo, Saulo S. and Martini, Antonio and Sjøberg, Dag I.K. and Przybyszewska, Agata and Frandsen, Johannes Skov},
  booktitle = {2021 47th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)},
  title     = {Reducing Incidents in Microservices by Repaying Architectural Technical Debt},
  year      = {2021},
  month     = {Sep.},
  pages     = {196-205},
  abstract  = {Architectural technical debt (ATD) may create a substantial extra effort in software development, which is called interest. There is little evidence about whether repaying ATD in microservices reduces such interest. Objectives: We wanted to conduct a first study on investigating the effect of removing ATD on the occurrence of incidents in a microservices architecture. Method: We conducted a quantitative and qualitative case study of a project with approximately 1000 microservices in a large, international financing services company. We measured and compared the number of software incidents of different categories before and after repaying ATD. Results: The total number of incidents was reduced by 84%, and the numbers of critical- and high-priority incidents were both reduced by approximately 90% after the architectural refactoring. The number of incidents in the architecture with the ATD was mainly constant over time, but we observed a slight increase of low priority incidents related to inaccessibility and the environment in the architecture without the ATD. Conclusion: This study shows evidence that refactoring ATDs, such as lack of communication standards, poor management of dead-letter queues, and the use of inadequate technologies in microservices, reduces the number of critical- and high-priority incidents and, thus, part of its interest, although some low priority incidents may increase.},
  doi       = {10.1109/SEAA53835.2021.00033},
}

@InProceedings{Tseng2019,
  author    = {Tseng, Yuchia and Imadali, Sofiane and Houatra, Drissa and Aravinthan, Gopalasingham and Thomas, Laurent},
  booktitle = {IEEE INFOCOM 2019 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)},
  title     = {Demo Abstract: Monitoring Virtualized Telco Services for Multisided Platforms with SQL-like Query},
  year      = {2019},
  month     = {April},
  pages     = {949-950},
  abstract  = {The Telco ecosystem transformation towards cloud-native network services enables constructing an integrative platform business model in the form of a Multi-Sided Platform (MSP) leveraging microservice-based Virtualized Network Function architecture. In particular, MSP based architectures enable a multi-organizational ecosystem with increased automation possibilities for carrier-grade services creation and operations. We present a microservice-based monitoring system for virtualized Telco services based on OpenAirInterface (OAI) with an SQL-like query manager for metrics. We demonstrate two monitoring scenarios: (1) Average receiving (rx) PDU in bytes at MAC layer from the targeted user equipment (UE). (2) Finding the UE who consumes the most Physical Resource Blocks (PRB) within a specific time interval for the uplink and downlink transmission.},
  doi       = {10.1109/INFCOMW.2019.8845242},
}

@InProceedings{Hou2021,
  author    = {Hou, Chuanjia and Jia, Tong and Wu, Yifan and Li, Ying and Han, Jing},
  booktitle = {2021 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)},
  title     = {Diagnosing Performance Issues in Microservices with Heterogeneous Data Source},
  year      = {2021},
  month     = {Sep.},
  pages     = {493-500},
  abstract  = {Microservices architecture is vulnerable to performance issues due to its highly fine-grained decomposition of an application. To diagnose performance issues in microservices, existing works utilize system metrics as the specific indicator and do a lot of heavy computation such as building service dependency graphs during the diagnosing process.To improve the effectiveness and efficiency of issue diagnosing, we propose PDiagnose, a practical approach using multiple data sources including metrics, logs and traces jointly to diagnose performance issues in microservices systems. Through combining lightweight unsupervised anomaly detection algorithms and vote-based issue localization strategy, PDiagnose is application-agnostic and can localize root cause indicators accurately. Our evaluation on two public-available datasets shows that PDiagnose can achieve an overall recall of 84.8%, outperforming the best baseline approach. Meanwhile, the diagnosis duration of PDiagnose is also promising.},
  doi       = {10.1109/ISPA-BDCloud-SocialCom-SustainCom52081.2021.00074},
}

@InProceedings{Song2021,
  author    = {Song, Da and Yuan, Long and Zhao, Weixing and Yu, Quanxi and Du, Jie and Pan, Kaiyan},
  booktitle = {2021 China International Conference on Electricity Distribution (CICED)},
  title     = {Cloud-Edge Computing Resource Collaborative Optimization Method for Power Distribution Fault Analysis Service},
  year      = {2021},
  month     = {April},
  pages     = {627-632},
  abstract  = {The cloud-edge computing architecture of distribution network can meet the computing and communication requirements of most novel and traditional distribution services. However, the demand for computing resources of fault service is often greater than the resource capacity of edge computing terminal. Therefore, based on the cloud-edge collaborative architecture, this paper proposes a collaborative optimization method of cloud and edge computing resources for fault service in distribution network. Firstly, this paper elaborates the characteristics of fault service in distribution network, and describes the possibility of cloud-edge collaborative information interaction and microservice offloading based on container technology. Then, a cloud-edge collaborative service computing model and the microservice model of fault service are established. According to the offloading mechanism, a microservice offloading decision optimization model is established, which take the system operation cost and calculation delay as the comprehensive measuring index. Finally, the method proposed in this paper is simulated by MATLAB, and the simulation results show that this method can effectively reduce the microservice response time of distribution network and meet the computing resource requirements of fault service.},
  doi       = {10.1109/CICED50259.2021.9556733},
  issn      = {2161-749X},
}

@InProceedings{Rossi2020a,
  author    = {Rossi, Fabiana and Cardellini, Valeria and Presti, Francesco Lo},
  booktitle = {2020 IEEE International Conference on Autonomic Computing and Self-Organizing Systems (ACSOS)},
  title     = {Hierarchical Scaling of Microservices in Kubernetes},
  year      = {2020},
  month     = {Aug},
  pages     = {28-37},
  abstract  = {In the last years, we have seen the increasing adoption of the microservice architectural style where applications satisfy user requests by invoking a set of independently deployable services. Software containers and orchestration tools, such as Kubernetes, have simplified the development and management of microservices. To manage containers' horizontal elasticity, Kubernetes uses a decentralized threshold-based policy that requires to set thresholds on system-oriented metrics (i.e., CPU utilization). This might not be well-suited to scale latency-sensitive applications, which need to express requirements in terms of response time. Moreover, being a fully decentralized solution, it may lead to frequent and uncoordinated application reconfigurations. In this paper, we present me-kube (Multi-level Elastic Kubernetes), a Kubernetes extension that introduces a hierarchical architecture for controlling the elasticity of microservice-based applications. At higher level, a centralized per-application component coordinates the run-time adaptation of subordinated distributed components, which, in turn, locally control the adaptation of each microservice. Then, we propose novel proactive and reactive hierarchical control policies, based on queuing theory. To show that me-kube provides general mechanisms, we also integrate reinforcement learning-based scaling policies. Using me-kube, we perform a large set of experiments, aimed to show the advantages of a hierarchical control over the default Kubernetes autoscaler.},
  doi       = {10.1109/ACSOS49614.2020.00023},
}

@InProceedings{Ray2020,
  author    = {Ray, Kaustabha and Banerjee, Ansuman and Narendra, Nanjangud C.},
  booktitle = {2020 IEEE/ACM Symposium on Edge Computing (SEC)},
  title     = {Proactive Microservice Placement and Migration for Mobile Edge Computing},
  year      = {2020},
  month     = {Nov},
  pages     = {28-41},
  abstract  = {In recent times, Mobile Edge Computing (MEC) has emerged as a new paradigm allowing low-latency access to services deployed on edge nodes offering computation, storage and communication facilities. Vendors deploy their services on MEC servers to improve performance and mitigate network latencies often encountered in accessing cloud services. A service placement policy determines which services are deployed on which MEC servers. A number of mechanisms exist in literature to determine the optimal placement of services considering different performance metrics. However, for applications designed as microservice workflow architectures, service placement schemes need to be re-examined through a different lens owing to the inherent interdependencies which exist between microservices. Indeed, the dynamic environment, with stochastic user movement and service invocations, along with a large placement configuration space makes microservice placement in MEC a challenging task. Additionally, owing to user mobility, a placement scheme may need to be recalibrated, triggering service migrations to maintain the advantages offered by MEC. Existing microservice placement and migration schemes consider on-demand strategies. In this work, we take a different route and propose a Reinforcement Learning based proactive mechanism for microservice placement and migration. We use the San Francisco Taxi dataset to validate our approach. Experimental results show the effectiveness of our approach in comparison to other state-of-the-art methods.},
  doi       = {10.1109/SEC50012.2020.00010},
}

@InProceedings{Valdivia2019,
  author    = {Valdivia, José A. and Limón, Xavier and Cortes-Verdin, Karen},
  booktitle = {2019 7th International Conference in Software Engineering Research and Innovation (CONISOFT)},
  title     = {Quality attributes in patterns related to microservice architecture: a Systematic Literature Review},
  year      = {2019},
  month     = {Oct},
  pages     = {181-190},
  abstract  = {Microservices is an interesting option for those who want to migrate their systems to improve performance, maintainability, scalability, and interoperability. Microservice architecture is a collection of self-sufficient services working together to provide functionalities. Nowadays, there are many options to build microservices, some of them are lead by patterns. However, the mapping between quality attributes and patterns is not clear yet. This systematic literature review presents a microservice pattern collection, it describes their benefits and the association between patterns and quality attributes. Finally, some metrics of quality attributes are identified.},
  doi       = {10.1109/CONISOFT.2019.00034},
}

@InProceedings{AlDebagy2020a,
  author    = {Al-Debagy, Omar and Martinek, Péter},
  booktitle = {2020 IEEE 15th International Conference of System of Systems Engineering (SoSE)},
  title     = {Extracting Microservices’ Candidates from Monolithic Applications: Interface Analysis and Evaluation Metrics Approach},
  year      = {2020},
  month     = {June},
  pages     = {289-294},
  abstract  = {There is a migration trend toward microservices architecture coming from the monolithic applications. This research proposes a decomposition method that extracts microservices’ candidates through analyzing the application programming interface in order to extract the operations and the parameters. Then the operation names are converted into word representations using word embedding models. Next, semantically similar operations are clustered together to provide a microservice’ candidate. Additional step is to evaluate the proposed candidate using cohesion and complexity metrics. The proposed algorithm improved the decomposition approach for big applications but did not affect the decomposition of smaller applications.},
  doi       = {10.1109/SoSE50414.2020.9130466},
}

@InProceedings{Guaman2018,
  author    = {Guaman, Daniel and Yaguachi, Lady and Samanta, Cueva C. and Danilo, Jaramillo H. and Soto, Fernanda},
  booktitle = {2018 13th Iberian Conference on Information Systems and Technologies (CISTI)},
  title     = {Performance evaluation in the migration process from a monolithic application to microservices},
  year      = {2018},
  month     = {June},
  pages     = {1-8},
  abstract  = {Microservices are considered as a software architecture that allows the decomposition of a system, its components or its functionalities into a set of small services, which are implemented, deployed and managed independently. In this study, the models that allow migrating a Monolith to Microservices such as NGINX and IBM are analyzed. From these models, activities that allow such migration are carefully selected and identified. In order to implement and evaluate the activities proposed in those models, an application that initially does not have any structure at the design and coding level (using PHP programming language) is applied. Then, the application's coding language changes to Java and the classes and libraries are distributed into packages. Subsequently, as it is suggested in the models, services are identified and implemented using RESTful Web Services to finally implement the microservices using technologies such as Spring Boot, Eureka, and Zuul. In the migration process, the application under study is modified at the code and design level, including patterns such as Singleton, Façade, Strangler, Single Service per Host, Service Discovery, and API Gateway, which are used to evaluate performance as a quality attribute in each migration phase. In order to obtain the performance related metrics and to analyze the advantages and disadvantages of each migration phase, Apache JMeter as tool is used. This tool is set up to generate results regarding the use of resources such as CPU, memory, network, and database access. Finally, the results show scenarios of several concurrent users who access to consult records in the database that uses the aforementioned application in each migration phase.},
  doi       = {10.23919/CISTI.2018.8399148},
}

@Article{Xu2021a,
  author   = {Xu, Rongxu and Jin, Wenquan and Kim, Dohyeun},
  journal  = {IEEE Access},
  title    = {Enhanced Service Framework Based on Microservice Management and Client Support Provider for Efficient User Experiment in Edge Computing Environment},
  year     = {2021},
  issn     = {2169-3536},
  pages    = {110683-110694},
  volume   = {9},
  abstract = {Leveraging the edge computing paradigm, computing resources are deployed in the network edge to provide heterogeneous services. Edge computing delivers sensing and actuating services to the Internet from the constrained Internet of Things (IoT) devices. Meanwhile, management of various elements is provided by offloading sufficient computing and storage to the edge of the networks for the IoT environments such as home, factory, and private spaces without cloud servers. In this paper, we propose an enhanced service framework based on microservice management and client support provider for efficient user experiments in the edge computing environment. For providing the edge computing service and management in the network edge, this paper presents an edge-computing architecture that provides various functions through microservice modules on the edge platform engine. Through the microservices, the interfaces are provided to the client to access the device, data, and additional services. Using Docker, the microservice modules are deployed in the edge platform to provide the services. However, the services and management functions need to be presented to the clients based on the friendly user interfaces. For providing the user interfaces of the services and Docker engine to the clients, the client support service provider is developed and deployed in the network edge based on the edge platform. Therefore, the proposed edge platform provides the services and management to the users for accessing the resources and functions through visualized interfaces in the IoT environment based on edge computing. The performance of our proposed system can be checked through the test result screen and delay time. Compared to controlling edge computing by using a command-line tool for users, we made it easy for general users who are not computer savvy to access edge services through a graphic user interface. And by measuring the delay time and comparing the execution time, it can be seen that the proposed system operates faster.},
  doi      = {10.1109/ACCESS.2021.3102595},
}

@InProceedings{Cebotari2020,
  author    = {Cebotari, Vadim and Kugele, Stefan},
  booktitle = {2020 IEEE Intelligent Vehicles Symposium (IV)},
  title     = {Playground for Early Automotive Service Architecture Design and Evaluation},
  year      = {2020},
  month     = {Oct},
  pages     = {1349-1356},
  abstract  = {Context: We consider the structure of service-oriented architectures in vehicular software. Aim: We aim at evaluating the structure and grouping of service architectures. Method: We propose and discuss architectural metrics tailored towards automotive service-oriented architectures. We apply the metrics on an adaptive cruise control case example extracted from the AUTOSAR standard. Results: The application of the proposed metrics to two different service groupings for ACC points clearly to the same service grouping that we consider, after a thorough analysis, to be better with respect to coupling and cohesion attributes. Conclusion: We demonstrate the usefulness of proposed service group metrics in early design phases of the development process and validate the metrics on the case example of an adaptive cruise control function.},
  doi       = {10.1109/IV47402.2020.9304633},
  issn      = {2642-7214},
}

@InProceedings{Samir2019,
  author    = {Samir, Areeg and Pahl, Claus},
  booktitle = {2019 7th International Conference on Future Internet of Things and Cloud (FiCloud)},
  title     = {DLA: Detecting and Localizing Anomalies in Containerized Microservice Architectures Using Markov Models},
  year      = {2019},
  month     = {Aug},
  pages     = {205-213},
  abstract  = {Container-based microservice architectures are emerging as a new approach for building distributed applications as a collection of independent services that works together. As a result, with microservices, we are able to scale and update their applications based on the load attributed to each service. Monitoring and managing the load in a distributed system is a complex task as the degradation of performance within a single service will cascade reducing the performance of other dependent services. Such performance degradations may result in anomalous behaviour observed for instance for the response time of a service. This paper presents a Detection and Localization system for Anomalies (DLA) that monitors and analyzes performance-related anomalies in container-based microservice architectures. To evaluate the DLA, an experiment is done using R, Docker and Kubernetes, and different performance metrics are considered. The results show that DLA is able to accurately detect and localize anomalous behaviour.},
  doi       = {10.1109/FiCloud.2019.00036},
}

@InProceedings{Orduz2019,
  author    = {Orduz, Juan S. and Orozco, Gabriel D. and Tobar-Arteaga, Carlos H. and Rendon, Oscar Mauricio Caicedo},
  booktitle = {2019 IEEE 44th LCN Symposium on Emerging Topics in Networking (LCN Symposium)},
  title     = {μvIMS: A Finer-Scalable Architecture Based on Microservices},
  year      = {2019},
  month     = {Oct},
  pages     = {141-148},
  abstract  = {The steps toward all over IP have defined to the IP Multimedia Subsystem (IMS) as the de facto technology for end-to-end multimedia service provisioning in 5G. However, the unpredictable growth of users in 5G requires to improve IMS scalability to handle dynamic user traffic. Several works have addressed this issue by introducing auto-scaling mechanisms in virtualized IMS (vIMS) architectures. However, the current vIMS deployments use monolithic designs that do not allow finer-scalability. In this paper, we present μvIMS, an architecture that uses microservices to provide finer-scalability and more effective resource usage than regular monolithic design. To test our architecture, we evaluate μvIMS prototype regarding CPU usage, RAM usage, Successful Call Rate (SCR), and latency metrics. Our test results reveal that μvIMS achieves a higher SCR, using the available resources effectively with a negligible latency increasing. Thus, we can state that dividing the monolithic vIMS architecture in microservices allows providing finer-scalability.},
  doi       = {10.1109/LCNSymposium47956.2019.9000664},
}

@InProceedings{Wu2021,
  author    = {Wu, Li and Tordsson, Johan and Bogatinovski, Jasmin and Elmroth, Erik and Kao, Odej},
  booktitle = {2021 IEEE/ACM International Workshop on Cloud Intelligence (CloudIntelligence)},
  title     = {MicroDiag: Fine-grained Performance Diagnosis for Microservice Systems},
  year      = {2021},
  month     = {May},
  pages     = {31-36},
  abstract  = {Microservice architecture has emerged as a popular pattern for developing large-scale applications for its benefits of flexibility, scalability, and agility. However, the large number of services and complex dependencies make it difficult and time-consuming to diagnose performance issues. We propose Micro-Diag, an automated system to localize root causes of performance issues in microservice systems at a fine granularity, including not only locating the faulty component but also discovering detailed information for its abnormality. MicroDiag constructs a component dependency graph and performs causal inference on diverse anomaly symptoms to derive a metrics causality graph, which is used to infer root causes. Our experimental evaluation on a microservice benchmark running in a Kubernetes cluster shows that MicroDiag localizes root causes well, with 97% precision of the top 3 most likely root causes, outperforming state-of-the-art methods by at least 31.1%.},
  doi       = {10.1109/CloudIntelligence52565.2021.00015},
}

@InProceedings{Choochotkaew2021,
  author    = {Choochotkaew, Sunyanan and Chiba, Tatsuhiro and Trent, Scott and Amaral, Marcelo},
  booktitle = {2021 IEEE 14th International Conference on Cloud Computing (CLOUD)},
  title     = {Run Wild: Resource Management System with Generalized Modeling for Microservices on Cloud},
  year      = {2021},
  month     = {Sep.},
  pages     = {609-618},
  abstract  = {Microservice architecture competes with the traditional monolithic design by offering benefits of agility, flexibility, reusability resilience, and ease of use. Nevertheless, due to the increase in internal communication complexity, care must be taken for resource-usage scaling in harmony with placement scheduling, and request balancing to prevent cascading performance degradation across microservices. We prototype Run Wild, a resource management system that controls all mechanisms in the microservice-deployment process covering scaling, scheduling, and balancing to optimize for desirable performance on the dynamic cloud driven by an automatic, united, and consistent deployment plan. In this paper, we also highlight the significance of co-location aware metrics on predicting the resource usage and computing the deployment plan. We conducted experiments with an actual cluster on the IBM Cloud platform. RunWild reduced the 90th percentile response time by 11% and increased average throughput by 10% with more than 30% lower resource usage for widely used autoscaling benchmarks on Kubernetes clusters.},
  doi       = {10.1109/CLOUD53861.2021.00079},
  issn      = {2159-6190},
}

@InProceedings{Ramesh2021a,
  author    = {Ramesh, Srinivasan and Ross, Robert and Dorier, Matthieu and Malony, Allen and Carns, Philip and Huck, Kevin},
  booktitle = {2021 IEEE 28th International Conference on High Performance Computing, Data, and Analytics (HiPC)},
  title     = {SYMBIOMON: A High-Performance, Composable Monitoring Service},
  year      = {2021},
  month     = {Dec},
  pages     = {332-342},
  abstract  = {High-performance computing (HPC) software is evolving to support an increasingly diverse set of applications and heterogeneous hardware architectures. As part of this evolution, the construction of scientific software has shifted from a traditional monolithic message passing interface executable model to a coupled, services-style model in which simulations run alongside a host of distributed HPC data services within the same batch job allocation. Microservices have emerged as a powerful new way to build these distributed data services through a composition model. However, performance analysis of composed microservices is a daunting challenge. It requires collecting, monitoring, aggre-gating, and exporting performance data from multiple sources. To be effective, the design of such a monitoring solution must allow for seamless integration into HPC applications and distributed services alike, be scalable, operate with a low overhead, and take advantage of the HPC platform. We propose SYMBIOMON, a monitoring service that is built by composing high-performance microservices. We describe its design and implementation within the context of the Mochi framework. SYMBIOMON combines a time-series data model with existing Mochi data services to collect, aggregate, and export performance metrics in a distributed manner. SYMBIOMON enables seamless, low-overhead monitoring and analysis of data services and HPC applications alike. Using HEPnOS, a production-quality Mochi data service, we demonstrate the use of SYMBIOMON to identify better service configurations.},
  doi       = {10.1109/HiPC53243.2021.00047},
  issn      = {2640-0316},
}

@InProceedings{Do2017,
  author    = {Do, Nam H. and Van Do, Tien and Thi Tran, Xuan and Farkas, Lóránt and Rotter, Csaba},
  booktitle = {2017 20th Conference on Innovations in Clouds, Internet and Networks (ICIN)},
  title     = {A scalable routing mechanism for stateful microservices},
  year      = {2017},
  month     = {March},
  pages     = {72-78},
  abstract  = {Scalability is an important requirement in the development and the operation of applications in a cloud environment. To handling heavy concurrency in the input load, many design-related and operational factors should be considered. The microservice architecture patterns provide better means to increase the scalability than traditional software architecture patterns. However, certain aspects of applications such as the need to persist/maintain the application state require additional measures in the design and the supporting mechanism. We propose a scalable routing mechanism for applications designed according to the microservice architecture. In particular, a cloud infrastructure resource reservation application has been designed with some stateful services. The proposed approach maintains a good scalability, which provides a mean to achieve the efficient usage of the infrastructure resources.},
  doi       = {10.1109/ICIN.2017.7899252},
  issn      = {2472-8144},
}

@InProceedings{Pulparambil2018,
  author    = {Pulparambil, Supriya and Baghdadi, Youcef and Al-Hamdani, Abdullah and Al-Badawi, Mohammed},
  booktitle = {2018 9th International Conference on Computing, Communication and Networking Technologies (ICCCNT)},
  title     = {Service Design Metrics to Predict IT-Based Drivers of Service Oriented Architecture Adoption},
  year      = {2018},
  month     = {July},
  pages     = {1-7},
  abstract  = {The key factors for deploying successful services is centered on the service design practices adopted by an enterprise. The design level information should be validated and measures are required to quantify the structural attributes. The metrics at this stage will support an early discovery of design flaws and help designers to predict the capabilities of service oriented architecture (SOA) adoption. In this work, we take a deeper look at how we can forecast the key SOA capabilities infrastructure efficiency and service reuse from the service designs modeled by SOA modeling language. The proposed approach defines metrics based on the structural and domain level similarity of service operations. The proposed metrics are analytically validated with respect to software engineering metrics properties. Moreover, a tool has been developed to automate the proposed approach and the results indicate that the metrics predict the SOA capabilities at the service design stage. This work can be further extended to predict the business based capabilities of SOA adoption such as flexibility and agility.},
  doi       = {10.1109/ICCCNT.2018.8494072},
}

@InProceedings{Gamage2021,
  author    = {Gamage, Isuru Udara Piyadigama and Perera, Indika},
  booktitle = {2021 Moratuwa Engineering Research Conference (MERCon)},
  title     = {Using dependency graph and graph theory concepts to identify anti-patterns in a microservices system: A tool-based approach},
  year      = {2021},
  month     = {July},
  pages     = {699-704},
  abstract  = {Microservice architecture (MSA) based application developments are becoming the common trend in implementing large-scale applications. Unlike the traditional monolith applications, MSA applications are composed of many services hence there is an immense possibility of anti-patterns introduced into the system. To identify these design problems, a detailed analysis of the architecture needs to be performed. We see great potential for adopting graph concepts and algorithms in this regard. However, the few tools proposed by existing work to find anti-patterns that adopt graph concepts are not up to providing developers with adequate statistical information such as metrics along with visualization techniques or they are not fully automated. In this research, we present a tool-based solution for this problem which is capable of utilizing traced data of an MSA system to generate dependency graphs and thereby extract metrics using graph theory concepts and algorithms. We analyze a sample MSA system for anti-patterns with the tool. To verify the usability of the tool further, a group of developers also analyze an open-source system with the tool.},
  doi       = {10.1109/MERCon52712.2021.9525743},
  issn      = {2691-364X},
}

@InProceedings{Brusakova2020,
  author    = {Brusakova, I. A.},
  booktitle = {2020 XXIII International Conference on Soft Computing and Measurements (SCM)},
  title     = {Metrics for Cognitive Management of IT Services},
  year      = {2020},
  month     = {May},
  pages     = {259-261},
  abstract  = {The article presents metrics for managing IT services in a service-oriented architecture of the information system. Cognitive management of the effectiveness of IT services is considered on a variety of ICT infrastructure management metrics, information system management metrics, IT service management metrics. The necessary components of the formation of an analytical platform for the cognitive management of IT services in the EIM environment for SAP BI (Business Objects Business Intelligent) are considered. A model of cognitive management of IT services using key performance indicators (KPIs) for managing IT service metrics is presented.},
  doi       = {10.1109/SCM50615.2020.9198750},
}

@InProceedings{Wang2017a,
  author    = {Wang, Hanzhang and Kessentini, Marouane and Hassouna, Taghreed and Ouni, Ali},
  booktitle = {2017 IEEE International Conference on Web Services (ICWS)},
  title     = {On the Value of Quality of Service Attributes for Detecting Bad Design Practices},
  year      = {2017},
  month     = {June},
  pages     = {341-348},
  abstract  = {Service-Oriented Architectures (SOAs) successfully evolve over time to update existing exposed features to the users and fix possible bugs. This evolution process may have a negative impact on the design quality of Web services. Recent studies addressed the problem of Web service antipatterns detection (bad design practices). To the best of our knowledge, these studies focused only on the use of metrics extracted from the implementation details (source code) of the interface and the services. However, the quality of service (QoS) metrics, widely used to evaluate the overall performance, are never used in the context of Web service antipatterns detection. We start, in this work, from the hypothesis that these bad design practices may impact several QoS metrics such as the response time. Furthermore, the source code metrics of services may not be always available. Without the consideration of these QoS metrics, the current detection processes of antipatterns will still lack the integration of symptoms that could be extracted from the usage of services. In this paper, we propose an automated approach to generate Web service defect detection rules that consider not only the code/interface level metrics but also the quality of service attributes. Through multi-objective optimization, the proposed approach generates solutions (detection rules) that maximize the coverage of antipattern examples and minimize the coverage of well-designed service examples. An empirical validation is performed with eight different common types of Web design defects to evaluate our approach. We compared our results with three other state of the art techniques which are not using QoS metrics. The statistical analysis of the obtained results confirm that our approach outperforms other techniques and generates detection rules that are more meaningful from the services' user perspective.},
  doi       = {10.1109/ICWS.2017.126},
}

@InProceedings{AlvarezQ.2019,
  author    = {Alvarez Q., Juan M. and Sanabria O., John A. and Garcia M., Jose I},
  booktitle = {2019 IEEE Latin American Test Symposium (LATS)},
  title     = {Microservices-based architecture for fault diagnosis in tele-rehabilitation equipment operated via Internet},
  year      = {2019},
  month     = {March},
  pages     = {1-6},
  abstract  = {This paper presents the design of a microservices based architecture allows early fault detection and diagnosis on a remote controlled physical rehabilitation machine using the Internet as a communication channel. Aforementioned architecture is composed of three layers: the low layer which collects variables from the rehabilitation machine components, using Internet of Things protocols. The middle layer which analyses the provided variables and diagnoses the component status, using fuzzy logic. And finally, the upper layer which makes decisions depending on the diagnosis data. The proposed architecture is suitable for heterogeneous systems.This paper also shows how this architecture fulfills the specific and rigorous safety measures for critical mission devices like technical aids for health-care.},
  doi       = {10.1109/LATW.2019.8704556},
  issn      = {2373-0862},
}

@InProceedings{Gomathy2014,
  author    = {Gomathy, C. K. and Rajalakshmi, S.},
  booktitle = {Second International Conference on Current Trends In Engineering and Technology - ICCTET 2014},
  title     = {A software quality metric performance of professional management in service oriented architecture},
  year      = {2014},
  month     = {July},
  pages     = {41-47},
  abstract  = {Service-oriented architecture (SOA) is generally the way of containing and examines to develop the information management needs in order to make dealing responsive and elastic in pace with forceful quality conditions. Adopting, implementing and running SOA require considerable thought and effort in order to distribute high-quality metrics data and become conscious the complete assessment of SOA. In this paper, inspect the sequentially and quality related metrics issues that have been investigated organizations in order to uncover the activities in regard to information quality within their initiatives of implementing SOA. In the succession of quality behavior that solve certain information quality and maintenance, development issues therefore, can be enthusiastically established across any industry to support the building of high quality and then making SOA solutions. In current days service oriented architecture design is also incorporated and potentially distributed with the quality metrics and to perform a superior evaluation of the representation.},
  doi       = {10.1109/ICCTET.2014.6966260},
}

@InProceedings{Alnahdi2017,
  author    = {Alnahdi, Amany and Liu, Shih-Hsi},
  booktitle = {2017 IEEE International Conference on Services Computing (SCC)},
  title     = {Identifying Characteristic Attributes for Estimating Cost of Service in Service Oriented Architecture},
  year      = {2017},
  month     = {June},
  pages     = {467-470},
  abstract  = {Web services are software modules that provide interoperability over a network. Web services provide Web service users platform independence while using software. It enables businesses to collaborate by using Web services from Web service providers. Estimating a Cost of Service (CoS) is essential when pricing, selecting, and monitoring a Web service. The concept of cost is not restricted to financial value of technology hardware and software. The cost concept can also include time, usability, and maintenance. Cost of a Web service can be estimated by identifying the attributes of cost from the perspective of different stakeholders such as Web service provider, Web service consumer, Web service repository moderator, and Web service policy maker. In addition, analyzing different roles in Service Oriented Architecture (SOA) will further provide more knowledge about different perspectives of cost concepts in SOA. This paper addresses the essential attributes of estimating cost of a Web service. Moreover, this paper specifies attributes of measuring CoS, defines these attributes, and defines metrics and units of these attributes. Additionally, it provides further hierarchy classification of Web service cost concepts. It also provides a model for evaluating Web service cost based on different cost criteria. By measuring CoS, Web service stakeholders will be able to estimate an accurate value to the CoS.},
  doi       = {10.1109/SCC.2017.66},
  issn      = {2474-2473},
}

@InProceedings{White2019,
  author    = {White, Gary and Palade, Andrei and Cabrera, Christian and Clarke, Siobhán},
  booktitle = {2019 IEEE International Conference on Pervasive Computing and Communications (PerCom},
  title     = {Autoencoders for QoS Prediction at the Edge},
  year      = {2019},
  month     = {March},
  pages     = {1-9},
  abstract  = {In service-oriented architectures, collaborative filtering is a key technique for service recommendation based on QoS prediction. Matrix factorisation has emerged as one of the main approaches for collaborative filtering as it can handle sparse matrices and produces good prediction accuracy. However, this process is resource-intensive and training must take place in the cloud, which can lead to a number of issues for user privacy and being able to update the model with new QoS information. Due to the time-varying nature of QoS it is essential to update the QoS prediction model to ensure that it is using the most recent values to maintain prediction accuracy. The request time, which is the time for a middleware to submit a user's information and receive QoS metrics for a candidate services is also important due to the limited time during dynamic service adaptations to choose suitable replacement services. In this paper we propose a stacked autoencoder with dropout on a deep edge architecture and show how this can be used to reduce training and request time compared to traditional matrix factorisation algorithms, while maintaining predictive accuracy. To evaluate the accuracy of the algorithms we compare the actual and predicted QoS values using standard error metrics such as MAE and RMSE. In addition, we propose an alternative evaluation technique using the predictions as part of a service composition and measuring the impact that the predictions have on the response time and throughput of the final composition. This more clearly shows the direct impact that these algorithms will have in practice.},
  doi       = {10.1109/PERCOM.2019.8767397},
  issn      = {2474-249X},
}

@InProceedings{Bora2015,
  author    = {Bora, Abhijit and Bezboruah, Tulshi},
  booktitle = {2015 IEEE International Conference on Research in Computational Intelligence and Communication Networks (ICRCICN)},
  title     = {Some aspects of QoS for interoperability of multi service multi functional service oriented computing},
  year      = {2015},
  month     = {Nov},
  pages     = {363-368},
  abstract  = {Quality of service is the key indicator for service oriented architectures, because it directly expresses the operability and computational nature of the system. As such, we propose a quality evaluation framework for multi service multi functional hierarchical SOAP based web service. The overall interoperable quality is evaluated through load testing using Mercury Load Runner with Apache Tomcat web server and MySQL database engine. The recorded quality metrics are analyzed statistically. We present here in detail the architecture, observed metrics and analyzed results of the service oriented computing to validate the acceptability of the evaluation framework.},
  doi       = {10.1109/ICRCICN.2015.7434265},
}

@InProceedings{Park2018,
  author    = {Park, Youngki and Yang, Hyunsik and Kim, Younghan},
  booktitle = {2018 International Conference on Information and Communication Technology Convergence (ICTC)},
  title     = {Performance Analysis of CNI (Container Networking Interface) based Container Network},
  year      = {2018},
  month     = {Oct},
  pages     = {248-250},
  abstract  = {The increasing significance of lightweight cloud infrastructure for microservices cannot be overstated. This has led many researchers to propose container based virtualized computing services. Specifically, for networks, Container Networking Interface technologies are proposed to connect heterogeneous network services between virtual-machine based clouds and containers. In order to improve network performance of cloud systems, a comparison with detailed design and performance verification of network configuration using CNI technologies is required. In this paper, centering on various CNI technologies, we designed network architectures with OpenStack cloud platform and Kubernetes container management environment, and subsequently measured network performance for each design. The results of the evaluation are useful to provide guidelines for containerized cloud system deployment.},
  doi       = {10.1109/ICTC.2018.8539382},
  issn      = {2162-1233},
}

@InProceedings{Liu2020,
  author    = {Liu, Bo and Betancourt, Victor Pazmino and Zhu, Yimeng and Becker, Jürgen},
  booktitle = {2020 IEEE International Symposium on Systems Engineering (ISSE)},
  title     = {Towards an On-Demand Redundancy Concept for Autonomous Vehicle Functions using Microservice Architecture},
  year      = {2020},
  month     = {Oct},
  pages     = {1-5},
  abstract  = {More and more functionalities will be deployed on heterogeneous devices in the vehicle for future autonomous driving. These devices will be connected not only within the vehicle but also to the internet to receive information or consume services provided by other vehicles or road-side units. Even some functions could be offloaded to the cloud infrastructure. However, this high connectivity also means more cyber-security issues for future autonomous driving cars. As cyber-attacks become a more serious issue for the future automotive industry, keeping high availability of safety-critical and non-safety-critical vehicle functions when connected devices in the vehicle are being attacked is an important and challenging task. In this paper, we propose an on-demand redundancy concept to get high availability for autonomous vehicle functions using microservice architecture and container technology. We implemented the concept of embedded devices and showed the feasibility of this concept. The results showed that redundancy could be setup dynamically for non-safety-critical vehicle functions in a cost-effective manner using the proposed approach. This approach could be taken as a security measure while certain devices are being attacked, and the system could continue working without being influenced.},
  doi       = {10.1109/ISSE49799.2020.9272016},
  issn      = {2687-8828},
}

@InProceedings{Bajenaru2020,
  author    = {Băjenaru, Lidia and Dobre, Ciprian and Ciobanu, Radu-Ioan and Dedu, Georgiana and Pantelimon, Silviu-George and Marinescu, Ion Alexandru and Gavrilă, Veronica},
  booktitle = {2020 International Conference on e-Health and Bioengineering (EHB)},
  title     = {Depth-based Human Activity Recognition: vINCI Case Study},
  year      = {2020},
  month     = {Oct},
  pages     = {1-4},
  abstract  = {The growing aging of the world's population is leading to the need to take assistance measures and prepare health care systems for the elderly. The innovative vINCI system provides technologies and uses smart devices that can noninvasively monitor the activity of elderly, to intervene in case of alerts, to prevent possible health problems, such as falling, in the same time to keep their life independent and to improve their quality of life. Monitoring physical activity of the elderly with the help of smart cameras is important in identifying one of the most important lifestyle risk factors for many chronic conditions in the older age. In this paper there are presented the microservice-based vINCI architecture and how an Orbbec Persee camera is used to monitor the physical activity as well as to recognize the elderly. The advantages of the monitoring physical activity application consist in detecting a low level of activity or detecting health problems allowing intervention and correction of an unhealthy lifestyle.},
  doi       = {10.1109/EHB50910.2020.9279887},
  issn      = {2575-5145},
}

@InProceedings{Faria2021,
  author    = {de Faria, Brenno Tondato and Aguzzi, Cristiano and Bates, Travis and Campbell, Colin and Tomei, Fausto and Bittelli, Marco and Roffia, Luca},
  booktitle = {2021 IEEE International Workshop on Metrology for Agriculture and Forestry (MetroAgriFor)},
  title     = {Predict soil moisture into the future: on the integration of CRITERIA-1D into ZENTRA cloud},
  year      = {2021},
  month     = {Nov},
  pages     = {331-335},
  abstract  = {This paper presents a case of study of a IoT cloud plat-form composed of a microservices architecture that has been developed to integrate the CRITERIA-1D into the ZENTRA cloud. CRITERIA-1D is an open-source agro-hydrological model developed by ARPAE simulating one-dimensional soil water fluxes, crop development, and crop water needs. CRITERIA-1D comes with a default set of crops and soils that can be used or tuned for a specific scenarios. Taking as input the weather forecasts (i.e., temperatures and precipitations), the model can be used to predict the soil water content and soil water potential at different depths. Along with the design of the implemented solution, this paper presents the process of tuning crop and soil parameters for a specific use case. The results show that the tuned model estimates very well with respect to the measures observed by sensors, paving the way to its application within the larger context of the METER’s ZENTRA cloud.},
  doi       = {10.1109/MetroAgriFor52389.2021.9628475},
}

@InProceedings{Streiffer2018,
  author    = {Streiffer, Christopher and Raghavendra, Ramya and Benson, Theophilus and Srivatsa, Mudhakar},
  booktitle = {2018 IEEE International Conference on Big Data (Big Data)},
  title     = {Learning to Simplify Distributed Systems Management},
  year      = {2018},
  month     = {Dec},
  pages     = {1837-1845},
  abstract  = {Managing large-scale distributed systems is a difficult task. System administrators are responsible for the upkeep and maintenance of numerous components with complex dependencies. With the shift to microservices-based architectures, these systems can consist of 100s to 1000s of interconnected nodes. To combat this difficulty, administrators rely on analyzing logs and metrics collected from the different services. However, the number of available metrics for large systems presents complexity and scaling issues. To combat these issues, we present Minerva, an unsupervised Machine Learning (ML) framework for performing network diagnosis analysis. Minerva is composed of a multi-stage pipeline, where each component can act individually or cohesively to perform various management tasks. Our system offers a unified and extensible framework for managing the complexity of large networks, and presents administrators with a swiss-army knife for diagnosing the overall health of their systems. To demonstrate the feasibility of Minerva, we evaluate its performance on a production-scale system. We present use cases for the various management tools made available by Minerva, and show how these tools can be used to make strong inferences about the system using unsupervised techniques.},
  doi       = {10.1109/BigData.2018.8622058},
}

@InProceedings{Lennick2021,
  author    = {Lennick, David and Azim, Akramul and Liscano, Ramiro},
  booktitle = {2021 22nd IEEE International Conference on Industrial Technology (ICIT)},
  title     = {A Microservice-Based Architecture for Performance and Energy Benchmarking of Docker-Host Linux Distributions on Internet-of-Things Devices},
  year      = {2021},
  month     = {March},
  pages     = {705-711},
  volume    = {1},
  abstract  = {Containers are rapidly being adopted in several areas of the information technology industry. A major area is edge and embedded Internet-of-Things systems. In this paper, we present a microservice-based architecture for performance analysis and energy consumption of Internet-of-Things "Docker host" Linux distributions. Our methodology builds on previous container benchmarking work, with analysis of performance metrics such as processing, memory, and disk throughput. Furthermore, our methodology introduces container-engine performance metrics related to container lifecycle operations, and concurrent container performance. We demonstrate by comparing four Linux distributions in this domain: BalenaOS, HypriotOS, RancherOS, and Raspbian Lite. All source code is provided.},
  doi       = {10.1109/ICIT46573.2021.9453517},
}

@InProceedings{DeepigaA2014,
  author    = {Deepiga A S and Senthil Velan S and Babu, Chitra},
  booktitle = {2014 IEEE International Conference on Advanced Communications, Control and Computing Technologies},
  title     = {Empirical investigation of introducing Aspect Oriented Programming across versions of an SOA application},
  year      = {2014},
  month     = {May},
  pages     = {1732-1739},
  abstract  = {Service Oriented Architecture (SOA) is an architectural style used to provide services to consumers that promotes loose coupling between services. The scattered and tangled functionalities modeled in an SOA application can be redesigned using Aspect Oriented Programming (AOP). This results in two sets of services, the first set having services for the base functionalities and the other modeling cross-cutting functionalities. During compilation, cross-cutting functionalities in the second set are woven to the functionalities modeled in the first set. By introducing AOP in SOA, the quality attributes such as re-usability, extendibility and maintainability can be improved. The objective of this paper is to perform an empirical investigation by quantitatively measuring the effect of introducing Aspect Orientation (AO) in SOA by developing with multiple versions of a given application. An AO based SOA application (University Automation System) for automating the functionalities of a typical University with multiple versions has been developed as an experimental test bed. An equivalent set of versions without introducing aspectization are also developed in parallel. The values of the AOP metrics are measured for the different versions of University Automation System both aspectized and unaspectized. The measured values show that the quality attributes namely maintainability, reusability and extendibility improve whereas the complexity of the application decreases during the evolution of the case study application.},
  doi       = {10.1109/ICACCCT.2014.7019405},
}

@InProceedings{Alzahmi2014,
  author    = {Alzahmi, Salwa Mohamed and Abu-Matar, Mohammad and Mizouni, Rabeb},
  booktitle = {2014 IEEE 8th International Symposium on Service Oriented System Engineering},
  title     = {A Practical Tool for Automating Service Oriented Software Product Lines Derivation},
  year      = {2014},
  month     = {April},
  pages     = {90-97},
  abstract  = {Service Oriented Architecture (SOA) is a business driven architecture that supports business strategies and goals. In enterprise systems, it offers flexibility for building IT solutions that can respond rapidly to changing business requirements and technology. The success of a service-oriented application implementation is measured by the level of flexibility, extendibility and customization in the provided services. In effect, it raises variability management concerns that require a good understanding of the business domain and a careful design of the application artifacts to cater for various service consumers' demands and requirements. Many approaches and frameworks have been proposed to realize variability in SOA by applying the concept of Software Product Lines (SPL) where services are the core assets and each member of the service-oriented product line is a possible assembly of those services. However, there are few tools that support these approaches and ease the derivation process of member applications taking into consideration the variability from different perspectives. In this paper we present a tool that facilitates the automatic derivation of SOA applications based on Model Driven Engineering (MDE) as an implementation methodology. The tool is based on the Multiple-Views Service-Oriented Product Line Variability approach. The tool architecture as well as its implemented modules is first described. Then, an example in the e-health domain is presented.},
  doi       = {10.1109/SOSE.2014.16},
}

@InProceedings{Arcuri2017,
  author    = {Arcuri, Andrea},
  booktitle = {2017 IEEE International Conference on Software Quality, Reliability and Security (QRS)},
  title     = {RESTful API Automated Test Case Generation},
  year      = {2017},
  month     = {July},
  pages     = {9-20},
  abstract  = {Nowadays, web services play a major role in the development of enterprise applications. Many such applications are now developed using a service-oriented architecture (SOA), where microservices is one of its most popular kind. A RESTful web service will provide data via an API over the network using HTTP, possibly interacting with databases and other web services. Testing a RESTful API poses challenges, as inputs/outputs are sequences of HTTP requests/responses to a remote server. Many approaches in the literature do black-box testing, as the tested API is a remote service whose code is not available. In this paper, we consider testing from the point of view of the developers, which do have full access to the code that they are writing. Therefore, we propose a fully automated white-box testing approach, where test cases are automatically generated using an evolutionary algorithm. Tests are rewarded based on code coverage and fault finding metrics. We implemented our technique in a tool called EVOMASTER, which is open-source. Experiments on two open-source, yet non-trivial RESTful services and an industrial one, do show that our novel technique did automatically find 38 real bugs in those applications. However, obtained code coverage is lower than the one achieved by the manually written test suites already existing in those services. Research directions on how to further improve such approach are therefore discussed.},
  doi       = {10.1109/QRS.2017.11},
}

@InProceedings{Bogner2018a,
  author    = {Bogner, Justus and Fritzsch, Jonas and Wagner, Stefan and Zimmermann, Alfred},
  booktitle = {2018 IEEE/ACM International Conference on Technical Debt (TechDebt)},
  title     = {Limiting Technical Debt with Maintainability Assurance – An Industry Survey on Used Techniques and Differences with Service- and Microservice-Based Systems},
  year      = {2018},
  month     = {May},
  pages     = {125-133},
  abstract  = {Maintainability assurance techniques are used to control this quality attribute and limit the accumulation of potentially unknown technical debt. Since the industry state of practice and especially the handling of Service-and Microservice-Based Systems in this regard are not well covered in scientific literature, we created a survey to gather evidence for a) used processes, tools, and metrics in the industry, b) maintainability-related treatment of systems based on service-orientation, and c) influences on developer satisfaction w.r.t. maintainability. 60 software professionals responded to our online questionnaire. The results indicate that using explicit and systematic techniques has benefits for maintainability. The more sophisticated the applied methods the more satisfied participants were with the maintainability of their software while no link to a hindrance in productivity could be established. Other important findings were the absence of architecture-level evolvability control mechanisms as well as a significant neglect of service-oriented particularities for quality assurance. The results suggest that industry has to improve its quality control in these regards to avoid problems with long-living service-based software systems.},
}

@Article{Rumez2020,
  author   = {Rumez, Marcel and Grimm, Daniel and Kriesten, Reiner and Sax, Eric},
  journal  = {IEEE Access},
  title    = {An Overview of Automotive Service-Oriented Architectures and Implications for Security Countermeasures},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {221852-221870},
  volume   = {8},
  abstract = {New requirements from the customers' and manufacturers' point of view such as adding new software functions during the product life cycle require a transformed architecture design for future vehicles. The paradigm of signal-oriented communication established for many years will increasingly be replaced by service-oriented approaches in order to increase the update and upgrade capability. In this article, we provide an overview of current protocols and communication patterns for automotive architectures based on the service-oriented architecture (SOA) paradigm and compare them with signal-oriented approaches. Resulting challenges and opportunities of SOAs with respect to information security are outlined and discussed. For this purpose, we explain different security countermeasures and present a state of the section of automotive approaches in the fields of firewalls, Intrusion Detection Systems (IDSs) and Identity and Access Management (IAM). Our final discussion is based on an exemplary hybrid architecture (signal- and service-oriented) and examines the adaptation of existing security measures as well as their specific security features.},
  doi      = {10.1109/ACCESS.2020.3043070},
}

@InProceedings{Zavvar2017,
  author    = {Zavvar, Mohammad and Garavand, Shole and Sabbagh, Esmaeel and Rezaei, Meysam and Khalili, Hajar and Zavvar, Mohammad Hossein and Motameni, Homayun},
  booktitle = {2017 3th International Conference on Web Research (ICWR)},
  title     = {Measuring service quality in service-oriented architectures using a hybrid particle swarm optimization algorithm and artificial neural network (PSO-ANN)},
  year      = {2017},
  month     = {April},
  pages     = {78-83},
  abstract  = {Web service combination is an important task performed in different phases of the service-oriented architecture lifecycle. Measuring service quality based on the non-functional characteristics is an exceedingly difficult task. Therefore, this paper presents a Multilayer Perceptron Artificial Neural Network (MLPANN) to provide a method for measuring quality of service in a service-oriented architecture. To improve network performance, Particle Swarm Optimization (PSO) is used to optimize the weights of the network. Finally, our results are compared to those of a combination of Different Evolution (DE) algorithm and MLPANN in terms of Mean Square Error (MSE), Root Mean Square Error (RMSE) and Standard Deviation (STD). The results demonstrate the superiority of the proposed method.},
  doi       = {10.1109/ICWR.2017.7959309},
}

@InProceedings{Plessis2021,
  author    = {du Plessis, Shani and Correia, Noélia},
  booktitle = {2021 IEEE International Conference on Internet of Things and Intelligence Systems (IoTaIS)},
  title     = {A Comparative Study of Software Architectures in Constrained Device IoT Deployments},
  year      = {2021},
  month     = {Nov},
  pages     = {35-41},
  abstract  = {The Internet of Things (IoT) is an area that has consistently seen growth and development and will no doubt continue to do so. One group of IoT devices - constrained devices - has seen significant developments in recent years. With the advent of constrained devices in almost every area of life, e.g. industrial, leisure and medical, this group of devices is well worth studying. Clearly, resource management is a critical aspect to ensure optimal use of such devices. A number of factors can have a significant impact on resource management, such as the operating system and the software architecture.This study aimed to compare the power consumption, runtime performance and memory consumption of two software architectures: microservices and monolithic. The study was conducted using a constrained device, and to ensure that the results are not language-specific, three different programming languages were used: Go, Python and C++. It was found that, for smallscale applications, the monolithic architecture performed better across most metrics. These results may provide valuable insights to engineers for the design and implementation of constrained-device IoT applications. It was recommended that additional research be conducted on larger-scale applications.},
  doi       = {10.1109/IoTaIS53735.2021.9628703},
}

@InProceedings{Ahmed2018,
  author    = {Ahmed, Abdelmuttlib Ibrahim Abdalla and Khan, Suleman and Gani, Abdullah and Hamid, Siti Hafizah Ab and Guizani, Mohsen},
  booktitle = {2018 IEEE 43rd Conference on Local Computer Networks (LCN)},
  title     = {Entropy-based Fuzzy AHP Model for Trustworthy Service Provider Selection in Internet of Things},
  year      = {2018},
  month     = {Oct},
  pages     = {606-613},
  abstract  = {Nowadays, trust and reputation models are used to build a wide range of trust-based security mechanisms and trust-based service management applications on the Internet of Things (IoT). Considering trust as a single unit can result in missing important and significant factors. We split trust into its building-blocks, then we sort and assign weight to these building-blocks (trust metrics) on the basis of its priorities for the transaction context of a particular goal. To perform these processes, we consider trust as a multi-criteria decision-making problem, where a set of trust worthiness metrics represent the decision criteria. We introduce Entropy-based fuzzy analytic hierarchy process (EFAHP) as a trust model for selecting a trustworthy service provider, since the sense of decision making regarding multi-metrics trust is structural. EFAHP gives 1) fuzziness, which fits the vagueness, uncertainty, and subjectivity of trust attributes; 2) AHP, which is a systematic way for making decisions in complex multi-criteria decision making; and 3) entropy concept, which is utilized to calculate the aggregate weights for each service provider. We present a numerical illustration in trust-based Service Oriented Architecture in the IoT (SOA-IoT) to demonstrate the service provider selection using the EFAHP Model in assessing and aggregating the trust scores.},
  doi       = {10.1109/LCN.2018.8638056},
  issn      = {0742-1303},
}

@Article{Hertis2014,
  author   = {Hertis, Matej and Juric, Matjaz B.},
  journal  = {IEEE Transactions on Software Engineering},
  title    = {An Empirical Analysis of Business Process Execution Language Usage},
  year     = {2014},
  issn     = {1939-3520},
  month    = {Aug},
  number   = {8},
  pages    = {738-757},
  volume   = {40},
  abstract = {The current state of executable business process languages allows for and demands optimization of design practices and specifications. In this paper, we present the first empirical study that analyses Web Services Business Process Execution Language (WS-BPEL or BPEL) usage and characteristics of real world executable business processes. We have analysed 1,145 BPEL processes by measuring activity usage and process complexity. In addition, we investigated the occurrence of activity usage patterns. The results revealed that the usage frequency of BPEL activities varies and that some activities have a strong co-occurrence. BPEL activities often appear in activity patterns that are repeated in multiple processes. Furthermore, the current process complexity metrics have proved to be inadequate for measuring BPEL process complexity. The empirical results provide fundamental knowledge on how BPEL specification and process design practices can be improved. We propose BPEL design guidelines and BPEL language improvements for the design of more understandable and less complex processes. The results are of interest to business process language designers, business process tool developers, business process designers and developers, and software engineering researchers, and contribute to the general understanding of BPEL and service-oriented architecture.},
  doi      = {10.1109/TSE.2014.2322618},
}

@InProceedings{Mahajan2020,
  author    = {Mahajan, Yash and Krishnaswamy, Dilip and Chelliah, Pethuru Raj},
  booktitle = {2020 IEEE Conference on Technologies for Sustainability (SusTech)},
  title     = {MiSA - A System for a Microlending Service to Assist Edge Communities},
  year      = {2020},
  month     = {April},
  pages     = {1-8},
  abstract  = {In this paper, we propose a distributed edge+cloud system to assist with microlending services to communities, with machine learning catered to that specific community. A combination of technologies including microservices-based architecture and blockchain technology coupled with machine learning is utilized to provide microfinancing services to help sustain businesses in a local community, and to enable the community to grow into a thriving economy. To minimize the widespread expressed risk, in our prototype, the prediction of whether a loan will default or not is based on the various decision-enabling parameters and on any available information about the borrowers' past transaction as well as aggregate metrics related to the community that the borrower resides in. The authors hope that the suggested distributed edge+cloud architecture in the paper can be leveraged for other emerging sustainable edge applications as well.},
  doi       = {10.1109/SusTech47890.2020.9150502},
}

@InProceedings{Afwani2018,
  author    = {Afwani, Royana and Irmawati, Budi and Jatmika, Andy Hidayat and Agitha, Nadiyasari},
  booktitle = {2018 5th International Conference on Data and Software Engineering (ICoDSE)},
  title     = {Specialized Mobile Health Design Using the Open Group Architecture Framework (TOGAF): A Case Study in Child and Maternity Health Services Organization},
  year      = {2018},
  month     = {Nov},
  pages     = {1-6},
  abstract  = {Mobile health applications are well known effective to provide education materials, receive personalized prompts, as a reminder system, and also create great impacts as early diagnose system and even facilitate a doctor to recommend treatments for patients in rural area as well as in the disaster area. E-health projects failed with the major problem was “no clear definition of the system requirements”. Another challenge for health organization that have specialized units are flexibility, easily expandable, and sustainability information system architecture to be integrated. Therefore, providing a good architecture design for build mobile health application is important. This research have done initial study to particular units in health care organization (Maternal and Child Health Services - PKIA), observation, site interview, and data collection. The research main phase are analyze and design TOGAF architecture for PKIA organization. TOGAF produced some tables and matrices to address detailed requirements in specialized mobile health services. The result from enterprise architecture than becomes reference for the design and development of mobile information system based on service oriented architecture and can be used on mobile devices for multiple platforms. For future work, we will create a model to map the diagrams and tables of enterprise architecture into specific software design, and work for detailed architecture validation using ALMA and object-oriented metrics.},
  doi       = {10.1109/ICODSE.2018.8705779},
  issn      = {2640-0227},
}

@InProceedings{LaSorda2020,
  author    = {LaSorda, Maj Michael and Borky, John and Sega, Ron},
  booktitle = {2020 IEEE Aerospace Conference},
  title     = {Model-Based Systems Architecting with Decision Quantification for Cybersecurity, Cost, and Performance},
  year      = {2020},
  month     = {March},
  pages     = {1-13},
  abstract  = {The architecture selection process early in a major system acquisition is a critical step in determining the success of a program. There are recognized deficiencies that frequently occur in this step such as poor transparency into the final selection decision and excessive focus on lowest cost, which does not necessarily result in best value. This research investigates improvements to this process by integrating Model-Based Systems Engineering (MBSE) techniques; enforcing rigorous, quantitative evaluation metrics with a corresponding understanding of uncertainties; and eliciting stakeholder feedback in order to generate an architecture that is better optimized and trusted to provide improved value for the stakeholders. The proposed methodology presents a decision authority with an integrated assessment of architecture alternatives, to include expected performance evaluated against desired parameters with corresponding uncertainty distributions, and traceable to the concerns of the system's stakeholders. This thus enables a more informed and objective selection of the preferred alternative. We present a case study that analyzes the evaluation of a service-oriented architecture (SOA) providing satellite command and control with cyber security protections. This serves to define and demonstrate a new, more transparent and trusted architecture selection process, and the results show that it consistently achieves the desired improvements. Several excursions are also presented to show how rigorously capturing uncertainty could potentially lead to greater insights in architecture evaluation, which is a robust area for further investigation. The primary contribution of this research then is improved decision support to an architecture selection in the early phases of a system acquisition program.},
  doi       = {10.1109/AERO47225.2020.9172283},
  issn      = {1095-323X},
}

@InProceedings{Mohamed2014,
  author    = {Mohamed, Merabet and Mohamed, Benslimane Sidi and El Amine Chergui, Mohamed},
  booktitle = {2014 Second World Conference on Complex Systems (WCCS)},
  title     = {A hybrid particle swarm optimization for service identification from business process},
  year      = {2014},
  month     = {Nov},
  pages     = {122-127},
  abstract  = {Service identification - as the first step of Service-Oriented Architecture -holds the main emphasis on the modeling process and has a broad influence on the system development. Selecting appropriate service identification method is essential for the prosperity of any service-oriented architecture project. Existing methods for service identification ignore the automation capability while providing human based prescriptive guidelines, which mostly are not applicable at enterprise scales. In this paper, we propose a top down approach to identify automatically services from business process. We use for clustering a hybrid particle swarm optimization algorithm and several design metrics for produce reusable services with proper granularity and acceptable level of cohesion and coupling. The experimental results show that our method HPSOSI (Hybrid Particle Swarm Algorithm for Service Identification) can achieve a high performance in terms of execution time and convergence speed.},
  doi       = {10.1109/ICoCS.2014.7060895},
}

@InProceedings{Saadaoui2018,
  author    = {Saadaoui, Alaeddine and Scott, Stephen L.},
  booktitle = {2018 IEEE 4th International Conference on Collaboration and Internet Computing (CIC)},
  title     = {Lightweight Web Services Migration Framework in Hybrid Clouds},
  year      = {2018},
  month     = {Oct},
  pages     = {106-113},
  abstract  = {Service-oriented architectures allow the deployment of loosely coupled services that are platform independent. An enterprise can take advantage of service-oriented architecture in two different directions. On one side, the abstraction of technology implementation allows the deployment of web services in disparate systems. On the other side, the flexibility and independence of services from each other makes scalability easier to achieve. This paper presents a migration solution of web services in hybrid clouds. The adoption of hybrid cloud solutions is valuable for dynamic workloads to maintain the availability of web services during periods of spikes in demand. The migration solution is a lightweight framework composed of web services to manage cloud instances and the migration task of web services deployed on Java-based web containers. The peak management process is based on Java Management Extensions (JMX) technology to monitor resources and deployed web services. In addition, the framework dynamically integrates a set of JMX metrics to synchronize enterprise demand for resources with the migration process. Finally, a design of the framework prototype is described and a real case of CPU intensive web service is presented to test the migration process and show an improvement of CPU usage and execution time.},
  doi       = {10.1109/CIC.2018.00025},
}

@InProceedings{Kumari2015,
  author    = {Kumari, Smita and Rath, Santanu Kumar},
  booktitle = {2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)},
  title     = {Performance comparison of SOAP and REST based Web Services for Enterprise Application Integration},
  year      = {2015},
  month     = {Aug},
  pages     = {1656-1660},
  abstract  = {Web Services are common means to exchange data and information over the network. Web Services make themselves available over the internet, where technology and platform are independent. Once web services are built it is accessed via uniform resource locator (URL) and their functionalities can be utilized in the application domain. Web services are self-contained, modular, distributed and dynamic in nature. These web services are described and then published in Service Registry e.g., UDDI and then they are invoked over the Internet. Web Services are basic Building blocks of Services Oriented Architecture (SOA). These web services can be developed based on two interaction styles such as Simple Object Access Protocol (SOAP) and Representational State Transfer Protocol (REST). It is important to select appropriate interaction styles i.e., either SOAP or REST for building Web Sevices. Choosing service interaction style is an important architectural decision for designers and developers, as it influences the underlying requirements for implementing web service solutions. In this study, the performance of application of web services for Enterprise Application Integration (EAI) based on SOAP and REST is compared. Since web services operate over network throughput and response time are considered as a metrics parameter for evaluation.},
  doi       = {10.1109/ICACCI.2015.7275851},
}

@Article{Bianchini2014,
  author   = {Bianchini, Devis and Cappiello, Cinzia and De Antonellis, Valeria and Pernici, Barbara},
  journal  = {IEEE Transactions on Services Computing},
  title    = {Service Identification in Interorganizational Process Design},
  year     = {2014},
  issn     = {1939-1374},
  month    = {April},
  number   = {2},
  pages    = {265-278},
  volume   = {7},
  abstract = {Service identification is one of the main phases in the design of a service-oriented application. The way in which services are identified may influence the effectiveness of the SOA architecture. More specifically, the granularity of the services is very important in reaching flexibility and reusing them. Such properties are crucial in interorganizational interactions based on collaborative business processes. In fact, collaboration is facilitated by ensuring a homogeneous description of services at the right level of granularity. In this paper, we provide a detailed description of P2S (Process-to-Services), a computer-aided methodology to enable the identification of services that compose a collaborative business process. The methodology is based on metrics defined to setup service granularity, cohesion, coupling, and reuse. A prototype tool based on the methodology is also described with reference to a real case scenario.},
  doi      = {10.1109/TSC.2013.26},
}

@InProceedings{Guntupally2018,
  author    = {Guntupally, Kavya and Devarakonda, Ranjeet and Kehoe, Kenneth},
  booktitle = {2018 IEEE International Conference on Big Data (Big Data)},
  title     = {Spring Boot based REST API to Improve Data Quality Report Generation for Big Scientific Data: ARM Data Center Example},
  year      = {2018},
  month     = {Dec},
  pages     = {5328-5329},
  abstract  = {Web application technologies are growing rapidly with continuous innovation and improvements. This paper focuses on the popular Spring Boot [1] java-based framework for building web and enterprise applications and how it provides the flexibility for service-oriented architecture (SOA). One challenge with any Spring-based applications is its level of complexity with configurations. Spring Boot makes it easy to create and deploy stand-alone, production-grade Spring applications with very little Spring configuration. Example, if we consider Spring Model-View-Controller (MVC) framework [2], we need to configure dispatcher servlet, web jars, a view resolver, and component scan among other things. To solve this, Spring Boot provides several Auto Configuration options to setup the application with any needed dependencies. Another challenge is to identify the framework dependencies and associated library versions required to develop a web application. Spring Boot offers simpler dependency management by using a comprehensive, but flexible, framework and the associated libraries in one single dependency, which provides all the Spring related technology that you need for starter projects as compared to CRUD web applications. This framework provides a range of additional features that are common across many projects such as embedded server, security, metrics, health checks, and externalized configuration. Web applications are generally packaged as war and deployed to a web server, but Spring Boot application can be packaged either as war or jar file, which allows to run the application without the need to install and/or configure on the application server. In this paper, we discuss how Atmospheric Radiation Measurement (ARM) Data Center (ADC) at Oak Ridge National Laboratory, is using Spring Boot to create a SOA based REST [4] service API, that bridges the gap between frontend user interfaces and backend database. Using this REST service API, ARM scientists are now able to submit reports via a user form or a command line interface, which captures the same data quality or other important information about ARM data.},
  doi       = {10.1109/BigData.2018.8621924},
}

@InProceedings{AlShammari2018,
  author    = {Al-Shammari, Haider Qays and Lawey, Ahmed and El-Gorashi, Taisir and Elmirghani, Jaafar M. H.},
  booktitle = {2018 27th Wireless and Optical Communication Conference (WOCC)},
  title     = {Energy efficient service embedding in IoT networks},
  year      = {2018},
  month     = {April},
  pages     = {1-5},
  abstract  = {The Internet of Things (IoT) is anticipated to participate in performing diverse and complex tasks in the near future. IoT objects capable of handling multiple sensing and actuating functions will be the corner stone of future IoT systems in smart cities. In this paper, we present an energy efficient service embedding framework in IoT network by using mixed integer linear programming (MILP). This framework addresses a set of metrics such as scalability, flexible resource allocation, cost reduction, and efficient use of resources. We consider the event-driven paradigm of Service Oriented Architecture (SOA) in our framework in order to provide service abstraction of basic services which can be composed into complex services and exploited by the upper application layer. The results show that our optimized network can save an average of 27% and 36% of the processing and network power consumption, respectively, compared to an energy unaware service embedding scheme.},
  doi       = {10.1109/WOCC.2018.8372741},
  issn      = {2379-1276},
}

@InProceedings{Chituc2015,
  author    = {Chituc, Claudia-Melania},
  booktitle = {2015 IEEE 7th International Conference on Cloud Computing Technology and Science (CloudCom)},
  title     = {Towards a Methodology for Trade-off Analysis in a Multi-cloud Environment Considering Monitored QoS Metrics and Economic Performance Assessment Results},
  year      = {2015},
  month     = {Nov},
  pages     = {479-482},
  abstract  = {Cloud computing and service-oriented computing brought new opportunities for companies. However, numerous challenges, (e.g., related to application design and deployment, service monitoring) are associated with the cloud and provisioned services. Complex SLAs need to be established and monitored. Current approaches do not sufficiently address the challenges of QoS monitoring in multi-cloud environments in a holistic manner, tackling mainly technical aspects. This paper presents an on-going research project towards the development of a methodology for a trade-off analysis in a multi-cloud environment considering monitored QoS metrics and economic performance assessment results. The research methodology followed and partial results are presented, and directions for future work are discussed. Based on the needs identified, an architecture for SLA monitoring and dynamic runtime adaptations in multi-cloud environments is proposed, tackling technical and business-economic aspects.},
  doi       = {10.1109/CloudCom.2015.87},
}

@InProceedings{Thirumaran2014,
  author    = {Thirumaran, M. and Jannani, M.},
  booktitle = {Proceedings of IEEE International Conference on Computer Communication and Systems ICCCS14},
  title     = {Theoretical foundation to evaluate the change measures for an effective web service change management},
  year      = {2014},
  month     = {Feb},
  pages     = {226-232},
  abstract  = {With the advent in the need for a cost effective and efficient solution which supports the evolution and enhancement of the Enterprise Information Systems, the adoption of Service Oriented Architectures (SOAs) for the automation of business processes and the integration of IT systems is increasing. These SOAs rely on web service standards for the implementation of service invocations across machine boundaries. Web services are software systems designed to support interoperable machine-to-machine interaction over a network. This interoperability is gained through a set of XML-based open standards. These standards provide a common approach for defining, publishing, and using web services. However after a product is introduced in the market, its successful growth against the competitors depends critically on the company's ability to rapidly improve and extend its product in response to customer feedback. These changes must be reflected accordingly in the web service without injecting any disputes. Hence an effective web service Change Management with appropriate change measures is very essential. This paper focuses on such change measures for an effective change management.},
  doi       = {10.1109/ICCCS.2014.7068197},
}

@InProceedings{Fethallah2017,
  author    = {Fethallah, Hadjila and Ismail, Smahi Mohamed and Mohamed, Merzoug and Zeyneb, Torchane},
  booktitle = {2017 International Conference on Mathematics and Information Technology (ICMIT)},
  title     = {An outranking model for web service discovery},
  year      = {2017},
  month     = {Dec},
  pages     = {162-167},
  abstract  = {The web service discovery is the cornerstone of the service oriented architecture. To solve this issue, we usually leverage a matching model as well as the operation signature in order to minimize the residual errors. In this paper, we resolve this problem by combining a set of similarity measures through the use of a majority voting model called “outranking”. The Experimental evaluation confirms that this model performs better than the well-known Borda and all input similarity measures.},
  doi       = {10.1109/MATHIT.2017.8259711},
}

@InProceedings{Gehrmann2020,
  author    = {Gehrmann, Tobias and Duplys, Paul},
  booktitle = {2020 23rd Euromicro Conference on Digital System Design (DSD)},
  title     = {Intrusion Detection for SOME/IP: Challenges and Opportunities},
  year      = {2020},
  month     = {Aug},
  pages     = {583-587},
  abstract  = {Due to ever increasing complexity and the introduction of more and more connectivity, modern cars have an ever growing attack surface. To cope with this, intrusion detection should be used as an additional layer of defense complementing dedicated security measures. There is, however, very little published work on intrusion detection in cars, in particular for service-oriented communication. In this short paper, we first discuss selected challenges and opportunities for intrusion detection in SOME/IP, a standard protocol for service-oriented communication in cars. We then propose an architecture for a SOME/IP intrusion detection system, discuss its security properties and report preliminary experimental results.},
  doi       = {10.1109/DSD51259.2020.00096},
}

@InProceedings{Kumar2018,
  author    = {Kumar, Lov and Sureka, Ashish},
  booktitle = {2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)},
  title     = {An Empirical Analysis on Web Service Anti-pattern Detection Using a Machine Learning Framework},
  year      = {2018},
  month     = {July},
  pages     = {2-11},
  volume    = {01},
  abstract  = {Web Services are application components characterised by interoperability, extensibility, distributed application development and service oriented architecture. A complex distributed application can be developed by combing several third-party web-services. Anti-patterns are counter-productive and poor design and practices. Web-services suffer from a multitude of anti-patterns such as God object Web service and Fine grained Web service. Our work is motivated by the need to build techniques for automatically detecting common web-services anti-patterns by static analysis of the source code implementing a web-service. Our approach is based on the premise that summary values of object oriented source code metrics computed at a web-service level can be used as a predictor for anti-patterns. We present an empirical analysis of 4 data sampling techniques to encounter the class imbalance problem, 5 feature ranking techniques to identify the most informative and relevant features and 8 machine learning algorithms for predicting 5 different types of anti-patterns on 226 real-world web-services across several domains. We conclude that it is possible to predict anti-patterns using source code metrics and a machine learning framework. Our analysis reveals that the best performing classification algorithm is Random Forest, best performing data sampling technique is SMOTE and the best performing feature ranking method is OneR.},
  doi       = {10.1109/COMPSAC.2018.00010},
  issn      = {0730-3157},
}

@Article{Jin2021a,
  author   = {Jin, Hai and Li, Zhi and Zou, Deqing and Yuan, Bin},
  journal  = {IEEE Transactions on Dependable and Secure Computing},
  title    = {DSEOM: A Framework for Dynamic Security Evaluation and Optimization of MTD in Container-Based Cloud},
  year     = {2021},
  issn     = {1941-0018},
  month    = {May},
  number   = {3},
  pages    = {1125-1136},
  volume   = {18},
  abstract = {Due to the lightweight features, the combination of container technology and microservice architecture makes container-based cloud environment more efficient and agile than VM-based cloud environment. However, it also greatly amplifies the dynamism and complexity of the cloud environment and increases the uncertainty of security issues in the system concurrently. In this case, the effectiveness of defense mechanisms with fixed strategies would fluctuate as the updates occur in cloud environment. We refer this problem as effectiveness drift problem of defense mechanisms, which is particularly acute in the proactive defense mechanisms, such as moving target defense (MTD). To tackle this problem, we present DSEOM, a framework that can automatically perceive updates of container-based cloud environment, rapidly evaluate the effectiveness change of MTD and dynamically optimize MTD strategies. Specifically, we establish a multi-dimensional attack graphs model to formalize various complex attack scenarios. Combining with this model, we introduce the concept of betweenness centrality to effectively evaluate and optimize the implementation strategies of MTD. In addition, we present a series of security and performance metrics to quantify the effectiveness of MTD strategies in DSEOM. And we conduct extensive experiments to illustrate the existence of the effectiveness drift problem and demonstrate the usability and scalability of DSEOM.},
  doi      = {10.1109/TDSC.2019.2916666},
}

@Article{Herrera2020,
  author   = {Herrera, José and Moltó, Germán},
  journal  = {IEEE Access},
  title    = {Toward Bio-Inspired Auto-Scaling Algorithms: An Elasticity Approach for Container Orchestration Platforms},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {52139-52150},
  volume   = {8},
  abstract = {The wide adoption of microservices architectures has introduced an unprecedented granularisation of computing that requires the coordinated execution of multiple containers with diverse lifetimes and with potentially different auto-scaling requirements. These applications are managed by means of container orchestration platforms and existing centralised approaches for auto-scaling face challenges when used for the timely adaptation of the elasticity required for the different application components. This paper studies the impact of integrating bio-inspired approaches for dynamic distributed auto-scaling on container orchestration platforms. With a focus on running self-managed containers, we compare alternative configuration options for the container life cycle. The performance of the proposed models is validated through simulations subjected to both synthetic and real-world workloads. Also, multiple scaling options are assessed with the purpose of identifying exceptional cases and improvement areas. Furthermore, a nontraditional metric for scaling measurement is introduced to substitute classic analytical approaches. We found out connections for two related worlds (biological systems and software container elasticity procedures) and we open a new research area in software containers that features potential self-guided container elasticity activities.},
  doi      = {10.1109/ACCESS.2020.2980852},
}

@InProceedings{Kesim2020,
  author    = {Kesim, Dominik and van Hoorn, André and Frank, Sebastian and Häussler, Matthias},
  booktitle = {2020 IEEE 31st International Symposium on Software Reliability Engineering (ISSRE)},
  title     = {Identifying and Prioritizing Chaos Experiments by Using Established Risk Analysis Techniques},
  year      = {2020},
  month     = {Oct},
  pages     = {229-240},
  abstract  = {The prevalence of microservice architectures and container orchestration technologies increases the complexity of assessing such systems' resilience. Chaos engineering is an emerging approach for resilience assessment by testing hypotheses after intentionally injecting faults into a distributed system and observing customer- and business-affecting metrics. As the number of potential risks within a complex system is high, the identification and prioritization of effective and efficient chaos experiments are non-trivial. In the scope of an industrial case study, this work investigates means to identify and prioritize chaos experiments by using established risk analysis techniques known from engineering safety-critical systems, namely i) Fault Tree Analysis, ii) Failure Mode and Effects Analysis, iii) and Computer Hazard and Operability Study. We conducted semi-structured interviews to elicit architectural information and resilience requirements of the case study system. The extracted knowledge was leveraged during the application of the risk analysis techniques. A subset of the identified and prioritized risks was used to create and execute chaos experiments. The risk analysis resulted in over 100 findings and revealed that the system is rather fragile as it comprises a high amount of single points of failure. The chaos experiments revealed further weaknesses for formerly unknown system behavior.},
  doi       = {10.1109/ISSRE5003.2020.00030},
  issn      = {2332-6549},
}

@InProceedings{Filipe2018,
  author    = {Filipe, Ricardo and Correia, Jaime and Araujo, Filipe and Cardoso, Jorge},
  booktitle = {2018 IEEE 17th International Symposium on Network Computing and Applications (NCA)},
  title     = {On Black-Box Monitoring Techniques for Multi-Component Services},
  year      = {2018},
  month     = {Nov},
  pages     = {1-5},
  abstract  = {Despite the advantages of microservice and function-oriented architectures, there is an increase in complexity to monitor such highly dynamic systems. In this paper, we analyze two distinct methods to tackle the monitoring problem in a system with reduced instrumentation. Our goal is to understand the feasibility of such approach with one specific driver: simplicity. We aim to determine the extent to which it is possible to characterize the state of two generic tandem processes, using as little information as possible. To answer this question, we resorted to a simulation approach. Using a queue system, we simulated two services, that we could manipulate with distinct operation sets for each module. We used the total response time seen upstream of the system. Having this setup and metric, we applied two distinct methods to analyze the results. First, we used supervised machine learning algorithms to identify where the bottleneck is happening. Secondly, we used an exponential decomposition to identify the occupation in the two components in a more black-box fashion. Results show that both methodologies have their advantages and limitations. The separation of the signal more accurately identifies occupation in low occupied resources, but when a service is totally dominating the overall time, it lacks precision. The machine learning has a more stable error, but needs the training set. This study suggest that a black-box occupation approach with both techniques is possible and very useful.},
  doi       = {10.1109/NCA.2018.8548336},
}

@InProceedings{Sekar2017,
  author    = {Sekar, K. R. and Sethuraman, J. and Srinivasan, Manav and Ravichandran, K.S. and Manikandan, R.},
  booktitle = {2017 International Conference on Networks & Advances in Computational Technologies (NetACT)},
  title     = {Concurrent classifier based analysis for climate prediction using service oriented architecture},
  year      = {2017},
  month     = {July},
  pages     = {370-375},
  abstract  = {Climate prediction is the essential one for the unforeseen world and reduces the uncertainty. Many research articles are available in bountiful in research arena. In this work the climate prediction will be obtained through concurrent classifiers, usually pronounced as ensemble classifier. Using `N' number of weather forecasting, web sites the training set well called semantic has formulated with a worthy attributes. The interface has created using the concept of Service oriented Architecture (SoA), so that to provide rooms for other applications can also integrated in the future trend. Using the climate prediction, what are the remedial measures to be taken and estimating their budget cost planning can be the one another good application to integrate with the existing application. The homogeneous property of the application can also be verified while integrating with the existing applications. SoA architecture needs umpteen number of services, to accomplish that factor, software components and web services are plays a important role. In the heterogeneous environment the weather forecasting is inevitable for the meter logical department to predict the season of the day.},
  doi       = {10.1109/NETACT.2017.8076798},
}

@InProceedings{Musavi2014,
  author    = {Musavi, Maryam and Pasha, Mohammad Reza and Hamzehnia, Mahnaz and Hoseini, Mahyar},
  booktitle = {2014 6th Conference on Information and Knowledge Technology (IKT)},
  title     = {A QoS-based fuzzy model for evaluation service quality parameters in service-oriented architecture},
  year      = {2014},
  month     = {May},
  pages     = {15-19},
  abstract  = {Nowadays, service-oriented architecture is developed as a flexible architecture for developing dynamic systems. In consider to the importance of quality of service (QoS), measured parameters in this architectural services such as security, reliability and ... has a special place. Uncertainty of parameters affect service quality is considered as a key challenge in such environments. This requiring measurement of these parameters reveals a consistent and efficient manner. Since fuzzy logic is able to express the relative value of the credit in real-world concepts, this article proposes an approach on fuzzy logic to deal with these challenges and evaluation of quality of service.},
  doi       = {10.1109/IKT.2014.7030325},
}

@InProceedings{Pinarer2016,
  author    = {Pinarer, Ozgun and Gripay, Yann and Servigne, Sylvie and Ozgovde, Atay},
  booktitle = {2016 24th Signal Processing and Communication Application Conference (SIU)},
  title     = {Real-time multi-application based sensor flux management},
  year      = {2016},
  month     = {May},
  pages     = {765-768},
  abstract  = {Smart building management systems become very popular research topics due to high energy consumption of buildings in developed countries. Proposed approaches in the literature commonly focus on smart building energy management systems to improve this high consumption and on network communications between deployed devices. However, these approaches are specialized for a single monitoring application, and adopt static wireless sensor device configurations. In this study, we focus on the energy and lifetime of the monitoring architecture itself. We consider a monitoring system as a set of applications that exploit sensor measures in real-time, where these applications are declaratively expressed as (service-oriented) continuous queries over sensor data streams. We tackle the optimization of interactions between application real-time requirements for data and wireless sensor devices that produces those data. In this context, we present a novel approach, an energy-aware dynamic sensor configuration mechanism for a sustainable declarative monitoring architecture that can support multiple applications. We first introduce formalization of application requirements and sensor configuration based on data acquisition/transmission and continuous stream queries. We then propose a self-adaptive energy-aware algorithm that dynamically generates optimized sensor configurations based on real-time query requirements. We also present a Smart-Service Stream-oriented Sensor Management (3SoSM) Gateway that optimizes sensor configurations and manages sensor data streams. Finally, we present a set of experiments we conducted with a wireless sensor network simulator and with a real Smart Building platform.},
  doi       = {10.1109/SIU.2016.7495852},
}

@InProceedings{Huang2021b,
  author    = {Huang, Pei-Shu and Fahmi, Faisal and Wang, Feng-Jian and Yang, Hongji},
  booktitle = {2021 8th International Conference on Dependable Systems and Their Applications (DSA)},
  title     = {Constructing A Creative Service Software with Semantic Web},
  year      = {2021},
  month     = {Aug},
  pages     = {499-507},
  abstract  = {In software development, Service Oriented Architecture (SOA) and creative computing can be adopted to utilize multiple-domain knowledges to construct service software possessing creative properties, i.e., novel, useful, and surprising. In the past, several theoretical evaluation metrics have been proposed to measure creativity of a software system. However, a systematic practical method to construct creative service software is rarely considered in current researches. In this paper, we propose a model for creative service software development based on semantic web, which is applied in two phases: domain-creative requirement specification and semantic-based service design. The model can reduce communication work between domain experts and software engineers, improve traceability of the specifications, and improve machine readability during the generation of creativity. After the model of service design is validated for completeness and consistency, the creative service software is well-designed and can be implemented and reused effectively without losing of creativity.},
  doi       = {10.1109/DSA52907.2021.00074},
  issn      = {2767-6684},
}

@InProceedings{Garusinghe2016,
  author    = {Garusinghe, Asanka and Perera, Indika and Meedeniya, Dulani},
  booktitle = {2016 Sixteenth International Conference on Advances in ICT for Emerging Regions (ICTer)},
  title     = {Managing Service Level Agreements in Service Oriented Product Lines},
  year      = {2016},
  month     = {Sep.},
  pages     = {274-280},
  abstract  = {Service Oriented Architecture (SOA) and Software Product Line (SPL) have individually proven to be Software Engineering concepts, which are creating values for developing software systems. While SOA is being used for developing applications from an orchestration of web services, SPL has ability to prepare core sets of assets and manage with variable components. The combination of SOA and SPL has highlighted the term of Service Oriented Product Line (SOPL) which is setting up the application to manage common parts and reuse them without developing from scratch. It helps to manage service component bundles dynamically according to identified commonalities and variabilities. In this paper, we present our implementation approach of SOPL and manage Service Level Agreements (SLAs) in such environments by monitoring Quality of Service (QoS) attributes in bundles of web service components. The designing and developing service bundles for representing core sets of assets in SOPL are followed by the initial feature based analysis and identification of service components. Then, the managing SLAs is handled by detecting the deviation between actual and acceptable pre-defined QoS metrics values in previously analysed web service components via Web Service Level Agreement (WSLA) language specified templates.},
  doi       = {10.1109/ICTER.2016.7829931},
  issn      = {2472-7598},
}

@InProceedings{Torkura2017,
  author    = {Torkura, Kennedy A. and Sukmana, Muhammad I.H. and Cheng, Feng and Meinel, Christoph},
  booktitle = {2017 IEEE International Conference on Smart Cloud (SmartCloud)},
  title     = {Leveraging Cloud Native Design Patterns for Security-as-a-Service Applications},
  year      = {2017},
  month     = {Nov},
  pages     = {90-97},
  abstract  = {This paper discusses a new approach for designing and deploying Security-as-a-Service (SecaaS) applications using cloud native design patterns. Current SecaaS approaches do not efficiently handle the increasing threats to computer systems and applications. For example, requests for security assessments drastically increase after a high-risk security vulnerability is disclosed. In such scenarios, SecaaS applications are unable to dynamically scale to serve requests. A root cause of this challenge is employment of architectures not specifically fitted to cloud environments. Cloud native design patterns resolve this challenge by enabling certain properties e.g. massive scalability and resiliency via the combination of microservice patterns and cloud-focused design patterns. However adopting these patterns is a complex process, during which several security issues are introduced. In this work, we investigate these security issues, we redesign and deploy a monolithic SecaaS application using cloud native design patterns while considering appropriate, layered security counter-measures i.e. at the application and cloud networking layer. Our prototype implementation out-performs traditional, monolithic applications with an average Scanner Time of 6 minutes, without compromising security. Our approach can be employed for designing secure, scalable and performant SecaaS applications that effectively handle unexpected increase in security assessment requests.},
  doi       = {10.1109/SmartCloud.2017.21},
}

@InProceedings{DeIasio2019,
  author    = {De Iasio, Antonio and Furno, Angelo and Goglia, Lorenzo and Zimeo, Eugenio},
  booktitle = {2019 IEEE International Conference on Big Data (Big Data)},
  title     = {A Microservices Platform for Monitoring and Analysis of IoT Traffic Data in Smart Cities},
  year      = {2019},
  month     = {Dec},
  pages     = {5223-5232},
  abstract  = {The ongoing digitization of cities, enabled by the diffusion of interconnected sensors and devices, makes it possible to continuously collect and analyze huge streams of data at extremely large spatio-temporal scales and fine resolutions. These data can be used to monitor, detect and anticipate different kinds of infrastructure vulnerabilities and anomalies, as well as to implement more personalized services that could improve citizens' life. In this new context, full of opportunities, it is difficult to foresee and develop, in advance, the set of applications and services that can be potentially useful for administrators and citizens to solve the manifold compelling needs a city may have to face. Novel ICT paradigms and technologies can help designing agile, general-purpose smart city platforms aimed at supporting the collection and treatment of large-scale, multi-source (streams of) data and the development of novel applications that could fulfill diverse functional requirements under strict non-functional constraints. This paper presents the reference architecture, a prototype implementation and a city-scale case-study evaluation of PROMENADE, a platform that exploits IoT/Fog/Cloud paradigms, microservices and DevOps infrastructures to guarantee continuous development of robust and reliable applications for real-time monitoring and analysis of traffic data generated by IoT devices in large smart cities. The prototype has been evaluated in a case study concerning the quasi real-time detection of road networks vulnerabilities via centrality measures from on-line traffic conditions, emulated from off-line real datasets available for the city of Lyon, France.},
  doi       = {10.1109/BigData47090.2019.9006025},
}

@InProceedings{Serth2017,
  author    = {Serth, Sebastian and Podlesny, Nikolai and Bornstein, Marvin and Lindemann, Jan and Latt, Johanna and Selke, Jan and Schlosser, Rainer and Boissier, Martin and Uflacker, Matthias},
  booktitle = {2017 IEEE 21st International Enterprise Distributed Object Computing Conference (EDOC)},
  title     = {An Interactive Platform to Simulate Dynamic Pricing Competition on Online Marketplaces},
  year      = {2017},
  month     = {Oct},
  pages     = {61-66},
  abstract  = {E-commerce marketplaces are highly dynamic with constant competition. While this competition is challenging for many merchants, it also provides plenty of opportunities, e.g., by allowing them to automatically adjust prices in order to react to changing market situations. For practitioners however, testing automated pricing strategies is time-consuming and potentially hazardously when done in production. Researchers, on the other side, struggle to study how pricing strategies interact under heavy competition. As a consequence, we built an open continuous time framework to simulate dynamic pricing competition called Price Wars. The microservice-based architecture provides a scalable platform for large competitions with dozens of merchants and a large random stream of consumers. Our platform stores each event in a distributed log. This allows to provide different performance measures enabling users to compare profit and revenue of various repricing strategies in real-time. For researchers, price trajectories are shown which ease evaluating mutual price reactions of competing strategies. Furthermore, merchants can access historical marketplace data and apply machine learning. By providing a set of customizable, artificial merchants, users can easily simulate both simple rule-based strategies as well as sophisticated data-driven strategies using demand learning to optimize their pricing strategies.},
  doi       = {10.1109/EDOC.2017.17},
  issn      = {2325-6362},
}

@InProceedings{Li2020d,
  author    = {Li, Zhuo and Cao, Jiannong and Liu, Xiulong and Zhang, Jiuwu and Hu, Haoyuan and Yao, Didi},
  booktitle = {2020 29th International Conference on Computer Communications and Networks (ICCCN)},
  title     = {A Self-Adaptive Bluetooth Indoor Localization System using LSTM-based Distance Estimator},
  year      = {2020},
  month     = {Aug},
  pages     = {1-9},
  abstract  = {In recent years, there is an increasing demand for indoor localization services with the aim to locate people and objects inside buildings. However, localization accuracy is susceptible to inaccurate and high variant sensor measurements due to the unpredictable fluctuations of received wireless signals and the sensitivity of hardware devices. To address this issue, in this paper, we establish a new Bluetooth indoor localization system, whose architecture can be basically decomposed into two parts: the internet-of-things (IoT) framework and the localization module. Concretely, the IoT platform uses the state-of-the-art light weight Spring Boot microservice framework consisting of multi-layer structure. In the localization module, it follows the general process of trilateration but significantly distinguished from it. A set of measures are adopted to strengthen the system's robustness when obtained measurements cannot be fully trusted. Specifically, in the first place, rather than using conventional propagation model to predict the distance between Bluetooth transmitter and receiver, we design a bran-new LSTM-based distance estimator which can better depict the nonlinearity of attenuation characteristics of radio signal. Moreover, we also employ a series of self-adaptive mechanisms, including elastic radius intersecting, multiple weighted centroid localization and self-adaptive Kalman tracking, to make the system robust against inaccurate measurements and unpredictable sudden variation of received wireless signal. A bunch of tests are conducted in both ideal lab environment and Alibaba's large-scale warehouse, and experimental results show our indoor localization system outperforms the state-of-the-art benchmarks by a large margin in both localization accuracy and stability.},
  doi       = {10.1109/ICCCN49398.2020.9209674},
  issn      = {2637-9430},
}

@InProceedings{Andersen2021,
  author    = {Andersen, Nicklas Sindlev and Chiarandini, Marco and Mauro, Jacopo},
  booktitle = {2021 IEEE/ACM 3rd International Workshop on Software Engineering for Healthcare (SEH)},
  title     = {Wandering and getting lost: the architecture of an app activating local communities on dementia issues},
  year      = {2021},
  month     = {June},
  pages     = {36-43},
  abstract  = {We describe the architecture of Sammen Om Demens (SOD), an application for portable devices aiming at helping persons with dementia when wandering and getting lost through the involvement of caregivers, family members, and ordinary citizens who volunteer.To enable the real-time detection of a person with dementia that has lost orientation, we transfer location data at high frequency from a frontend on the smartphone of a person with dementia to a backend system. The backend system must be able to cope with the high throughput data and carry out possibly heavy computations for the detection of anomalous behavior via artificial intelligence techniques. This sets certain performance and architectural requirements on the design of the backend.In the paper, we discuss our design and implementation choices for the backend of SOD that involve microservices and serverless services to achieve efficiency and scalability. We give evidence of the achieved goals by deploying the SOD backend on a public cloud and measuring the performance on simulated load tests.},
  doi       = {10.1109/SEH52539.2021.00014},
}

@InProceedings{&x00DC2021,
  author    = {&} # x00DC;nl& # {x00FC;, H&} # x00FC;seyin and Hacalo& # {x011F;lu, Tuna and Leblebici, Onur and Demir&#x00F6;rs, Onur},
  booktitle = {2021 15th Turkish National Software Engineering Symposium (UYMS)},
  title     = {Effort Prediction for Microservices: A Case Study},
  year      = {2021},
  month     = {Nov},
  pages     = {1-6},
  abstract  = {Software size measurement is critical as an input to perform important project management processes such as effort, cost and schedule estimation. Functional size measurement (FSM) methods are beneficial in terms of being applicable in the early phases of the software life cycle over functional requirements and providing a systematic and repeatable method. However, in agile organizations, it can be challenging to seperate measurement components of FSM methods from requirements in the early phases as the documentation is kept to a minimum compared to traditional methods such as the Waterfall Model and is detailed as the project steps. In addition, the existing FSM methods are not fully compatible with today&#x0027;s architectural structures, which are from being data-driven and to evolve into a behaviour-oriented structure. In this study, we performed a case study which includes a project developed with agile methods and using microservice-based architecture to compare the effectiveness of COSMIC FSM and event-based software size measurement. For this purpose, we measured the size of the project and created effort estimation models based on two methods. The measurers had difficulty in applying both methods due to the limited detail level of the requirements in the project. However, the event-based method was found to estimate effort with less error than the COSMIC FSM method.},
  doi       = {10.1109/UYMS54260.2021.9659766},
}

@InProceedings{Triantafyllidis2014,
  author    = {Triantafyllidis, Andreas K. and Koutkias, Vassilis G. and Chouvarda, Ioanna and Maglaveras, Nicos},
  booktitle = {2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society},
  title     = {Development and usability of a personalized sensor-based system for pervasive healthcare},
  year      = {2014},
  month     = {Aug},
  pages     = {6623-6626},
  abstract  = {Although a plethora of remote health monitoring systems have been proposed for chronic conditions, the challenge posed by the changing patient needs and the requirement for personalization in health monitoring to move beyond proprietary, difficult to extend, and unsustainable solutions still pertains. In this direction, we describe a mobile health system based on a smartphone, portable/wearable sensors for measuring the patient's physiological parameters, and back-end platforms for the health professionals to monitor the patient condition and configure monitoring plans in an individualized manner. A prototype system was developed based on a Service-oriented Architecture and integrating commercially available sensing devices. An experimental study has been conducted with 53 patients in order to investigate the usability of the proposed system. The patients were able to perform the majority of the target tasks successfully (Success Rate = 77%), while the perceived usability using the System Usability Scale (SUS) was found to be above average (SUS score = 73%), indicating that the patients overall perceived the system as both easy to use and useful.},
  doi       = {10.1109/EMBC.2014.6945146},
  issn      = {1558-4615},
}

@InProceedings{Dongre2020,
  author    = {Dongre, Yashwant and Ingle, Rajesh},
  booktitle = {2020 2nd International Conference on Innovative Mechanisms for Industry Applications (ICIMIA)},
  title     = {An Investigation of QoS Criteria for Optimal Services Selection in Composition},
  year      = {2020},
  month     = {March},
  pages     = {705-710},
  abstract  = {Web service plays a vital role in the service industry to improve the web service applications and it is service oriented architecture. Due to which formation of composite service leads to non-optimal. Service selection task in the composition process is to select the best service for each candidate services out of available services which are a functionally similar but non-functional measures of services are different. This paper, presents the investigation of quality of service parameters and optimality criteria for services selection. The work in the paper provides the analysis of quality of service parameters used in existing works for services selection/composition. Through the survey and analysis it has been revealed that the response time, availability, and reliability are most common used quality of service attributes with minimum/maximum as optimality criteria. However, after analysis of these parameters, the work suggests to use these attributes to solve optimal services selection problem in composition.},
  doi       = {10.1109/ICIMIA48430.2020.9074950},
}

@InProceedings{Su2017,
  author    = {Su, Rui and Wan, Bo and Deng, Zhaoyun and Mei, Zheng and Mi, Weimin and Xie, Qiaoyun and Lin, Wenbin},
  booktitle = {2017 36th Chinese Control Conference (CCC)},
  title     = {Research and application on integrated maintenance of smart substation and remote control center based on SOA},
  year      = {2017},
  month     = {July},
  pages     = {10588-10593},
  abstract  = {The RCC-SS (Remote Control Center — Smart Substation) integrated maintenance technology based on SOA (Service Oriented Architecture) is proposed to solve the following problems: the complexity of debugging and maintenance when connecting the smart substation to the remote control center, the singularity of information exchange, and the difficulty to support advanced interactive application. By the construction of a wide-area distribution service system between the RCC (Remote Control Center) and the SS (Smart Substation), this proposal provides services in modelling, communication interface, real-time and historic data, and information verification as example. This RCC-SS system also unifies the modeling and the configuration, develops integrated maintenance tools, converts the substation SCD (Substation Configuration Description) file to CIM/E (Common Information Model / Efficient model exchange format) file and CIM/G (Common Information Model / Graphic exchange format) file used in remote control center, associates ID (Identification) between model and graphic files, imports all the information and stores in database, and lastly executes the automatic checking of the tele-measuring, tele-signaling and protection signaling. As a result, the smart substation's programmatic and automatic connection to the RCC is achieved, and the information exchange and business collaboration capabilities between the RCC and the SS is enhanced.},
  doi       = {10.23919/ChiCC.2017.8029043},
  issn      = {1934-1768},
}

@InProceedings{Ribin2019,
  author    = {Ribin, Jones S.B and Kumar, N.},
  booktitle = {2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI)},
  title     = {Precursory study on varieties of DDoS attacks and its implications in Cloud Systems},
  year      = {2019},
  month     = {April},
  pages     = {1003-1008},
  abstract  = {Cloud Computing has emerged into an inevitable platform for computing services by effectively implementing Service Oriented Architecture (SOA) and Virtualization. However it is still vulnerable to traditional security threats and offers scope for innovative security attacks such as EDoS [1]. While it offers platform to generate innumerable Virtual components from a single physical component, it inadvertently provides wide spectrum of possibilities for distributed attacks. Moreover such attacks have adapted to cloud platform and have exploited various inherent vulnerabilities. In an unprecedented manner, they became unpredictable, evasive and challenging to Cloud Security measures. Therefore various versions of DDoS attack that targets the cloud platform have been extensively researched and narrated. The Cloud Security faces unprecedented challenges such as the Single-point-of-Failure occurs when a Cloud Supervisory Component or hypervisor fails due to a security breach. Moreover Cloud requirements often require being liberal to meet the Clients needs. This does not help the CSP to adapt traditional stringent security measures in Cloud System the reasons have been discussed in details.},
  doi       = {10.1109/ICOEI.2019.8862722},
}

@InProceedings{Alzaghoul2014,
  author    = {Alzaghoul, Esra and Bahsoon, Rami},
  booktitle = {2014 23rd Australian Software Engineering Conference},
  title     = {Evaluating Technical Debt in Cloud-Based Architectures Using Real Options},
  year      = {2014},
  month     = {April},
  pages     = {1-10},
  abstract  = {A Cloud-based Service-Oriented Architecture (CBSOA) is typically composed of web services, which are offered off the cloud marketplace. CB-SOA can improve its utility and add value to its composition by switching among its constituent services. We look at the option to defer the decision of substitution under uncertainty. We exploit Binomial Options to the formulation. We quantify the time-value of the architecture decisions of switching web services and technical debt they can imply on the structure. As CB-SOA are market-sensitive, dynamic and "volatile", the decision of deferral tends to be sensitive to these dynamics. Henceforth, the structural complexity of a CB-SOAcan change over time and so the technical debt as its constituent web services are modified, replaced, upgraded, etc. The method builds on Design Structure Matrix (DSM) and introduces time and complexity aware propagation cost metrics to assess the value of deferral decisions relative to changes in the structure. Architects of CB-SOA can use our method to assess the time value of deferring the decisions to switch web services relative to complexity, technical debt and value creation. We demonstrate the applicability of the method using an illustrative example.},
  doi       = {10.1109/ASWEC.2014.27},
  issn      = {2377-5408},
}

@InProceedings{Hecht2014,
  author    = {Hecht, Geoffrey and Jose-Scheidt, Benjamin and De Figueiredo, Clement and Moha, Naouel and Khomh, Foutse},
  booktitle = {2014 IEEE 6th International Conference on Cloud Computing Technology and Science},
  title     = {An Empirical Study of the Impact of Cloud Patterns on Quality of Service (QoS)},
  year      = {2014},
  month     = {Dec},
  pages     = {278-283},
  abstract  = {Cloud patterns are described as good solutions to recurring design problems in a cloud context. These patterns are often inherited from Service Oriented Architectures or Object Oriented Architectures where they are considered good practices. However, there is a lack of studies that assess the benefits of these patterns for cloud applications. In this paper, we conduct an empirical study on a Restful application deployed in the cloud, to investigate the individual and the combined impact of three cloud patterns (i.e., Local Database proxy, Local Sharding-Based Router and Priority Queue Patterns) on Quality of Service (QoS). We measure the QoS using the application's response time, average, and maximum number of requests processed per seconds. Results show that cloud patterns doesn't always improve the response time of an application. In the case of the Local Database proxy pattern, the choice of algorithm used to route requests has an impact on response time, as well as the average and maximum number of requests processed per second. Combinations of patterns can significantly affect the QoS of applications. Developers and software architects can make use of these results to guide their design decisions.},
  doi       = {10.1109/CloudCom.2014.141},
}

@InProceedings{Yang2021a,
  author    = {Yang, Meixia and Yang, JingJing and Xiao, Zhe and Huang, Ming},
  booktitle = {2021 International Conference on Computer Communication and Informatics (ICCCI)},
  title     = {A modular spectrum sensing node for Resources-Oriented Radio Monitoring},
  year      = {2021},
  month     = {Jan},
  pages     = {1-8},
  abstract  = {The existing radio monitoring practices suffer from two critical limitations: 1) current practices have been limited to isolated measuring and are unable to integrate data from different spectrum sensors; 2) these practices still require human operators to interpret signals, which prevent automated and intelligent processing. To address these limitations, we present a novel design of a spectrum sensing node based on the Representational State Transfer (REST) architecture. The spectrum sensing node exploits the REST architecture to integrate resources (data) into the web and to make it effortless to collect and share resources by exposing resources as service-oriented Web APIs. In addition, the spectrum sensing node introduces standardization and automation to radio monitoring. We outline the procedures of spectrum analysis and signal analysis for radio monitoring. Furthermore, to automate spectrum sensing node functionalities, we implement spectrum analysis and signal analysis using machine learning methods, which reliably extract and learn intrinsic features of complex data. The spectrum sensing node has been packaged and deployed in Honghe Hani and Yi Autonomous Prefecture of China for radio spectrum management. We describe and discuss our implemented prototype of the spectrum sensing node to demonstrate its practical advantages.},
  doi       = {10.1109/ICCCI50826.2021.9402637},
  issn      = {2329-7190},
}

@Article{Li2014a,
  author   = {Li, Shancang and Zhao, Shanshan and Wang, Xinheng and Zhang, Kewang and Li, Ling},
  journal  = {IEEE Systems Journal},
  title    = {Adaptive and Secure Load-Balancing Routing Protocol for Service-Oriented Wireless Sensor Networks},
  year     = {2014},
  issn     = {1937-9234},
  month    = {Sep.},
  number   = {3},
  pages    = {858-867},
  volume   = {8},
  abstract = {Service-oriented architectures for wireless sensor networks (WSNs) have been proposed to provide an integrated platform, where new applications can be rapidly developed through flexible service composition. In WSNs, the existing multipath routing schemes have demonstrated the effectiveness of traffic distribution over multipaths to fulfill the quality of service requirements of applications. However, the failure of links might significantly affect the transmission performance, scalability, reliability, and security of WSNs. Thus, by considering the reliability, congestion control, and security for multipath, it is desirable to design a reliable and service-driven routing scheme to provide efficient and failure-tolerant routing scheme. In this paper, an evaluation metric, path vacant ratio, is proposed to evaluate and then find a set of link-disjoint paths from all available paths. A congestion control and load-balancing algorithm that can adaptively adjust the load over multipaths is proposed. A threshold sharing algorithm is applied to split the packets into multiple segments that will be delivered via multipaths to the destination depending on the path vacant ratio. Simulations demonstrate the performance of the adaptive and secure load-balance routing scheme.},
  doi      = {10.1109/JSYST.2013.2260626},
}

@Article{Wang2021c,
  author   = {Wang, Chao and Gong, Lei and Li, Xi and Yu, Qi and Wang, Aili and Hung, Patrick and Zhou, Xuehai},
  journal  = {IEEE Transactions on Services Computing},
  title    = {SOLAR: Services-Oriented Deep Learning Architectures-Deep Learning as a Service},
  year     = {2021},
  issn     = {1939-1374},
  month    = {Jan},
  number   = {1},
  pages    = {262-273},
  volume   = {14},
  abstract = {Deep learning has been an emerging field of machine learning during past decades. However, the diversity and large scale data size have posed significant challenge to construct a flexible and high performance implementations of deep learning neural networks. In order to improve the performance as well to maintain the scalability, in this paper we present SOLAR, a services-oriented deep learning architecture using various accelerators like GPU and FPGA. SOLAR provides a uniform programming model to users so that the hardware implementation and the scheduling is invisible to the programmers. At runtime, the services can be executed either on the software processors or the hardware accelerators. To leverage the trade-offs between the metrics among performance, power, energy, and efficiency, we present a multitarget design space exploration. Experimental results on the real state-of-the-art FPGA board demonstrate that the SOLAR is able to provide a ubiquitous framework for diverse applications without increasing the burden of the programmers. Moreover, the speedup of the GPU and FPGA hardware accelerator in SOLAR can achieve significant speedup comparing to the conventional Intel i5 processors with great scalability.},
  doi      = {10.1109/TSC.2017.2777478},
}

@Article{Chiu2020,
  author   = {Chiu, Kai-Cheng and Liu, Chien-Chang and Chou, Li-Der},
  journal  = {IEEE Access},
  title    = {CAPC: Packet-Based Network Service Classifier With Convolutional Autoencoder},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {218081-218094},
  volume   = {8},
  abstract = {The Internet has been evolving from a traditional mechanism to a modern service-oriented architecture, such as quality-of-service (QoS) policies, to meet users’ various requirements for high service quality. An instant and effective network traffic classification method is indispensable to identify network services to enforce QoS policies on the corresponding service. Network managers can easily flexibly deploy traffic classification modules and configure the network policies with the help of the emerging software-defined networking. However, most existing traffic classification solutions, such as port-based methods or deep packet inspection, cannot handle real-time and encrypted traffic classification. In this research, a Convolutional Autoencoder Packet Classifier (CAPC) has been proposed to immediately classify incoming packets in fine-grained and coarse-grained manners, that is, classifying a service to a single application and a rough genre, respectively. The CAPC is a packet-based deep learning model consisting of a 1D convolutional neural network and an autoencoder, which can handle dynamic-port and encrypted traffic and even cluster similar applications. This classifier is verified on not only the private self-captured traffic but also a public VPN dataset to demonstrate its performance. Moreover, the CAPC classifies different types of service traffic with an accuracy of over 99.9% on the private dataset of 16 services and over 97% on the public dataset of 24 services, thereby outperforming other deep learning classifiers. Experimental results also show other performance metrics, including stability, average precision, and recall and the highest F1-score values of 15 and 18 services on the private and public datasets, respectively.},
  doi      = {10.1109/ACCESS.2020.3041806},
}

@InProceedings{Huang2021c,
  author    = {Huang, Pei-Shu and Fahmi, Faisal and Wang, Feng-Jian},
  booktitle = {2021 IEEE 45th Annual Computers, Software, and Applications Conference (COMPSAC)},
  title     = {A Model to Helping the Construction of Creative Service-Based Software},
  year      = {2021},
  month     = {July},
  pages     = {1235-1242},
  abstract  = {With the advent of the Service Oriented Architecture (SOA) in system design, various domain knowledges are included in a service-based application, such as the design of Artificial Intelligence (AI) or augmented reality (AR) systems. While merging one or multiple domains into computation systems, the computation systems can be widely applied in various domain usages with novelty, useful, and surprising properties, which are defined as systems of creative computing. In creative computing, several theoretical evaluation metrics and verification approaches have been proposed for system design in several domains. However, a solid practical design environment for creative service-based systems is rarely considered in current researches. In this paper, we propose a model for creative service software development based on semantic web, which is applied in two phases: (1) requirement specification and (2) service design. In order to bridge the knowledge gap between domain experts and software engineers, and provide a machine-readable format for creative computing, two sub-models, Requirement Specification and Service Structure Models, are constructed in both phases, sequentially. After the latter sub-model is validated, the creative service software is well-constructed based on the services definition and composition represented by the model.},
  doi       = {10.1109/COMPSAC51774.2021.00171},
  issn      = {0730-3157},
}

@InProceedings{Mishra2014,
  author    = {Mishra, Siba and Kumar, Chiranjeev},
  booktitle = {The 2014 2nd International Conference on Systems and Informatics (ICSAI 2014)},
  title     = {Estimating development size and effort of business process service-oriented architecture applications},
  year      = {2014},
  month     = {Nov},
  pages     = {1006-1011},
  abstract  = {Service-oriented Architecture (SOA) is adopted by many industrial and business organizations, as an efficient means for designing, developing and integrating enterprise business processes applications. With the built of Web Services, the developed business processes can be easily combined to achieve a composite business solution. Generally, any business applications are mixture of processes and some tasks corresponding to the processes. In the planning phase of software project management, estimation of development effort is very critical and crucial for software/business organizations. Having an accurate effort estimate guarantees the managers that the projects are completed within time and budget. So, estimation techniques/models need to be very efficient and should highlights all important cost drivers. The estimation of development effort for business processes primarily depends on the number of processes and it's associated tasks. The development effort of business applications primarily depends on the size of integrated applications. In this paper, some metrics for predicting the size of integrated business process SOA applications have been proposed. After estimating size, the development effort calculated by using the popular COCOMO model. A comparison of various performance evaluation criterion for assessing the accuracy of proposed model has been computed and shown.},
  doi       = {10.1109/ICSAI.2014.7009432},
}

@Article{Anta2016,
  author   = {Anta, Antonio Fernández and Gramoli, Vincent and Jiménez, Ernesto and Kermarrec, Anne-Marie and Raynal, Michel},
  journal  = {IEEE Transactions on Parallel and Distributed Systems},
  title    = {Distributed Slicing in Dynamic Systems},
  year     = {2016},
  issn     = {1558-2183},
  month    = {April},
  number   = {4},
  pages    = {1030-1043},
  volume   = {27},
  abstract = {Peer to peer (P2P) systems have moved from application specific architectures to a generic service oriented design philosophy. This raised interesting problems in connection with providing useful P2P middleware services capable of dealing with resource assignment and management in a large-scale, heterogeneous and unreliable environment. The slicing problem consists of partitioning a P2P network into $k$  groups (slices) of a given portion of the network nodes that share similar resource values. As the network is large and dynamic this partitioning is continuously updated without any node knowing the network size. In this paper, we propose the first algorithm to solve the slicing problem. We introduce the metric of slice disorder and show that the existing ordering algorithm cannot nullify this disorder. We propose a new algorithm that speeds up the existing ordering algorithm but that suffers from the same inaccuracy. Then, we propose another algorithm based on ranking that is provably convergent under reasonable assumptions. In particular, we notice experimentally that ordering algorithms suffer from resource-correlated churn while the ranking algorithm can cope with it. These algorithms are proved viable theoretically and experimentally.},
  doi      = {10.1109/TPDS.2015.2430856},
}

@InProceedings{Aljawawdeh2018,
  author    = {Aljawawdeh, Hamzeh and Odeh, Mohammed and Simons, Christopher and Lebzo, Nawras},
  booktitle = {2018 1st International Conference on Cancer Care Informatics (CCI)},
  title     = {A Metaheuristic Search Framework to Derive Cancer Care Services from Business Process Models},
  year      = {2018},
  month     = {Nov},
  pages     = {142-151},
  abstract  = {Cancer Care involves not only handling patients' medical or physical needs but also other services to facilitate patient needs which are underpinned by appropriate software systems that assist in patient care processes. The Service-Oriented Architecture (SOA) model of computing has become widely adopted and can provide efficient and agile business solutions in the face of rapid changes to business requirements. Instead of adopting a more traditional way of building an IT system for Cancer Care by rigidly piecing together a collection of hardware, software and networking, SOA offers the opportunity to build the IT systems in an increasingly flexible and reconfigurable way. However, current service identification methods can suffer from shortcomings such as a lack of computational support, and not being able to address all the necessary activities of the service identification. To address these shortcomings, this paper presents a comprehensive metaheuristic search framework for deriving SOA-based services applied to Cancer Care business process models. This framework is evaluated using both quantitative and qualitative methods with the help of domain experts at King Hussein Cancer Centre (KHCC), Jordan. Evaluation by domain experts confirmed that the resulting services are feasible (i.e., valid services that can be practically applied for real-life projects) that the domain experts might not have arrived at manually. Statistical analysis shows candidate services produced by the search-based framework are superior to the services produced manually by domain experts at KHCC with respect to metrics for coupling and cohesion.},
  doi       = {10.1109/CANCERCARE.2018.8618153},
}

@InProceedings{Kim2014a,
  author    = {Kim, Yukyong and Choi, Jong-Seok and Shin, Yongtae},
  booktitle = {2014 4th World Congress on Information and Communication Technologies (WICT 2014)},
  title     = {A decision model for optimizing the service portfolio in SOA governance},
  year      = {2014},
  month     = {Dec},
  pages     = {57-62},
  abstract  = {Effective service-oriented architecture (SOA) governance requires an appropriate process in place by which services described by a service model become candidates to enter the service portfolio. This is a planning for the appropriate identified services to create business agility and maximize reuse. Not all services in the service model can be realized in the form of IT solutions, so if our intended use of the service portfolio is to drive IT development planning, we must first decide which services are potentially realizable and which services are not. In this paper, we present a decision model to evaluate the services based on the proposed metrics. Comparing the relative value of each service with its development or maintenance cost should make the prioritization. The decision model is useful to support an approach to identifying the optimum portfolio of services based on the prioritization of business needs, followed by an estimation of the technical feasibility for each candidate service.},
  doi       = {10.1109/WICT.2014.7077302},
}

@InProceedings{Azarmi2017,
  author    = {Azarmi, Mehdi and Bhargava, Bharat},
  booktitle = {2017 IEEE 10th International Conference on Cloud Computing (CLOUD)},
  title     = {An End-to-End Dynamic Trust Framework for Service-Oriented Architecture},
  year      = {2017},
  month     = {June},
  pages     = {568-575},
  abstract  = {Service-oriented architecture (SOA) is an architectural paradigm that advocates composition of loosely-coupled services in order to construct more complex applications. The agility and complexity of modern web services on one hand and the arbitrary interconnections among them on the other hand, make it difficult to maintain a sustainable trustworthiness in long-running SOA-based applications. Moreover, the chain of participating services in a specific SOA invocation may not be visible to the service consumers, which leads to a lack of accountability. To address these challenges in SOA, we propose the following contributions. First, we design a new dynamic and flexible trust model based on graph abstraction that uses multiple trust strategies to calculate trust across SOA. This trust model keeps track of three trust metrics: individual service trust, session trust, and composite trust. We further design a trust engine component that implements the proposed trust model and that continuously maintains the quantitative end-to-end trust based on processing actual execution of services. Second, to prove the practicality and usefulness of the proposed framework, we have implemented an adaptive and secure service composition engine (ASSC) which takes advantage of an efficient algorithm to generate service compositions with near-optimal trustworthiness under predefined QoS constraints. Finally, we have developed a tool that is able to automatically deploy SOA testbeds from arbitrary directed acyclic graphs (created in the GUI). This tool enables the researcher to study the dynamics of new trust algorithms and strategies under different scenarios (e.g., arbitrary SOA topologies and attacks). We have extensively studied the effectiveness and performance of the proposed solutions using testbeds in the Amazon EC2 cloud.},
  doi       = {10.1109/CLOUD.2017.78},
  issn      = {2159-6190},
}

@InProceedings{Fahmi2021,
  author    = {Fahmi, Faisal and Huang, Pei-Shu and Wang, Feng-Jian and Yang, Hongji},
  booktitle = {2021 IEEE International Conference on Services Computing (SCC)},
  title     = {Constructing a Creative Software with Services},
  year      = {2021},
  month     = {Sep.},
  pages     = {134-144},
  abstract  = {Service Oriented Architecture (SOA) and Creative Computing can be applied to construct a creative service software by utilizing various domain knowledges, where the software contains a solution that not only effective, but also novel, useful and surprising. In creative computing, several theoretical evaluation metrics and verification approaches have been proposed for system design in several domains. However, a solid methodology for development of creative service software is rarely considered in current researches. In this paper, we propose a method composed of requirement specification and service design phases to develop creative software with SOA, where each phase applies a specification model based on semantic web. Inside the development, the models containing XML structures and the associated directed graphs are constructed in both phases to improve machine readability for automatic information processing in creative computing and reduce communication work among development participants with different knowledges, respectively. The graph models defined also can improve the traceability of the specifications and support machine processing. After the model resulted in the second phase is validated for consistency and completeness, the creative service software is well-constructed and can be implemented and reused effectively. Besides, a real example is adopted to demonstrate the workings of the method.},
  doi       = {10.1109/SCC53864.2021.00026},
  issn      = {2474-2473},
}

@Article{Macis2020,
  author   = {Macis, Silvia and Loi, Daniela and Ulgheri, Andrea and Pani, Danilo and Solinas, Giuliana and Manna, Serena La and Cestone, Vincenzo and Guerri, Davide and Raffo, Luigi},
  journal  = {IEEE Journal of Biomedical and Health Informatics},
  title    = {Design and Usability Assessment of a Multi-Device SOA-Based Telecare Framework for the Elderly},
  year     = {2020},
  issn     = {2168-2208},
  month    = {Jan},
  number   = {1},
  pages    = {268-279},
  volume   = {24},
  abstract = {Telemonitoring is a branch of telehealth that aims at remotely monitoring vital signs, which is important for chronically ill patients and the elderly living alone. The available standalone devices and applications for the self-monitoring of health parameters largely suffer from interoperability problems; meanwhile, telemonitoring medical devices are expensive, self-contained, and are not integrated into user-friendly technological platforms for the end user. This paper presents the technical aspects and usability assessment of the telemonitoring features of the HEREiAM platform, which supports heterogeneous information technology systems. By exploiting a service-oriented architecture, the measured parameters collected by off-the-shelf Bluetooth medical devices are sent as XML documents to a private cloud that implements an interoperable health service infrastructure, which is compliant with the most recent healthcare standards and security protocols. This Android-based system is designed to be accessible both via TV and portable devices, and includes other utilities designed to support the elderly living alone. Four usability assessment sessions with quality-validated questionnaires were performed to accurately understand the ease of use, usefulness, acceptance, and quality of the proposed system. The results reveal that our system achieved very high usability scores even at its first use, and the scores did not significantly change over time during a field trial that lasted for four months, reinforcing the idea of an intuitive design. At the end of such a trial, the user-experience questionnaire achieved excellent scores in all aspects with respect to the benchmark. Good results were also reported by general practitioners who assessed the quality of their remote interfaces for telemonitoring.},
  doi      = {10.1109/JBHI.2019.2894552},
}

@InProceedings{Manso2015,
  author    = {Manso, Marco and Alcaraz Calero, Jose Maria and Barz, Christoph and Bloebaum, Trude Hafsøe and Chan, Kevin and Jansen, Norman and Johnsen, Frank Trethan and Markarian, Garik and Meiler, Peter-Paul and Owens, Ian and Sliwa, Joanna and Wang, Qi},
  booktitle = {MILCOM 2015 - 2015 IEEE Military Communications Conference},
  title     = {SOA and Wireless Mobile Networks in the tactical domain: Results from experiments},
  year      = {2015},
  month     = {Oct},
  pages     = {593-598},
  abstract  = {The NATO research task group IST-118 titled “SOA recommendations for disadvantaged grids in the tactical domain” is addressing the challenge of implementing the Service Oriented Architecture (SOA) paradigm at the tactical level by providing guidance and best practices in the form of a Tactical SOA Profile. The group will conduct identification and feasibility assessments of possible improvements of the Tactical SOA Profile, over a series of live and emulated experiments. In this paper, we describe our first experiments in applying SOA Web services to mobile nodes that are connected using Wireless Broadband Mobile Networks (WBMN) in the tactical domain. The experiments involved components provided by various nations, including radio hardware equipment, the Publish/Subscribe messaging service and NATO Friendly Force Information (NFFI) (as our functional service). We measured the system performance at service and physical (radio) levels in the presence of network disruption. We conclude by presenting the results of the experiments and a view of future work.},
  doi       = {10.1109/MILCOM.2015.7357508},
}

@Article{Trang2018,
  author   = {Trang, Mai Xuan and Murakami, Yohei and Ishida, Toru},
  journal  = {IEEE Transactions on Services Computing},
  title    = {Policy-Aware Service Composition: Predicting Parallel Execution Performance of Composite Services},
  year     = {2018},
  issn     = {1939-1374},
  month    = {July},
  number   = {4},
  pages    = {602-615},
  volume   = {11},
  abstract = {With the increasing volume of data to be analysed, one of the challenges in Service Oriented Architecture (SOA) is to make web services efficient in processing large-scale data. Parallel execution and cloud technologies are the keys to speed-up the service invocation. In SOA, service providers typically employ policies to limit parallel execution of the services based on arbitrary decisions. In order to attain optimal performance improvement, users need to adapt to the services policies. A composite service is a combination of several atomic services provided by various providers. To use parallel execution for greater composite service efficiency, the degree of parallelism (DOP) of the composite services need to be optimized by considering the policies of all atomic services. We propose a model that embeds service policies into formulae to calculate composite service performance. From the calculation, we predict the optimal DOP for the composite service, where it attains the best performance. Extensive experiments are conducted on real-world translation services. We use several measures such as mean prediction error (MPE), mean absolute deviation (MAD) and tracking signal (TS) to evaluate our model. The analysis results show that our proposed model has good prediction accuracy in identifying optimal DOPs for composite services.},
  doi      = {10.1109/TSC.2015.2467330},
}

@InProceedings{Soomro2020,
  author    = {Soomro, Arif Hussain and Jilani, Muhammad Taha},
  booktitle = {2020 International Conference on Information Science and Communication Technology (ICISCT)},
  title     = {Application of IoT and Artificial Neural Networks (ANN) for Monitoring of Underground Coal Mines},
  year      = {2020},
  month     = {Feb},
  pages     = {1-8},
  abstract  = {Explosions in coal mines during the work time is a one of major cause of casualties in the coal mines. Thus possess a life threaten situation for coal miners. In this paper we propose a system in which sensors sense concentration of gases (Methane and carbon monoxide) in the air, measures the mine temperature and humidity and heartbeat of miner. In response it generate the alerts, and identifies the location of miners. We propose ZigBee based wireless sensor network (WSN) for communication between sensors and coal mine safety monitoring system. The iBeacons are proposed for identification of miners. A service oriented architecture (SOA) has used to develop the system. The main purpose of this research paper is to ensure miners safety, by predicting the methane has with artificial neural network (ANN). The application of ANN seems more viable than others, the calculated values shows that its prove a negligible relative error that is around 0.05.. than the actual measurements. The proposed work is then compared with the state-of-the-art methods that overcomes the limitations form the existing systems.},
  doi       = {10.1109/ICISCT49550.2020.9080034},
}

@InProceedings{Yunofri2018,
  author    = {Yunofri and Suhardi and Kurniawan, Novianto Budi},
  booktitle = {2018 International Conference on Information Technology Systems and Innovation (ICITSI)},
  title     = {Designing Service Computing Platform for Statistical Project Management Based on SOA},
  year      = {2018},
  month     = {Oct},
  pages     = {99-104},
  abstract  = {Statistical are identical to conducting surveys. The process of conducting a survey is still not in accordance with the stages of planning, so that the impact on business processes is not maximized from the entire survey. The implementation of the project management system in statistical is expected to improve the control function in the survey. As information technology develops, service concepts can improve project management systems. Project management services make every component in project management work effectively and efficiently. Project management services develop in the addition of features, technology and resources. So there needs to be a system that can accommodate these needs by having functions that can be expanded. The service computing platform is the answer to this problem. A service computing platform is an architecture designed to support the process of preparing web services, and can provide tools and techniques for modeling, simulating, analyzing, planning, providing and monitoring service-oriented applications in real time. This platform can also be used as a basis for implementing various surveys. Statistics Indonesia (SI) needs to make improvements in conducting surveys. In line with the increasing quality of data produced by SI, it is necessary to develop a service computing platform for statistical project management. This study proposes a service computing platform using the Service Computing System Engineering (SCSE) methodology. After getting the service computing platform design, the proposed design is evaluated. Design evaluation is measured by Coupling Factor 0.0034 (loose coupling), Cohesion Factor 0.9198 (high cohesion), Complexity Factor 0.00368 (low complexity) and Reusability Factor 5.28571 (reusable) indicating that the design value is quite good.},
  doi       = {10.1109/ICITSI.2018.8695920},
}

@InProceedings{Radwan2017,
  author    = {Radwan, Wafaa and Hassouneh, Yousef and Sayyad, Abdel Salam and Ammar, Nariman},
  booktitle = {2017 IEEE International Conference on Services Computing (SCC)},
  title     = {YAFA-SOA: A GA-Based Optimizer for Optimizing Security and Cost in Service Compositions},
  year      = {2017},
  month     = {June},
  pages     = {330-337},
  abstract  = {This paper studies heuristic search-based optimization of service compositions. We have investigated applying Genetic Algorithms (GA) to optimize service-oriented architectures (SOA) in terms of security goals and cost, we help software Engineers to map the optimized service composition to the business process model based on security and cost. Service composition security risk is measured by implementing the aggregation rules from the local security risk values of the aggregated services in the composition. We adapt the DREAD model for Security risk assessment by suggesting new categorizations for calculating DREAD factors based on a proposed service structure and service attributes. We implemented the YAFA-SOA Optimizer as an extension of an existing GA implementation to solve multi-objective optimization problems for varying number of objectives in the context of SOA. We evaluated the tool in a case study. The study results show that applying multi-objective GA is feasible to find the optimized security and cost in SOA-based systems. We were able to approve that adding security services to the generated composition reduces the risk severity of the generated composition and enhances its security in terms of confidentiality, integrity and availability (CIA). We found that the generated service composition risk severity is less than 0.5, which matches the validation results obtained from a security expert.},
  doi       = {10.1109/SCC.2017.49},
  issn      = {2474-2473},
}

@InProceedings{Wang2022c,
  author    = {Wang, Yu-Te and Ma, Shang-Pin and Lai, Yue-Jun and Liang, Yan-Cih},
  booktitle = {2022 29th Asia-Pacific Software Engineering Conference (APSEC)},
  title     = {Analyzing and Monitoring Kubernetes Microservices based on Distributed Tracing and Service Mesh},
  year      = {2022},
  month     = {Dec},
  pages     = {477-481},
  abstract  = {The microservice system architecture (MSA) outperforms the monolithic system architecture in terms of maintainability, extensibility, scalability, and fault tolerance. This is prompting a widescale migration of software systems from existing monolith systems to MSA. Most microservice systems utilize container technology for deployment. The fact that Kubernetes (K8s) provides a fully-fledged toolchain for managing container-based applications is prompting many organizations to adopt the K8s protocol for microservice system deployment and operations. Microservice monitoring is essential to the success of any service operation. The collection of logs and aggregation of metrics by most existing microservice monitoring systems is somewhat intrusive. Furthermore, the heterogeneity of Kubernetes technology means that most monitoring methods are inapplicable in situations where microservices are developed for a system using a variety of underlying languages and platforms. In the current study, we developed a monitoring mechanism that provides various metrics specific to microservice systems in a nonintrusive way. The proposed K8s-based microservice monitoring system, referred to as KMamiz (Kubernetes-based Microservice Analysis and Monitoring using Istio and Zipkin), enables the construction and visualization for service-level/endpoint-level dependency graphs and endpoint request chains, and the service cohesion/coupling analysis to enhance system quality for the development team.},
  doi       = {10.1109/APSEC57359.2022.00066},
  issn      = {2640-0715},
}

@InProceedings{Joyce2022,
  author    = {Joyce, Josephine Eskaline and Sebastian, Shoney},
  booktitle = {2022 IEEE 4th PhD Colloquium on Emerging Domain Innovation and Technology for Society (PhD EDITS)},
  title     = {Reinforcement Learning based Autoscaling for Kafka-centric Microservices in Kubernetes},
  year      = {2022},
  month     = {Nov},
  pages     = {1-2},
  abstract  = {Microservices and Kafka have become a perfect match for enabling the Event-driven Architecture and this encourages microservices integration with various opensource platforms in the world of Cloud Native applications. Kubernetes is an opensource container orchestration platform, that can enable high availability, and scalability for Kafkacentric microservices. Kubernetes supports diverse autoscaling mechanisms like Horizontal Pod Autoscaler (HPA), Vertical Pod Autoscaler (VPA) and Cluster Autoscaler (CA). Among others, HPA automatically scales the number of pods based on the default Resource Metrics, which includes CPU and memory usage. With Prometheus integration, custom metrics for an application can be monitored. In a Kafkacentric microservices, processing time and speed depends on the number of messages published. There is a need for auto scaling policy which can be based on the number of messages processed. This paper proposes a new autoscaling policy, which scales Kafka-centric microservices deployed in an eventdriven deployment architecture, using a Reinforcement Learning model.},
  doi       = {10.1109/PhDEDITS56681.2022.9955300},
}

@InProceedings{Wang2022d,
  author    = {Wang, Xinkai and Li, Chao and Zhang, Lu and Hou, Xiaofeng and Chen, Quan and Guo, Minyi},
  booktitle = {2022 IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  title     = {Exploring Efficient Microservice Level Parallelism},
  year      = {2022},
  month     = {May},
  pages     = {223-233},
  abstract  = {The microservice architecture has recently become a driving trend in the cloud by disaggregating a monolithic application into many scenario-oriented service blocks (microservices). The decomposition process results in a highly dynamic execution scenario, in which various chained microservices contend for computing resources in different ways. While parallelism has been exploited at both the instruction/thread level and the task/request level, very limited work has been done with the grain-size of a microservice. Current parallel processing solutions are sub-optimal as they neither capture the unique characteristics of microservices nor consider the uncertainty arises in the microservice environment. In this work we introduce microservice level parallelism (MLP), a technique that aims to precisely coalesce and align parallel microservice chains for better system performance and resource utilization. We identify major issues that prevent servers from effectively exploiting MLP and we define metrics that can guide MLP optimization. We propose v-MLP, a volatility-aware MLP that is able to adapt to a highly heterogeneous and dynamic microservice environment. We show that v-MLP can reduce tail latency by up to 50% and improve resource utilization by up to 15 % under various scenarios.},
  doi       = {10.1109/IPDPS53621.2022.00030},
  issn      = {1530-2075},
}

@InProceedings{Li2023d,
  author    = {Li, Yang and Zhang, Yang and Yang, Yilong and Wang, Weiru and Yin, Yongfeng},
  booktitle = {2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)},
  title     = {RM2MS: A Tool for Automatic Identification of Microservices from Requirements Models},
  year      = {2023},
  month     = {Oct},
  pages     = {50-54},
  abstract  = {Microservices identification is the key development process of cloud-native applications. It focuses on decomposing system into decoupling autonomous components to support development and deployment independently. This process requires sophisticated human efforts for careful requirements analysis and validation to identify the appropriate microservices boundary inside system modules. Our previous work RM2PT can help to achieve a validated requirements model through automatically generating prototypes from original requirements models. The validated requirements model contains the precise definitions of functionality and data structure that can help in microservices identification. In this paper, we present a tool named RM2MS to further alleviate the problem of cloud-native application development to support automatic identification of microservices from the validated requirements model. RM2MS can automatically analyse the relationship between functionality and data structure, and trade-off non-functional factors for microservices identification. We demonstrate that the microservice architecture solution generated by RM2MS demonstrates a average gain of 27.1% over the manual approach in three key metrics(Function-Cohesion, Modularity, and Instability), while exhibiting efficiency that surpasses the manual process by more than 10-fold through five case studies. The proposed approach can be further extended and applied for the cloud-native application development in the software industry. The tool can be downloaded at https://rm2pt.com/advs/rm2ms, and a demo video casting its features is at https://www.youtube.com/watch?v=T71vQDasOSw},
  doi       = {10.1109/MODELS-C59198.2023.00018},
}

@Article{Xu2023,
  author   = {Xu, Yueshen and Qiu, Zhibo and Gao, Honghao and Zhao, Xinkui and Wang, Lu and Li, Rui},
  journal  = {IEEE Transactions on Consumer Electronics},
  title    = {Heterogeneous Data-Driven Failure Diagnosis for Microservice-Based Industrial Clouds Towards Consumer Digital Ecosystems},
  year     = {2023},
  issn     = {1558-4127},
  pages    = {1-1},
  abstract = {Consumer digital ecosystems include a large volume of different types of applications, and those applications are usually deployed in industrial cloud computing systems. Currently, microservices are one of the most prevailing architectures for industrial clouds. Similar to other architectures, microservices may also produce failures, so failure diagnosis for microservices becomes an inevitable problem in industrial clouds. A majority of existing methods focus on statistical analysis for monitoring data or system topological structure. However, because these methods usually only harness service-level or machine-level metrics, they cannot complete fine-grained failure diagnosis, increasing the running risk of microservice-based industrial clouds. To tackle this issue, in this paper, we design a novel graph structure to represent failure dependencies, especially the heterogeneity, and name it as the heterogeneous failure dependence graph (HFDG). We propose a framework to inform engineers which type of and where failures occur in industrial clouds. The HFDG can be used to mine the propagation of failures between different types of components. We also propose a novel neural network model based on attention mechanism and heterogeneous graph neural network, to fully leverage the metric data and HFDG. We performed experiments on three large-scale public datasets from real-world microservices-based systems. The experimental results demonstrate the superior performance of our model compared to well-known baselines.},
  doi      = {10.1109/TCE.2023.3337351},
}

@InProceedings{Jack2023,
  author    = {Jack, Chang Hoong and Teck, See Kwee and Ming, Lim Tong and Hong, Ding Ying},
  booktitle = {2023 IEEE 8th International Conference On Software Engineering and Computer Systems (ICSECS)},
  title     = {An Overview Analysis of Authentication Mechanism in Microservices-Based Software Architecture: A Discussion Paper},
  year      = {2023},
  month     = {Aug},
  pages     = {1-6},
  abstract  = {Microservices-based software architecture promotes scalability and flexibility by breaking down a software application into smaller modules and making it more independent and loosely coupled services compared to monolith systems. However, securing microservices in a distributed nature has become one of the challenges. Authentication is one of the most critical components that should be focused in the microservices security measures. It helps to identify that only authenticated personnel and services can access sensitive information and secure the trust between microservices. This discussion paper aims to provide an overview analysis and extensive understanding on the authentication mechanism in microservices-based software architecture. In this study, we explore different authentication mechanisms including Mutual Transport Layer Security (mTLS), Token based authentication and API Gateway authentication. This study examines the strengths and limitations of different authentication mechanisms in microservices-based software architecture. It also emphasizes the importance of authentication and the need for having a well-designed authentication mechanism to ensure the integrity and security of microservices-based software architecture is crucial.},
  doi       = {10.1109/ICSECS58457.2023.10256409},
}

@InProceedings{Speth2022,
  author    = {Speth, Sandro and Stieß, Sarah and Becker, Steffen},
  booktitle = {2022 IEEE 19th International Conference on Software Architecture Companion (ICSA-C)},
  title     = {A Saga Pattern Microservice Reference Architecture for an Elastic SLO Violation Analysis},
  year      = {2022},
  month     = {March},
  pages     = {116-119},
  abstract  = {Reference architectures are becoming increasingly popular for industry and researchers as benchmark solutions to test their novel concepts and tools. While many reference architectures exist in the microservice domain, they are often not built on state-of-the-art technologies. Furthermore, many existing reference architectures do not use lightweight and asynchronous communications, such as messaging, do not have out-of-the-box self-adaptation and do not consider state-of-the-art microservice patterns. Therefore, this paper proposes a self-adaptive microservice reference architecture that implements the microservice saga pattern. The architecture is implemented in Java Spring Boot and uses the Eventuate Tram framework for the saga orchestration. Moreover, the architecture is instrumented to export performance metrics for monitoring and data for system-wide tracing to check for correct execution of the system and its adaptations. The objective of this reference architecture is to provide a benchmark for explaining self-adaptation and propagation of service-level objective (SLOs) violations across an architecture with complex patterns. In addition to the architecture, we provide defined SLOs and load profiles to stress the architecture.},
  doi       = {10.1109/ICSA-C54293.2022.00029},
  issn      = {2768-4288},
}

@Article{Ma2022,
  author   = {Ma, Meng and Lin, Weilan and Pan, Disheng and Wang, Ping},
  journal  = {IEEE Transactions on Services Computing},
  title    = {Self-Adaptive Root Cause Diagnosis for Large-Scale Microservice Architecture},
  year     = {2022},
  issn     = {1939-1374},
  month    = {May},
  number   = {3},
  pages    = {1399-1410},
  volume   = {15},
  abstract = {The emergence of microservice architecture in Cloud systems poses a new challenges for the reliability operation and maintenance. Due to numerous services and diverse types of metrics, it is time-consuming and challenging to identify the root cause of anomaly in large-scale microservice architecture. To solve this issue, this article presents a multi-metric and self-adaptive root cause diagnosis framework, named MS-Rank. MS-Rank decomposes the task into four phases: impact graph construction, random walk diagnosis, result precision evaluation, metrics weight update. Initially, we introduce the concept of implicit metrics and propose a composite impact graph construction algorithm, using multiple types of metrics to discover causal relationships between services. Afterwards, we propose a diagnostic algorithm in which forward, selfward and backward transitions are designed to heuristically identify the root cause services. In addition, we establish a self-adaptive mechanism to update the confidence of different metrics dynamically according to their diagnostic precision. Lastly, we develop a prototype system and integrate MS-Rank into real production system - IBM Cloud. Experimental results show that MS-Rank has a high diagnostic precision and its performance outperforms several selected benchmarks. Through multiple rounds of diagnosis, MS-Rank can optimize itself effectively. MS-Rank can be rapidly deployed in various microservice-based systems and applications, requiring no predefined knowledge. MS-Rank also allows us to introduce expert experiences into its framework to improve the diagnostic efficiency and precision.},
  doi      = {10.1109/TSC.2020.2993251},
}

@InProceedings{Sarda2023,
  author    = {Sarda, Komal},
  booktitle = {2023 IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion (ACSOS-C)},
  title     = {Leveraging Large Language Models for Auto-remediation in Microservices Architecture},
  year      = {2023},
  month     = {Sep.},
  pages     = {16-18},
  abstract  = {Microservices architecture is popular due to its scalability and flexibility. However, managing and troubleshooting distributed microservices-based systems can be challenging and time consuming. Auto-remediation of anomalies, that is the automated detection and root-causes generation and execution of repair scripts, can reduce the down-times and increase the availability of systems. This thesis will explore the potential and effectiveness of using large language models (LLMs) in auto-remediation. It will develop an auto-remediation framework to mitigate the effects of performance-based anomalies in self-adaptive microservice architectures. Multiple sample microservice applications as test-bed will be rigorously studied, and a dataset will be created to evaluate LLM-based codegeneration models using semantic, lexical, and correctness metrics in zero-shot and few-shot scenarios. Additionally, we will develop reliable prompts for automated Ansible runbook generation and assess their efficiency for orchestrating the auto-remediation process, including deployment, configuration changes, and system recovery to improve application reliability and operational efficiency.},
  doi       = {10.1109/ACSOS-C58168.2023.00025},
}

@InProceedings{Frank2022,
  author    = {Frank, Sebastian and Wagner, Lion and Hakamian, Alireza and Straesser, Martin and van Hoorn, André},
  booktitle = {2022 IEEE 22nd International Conference on Software Quality, Reliability and Security (QRS)},
  title     = {MiSim: A Simulator for Resilience Assessment of Microservice-Based Architectures},
  year      = {2022},
  month     = {Dec},
  pages     = {1014-1025},
  abstract  = {Increased resilience compared to monolithic architectures is both one of the key promises of microservice-based architectures and a big challenge, e.g., due to the systems’ distributed nature. Resilience assessment through simulation requires fewer resources than the measurement-based techniques used in practice. However, there is no existing simulation approach that is suitable for a holistic resilience assessment of microservices comprised of (i) representative fault injections, (ii) common resilience mechanisms, and (iii) time-varying workloads. This paper presents MiSim — an extensible simulator for resilience assessment of microservice-based architectures. It overcomes the stated limitations of related work. MiSim fits resilience engineering practices by supporting scenario-based experiments and requiring only lightweight input models. We demonstrate how MiSim simulates (1) common resilience mechanisms — i.e., circuit breaker, connection limiter, retry, load balancer, and autoscaler — and (2) fault injections — i.e., instance/service killing and latency injections. In addition, we use TeaStore, a reference microservice-based architecture, aiming to reproduce scaling behavior from an experiment by using simulation. Our results show that MiSim allows for quantitative insights into microservice-based systems’ complex transient behavior by providing up to 25 metrics.},
  doi       = {10.1109/QRS57517.2022.00105},
  issn      = {2693-9177},
}

@InProceedings{Li2023e,
  author    = {Li, Yuewei and Lu, Yan and Wang, Jingyu and Qi, Qi and Wang, Jing and Wang, Yingying and Liao, Jianxin},
  booktitle = {2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  title     = {TADL: Fault Localization with Transformer-based Anomaly Detection for Dynamic Microservice Systems},
  year      = {2023},
  month     = {March},
  pages     = {718-722},
  abstract  = {Due to the complexity of microservice architecture, it is difficult to accomplish efficient microservice anomaly detection and localization tasks and achieve the target of high system reliability. For rapid failure recovery and user satisfaction, it is significant to detect and locate anomalies fast and accurately in microservice systems. In this paper, we propose an anomaly detection and localization model based on Transformer, named TADL (Transformer-based Anomaly Detector and Locator), which models the temporal features and dynamically captures container relationships using Transformer with sandwich structure. TADL uses readily available container performance metrics, making it easy to implement in already-running container clusters. Evaluations are conducted on a sock-shop dataset collected from a real microservice system and a publicly available dataset SMD. Empirical studies on the above two datasets demonstrate that TADL can outperform baseline methods in the performance of anomaly detection, the latency of anomaly detection, and the effect of anomalous container localization, which indicates that TADL is useful in maintaining complex and dynamic microservice systems in the real world.},
  doi       = {10.1109/SANER56733.2023.00078},
  issn      = {2640-7574},
}

@InProceedings{Pearce2022,
  author    = {Pearce, Glen and Pflaum, Alexis and Balasoiu, Dumitru Alin and Szabo, Claudia},
  booktitle = {2022 Winter Simulation Conference (WSC)},
  title     = {Jeopardy Assessment for Dynamic Configuration of Collaborative Microservice Architectures},
  year      = {2022},
  month     = {Dec},
  pages     = {2070-2081},
  abstract  = {Microservice architectures, which are lightweight, flexible, and adapt easily to changes, have recently been considered for system development in military operations in contested and dynamic environments. However, in a military setting, the dynamic configuration of collaborative microservices execution becomes critical, and testing that microservice configurations behave as expected becomes paramount. In this paper, we propose a complex jeopardy metric and reconfiguration process that dynamically configures collaborative algorithms running on multiple nodes. Our metric and proposed scenarios will allow for the automated evaluation of microservice configurations and their re-configuration to suit operational needs. We evaluate our proposed scenario, metric, and various reconfiguration algorithms to show the benefits of this approach.},
  doi       = {10.1109/WSC57314.2022.10015475},
  issn      = {1558-4305},
}

@InProceedings{Bi2022,
  author    = {Bi, Tingzhu and Pan, Yicheng and Jiang, Xinrui and Ma, Meng and Wang, Ping},
  booktitle = {2022 IEEE 33rd International Symposium on Software Reliability Engineering (ISSRE)},
  title     = {VECROsim: A Versatile Metric-oriented Microservice Fault Simulation System (Tools and Artifact Track)},
  year      = {2022},
  month     = {Oct},
  pages     = {297-308},
  abstract  = {Automated fault diagnosis of microservice systems has been a hot topic in recent years. As most incidents in real commercial cloud systems are not publicly available, we have witnessed researchers putting considerable effort into developing various experimental systems. However, previous tools cannot quickly refactor their functionality, scale the architecture, and customize fault characteristics. Given this, we develop VECROsim, a versatile metric-oriented microservice fault simulation system, and release the VECROsim benchmark dataset. VECROsim works delicately as a highly-customizable toolkit to generate abnormal performance metrics datasets of microservice systems on demand and automatically. Validation of representative services from the benchmark dataset confirms the capability of VECROsim to generate realistic performance metrics for diverse real-world systems. Our case studies on root cause analysis and dynamic correlation discovery demonstrated the superiority of VECROsim. We also witnessed that the VECROsim dataset brings new research challenges to state-of-the-art fault diagnosis schemes. VECROsim concretely supports microservice developers from the industry, as well as academic researchers working on fault diagnosis or broader research topics in many ways.},
  doi       = {10.1109/ISSRE55969.2022.00037},
  issn      = {2332-6549},
}

@Article{Gu2023,
  author   = {Gu, Shenghui and Rong, Guoping and Ren, Tian and Zhang, He and Shen, Haifeng and Yu, Yongda and Li, Xian and Ouyang, Jian and Chen, Chunan},
  journal  = {IEEE Transactions on Software Engineering},
  title    = {TrinityRCL: Multi-Granular and Code-Level Root Cause Localization Using Multiple Types of Telemetry Data in Microservice Systems},
  year     = {2023},
  issn     = {1939-3520},
  month    = {May},
  number   = {5},
  pages    = {3071-3088},
  volume   = {49},
  abstract = {The microservice architecture has been commonly adopted by large scale software systems exemplified by a wide range of online services. Service monitoring through anomaly detection and root cause analysis (RCA) is crucial for these microservice systems to provide stable and continued services. However, compared with monolithic systems, software systems based on the layered microservice architecture are inherently complex and commonly involve entities at different levels of granularity. Therefore, for effective service monitoring, these systems have a special requirement of multi-granular RCA. Furthermore, as a large proportion of anomalies in microservice systems pertain to problematic code, to timely troubleshoot these anomalies, these systems have another special requirement of RCA at the finest code-level. Microservice systems rely on telemetry data to perform service monitoring and RCA of service anomalies. The majority of existing RCA approaches are only based on a single type of telemetry data and as a result can only support uni-granular RCA at either application-level or service-level. Although there are attempts to combine metric and tracing data in RCA, their objective is to improve RCA's efficiency or accuracy rather than to support multi-granular RCA. In this article, we propose a new RCA solution TrinityRCL that is able to localize the root causes of anomalies at multiple levels of granularity including application-level, service-level, host-level, and metric-level, with the unique capability of code-level localization by harnessing all three types of telemetry data to construct a causal graph representing the intricate, dynamic, and nondeterministic relationships among the various entities related to the anomalies. By implementing and deploying TrinityRCL in a real production environment, we evaluate TrinityRCL against two baseline methods and the results show that TrinityRCL has a significant performance advantage in terms of accuracy at the same level of granularity with comparable efficiency and is particularly effective to support large-scale systems with massive telemetry data.},
  doi      = {10.1109/TSE.2023.3241299},
}

@Article{Khazaei2022,
  author   = {Khazaei, Hamzeh and Mahmoudi, Nima and Barna, Cornel and Litoiu, Marin},
  journal  = {IEEE Transactions on Cloud Computing},
  title    = {Performance Modeling of Microservice Platforms},
  year     = {2022},
  issn     = {2168-7161},
  month    = {Oct},
  number   = {4},
  pages    = {2848-2862},
  volume   = {10},
  abstract = {Microservice architecture has transformed the way developers are building and deploying applications in the nowadays cloud computing centers. This new approach provides increased scalability, flexibility, manageability, and performance while reducing the complexity of the whole software development life cycle. The increase in cloud resource utilization also benefits microservice providers. Various microservice platforms have emerged to facilitate the DevOps of containerized services by enabling continuous integration and delivery. Microservice platforms deploy application containers on virtual or physical machines provided by public/private cloud infrastructures in a seamless manner. In this article, we study and evaluate the provisioning performance of microservice platforms by incorporating the details of all layers (i.e., both micro and macro layers) in the modeling process. To this end, we first build a microservice platform on top of Amazon EC2 cloud and then leverage it to develop a comprehensive performance model to perform what-if analysis and capacity planning for microservice platforms at scale. In other words, the proposed performance model provides a systematic approach to measure the elasticity of the microservice platform by analyzing the provisioning performance at both the microservice platform and the back-end macroservice infrastructures.},
  doi      = {10.1109/TCC.2020.3029092},
}

@Article{Abgaz2023,
  author   = {Abgaz, Yalemisew and McCarren, Andrew and Elger, Peter and Solan, David and Lapuz, Neil and Bivol, Marin and Jackson, Glenn and Yilmaz, Murat and Buckley, Jim and Clarke, Paul},
  journal  = {IEEE Transactions on Software Engineering},
  title    = {Decomposition of Monolith Applications Into Microservices Architectures: A Systematic Review},
  year     = {2023},
  issn     = {1939-3520},
  month    = {Aug},
  number   = {8},
  pages    = {4213-4242},
  volume   = {49},
  abstract = {Microservices architecture has gained significant traction, in part owing to its potential to deliver scalable, robust, agile, and failure-resilient software products. Consequently, many companies that use large and complex software systems are actively looking for automated solutions to decompose their monolith applications into microservices. This paper rigorously examines 35 research papers selected from well-known databases using a Systematic Literature Review (SLR) protocol and snowballing method, extracting data to answer the research questions, and presents the following four contributions. First, the Monolith to Microservices Decomposition Framework (M2MDF) which identifies the major phases and key elements of decomposition. Second, a detailed analysis of existing decomposition approaches, tools and methods. Third, we identify the metrics and datasets used to evaluate and validate monolith to microservice decomposition processes. Fourth, we propose areas for future research. Overall, the findings suggest that monolith decomposition into microservices remains at an early stage and there is an absence of methods for combining static, dynamic, and evolutionary data. Insufficient tool support is also in evidence. Furthermore, standardised metrics, datasets, and baselines have yet to be established. These findings can assist practitioners seeking to understand the various dimensions of monolith decomposition and the community's current capabilities in that endeavour. The findings are also of value to researchers looking to identify areas to further extend research in the monolith decomposition space.},
  doi      = {10.1109/TSE.2023.3287297},
}

@InProceedings{Yang2022b,
  author    = {Yang, Linwei and Li, Jing and Shi, Kuanzhi and Yang, Songlin and Yang, Qingfu and Sun, Jiangang},
  booktitle = {2022 23rd Asia-Pacific Network Operations and Management Symposium (APNOMS)},
  title     = {MicroMILTS: Fault Location for Microservices Based Mutual Information and LSTM Autoencoder},
  year      = {2022},
  month     = {Sep.},
  pages     = {1-6},
  abstract  = {Driven by the development of cloud computing and artificial intelligence, architecture has dramatically improved in terms of flexibility and scalability in software development. Therefore, it is increasingly being used to build large-scale applications for agile development. However, along with the technology heterogeneity, the dynamics of running instances, and the complexity of service dependencies, fault localization is extraordinarily difficult. In this paper, we present MicroMILTS, a microservice fault location method based on mutual information and an LSTM Autoencoder. MicroMILTS first uses BIRCH for anomaly detection based on the analysis of the performance metrics data correlated to microservice anomalies. Once anomalies are detected, a service dependency property graph is constructed based on the real-time microservice invocation relationships and the reconstructed deviations of performance metrics with the LSTM Autoencoder. Next, MicroMILTS dynamically updates the weight of each node in the service dependency property graph. Then, a PageRank-based random walk is applied for further ranking root causes. Finally, a Sock-shop microservice system is built on the Huawei Cloud to evaluate the performance of MicroMILTS. The experiment shows that MicroMILTS achieves a good root cause location result, with 90.4 % in precision and 91.6% in mean average precision, outperforming state-of-the-art methods.},
  doi       = {10.23919/APNOMS56106.2022.9919941},
  issn      = {2576-8565},
}

@Article{Zdun2023a,
  author   = {Zdun, Uwe and Queval, Pierre-Jean and Simhandl, Georg and Scandariato, Riccardo and Chakravarty, Somik and Jelić, Marjan and Jovanović, Aleksandar},
  journal  = {IEEE Transactions on Dependable and Secure Computing},
  title    = {Detection Strategies for Microservice Security Tactics},
  year     = {2023},
  issn     = {1941-0018},
  pages    = {1-17},
  abstract = {Microservice architectures are widely used today to implement distributed systems. Securing microservice architectures is challenging because of their polyglot nature, continuous evolution, and various security concerns relevant to such architectures. This article proposes a novel, model-based approach providing detection strategies to address the automated detection of security tactics (or patterns and best practices) in a given microservice architecture decomposition model. Our novel detection strategies are metrics-based rules that decide conformance to a security recommendation based on a statistical predictor. The proposed approach models this recommendation using Architectural Design Decisions (ADDs). We apply our approach for four different security-related ADDs on access management, traffic control, and avoiding plaintext sensitive data in the context of microservice systems. We then apply our approach to a model data set of 10 open-source microservice systems and 20 variants of those systems. Our results are detection strategies showing a very low bias, a very high correlation, and a low prediction error in our model data set.},
  doi      = {10.1109/TDSC.2023.3276487},
}

@InProceedings{Filippone2023,
  author    = {Filippone, Gianluca and Qaisar Mehmood, Nadeem and Autili, Marco and Rossi, Fabrizio and Tivoli, Massimo},
  booktitle = {2023 IEEE 20th International Conference on Software Architecture (ICSA)},
  title     = {From monolithic to microservice architecture: an automated approach based on graph clustering and combinatorial optimization},
  year      = {2023},
  month     = {March},
  pages     = {47-57},
  abstract  = {Migrating from a legacy monolithic system to a microservice architecture is a complex and time-consuming process. Software engineers may strongly benefit from automated support to identify a high-cohesive and loose-coupled set of microservices with proper granularity. The automated approach proposed in this paper extracts microservices by using graph clustering and combinatorial optimization to maximize cohesion and minimize coupling. The approach performs static analysis of the code to obtain a graph representation of the monolithic system. Then, it uses graph clustering to detect high-cohesive communities of nodes using the Louvain community algorithm. In parallel, the tool clusters the domain entities (i.e., classes representing uniquely identifiable concepts in a system domain) within bounded contexts to identify the required service granularity. Finally, it uses combinatorial optimization to minimize the coupling, hence deriving the microservice architecture. The approach is fully implemented. We applied it over four different monolithic systems and found valuable results. We evaluated the identified architectures through cohesion and coupling metrics, along with a comparison with other state-of-the-art approaches based on features such as granularity level, number of produced services, and methods applied. The approach implementation and the experimental results are publicly available.},
  doi       = {10.1109/ICSA56044.2023.00013},
}

@InProceedings{Uenlue2023,
  author    = {Ünlü, Hüseyin and Hacaloğlu, Tuna and Ömüral, Neslihan Küçükateş and Çalişkanel, Neslihan and Leblebici, Onur and Demirörs, Onur},
  booktitle = {2023 49th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)},
  title     = {An Exploratory Case Study on Effort Estimation in Microservices},
  year      = {2023},
  month     = {Sep.},
  pages     = {215-218},
  abstract  = {Software project management plays an important role in producing high-quality software, and effort estimation can be considered as a backbone for successful project management. Size is a very significant attribute of software by being the only input to perform early effort estimation. Even though functional size measurement methods showed successful results in effort estimation of traditional data-centric architectures such as monoliths, they were not designed for today’s architectures which are more service-based and decentralized such as microservices. In these new systems, the event concept is highly used specifically for communication among different services. By being motivated by this fact, in this study, we looked for more microservice-compatible ways of sizing microservices using events and developed a method accordingly. Then, we conducted an exploratory case study in an organization using agile methods and measured the size of 17 Product Backlog Items (PBIs) to assess how this proposed method can be useful in effort estimation in microservices. The implication from the case study is that despite performing a more accurate effort estimation using the proposed size measurement than COSMIC, we were unable to significantly outperform using the total number of events. However, our suggested approach demonstrated to us a different way to use software size in terms of events, namely, to determine the coupling complexity of the project. This finding can be beneficial specifically when evaluating the change requests.},
  doi       = {10.1109/SEAA60479.2023.00040},
  issn      = {2376-9521},
}

@InProceedings{Adrio2023,
  author    = {Adrio, Kendricko and Tanzil, Clementius Nichklaus and Lianto, Michael Christian and Rasjid, Zulfany Erlisa},
  booktitle = {2023 10th International Conference on Electrical Engineering, Computer Science and Informatics (EECSI)},
  title     = {Comparative Analysis of Monolith, Microservice API Gateway and Microservice Federated Gateway on Web-based application using GraphQL API},
  year      = {2023},
  month     = {Sep.},
  pages     = {654-660},
  abstract  = {The purpose of this research is to provide a detailed explanation regarding the characteristics as well as the pros and cons offered by various software development architecture, such as monolithic and Microservice architecture implemented with graph-based API called GraphQL. Monolithic architecture offers a centralized software development pattern with relatively simpler integration and development process. Conversely, Microservices architecture such as Gateway Aggregation and Federated Gateway will divide independent components of the application into smaller modules. Gateway Aggregation utilizes a single Gateway which acts as the main entry point for data exchange between the client and the application. In this research aims an application is developed using the three different architectures to measure the quality, both qualitative and quantitative performances of each architecture. There are several different parameters that are going to be used to measure the architecture’s performance such as response time and data throughput which become an essential criterion in conducting load and stress testing. The result is that the Monolithic architecture offers some advantages in its quantitative performance measurement due to better efficiency in collecting and processing requested data in a single application which utilizes fewer resources and shorter time. In contrast, the Gateway Aggregation architecture and Federated Gateway architecture also have some significant performance differences because it costs resources to combine several subgraphs together into a valid graph.},
  doi       = {10.1109/EECSI59885.2023.10295809},
}

@InProceedings{Kleftakis2022,
  author    = {Kleftakis, Spyridon and Mavrogiorgou, Argyro and Zafeiropoulos, Nikolaos and Mavrogiorgos, Konstantinos and Kiourtis, Athanasios and Kyriazis, Dimosthenis},
  booktitle = {2022 IEEE International Conference on Computing (ICOCO)},
  title     = {A Comparative Study of Monolithic and Microservices Architectures in Machine Learning Scenarios},
  year      = {2022},
  month     = {Nov},
  pages     = {352-357},
  abstract  = {Choosing the most suitable architecture for applications is not an easy decision. While the software giants have almost all put in place the microservices architecture, on smaller platforms such decision it is not so obvious. In the healthcare domain and specifically when accomplishing Machine Learning (ML) tasks in this domain, considering its special characteristics, the decision should be made based on specific metrics. In the context of the beHEALTHIER platform, a platform that is able to handle heterogeneous healthcare data towards their successful management and analysis by applying various ML tasks, such research gap was fully investigated. There has been conducted an experiment by installing the platform in three (3) different architectural ways, referring to the monolithic architecture, the clustered microservices architecture exploiting docker compose, and the microservices architecture exploiting Kubernetes cluster. For these three (3) environments, time-based measurements were made for each Application Programming Interface (API) of the diverse platform’s functionalities (i.e., components) and useful conclusions were drawn towards the adoption of the most suitable software architecture.},
  doi       = {10.1109/ICOCO56118.2022.10031648},
}

@InProceedings{Abbasi2023,
  author    = {Abbasi, Maryam and Melo, Pedro and Saraiva, Luzia and Pereira, Pedro and Martins, Pedro and Sá, Filipe and Cardoso, Filipe},
  booktitle = {2023 18th Iberian Conference on Information Systems and Technologies (CISTI)},
  title     = {Enhancing Banking Operations with Microservices and Mobile Technology},
  year      = {2023},
  month     = {June},
  pages     = {1-6},
  abstract  = {This paper presents a novel architecture for enhancing the banking experience by combining microservices and a mobile application. The use of microservices provides scalability and flexibility in the development process, making it easier to add new features or modify existing ones. The results of the study shows that the proposed architecture is capable of handling high volume of transactions and requests while providing high quality of service. The mobile application provides a user-friendly interface for accessing financial information, and the use of microservices ensures efficient management of data and transactions. The architecture also has the potential to improve security through the use of security measures to protect sensitive data. As a future research direction, the proposed architecture can be evaluated in real-world settings and its security can be further tested. The field of technology in the banking sector is constantly evolving, and it is important to stay updated with new advancements that can potentially improve the proposed architecture.},
  doi       = {10.23919/CISTI58278.2023.10211993},
  issn      = {2166-0727},
}

@Article{Zeb2023,
  author   = {Zeb, Shah and Rathore, Muhammad Ahmad and Hassan, Syed Ali and Raza, Saleem and Dev, Kapal and Fortino, Giancarlo},
  journal  = {IEEE Wireless Communications},
  title    = {Toward AI-Enabled NextG Networks with Edge Intelligence-Assisted Microservice Orchestration},
  year     = {2023},
  issn     = {1558-0687},
  month    = {June},
  number   = {3},
  pages    = {148-156},
  volume   = {30},
  abstract = {Network agility, automation, and intelligence are at the forefront of the next-generation networks (NGNs) vision, which aims to provide zero-touch service management and self-optimizing networks. In this article, we give an overview of the significance of artificial intelligence (Ali-enabled NGNs, their projected benefits, design requirements, and critical challenges for evolving heterogeneous softwarized networks where microservices can be autonomously orchestrated, scaled, and maintained. The convergence of emerging disruptive technologies, for example, AI, network softwarization, hybrid cloud/edge-native computing architecture, with NGNs accelerates the enhanced service-oriented architecture at the network core/edge level to support on-demand microservices, such as visibility services for intelligent network management. In addition, we present a use case study and conduct experiments based on a novel design of an edge intelligence framework that orchestrates and deploys AI microservices utilizing the testbed resources of a multisite cloud/edge-native NGNs. We use a deep learning-based forecaster model to predict near real-time edge network flow between a centralized service orchestrator hub and multiple edge devices, geographically apart. The obtained results show that the deployed forecaster model accurately predicts the throughput and latency of edge network flow (verified against the groundtruth observations), which is additionally validated through two performance metrics obtained, low root-mean-square error, and high coefficient of determination values. Finally, we outline some of the potential future prospects for AI-enabled NGNs research.},
  doi      = {10.1109/MWC.015.2200461},
}

@InProceedings{Raghunandan2023,
  author    = {Raghunandan, Arpitha and Kalasapura, Deepti and Caesar, Matthew},
  booktitle = {ICC 2023 - IEEE International Conference on Communications},
  title     = {Digital Twinning for Microservice Architectures},
  year      = {2023},
  month     = {May},
  pages     = {3018-3023},
  abstract  = {Digital twins have been designed and implemented for diverse applications like smart manufacturing, healthcare, supply chain and retail management. They provide monitoring, remote prognostics and health management capabilities for the various physical assets used in these domains. Many of these capabilities would be beneficial to microservice architectures as well, given the need for lightweight monitoring solutions in multitenant environments. In particular, twins can provide operators with real-time resource usage metrics which help with operational objectives such as resource planning, anomaly detection, rewind and replay and so on. In this work, we propose a design for building digital twins for microservice architectures. As a proof of concept, we focus on modelling the resource utilization as that is a key requirement for monitoring system reliability and security. In general, digital twins require a real world counterpart, a virtual model and a mechanism for consistently keeping both synchronized. We focus on the two latter aspects of the digital twin. Our approach involves converting a formal model of a microservice architecture into a digital twin that can capture and execute an actual cluster's state. We present an extensible architecture connecting the various components of the system and the twin and evaluate the twin's ability to capture the real-time state of a real Kubernetes cluster. We also discuss future extensions which can enhance the system's security by detecting a broad range of attacks.},
  doi       = {10.1109/ICC45041.2023.10279802},
  issn      = {1938-1883},
}

@InProceedings{Raharjo2022,
  author    = {Raharjo, Agus Budi and Andyartha, Putu Krisna and Wijaya, William Handi and Purwananto, Yudhi and Purwitasari, Diana and Juniarta, Nyoman},
  booktitle = {2022 International Conference on Computer Engineering, Network, and Intelligent Multimedia (CENIM)},
  title     = {Reliability Evaluation of Microservices and Monolithic Architectures},
  year      = {2022},
  month     = {Nov},
  pages     = {1-7},
  abstract  = {Software is continuously evolving as business processes that needed to be solved become increasingly complex. Software architecture is an important aspect during software design, with monolithic and microservices being two of the most common with their own advantages and disadvantages. Monolithic is a unified system with a relatively fast development time. Meanwhile, microservices facilitates low coupling and high cohesion, prioritizing maintenance, and ease of modification post-development. This research compares microservices and monolithic API-based thesis monitoring systems. Implementations are done using PHP, Redis, PostgreSQL, Docker, and Heroku. Reliability evaluations are done through automated tests with Apache JMeter. Metrics used are maturity, availability, fault tolerance, and recoverability based on the ISO/IEC 25010 reliability quality characteristics. The conclusion section showed that microservices are more reliable than the monolithic by demonstrating much better fault tolerance and recoverability, with comparable maturity and availability.},
  doi       = {10.1109/CENIM56801.2022.10037281},
}

@InProceedings{Hettiarachchi2022,
  author    = {Hettiarachchi, Lasal Sandeepa and Jayadeva, Senura Vihan and Bandara, Rusiru Abhisheak Vikum and Palliyaguruge, Dilmi and Arachchillage, Udara Srimath S. Samaratunge and Kasthurirathna, Dharshana},
  booktitle = {2022 13th International Conference on Computing Communication and Networking Technologies (ICCCNT)},
  title     = {Artificial Intelligence-Based Centralized Resource Management Application for Distributed Systems},
  year      = {2022},
  month     = {Oct},
  pages     = {1-6},
  abstract  = {Due to the decentralized nature and emergence of new practices, tools, and platforms, microservices have become one of the most widely spread software architectures in the modern software industry. Furthermore, the advancement of software packaging tools like Docker and orchestration platforms such as Kubernetes enable developers and operation engineers to deploy and manage microservice applications more effectively and efficiently. However, establishing and managing microservice applications are still cumbersome due to the infrastructure configuration and array of disjoint tools that fail to understand the application’s dynamic behavior. As a result, developers need to configure multiple tools and platforms to automate the deployment and monitoring process to provide the optimal deployment strategy for microservices. Even though many tools are available in the industry, the fully automated product which comprises deployment, monitoring, resiliency evaluation and optimization were not developed yet. In response to this issue, we propose an artificial intelligence (AI)-based centralized resource management tool, that provides an automated low latency container management, cluster metrics gathering, resiliency evaluation and optimal deployment strategy behave in dynamic nature.},
  doi       = {10.1109/ICCCNT54827.2022.9984530},
}

@InProceedings{Daniel2023,
  author    = {Daniel, João and Guerra, Eduardo and Rosa, Thatiane and Goldman, Alfredo},
  booktitle = {2023 49th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)},
  title     = {Towards the Detection of Microservice Patterns Based on Metrics},
  year      = {2023},
  month     = {Sep.},
  pages     = {132-139},
  abstract  = {Microservices is a popular architectural approach for complex systems in companies, despite its nature of decentralization. There is a comprehensive set of microservices architectural patterns that guides implementations and helps developers to overcome issues. However, the community still scarcely adopts these patterns and only has a theoretical understanding of them. In this work, in order to increase awareness of such patterns and provide aid to developers to better understand an architecture based on microservices, we propose a detection approach based on metrics for microservices patterns. We focused on structural or architectural patterns, and implemented detection for five of them. We conducted two case studies with real-world applications and evaluated the accuracy and applicability of our approach with the developers of those applications.},
  doi       = {10.1109/SEAA60479.2023.00029},
  issn      = {2376-9521},
}

@InProceedings{Huang2023b,
  author    = {Huang, Jun and Yang, Yang and Yu, Hang and Li, Jianguo and Zheng, Xiao},
  booktitle = {2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  title     = {Twin Graph-Based Anomaly Detection via Attentive Multi-Modal Learning for Microservice System},
  year      = {2023},
  month     = {Sep.},
  pages     = {66-78},
  abstract  = {Microservice architecture has sprung up over recent years for managing enterprise applications, due to its ability to independently deploy and scale services. Despite its benefits, ensuring the reliability and safety of a microservice system remains highly challenging. Existing anomaly detection algorithms based on a single data modality (i.e., metrics, logs, or traces) fail to fully account for the complex correlations and interactions between different modalities, leading to false negatives and false alarms, whereas incorporating more data modalities can offer opportunities for further performance gain. As a fresh attempt, we propose in this paper a semi-supervised graph-based anomaly detection method, MSTGAD, which seamlessly integrates all available data modalities via attentive multi-modal learning. First, we extract and normalize features from the three modalities, and further integrate them using a graph, namely MST (microservice system twin) graph, where each node represents a service instance and the edge indicates the scheduling relationship between different service instances. The MST graph provides a virtual representation of the status and scheduling relationships among service instances of a real-world microservice system. Second, we construct a transformer-based neural network with both spatial and temporal attention mechanisms to model the inter-correlations between different modalities and temporal dependencies between the data points. This enables us to detect anomalies automatically and accurately in real-time. Extensive experiments on two real-world datasets verify the effectiveness of our proposed MSTGAD method, achieving competitive performance against state-of-the-art approaches, with a 0.961 F1-score and an average increase of 4.85%. The source code of MST-GAD is publicly available at https://github.com/ant-research/microservice_system_twin_graph_based_anomaly_detection.},
  doi       = {10.1109/ASE56229.2023.00138},
  issn      = {2643-1572},
}

@InProceedings{Pramesti2022,
  author    = {Pramesti, Annisa Ayu and Kistijantoro, Achmad Imam},
  booktitle = {2022 9th International Conference on Advanced Informatics: Concepts, Theory and Applications (ICAICTA)},
  title     = {Autoscaling Based on Response Time Prediction for Microservice Application in Kubernetes},
  year      = {2022},
  month     = {Sep.},
  pages     = {1-6},
  abstract  = {Containerized application are evolving along with the microservice architectures in distributed application development. This trend shows the importance of managing and orchestrating containerized applications thus applications can operate properly. One of the aspects of container orchestration is scaling or increasing the application’s ability to handle more requests. In this study, an autoscaler based on response time prediction is developed for microservice applications in Kubernetes environment. The prediction function is developed using a machine learning model that features performance metrics at the microservice and node levels. The response time prediction is then used to calculate the number of pods required by the application to meet the target response time. Our experiment shows that the proposed autoscaler can serve more requests that match the target response time compare with the Kubernetes Horizontal Pod Autoscaler (HPA) that are using CPU usage as the target. However, as the consequence, the proposed autoscaler consumes more resources than the Kubernetes HPA.},
  doi       = {10.1109/ICAICTA56449.2022.9932943},
}

@InProceedings{Kalinagac2023a,
  author    = {Kalinagac, Onur and Soussi, Wissem and Anser, Yacine and Gaber, Chrystel and Gür, Gürkan},
  booktitle = {ICC 2023 - IEEE International Conference on Communications},
  title     = {Root Cause and Liability Analysis in the Microservices Architecture for Edge IoT Services},
  year      = {2023},
  month     = {May},
  pages     = {3277-3283},
  abstract  = {In this work, we present a liability analysis frame-work for root cause analysis (RCA) in the microservices architecture with IoT-oriented containerized network services. We keep track of the performance metrics of microservices, such as service response time, memory usage and availability, to detect anomalies. By injecting faults in the services, we construct a Causal Bayesian Network (CBN) which represents the relation between service faults and metrics. Service Level Agreement (SLA) data obtained from a descriptor named TRAILS (sTakeholder Responsibility, AccountabIlity and Liability deScriptor) is also used to flag service providers which have failed their commitments. In the case of SLA violation, the constructed CBN is used to predict the fault probability of services under given metric readings and to identify the root cause.},
  doi       = {10.1109/ICC45041.2023.10279721},
  issn      = {1938-1883},
}

@InProceedings{Castro2023a,
  author    = {Castro, Jessica and Laranjeiro, Nuno and Vieira, Marco},
  booktitle = {2023 IEEE International Conference on Web Services (ICWS)},
  title     = {Exploring Logic Scoring of Preference for DoS Attack Detection in Microservice Applications},
  year      = {2023},
  month     = {July},
  pages     = {573-584},
  abstract  = {Microservice architectures allow the development of highly scalable, flexible, and manageable systems. However, such architectures raise new security problems and exacerbate the challenge of monitoring applications at runtime due to their high service granularity and distributed nature. Developing effective monitoring and security strategies is thus crucial to effectively detect potential attacks. This paper explores the applicability of Logic Scoring of Preference (LSP), a multi-criteria decision-making method to compute a score based on a set of preferences, for attack detection in microservice applications. We present an extensive experimental study and define a model based on LSP and application-level metrics to characterize the impact of DoS attacks. The output of the model is a unique score used to determine whether a microservice is under a DoS attack. The results of the experimental study show precision, recall, and f1-score rates of more than 80%, indicating that LSP could effectively characterize the application under attack, opening several possibilities for future work.},
  doi       = {10.1109/ICWS60048.2023.00076},
  issn      = {2836-3868},
}

@InProceedings{Yang2023,
  author    = {Yang, Yunhao and Jiang, Ying},
  booktitle = {2023 IEEE 9th International Conference on Cloud Computing and Intelligent Systems (CCIS)},
  title     = {Microservice Indicator Prediction Method Based on STE and CNN-BiLSTM},
  year      = {2023},
  month     = {Aug},
  pages     = {511-515},
  abstract  = {Due to the extensibility and continuous evolution of microservice architecture, there are a lot of uncertainties in the microservice system, which brings great risks to the reliability of the service. Indicator prediction plays an important role in service reliability. If the predicted value exceeds the safe range, alarms are generated and measures are taken to prevent faults. Therefore, a microservice indicator prediction method based on SET and CNN-BiLSTM is proposed. Symbolic transfer entropy (STE) is used to analyze the nonlinear causality, and a prediction model based on CNN-BiLSTM is established. The simulation results show that this method can capture the causal relationship between the indicators with nonlinear relationship effectively and improve the prediction accuracy.},
  doi       = {10.1109/CCIS59572.2023.10262956},
  issn      = {2376-595X},
}

@InProceedings{Jhingran2023,
  author    = {Jhingran, Sushant and Rakesh, Nitin},
  booktitle = {2023 International Conference on Sustainable Emerging Innovations in Engineering and Technology (ICSEIET)},
  title     = {Application Deployment and Performance Measurement in Serverless Cloud for Microservices},
  year      = {2023},
  month     = {Sep.},
  pages     = {173-177},
  abstract  = {The effectiveness of Cloud technology relies heavily on its ability to perform at a high level. To measure this performance, it is necessary to conduct a performance evaluation based on specific aims and applications and assess the capabilities of the cloud services. In the case of enterprise applications deployed on the cloud, the service provider must consider the application's deployment model, security, networking, and operational constraints. This evaluation involves identifying benchmarks, configuring the system, running tests, analyzing results, and providing recommendations. There are various performance metrics that can be applied to different aspects of the cloud services to evaluate their performance. The figures below display data on resource utilization and the impact of the load on the application. Microservices offer organizations the opportunity to deploy applications on the cloud by providing web service functions and an architecture that enables scaling and updating of applications with minimal inconsistency. Through public cloud technology such as Amazon Web Services, organizations can deploy secure and valuable applications to the cloud.},
  doi       = {10.1109/ICSEIET58677.2023.10303332},
}

@InProceedings{Lin2023,
  author    = {Lin, Zhichao and Wang, Qingsheng and Yang, Shifeng and Luo, Busheng and Ma, Qiujie and Yu, Chuankun},
  booktitle = {2023 8th Asia Conference on Power and Electrical Engineering (ACPEE)},
  title     = {Modeling and Performance Analysis of Cloud-Based Active Distribution Networks Based on EdgeCloudSim},
  year      = {2023},
  month     = {April},
  pages     = {1682-1687},
  abstract  = {In order to realise the performance + analysis of the cloud-based active distribution network, this paper proposes the modeling and performance analysis method of the cloud-based active distribution network. Firstly, based on the task processing requirements of the active distribution network, the corresponding task modeling method based on microservices is proposed. Then, the cloud-based active distribution network architecture modeling is proposed, and the corresponding dynamic resource allocation process is realised. In addition, through the professional edge computing simulation software EdgeCloudSim, the modeling of the cloud-based active distribution network is realised. The modeling includes specific scenarios, resource allocation and two task spatio-temporal logics. Task delay and resource load rate are as performance metrics. Finally, with microservices as the research granularity, the performance differences of different task spatio-temporal logics are analysed.},
  doi       = {10.1109/ACPEE56931.2023.10136018},
}

@InProceedings{Xu2022b,
  author    = {Xu, Beibei and Zhao, Yanqing and Kuzminykh, Valeriy and Zhu, Shiwei and Yu, Junfeng and Zhang, Mingjun and Li, Sisi},
  booktitle = {ICETIS 2022; 7th International Conference on Electronic Technology and Information Science},
  title     = {Research on the Evaluation System of International S&T Cooperation Based on Microservice Architecture},
  year      = {2022},
  month     = {Jan},
  pages     = {1-5},
  abstract  = {The development of the world has benefited from advances in science and technology, and the destiny of mankind has become closer due to scientific and technological cooperation. International scientific and technological innovation cooperation is one of the important indicators to measure the potential and technological innovation of a country or region. Scientific evaluation and performance evaluation of international scientific and technological cooperation have become important for effectively improving the management level of international scientific and technological cooperation projects and promoting scientific and technological output. Means, the construction of a scientific cooperation evaluation and performance evaluation system has become a realistic demand for promoting international scientific and technological cooperation and strengthening performance management of international scientific and technological cooperation in the new era. Based on the analysis of the data sources, data structure, index evaluation system and system functions of the international scientific and technological cooperation evaluation system, the article proposes the system logic and hierarchical structure under the microservice architecture, and designs and implements the international scientific and technological cooperation evaluation system based on the microservice architecture.},
}

@InProceedings{Hrusto2022a,
  author    = {Hrusto, Adha and Engström, Emelie and Runeson, Per},
  booktitle = {2022 IEEE/ACM 10th International Workshop on Software Engineering for Systems-of-Systems and Software Ecosystems (SESoS)},
  title     = {Optimization of Anomaly Detection in a Microservice System Through Continuous Feedback from Development},
  year      = {2022},
  month     = {May},
  pages     = {13-20},
  abstract  = {Monitoring a microservice system may bring a lot of benefits to development teams such as early detection of run-time errors and various performance anomalies. In this study, we explore deep learning (DL) solutions for detection of anomalous system’s behavior based on collected monitoring data that consists of applications’ and systems’ performance metrics. The study is conducted in a collaboration with a Swedish company responsible for ticket and payment management in public transportation. Moreover, we specifically address a shortage of approaches for evaluating DL models without any ground truth data. Hence, we propose a solution design for anomaly detection and reporting alerts inspired by state-of-the-art DL solutions. Furthermore, we propose a plan for its in-context implementation and evaluation empowered by feedback from the development team. Through continuous feedback from development, the labeled data is generated and used for optimization of the DL model. In this way, a microservice system may leverage DL solutions to address rising challenges within its architecture. CCS CONCEPTS • Software and its engineering → Software post-development issues; • Information systems → Data mining; Computing platforms; • Computing methodologies → Machine learning.},
}

@InProceedings{Garbi2023,
  author    = {Garbi, Giulio and Incerto, Emilio and Tribastone, Mirco},
  booktitle = {2023 IEEE 16th International Conference on Cloud Computing (CLOUD)},
  title     = {μP: A Development Framework for Predicting Performance of Microservices by Design},
  year      = {2023},
  month     = {July},
  pages     = {178-188},
  abstract  = {Microservice (MS) architecture has become a popular paradigm in software engineering and has been embraced in the industry (e.g., Amazon, Netflix) for cloud-based applications with crucial performance requirements. Surprisingly, assessing how the MS designs affect performance is still a challenging issue, which is generally tackled by extensive and expensive profiling. In this paper, we propose $\mu \mathbf{P}$, a novel development framework for MS applications where performance can be predicted $by$ design. $\mu \mathbf{P}$ offers an API that automatically generates a per-formance model based on Layered Queuing Networks (LQNs) without requiring any development effort beyond writing the actual system code. The model can then be queried to predict performance metrics such as response time and utilization of individual microservices. We validate $\mu \mathbf{P}$ on four benchmarks taken from the literature. The results show the effectiveness of $\mu \mathbf{P}$ in accurately predicting performance due to increasing user load, vertical and horizontal scaling. We report prediction errors for response times consistently lower than 10% across a wide range of operating conditions.},
  doi       = {10.1109/CLOUD60044.2023.00029},
  issn      = {2159-6190},
}

@InProceedings{Pinciroli2023,
  author    = {Pinciroli, Riccardo and Aleti, Aldeida and Trubiani, Catia},
  booktitle = {2023 IEEE 20th International Conference on Software Architecture (ICSA)},
  title     = {Performance Modeling and Analysis of Design Patterns for Microservice Systems},
  year      = {2023},
  month     = {March},
  pages     = {35-46},
  abstract  = {The adoption of design patterns in the microservice architecture and cloud-native development scope was recently reviewed to investigate the industry practice. Interestingly, when considering performance-related aspects, practitioners focus on specific metrics (e.g., the time taken to handle requests) to identify sources of performance hindrance. This paper investigates a subset of seven design patterns that industrial practitioners indicate as relevant for system performance. We are interested to quantify the impact of these patterns while considering heterogeneous workloads, thus supporting software architects in understanding the root causes of performance issues. We use queuing networks to build the performance models of the seven design patterns and extract quantitative insights from model-based performance analysis. Our performance models are flexible in their input parameterization and reusable in different application contexts. We find that most design patterns confirm the expectation of practitioners, and our experimental results assess the identified performance gains and pains. One design pattern (i.e., Gateway Offloading) shows the peculiar characteristic of contributing to performance pains in some cases, leading to novel insights about the impact of design patterns in microservice systems.},
  doi       = {10.1109/ICSA56044.2023.00012},
}

@InProceedings{Li2022e,
  author    = {Li, Gongliang and Wen, Zepeng and Xie, Xin},
  booktitle = {2022 IEEE 24th Int Conf on High Performance Computing & Communications; 8th Int Conf on Data Science & Systems; 20th Int Conf on Smart City; 8th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)},
  title     = {Unsupervised Anomaly Detection Based on CNN-VAE with Spectral Residual for KPIs},
  year      = {2022},
  month     = {Dec},
  pages     = {1307-1313},
  abstract  = {Current large-scale applications, such as trading systems, blockchain, social software, etc, are increasingly adopting microservice architecture, which bring challenges to manual operation and maintenance, intrusion detection. In both operations and intrusion detection, there are a common characteristic that service metrics and network traffic are normal for most of the time, but anomaly data is more important. In this paper, we propose an unsupervised anomaly detection algorithm based on convolutional neural network with Spectral Residual, which is verified experimentally and has potential application capability with 19.2% f1-score improvement compared to the Variational AutoEncoder.},
  doi       = {10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00204},
}

@InProceedings{Jaival2022,
  author    = {Jaival, Madhavi and Mkrtchyan, Katya and Kaplan, Adam},
  booktitle = {2022 International Conference on Computational Science and Computational Intelligence (CSCI)},
  title     = {Serverless Cloud Functions - Opportunity in Chaos},
  year      = {2022},
  month     = {Dec},
  pages     = {1330-1335},
  abstract  = {Due to its cost-effectiveness and limited scope of administration, Serverless Computing has fast become a favorite cloud computing execution model. Meanwhile, with the rise of distributed cloud architectures and microservices in the last decade, many development teams have adopted the principles of Chaos Engineering. This allows them to assess the effects of random failures or delays on an application. In prior literature, serverless developers measured and reported cold-start penalties and transaction latency, whereas Chaos Engineers have studied security and resiliency in cloud infrastructure. In this work, we combine these approaches to measure the performance of a set of serverless cloud functions which implement common server-side file and database operations. We study each function's performance response under a set of controlled chaos experiments, wherein we emulate various client load conditions, as well as inject random delays into the function execution. We find that under heavy 1000-client load, the longest-latency operations can provide as much as 36.5% improvement to overall response time by failing early.},
  doi       = {10.1109/CSCI58124.2022.00239},
  issn      = {2769-5654},
}

@InProceedings{Centofanti2023,
  author    = {Centofanti, C. and Tiberti, W. and Marotta, A. and Graziosi, F. and Cassioli, D.},
  booktitle = {2023 IEEE 9th International Conference on Network Softwarization (NetSoft)},
  title     = {Latency-Aware Kubernetes Scheduling for Microservices Orchestration at the Edge},
  year      = {2023},
  month     = {June},
  pages     = {426-431},
  abstract  = {Network and computing infrastructures are nowadays challenged to meet the increasingly stringent requirements of novel applications. One of the most critical aspect is optimizing the latency perceived by the end-user accessing the services. New network architectures offer a natural framework for the efficient orchestration of microservices. However, how to incorporate accurate latency metrics into orchestration decisions still represents an open challenge.In this work we propose a novel architectural approach to perform scheduling operations in Kubernetes environment. Existing approaches proposed the collection of network metrics, e.g. latency between nodes in the cluster, via purposely-built external measurement services deployed in the cluster. Compared to other approaches the proposed one: (i) collects performance metrics at the application layer instead of network layer; (ii) relies on latency measurements performed inside the service of interest instead of utilizing external measurement services; (iii) takes scheduling decisions based on effective end-user perceived latency instead of considering the latency between cluster nodes.We show the effectiveness of our approach by adopting an iterative discovery strategy able to dynamically determine which node operates with the lowest latency for the Kubernetes pod placement.},
  doi       = {10.1109/NetSoft57336.2023.10175431},
  issn      = {2693-9789},
}

@InProceedings{Leiter2022,
  author    = {Leiter, Ákos and Huszti, Dániel and Galambosi, Nándor and Lami, Edina and Salah, Mohamad Saleh and Kulics, Péter and Bokor, László},
  booktitle = {2022 13th International Symposium on Communication Systems, Networks and Digital Signal Processing (CSNDSP)},
  title     = {Cloud-native IP-based mobility management: a MIPv6 Home Agent standalone microservice design},
  year      = {2022},
  month     = {July},
  pages     = {252-257},
  abstract  = {The ever-increasing traffic and mobility events impose an unprecedented load on mobile networks. Meanwhile, the number of connected users and devices has been growing continuously; hence IPv6 is necessary to serve them. The mobility extension of IPv6 (Mobile IPv6) can also support and handle the rising demand for mobility management in the IP layer. At the same time, concepts like Network Function Virtualization, Software Defined Networks, and microservice architectures have changed the landscape of telecommunication services. In this paper, our prototype implementation is measured and evaluated: what containerization causes in case of different MIPv6-re1ated traffic types on the top of Kubernetes. Additionally, Kubernetes Container Network Interface types are compared for a microservice and container-based standalone Home Agent entity of a cloud-native Mobile IPv6 implementation.},
  doi       = {10.1109/CSNDSP54353.2022.9908059},
}

@InProceedings{Serbout2022,
  author    = {Serbout, Souhaila and Lauro, Fabio Di and Pautasso, Cesare},
  booktitle = {2022 IEEE 19th International Conference on Software Architecture Companion (ICSA-C)},
  title     = {Web APIs Structures and Data Models Analysis},
  year      = {2022},
  month     = {March},
  pages     = {84-91},
  abstract  = {Microservice architectures emphasize keeping components small, to foster autonomy, low coupling and independent evolution. In this large-scale empirical study we measure the size of Web API specifications mined from open source repositories. These APIs are modeled using the OpenAPI Specification (OAS), which, in addition to documenting the offered operations, also contain schemas definitions for the data exchanged with the API request and response message payloads. This study has as a goal to build empirical knowledge about: (1) How big and diverse are real-world web APIs both in terms of their operations and data, (2) How different API structures use and reuse schema definitions. By mining public software repositories on Github, we gathered 42,194 valid OAS specifications published between 2014-2021. These specifications include descriptions of Web APIs of well-known services providers such as Google, VMware (Avi Networks), Twilio, Amazon. After measuring the size of API structures and their data model schemas, we found that most APIs are rather small. Also there is a medium correlation between the size of the APIs’ functional structures and their data models. API developers do reuse schema definitions within the same API model.},
  doi       = {10.1109/ICSA-C54293.2022.00059},
  issn      = {2768-4288},
}

@InProceedings{Uenlue2022,
  author    = {Ünlü, Hüseyin and Hacaloglu, Tuna and Büber, Fatma and Berrak, Kıvılcım and Leblebici, Onur and Demirörs, Onur},
  booktitle = {2022 48th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)},
  title     = {Utilization of Three Software Size Measures for Effort Estimation in Agile World: A Case Study},
  year      = {2022},
  month     = {Aug},
  pages     = {239-246},
  abstract  = {Functional size measurement (FSM) methods, by being systematic and repeatable, are beneficial in the early phases of the software life cycle for core project management activities such as effort, cost, and schedule estimation. However, in agile projects, requirements are kept minimal in the early phases and are detailed over time as the project progresses. This situation makes it challenging to identify measurement components of FSM methods from requirements in the early phases, hence complicates applying FSM in agile projects. In addition, the existing FSM methods are not fully compatible with today’s architectural styles, which are evolving into event-driven decentralized structures. In this study, we present the results of a case study to compare the effectiveness of different size measures: functional -COSMIC Function Points (CFP)-, event-based - Event Points-, and code length-based - Line of Code (LOC)-on projects that were developed with agile methods and utilized a microservice-based architecture. For this purpose, we measured the size of the project and created effort estimation models based on three methods. It is found that the event-based method estimated effort with better accuracy than the CFP and LOC-based methods.},
  doi       = {10.1109/SEAA56994.2022.00045},
}

@Article{Surantha2022,
  author   = {Surantha, Nico and Utomo, Oei K. and Lionel, Earlicha M. and Gozali, Isabella D. and Isa, Sani M.},
  journal  = {IEEE Access},
  title    = {Intelligent Sleep Monitoring System Based on Microservices and Event-Driven Architecture},
  year     = {2022},
  issn     = {2169-3536},
  pages    = {42069-42080},
  volume   = {10},
  abstract = {Sleep monitoring using polysomnography (PSG) in hospitals can be considered expensive, so the preferable way is to use contactless and wearable sensors to monitor sleep daily by patients at home. In this study, the Internet-of-Things (IoT) platform was utilized for sleep monitoring with contactless or wearable sensors as an integrated system developed based on an event-driven and microservice architecture. Multiple services that respond to events are provided within the system. Electrocardiogram (ECG) data were used as the input in the sleep monitoring system. The combination of the weighted extreme learning machine (WELM) algorithm with particle swarm optimization (PSO) was used to process the ECG data, followed by fuzzy logic to measure sleep quality, then display the data on the dashboard. Based on the experimental results, the proposed architecture increased throughput by 34.76%, decreased response time by 55.85%, and reduced memory consumption by 37.26% per instance replication compared to the non-event-driven architecture. The accuracies of the sleep stage classification were 78.78% and 73.09% for the three and four classes, respectively, and the area under a receiver operating characteristic (ROC) curve (AUC) reached 0.89 for both the three and four class classifications.},
  doi      = {10.1109/ACCESS.2022.3167637},
}

@InProceedings{ElMalki2022,
  author    = {El Malki, Amine and Zdun, Uwe and Pautasso, Cesare},
  booktitle = {2022 IEEE International Conference on Service-Oriented System Engineering (SOSE)},
  title     = {Impact of API Rate Limit on Reliability of Microservices-Based Architectures},
  year      = {2022},
  month     = {Aug},
  pages     = {19-28},
  abstract  = {Many API patterns and best practices have been developed around microservices-based architectures, such as Rate Limiting and Circuit Breaking, to increase quality properties such as reliability, availability, scalability, and performance. Even though estimates on such properties would be beneficial, especially during the early design of such architectures, the real impact of the patterns on these properties has not been rigorously studied yet. This paper focuses on API Rate Limit and its impact on reliability properties from the perspective of API clients. We present an analytical model that considers specific workload configurations and predefined rate limits and then accurately predicts the success and failure rates of the back-end services. The model also presents a method for adaptively fine-tuning rate limits. We performed two extensive data experiments to validate the model and measured Rate Limiting impacts, firstly on a private cloud to minimize latency and other biases, and secondly on the Google Cloud Platform to test our model in a realistic cloud environment. In both experiments, we observed a low percentage of prediction errors. Thus, we conclude that our model can provide distributed system engineers and architects with insights into an acceptable value for the rate limits to choose for a given workload. Very few works empirically studied the impact of Rate Limit or similar API-related patterns on reliability.},
  doi       = {10.1109/SOSE55356.2022.00009},
  issn      = {2642-6587},
}

@InProceedings{Vosteen2022,
  author    = {Vosteen, Lars and John, Fabian and Schuljak, Joerg and Sievers, Bjoern and Hanemann, Andreas and Hellbrueck, Horst},
  booktitle = {Mobile Communication - Technologies and Applications; 26th ITG-Symposium},
  title     = {Practical Security Analysis and Measures for 5G Private Industrial Standalone (SA) Deployments},
  year      = {2022},
  month     = {May},
  pages     = {1-6},
  abstract  = {The standardization of the fifth generation of mobile communications has been completed, and the expansion of the 5G system is currently being driven forward. In addition to public mobile networks, the 5G mobile network standard foresees privately operated systems. Private 5G systems are started to be deployed and operated in industrial and academic environments using off-the-shelf components like standard computing hardware, software-defined radios, and open-source software with costs below 10k EUR. 5G systems are extensible and scalable due to the service-oriented architecture of the distributed 5G system. Especially in industrial deployment, the demand for security of networks is high, for example, to protect in-house data. In this paper, we present a security analysis for 5G systems from different possible attack points from the operator’s perspective. We conduct selected attacks to highlight and demonstrate weakness on our private indoor 5G testbed at the University of Applied Sciences in Lübeck. From the results of the security analysis and attacks, we derive measures to improve the security of the 5G system. Finally, we verify the effectiveness of the measures by additional tests.},
}

@InProceedings{Beingolea2023,
  author    = {Beingolea, Jorge R. and Zegarra, Milagros and Bolivar, Renzo and Rendulich, Jorge and Borja-Murillo, Juan},
  booktitle = {2023 IEEE Colombian Conference on Communications and Computing (COLCOM)},
  title     = {Heterogeneous Devices: Network Layer Integration Experience},
  year      = {2023},
  month     = {July},
  pages     = {1-6},
  abstract  = {The work proposes the development of an integration architecture for highly heterogeneous sensor network ecosystems. The implementation is carried out on a device called the “integration device”. The device functions as a management and abstraction layer, integrated with the communication and data layer of a service-oriented middleware. The integration device controls real-time events through the programming of thread groups, which have the role of managing and abstracting the heterogeneity of data and communication protocols of wireless sensor devices. A part of the integration device implementation is presented, and data transfer rate experiments are conducted to measure its performance.},
  doi       = {10.1109/COLCOM59909.2023.10334274},
  issn      = {2771-568X},
}

@InProceedings{Yensabai2023,
  author    = {Yensabai, Chavapol and Ngoenthai, Waranyu and Leangarun, Teema and Koolpiruck, Diew},
  booktitle = {2023 Third International Symposium on Instrumentation, Control, Artificial Intelligence, and Robotics (ICA-SYMP)},
  title     = {Digital Retail Shop Services in Cyber-Physical Retail System: A Case Study of Food Business},
  year      = {2023},
  month     = {Jan},
  pages     = {61-64},
  abstract  = {Food demand is expected to grow substantially as a result of major factors such as population. It necessitates that food manufacturers streamline their supply chain to accommodate shorter product life cycles. To manage sustainable food solutions and successful supply chain management, cyber-physical systems at the supply chain level attempt to challenge the integration of data from suppliers, manufacturing, logistics, and retail. The implementation of Cyber-Physical Retail Systems (CPRS) was developed to sense and analyze dynamic market environments to modify sales and shop operation activities. The data were collected from several ERP modules and operational technology (OT) data. The shop CPS was managed using the OSIsoft-PI platform, which is based on service-oriented architecture (SOA) and then integrated into the Enterprise Cloud. The customer analytics service in CPRS was used as an example of a self-aware concept to notify the sales function and was implemented on the Azure platform. The results show that churn prediction in retail shops can be detected monthly for warning sales staff based on the customer object goal. The models that were used are RF, LR and GBC. The overall performance of GBC outperforms all measures with 78.05% accuracy. While the remaining were around 65%.},
  doi       = {10.1109/ICA-SYMP56348.2023.10044743},
}

@Article{Cabrera2022,
  author   = {Cabrera, Christian and Clarke, Siobhán},
  journal  = {IEEE Transactions on Services Computing},
  title    = {A Self-Adaptive Service Discovery Model for Smart Cities},
  year     = {2022},
  issn     = {1939-1374},
  month    = {Jan},
  number   = {1},
  pages    = {386-399},
  volume   = {15},
  abstract = {City services are frequently supported by software services that are managed by service-oriented architectures. However, a large number of software services is likely to cause performance issues when discovering software services. The distributed organisation of services information improves discovery performance. Existing research proposes to organise services information according to service location, domains, or city context, keeping that organisation constant under an assumption that cities do not change. However, cities are dynamic environments where entities interact, causing events that in turn, effect changes in the city. The organisation of services information must evolve or it will become outdated, negatively impacting discovery performance. We propose a self-adaptive service model for smart cities to support service discovery. This model adapts the organisation of services information according to city events. We introduce a self-adaptive architecture that keeps track of the discovery metrics and moves information about services between registries to maintain the discovery efficiency. We evaluate the proposed model in simulated environments and a real IoT testbed. Results show that our model outperforms competitors when reactive adaptation is triggered by a specific event. However, proactive adaptation needs further research. Results from the real IoT testbed present the costs of the proposed model.},
  doi      = {10.1109/TSC.2019.2944356},
}

@InProceedings{Li2018,
  author    = {Li, Keqin},
  booktitle = {2018 IEEE 16th International Conference on Software Engineering Research, Management and Applications (SERA)},
  title     = {Quantitative Modeling and Analytical Calculation of Elasticity in Cloud Computing},
  year      = {2018},
  month     = {June},
  pages     = {3-3},
  abstract  = {Elasticity is a fundamental feature of cloud computing and can be considered as a great advantage and a key benefit of cloud computing. Our research makes the following significant contributions. First, we present a new, quantitative, and formal definition of elasticity in cloud computing, i.e., the probability that the computing resources provided by a cloud platform match the current workload. Our definition is applicable to any cloud platform and can be easily measured and monitored. Furthermore, we develop an analytical model to study elasticity by treating a cloud platform as a queueing system, and use a continuous-time Markov chain (CTMC) model to precisely calculate the elasticity value of a cloud platform by using an analytical and numerical method based on just a few parameters, namely, the task arrival rate, the service rate, the virtual machine start-up and shut-down rates. In addition, we formally define auto-scaling schemes and point out that our model and method can be easily extended to handle arbitrarily sophisticated scaling schemes. Second, we apply our model and method to predict many other important properties of an elastic cloud computing system, such as average task response time, throughput, quality of service, average number of VMs, average number of busy VMs, utilization, cost, cost-performance ratio, productivity, and scalability. In fact, from a cloud consumer's point of view, these performance and cost metrics are even more important than the elasticity metric. Ourperformance and cost guarantee using the results developed in this talk. On the other hand, a cloud service provider can optimize its elastic scaling scheme to deliver the best cost-performance ratio. study in this talk has two significance. On one hand, a cloud service provider can predict its To the best of our knowledge, this is the first work that analytically and comprehensively studies elasticity, performance, and cost in cloud computing. Our model and method significantly contribute to the understanding of cloud elasticity and management of elastic cloud computing systems.},
  doi       = {10.1109/SERA.2018.8477218},
}

@InProceedings{Li2018a,
  author    = {Li, Keqin},
  booktitle = {2018 IEEE 16th International Conference on Software Engineering Research, Management and Applications (SERA)},
  title     = {Quantitative Modeling and Analytical Calculation of Elasticity in Cloud Computing},
  year      = {2018},
  month     = {June},
  pages     = {3-3},
  abstract  = {Elasticity is a fundamental feature of cloud computing and can be considered as a great advantage and a key benefit of cloud computing. Our research makes the following significant contributions. First, we present a new, quantitative, and formal definition of elasticity in cloud computing, i.e., the probability that the computing resources provided by a cloud platform match the current workload. Our definition is applicable to any cloud platform and can be easily measured and monitored. Furthermore, we develop an analytical model to study elasticity by treating a cloud platform as a queueing system, and use a continuous-time Markov chain (CTMC) model to precisely calculate the elasticity value of a cloud platform by using an analytical and numerical method based on just a few parameters, namely, the task arrival rate, the service rate, the virtual machine start-up and shut-down rates. In addition, we formally define auto-scaling schemes and point out that our model and method can be easily extended to handle arbitrarily sophisticated scaling schemes. Second, we apply our model and method to predict many other important properties of an elastic cloud computing system, such as average task response time, throughput, quality of service, average number of VMs, average number of busy VMs, utilization, cost, cost-performance ratio, productivity, and scalability. In fact, from a cloud consumer's point of view, these performance and cost metrics are even more important than the elasticity metric. Ourperformance and cost guarantee using the results developed in this talk. On the other hand, a cloud service provider can optimize its elastic scaling scheme to deliver the best cost-performance ratio. study in this talk has two significance. On one hand, a cloud service provider can predict its To the best of our knowledge, this is the first work that analytically and comprehensively studies elasticity, performance, and cost in cloud computing. Our model and method significantly contribute to the understanding of cloud elasticity and management of elastic cloud computing systems.},
  doi       = {10.1109/SERA.2018.8477227},
}

@InProceedings{Poggi2014,
  author    = {Poggi, Nicolas and Carrera, David and Ayguadé, Eduard and Torres, Jordi},
  booktitle = {2014 IEEE International Conference on Cluster Computing (CLUSTER)},
  title     = {POSTER: Profit-aware cloud resource provisioner for ecommerce},
  year      = {2014},
  month     = {Sep.},
  pages     = {274-275},
  abstract  = {In recent years, the Cloud Computing paradigm has proven effective in scaling dynamically the number of servers according to simple performance metrics and the incoming workload. However while some applications are able to scale-out, as current scaling metrics do not relate system performance to sales, hosting costs and profits are not optimized completely. The following article proposes a novel technique for dynamic resource provisioning based on revenue and cost metrics, to optimize profits for online retailers in the Cloud. The proposal relies on user behavior models that relate Quality-of-Service (QoS) to service capacity, and to the intention of users to buy a product on an Ecommerce site. We show how such metrics can enable profit-aware resource management by setting an optimal number of servers at each time of the day. Experiments are performed on custom, real-life datasets from an Ecommerce retailer contain over two years of access, performance, and sales data from popular travelWeb applications.},
  doi       = {10.1109/CLUSTER.2014.6968746},
  issn      = {2168-9253},
}

@InProceedings{Ibrahim2018,
  author    = {Ibrahim, Abdallah A. Z. A. and Varrette, Sebastien and Bouvry, Pascal},
  booktitle = {2018 International Conference on Information Networking (ICOIN)},
  title     = {PRESENCE: Toward a novel approach for performance evaluation of mobile cloud SaaS Web Services},
  year      = {2018},
  month     = {Jan},
  pages     = {50-55},
  abstract  = {Cloud Services Providers (CSPs) deliver cloud services to cloud customers on a pay-per-use model. The quality of the provided services are defined using Service Level Agreements (SLAs). The recent developments around edge computing and the advent of mobile cloud computing platforms contribute to the success of this approach and the multiplication of offers. Unfortunately, despite the projections foreseeing a growing market for the coming years, there is no standard mechanism which exists to verify and assure that delivered services satisfy the signed SLA agreement. Accurate measures of the provided Quality of Service (QoS) is also missing most of time. In this context, we aim at offering an automatic framework named PRESENCE, to evaluate the QoS and SLA compliance of Web Services (WSs) offered across several CSPs. PRESENCE aims at quantifying in a fair and by stealth way the performance and scalability of the delivered WS. By stealthiness, we refer to the capacity of evaluating a given Cloud service by orchestrating multiple workload patterns that making them indistinguishable from a regular user traffic from the provider point of view. PRESENCE defines a set of Common performance metrics handled by a set of agents within a customized client (called the Auditor) for measuring the behaviour of cloud applications on top of a given CSP. This position paper offers a description of the PRESENCE framework, and the way each modules are foreseen to be designed. This opens novel perspectives for assessing the SLA compliance of Cloud providers using the PRESENCE framework.},
  doi       = {10.1109/ICOIN.2018.8343082},
}

@InProceedings{Khurana2016,
  author    = {Khurana, Ravi and Bawa, Rajesh Kumar},
  booktitle = {2016 Fourth International Conference on Parallel, Distributed and Grid Computing (PDGC)},
  title     = {Quality based cloud simulators: State-of-the-art & road ahead},
  year      = {2016},
  month     = {Dec},
  pages     = {101-106},
  abstract  = {Cloud Computing is an emerging technology nowadays. It has been used by many leading organisations. They deploy their critical information onto the cloud. Several challenges are associated with it like quality issues, security, energy consumption etc. Continuous research is going on to cater these issues. It is not easy to setup a cloud for any researcher or group of researchers, it needs huge investment. Big organisations having huge budgets can only afford that. To address these issues cloud simulators are really helpful. Cloud simulator is a simulating environment through which one can realize actual cloud environment. Data centers, virtual machines, hosts and networks can be setup virtually. Numbers of cloud simulators are there in the literature each offering different scenario. Cloudsim, a well known cloud simulator calculates start time, finish time and total time for execution of cloudlet. Another cloud simulator GreenCloud calculates energy consumption by data centers, hosts, switches and other network equipments. In the present paper, we focus on quality metrics addressed by cloud simulators. With each simulator, we will enlist quality metrics discussed by them. At the end, we conclude that there is a need to develop simulator which will address relevant quality metrics.},
  doi       = {10.1109/PDGC.2016.7913123},
}

@Article{Feng2020,
  author   = {Feng, Jie Xu and Si, Guannan and Zhou, Fengyu},
  journal  = {IEEE Access},
  title    = {Overview and Framework of Quality Service Metrics for Cloud-Based Robotics Platforms},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {185885-185898},
  volume   = {8},
  abstract = {With the rapid development of big data, cloud computing and other technologies, Cloud-based robotic has become one of the key research directions for service robot, such as used in hospitals. A framework and set of metrics for evaluating the quality of service (QOS) of a cloud robotic platform would be greatly facilitate research into and actual practice of service robots. In this paper, a QOS metrics framework of cloud robotic computing is summarized and the research of components and metrics of a cloud robotic platform is reviewed. QOS metrics are organized into software, network, and robotic services. By summarizing and analyzing the above three groups of metrics, a QOS framework or index system is proposed. Finally, future research towards open source and standardization of components of robotic cloud platform is discussed.},
  doi      = {10.1109/ACCESS.2020.3030069},
}

@InProceedings{Upadhyaya2017,
  author    = {Upadhyaya, Jolly and Ahuja, Neelu Jyoti},
  booktitle = {2017 International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)},
  title     = {Quality of service in cloud computing in higher education: A critical survey and innovative model},
  year      = {2017},
  month     = {Feb},
  pages     = {137-140},
  abstract  = {Cloud Computing, an emerging trend, in the e-learning sector has attracted number of service providers to the market in very less time, providing users with several applications at their disposal. However, while providing such service, not sufficient importance is given to the quality of the service, especially from the user's point of view. Hence it becomes necessary to monitor, track and quantify the QoS of the cloud computing e-learning applications in order to provide the right information to both the customers and the service providers. This information would help both the parties in terms of the comparison between the expectations and the capacity to meet them, but in this sector there is no standard model which defines the QoS parameters from the user's point of view. Thus, the need arises for developing a metrics model for enhancing the quality of service in cloud computing e-learning applications for higher education sector. In the current work, Quality of Service models are studied and comprehensive review of work done in this field is presented. Additionally an innovative QoS model for resolving this issue has been suggested.},
  doi       = {10.1109/I-SMAC.2017.8058324},
}

@InProceedings{Geetha2017,
  author    = {Geetha, P. and Robin, C.R. Rene},
  booktitle = {2017 International Conference on Energy, Communication, Data Analytics and Soft Computing (ICECDS)},
  title     = {A comparative-study of load-cloud balancing algorithms in cloud environments},
  year      = {2017},
  month     = {Aug},
  pages     = {806-810},
  abstract  = {The enrichment knowledge of Cloud Computing is Green Cloud Computing. The term of Cloud Computing is a globally inter — connected networks of Computing Resources( Servers, Networks, Applications, Hardwares, Softwares). The Green Computing is an Environmental Benefits of eco-friendly usage of Computing Resources. The combination of Green Computing and Cloud computing is Green Cloud Computing. GCC performs both performance and efficiency. The combination of Mobile Computing and Cloud Computing is known as Mobile Cloud Computing. Now, the Computational science is changing to be data-intensive. So, Load balancing is a technique to distribute the load across a given Green Cloud Network Vs Mobile Cloud Network. In this proposed system, the in-depth analysis of Load Balancing Algorithms. The Load of Cloud Balancing is a process of reassigning the total load to the individual nodes in a given network. Then the Comparative study of load balancing algorithms with its quality metrics are summarized.},
  doi       = {10.1109/ICECDS.2017.8389549},
}

@InProceedings{Dhirani2018,
  author    = {Dhirani, Lubna Luxmi and Newe, Thomas and Nizamani, Shahzad},
  booktitle = {2018 5th International Multi-Topic ICT Conference (IMTIC)},
  title     = {Hybrid Cloud Computing QoS Glitches},
  year      = {2018},
  month     = {April},
  pages     = {1-6},
  abstract  = {The Hybrid Cloud Computing model has been growing extensively due to its Infrastructure as a Service (IaaS) architecture, customisation and cost benefits. The hybrid cloud services are measured based on the Quality of Service parameters defined by the public cloud vendors. These parameters (i.e. availability, scalability, latency etc.) vary from vendor-to-vendor, developing complexity and confusion on the grounds of methods of service assessments. A Cloud Service Level Agreement (SLA) lists the QoS provisions to be provided to the tenant, the objectives, and exclusions. Regardless of vendors promised uptimes and service metrics, the tenants are susceptible to the following threats: data governance, Denial of Services, multi-tenancy, etc. Cloud computing has often been compared as a utility, but the basic different between a utility and the cloud is the amount of risk involved with data protection, provisioning and control. Few cloud standards have been developed for standardizing the hybrid cloud model but since each public cloud vendor provides different applications and services, these standards do not resolve the existing cloud QoS issue. Since each enterprise implementing the cloud and vendor supplying the services is diverse, a customized Trio (Cloud-IT-Business) QoS model is required to resolve the business need. The authors have designed a model to resolve this existing cloud QoS issue, the abstraction of the model is detailed in this paper.},
  doi       = {10.1109/IMTIC.2018.8467224},
}

@InProceedings{Shin2018,
  author    = {Shin, Young-Rok and Son, A-Young and Jo, Hyeok Kyun and Huh, Eui-Nam},
  booktitle = {2018 Second World Conference on Smart Trends in Systems, Security and Sustainability (WorldS4)},
  title     = {Cloud Service Broker Based Quality Metrics Integration Model for Mobile Environment},
  year      = {2018},
  month     = {Oct},
  pages     = {254-259},
  abstract  = {Mobile cloud computing is high technology that extends existing IT capabilities and requirements. And it can also access to shareable remote computing resources pool through the network. As the concept of mobile cloud, many providers have served the mobile cloud services using their own service policies. In other words, there is no formal definition of quality criteria for mobile cloud service evaluation. To solve this problem, some quality models are proposed for cloud service evaluation. However, those did not include many metrics to evaluate the services. Even if the model included a number of criteria, it is difficult to identify whether the metrics are proper or not. Furthermore, most existing models were not concerned about mobile characteristics. Therefore, we propose a cloud service integration model to solve the problem as we mentioned above. First, we select additional metrics to satisfy the mobile characteristics. Second, we present an extended SLA model for modeling complex service-dependencies in mobile cloud services. Third, we describe a method of discovering relations between the metrics of service belonging to mobile cloud services and then using these relations for establishing newly generated SLA.},
  doi       = {10.1109/WorldS4.2018.8611562},
}

@InProceedings{Zhou2015a,
  author    = {Zhou, Ping and Wang, Zhipeng and Li, Wenjing and Jiang, Ning},
  booktitle = {2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems},
  title     = {Quality Model of Cloud Service},
  year      = {2015},
  month     = {Aug},
  pages     = {1418-1423},
  abstract  = {In recent years, services based on cloud computing have been used more and more widely. Stakeholders have paid more and more attention on the quality of cloud service. But most of them don't know how to evaluate the quality of cloud service. This paper proposes a comprehensive, structurized, and hierarchical quality model of cloud service, which concerned not only the IT features but also the service features of cloud service. The quality model was constructed by 6 characteristics, i.e., usability, security, reliability, tangibility, responsiveness, and empathy. We divided each characteristic into several subcharacteristics. In order to apply the cloud service model better, and to evaluate the service quality systematically, we provide a metrics framework for those subcharacteristics, which was made up of objective and subjective metrics. We give a brief intro to the methodology on evaluating the cloud service quality. We also illustrate the evaluation process with a case study.},
  doi       = {10.1109/HPCC-CSS-ICESS.2015.134},
}

@InProceedings{Padma2021,
  author    = {Padma, P. and Akshaya, RS. and Akshaya, H. and Harini, R.},
  booktitle = {2021 4th International Conference on Computing and Communications Technologies (ICCCT)},
  title     = {Perlustrate Study on Cloud Security and Vulnerabilities},
  year      = {2021},
  month     = {Dec},
  pages     = {293-296},
  abstract  = {In this modern technology,cloud computing plays an integral role which is also the fastest emerging technology. Cloud computing refers to manipulating,configuring and accessing the applications online. It offers online data storage,infrastructure and application. It is both a combination of software and hardware based computing resources delivered as a network service. High Quality services with improved performance and with reduced cost made the cloud computing a popular paradigm. Cloud computing has numerous advantages to the customer, like its ability to scale and recover from various problems agility and flexibility. As every technology emerges with its own pros and cons cloud computing is vulnerable to certain threats regarding security issues which makes the clients a lack of confidence to adopt cloud technologies. The main reason why companies are leaving the cloud is due to security concerns. Cloud security measures are often inadequate to protect sensitive data. This work aims at presenting a survey of various security issues faced by clients and the necessary measures to counter these threats.},
  doi       = {10.1109/ICCCT53315.2021.9711797},
}

@InProceedings{Khan2016,
  author    = {Khan, Hassan Mahmood and Chan, Gaik-Yee and Chua, Fang-Fang},
  booktitle = {2016 International Conference on Information Networking (ICOIN)},
  title     = {An adaptive monitoring framework for ensuring accountability and quality of services in cloud computing},
  year      = {2016},
  month     = {Jan},
  pages     = {249-253},
  abstract  = {Cloud computing platform has gained popularity among service providers and consumers to perform business operations due to the ease of communication and transaction convenience in terms of accessibility and availability. However, due to the vulnerability of this dynamic open environment, it is crucial to have a binding agreement between all the service parties for ensuring trust while fulfilling the expected Quality of Services (QoS). There is a need to improve on the current Service Level Agreements (SLAs) practice which does not focus on the QoS and accountability assurance. In this paper, we propose an adaptive monitoring framework to dynamically monitor QoS metrics and performance measures to verify compliances to the respective SLAs. The framework is validated with scenarios on response time and availability which shown to provide adaptive remedy action to rectify violation situation. Besides, any service party which establishes non-compliance to SLAs shall be penalized in monetary terms.},
  doi       = {10.1109/ICOIN.2016.7427071},
}

@InProceedings{Brilhante2014,
  author    = {Brilhante, Jonathan and Silva, Bruno and Maciel, Paulo and Zimmermann, Armin},
  booktitle = {2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  title     = {Dependability models for Eucalyptus infrastructure clouds considering VM life-cycle},
  year      = {2014},
  month     = {Oct},
  pages     = {1336-1341},
  abstract  = {Managing a cloud computing provider is a difficult task, which involves the control and maintenance of several components, such as computers, network infrastructures and software components. In these environments, availability, security and low costs are important requirements to achieve high quality of service. Therefore, the evaluation of these systems is important to find a configuration that meets the constraints of users and provider. A widely adopted strategy to evaluate cloud computing systems consists by the utilization of stochastic models (e.g., stochastic Petri nets - SPN) to assess the concern metrics. In this context, Eucalyptus is an open source private cloud software for building private and hybrid clouds. This work presents dependability models for evaluation on Eucalyptus clouds. These models focus on the user point of view metrics (e.g., number of running virtual machines) to assess the dependability metrics. In order to demonstrate the feasibility of the proposed models, we evaluate a real world environment and validate the presented models by using Eucabomber tool version 2.0.},
  doi       = {10.1109/SMC.2014.6974100},
  issn      = {1062-922X},
}

@Article{Hussain2015,
  author   = {Hussain, Omar Khadeer and Rahman, Zia-ur- and Hussain, Farookh Khadeer and Singh, Jaipal and Janjua, Naeem Khalid and Chang, Elizabeth},
  journal  = {The Computer Journal},
  title    = {A User-Based Early Warning Service Management Framework in Cloud Computing},
  year     = {2015},
  issn     = {1460-2067},
  month    = {March},
  number   = {3},
  pages    = {472-496},
  volume   = {58},
  abstract = {Cloud computing is a very attractive option for service users and service providers for their businesses because of the benefits it provides. A major concern among service users regarding cloud adoption, however, is the unpredictability of performance in relation to the services provided. Even though guarantees in the form of service-level agreements are provided to users by service providers, real-time service-level degradability remains a critical concern; hence, there is a need for an approach that assists users to manage a service before it fails. The approaches proposed in the literature assess and evaluate the performance of the cloud infrastructure of providers, but this does not guarantee that a given service instance will meet the desired quality level because there may be factors other than the provider's infrastructure that will affect the level of quality of the service instance. In this paper, we present an approach that measures the quality of a service instance in real time and provides important analysis for service users as to whether they will achieve their desired objectives. This analysis also constitutes an important input for service users in the assessment and management of a service to avoid the failure to achieve objectives.},
  doi      = {10.1093/comjnl/bxu064},
}

@Article{Xu2019a,
  author   = {Xu, Jianwen and Ota, Kaoru and Dong, Mianxiong},
  journal  = {China Communications},
  title    = {A real plug-and-play fog: Implementation of service placement in wireless multimedia networks},
  year     = {2019},
  issn     = {1673-5447},
  month    = {Oct},
  number   = {10},
  pages    = {191-201},
  volume   = {16},
  abstract = {Initially as an extension of cloud computing, fog computing has been inspiring new ideas about moving computing tasks to the edge of networks. In fog, we often repeat the procedure of placing services because of the geographical distribution of mobile users. We may not expect a fixed demand and supply relationship between users and service providers since users always prefer nearby service with less time delay and transmission consumption. That is, a plug-and-play service mode is what we need in fog. In this paper, we put forward a dynamic placement strategy for fog service to guarantee the normal service provision and optimize the Quality of Service (QoS). The simulation results show that our strategy can achieve better performance under metrics including energy consumption and end-to-end latency. Moreover, we design a real Plug-and-Play Fog (PnPF) based on Raspberry Pi and OpenWrt to provide fog services for wireless multimedia networks.},
  doi      = {10.23919/JCC.2019.10.012},
}

@InProceedings{Vijayakumar2015,
  author    = {Vijayakumar, N and Ramya, R},
  booktitle = {2015 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS)},
  title     = {The real time monitoring of water quality in IoT environment},
  year      = {2015},
  month     = {March},
  pages     = {1-5},
  abstract  = {In order to ensure the safe supply of the drinking water the quality needs to be monitor in real time. In this paper we present a design and development of a low cost system for real time monitoring of the water quality in IOT(internet of things). The system consist of several sensors is used to measuring physical and chemical parameters of the water. The parameters such as temperature, PH, turbidity, conductivity, dissolved oxygen of the water can be measured. The measured values from the sensors can be processed by the core controller. The raspberry PI B+ model can be used as a core controller. Finally, the sensor data can be viewed on internet using cloud computing.},
  doi       = {10.1109/ICIIECS.2015.7193080},
}

@InProceedings{Vijayakumar2015a,
  author    = {Vijayakumar, N and Ramya, R},
  booktitle = {2015 International Conference on Circuits, Power and Computing Technologies [ICCPCT-2015]},
  title     = {The real time monitoring of water quality in IoT environment},
  year      = {2015},
  month     = {March},
  pages     = {1-4},
  abstract  = {In order to ensure the safe supply of the drinking water the quality needs to be monitor in real time. In this paper we present a design and development of a low cost system for real time monitoring of the water quality in IOT(internet of things).the system consist of several sensors is used to measuring physical and chemical parameters of the water. The parameters such as temperature, PH, turbidity, conductivity, dissolved oxygen of the water can be measured. The measured values from the sensors can be processed by the core controller. The raspberry PI B+ model can be used as a core controller. Finally, the sensor data can be viewed on internet using cloud computing.},
  doi       = {10.1109/ICCPCT.2015.7159459},
}

@InProceedings{Martins2020,
  author    = {Martins, Wictor Souza and Tardiole Kuehne, Bruno and Sobrinho, Rafael Ferreira and Preti, Fábio},
  booktitle = {2020 IEEE International Conference on Services Computing (SCC)},
  title     = {A Reference Method for Performance Evaluation in Big Data Architectures},
  year      = {2020},
  month     = {Nov},
  pages     = {1-8},
  abstract  = {This paper presents a reference method for performance evaluation in Big Data architectures, called by Improvement Method for Big Data Architectures (IMBDA) aiming to increase the performance, and consequently raising the quality of service provided. The method will contribute to small businesses and startups that have limited financial re-sources (impossible to invest in market solutions). The proposed approach considers the relationship of the processes in a data processing flow to find possible bottlenecks and optimization points. To this end, IMBDA collects system logs to compose functional metrics (e.g., processing time) and non-functional metrics (e.g., CPU and memory utilization, and other cloud computing infrastructure resources). The system stores these metrics in an external data analysis tool that investigates the correlation of performance between processes. The reference method applies to the architecture of a Big Data application, which provides solutions in fleet logistics. With the use of IMBDA, it was possible to identify performance bottlenecks, allowing the reconfiguration of the architecture to increase service quality at the lowest possible cost.},
  doi       = {10.1109/SCC49832.2020.00044},
  issn      = {2474-2473},
}

@InProceedings{Han2021,
  author    = {Han, Jaehyun and Zhu, Guangyu and Lee, Eunseo and Lee, Sangmook and Son, Yongseok},
  booktitle = {2021 International Conference on Information Networking (ICOIN)},
  title     = {An Empirical Evaluation and Analysis of Performance of Multiple Optane SSDs},
  year      = {2021},
  month     = {Jan},
  pages     = {541-545},
  abstract  = {Cloud Computing as a service-on-demand architecture has grown in importance over the previous few years. The storage subsystem in cloud computing has undergone enormous innovation in order to provide high-quality cloud services. Emerging non-volatile memory express (NVMe) technology has a considerable attraction in cloud computing by delivering high I/O performance in terms of latency and bandwidth. Especially, multiple NVMe SSDs can provide higher performance, fault tolerance, and storage capacity in the cloud computing environment. In this paper, we perform an empirical evaluation study of performance on recent NVMe SSDs (i.e., Intel Optane SSDs) with different RAID environments. We analyze the performance of the multiple NVMe SSDs with RAID in terms of different performance metrics via micro and macro benchmarks. We anticipate that the experimental results and performance analysis will provide the implications on various storage systems.},
  doi       = {10.1109/ICOIN50884.2021.9333865},
  issn      = {1976-7684},
}

@InProceedings{Hlaing2019,
  author    = {Hlaing, Yamin Thet Htar and Yee, Tin Tin},
  booktitle = {2019 International Conference on Advanced Information Technologies (ICAIT)},
  title     = {Static Independent Task Scheduling on Virtualized Servers in Cloud Computing Environment},
  year      = {2019},
  month     = {Nov},
  pages     = {55-59},
  abstract  = {Cloud Computing is the advanced design of client-server computing, cluster computing and grid computing. The cloud providers provide cloud services mainly as Infrastructure as a Service (IaaS), Platform as a Service (PaaS), Software as a Service (SaaS) to the users who can access publicly, privately or hybrid via the Internet. In Cloud computing, there are many research areas like task scheduling, allocation of resource, security and privacy etc. Task scheduling is a vital area in the cloud computing, and it must be optimized by considering different parameters. Nowadays, there are a lot of different scheduling algorithms to minimize execution time and cost, to improve the quality of service, system performance and to maximize resource utilization and load balancing, etc. This paper proposed a Static Independent Task Scheduling on Virtualized Servers in Cloud Computing Environment in which tasks are allocated to the suitable VM by measuring the availability of each resource with respect to its processing power, cost and the number of available processing elements and by grouping tasks according to their instruction length. This method is simulated on Cloud Simulator (Cloudsim toolkit) and results show the proposed method that maximizes total execution time and minimizes execution cost for all tasks than scheduling algorithms such as Shortest Job First (SJF) and First Come First Serve (FCFS) algorithms.},
  doi       = {10.1109/AITC.2019.8920865},
}

@InProceedings{P.M.S.S2016,
  author    = {Chandu P.M.S.S and Kata, Divyasree},
  booktitle = {2016 International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET)},
  title     = {Integrating and enhancing the quality of services in cloud computing with software testing},
  year      = {2016},
  month     = {March},
  pages     = {2008-2010},
  abstract  = {Cloud computing involves to delivering the hosted services throughout the internet. Testing tools are used to test the desktop applications, web applications and the cloud based software systems that are used to address the quality of the cloud infrastructure such as tremendous extensibility and aggressive composition. In the existing paper it is not providing the quality of services in the effective manner. In this paper we focused on integrating the software metrics for getting the quality of services, in terms of speed, memory size, RAM, ROM size and we are also using the D-cloud and prefail testing tools to perform the fault tolerance and recovery testing. By using OVMP algorithm we are minimizing the cost spending for services and load prediction algorithm and it is also used to reduce the load. The aim is to extend the above framework with cross cloud testing scenario involving communications between heterogeneous cloud hosts. The results shows that the cloud environment ensures more flexible and quality of services.},
  doi       = {10.1109/WiSPNET.2016.7566494},
}

@InProceedings{Jelassi2017,
  author    = {Jelassi, Mariem and Ghazel, Cherif and Saïdane, Leila Azzouz},
  booktitle = {2017 3rd International Conference on Frontiers of Signal Processing (ICFSP)},
  title     = {A survey on quality of service in cloud computing},
  year      = {2017},
  month     = {Sep.},
  pages     = {63-67},
  abstract  = {The quality of service is one of challenges posed by the Cloud Computing. This issue plays an important role in making the Cloud services acceptable to customers, denotes the levels of performance, reliability, and availability offered by Cloud services. Literature has reported many implementations for measuring and ensuring QoS in Cloud Computing systems to achieve better results and meet the needs of producers and consumers. In this paper, we have presented a survey on QoS in Cloud Computing, the mechanisms and methods to guarantee quality of service (QoS) used to Cloud Computing services.},
  doi       = {10.1109/ICFSP.2017.8097142},
}

@InProceedings{Hu2016a,
  author    = {Yazhou Hu and Bo Deng and Fuyang Peng},
  booktitle = {2016 2nd IEEE International Conference on Computer and Communications (ICCC)},
  title     = {Autoscaling prediction models for cloud resource provisioning},
  year      = {2016},
  month     = {Oct},
  pages     = {1364-1369},
  abstract  = {The elasticity mechanism of cloud computing can auto scale cloud resources to meet users' need. Elastic adding or removing virtual machines is the most common method to achieve the auto scaling. But the elastic scaling often takes tens of minutes, which is inefficient for the running workload. To reduce the latency and improve the quality of service (QoS), the new virtual machine should be provisioned when the request arrives. In this paper, we present a prediction framework for virtual machines provisioning. This prediction framework includes three main modules: monitor, filter and predictor. This framework aims to predict the upcoming workload and provision the virtual machines in advance. To get the reasonable monitored metrics, we propose the Kalman filter method to preprocess the raw data. Moreover, we present five different prediction models as the based predictor. These prediction models include moving average (MA), auto regression (AR), auto regression integrated moving average (ARIMA), neural networks (NN) and support vector machine (SVM). Meanwhile, we propose four evaluation metrics, including the prediction error, the time saving, under-prediction resource and over-prediction resource, to evaluate the performance of prediction framework. In addition, we use Alicloud as the experimental infrastructure. Experimental results demonstrate that the prediction framework can reduce the latency of provisioning cloud resource and improve the cloud service quality.},
  doi       = {10.1109/CompComm.2016.7924927},
}

@InProceedings{Haque2021,
  author    = {Haque, Halima and Labeeb, Kashshaf and Riha, Rabea Basri and Khan, Md. Nasfikur R.},
  booktitle = {2021 International Conference on Emerging Smart Computing and Informatics (ESCI)},
  title     = {IoT Based Water Quality Monitoring System By Using Zigbee Protocol},
  year      = {2021},
  month     = {March},
  pages     = {619-622},
  abstract  = {This paper dictates the damages caused by water and what can be done to resolve those issues by involving the Internet of things (IoT). Keeping the quality of water in check is today's ultimate objective. Thereby, to guarantee safe drinking water supply, the quality of water should be observed regularly. The use of IoT based solution, focused mainly on water quality monitoring has therefore been suggested. In order to support the issue, an IoT-based water quality checking network has been introduced that continuously monitors and evaluates the quality of water and tries to distinguish whether it is up to the mark for general use. This paper includes the use of specific sensors that calculates the various parameters of the quality of water which includes conductivity and dissolved oxygen (DO), turbidity, pH, and temperature. The values from the sensors have been measured and calculated using the microcontrollers. Then these processed remote values have been transmitted to the raspberry pi, the central controller which uses the Zigbee protocol. Lastly, all the data from the sensors are then accessible via cloud computing through any browser, on request.},
  doi       = {10.1109/ESCI50559.2021.9397031},
}

@InProceedings{Wang2021d,
  author    = {Wang, Lei and He, Qiang and Gao, Demin and Wan, Jing and Zhang, Yunqiu},
  booktitle = {2021 IEEE World Congress on Services (SERVICES)},
  title     = {Temporal-Perturbation aware Reliability Sensitivity Measurement for Adaptive Cloud Service Selection},
  year      = {2021},
  month     = {Sep.},
  pages     = {8-8},
  abstract  = {Benefiting from the pay-as-you-go business model, cloud computing has significantly promoted service computing techniques in real-world industrial applications. Software applications based on cloud computing are becoming more and more popular. By integrating existing component cloud services through the internet, composite cloud systems can be built to meet sophisticated application logic. Stable execution of such systems is desirable in the long term so that the service-level agreements (SLAs), as well as users’ quality of experience (QoE), can be fulfilled. To achieve this goal, it is critical to identify and fault-tolerate system components at high risks of failing. This is extremely challenging due to the dynamic and uncertainty of the cloud environment that hosts the component cloud services. Nevertheless, existing approaches pay little attention to the modeling and analysis of system components’ reliability time series. To address the above issues, we first present a reliability evaluation method for component cloud services based on the reliability model and their failure probability under continuous client-side invocation tests. Then, we propose a perturbation-aware reliability sensitivity measurement approach (named PARS) for measuring the reliability sensitivity of component cloud services. It first analyzes the negative perturbations in component cloud services’ historical reliability time series based on the Markov chain rule. Then, it calculates the reliability sensitivity of component cloud services by analyzing how their reliability perturbations impact the reliability of the entire cloud system. To guarantee the execution quality of the composite cloud system, we further propose a proactive adaptation approach named PA-PARS that enables 1-out-of-2 N-version Programming fault-tolerance for composite cloud systems based on PARS. PA-PARS takes the reliability sensitivity of component cloud services estimated by PARS as input to assure the reliability of the cloud system. It consists of four parts: 1) risky system component identification; 2) adaptation trigger; 3) candidate component cloud service selection; and 4) NVP-based system construction as the proactive adaptation for the composite cloud system. The results of experiments conducted on two widely-used datasets demonstrate the effectiveness and efficiency of the proposed approaches in ensuring the reliability of composite cloud systems.},
  doi       = {10.1109/SERVICES51467.2021.00019},
  issn      = {2642-939X},
}

@Article{Zuo2015,
  author   = {Zuo, Liyun and Shu, Lei and Dong, Shoubin and Zhu, Chunsheng and Hara, Takahiro},
  journal  = {IEEE Access},
  title    = {A Multi-Objective Optimization Scheduling Method Based on the Ant Colony Algorithm in Cloud Computing},
  year     = {2015},
  issn     = {2169-3536},
  pages    = {2687-2699},
  volume   = {3},
  abstract = {For task-scheduling problems in cloud computing, a multi-objective optimization method is proposed here. First, with an aim toward the biodiversity of resources and tasks in cloud computing, we propose a resource cost model that defines the demand of tasks on resources with more details. This model reflects the relationship between the user's resource costs and the budget costs. A multi-objective optimization scheduling method has been proposed based on this resource cost model. This method considers the makespan and the user's budget costs as constraints of the optimization problem, achieving multi-objective optimization of both performance and cost. An improved ant colony algorithm has been proposed to solve this problem. Two constraint functions were used to evaluate and provide feedback regarding the performance and budget cost. These two constraint functions made the algorithm adjust the quality of the solution in a timely manner based on feedback in order to achieve the optimal solution. Some simulation experiments were designed to evaluate this method's performance using four metrics: 1) the makespan; 2) cost; 3) deadline violation rate; and 4) resource utilization. Experimental results show that based on these four metrics, a multi-objective optimization method is better than other similar methods, especially as it increased 56.6% in the best case scenario.},
  doi      = {10.1109/ACCESS.2015.2508940},
}

@InProceedings{Bhonde2021,
  author    = {Bhonde, Aparna and Devane, Satish},
  booktitle = {2021 International Conference on Communication information and Computing Technology (ICCICT)},
  title     = {Impact of Cloud Attacks on Service Level Agreement},
  year      = {2021},
  month     = {June},
  pages     = {1-6},
  abstract  = {Cloud computing has taken center stage in the current business due to reduced cost, high performance and zero infrastructure. Cloud computing paradigm is yet unable to provide quality of service (QoS) by complying service level agreement (SLA) because of lack of analysis on the unaddressed security issues, challenges, threats which has paved the path for researchers to overcome the lapses in order to improve the QoS. In this paper, we present a survey on the cloud service model attacks and threat analysis. It is been observed after thorough analysis of attacks on all the service models that there is a need to have stronger security for infrastructure as a service level attack. Trust can be ensured among the cloud users with the introduction of security metrics in the service level agreement. Cloud service providers can mention the security metrics in SLA only if it can confidently address these attacks by adding security for infrastructure as a service.},
  doi       = {10.1109/ICCICT50803.2021.9510130},
}

@InProceedings{Gholami2015,
  author    = {Gholami, Atoosa and Arani, Mostafa Ghobaei},
  booktitle = {2015 2nd International Conference on Knowledge-Based Engineering and Innovation (KBEI)},
  title     = {A trust model for resource selection in cloud computing environment},
  year      = {2015},
  month     = {Nov},
  pages     = {144-151},
  abstract  = {In recent years, cloud computing technology has been increasingly embraced by people and most organizations tend to use this technology in their business processes. On the other hand, the use of this technology is not so easy and many organizations are concerned about the storage of their sensitive data in their data centers instead of storing them in the cloud storage centers. Today, one of the most important factors for the success of cloud computing is to create trust and security. Cloud computing will face a lot of challenges when the key element trust is absent. Trust is one of the most important ways to improve the reliability of cloud computing resources provided in the cloud environment and plays an important role in business carried out in the cloud business environments. User trust contributes to selection of appropriate sources in heterogeneous cloud infrastructure. In this paper, we present the trust model based on standards of appropriate service quality and speed of implementation for choose the best source. The proposed approach, in addition to taking into account criteria of quality of service such as cost, response time, bandwidth, and processor speed. Simulation results show that the proposed approach compared with similar approaches, in addition to taking into account measures of the quality of service, selects the most reliable source in a cloud environment by taking into account the speed of things.},
  doi       = {10.1109/KBEI.2015.7436036},
}

@InProceedings{Vallone2015,
  author    = {Vallone, Joël and Birke, Robert and Chen, Lydia Y. and Falsafi, Babak},
  booktitle = {2015 IEEE 23rd International Symposium on Quality of Service (IWQoS)},
  title     = {Contention detection by throttling: A black-box on-line approach},
  year      = {2015},
  month     = {June},
  pages     = {237-242},
  abstract  = {Visualization technology powers up the cloud computing paradigm and inevitably raises concerns about performance isolation of collocated virtual machines (VM). It is imperative for public cloud providers to guarantee performance targets for tenants' VMs while respecting strict business confidentiality, e.g., having no information on applications nor their performance. A large body of related work addresses the challenges of detecting performance interferences by leveraging client's quality of service (QoS) metrics, such as latency, and additional profiling servers. Whereas to assist cloud providers, we resort to an on-line blackbox approach based on throttling that detects a wide range of resource contentions with no cooperation need from the virtual machines. We focus on different resource metrics and actively monitor them from the hypervisor in fine time granularity at low cost. To detect resource contention, we propose a three-phase algorithm: an alarm phase, to identify statistical outliers in the victim's VM resource metrics; a passive diagnosis phase, to match the current sample to historical behaviors; and, an active learning phase, to discern contentions from application phase changes via throttling. We evaluate our algorithm on a prototype running Wikimedia as victim application across a set of VMs collocated with neighboring VMs running resource hoggers, i.e. PARSEC and Cachebench. Our extensive experimental results show that we can reach an average detection accuracy above 90% while limiting the performance degradation experienced by offender workloads to short learning phases.},
  doi       = {10.1109/IWQoS.2015.7404740},
}

@InProceedings{Kotteswari2019,
  author    = {Kotteswari, K. and Bharathi, A.},
  booktitle = {2019 International Conference on Advances in Computing and Communication Engineering (ICACCE)},
  title     = {Spectral Expansion Method for Cloud Reliability Analysis},
  year      = {2019},
  month     = {April},
  pages     = {1-5},
  abstract  = {Cloud Computing is a computing hypothesis, where a huge group of systems linked together in private, public or hybrid network, to offer dynamically amendable infrastructure for data storage, file storage and application. With this emerging technology, application hosting, delivery, content storage, and reduced computation cost, and it acts as an essential module for backbone of the Internet of Things (IOT). The efficiency of cloud Service providers (CSP) could be improved by considering significant factors such as availability, reliability, usability, security, responsiveness, and elasticity. Assessment of these factors leads to efficiency in designing scheduler for CSP. This metrics also improved the Quality of Service (QoS) in cloud. Many existing model and approaches evaluate this metrics. But these existing approaches doesn't offer efficient outcome. In this paper, a prominent performance model named as Spectral Expansion Method (SPM) evaluates cloud reliability. Spectral expansion Method (SPM) is a huge technique useful in reliability and performance modelling of computing system. This approach solves the Markov model of Cloud service Provider (CSP) to predict the reliability. The SPM is better compared to matrix geometric methods.},
  doi       = {10.1109/ICACCE46606.2019.9080012},
}

@InProceedings{Abdeladim2014,
  author    = {Abdeladim, Alfath and Baina, Salah and Baina, Karim},
  booktitle = {2014 Third IEEE International Colloquium in Information Science and Technology (CIST)},
  title     = {Elasticity and scalability centric quality model for the cloud},
  year      = {2014},
  month     = {Oct},
  pages     = {135-140},
  abstract  = {Cloud computing seems to be the most logical shift in terms of Information Technology after Internet, Social Networking. Despite the potential benefits that cloud computing offers, the model brings new issues, challenges, and needs in term of SLA formalization, Quality of Service (QoS) evaluation due to the heterogeneous resources and to the special features it implies, such as Elasticity and Scalability. In the scope of this paper we focus on the Elasticity and Scalability attributes to assess their impact on the QoS. The paper provides a multi-lenses overview that can help both cloud consumers and potential business application's owners to understand, analyze, and evaluate important aspects related to Scalability and Elasticity capabilities. We determine and analyze the key features of these characteristics and derive metrics that evaluate the cloud elasticity-centric capabilities. We present a specific quality model for those two characteristics derived from their sub-attributes.},
  doi       = {10.1109/CIST.2014.7016607},
  issn      = {2327-1884},
}

@InProceedings{Shin2015,
  author    = {Young-Rok Shin and Eui-Nam Huh},
  booktitle = {2015 Seventh International Conference on Ubiquitous and Future Networks},
  title     = {QoE metrics aggregation for hierarchical Service Level Agreement in Cross-Layered SLA architecture},
  year      = {2015},
  month     = {July},
  pages     = {831-836},
  abstract  = {Numerous services are developed using cloud computing technology. It is possible to use service from remote location, not in place of local computer. Accordingly, the research groups predict that the scale of cloud service also will be grown. One of cloud computing's advantage is scalability. It can extend its service scale and range using collaboration between cloud service providers. To make it possible, however, interoperability is required in that environment. Cross-Layered SLA architecture is the cloud service environment that supports interoperability. In this paper, we propose aggregation functions and quality model for QoE metrics and newly generating Service Level Agreement in cross-layered SLA architecture. We expect that this aggregation function and quality model will solve the possible problems in the cloud service area.},
  doi       = {10.1109/ICUFN.2015.7182659},
  issn      = {2165-8536},
}

@InProceedings{Bousselmi2016,
  author    = {Bousselmi, Khadija and Brahmi, Zaki and Gammoudi, Mohamed Mohsen},
  booktitle = {2016 IEEE 30th International Conference on Advanced Information Networking and Applications (AINA)},
  title     = {QoS-Aware Scheduling of Workflows in Cloud Computing Environments},
  year      = {2016},
  month     = {March},
  pages     = {737-745},
  abstract  = {Cloud Computing has emerged as a service model that enables on-demand network access to a large number of available virtualized resources and applications with a minimal management effort and a minor price. The spread of Cloud Computing technologies allowed dealing with complex applications such as Scientific Workflows, which consists of a set of intensive computational and data manipulation operations. Cloud Computing helps such Workflows to dynamically provision compute and storage resources necessary for the execution of its tasks thanks to the elasticity asset of these resources. However, the dynamic nature of the Cloud incurs new challenges, as some allocated resources may be overloaded or out of access during the execution of the Workflow. Moreover, for data intensive tasks, the allocation strategy should consider the data placement constraints since data transmission time can increase notably in this case which implicates the increase of the overall completion time and cost of the Workflow. Likewise, for intensive computational tasks, the allocation strategy should consider the type of the allocated virtual machines, more specifically its CPU, memory and network capacities. Yet, a critical challenge is how to efficiently schedule the Workflow tasks on Cloud resources to optimize its overall quality of service. In this paper, we propose a QoS-aware algorithm for Scientific Workflows scheduling that aims to improve the overall quality of service (QoS) by considering the metrics of execution time, data transmission time, cost, resources availability and data placement constraints. We extended the Parallel Cat Swarm Optimization (PCSO) algorithm to implement our proposed approach. We tested our algorithm within two sample Workflows of different scales and we compared the results to those given by the standard PSO, the CSO and the PCSO algorithms. The results show that our proposed algorithm improves the overall quality of service of the tested Workflows.},
  doi       = {10.1109/AINA.2016.72},
  issn      = {1550-445X},
}

@Article{Sun2017,
  author   = {Sun, Chang-ai and Pan, Lin and Wang, Qiaoling and Liu, Huai and Zhang, Xiangyu},
  journal  = {The Computer Journal},
  title    = {An Empirical Study on Mutation Testing of WS-BPEL Programs},
  year     = {2017},
  issn     = {1460-2067},
  month    = {Jan},
  number   = {1},
  pages    = {143-158},
  volume   = {60},
  abstract = {Nowadays, applications are increasingly deployed as Web services in the globally distributed cloud computing environment. Multiple services are normally composed to fulfill complex functionalities. Business Process Execution Language for Web Services (WS-BPEL) is an XML-based service composition language that is used to define a complex business process by orchestrating multiple services. Compared with traditional applications, WS-BPEL programs pose many new challenges to the quality assurance, especially testing, of service compositions. A number of techniques have been proposed for testing WS-BPEL programs, but only a few studies have been conducted to systematically evaluate the effectiveness of these techniques. Mutation testing has been widely acknowledged as not only a testing method in its own right but also a popular technique for measuring the fault-detection effectiveness of other testing methods. Several previous studies have proposed a family of mutation operators for generating mutants by seeding various faults into WS-BPEL programs. In this study, we conduct a series of empirical studies to evaluate the applicability and effectiveness of various mutation operators for WS-BPEL programs. The experimental results provide insightful and comprehensive guidance for mutation testing of WS-BPEL programs in practice. In particular, our work is the systematic study in the selection of effective mutation operators specifically for WS-BPEL programs.},
  doi      = {10.1093/comjnl/bxw076},
}

@InProceedings{Le2021,
  author    = {Le, Van Thanh and El Ioini, Nabil and Pahl, Claus and Barzegar, Hamid R. and Ardagna, Claudio},
  booktitle = {2021 Sixth International Conference on Fog and Mobile Edge Computing (FMEC)},
  title     = {A Distributed Trust Layer for Edge Infrastructure},
  year      = {2021},
  month     = {Dec},
  pages     = {1-8},
  abstract  = {Recently, Mobile Edge Cloud computing (MEC) has attracted attention both from academia and industry. The idea of moving a part of cloud resources closer to users and data sources can bring many advantages in terms of speed, data traffic, security and context-aware services. The MEC infrastructure does not only host and serves applications next to the end-users, but services can be dynamically migrated and reallocated as mobile users move in order to guarantee latency and performance constraints. This specific requirement calls for the involvement and collaboration of multiple MEC providers, which raises a major issue related to trustworthiness. Two main challenges need to be addressed: i) trustworthiness needs to be handled in a manner that does not affect latency or performance, ii) trustworthiness is considered in different dimensions - not only security metrics but also performance and quality metrics in general. In this paper, we propose a trust layer for public MEC infrastructure that handles establishing and updating trust relations among all MEC entities, making the interaction withing a MEC network transparent. First, we define trust attributes affecting the trusted quality of the entire infrastructure and then a methodology with a computation model that combines these trust attribute values. Our experiments showed that the trust model allows us to reduce latency by removing the burden from a single MEC node, while at the same time increase the network trustworthiness.},
  doi       = {10.1109/FMEC54266.2021.9732606},
}

@Article{Xia2015,
  author   = {Xia, Yunni and Zhou, MengChu and Luo, Xin and Zhu, Qingsheng and Li, Jia and Huang, Yu},
  journal  = {IEEE Transactions on Automation Science and Engineering},
  title    = {Stochastic Modeling and Quality Evaluation of Infrastructure-as-a-Service Clouds},
  year     = {2015},
  issn     = {1558-3783},
  month    = {Jan},
  number   = {1},
  pages    = {162-170},
  volume   = {12},
  abstract = {Cloud computing is a recently developed new technology for complex systems with massive service sharing, which is different from the resource sharing of the grid computing systems. In a cloud environment, service requests from users go through numerous provider-specific steps from the instant it is submitted to when the requested service is fully delivered. Quality modeling and analysis of clouds are not easy tasks because of the complexity of the automated provisioning mechanism and dynamically changing cloud environment. This work proposes an analytical model-based approach for quality evaluation of Infrastructure-as-a-Service cloud by considering expected request completion time, rejection probability, and system overhead rate as key quality metrics. It also features with the modeling of different warm-up and cool-down strategies of machines and the ability to identify the optimal balance between system overhead and performance. To validate the correctness of the proposed model, we obtain simulative quality-of-service (QoS) data and conduct a confidence interval analysis. The result can be used to help design and optimize industrial cloud computing systems.},
  doi      = {10.1109/TASE.2013.2276477},
}

@InProceedings{Bouzidi2018,
  author    = {Bouzidi, Mohammed Ridha and Soltani, Abdelghani and Bouhank, Asma and Daoudi, Mourad},
  booktitle = {2018 5th International Conference on Control, Decision and Information Technologies (CoDIT)},
  title     = {New Search Based Methods to Solve Workflow Scheduling Problem in Cloud Computing},
  year      = {2018},
  month     = {April},
  pages     = {647-652},
  abstract  = {Scheduling has a big influence on the performance of the cloud computing environment, and still remains of big interest for researchers, in particular when a certain level of quality should be maintained in order to satisfy the customer. We consider the particular scheduling multiobjective optimization problem of allocating workflows to the resources of a cloud computing environment, by managing four QoS metrics: makespan, cost, reliability and the availability. It belongs to a category of NP Hard problems. A particular metaheuristic, BBO is investigated. New workflow scheduling BBO based methods are proposed. Further, two multiobjective pareto based optimization methods MOHEFT and NSGA-II are considered in solving our problem. Tests are performed on well-known benchmarks, showing a good behavior of the different methods.},
  doi       = {10.1109/CoDIT.2018.8394855},
  issn      = {2576-3555},
}

@InProceedings{Patel2021,
  author    = {Patel, Jatin and Halabi, Talal},
  booktitle = {2021 IEEE 6th International Conference on Smart Cloud (SmartCloud)},
  title     = {Optimizing the Performance of Web Applications in Mobile Cloud Computing},
  year      = {2021},
  month     = {Nov},
  pages     = {33-37},
  abstract  = {Cloud computing adoption is on the rise. Many organizations have decided to shift their workload to the cloud to benefit from the scalability, resilience, and cost reduction characteristics. Mobile Cloud Computing (MCC) is an emerging computing paradigm that also provides many advantages to mobile users. Mobile devices function on wireless internet connectivity, which entails issues of limited bandwidth and network congestion. Hence, the primary focus of Web applications in MCC is on improving performance by quickly fulfilling customer's requests to improve service satisfaction. This paper investigates a new approach to caching data in these applications using Redis, an in-memory data store, to enhance Quality of Service. We highlight the two implementation approaches of fetching the data of an application either directly from the database or from the cache. Our experimental analysis shows that, based on performance metrics such as response time, throughput, latency, and number of hits, the caching approach achieves better performance by speeding up the data retrieval by up to four times. This improvement is of significant importance in mobile devices considering their limitation of network bandwidth and wireless connectivity.},
  doi       = {10.1109/SmartCloud52277.2021.00013},
}

@InProceedings{Ravanello2014,
  author    = {Ravanello, Anderson and Desharnais, Jean-Marc and Bautista Villalpando, Luis Eduardo and April, Alain and Gherbi, Abdelouahed},
  booktitle = {2014 Joint Conference of the International Workshop on Software Measurement and the International Conference on Software Process and Product Measurement},
  title     = {Performance Measurement for Cloud Computing Applications Using ISO 25010 Standard Characteristics},
  year      = {2014},
  month     = {Oct},
  pages     = {41-49},
  abstract  = {Measuring the performance of cloud computing-based applications using ISO quality characteristics is a complex activity for various reasons, among them the complexity of the typical cloud computing infrastructure on which an application operates. To address this issue, the authors use Bautista's proposed performance measurement framework [1] on log data from an actual data centre to map and statistically analyze one of the ISO quality characteristics: time behavior. This empirical case study was conducted on an industry private cloud. The results of the study demonstrate that it is possible to use the proposed performance measurement framework in a cloud computing context. They also show that the framework holds great promise for expanding the experimentation to other ISO quality characteristics, larger volumes of data, and other statistical techniques that could be used to analyze performance.},
  doi       = {10.1109/IWSM.Mensura.2014.33},
}

@InProceedings{Aggarwal2021,
  author    = {Aggarwal, Pooja and Nagar, Seema and Gupta, Ajay and Shwartz, Larisa and Mohapatra, Prateeti and Wang, Qing and Paradkar, Amit and Mandal, Atri},
  booktitle = {2021 IEEE 14th International Conference on Cloud Computing (CLOUD)},
  title     = {Causal Modeling based Fault Localization in Cloud Systems using Golden Signals},
  year      = {2021},
  month     = {Sep.},
  pages     = {124-135},
  abstract  = {In cloud-native applications, a large fraction of operational failures, known as outages, result in violations of Service Level Objectives (SLOs). SLOs are defined around specific measurable characteristics: availability, throughput, frequency, response time, and quality. Four metrics, latency, traffic, errors, and saturation, ensure coverage for most outages of an application. These are often called golden signals. The dynamicity and complexity of cloud-native applications complicate Site Reliability Engineers’ (SREs) efforts in problem determination, in particular in its fault localization. The fault localization is often a try-and-error process in which SREs rely on their domain knowledge and experience. It is laborious and frequently results in long Mean Time To Resolution (MTTR) for outages. This paper describes a lightweight fault localization system, that establishes causal relationships among the golden signal service errors and error logs, and further leverages PageRank centrality of the derived causal graph for generating a ranked list of faulty microservices.},
  doi       = {10.1109/CLOUD53861.2021.00026},
  issn      = {2159-6190},
}

@InProceedings{Althani2016,
  author    = {Althani, B. and Khaddaj, S. and Makoond, B.},
  booktitle = {2016 IEEE Intl Conference on Computational Science and Engineering (CSE) and IEEE Intl Conference on Embedded and Ubiquitous Computing (EUC) and 15th Intl Symposium on Distributed Computing and Applications for Business Engineering (DCABES)},
  title     = {A Quality Assured Framework for Cloud Adaptation and Modernization of Enterprise Applications},
  year      = {2016},
  month     = {Aug},
  pages     = {634-637},
  abstract  = {Cloud Computing has emerged as a viable alternative to in-house computing resources for many organisations. It offers an alternative solution for many enterprise applications, particularly large-scale legacy applications. In addition, it can offer a cost effective strategy for small and medium-sized enterprises (SMEs) where the high set-up and maintenance cost of computing resources can be prohibiting. Thus, in this paper a System Migration Life Cycle (SMLC) framework is proposed, which includes a step by-stepmigration strategy that is descriptive at the business analyst level and based on quality metrics modelling at the technical level, to estimate the potential computational needs, risks, and costs for an organisation. The proposed framework is generic and adaptable in order to accommodate various organisational requirements, thus covering a wide range of enterprise applications and following a number of novel software requirements and quality engineering principles.},
  doi       = {10.1109/CSE-EUC-DCABES.2016.251},
}

@InProceedings{Mahenge2019,
  author    = {Mahenge, Michael P. J. and Li, Chunlin and Sanga, Camilius A.},
  booktitle = {2019 IEEE 4th International Conference on Computer and Communication Systems (ICCCS)},
  title     = {Collaborative Mobile Edge and Cloud Computing: Tasks Unloading for Improving Users’ Quality of Experience in Resource-Intensive Mobile Applications},
  year      = {2019},
  month     = {Feb},
  pages     = {322-326},
  abstract  = {The advancement in resource-intensive and latency-sensitive applications challenge the legacy systems in Mobile Cloud Computing (MCC) in terms of network congestion, bandwidth utilization, performance and Quality of Service (QoS) metrics. Such challenges emanate from first, limited energy sources and resource poverty of mobile devices. Second, multi-hop connection between user devices and the cloud. To address such challenges, mobile edge computing is a promising solution. This study proposes an architecture that considers unloading resource-intensive tasks from clients' devices to more resourceful edge servers which exploit cooperative approach for tasks processing. Thus, it is essential for minimizing delay, bandwidth usage, congestion to the core network and guarantees cost-effective approach for meeting user's demands. The simulation results show that the proposed approach through unloading, it reduces response time and energy usage. This in turn improves performance, system utility and Quality of Experience (QoE).},
  doi       = {10.1109/CCOMS.2019.8821787},
}

@InProceedings{Baliyan2014,
  author    = {Baliyan, Niyati and Kumar, Sandeep},
  booktitle = {2014 Seventh International Conference on Contemporary Computing (IC3)},
  title     = {Towards software engineering paradigm for software as a service},
  year      = {2014},
  month     = {Aug},
  pages     = {329-333},
  abstract  = {The Software as a Service model of Cloud Computing offers economies of scale through the pay per use model; however, it renders the modern software very different from traditional software. Hence, there is a need to adapt Software Engineering approach in a manner that will make the development process and delivery of Software as a Service more efficient and of high quality. After performing literature review, a classification of ongoing research in this direction of adaptation is presented. Various research gaps in the areas of software development process, software reengineering, measurement, metrics, and quality models targeted at Software as a Service are identified, which can be a first step towards the definition of standards and guidelines for Software as a Service development.},
  doi       = {10.1109/IC3.2014.6897195},
}

@InProceedings{ArmandoCabrera2015,
  author    = {Armando Cabrera, S. and Abad, E. Marco and Danilo Jaramillo, H. and Poma, G. Ana and Verdúm, José Carrillo},
  booktitle = {2015 10th Iberian Conference on Information Systems and Technologies (CISTI)},
  title     = {Incidence of software quality attributes in the design, construction and deployment of Cloud architectural environments},
  year      = {2015},
  month     = {June},
  pages     = {1-7},
  abstract  = {Cloud Computing (CC) is a new paradigm in the world of computing, it includes several service and deployment models. This project is part of a general study that starts from the software engineering process and the software development life cycle (SDLC), this study is based on the ISO / IEC / IEEE 12207 standard, to evaluate the software implementation process and then we review some software quality aspects by applying the standard ISO / IEC 9126; finally we review some key terms, features, models, architecture, taxonomy, deployment scenarios and scope statements of Cloud Computing. After that we proceed to identify the key characteristics of private and public SaaS environments and obtained a quality model of service (QoS) using quality attributes and their corresponding metrics derived from the ISO / IEC 9126 Standard.},
  doi       = {10.1109/CISTI.2015.7170460},
  issn      = {2166-0727},
}

@InProceedings{Paolanti2021,
  author    = {Paolanti, Marina and Mameli, Marco and Frontoni, Emanuele and Gioacchini, Giorgia and Giorgini, Elisabetta and Notarstefano, Valentina and Zacà, Carlotta and Carnevali, Oliana and Borini, Andrea},
  booktitle = {2020 25th International Conference on Pattern Recognition (ICPR)},
  title     = {Automatic Classification of Human Granulosa Cells in Assisted Reproductive Technology using vibrational spectroscopy imaging},
  year      = {2021},
  month     = {Jan},
  pages     = {209-216},
  abstract  = {In the field of reproductive technology, the biochemical composition of female gametes has been successfully investigated with the use of vibrational spectroscopy. Currently, in assistive reproductive technology (ART), there are no shared criteria for the choice of oocyte, and automatic classification methods for the best quality oocytes have not yet been applied. In this paper, considering the lack of criteria in Assisted Reproductive Technology (ART), we use Machine Learning (ML) techniques to predict oocyte quality for a successful pregnancy. To improve the chances of successful implantation and minimize any complications during the pregnancy, Fourier transform infrared microspectroscopy (FTIRM) analysis has been applied on granulosa cells (GCs) collected along with the oocytes during oocyte aspiration, as it is routinely done in ART, and specific spectral biomarkers were selected by multivariate statistical analysis. A proprietary biological reference dataset (BRD) was successfully collected to predict the best oocyte for a successful pregnancy. Personal health information are stored, maintained and backed up using a cloud computing service. Using a user-friendly interface, the user will evaluate whether or not the selected oocyte will have a positive result. This interface includes a dashboard for retrospective analysis, reporting, real-time processing, and statistical analysis. The experimental results are promising and confirm the efficiency of the method in terms of classification metrics: precision, recall, and F1-score (F1) measures.},
  doi       = {10.1109/ICPR48806.2021.9412544},
  issn      = {1051-4651},
}

@InProceedings{Kumar2017,
  author    = {Kumar, Somansh and Jasuja, Ashish},
  booktitle = {2017 International Conference on Computing, Communication and Automation (ICCCA)},
  title     = {Air quality monitoring system based on IoT using Raspberry Pi},
  year      = {2017},
  month     = {May},
  pages     = {1341-1346},
  abstract  = {Air pollution is the largest environmental and public health challenge in the world today. Air pollution leads to adverse effects on Human health, climate and ecosystem. Air is getting polluted because of release of Toxic gases by industries, vehicular emissions and increased concentration of harmful gases and particulate matter in the atmosphere. Particulate matter is one of the most important parameter having the significant contribution to the increase in air pollution. This creates a need for measurement and analysis of real-time air quality monitoring so that appropriate decisions can be taken in a timely period. This paper presents a real-time standalone air quality monitoring system which includes various parameters: PM 2.5, carbon monoxide, carbon dioxide, temperature, humidity and air pressure. Internet of Things is nowadays finding profound use in each and every sector, plays a key role in our air quality monitoring system too. Internet of Things converging with cloud computing offers a novel technique for better management of data coming from different sensors, collected and transmitted by low power, low cost ARM based minicomputer Raspberry pi. The system is tested in Delhi and the measurements are compared with the data provided by the local environment control authority and are presented in a tabular form. The values of the parameters measured are shown in IBM Bluemix Cloud.},
  doi       = {10.1109/CCAA.2017.8230005},
}

@InProceedings{Hussain2020a,
  author    = {Hussain, Mujahid and Aleem, Sadaf and Karim, Arif and Ghazanfar, Faisal and Hai, Mansoor and Hussain, Kashif},
  booktitle = {2020 International Conference on Emerging Trends in Smart Technologies (ICETST)},
  title     = {Design of Low Cost, Energy Efficient, IoT Enabled, Air Quality Monitoring System with Cloud Based Data Logging, Analytics and AI},
  year      = {2020},
  month     = {March},
  pages     = {1-6},
  abstract  = {This paper presents a design of real-time Air Quality Monitoring System (AQMS) which incorporates Internet of Things (IoT) and cloud computing. AQMS utilizes solar panel and battery pack for independent and autonomous operation, thus, making it self-powered and sustainable. AQMS is based on AVR Microcontroller (Atmega32) and GSM modem (Sim900) for connectivity with the cloud application. The design is made low cost and scalable so that around 50nos. of such systems can be installed on roundabouts of market places, residential and industrial areas. The AQMS monitors the air quality with the help of a miniature suction pump (5volt DC) which establishes a controlled and constant stream of air-flow through a manifold that encapsulates electromechanical sensors, thus measuring the concentration of O2, CO, CO2, SO / SO2 (SOx), NO/ NO2 (NOx), Hydrocarbon (CxHx), temperature, humidity and noise. By default, the air sampling is carried out once in an hour which may be changed depending on the change in air quality, i.e. making it adoptive for energy conservation and extending the sensor's life. The data collected at the cloud application will be processed using data analytics and Artificial Intelligence (AI) for getting insights of data (data mining) regarding the potential locations where the emissions are critical and disastrous for environmental, thus, leading to prevent any mishap. The design is mapped over a metropolitan city of Pakistan, i.e. Karachi, thus initiating the transformation of Karachi to a smart city.},
  doi       = {10.1109/ICETST49965.2020.9080705},
}

@InProceedings{Luo2016,
  author    = {Shan Luo and Yanhui Zhou},
  booktitle = {2016 7th IEEE International Conference on Software Engineering and Service Science (ICSESS)},
  title     = {How to guarantee the cloud services quality},
  year      = {2016},
  month     = {Aug},
  pages     = {791-795},
  abstract  = {At present, cloud computing is used widely. Cloud services through the cloud platform provide various services to users. And cloud services will play an increasingly important role in the economy and society. Service level agreement (SLA) is an indispensable part of information service in the cloud environment. It is not only the legal protection of the quality of the cloud services, but also provides the service terms and services between the providers and users. Cloud services quality is directly reflected in the user's satisfaction, and it is still a problem to be solved. In this paper, a simple cloud SLA model is proposed to solve the problem of cloud service quality which cannot be measured by the SLA case.},
  doi       = {10.1109/ICSESS.2016.7883186},
  issn      = {2327-0594},
}

@InProceedings{Shi2015,
  author    = {Shi, Peichang and Gangopadhyay, Aryya},
  booktitle = {2015 International Conference on Healthcare Informatics},
  title     = {Personalized Health Plan Ranking - One Application of Cloud Computing to Health Care Data},
  year      = {2015},
  month     = {Oct},
  pages     = {447-447},
  abstract  = {Health plan ranking is one important factor when people are considering their health plan selection. The current health plan ranking is done by National Committee for Quality Assurance, which calculates the ratings based on three types of quality measures and gives an overall ranking of health plans. Individual consumers may be more interested in the ranks of health plans for people with similar conditions. For example, what is the plan ranking for people with both asthma and diabetes? This paper will explore how to combine some data mining techniques and cloud computing to provide a personalized health plan ranking based on each individual's physical conditions.},
  doi       = {10.1109/ICHI.2015.65},
}

@Article{Mubeen2018,
  author   = {Mubeen, Saad and Asadollah, Sara Abbaspour and Papadopoulos, Alessandro Vittorio and Ashjaei, Mohammad and Pei-Breivold, Hongyu and Behnam, Moris},
  journal  = {IEEE Access},
  title    = {Management of Service Level Agreements for Cloud Services in IoT: A Systematic Mapping Study},
  year     = {2018},
  issn     = {2169-3536},
  pages    = {30184-30207},
  volume   = {6},
  abstract = {Cloud computing and Internet of Things (IoT) are computing technologies that provide services to consumers and businesses, allowing organizations to become more agile and flexible. Therefore, ensuring quality of service (QoS) through service-level agreements (SLAs) for such cloud-based services is crucial for both the service providers and service consumers. As SLAs are critical for cloud deployments and wider adoption of cloud services, the management of SLAs in cloud and IoT has thus become an important and essential aspect. This paper investigates the existing research on the management of SLAs in IoT applications that are based on cloud services. For this purpose, a systematic mapping study (a well-defined method) is conducted to identify the published research results that are relevant to SLAs. This paper identifies 328 primary studies and categorizes them into seven main technical classifications: SLA management, SLA definition, SLA modeling, SLA negotiation, SLA monitoring, SLA violation and trustworthiness, and SLA evolution. This paper also summarizes the research types, research contributions, and demographic information in these studies. The evaluation of the results shows that most of the approaches for managing SLAs are applied in academic or controlled experiments with limited industrial settings rather than in real industrial environments. Many studies focus on proposal models and methods to manage SLAs, and there is a lack of focus on the evolution perspective and a lack of adequate tool support to facilitate practitioners in their SLA management activities. Moreover, the scarce number of studies focusing on concrete metrics for qualitative or quantitative assessment of QoS in SLAs urges the need for in-depth research on metrics definition and measurements for SLAs.},
  doi      = {10.1109/ACCESS.2017.2744677},
}

@InProceedings{Kritikos2014,
  author    = {Kritikos, Kyriakos and Domaschka, Jörg and Rossini, Alessandro},
  booktitle = {2014 IEEE 6th International Conference on Cloud Computing Technology and Science},
  title     = {SRL: A Scalability Rule Language for Multi-cloud Environments},
  year      = {2014},
  month     = {Dec},
  pages     = {1-9},
  abstract  = {The benefits of cloud computing have led to a proliferation of infrastructures and platforms covering the provisioning and deployment requirements of many cloud-based applications. However, the requirements of an application may change during its life cycle. Therefore, its provisioning and deployment should be adapted so that the application can deliver its target quality of service throughout its entire life cycle. Existing solutions typically support only simple adaptation scenarios, whereby scalability rules map conditions on fixed metrics to a single scaling action targeting a single cloud environment (e.g., Scale out an application component). However, these solutions fail to support complex adaptation scenarios, whereby scalability rules could map conditions on custom metrics to multiple scaling actions targeting multi-cloud environments. In this paper, we propose the Scalability Rule Language (SRL), a language for specifying scalability rules that support such complex adaptation scenarios of multi-cloud applications. SRL provides Eclipse-based tool support, thus allowing modellers not only to specify scalability rules but also to syntactically and semantically validate them. Moreover, SRL is well integrated with the Cloud Modelling Language (Cloud ML), thus allowing modellers to associate their scalability rules with the components and virtual machines of provisioning and deployment models.},
  doi       = {10.1109/CloudCom.2014.170},
}

@Article{Junaid2020,
  author   = {Junaid, Muhammad and Sohail, Adnan and Ahmed, Adeel and Baz, Abdullah and Khan, Imran Ali and Alhakami, Hosam},
  journal  = {IEEE Access},
  title    = {A Hybrid Model for Load Balancing in Cloud Using File Type Formatting},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {118135-118155},
  volume   = {8},
  abstract = {Maintaining accuracy in load balancing using metaheuristics is a difficult task even with the help of recent hybrid approaches. In the existing literature, various optimized metaheuristic approaches are being used to achieve their combined benefits for proper load balancing in the cloud. These approaches often adopt multi-objective QoS metrics, such as reduced SLA violations, reduced makespan, high throughput, low overload, low energy consumption, high optimization, minimum migrations, and higher response time. The cloud applications are generally computation-intensive and can grow exponentially in memory with the increase in size if no proper effective and efficient load balancing technique is adopted resulting in poor quality solutions. To provide a better load balancing solution in cloud computing, with extensive data, a new hybrid model is being proposed that performs classification on the number of files present in the cloud using file type formatting. The classification is performed using Support Vector Machine (SVM) considering various file formats such as audio, video, text maps, and images in the cloud. The resultant data class provides high classification accuracy which is further fed into a metaheuristic algorithm namely Ant Colony Optimization (ACO) using File Type Formatting FTF for better load balancing in the cloud. Frequently used QoS metrics, such as SLA violations, migration time, throughput time, overhead time, and optimization time are evaluated in the cloud environment and comparative analysis is performed with recent metaheuristics, such as Ant Colony Optimization-Particle Swarm Optimization (ACOPS), Chaotic Particle Swarm Optimization (CPSO), Q- learning Modified Particle Swarm Optimization (QMPSO), Cat Swarm Optimization (CSO) and D-ACOELB. The proposed algorithm outperforms them and provides good performance with scalability and robustness.},
  doi      = {10.1109/ACCESS.2020.3003825},
}

@InProceedings{Meng2016,
  author    = {Meng, Shunmei and Zhou, Zuojian and Huang, Taigui and Li, Duanchao and Wang, Song and Fei, Fan and Wang, Wenping and Dou, Wanchun},
  booktitle = {2016 IEEE International Conference on Web Services (ICWS)},
  title     = {A Temporal-Aware Hybrid Collaborative Recommendation Method for Cloud Service},
  year      = {2016},
  month     = {June},
  pages     = {252-259},
  abstract  = {With the rapid development of cloud computing, large scale of cloud services are provided to users. Recommender systems have been proven to be valuable tools to deal with information overload and be able to provide appropriate recommendations to users. The cloud environment is dynamic and uncertain, which makes the quality of cloud services time-sensitive. However, most existing recommender systems did not take temporal influence into consideration, therefore could not accommodate the dynamic cloud environment. In view of this challenge, we propose a temporal-aware hybrid collaborative recommendation method for cloud service. It aims at providing users with appropriate recommendations from time-sensitive cloud services. In our method, by distinguishing temporal QoS metrics from stable QoS metrics, temporal influence is integrated into classical neighborhood-based collaborative recommender algorithm. Besides, to get an optimal recommendation, a temporal-aware latent factor model based on tensor decomposition is proposed and combined to improve the recommendation performance. Finally, experiments are designed and conducted to demonstrate the efficiency of our method.},
  doi       = {10.1109/ICWS.2016.40},
}

@InProceedings{Ramos2021,
  author    = {Ramos, Felipe and Viegas, Eduardo and Santin, Altair and Horchulhack, Pedro and dos Santos, Roger R. and Espindola, Allan},
  booktitle = {ICC 2021 - IEEE International Conference on Communications},
  title     = {A Machine Learning Model for Detection of Docker-based APP Overbooking on Kubernetes},
  year      = {2021},
  month     = {June},
  pages     = {1-6},
  abstract  = {Resource allocation overbooking is an approach used by cloud providers that allocates more virtual resources than available on physical hardware, which may imply service quality degradation. Docker in cloud computing environments is being increasingly used due to their fast provisioning and deployment, while the impact of overbooking of resources allocation due to multi-tenancy remains overlooked. This paper proposes a machine learning model to detect overbooking in Kubernetes environments within the docker container. The proposed model continuously monitors distributed container OS usage and application performance metrics. The collected metrics are used as input to a machine learning model that identifies multi-tenancy interference incurring in application performance degradation. Experiments performed on a Kubernetes cluster with a Docker-based Big Data processing application showed that our proposed model could detect resource overbooking with up to 98% accuracy. This implies an overbooking on a resource of up to 1.2 in the client’s domain.},
  doi       = {10.1109/ICC42927.2021.9500259},
  issn      = {1938-1883},
}

@InProceedings{Firdhous2020,
  author    = {Firdhous, M.F.M. and Budiarto, Rahmat},
  booktitle = {2020 5th International Conference on Information Technology Research (ICITR)},
  title     = {BTDM: A QoS-based Trust Distribution Mechanism for Cloud Computing},
  year      = {2020},
  month     = {Dec},
  pages     = {1-6},
  abstract  = {Cloud computing makes the delivery of computing resources over the Internet as services. As there are many providers in the market, it is necessary to monitor their performance. Several mechanisms for monitoring service quality of providers have been reported in the literature. But, it is not possible to monitor the entire cloud system by a single monitor. Hence, there is a need for a mechanism to share the performance metrics across a large geographical area. In this paper, the authors propose a mechanism called Bayesian Trust Distribution Mechanism (BTDM) for sharing the performance metrics as trust scores across an extended geographical area. The proposed BTDM also checks the reliability of the received scores based on their previous experience and adjusts them based on the reliability of sender. BTDM was tested using simulations and the results show that it performs better than the other mechanisms reported in the literature.},
  doi       = {10.1109/ICITR51448.2020.9310816},
}

@InProceedings{Maiyama2017,
  author    = {Maiyama, Kabiru Muhammad and Kouvatsos, Demetres and Mohammed, Bashir and Kiran, Mariam and Kamala, Mumtaz Ahmed},
  booktitle = {2017 IEEE 5th International Conference on Future Internet of Things and Cloud (FiCloud)},
  title     = {Performance Modelling and Analysis of an OpenStack IaaS Cloud Computing Platform},
  year      = {2017},
  month     = {Aug},
  pages     = {198-205},
  abstract  = {Performance is one of the main aspects that should be taken into consideration during the design, development, tuning and optimisation of computer networks supported by cloud computing platforms (CCPs). Queueing network models (QNMs) of CCPs constitute essential quantitative tools of investigation towards identifying acceptable levels of quality-of-service (QoS), whether for upgrading an existing CCP or designing a new one. In this paper, a new stable open QNM with either single or multiple server queueing stations, first-come-first-served (FCFS) scheduling and random routing is proposed for the performance modelling and analysis of an OpenStack Infrastructure as a Service (IaaS) CCP. In this context, it is assumed that the external arrival process is Poisson and the queueing stations provide exponentially distributed service times. Based on Jackson's Theorem, the open QNM is decomposed into individual M/M/c queues with c server(s) (c≥ 1) and exponential inter-arrival and service times, each of which can be analysed in isolation. Consequently, closed form expressions for key performance metrics of the QNM are determined, such as those for the mean response time, throughput, server (resource) utilisation and the probability of the number of requests by clients at each queueing station during waiting for and/or receiving resource provisioning. The evaluation of these metrics identifies the bottlenecks of the CCP that are causing the worst network delays and associated performance degradation and thus, provides insights into the capacity planning of networks with OpenStack IaaS solutions for CSPs.},
  doi       = {10.1109/FiCloud.2017.54},
}

@InProceedings{Haupt2017a,
  author    = {Haupt, Florian and Leymann, Frank and Scherer, Anton and Vukojevic-Haupt, Karolina},
  booktitle = {2017 IEEE International Conference on Software Architecture (ICSA)},
  title     = {A Framework for the Structural Analysis of REST APIs},
  year      = {2017},
  month     = {April},
  pages     = {55-58},
  abstract  = {Today, REST APIs have established as a means for realizing distributed systems and are supposed to gain even more importance in the context of Cloud Computing, Internet of Things, and Microservices. Nevertheless, many existing REST APIs are known to be not well-designed, resulting in the absence of desirable quality attributes that truly RESTful systems entail. Although existing analysis show, that many REST APIs are not fully REST compliant, it is still an open issue how to improve this deficit and where to start. In this work, we introduce a framework for the structural analysis of REST APIs based on their description documents, as this allows for a comprehensive, well-structured analysis approach that also includes analyzing the corresponding API description languages. A first validation builds on a set of 286 real world API descriptions available as Swagger documents, and comprises their transformation into a canonical metamodel for REST APIs as well as a metrics-based analysis and discussion of their structural characteristics with respect to compliance with the REST architectural style.},
  doi       = {10.1109/ICSA.2017.40},
}

@InProceedings{Gabi2017,
  author    = {Gabi, Danlami and Ismail, Abdul Samad and Zainal, Anazida and Zakaria, Zalmiyah and Al-Khasawneh, Ahmad},
  booktitle = {2017 8th International Conference on Information Technology (ICIT)},
  title     = {Cloud scalable multi-objective task scheduling algorithm for cloud computing using cat swarm optimization and simulated annealing},
  year      = {2017},
  month     = {May},
  pages     = {1007-1012},
  abstract  = {In cloud computing, customers-desired Quality of Service (QoS) expectations are quite superficial due to lack of scalable task scheduling solutions that can adjust to long-time changes. Researchers in the literature have put forward several task scheduling algorithms to account for customers' QoS expectations. Unfortunately, most of these algorithms need improvements to ensure the provisioning of better consumers' QoS expectation. In this study, a Multi-Objective QoS model to address customers' expectation based on execution time and execution cost criteria is presented. A Cloud Scalable Multi-Objective Cat Swarm Optimization (CSO) based Simulated Annealing (SA) (CSM-CSOSA) algorithm is then proposed to solve the model. In this method, the Taguchi Orthogonal approach is used to enhanced the SA and incorporated into the local search of the proposed algorithm for enhancing it exploration capability. Implementation of the algorithm is carried out on CloudSim tool and evaluated using one dataset (Normal distributed) and one Parallel Workload (High-Performance Computing Center North(HPC2N)). Quantitative analysis of the algorithm performance is taken based on metrics of execution time, execution cost, QoS and percentage improvement. Result obtained is compared with that of Multi-Objective Genetic Algorithm (MOGA), Multi-Objective Ant Colony (MOSACO) and Multi-Objective Particle Swarm Optimization (MOPSO), where proposed method is able to return substantial performance with improved QoS.},
  doi       = {10.1109/ICITECH.2017.8079983},
}

@InProceedings{Lima2019,
  author    = {Lima, Diana Bezerra Correia and da Silva Lima, Rubens Matheus Brasil and de Farias Medeiros, Douglas and Pereira, Renata Imaculada Soares and de Souza, Cleonilson Protasio and Baiocchi, Orlando},
  booktitle = {2019 IEEE 10th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON)},
  title     = {A Performance Evaluation of Raspberry Pi Zero W Based Gateway Running MQTT Broker for IoT},
  year      = {2019},
  month     = {Oct},
  pages     = {0076-0081},
  abstract  = {The Internet of Things (IoT) has become widely used in recent years in a wide range of applications, such as, weather condition monitoring, transportation, smart homes, smart cities, smart farm, etc. The ecosystem of the IoT is also vast, including from sensor and hardware devices up to cloud-computing. An approach that is getting more and more attention in the IoT ecosystem is the edge-computing and one of its fundamental pieces of equipment is the edge-computing gateway (GTW), which can working as a data-processing device nearer to the things and as a bridge to the Internet, as well. The most important features for these GTWs must be robustness and efficiency and a very popular solution is to use low-cost Raspberry Pi card-size computers. Considering protocol solution, Message Queue Telemetry Transport (MQTT) communication protocol has been considered one of the most applicable to IoT because of its low-power capability. In this context, this paper describes a study about the performance evaluation of a low-power member of the Raspberry Pi family, the Raspberry Pi Zero W, working as an IoT gateway and running MQTT. The experimental results show its performance using as metrics: the processor temperature, the CPU usage level, and rate of MQTT received messages under different Quality of Services (QoS).},
  doi       = {10.1109/IEMCON.2019.8936206},
  issn      = {2644-3163},
}

@InProceedings{Xu2018a,
  author    = {Xu, Jianwen and Ota, Kaoru and Dong, Mianxiong},
  booktitle = {2018 IEEE/CIC International Conference on Communications in China (ICCC)},
  title     = {Plug-and-Play for Fog: Dynamic Service Placement in Wireless Multimedia Networks},
  year      = {2018},
  month     = {Aug},
  pages     = {490-494},
  abstract  = {Initially as an extension of cloud computing, fog computing has been inspiring new ideas about moving computing tasks to the edge of a network. In fog, we often repeat the procedure of placing service because of the geographical distribution of mobile users. We may not expect a fixed demand and supply relationship between users and service providers since users always prefer nearby service with less time delay and transmission consumption. That is, a plug-and-play service mode is what we need in fog. In this paper, we put forward a dynamic placement strategy for fog service in a three-tier wireless multimedia network to guarantee the normal service provision and optimize the Quality of Service (QoS). The simulation results show that our strategy can achieve better performance under metrics including energy consumption and end-to-end latency compared with existed methods.},
  doi       = {10.1109/ICCChina.2018.8641090},
  issn      = {2377-8644},
}

@InProceedings{Mdhaffar2014,
  author    = {Mdhaffar, Afef and Halima, Riadh Ben and Jmaiel, Mohamed and Freisleben, Bernd},
  booktitle = {2014 IEEE 23rd International WETICE Conference},
  title     = {CEP4Cloud: Complex Event Processing for Self-Healing Clouds},
  year      = {2014},
  month     = {June},
  pages     = {62-67},
  abstract  = {This paper presents a cross-layer self-healing approach for Cloud computing environments, based on the Complex Event Processing method. It analyzes monitored events to detect performance-related problems and performs action to fix them without human intervention. Our proposal makes use of novel analysis rules, derived from a comprehensive study of the relationships between monitored metrics across multiple Cloud layers. The results of our study are used to define and optimize the analysis rules and identify the causes of performance-related problems. The results of several experiments demonstrate the benefits of the proposed approach in terms of speeding up the analysis without affecting the quality of the diagnosis.},
  doi       = {10.1109/WETICE.2014.56},
  issn      = {1524-4547},
}

@InProceedings{Techio2015,
  author    = {Techio, Leila Regina and Misaghi, Mehran},
  booktitle = {Fifth International Conference on the Innovative Computing Technology (INTECH 2015)},
  title     = {EMSCLOUD – an evaluative model of cloud services cloud service management},
  year      = {2015},
  month     = {May},
  pages     = {100-105},
  abstract  = {Cloud computing is considered a paradigm both technology and business. Its widespread adoption is an increasingly effective trend. However, the lack of quality metrics and audit of services offered in the cloud slows its use, and it stimulates the increase in focused discussions with the adaptation of existing standards in management services for cloud services offered. This article describes the EMSCloud, that is an Evaluative Model of Cloud Services following interoperability standards, risk management and audit of cloud IT services. Aims to present that is possible to assess the life cycle of services offered in the cloud in the technical dimensions of usability, good practices and economic viability.},
  doi       = {10.1109/INTECH.2015.7173479},
}

@InProceedings{Gabi2017a,
  author    = {Gabi, Danlami and Ismail, Abdul Samad and Zainal, Anazida and Zakaria, Zalmiyah and Al-Khasawneh, Ahmad},
  booktitle = {2017 8th International Conference on Information Technology (ICIT)},
  title     = {Cloud scalable multi-objective task scheduling algorithm for cloud computing using cat swarm optimization and simulated annealing},
  year      = {2017},
  month     = {May},
  pages     = {599-604},
  abstract  = {In cloud computing, customers-desired Quality of Service (QoS) expectations are quite superficial due to lack of scalable task scheduling solutions that can adjust to long-time changes. Researchers in the literature have put forward several task scheduling algorithms to account for customers' QoS expectations. Unfortunately, most of these algorithms need improvements to ensure the provisioning of better consumers' QoS expectation. In this study, a Multi-Objective QoS model to address customers profit based on execution time and execution cost criteria is presented. A Cloud Scalable Multi-Objective Cat Swarm Optimization (CSO) based Simulated Annealing (SA) (CSM-CSOSA) algorithm is then proposed to solve the model. In this method, the Taguchi Orthogonal approach is used to enhanced the SA and incorporated into the local search of the proposed algorithm for enhancing it exploration capability. Implementation of the algorithm is carried out on CloudSim tool and evaluated using one dataset (Normal distributed) and one Parallel Workload (High-Performance Computing Center North(HPC2N)). Quantitative analysis of the algorithm performance is taken based on metrics of execution time, execution cost, QoS and percentage improvement. Result obtained is compared with that of Multi-Objective Genetic Algorithm (MOGA), Multi-Objective Ant Colony (MOSACO) and Multi-Objective Particle Swarm Optimization (MOPSO), where proposed method is able to returned substantial performance with improved QoS.},
  doi       = {10.1109/ICITECH.2017.8080065},
}

@InProceedings{Goncalves2017,
  author    = {Gonçalves, Charles Ferreira},
  booktitle = {2017 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)},
  title     = {Benchmarking the Security of Virtualization Infrastructures: Motivation and Approach},
  year      = {2017},
  month     = {Oct},
  pages     = {100-103},
  abstract  = {With the growing adoption of cloud computing for business systems, the efforts to keep those environments secure are also increasing. Virtualization infrastructures are key to support such systems, but engineers lack means to help them in selecting the best solutions according to their security requirements. The goal of this work is to define and develop a benchmarking approach to assess and compare the security of virtualization infrastructures. The approach allows the benchmark user to define his usage scenario, which will influence the assessment metrics and quality model. Well established performance benchmarks will be used as workload. The evaluation procedure comprises two key phases: i) security qualification to make sure that detectable/known vulnerabilities are not present; ii) trustworthiness assessment to gather further evidences of the system security. We believe this approach will allow assessing and comparing systems in terms of security, thus helping IaaS providers to select the best infrastructure for their specific needs.},
  doi       = {10.1109/ISSREW.2017.70},
}

@InProceedings{Papakonstantinou2020,
  author    = {Papakonstantinou, Ioannis and Kalafatidis, Sarantis and Mamatas, Lefteris},
  booktitle = {2020 16th International Conference on Network and Service Management (CNSM)},
  title     = {A Techno-Economic Assessment of Microservices},
  year      = {2020},
  month     = {Nov},
  pages     = {1-5},
  abstract  = {The microservices design paradigm enables applications, usually based on containers, exploiting the flexibility of cloud computing and bringing unique scalability, fault-tolerance and resource-allocation benefits. A number of orchestration facilities, including Kubernetes, target the efficient deployment and operation of containers and are mainly focusing on the maintenance of server resource allocation under predefined thresholds, i.e., through scaling up or down containers to mitigate dynamic changes in the workload. In this work, we highlight the technical capabilities and cost-saving impact of microservices in contrast to traditional monolithic applications, based on a techno-economic analysis. We also investigate the service performance vs resource allocation trade-off, uncovering interesting dynamics when elasticity is driven from service quality metrics. This approach allows the Service Providers (SPs) to balance their profit margins with the customer satisfaction, i.e., reducing the infrastructure cost while keeping the service performance at an acceptable level.},
  doi       = {10.23919/CNSM50824.2020.9269114},
  issn      = {2165-963X},
}

@InProceedings{Nodehi2014,
  author    = {Nodehi, Tahereh and Ghimire, Sudeep and Jardim-Gonçalves, Ricardo},
  booktitle = {2014 2nd International Conference on Model-Driven Engineering and Software Development (MODELSWARD)},
  title     = {Toward a unified intercloud interoperability conceptual model for IaaS cloud service},
  year      = {2014},
  month     = {Jan},
  pages     = {673-681},
  abstract  = {The concept of interoperation between cloud providers is a recent research challenging objective. Current cloud systems have been developed without concerns of seamless cloud interconnection, and actually they do not support intercloud interoperability. The paper proposes a conceptual model for Intercloud Interoperability, to enable schedule dynamic operation for Infrastructure as a Service (IaaS) between different clouds. The paper is providing a better understanding of elaborates on the cloud computing architecture, appropriate metrics for Service Level Agreements (SLA) and Quality of Service (QoS) models that are required for seamless integration and interoperability between cloud environments. Then, a conceptual model for the Intercloud Interoperability Framework for Workload Migration is proposed. The novel component of the framework that provides interoperability is the Transformation Engine that maps workload between heterogeneous cloud providers, whilst Model Driven Architecture (MDA) is adopted as an applicable method for developing the Transformation Engine module.},
}

@Article{Wang2017b,
  author   = {Wang, Lujia and Liu, Ming and Meng, Max Q.-H.},
  journal  = {IEEE Transactions on Cybernetics},
  title    = {A Hierarchical Auction-Based Mechanism for Real-Time Resource Allocation in Cloud Robotic Systems},
  year     = {2017},
  issn     = {2168-2275},
  month    = {Feb},
  number   = {2},
  pages    = {473-484},
  volume   = {47},
  abstract = {Cloud computing enables users to share computing resources on-demand. The cloud computing framework cannot be directly mapped to cloud robotic systems with ad hoc networks since cloud robotic systems have additional constraints such as limited bandwidth and dynamic structure. However, most multirobotic applications with cooperative control adopt this decentralized approach to avoid a single point of failure. Robots need to continuously update intensive data to execute tasks in a coordinated manner, which implies real-time requirements. Thus, a resource allocation strategy is required, especially in such resource-constrained environments. This paper proposes a hierarchical auction-based mechanism, namely link quality matrix (LQM) auction, which is suitable for ad hoc networks by introducing a link quality indicator. The proposed algorithm produces a fast and robust method that is accurate and scalable. It reduces both global communication and unnecessary repeated computation. The proposed method is designed for firm real-time resource retrieval for physical multirobot systems. A joint surveillance scenario empirically validates the proposed mechanism by assessing several practical metrics. The results show that the proposed LQM auction outperforms state-of-the-art algorithms for resource allocation.},
  doi      = {10.1109/TCYB.2016.2519525},
}

@InProceedings{Saemi2021,
  author    = {Saemi, Behzad and Sadeghilalimi, Mehdi and Rahmani Hosseinabadi, Ali Asghar and Mouhoub, Malek and Sadaoui, Samira},
  booktitle = {2021 IEEE Congress on Evolutionary Computation (CEC)},
  title     = {A New Optimization Approach for Task Scheduling Problem Using Water Cycle Algorithm in Mobile Cloud Computing},
  year      = {2021},
  month     = {June},
  pages     = {530-539},
  abstract  = {Mobile devices are used by numerous applications that continuously need computing power to grow. Due to limited resources for complex computing, offloading, a service offered for mobile devices, is commonly used in cloud computing. In Mobile Cloud Computing (MCC), offloading decides where to execute the tasks to efficiently maximize the benefits. Hence, we represent offloading as a Task Scheduling Problem (TSP). This latter is a Multi-Objective Optimization (MOO) problem where the goal is to find the best schedule for processing mobile source tasks, while minimizing both the average processor energy consumption and the average task processing time. Owing to the combinatorial nature of the problem, the TSP in MCC is known as NP-hard. To overcome this difficulty in practice, we adopt meta-heuristic search techniques as they offer a good trade-off between solution quality and scalability. More precisely, we introduce a new optimization approach, that we call Multi-objective Discrete Water Cycle Algorithm (MDWCA), to schedule tasks from mobile source nodes to processor resources in a hybrid MCC architecture, including public cloud, cloudlets, and mobile devices. To evaluate the performance of our proposed approach, we conducted several comparative experiments on many generated TSP instances in MCC. The simulation results show that MDWCA outperforms the state-of-the-art optimization algorithms for several quality metrics.},
  doi       = {10.1109/CEC45853.2021.9504780},
}

@InProceedings{Hans2020,
  author    = {Hans, Manoj and Jagtap, Nilesh and Deokate, Jivan Balasaheb and Jogi, Vivek Kant},
  booktitle = {2020 Fourth International Conference on Inventive Systems and Control (ICISC)},
  title     = {Peak Load Management in Smart Grid – Integration of Rescheduling & Cloud Computing},
  year      = {2020},
  month     = {Jan},
  pages     = {861-865},
  abstract  = {Ever-increasing demand for power has motivated researchers to come up with methodologies for meeting the demand. A smart grid is one of the solutions to minimizing the issue. A smart grid has become a proven way to optimize the load flow, hence the balance between the demand and supply of power is maintained. Though the problem of demand and supply is resolved to some extent still problems persist. The efficiency of the system i.e. end to end must be high. The quality of power must be intact. Considering above mentioned factors there can be checkpoints at three different levels. Remedial measures can be at the utility or the consumer end. As much can’t be done at the utility side due to several constraints hence there is a need for implementation of remedial measures on the consumer end, also known as the Demand Side Management (DSM). The demand-side management must be given emphasis because of several advantages it serves to the consumer as well as to the utility. DSM has been implemented at the Institute premises with the application of cloud computing. Communication of data between the cloud and the microgrid at the institute has been monitored and analyzed in the experimentation. Through analysis has been presented in the paper.},
  doi       = {10.1109/ICISC47916.2020.9171079},
}

@Article{Yang2020,
  author   = {Yang, Xiao and Pavelsky, Tamlin M. and Allen, George H. and Donchyts, Gennadii},
  journal  = {IEEE Geoscience and Remote Sensing Letters},
  title    = {RivWidthCloud: An Automated Google Earth Engine Algorithm for River Width Extraction From Remotely Sensed Imagery},
  year     = {2020},
  issn     = {1558-0571},
  month    = {Feb},
  number   = {2},
  pages    = {217-221},
  volume   = {17},
  abstract = {The wetted width of a river is one of the most important hydraulic parameters that can be readily measured using remote sensing. Remotely sensed river widths are used to estimate key attributes of river systems, including changes in their surface area, channel storage, and discharge. Although several published algorithms automate river network and width extraction from remote sensing images, they are limited by only being able to run on local computers and do not automatically manage cloudy images as input. Here we present RivWidthCloud, a river width software package developed on the Google Earth Engine cloud computing platform. RivWidthCloud automatically extracts river centerline and widths from optical satellite images with the ability to flag observations that are obstructed by features like clouds, cloud shadows, and snow based on existing quality band classification. Because RivWidthCloud is built on a popular cloud computing platform, it allows users to easily apply the algorithm to the platform's vast archive of remote sensing images, thereby reducing the users' overhead for computing hardware and data storage. By comparing RivWidthCloud-derived widths from Landsat images to in situ widths from the U.S. and Canada, we show that RivWidthCloud can estimate widths with high accuracy (root mean square error: 99 m; mean absolute error: 43 m; mean bias: -21 m). By making RivWidthCloud publicly available, we anticipate that it will be used to address both river science questions and operational applications of water resource management.},
  doi      = {10.1109/LGRS.2019.2920225},
}

@InProceedings{AlShammari2015,
  author    = {Al-Shammari, Shaymaa and Al-Yasiri, Adil},
  booktitle = {2015 IEEE 9th International Symposium on the Maintenance and Evolution of Service-Oriented and Cloud-Based Environments (MESOCA)},
  title     = {MonSLAR: a middleware for monitoring SLA for RESTFUL services in cloud computing},
  year      = {2015},
  month     = {Oct},
  pages     = {46-50},
  abstract  = {Measuring the quality of cloud computing provision from the client's point of view is important in order to ensure that the service conforms to the level specified in the service level agreement (SLA). With a view to avoid SLA violation, the main parameters should be determined in the agreement and then used to evaluate the fulfillment of the SLA terms at the client's side. Current studies in cloud monitoring only handle monitoring the provider resources with little or no consideration to the client's side. This paper presents MonSLAR, a User-centric middleware for Monitoring SLA for Restful services in SaaS cloud computing environments. MonSLAR uses a distributed architecture that allows SLA parameters and the monitored data to be embedded in the requests and responses of the REST protocol.},
  doi       = {10.1109/MESOCA.2015.7328126},
  issn      = {2326-6937},
}

@InProceedings{Shibu2017,
  author    = {Shibu, Sini and Naik, Archana},
  booktitle = {2017 International Conference on Information, Communication, Instrumentation and Control (ICICIC)},
  title     = {An approach to increase the awareness of e-governance initiatives based on cloud computing},
  year      = {2017},
  month     = {Aug},
  pages     = {1-4},
  abstract  = {E-governance is being adopted by the governments of every country for its operations through the ICT (Information and Communication Technology) i.e. incorporating its operations through IT model so that the schemes can be reached to the masses. In India too, as of now, nearly every state government has its own e-Governance model. Cloud computing is now being widely used in e-governance. With the help of the features of Cloud computing, e-Governance operations can be built up as cost effective technology solutions and can be geographically distributed to heterogeneous resources thereby increasing the quality of service to the users. In fact, G-cloud (Governance on Cloud) is designed for using Government services. It is not merely enough to set up e-governance models but its awareness amongst masses is equally important. This paper analyses the cloud based model of e-governance and suggests measures to increase awareness among people regarding the various e-governance initiatives taken by the Government of Madhya Pradesh.},
  doi       = {10.1109/ICOMICON.2017.8279168},
}

@InProceedings{Singh2015,
  author    = {Singh, Sarbjeet and Sidhu, Jagpreet},
  booktitle = {2015 2nd International Conference on Recent Advances in Engineering & Computational Sciences (RAECS)},
  title     = {A collaborative trust calculation scheme for cloud computing systems},
  year      = {2015},
  month     = {Dec},
  pages     = {1-5},
  abstract  = {One of the major hurdles in the widespread use of cloud computing systems is the lack of trust between consumer and service provider. Lack of trust can put consumer's sensitive data and applications at risk. Consumers need assurance that service providers will provide services as per agreement and will not deviate from agreed terms and conditions. Though trust is a subjective term, it can be measured objectively also. In this paper we present the design and simulation of a collaborative trust calculation scheme in which trust on a service provider is build by participants in a collaborative way. Each collaborator shares its experience of service provider with the coordinator and then shared experiences are aggregated by coordinator to compute final trust value which represents the trustworthiness of service provider. The scheme makes use of fuzzy logic to aggregate responses and to handle uncertain and imprecise information. Collaborative trust calculation scheme makes it difficult for untrustworthy service provider to build its reputation in the system by providing quality services only to a selected set of participants. A service provider has to provide agreed services to all participants uniformly in order to build reputation in the environment. Simulation has been done using MATLAB toolkit. Simulation results show that the scheme is workable and can be adopted for use in collaborative cloud computing systems to determine trustworthiness of service providers.},
  doi       = {10.1109/RAECS.2015.7453380},
}

@InProceedings{Mengge2018,
  author    = {Mengge, YUAN and Rui, LI and Ning, ZHAO},
  booktitle = {2018 International Conference on Information Systems and Computer Aided Education (ICISCAE)},
  title     = {Optimization of the Number of Servers in Cloud Computing Centers},
  year      = {2018},
  month     = {July},
  pages     = {269-273},
  abstract  = {To improve the service quality and save the system cost of the cloud computing center, this paper studies the joint optimization problem of energy consumption and performance of cloud computing centers with a batch Markovian arrival process. The system has multiple parallel processors and the processing time of each processor follows phase type distribution. The system has finite buffer. We construct the system as a BMAP/PH/N/M queueing system and analyze the performance of the system based on queuing theory. An optimization model is established by combing the energy consumption and system performance measures. The optimal number of servers is analyzed. Some managerial insights are given by numerical analysis.},
  doi       = {10.1109/ICISCAE.2018.8666838},
}

@InProceedings{Chen2020a,
  author    = {Chen, Zhijia and Di, Yanqiang and Yuan, Hongli and Feng, Shaochong},
  booktitle = {2020 IEEE 4th Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)},
  title     = {Intelligent Cloud Training System based on Edge Computing and Cloud Computing},
  year      = {2020},
  month     = {June},
  pages     = {1550-1553},
  volume    = {1},
  abstract  = {Equipment simulation training based on cloud computing is emerging. However, the latency between cloud center and client is long, and the energy consumption management is difficult, which are influencing the development of cloud training. Intelligent cloud training system based on edge computing and cloud computing is introduced in this paper. Intelligent gateway is introduced, through which the task and resources are scheduled and managed together. The popularity of training resources is analyzed. The management of servers in cloud center and edge is intelligently switched between timing sleep and task-activation. Intelligent training service provisioning is achieved through above measures. The simulation results show that the system and management methods are effective on improving training service quality and lower the energy consumption.},
  doi       = {10.1109/ITNEC48623.2020.9084987},
}

@Article{Ala’anzy2019,
  author   = {Ala’anzy, Mohammed and Othman, Mohamed},
  journal  = {IEEE Access},
  title    = {Load Balancing and Server Consolidation in Cloud Computing Environments: A Meta-Study},
  year     = {2019},
  issn     = {2169-3536},
  pages    = {141868-141887},
  volume   = {7},
  abstract = {The data-center is considered the heart of cloud computing. Recently, the growing demand for cloud computing services has caused a growing load on data centers. In terms of system behavior and workload, patterns of cloud computing are very dynamic; and that might serve to imbalance the load among data center resources. Eventually, some data-center resources could come to be over-loaded/under-loaded, which leads to an increase in energy consumption in addition to decreased functioning and wastage of resources. Just considering energy-efficiency (that can be attained efficiently by consolidate the servers) may not be enough for real applications because it may cause problems such as unbalanced load for each Physical Machine (PM). Therefore, this paper surveys published load balancing algorithms that achieved by server consolidation via a meta-analysis. Load balancing with server consolidation enriches the exploitation of resource utilization and can enhance Quality of Service (QoS) metrics, since data-centers and their applications are increasing exponentially. This meta-study, reviews the literature on load balancing and server consolidation and presents a ready reference taxonomy on the most efficient algorithms that achieve load balancing and server consolidation. This work attempts to present a taxonomy with a new classification for load balancing and server consolidation, such as migration overhead, hardware threshold, network traffic, and reliability.},
  doi      = {10.1109/ACCESS.2019.2944420},
}

@Article{Bui2020,
  author   = {Bui, Khiet Thanh and Van Vo, Len and Nguyen, Canh Minh and Pham, Tran Vu and Tran, Hung Cong},
  journal  = {Journal of Communications and Networks},
  title    = {A fault detection and diagnosis approach for multi-tier application in cloud computing},
  year     = {2020},
  issn     = {1976-5541},
  month    = {Oct},
  number   = {5},
  pages    = {399-414},
  volume   = {22},
  abstract = {Ensuring the availability of cloud computing services always concerns both service providers and end users. Therefore, the system always needs precautions for unexpected cases. Accordingly, cloud computing services must be capable of identifying faults and behaving appropriately when it is abnormal to ensure the smoothness as well as the service quality. In this study, we propose a fault detection method for multi-tier web application in cloud computing deployment environment based on the Fuzzy One-class support vector machine and Exponentially Weighted Moving Average method. And then, the suspicious metrics are located by using feature selection method which based on Random Forest algorithm. To evaluate our approach, a multi-tier application is deployed by a transnational web e-Commerce benchmark by using TPC-W (TPC Benchmark™ W, simulates the activities of a business oriented transaction web server in a controlled internet commerce environment) in private cloud and then it is injected typical faults. The effectiveness of the fault detection and diagnosis are demonstrated in experiment results.},
  doi      = {10.1109/JCN.2020.000023},
}

@InProceedings{Kong2018,
  author    = {Kong, Cuiyu and Rimal, Bhaskar Prasad and Bhattarai, Bishnu P. and Devetsikiotis, Michael},
  booktitle = {2018 IEEE International Conference on Communications (ICC)},
  title     = {Cloud-Based Charging Management of Electric Vehicles in a Network of Charging Stations},
  year      = {2018},
  month     = {May},
  pages     = {1-6},
  abstract  = {A large scale of electric vehicles (EVs) and the operation of smart grid requires the support of a reliable and robust communication infrastructure. Cloud computing has gained popularity in smart grid for reducing computational and communication complexity. Based on cloud computing services, this paper considers the issues of high charging demand in fast charging stations (FCSs) during peak hours and communication among a large-scale of EVs, a network of FCSs, and system operator (SO). More specifically, we propose a novel cloud-based hierarchical charging management model of EVs, whereby two levels of cloud computing infrastructures are considered to meet different latency requirements of customers in highway exits and parking lots. Considering the quality of service (QoS) metrics (average waiting time in the queue, and blocking probability), the model is composed of: server planning in the cloud, capacity planning in FCSs, and profit maximization. Meanwhile, a price incentive mechanism is applied to shift the heavy load from peak hours to off-peak hours. Numerical results demonstrate the effectiveness of the proposed method, which can guarantee QoS and system profit, thereby more customers can satisfy their charging demand.},
  doi       = {10.1109/ICC.2018.8422909},
  issn      = {1938-1883},
}

@InProceedings{Baghel2017,
  author    = {Baghel, Dinesh Kumar and Singh, Arun and Deka, Pratyush Kumar},
  booktitle = {2017 International Conference on Computing, Communication and Automation (ICCCA)},
  title     = {Agricultural management using cloud computing in India},
  year      = {2017},
  month     = {May},
  pages     = {801-806},
  abstract  = {Although agriculture now accounts for only 14 percent of Gross Domestic Product (GDP), rapid growth of agriculture in India is critical for inclusiveness. Information Communication and Technology (ICT) provides greater role in offering greater expertise to producers regarding pricing, good quality seed information, fertilizers, disease detail, sharing new discoveries of scientists working at various Agricultural Institutes. An effective implementation of cloud computing in agricultural sector is encouraging and required for overall development of agricultural sector of India. There are potential risks in cloud computing which if properly addressed can be a potent ICT tool in agricultural sector in India. Considering the benefits of cloud computing, a design is proposed for Indian agricultural sector and two performance metrics are discussed which can be used to assess any cloud based application.},
  doi       = {10.1109/CCAA.2017.8229905},
}

@InProceedings{Gopavanitha2017,
  author    = {Gopavanitha, K. and Nagaraju, S.},
  booktitle = {2017 International Conference on Energy, Communication, Data Analytics and Soft Computing (ICECDS)},
  title     = {A low cost system for real time water quality monitoring and controlling using IoT},
  year      = {2017},
  month     = {Aug},
  pages     = {3227-3229},
  abstract  = {Water is a prerequisite element required for humans and therefore there must be mechanisms put in place to vigorously test the quality of drinking water in real time. This paper proposes a low cost system for real time water quality monitoring and controlling using IoT. The system consist of physiochemical sensors which can measures the physical and chemical parameters of the water such as Temperature, Turbidity, Conductivity, pH and Flow. By these sensors, water contaminants are detected. The sensor values processed by Raspberry pi and send to the cloud. Finally the sensed data is visible on the cloud using cloud computing and the flow of the water in the pipeline is controlled through IoT.},
  doi       = {10.1109/ICECDS.2017.8390054},
}

@InProceedings{Li2016a,
  author    = {Li, Suyou and Guo, Zhigang and Shou, Guochu and Hu, Yihong and Li, Hongxing},
  booktitle = {2016 IEEE International Conference on Network Infrastructure and Digital Content (IC-NIDC)},
  title     = {QoE analysis of NFV-based mobile edge computing video application},
  year      = {2016},
  month     = {Sep.},
  pages     = {411-415},
  abstract  = {Mobile Edge Computing (MEC) provides mobile and cloud computing capabilities within the access network. Network Functions Virtualization (NFV) leverages standard IT Virtualization technology to decouple the network functions from the underlying physical infrastructure. Basing on the ICT demand, MEC can be consolidated into NFV, as a network element within access network. This paper presents an architecture of NFV-based MEC platform and analyzes its Quality of Service (QoS) compared with the remote servers (Shenzhen and Qingdao). Then, this paper measures the Quality of Experience (QoE) of HTTP videos deployed in the servers. The result shows MEC can offer a service environment with higher bandwidth, which supports 10-fold gains, and ultra-low latency, jitter and packet loss rate. Moreover, along with the higher resolution and bitrates, the range of the video QoE improvement on this platform rises compared with the remote servers. In a word, the NFV-based MEC can achieve better performance than the remote servers.},
  doi       = {10.1109/ICNIDC.2016.7974607},
}

@InProceedings{Puteaux2017,
  author    = {Puteaux, Pauline and Puech, William},
  booktitle = {2017 Seventh International Conference on Image Processing Theory, Tools and Applications (IPTA)},
  title     = {Reversible data hiding in encrypted images based on adaptive local entropy analysis},
  year      = {2017},
  month     = {Nov},
  pages     = {1-6},
  abstract  = {With the development of cloud computing, the growth in information technology has led to serious security issues. For this reason, a lot of multimedia files are stored in encrypted forms. Methods of reversible data hiding in encrypted images (RDHEI) have been designed to provide authentication and integrity in the encrypted domain. The original image is firstly encrypted to ensure confidentiality, by making the content unreadable. A secret message is then embedded in the encrypted image, without the need of the encryption key or any access to the clear content. The challenge lies in finding the best trade-off between embedding capacity and quality of the reconstructed image. In 2008, Puech et al. suggested using the AES algorithm to encrypt an original image and to embed one bit in each block of 16 pixels (payload = 0.0625 bpp) [12]. During the decryption phase, the original image is reconstructed by measuring the standard deviation into each block. In this paper, we propose an improvement to this method, by performing an adaptive local entropy measurement. We can achieve a larger payload without altering the recovered image quality. Our obtained results are very good and better than most of the modern state-of-the-art methods, whilst offering an improved security level with the use of the AES algorithm, defined as the encryption standard by the NIST.},
  doi       = {10.1109/IPTA.2017.8310143},
  issn      = {2154-512X},
}

@Article{AbdulRahman2020,
  author   = {Abdul-Rahman, Omar Arif and Aida, Kento},
  journal  = {IEEE Transactions on Cloud Computing},
  title    = {Google Users as Sequences: A Robust Hierarchical Cluster Analysis Study},
  year     = {2020},
  issn     = {2168-7161},
  month    = {Jan},
  number   = {1},
  pages    = {167-179},
  volume   = {8},
  abstract = {In this era of cloud computing, users encounter the challenging task of effectively composing and running their applications on the cloud. By understanding user behavior in constructing applications and interacting with typical cloud infrastructures, cloud managers can develop better systems that improve the users' experience. In this paper, we analyze a large dataset of a Google cluster to characterize the users into distinct groups of similar usage behavior. We used a wide range of measured metrics to model user behavior in composing applications from the perspective of actions around application architecting, capacity planning, and workload type planning and to model user interaction behavior around the session view. The trajectories of users' actions are represented as sequences using categorical and proportional encoding schemes. We used techniques from the sequence analysis paradigm to quantify dissimilarity among users. We employed a robust cluster analysis procedure based on the agglomerative hierarchical methods to optimally classify users into 12 classes. We used a variety of formal indices and visual aids to confirm the quality and stability of the outcomes. By visual inspection, we regrouped the obtained clusters into 5 main groups that reveal interesting insights about the characteristics which underline different groups' utilization behavior.},
  doi      = {10.1109/TCC.2017.2766227},
}

@InProceedings{He2016,
  author    = {He, Fei-Long and Chen, Wei-Neng and Hu, Xiao-Min},
  booktitle = {2016 IEEE Congress on Evolutionary Computation (CEC)},
  title     = {Differential evolution with double-level archives for bi-objective cloud task scheduling},
  year      = {2016},
  month     = {July},
  pages     = {2942-2949},
  abstract  = {In cloud computing, scheduling plays a critical role for quality of service (QoS) and provider efficiency which are generally measured by several metrics and make the scheduling a multiobjective problem (MOP). In this paper, we propose a differential evolution algorithm with double-level archives (DE-DLA) for bi-objective cloud task scheduling. The proposed algorithm is based on the newly-developed framework, multiobjective evolutionary algorithm with double-level archives (MOEA-DLA), and uses differential evolution to implement this framework. Global Archive is used to save Pareto-optimal individuals for the whole problem and Sub-archive is used to save several comparatively good individuals for the corresponding sub-problem formed by decomposition. So the algorithm takes advantages of both whole multiobjective problem optimization and decomposition based optimization. Precedence constraint in user's application is considered in the scheduling model of this paper. To minimize cost and makespan simultaneously, the proposed algorithm tries to find optimal resource allocation and optimal order of task executing. In the experiment, compared with two other algorithms, DE-DLA has shown competitive advantages.},
  doi       = {10.1109/CEC.2016.7744161},
}

@Article{Shuja2016,
  author   = {Shuja, Junaid and Bilal, Kashif and Madani, Sajjad A. and Othman, Mazliza and Ranjan, Rajiv and Balaji, Pavan and Khan, Samee U.},
  journal  = {IEEE Systems Journal},
  title    = {Survey of Techniques and Architectures for Designing Energy-Efficient Data Centers},
  year     = {2016},
  issn     = {1937-9234},
  month    = {June},
  number   = {2},
  pages    = {507-519},
  volume   = {10},
  abstract = {Cloud computing has emerged as the leading paradigm for information technology businesses. Cloud computing provides a platform to manage and deliver computing services around the world over the Internet. Cloud services have helped businesses utilize computing services on demand with no upfront investments. The cloud computing paradigm has sustained its growth, which has led to increase in size and number of data centers. Data centers with thousands of computing devices are deployed as back end to provide cloud services. Computing devices are deployed redundantly in data centers to ensure 24/7 availability. However, many studies have pointed out that data centers consume large amount of electricity, thus calling for energy-efficiency measures. In this survey, we discuss research issues related to conflicting requirements of maximizing quality of services (QoSs) (availability, reliability, etc.) delivered by the cloud services while minimizing energy consumption of the data center resources. In this paper, we present the concept of inception of data center energy-efficiency controller that can consolidate data center resources with minimal effect on QoS requirements. We discuss software- and hardware-based techniques and architectures for data center resources such as server, memory, and network devices that can be manipulated by the data center controller to achieve energy efficiency.},
  doi      = {10.1109/JSYST.2014.2315823},
}

@Article{Gamal2019,
  author   = {Gamal, Marwa and Rizk, Rawya and Mahdi, Hani and Elnaghi, Basem E.},
  journal  = {IEEE Access},
  title    = {Osmotic Bio-Inspired Load Balancing Algorithm in Cloud Computing},
  year     = {2019},
  issn     = {2169-3536},
  pages    = {42735-42744},
  volume   = {7},
  abstract = {Cloud computing is increasing rapidly as a successful paradigm presenting on-demand infrastructure, platform, and software services to clients. Load balancing is one of the important issues in cloud computing to distribute the dynamic workload equally among all the nodes to avoid the status that some nodes are overloaded while others are underloaded. Many algorithms have been suggested to perform this task. Recently, worldview is turning into a new paradigm for optimization search by applying the osmosis theory from chemistry science to form osmotic computing. Osmotic computing is aimed to achieve balance in highly distributed environments. The main goal of this paper is to propose a hybrid metaheuristics technique which combines the osmotic behavior with bio-inspired load balancing algorithms. The osmotic behavior enables the automatic deployment of virtual machines (VMs) that are migrated through cloud infrastructures. Since the hybrid artificial bee colony and ant colony optimization proved its efficiency in the dynamic environment in cloud computing, the paper then exploits the advantages of these bio-inspired algorithms to form an osmotic hybrid artificial bee and ant colony (OH_BAC) optimization load balancing algorithm. It overcomes the drawbacks of the existing bio-inspired algorithms in achieving load balancing between physical machines. The simulation results show that OH_BAC decreases energy consumption, the number of VMs migrations and the number of shutdown hosts compared to existing algorithms. In addition, it enhances the quality of services (QoSs) which is measured by service level agreement violation (SLAV) and performance degradation due to migrations (PDMs).},
  doi      = {10.1109/ACCESS.2019.2907615},
}

@InProceedings{Wang2017c,
  author    = {Wang, Paul and Takizawa, Shigeyuki and He, David and Ge, Fred and Wang, Orson and Ye, Fred and Liang, Park and Tan, KG},
  booktitle = {2017 18th International Conference on Electronic Packaging Technology (ICEPT)},
  title     = {DDR4 dual-contact interconnect methodology, component, and board level reliability},
  year      = {2017},
  month     = {Aug},
  pages     = {1337-1344},
  abstract  = {This article is a series of study on new generation of electronic contact challenges and component interconnects technology for high-end computing products. These products include server and data storage for cloud computing applications at the data center as well as core routers for service providers, edge and branch routers for enterprise networking companies, and small switch and wireless router for commercial and small and home office. All these cloud computing products require high data speed in terabytes per second and high signal integrity for the massive mobile users and loT application whenever and wherever they connected To achieve such mobility and signal integrity the major focus is the electrical interconnections between the CPUlGPU and component in the system. Due to the large number of edge-card connections such as DIMM, PCle, etc. in modern computer systems and due to their relatively low reliability, in previous Part 2 of the study a test vehicle with daisy chain was used to assess the contact interconnect failure related to factors such as soldering flux residue, plating quality, contact interface cleaning and doubt insertion, and particulate control and management. As concluded in Part 2, the heavy flux residue and vibration preconditioning have medium effect on contact failure, however contact interface cleaning and particulate control show no significant contribution and not able to eliminate the last thousands DPPM of DIMM contact failure. The purpose of current study is to look into a new generation of dual-contact interconnect methodology and assess component level contact configuration and interconnect reliability. First, the contact pin configuration and plating morphology such as homogeneity and thickness are carefully examined to ensure contact integrity between DDR4 connect and DIMM module can be achieved. Then normal force of dual-pin and individual first and second contact were measured to benchmark to existing conventional single-contacts. Furthermore the JEDEC Raptor test vehicle was adapted to assess characteristic impedance and four signal integrity tests, RL (return loss), IL (insertion loss), NEXT (near-end cross talk), and FEXT (far-end cross talk) to ensure signal integrity requirements are fulfilled. Finally, board level reliability test is proposed for Raptor test board and trial run on real product. The overall goal of Part 3 of the study is to ensure a smooth migration from conventional single-contact to a new interconnect mechanism with robust board and system reliability for high signal integrity requirement in cloud computing and loT application.},
  doi       = {10.1109/ICEPT.2017.8046685},
}

@InProceedings{Ishak2021,
  author    = {Ishak, Md and Rahman, Raiyan and Mahmud, Tahasin},
  booktitle = {2021 5th International Conference on Electrical Engineering and Information Communication Technology (ICEEICT)},
  title     = {Integrating Cloud Computing in E-healthcare: System Design, Implementation and Significance in Context of Developing Countries},
  year      = {2021},
  month     = {Nov},
  pages     = {1-6},
  abstract  = {Cloud computing in the medical sector refers to the method of storing, maintaining, and processing electronic health records and relevant services on cloud servers that are accessible over the internet. The flexibility of cloud computing makes it a practical approach for enhancing the quality, dependability, and efficiency of medical services, as well as increasing patient-doctor interaction and safeguarding patient anonymity if proper measures are taken. Furthermore, cloud strategies facilitate healthcare technologies such as computerized healthcare records, remote appointments, mobile applications, patient portals, IoT devices, and big data analytics, enabling trouble-free scalable solutions. Integrating cloud computing technologies can especially be beneficial in increasing the efficiency of healthcare services in developing counties where physical health infrastructure is usually limited. As such, the objective of this work is to explore the feasibility of incorporating cloud and distributed computing in e-healthcare through an extensive requirement analysis and user study. Then, the smart healthcare system will be compared with traditional database-centric healthcare systems and a prototype system will be designed and implemented based on the findings. Finally, we focus on finding the usability and user acceptance of such systems and challenges that lie with integrating cloud services to e-healthcare systems for the general user demographic of developing countries through extensive usability evaluation.},
  doi       = {10.1109/ICEEICT53905.2021.9667831},
}

@InProceedings{Wen2014,
  author    = {Wen, Zi-Yi and Hsiao, Hsu-Feng},
  booktitle = {2014 IEEE 16th International Workshop on Multimedia Signal Processing (MMSP)},
  title     = {QoE-driven performance analysis of cloud gaming services},
  year      = {2014},
  month     = {Sep.},
  pages     = {1-6},
  abstract  = {With the popularity of cloud computing services and the endorsement from the video game industry, cloud gaming services have emerged promisingly. In a cloud gaming service, the contents of games can be delivered to the clients through either video streaming or file streaming. Due to the strict constraint on the end-to-end latency for real-time interaction in a game, there are still challenges in designing a successful cloud gaming system, which needs to deliver satisfying quality of experience to the customers. In this paper, the methodology for subjective and objective evaluation as well as the analysis of cloud gaming services was developed. The methodology is based on a nonintrusive approach, and therefore, it can be used on different kinds of cloud gaming systems. There are challenges in such objective measurements of important QoS factors, due to the fact that most of the commercial cloud gaming systems are proprietary and closed. In addition, satisfactory QoE is one of the crucial ingredients in the success of cloud gaming services. By combining subjective and objective evaluation results, cloud gaming system developers can infer possible results of QoE levels based on the measured QoS factors. It can also be used in an expert system for choosing the list of games that customers can appreciate at a given environment, as well as for deciding the upper bound of the number of users in a system.},
  doi       = {10.1109/MMSP.2014.6958835},
}

@InProceedings{Forcan2020,
  author    = {Forcan, M. and Maksimović, M. and Forcan, J. and Jokić, S.},
  booktitle = {2020 28th Telecommunications Forum (TELFOR)},
  title     = {5G and Cloudification to Enhance Real-Time Electricity Consumption Measuring in Smart Grid},
  year      = {2020},
  month     = {Nov},
  pages     = {1-4},
  abstract  = {The number of smart devices in Smart Grid (SG) increases continuously and the presence of big data demands more efficient communication architectures. It is anticipated that the full potential of the SG vision in terms of better performances, reliability, and quality of service, can be achieved by incorporating the fifth generation of cellular network technology (5G) and Cloudification into the SG. In order to demonstrate their potential in SG, this paper presents the enhancement of real-time electricity consumption measuring with the help of 5G and Cloud computing. 5G-based communication model supporting Advanced Metering Infrastructure (AMI) in SG is built and validated on the example of real-time communication between the SM model and Cloud platform ThingSpeak.},
  doi       = {10.1109/TELFOR51502.2020.9306518},
}

@InProceedings{Anita2019,
  author    = {Anita, J. Mary and Raina, Roma},
  booktitle = {2019 International Conference on Computational Intelligence and Knowledge Economy (ICCIKE)},
  title     = {Review on Smart Grid Communication Technologies},
  year      = {2019},
  month     = {Dec},
  pages     = {215-220},
  abstract  = {Smart grid (SG) has given a better vision for electricity infrastructure. The quality, quantity of power transmitted and the usage of available data from smart sensing, metering and communication has dramatically increased with the introduction of smart grid to power systems. SG also has empowered customer participation by managing their load pattern to take advantage of choosing their supply and pricing options. The heart of the SG lies on the communication between the consumers and the grid operators. Grids operators need the real time customer meter data to schedule their supply and pricing policies and the consumers need the same to manage their loads. The Wireless Sensor Network (WSN) uses Aggregation Protocol with Error Detection (APED) to improve the security of data. The SG with SCADA is facilitated by data acquisitions which includes the meter reading, system conditions, etc. that are monitored and transmitted at regular intervals in real time. The security of data transfer is assured by the introduction of improvised Ciphertext Policy_ Attribute Based Encryption (CP-ABE) is used to achieve the security parameters like confidentiality, integrity, and availability in cloud computing. Block chain-based systems combine distributed register and cryptographic security measures. Introduction of block chain in SG has revolutionized the functioning of SG with smart contracts, and transaction of huge amount of data in a fully decentralized market platform.This paper reviews the modern technologies used in smart grid communication based on IEEE 802.15.4 standard to the SG and how it is modified to ensure effective, efficient and economical and secured communication of the huge real time data from the smart meters.},
  doi       = {10.1109/ICCIKE47802.2019.9004389},
}

@InProceedings{Lin2016,
  author    = {Lin, Cho-Chin and Kuo, Yuan-Han and Xie, Dong-Ye and Goh, Wei-Ping and Wu, Shyi-Tsong},
  booktitle = {2016 7th International Conference on Cloud Computing and Big Data (CCBD)},
  title     = {A Practical Model for Analyzing Push-Based Virtual Machine Live Migration},
  year      = {2016},
  month     = {Nov},
  pages     = {347-352},
  abstract  = {Virtual Technology has been employed by cloud computing to satisfy service requests from the customers. Virtual machine live migration provides non-stop services while an unexpected event impacts the service quality of the host. The cost of performing live migration is measured by the total number of transferred pages and the service suspension time. In this paper, a practical model for analysing push-based live migration is proposed. The model abstracts live migration strategy into trend and sanction functions. Based on the model, the patterns on the numbers of transferred memory frames in the iterations have been analysed for various dirty frequencies and push rules. Furthermore, it is useful for developing a formal method for conducting complex analysis.},
  doi       = {10.1109/CCBD.2016.074},
}

@InProceedings{Tri2019,
  author    = {Tri, Nguyen Minh and Nagata, Syunya and Tsuru, Masato},
  booktitle = {2019 20th Asia-Pacific Network Operations and Management Symposium (APNOMS)},
  title     = {Locating Delay Fluctuation-Prone Links by Packet Arrival Intervals in OpenFlow Networks},
  year      = {2019},
  month     = {Sep.},
  pages     = {1-6},
  abstract  = {In cloud computing and content delivery networking, OpenFlow-based centrally managed networks to connect distributed servers are becoming popular these days. To maintain service quality and availability in such networks by flexible and dynamic traffic engineering, detecting and locating deteriorated (e.g., congested) links in an efficient manner is essential. Following our previous study that actively monitors packet loss rate to find deteriorated links, in this paper, we actively estimate packet delay variance on each link (note both up and down directions of each full-duplex link are distinguished) in an OpenFlow network. A notable feature is that packet delay variance is estimated based on monitoring arrival time intervals of probe packets without directly measuring packet delay time over a link. In the proposed scheme, a series of probe packets is launched from a measurement host and traverses each direction of each link once and only once by multicasting, while arrival time intervals of those packets at each input port of OpenFlow switches are monitored. Then the OpenFlow controller collects the arrival time interval statistics from those switches to locate delay fluctuation-prone links, i.e., links with a high packet delay variance, which are likely congested or physically unstable. In addition, to minimize the necessary number of accesses to switch ports, an appropriate order of collecting statistics from switches is dynamically controlled. The results of numerical simulation on large-scale network topologies demonstrate the effectiveness of our proposed scheme. A prototype implementation which requires an extension of OpenFlow is also presented on Mininet.},
  doi       = {10.23919/APNOMS.2019.8892932},
  issn      = {2576-8565},
}

@InProceedings{Prathibha2018,
  author    = {Prathibha, K and Hegde, Pawan},
  booktitle = {2018 9th International Conference on Computing, Communication and Networking Technologies (ICCCNT)},
  title     = {A Real-Time System for Environmental Study Based on Cloud Computing},
  year      = {2018},
  month     = {July},
  pages     = {1-6},
  abstract  = {Following the ecological parameters variation is important keeping in mind the end goal to decide on the nature of our environment. This paper aims at detecting and detailing the changes in the environmental parameters. Environmental monitoring applications based on cloud computing makes use of sensors to help in protecting environmental conditions by checking parameters like temperature, air quality, earthquake and so on. The utilization of present day advances such as the single-board computers can encourage and give much more functionalities to cloud. The significant areas that cover the above said applications are home, industries, buildings and so forth. This is the way toward observing some of the modules of environment and thus providing the features to the admins and clients. It causes the specialists to screen the states of the work in an organization or industry from remote areas and to take prompt measures.},
  doi       = {10.1109/ICCCNT.2018.8494151},
}

@InProceedings{Munadi2019,
  author    = {Munadi, Rendy and Irawan, Arif Indra and Romiadi, Yuman Fariz},
  booktitle = {2019 International Conference on Mechatronics, Robotics and Systems Engineering (MoRSE)},
  title     = {Security System ATM Machine with One-Time Passcode on M-Banking Application},
  year      = {2019},
  month     = {Dec},
  pages     = {92-96},
  abstract  = {Automated Teller Machine (ATM) security system currently still uses magnetic cards and static PIN as its security system, which create many security holes. This security hole in many cases caused many bank customers to lose money mysteriously. In this paper a two-factor authentication system which uses ATM card and dynamic PIN is proposed to overcome this security hole. In this paper, a prototype of an ATM and m-banking application were built. The ATM prototype uses several components such as the Raspberry Pi 3B, smart card, smart card reader / writer, keypad number and LCD monitor. Dynamic PINs are generated using the CSPRNG-SHA1-MWC random number generator. In developing the prototypes, the framework used in this study is based on mobile applications and cloud computing. To evaluate the quality of the prototype, we performed qualitative and quantitative tests. Qualitatively we tested the prototype using a questionnaire using 165 sample respondents to provide an opinion about the safety and comfort of our prototype and quantitatively we measured the prototype to find out the level of randomness of the generated PIN and the QoS of the designed prototype.},
  doi       = {10.1109/MoRSE48060.2019.8998716},
}

@InProceedings{Rana2019,
  author    = {Rana, Prateek and Sharma, Monika},
  booktitle = {2019 2nd International Conference on Power Energy, Environment and Intelligent Control (PEEIC)},
  title     = {Less Energy Consumption Framework for Fog Computing With IoT},
  year      = {2019},
  month     = {Oct},
  pages     = {41-46},
  abstract  = {IOT applications nowadays have quickly expanded and the basic standard centralized models of cloud computing have faced numerous challenging situations which has excessiveness in latency; have low capacity and the failure of network, less capacity of storing and excessive use of power. Fog computing has brought the cloud nearer to the devices of IOT, which deals with the challenges. The services being provided by the fog have quicker response moreover more better quality, in comparison to the cloud. The choices which are best, allow the IOT to offer services which are efficient and secured for most of the users of IOT, that is being measured by the fog computing. In this paper, we are focusing on the fog computing furthermore the incorporation of fog computing with the IOT by specially focusing on the implementation of the challenges is being presented. We have proposed architecture for the less consumption of energy and power.},
  doi       = {10.1109/PEEIC47157.2019.8976772},
}

@InProceedings{Yang2020a,
  author    = {Yang, Yi},
  booktitle = {2020 International Conference on Advance in Ambient Computing and Intelligence (ICAACI)},
  title     = {Simulation Analysis of Standardized Management Measures of Enterprise Accounting Based on Cloud Computing},
  year      = {2020},
  month     = {Sep.},
  pages     = {143-146},
  abstract  = {In the current corporate governance, accounting management is an indispensable part, in which the quality of accounting directly affects the prosperity of enterprises. Accounting is a basic work in the related work of enterprise accounting, which is the accounting of economic activities of enterprises under the constraints of relevant laws and regulations, and is a summary of previous economic activities. Accounting, as a basic function and the core content of enterprise accounting work, has always been in a very important position. Accounting information feeds back the problems existing in the production and operation of enterprises, so that relevant personnel can continuously optimize their work, and ultimately enhance the competitiveness of products or services provided by enterprises in the market. This paper discusses the connotation and importance of enterprise accounting standardization management, analyzes the problems existing in the process of enterprise accounting standardization management, and puts forward specific measures of enterprise accounting standardization management based on cloud computing.},
  doi       = {10.1109/ICAACI50733.2020.00036},
}

@InProceedings{Li2021c,
  author    = {Li, Xu and Gao, Guanbin and Na, Jing and Chen, Xin},
  booktitle = {2021 33rd Chinese Control and Decision Conference (CCDC)},
  title     = {Design of an Automatic T-beam Erection System Based on NB-IoT for Bridge-Erecting Cranes},
  year      = {2021},
  month     = {May},
  pages     = {684-689},
  abstract  = {Bridge-erecting cranes are often used for beam erection in the construction of expressways. To improve the speed and quality of T-beam erection and ensure the safety of bridge-erecting cranes, an automatic T-beam erection system based on the Internet of Things (IoT) is designed in this paper. Narrow Band Internet of Things (NB-IoT) communication technology is used to integrate laser-ranging sensors, batteries, and communication modules into base station subsystems, which are installed in specific locations of the bridge-erecting crane. The position of the T-beam can be measured in real-time by the laser ranging sensors, with which a closed-loop control system is constructed for the T-beam erection system. The information of the running state including the position of the T-beam, the installation progress, and the position of the bridge-erecting crane is transferred to the cloud computing platform by NB-IoT, which can be viewed by mobile terminals. The experimental tests show that the distance measurement range of the system is 0.045m~30m, and the measurement accuracy is 2mm. Compared with the manual operation, the automatic T-beam erection system can reduce the risk of the T-beam erection and improve efficiency.},
  doi       = {10.1109/CCDC52312.2021.9602504},
  issn      = {1948-9447},
}

@Article{Azizi2021,
  author   = {Azizi, Sadoon and Shojafar, Mohammad and Abawajy, Jemal and Buyya, Rajkumar},
  journal  = {IEEE Systems Journal},
  title    = {GRVMP: A Greedy Randomized Algorithm for Virtual Machine Placement in Cloud Data Centers},
  year     = {2021},
  issn     = {1937-9234},
  month    = {June},
  number   = {2},
  pages    = {2571-2582},
  volume   = {15},
  abstract = {Cloud computing efficiency greatly depends on the efficiency of the virtual machines (VMs) placement strategy used. However, VM placement has remained one of the major challenging issues in cloud computing mainly because of the heterogeneity in both virtual and physical machines (PMs), the multidimensionality of the resources, and the increasing scale of the cloud data centers (CDCs). An inefficiency in VM placement strategy has a significant influence on the quality of service provided, the amount of energy consumed, and the running costs of the CDCs. To address these issues, in this article, we propose a greedy randomized VM placement (GRVMP) algorithm in a large-scale CDC with heterogeneous and multidimensional resources. GRVMP inspires the “power of two choices” model and places VMs on the more power-efficient PMs to jointly optimize CDC energy usage and resource utilization. The performance of GRVMP is evaluated using synthetic and real-world production scenarios (Amazon EC2) with several performance matrices. The results of the experiment confirm that GRVMP jointly optimizes power usage and the overall wastage of resource utilization. The results also show that GRVMP significantly outperforms the baseline schemes in terms of the performance metrics used.},
  doi      = {10.1109/JSYST.2020.3002721},
}

@InProceedings{Na2014,
  author    = {Sang-Ho Na and Eui-Nam Huh},
  booktitle = {Fourth edition of the International Conference on the Innovative Computing Technology (INTECH 2014)},
  title     = {A methodology of assessing security risk of cloud computing in user perspective for security-service-level agreements},
  year      = {2014},
  month     = {Aug},
  pages     = {87-92},
  abstract  = {underlying cloud computing feature, outsourcing of resources, makes the Service Level Agreement (SLA) is a critical factor for Quality of Service (QoS), and many researchers have addressed the question of how a SLA can be evaluated. Lately, security-SLAs have also received much attention with the Security-as-a-Service mode in cloud computing. The quantitative measurement of security metrics is a considerably difficult problem and might be considered the multi-dimensional aspects of security threats and user requirements. To address these issues, we provide a novel a methodology of security risk assessment for security-service-level agreements in the cloud service based on a multi-dimensional approach depending on services type, probabilities of threats, and network environments to reach a security-SLA evaluation.},
  doi       = {10.1109/INTECH.2014.6927759},
}

@InProceedings{Reddy2021,
  author    = {Reddy, Gangireddy Narendra Kumar and Manikandan, M. Sabarimalai and Murty, N. V. L. Narasimha},
  booktitle = {2021 IEEE International Conference on Health, Instrumentation & Measurement, and Natural Sciences (InHeNce)},
  title     = {Lightweight Compressed Sensing (CS) and Partial DCT Based Compression Schemes for Energy-Efficient Wearable PPG Monitoring Devices},
  year      = {2021},
  month     = {July},
  pages     = {1-6},
  abstract  = {Most wearable medical devices are designed to continuously acquire photoplethysmography (PPG) for measuring vital signs and transmitting acquired PPG data wirelessly to edge-computing device or cloud-computing server. These devices are constrained with limited battery power and data-rate capacity. Therefore, in this paper, we present a lightweight effective data-reduction method by investigating the performance of compressed sensing (CS)-based and and partial discrete cosine transform (DCT)-based compression methods with major objectives of achieving higher compression ratio (CR) with minimal waveform distortion with low reconstruction time. By using both normal and abnormal PPG signals, the performance of the CS-based and DCT-based compression methods is evaluated in terms of CR, global and local distortion measures and processing time. Evaluation results showed that CR values of the partial-DCT based method are 3 times higher (CR ranging from 7.50 to 9.38) without distorting fiducial points and shapes of the PPG signal (percentage root-mean-square difference (PRD) ranging from 1% to 2%) as compared to the CS-based data method (CR from 2.50 to 3.13 for PRD from 2% of 4%). The higher data reduction with acceptable level of reconstruction quality demonstrates that the partial DCT-based method can lead to provide better overall energy consumption reduction solution for resource-constrained wearable devices.},
  doi       = {10.1109/InHeNce52833.2021.9537262},
}

@Article{Peng2017,
  author   = {Peng, Kuan-Li and Huang, Chin-Yu},
  journal  = {IEEE Transactions on Services Computing},
  title    = {Reliability Analysis of On-Demand Service-Based Software Systems Considering Failure Dependencies},
  year     = {2017},
  issn     = {1939-1374},
  month    = {May},
  number   = {3},
  pages    = {423-435},
  volume   = {10},
  abstract = {Service-based software systems (SBSSs) are widely deployed due to the growing trend of distributed computing and cloud computing. It is important to ensure high quality of an SBSS, especially in a strongly competitive market. Existing works on SBSS reliability usually assumed independence of service failures. However, the fact that resource sharing exists in different levels of SBSS operations invalidates this assumption. Ignorance of failure dependencies have been discussed as potentially affecting system reliability predictions and lowering the benefits of design diversity, as typically seen in high-reliability systems. In this paper, we propose a reliability framework that incorporates failure dependence modeling, system reliability modeling, as well as reliability analysis for individual services and for failure sources. The framework is also capable of analyzing the internal structures of popular software fault tolerant (FT) schemes. The proposed method is applied to a travel agency system based upon a real-world practice for verifying its accuracy of reliability modeling and effectiveness of varied reliability measures. The results show that failure dependence of the services is an essential factor for analyzing any valuable SBSS system. Further, a set of reliability measures with different capabilities and complexities are available for assisting SBSS engineers with system improvements.},
  doi      = {10.1109/TSC.2015.2473843},
}

@InProceedings{Navamani2018,
  author    = {Navamani, Beaulah A and Yue, Chuan and Zhou, Xiaobo},
  booktitle = {2018 IEEE 37th International Performance Computing and Communications Conference (IPCCC)},
  title     = {Discover and Secure (DaS): An Automated Virtual Machine Security Management Framework},
  year      = {2018},
  month     = {Nov},
  pages     = {1-6},
  abstract  = {Cloud computing is very appealing for its convenient central management, the elasticity of resource provisioning and its economic benefits. Undoubtedly, the non-transparent nature of the Cloud infrastructure introduces significant security concerns. Naively, Virtual Machine (VM) migration can weaken or even nullify the security protection on a VM. Attackers compromise such vulnerable hosts and can either take control over their resources or use them as a channel for future attacks. To overcome the hidden security risk, this paper proposes Discover and Secure (DaS) framework for automated VM security management. This framework accomplishes two qualities: 1) to discover whether the VM is an inadvertent security victim 2) to secure the VM and the mission-critical applications running inside them. Modules in this framework detect, extract and measures the new identifiers assigned to the VM. Comparing the new identifiers to the reference table containing the old measured identifier values, verifies the identifier/s status. Transformed identifiers are perceived and replaced with new valid ones, hence, restoring the nullified security. This framework is implemented as VM-Internal security, self-supplied by the user and VM-introspection security, host-supplied by the cloud provider. Experimental results show that DaS framework can armor the VM from obscured security problems and seal the hidden door against attackers.},
  doi       = {10.1109/PCCC.2018.8711239},
  issn      = {2374-9628},
}

@InProceedings{Shrivastava2021,
  author    = {Shrivastava, Ritu and Tiwary, Abhigyan and Yadav, Pranay},
  booktitle = {2021 International Conference on Advances in Technology, Management & Education (ICATME)},
  title     = {Challenges Block Chain Technology Using IOT for Improving Personal and Physical Safety - Review},
  year      = {2021},
  month     = {Jan},
  pages     = {238-243},
  abstract  = {Web of Things (IoT) is an interconnection of clever actual articles called things and People. IoT permits each “Thing” to associate and impart in this manner creating and sending a colossal measure of Data like a monster Information System. Because of the immense measure of Data dealing with by IoT gadgets it got fundamental to incorporate Cloud Computing, Machine Learning and Information Modelling into The IoT stage. The enormous development in the field of IoT is causing increment in Information and Communication Technology (ICT) business too. It is anticipated that before the finish of 2020 95% of the new items will have IoT as its canter. As can be seen there will be an expanding presence of IoT objects and thus their perceivability from the Internet and lawful admittance to assets is a subject of grave concern. IoT gives and empowers the formation of creative applications that improved the physical and individual existence of an individual, yet the absence of security and weakness of individuals may prompt basic issues like the wellbeing of our homes might be undermined, and Centralized organizations utilizing delicate information are consistently at a danger hacking. Block-chain innovation is increasing a ton of consideration from different associations and parcel of examination is being done as it gives extraordinary answers for the issues related with the traditional incorporated design of IoT. Since, there are so numerous IoT gadgets which are on the lookout for the upgrade of an individual's physical, mental development and improving the personal satisfaction by and large, a conveyed trust innovation, guaranteeing versatility, security, and unwavering quality, is the need of great importance for the development of IoT conditions. The joining of IoT and BC represents a ton of difficulties. The Objective of this exploration paper is to build up an incorporated IOT and Block-chain Application Environment to upgrade the individual and Physical existence of a being. Consequently, our center will be to build up a safe and safe climate for a Smart home. Our proposed design depends on progressive structure and disseminated foundation of Block-chain to keep up security and protection and make it appropriate for explicit prerequisites of IoT. Subsequently we have coordinated the mechanization of the home alongside the actual soundness of an individual in this manner guaranteeing wellbeing, accommodation and strength of an individual.},
  doi       = {10.1109/ICATME50232.2021.9732730},
}

@Article{AbdelBasset2021,
  author   = {Abdel-Basset, Mohamed and El-Shahat, Doaa and Elhoseny, Mohamed and Song, Houbing},
  journal  = {IEEE Internet of Things Journal},
  title    = {Energy-Aware Metaheuristic Algorithm for Industrial-Internet-of-Things Task Scheduling Problems in Fog Computing Applications},
  year     = {2021},
  issn     = {2327-4662},
  month    = {Aug},
  number   = {16},
  pages    = {12638-12649},
  volume   = {8},
  abstract = {In Industrial-Internet-of-Things (IIoT) applications, fog computing (FC) has soared as a means to improve the Quality of Services (QoSs) provided to users through cloud computing, which has become overwhelmed by the massive flow of data. Transmitting all these amounts of data to the cloud and coming back with a response can cause high latency and requires high network bandwidth. The availability of sustainable energy sources for FC servers is one of the difficulties that the service providers can face in IIoT applications. The most important factor contributing to energy consumption on fog servers is task scheduling. In this article, we suggest an energy-aware metaheuristic algorithm based on a Harris Hawks optimization algorithm based on a local search strategy (HHOLS) for task scheduling in FC (TSFC) to improve the QoSs provided to the users in IIoT applications. First, we describe the high virtualized layered FC model taking into account its heterogeneous architecture. The normalization and scaling phase aids the standard Harris hawks algorithm to solve the TSFC, which is discrete. Moreover, the swap mutation ameliorates the quality of the solutions due to its ability to balance the workloads among all virtual machines. For further improvements, a local search strategy is integrated with HHOLS. We compare HHOLS with other metaheuristics using various performance metrics, such as energy consumption, makespan, cost, flow time, and emission rate of carbon dioxide. The proposed algorithm gives superior results in comparison with other algorithms.},
  doi      = {10.1109/JIOT.2020.3012617},
}

@InProceedings{Albur2020,
  author    = {Albur, Nageshwar and Handigol, Sonal and Naik, Sonali and Mulla, Mohammed Moin and Narayan, D. G.},
  booktitle = {2020 12th International Conference on Computational Intelligence and Communication Networks (CICN)},
  title     = {QoS-aware Flow Management in Software Defined Network},
  year      = {2020},
  month     = {Sep.},
  pages     = {215-220},
  abstract  = {Software Defined Networking is a developing pattern in a computer network that authorize a controller to control and keep track of the entire network state of a system. Traditional networks are not compatible for business ventures since they are manually configured (static) and are inflexible. To solve the problems related to traditional network framework, SDN is considered as an effective solution because SDN is dynamic and easily manageable. Quality-of-Service (QoS) is a list of network requirements that is mentioned in Service Level Agreement (SLA) and this requirements has to be satisfied when a packet is being streamed from one node to another node in a network. QoS metrics provide a sophisticated way to prioritise the network traffic over a network to guarantee better performance. QoS assures that the priorities of routing does not change because change-in prioritise may lead to jitter, packet loss and delay. With rapid development in the cloud computing environment for hosting various virtual applications, Quality Of Service (QoS) has to be maintained while delivering the services that were specified in the Software Level Agreement (SLA). Network Traffic Management helps the administrator to reduce the congestion, packet loss, latency, and also ensures smooth network operations with the help of traffic monitoring tools and techniques. The proposed work presents the QoS aware routing using the OpenDayLight controller. To implement the routing algorithm the bandwidth and the delay parameters are considered. These help to manage the resources of the network by prioritizing specific types of packets on the network. Packet switching not only forwards the data packets but also focuses on selecting the optimal path available for routing of these packets based on certain parameters.},
  doi       = {10.1109/CICN49253.2020.9242580},
  issn      = {2472-7555},
}

@InProceedings{ODonncha2016,
  author    = {O'Donncha, Fearghal and Venugopal, Srikumar and James, Scott C. and Ragnoli, Emanuele},
  booktitle = {OCEANS 2016 MTS/IEEE Monterey},
  title     = {Deploying and optimizing performance of a 3D hydrodynamic model on cloud},
  year      = {2016},
  month     = {Sep.},
  pages     = {1-7},
  abstract  = {Container-based cloud computing, as standardised and popularised by the open-source docker project has many potential opportunities for scientific application in highperformance computing. It promises highly flexible and available compute capabilities via cloud, without the resource overheads of traditional virtual machines. Further, productivity gains can be made by easy repackaging of images with additional developments, automated deployments, and version-control integrations. Nevertheless, the impact of container overhead and overlay network implementation and performance are areas that requires detailed study to allow for well-defined quality of service for typical HPC applications. This papers presents details on deploying the Environmental Fluid Dynamics Code (EFDC) on a container-based cloud environment. Results are compared to a bare metal deployment. Application-specific benchmarking tests are complemented by detailed network tests that evaluate isolated MPI communication protocols both at intra-node and inter-node level with varying degrees of self-contention. Cloud-based simulations report significant performance loss in mean run-times. A containerised environment increases simulation time by up to 50%. More detailed analysis demonstrates that much of this performance penalty is a result of large variance in MPI communciation times. This manifests as simulation runtime variance on container cloud that hinders both simulation run-time and collection of well-defined quality-of-service metrics.},
  doi       = {10.1109/OCEANS.2016.7761131},
}

@InProceedings{Silva2018a,
  author    = {Silva, Helber and Barbalho, Felipe and Neto, Augusto},
  booktitle = {2018 International Conference on Computing, Networking and Communications (ICNC)},
  title     = {Cross-layer Multiuser Session Control for Improved SDN Cloud Communications},
  year      = {2018},
  month     = {March},
  pages     = {377-382},
  abstract  = {The integration of Cloud Computing and Internet of Things (IoT) is foreseen as an enabler to suit a plethora of novel latency critical applications (e.g, e-health, intelligent transportation, safety, energy, smart cities, and many others). These applications require multimedia (mainly video) flows to be handled by the underlying network in an efficient and scalable way, as they expect to consume a massive data produced by billions of things. In view of this, we propose a dynamic multiuser session control plane which leverages 5G's support of Software-Defined Networking (SDN) substrate to advance beyond todays limited, per-flow IP-based communication systems. We handle such limitations by proposing CLASSICO, a Cross-LAyer Sdn SessIon COntrol architecture that exploits SDN to offload the flow streaming computation operations from the IoT cloud platform to the network edge, affording high timeliness and scalability for the IoT-cloudified system. CLASSICO dynamically builds Application Layer multiuser data sessions and maps them into enhanced group-enabled data paths featuring SDN replication at branching nodes. We applied our solution to multimedia-alike use case, and results show that CLASSICO outperforms typical SDN-enabled IoT systems in terms to Quality of Service (QoS) and Quality of Experience (QoE) video metrics.},
  doi       = {10.1109/ICCNC.2018.8390400},
}

@InProceedings{Estrela2021,
  author    = {Estrela, Vania V. and Andreopoulos, Nikolaos and Sroufer, Robert and de Jesus, Maria A. and Mamani, Wilma Dora Huacasi and Peixoto, Aruquia},
  booktitle = {2021 IEEE Global Engineering Education Conference (EDUCON)},
  title     = {Transmedia Ecosystems, Quality of Experience and Quality of Service in Fog Computing for Comfortable Learning},
  year      = {2021},
  month     = {April},
  pages     = {1003-1009},
  abstract  = {This paper looks at the concepts of Quality of Service (QoS) and Quality of Experience (QoE) for the valuation of Transmedia Ecosystems (TEs) services in fog networking. Fog computing (FC) has delivered new services that cloud computing (CC) cannot make available, particularly those calling for QoE warranties. The suggested model is advantageous in an FC that comprises cloud-like services to sustain users with low latency response necessities. This TE model for QoE/QoS relies on objective and subjective QoE metrics. These assessment mechanisms will capture evidence automatically employing agent technology with user feedback. This proposed structure observes, investigates, yields reports and policy alterations without administrators' intervention.},
  doi       = {10.1109/EDUCON46332.2021.9454002},
  issn      = {2165-9567},
}

@InProceedings{Younis2021,
  author    = {Younis, Ayman and Qiu, Brian and Pompili, Dario},
  booktitle = {2021 16th Annual Conference on Wireless On-demand Network Systems and Services Conference (WONS)},
  title     = {QLRan: Latency-Quality Tradeoffs and Task Offloading in Multi-node Next Generation RANs},
  year      = {2021},
  month     = {March},
  pages     = {1-8},
  abstract  = {Next-Generation Radio Access Network (NG-RAN) is an emerging paradigm that provides flexible distribution of cloud computing and radio capabilities at the edge of the wireless Radio Access Points (RAPs). Computation at the edge bridges the gap for roaming end users, enabling access to rich services and applications. In this paper, we propose a multi-edge node task offloading system, i.e., QLRan, a novel optimization solution for latency and quality tradeoff task allocation in NG-RANs. Considering constraints on service latency, quality loss, and edge capacity, the problem of joint task offloading, latency, and Quality Loss of Result (QLR) is formulated in order to minimize the User Equipment (UEs) task offloading utility, which is measured by a weighted sum of reductions in task completion time and QLR cost. The QLRan optimization problem is proved as a Mixed Integer Nonlinear Program (MINLP) problem, which is a NP-hard problem. To efficiently solve the QLRan optimization problem, we utilize Linear Programming (LP)-based approach that can be later solved by using convex optimization techniques. Additionally, a programmable NG-RAN testbed is presented where the Central Unit (CU), Distributed Unit (DU), and UE are virtualized using the OpenAirInterface (OAI) software platform to characterize the performance in terms of data input, memory usage, and average processing time with respect to QLR levels. Simulation results show that our algorithm performs significantly improves the network latency over different conflgurations.},
  doi       = {10.23919/WONS51326.2021.9415574},
}

@InProceedings{Stofova2018,
  author    = {Štofová, Lenka and Szaryszova, Petra and Bosák, Martin and Tarča, Alexander and Hajduová, Zuzana},
  booktitle = {2018 XIV International Scientific-Technical Conference on Actual Problems of Electronics Instrument Engineering (APEIE)},
  title     = {Ambient Intelligence for Increasing Innovation Performance of Enterprises},
  year      = {2018},
  month     = {Oct},
  pages     = {452-458},
  abstract  = {The new development of the changing global environment brings to the attention of ideas in the form of trends that show the future environment very differently from the current state. Technical experts are discussing the growing presence of internet of things and technologies, the involvement of all devices, and the prediction of how to create ambient intelligence. This type of intelligence refers to an electronic environment that is sensitive and responsive to the presence of users. Within these ambient systems, we can identify what the user needs and at the same time obtain it without asking for it. Ambient intelligence is a combination of neural networking, smart technologies, cloud computing, big data, websites, bearers, and user interface to services that can automate processes and make recommendations to improve the quality of users' lives. On a wider scale, there are modern high-tech possibilities to closely monitor the impact on the quality and safety of the current market environment by ambient intelligence and sensory management solutions. The aim of the paper is to highlight the selected trends of ambient intelligence system applications as an innovative paradigm to support smart innovation that will further enhance the quality of the automotive industry's technological solution in Slovak republic with advancing developments inspired by other successful companies' results acting in this sector. The reliability of their most important measures were obtained by correlation analysis and multiple linear regression.},
  doi       = {10.1109/APEIE.2018.8545546},
  issn      = {2473-8573},
}

@InProceedings{Heidari2015,
  author    = {Heidari, Parisa and Boucheneb, Hanifa and Shami, Abdallah},
  booktitle = {2015 IEEE 7th International Conference on Cloud Computing Technology and Science (CloudCom)},
  title     = {A Formal Approach for QoS Assurance in the Cloud},
  year      = {2015},
  month     = {Nov},
  pages     = {629-634},
  abstract  = {Cloud computing is an attractive business model offering cost-efficiency and business agility. Recently, the trend is that small and large businesses are moving their services to cloud environments. The quality of service is always negotiated between the cloud users and the cloud providers and documented in the service level agreement (SLA). Yet assuring -- or even measuring -- the quality of the provided service can be challenging. This paper proposes a formal approach for quantifying the quality of service in the cloud systems as promised in the SLA. The proposed approach uses controller synthesis to find a system configuration that meets the SLA requirement. The formal approach suggested in this paper is based on, but not limited to, %the controller synthesis of Time Petri Nets (TPN). As a case study, we focus on service availability as a key performance indicator in the SLA and for a sample set of resources providing a service, we determine the system configuration satisfying the SLA.},
  doi       = {10.1109/CloudCom.2015.36},
}

@Article{Mei2017,
  author   = {Mei, Jing and Li, Kenli and Li, Keqin},
  journal  = {IEEE Transactions on Sustainable Computing},
  title    = {Customer-Satisfaction-Aware Optimal Multiserver Configuration for Profit Maximization in Cloud Computing},
  year     = {2017},
  issn     = {2377-3782},
  month    = {Jan},
  number   = {1},
  pages    = {17-29},
  volume   = {2},
  abstract = {Along with the development of cloud computing, an increasing number of enterprises start to adopt cloud service, which promotes the emergence of many cloud service providers. For cloud service providers, how to configure their cloud service platforms to obtain the maximum profit becomes increasingly the focus that they pay attention to. In this paper, we take customer satisfaction into consideration to address this problem. Customer satisfaction affects the profit of cloud service providers in two ways. On one hand, the cloud configuration affects the quality of service which is an important factor affecting customer satisfaction. On the other hand, the customer satisfaction affects the request arrival rate of a cloud service provider. However, few existing works take customer satisfaction into consideration in solving profit maximization problem, or the existing works considering customer satisfaction do not give a proper formalized definition for it. Hence, we first refer to the definition of customer satisfaction in economics and develop a formula for measuring customer satisfaction in cloud computing. And then, an analysis is given in detail on how the customer satisfaction affects the profit. Lastly, taking into consideration customer satisfaction, service-level agreement, renting price, energy consumption, and so forth, a profit maximization problem is formulated and solved to get the optimal configuration such that the profit is maximized.},
  doi      = {10.1109/TSUSC.2017.2667706},
}

@Article{ElKassabi2018,
  author   = {El Kassabi, Hadeel T. and Serhani, Mohamed Adel and Dssouli, Rachida and Benatallah, Boualem},
  journal  = {IEEE Access},
  title    = {A Multi-Dimensional Trust Model for Processing Big Data Over Competing Clouds},
  year     = {2018},
  issn     = {2169-3536},
  pages    = {39989-40007},
  volume   = {6},
  abstract = {Cloud computing has emerged as a powerful paradigm for delivering data-intensive services over the Internet. Cloud computing has enabled the implementation and success of big data, a recent phenomenon handling huge data being generated from different sources. Competing clouds have made it challenging to select a cloud provider that guarantees quality of cloud service (QoCS). Also, cloud providers' claims of guaranteeing QoCS are exaggerated for marketing purposes; hence, they cannot often be trusted. Therefore, a comprehensive trust model is necessary to evaluate the QoCS prior to making any selection decision. In this paper, we propose a multi-dimensional trust model for big data workflow processing over different clouds. It evaluates the trustworthiness of cloud providers based on: the most up-to-date cloud resource capabilities, the reputation evidence measured by neighboring users, and a recorded personal history of experiences with the cloud provider. The ultimate goal is to ensure an efficient selection of trustworthiness cloud provider who eventually will guarantee high QoCS and fulfills key big data workflow requirements. Various experiments were conducted to validate our proposed model. The results show that our model captures the different components of trust, ensures high QoCS, and effectively adapts to the dynamic nature of the cloud.},
  doi      = {10.1109/ACCESS.2018.2856623},
}

@InProceedings{Bruschi2016,
  author    = {Bruschi, Gustavo C. and Spolon, Roberta and Pauro, Leandro L. and Lobato, Renata S. and Manacero, Aleardo and Cavenaghi, Marcos A.},
  booktitle = {2016 15th International Symposium on Parallel and Distributed Computing (ISPDC)},
  title     = {StackAct: Performance Evaluation in an IaaS Cloud Multilayer},
  year      = {2016},
  month     = {July},
  pages     = {149-156},
  abstract  = {Cloud Computing has become synonymous of quality, efficiency, and return of investment in Information Technology, creating new challenges for processing and data integrations. This paper presents the StackAct, a mechanism that allows performing monitoring and obtaining data on the consumption of computing resources of a solution in three layers using orchestrator IaaS Apache CloudStack, XenServer hypervisor and data storage on the NAS OpenFiler system. Performance tests were conducted using three different instances profile in a private cloud computing, allowing measuring CPU consumption, I/O disk and memory in three layers with different service offerings. The tests resulted in a comparison between the layers, it is possible to note the high consumption of disk in the data storage layer, in particular I/O data recording and the high memory consumption on the hypervisor layer, which is justified by the hypervisor itself to allocation of VMs being created and used in the process.},
  doi       = {10.1109/ISPDC.2016.27},
}

@InProceedings{Toka2021a,
  author    = {Toka, Laszlo and Dobreff, Gergely and Haja, David and Szalay, Mark},
  booktitle = {2021 IFIP/IEEE International Symposium on Integrated Network Management (IM)},
  title     = {Predicting cloud-native application failures based on monitoring data of cloud infrastructure},
  year      = {2021},
  month     = {May},
  pages     = {842-847},
  abstract  = {The quality of service provided by cloud-deployed online applications is often affected by faults in the underlying cloud platform and infrastructure. In order to discover the cause and effect at application failures, a cloud monitoring system must be in place. The sheer amount of the produced monitoring data calls for smart and automatic handling in order to find the patterns that can be used for fault management. In this paper we present an open source, cloud-native, lightweight cloud monitoring system, and a data analytics pipeline that efficiently processes the gathered data and is able to discover useful inference between infrastructure-, and application-level metrics. We apply time series clustering steps within the pipeline to compress the collected data for fast and lightweight data mining. We show the capabilities of our proposed system in a reactive and a proactive use case. The results prove that the proposed system brings precious insights for root-cause analysis and proactive fault management frameworks of cloud applications.},
  issn      = {1573-0077},
}

@InProceedings{Mushtaq2016,
  author    = {Mushtaq, M. Sajid and Fowler, Scott and Augustin, Brice and Mellouk, Abdelhamid},
  booktitle = {2016 IEEE Wireless Communications and Networking Conference},
  title     = {QoE in 5G cloud networks using multimedia services},
  year      = {2016},
  month     = {April},
  pages     = {1-6},
  abstract  = {The 4G standard Long Term Evolution-Advanced (LTE-A) has been deployed in many countries. Now, technology is evolving towards the 5G standard since it is expecting to start its service in 2020. The 5G cellular networks will mainly contain in cloud computing and primarily Quality of Service (QoS) parameters (e.g. delay, loss rate, etc.) influence the cloud network performance. The impact of user perceived Quality of Experience (QoE) using multimedia services, and application significantly relies on the QoS parameters. The key challenge of 5G technology is to reduce the delay less than one millisecond. In this paper, we have described a method that minimizes the overall network delay for multimedia services; which are constant bit rate (VoIP) and variable bit rate (video) traffic model. We also proposed a method that measures the user's QoE for video streaming traffic using the network QoS parameters, i.e. delay and packet loss rate. The performance of proposed QoE method is compared with QoV method, and our proposed QoE method performs best by carefully handle the impact of QoS parameters. The results show that our described method successfully reduces the overall network delays, which result to maximize the user's QoE.},
  doi       = {10.1109/WCNC.2016.7565173},
  issn      = {1558-2612},
}

@Article{Vatalaro2020,
  author   = {Vatalaro, Francesco and Ciccarella, Gianfranco},
  journal  = {IEEE Access},
  title    = {A Network Paradigm for Very High Capacity Mobile and Fixed Telecommunications Ecosystem Sustainable Evolution},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {135075-135090},
  volume   = {8},
  abstract = {The main objective for Very High Capacity (VHC) fixed and mobile networks is improving end-user Quality of Experience (QoE), i.e., meeting the Key Performance Indicators (KPIs) - throughput, download time, round trip time, and video delay - required by the applications. KPIs depend on the end-to-end connection between the server and the end-user device. Not only Telco operators must provide the quality needed for the different applications, but also they must address economic sustainability objectives for VHC networks. Today, both goals are often not met, mainly due to the push to increase the access networks bitrate without considering the end-to-end applications KPIs. This paper's main contribution deals with the definition of a VHC network deployment framework able to address performance and cost issues. We show that three are the interventions on which it is necessary to focus: i) the reduction of bit-rate through video compression, ii) the reduction of packet loss rate through artificial intelligence algorithms for access lines stabilization, and iii) the reduction of latency (i.e., the round-trip time) with edge-cloud computing and content delivery platforms, including transparent caching. The concerted and properly phased action of these three measures can allow a Telco to get out of the Ultra Broad Band access network “trap”as defined in the paper. We propose to work on the end-to-end optimization of the bandwidth utilization ratio (i.e., the ratio between the throughput and the bit-rate that any application can use). It leads to better performance experienced by the end-user, enables new business models and revenue streams, and provides a sustainable cost for the Telco operators. To make such a perspective more precise, the case of MoVAR (Mobile Virtual and Augmented Reality), one of the most challenging future services, is finally described.},
  doi      = {10.1109/ACCESS.2020.3010348},
}

@InProceedings{Brunschwiler2019,
  author    = {Brunschwiler, T. and Weiss, J. and Paredes, S. and Sridhar, A. and Pluntke, U. and Chau, S. Mai and Gerke, S. and Barroso, J. and Loertscher, E. and Temiz, Y. and Ruch, P. and Michel, B. and Zafar, S. and van Kessel, T.},
  booktitle = {2019 Global IoT Summit (GIoTS)},
  title     = {Internet of the Body - Wearable Monitoring and Coaching},
  year      = {2019},
  month     = {June},
  pages     = {1-6},
  abstract  = {Wearables that acquire relevant vital and contextual parameters improve work safety as well as quality of life of elderly citizens or patients with chronic diseases. A scalable architecture connects wearables via a hub to the cloud and combines edge with cloud computing to provide optimal user interaction and allow analytics on multi-stream data. The functionality was expanded to enable demonstrations of physiological and psychological stress classification in firemen and mobile health interventions in patients with lung diseases. Following an initial table-top edge demonstrator a hemi-spherical display improves emotional contact to users. A first use case tested an integrated acquisition and inference system that was trained to differentiate physical and emotional stress. The system measured stress in firemen during training in a cage maze and in hot training locations and provided functions to acquire expert labels. A second use case focused on mobile-health intervention for patients suffering from Chronic-Obstructive-Pulmonary-Disease (COPD), to improve their quality-of-life. Patient-physician conversations are extended through a communication channel and a virtual assistant provides disease related information, reminders, and alerts.},
  doi       = {10.1109/GIOTS.2019.8766409},
}

@InProceedings{Shen2014,
  author    = {Hong Shen and Jinglei Meng and Licheng Yu and Xuefeng Fang and Tianzhou Chen and Hui Yan and Honglun Hou},
  booktitle = {2014 IEEE 3rd International Conference on Cloud Computing and Intelligence Systems},
  title     = {A quantitative quality control method of big data in cancer patients using artificial neural network},
  year      = {2014},
  month     = {Nov},
  pages     = {499-504},
  abstract  = {Nonstandard treatments for cancer patients are commonly seen in hospitals of developing countries like China. So it is crucial to standardize the treatments for cancer with technological means in order to supervise the process of treatments. Widespread of electronic health records (EHRs) has generated massive data sets which are far beyond the capability of traditional computing model. Although there are process and measures about quality control, but automatic computerized Quantitative Control (QC) and quantization methods are still lack. In this paper, we propose a quantitative quality control method of radiotherapy and chemotherapy based on artificial neural network to automatically analysis and rate the compliance with standard treatment process. The quantitative QC items are established and the artificial neural network is constructed accordingly. Then the selected cases are evaluated by experts for corresponding QC grades to train the artificial neural network. After that, the trained artificial neural network can be used to grade new cases for their QC score. To meet the high requirement of computation and accommodate massive data sets, we adopt our proposal in the cloud. With massive data distributed on computing nodes in the cloud, computing capability of nodes are dynamically allocated to homogenization and ANN computing, each node work both homogenization medical records and ANN computing according to system load balance resulting the quantitative QC process perform in high parallelism.},
  doi       = {10.1109/CCIS.2014.7175787},
  issn      = {2376-595X},
}

@Article{Bruneo2014,
  author   = {Bruneo, Dario},
  journal  = {IEEE Transactions on Parallel and Distributed Systems},
  title    = {A Stochastic Model to Investigate Data Center Performance and QoS in IaaS Cloud Computing Systems},
  year     = {2014},
  issn     = {1558-2183},
  month    = {March},
  number   = {3},
  pages    = {560-569},
  volume   = {25},
  abstract = {Cloud data center management is a key problem due to the numerous and heterogeneous strategies that can be applied, ranging from the VM placement to the federation with other clouds. Performance evaluation of cloud computing infrastructures is required to predict and quantify the cost-benefit of a strategy portfolio and the corresponding quality of service (QoS) experienced by users. Such analyses are not feasible by simulation or on-the-field experimentation, due to the great number of parameters that have to be investigated. In this paper, we present an analytical model, based on stochastic reward nets (SRNs), that is both scalable to model systems composed of thousands of resources and flexible to represent different policies and cloud-specific strategies. Several performance metrics are defined and evaluated to analyze the behavior of a cloud data center: utilization, availability, waiting time, and responsiveness. A resiliency analysis is also provided to take into account load bursts. Finally, a general approach is presented that, starting from the concept of system capacity, can help system managers to opportunely set the data center parameters under different working conditions.},
  doi      = {10.1109/TPDS.2013.67},
}

@Article{Neghabi2018,
  author   = {Neghabi, Ali Akbar and Jafari Navimipour, Nima and Hosseinzadeh, Mehdi and Rezaee, Ali},
  journal  = {IEEE Access},
  title    = {Load Balancing Mechanisms in the Software Defined Networks: A Systematic and Comprehensive Review of the Literature},
  year     = {2018},
  issn     = {2169-3536},
  pages    = {14159-14178},
  volume   = {6},
  abstract = {With the expansion of the network and increasing their users, as well as emerging new technologies, such as cloud computing and big data, managing traditional networks is difficult. Therefore, it is necessary to change the traditional network architecture. Lately, to address this issue, a notion named software-defined network (SDN) has been proposed, which makes network management more conformable. Due to limited network resources and to meet the requirements of quality of service, one of the points that must be considered is load balancing issue that serves to distribute data traffic among multiple resources in order to maximize the efficiency and reliability of network resources. Load balancing is established based on the local information of the network in the conventional network. Hence, it is not very precise. However, SDN controllers have a global view of the network and can produce more optimized load balances. Although load balancing mechanisms are important in the SDN, to the best of our knowledge, there exists no precise and systematic review or survey on investigating these issues. Hence, this paper reviews the load balancing mechanisms which have been used in the SDN systematically based on two categories, deterministic and non-deterministic. Also, this paper represents benefits and some weakness regarded of the selected load balancing algorithms and investigates the metrics of their algorithms. In addition, the important challenges of these algorithms have been reviewed, so better load balancing techniques can be applied by the researchers in the future.},
  doi      = {10.1109/ACCESS.2018.2805842},
}

@InProceedings{AlDhuraibi2017,
  author    = {Al-Dhuraibi, Yahya and Paraiso, Fawaz and Djarallah, Nabil and Merle, Philippe},
  booktitle = {2017 IEEE 10th International Conference on Cloud Computing (CLOUD)},
  title     = {Autonomic Vertical Elasticity of Docker Containers with ELASTICDOCKER},
  year      = {2017},
  month     = {June},
  pages     = {472-479},
  abstract  = {Elasticity is the key feature of cloud computing to scale computing resources according to application workloads timely. In the literature as well as in industrial products, much attention was given to the elasticity of virtual machines, but much less to the elasticity of containers. However, containers are the new trend for packaging and deploying microservices-based applications. Moreover, most of approaches focus on horizontal elasticity, fewer works address vertical elasticity. In this paper, we propose ELASTICDOCKER, the first system powering vertical elasticity of Docker containers autonomously. Based on the well-known IBM's autonomic computing MAPE-K principles, ELASTICDOCKER scales up and down both CPU and memory assigned to each container according to the application workload. As vertical elasticity is limited to the host machine capacity, ELASTICDOCKER does container live migration when there is no enough resources on the hosting machine. Our experiments show that ELASTICDOCKER helps to reduce expenses for container customers, make better resource utilization for container providers, and improve Quality of Experience for application end-users. In addition, based on the observed migration performance metrics, the experiments reveal a high efficient live migration technique. As compared to horizontal elasticity, ELASTICDOCKER outperforms Kubernetes elasticity by 37.63%.},
  doi       = {10.1109/CLOUD.2017.67},
  issn      = {2159-6190},
}

@Article{Xia2015a,
  author   = {Xia, YunNi and Zhou, MengChu and Luo, Xin and Pang, ShanChen and Zhu, QingSheng},
  journal  = {IEEE Transactions on Industrial Informatics},
  title    = {Stochastic Modeling and Performance Analysis of Migration-Enabled and Error-Prone Clouds},
  year     = {2015},
  issn     = {1941-0050},
  month    = {April},
  number   = {2},
  pages    = {495-504},
  volume   = {11},
  abstract = {Cloud computing is a promising paradigm capable of rationalizing the use of computational resources by means of outsourcing and virtualization. Virtualization allows to instantiate virtual machines (VMs) on top of fewer physical systems managed by a VM manager. Performance evaluation of clouds is required to evaluate and quantify the cost-benefit of a strategy portfolio and the quality of service (QoS) experienced by end-users. Such evaluation is not feasible by means of simulation or on-the-field measurement, due to the great scale of parameter spaces that have to be traversed. In this study, we present a stochastic-queuing-network-based approach to performance analysis of migration-enabled clouds in error-prone environment. Several performance metrics are defined and evaluated: utilization, expected task completion time, and task rejection rate under different load conditions and error intensities. To validate the proposed approach, we obtain experimental performance data through a real-world cloud and conduct a confidence-interval analysis. The analysis results suggest the perfect coverage of theoretical performance results by corresponding experimental confidence intervals.},
  doi      = {10.1109/TII.2015.2405792},
}

@Article{Farid2020,
  author   = {Farid, Mazen and Latip, Rohaya and Hussin, Masnida and Abdul Hamid, Nor Asilah Wati},
  journal  = {IEEE Access},
  title    = {Scheduling Scientific Workflow Using Multi-Objective Algorithm With Fuzzy Resource Utilization in Multi-Cloud Environment},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {24309-24322},
  volume   = {8},
  abstract = {The provision of resources and services for scientific workflow applications using a multi-cloud architecture and a pay-per-use rule has recently gained popularity within the cloud computing research domain. This is because workflow applications are computation intensive. Most of the existing studies on workflow scheduling in the cloud mainly focus on finding an ideal makespan or cost. Nevertheless, there are other important quality of service metrics that are of critical concern in workflow scheduling such as reliability and resource utilization. In this respect, this paper proposes a new multi-objective scheduling algorithm with Fuzzy resource utilization (FR-MOS) for scheduling scientific workflow based on particle swarm optimization (PSO) method. The algorithm minimizes cost and makespan while considering reliability constraint. The coding scheme jointly considers task execution location and data transportation order. Simulation experiments reveal that FR-MOS outperforms the basic MOS over the PSO algorithm.},
  doi      = {10.1109/ACCESS.2020.2970475},
}

@Article{Nesmachnow2015,
  author   = {Nesmachnow, Sergio and Iturriaga, Santiago and Dorronsoro, Bernabe},
  journal  = {IEEE Computational Intelligence Magazine},
  title    = {Efficient Heuristics for Profit Optimization of Virtual Cloud Brokers},
  year     = {2015},
  issn     = {1556-6048},
  month    = {Feb},
  number   = {1},
  pages    = {33-43},
  volume   = {10},
  abstract = {This article introduces a new kind of broker for cloud computing, whose business relies on outsourcing virtual machines (VMs) to its customers. More specifically, the broker owns a number of reserved instances of different VMs from several cloud providers and offers them to its customers in an on-demand basis, at cheaper prices than those of the cloud providers. The essence of the business resides in the large difference in price between on-demand and reserved VMs. We define the Virtual Machine Planning Problem, an optimization problem to maximize the profit of the broker. We also propose a number of efficient smart heuristics (seven two-phase list scheduling heuristics and a reordering local search) to allocate a set of VM requests from customers into the available pre-booked ones, that maximize the broker earnings. We perform experimental evaluation to analyze the profit and quality of service metrics for the resulting planning, including a set of 400 problem instances that account for realistic workloads and scenarios using real data from cloud providers.},
  doi      = {10.1109/MCI.2014.2369893},
}

@Article{Ayoubi2015,
  author   = {Ayoubi, Sara and Assi, Chadi and Shaban, Khaled and Narayanan, Lata},
  journal  = {IEEE Transactions on Communications},
  title    = {MINTED: Multicast VIrtual NeTwork Embedding in Cloud Data Centers With Delay Constraints},
  year     = {2015},
  issn     = {1558-0857},
  month    = {April},
  number   = {4},
  pages    = {1291-1305},
  volume   = {63},
  abstract = {Network virtualization is regarded as the pillar of cloud computing, enabling the multi-tenancy concept where multiple Virtual Networks (VNs) can cohabit the same substrate network. With network virtualization, the problem of allocating resources to the various tenants, commonly known as the Virtual Network Embedding problem, emerges as a challenge. Its NP-Hard nature has drawn a lot of attention from the research community, many of which however overlooked the type of communication that a given VN may exhibit, assuming that they all exhibit a one-to-one (unicast) communication only. In this paper, we motivate the importance of characterizing the mode of communication in VN requests, and we focus our attention on the problem of embedding VNs with a one-to-many (multicast) communication mode. Throughout this paper, we highlight the unique properties of multicast VNs and its distinct Quality of Service (QoS) requirements, most notably the end-delay and delay-variation constraints for delay-sensitive multicast services. Further, we showcase the limitations of handling a multicast VN as unicast. To this extent, we formally define the VNE problem for Multicast VNs (MVNs) and prove its NP-Hard nature. We propose two novel approach to solve the Multicast VNE (MVNE) problem with end-delay and delay variation constraints: A 3-Step MVNE technique, and a Tabu-Search algorithm. We motivate the intuition behind our proposed embedding techniques, and provide a competitive analysis of our suggested approaches over multiple metrics and against other embedding heuristics.},
  doi      = {10.1109/TCOMM.2015.2404440},
}

@InProceedings{Cao2014,
  author    = {Cao, Fei and Zhu, Michelle M. and Wu, Chase Q.},
  booktitle = {2014 IEEE World Congress on Services},
  title     = {Energy-Efficient Resource Management for Scientific Workflows in Clouds},
  year      = {2014},
  month     = {June},
  pages     = {402-409},
  abstract  = {The elastic resource provision, non-interfering resource sharing and flexible customized configuration provided by the Cloud infrastructure has shed light on efficient execution of many scientific applications. Due to the increasing deployment of data centers and computer servers around the globe escalated by the higher electricity price, the energy cost on running the computing, communication and cooling together with the amount of CO2 emissions have skyrocketed. In order to maintain sustainable Cloud computing facing with ever-increasing problem complexity and big data size in the next decades, we design and develop energy-aware scientific workflow scheduling algorithm to minimize energy consumption and CO2 emission while still satisfying certain Quality of Service (QoS) such as response time specified in Service Level Agreement (SLA). We also apply Dynamic Voltage and Frequency Scaling (DVFS) and DNS scheme to further reduce energy consumption within acceptable performance bounds. Our multiple-step resource provision and allocation algorithm achieves the response time requirement in the step of forwarding task scheduling and minimizes the VM overhead for reduced energy consumption and higher resource utilization rate in the backward task scheduling step. The effectiveness of our algorithm is evaluated under various performance metrics and experimental scenarios using software adapted from open source CloudSim simulator.},
  doi       = {10.1109/SERVICES.2014.76},
  issn      = {2378-3818},
}

@Article{Zhou2019,
  author   = {Zhou, Xijia and Li, Kenli and Liu, Chubo and Li, Keqin},
  journal  = {IEEE Access},
  title    = {An Experience-Based Scheme for Energy-SLA Balance in Cloud Data Centers},
  year     = {2019},
  issn     = {2169-3536},
  pages    = {23500-23513},
  volume   = {7},
  abstract = {The proliferation of cloud computing has resulted in the establishment of large-scale data centers containing thousands of computing nodes and consuming enormous amounts of electrical energy. However, the low-cost and high-efficiency slogans are getting louder and louder, and the IT industry is also striving for this pursuit. Therefore, it is vital to minimizing the energy consumption for cloud providers while ensuring the quality of service for cloud users. In this paper, we propose several heuristic strategies to optimize these two metrics based on a two-level management model under a heterogeneous cloud environment. First, to detect whether a physical node is continuously overloaded, we propose an empirical forecast algorithm, which predicts the future state of the host by statistically analyzing the historical utilization data of the host. Second, we propose a weighted priority virtual machine (VM) selection algorithm. For each VM on the overloaded host, we weight several utilization factors and calculate its migration priority. Then, we simulate the proposed approach and compare it with the existing overloaded hosts detection algorithms with different VM selection policies under different workloads.},
  doi      = {10.1109/ACCESS.2019.2899101},
}

@Article{He2021a,
  author   = {He, Xingqiu and Wang, Sheng},
  journal  = {IEEE Internet of Things Journal},
  title    = {Peer Offloading in Mobile-Edge Computing With Worst Case Response Time Guarantees},
  year     = {2021},
  issn     = {2327-4662},
  month    = {Feb},
  number   = {4},
  pages    = {2722-2735},
  volume   = {8},
  abstract = {Mobile-edge computing (MEC) is a new paradigm that provides cloud computing services at the edge of networks. To achieve better performance with limited computing resources, peer offloading between cooperative edge servers (e.g., MEC-enabled base stations) has been proposed as an effective technique to handle bursty and spatially imbalanced arrival of computation tasks. While various performance metrics of peer offloading policies have been considered in the literature, the worst case response time, a common quality of service (QoS) requirement in real-time applications, yet receives much less attention. To fill the gap, we formulate the peer offloading problem based on a stochastic arrival model and propose two online algorithms for cases with and without prior knowledge of task arrival rate. Our goal is to maximize the utility function of time-average throughput under constraints of energy consumption and worst case response time. Both theoretical analysis and numerical results show that our algorithms are able to produce close to optimal performance.},
  doi      = {10.1109/JIOT.2020.3019492},
}

@InProceedings{Alqahtani2018,
  author    = {Alqahtani, Awatif and Li, Yinhao and Patel, Pankesh and Solaiman, Ellis and Ranjan, Rajiv},
  booktitle = {2018 International Conference on High Performance Computing & Simulation (HPCS)},
  title     = {End-to-End Service Level Agreement Specification for IoT Applications},
  year      = {2018},
  month     = {July},
  pages     = {926-935},
  abstract  = {The Internet of Things (IoT) promises to help solve a wide range of issues that relate to our wellbeing within applica¬tion domains that include smart cities, healthcare monitoring, and environmental monitoring. IoT is bringing new wireless sensor use cases by taking advantage of the computing power and flexibility provided by Edge and Cloud Computing. However, the software and hardware resources used within such applications must perform correctly and optimally. Especially in applications where a failure of resources can be critical. Service Level Agreements (SLA) where the performance requirements of such applications are defined, need to be specified in a standard way that reflects the end-to-end nature of IoT application domains, accounting for the Quality of Service (QoS) metrics within every layer including the Edge, Network Gateways, and Cloud. In this paper, we propose a conceptual model that captures the key entities of an SLA and their relationships, as a prior step for end-to-end SLA specification and composition. Service level objective (SLO) terms are also considered to express the QoS constraints. Moreover, we propose a new SLA grammar which considers workflow activities and the multi-layered nature of IoT applications. Accordingly, we develop a tool for SLA specification and composition that can be used as a template to generate SLAs in a machine-readable format. We demonstrate the effectiveness of the proposed specification language through a literature survey that includes an SLA language comparison analysis, and via reflecting the user satisfaction results of a usability study.},
  doi       = {10.1109/HPCS.2018.00147},
}

@InProceedings{Maliszewski2019,
  author    = {Maliszewski, Anderson M. and Vogel, Adriano and Griebler, Dalvan and Roloff, Eduardo and Fernandes, Luiz G. and Philippe O. A., Navaux},
  booktitle = {2019 IEEE Symposium on Computers and Communications (ISCC)},
  title     = {Minimizing Communication Overheads in Container-based Clouds for HPC Applications},
  year      = {2019},
  month     = {June},
  pages     = {1-6},
  abstract  = {Although the industry has embraced the cloud computing model, there are still significant challenges to be addressed concerning the quality of cloud services. Network-intensive applications may not scale in the cloud due to the sharing of the network infrastructure. In the literature, performance evaluation studies are showing that the network tends to limit the scalability and performance of HPC applications. Therefore, we proposed the aggregation of Network Interface Cards (NICs) in a ready-to-use integration with the OpenNebula cloud manager using Linux containers. We perform a set of experiments using a network microbenchmark to get specific network performance metrics and NAS parallel benchmarks to analyze the performance impact on HPC applications. Our results highlight that the implementation of NIC aggregation improves network performance in terms of throughput and latency. Moreover, HPC applications have different patterns of behavior when using our approach, which depends on communication and the amount of data transferring. While network-intensive applications increased the performance up to 38%, other applications with aggregated NICs maintained the same performance or presented slightly worse performance.},
  doi       = {10.1109/ISCC47284.2019.8969716},
  issn      = {2642-7389},
}

@InProceedings{Bruneo2015,
  author    = {Bruneo, Dario and Longo, Francesco and Ghosh, Rahul and Scarpa, Marco and Puliafito, Antonio and Trivedi, Kishor S.},
  booktitle = {2015 IEEE 8th International Conference on Cloud Computing},
  title     = {Analytical Modeling of Reactive Autonomic Management Techniques in IaaS Clouds},
  year      = {2015},
  month     = {June},
  pages     = {797-804},
  abstract  = {Cloud computing infrastructures provide services to a wide number of users whose behavior can deeply change at the occurrence of particular events. To correctly handle such situations a cloud infrastructure have to be reconfigured in a way that does not cause degradation in the overall performance. Otherwise, the quality of service specified in the service level agreement could be violated. To prevent such situations, the infrastructure could be organized as an autonomic system where self-adaptation and self-configuration techniques are implemented. Appropriate design choices become important in order not to fail in this goal. We propose a technique, based on a Petri net model and a specific analytical analysis approach, to represent Infrastructure-as-a-Service (IaaS) systems in the case in which the load conditions can suddenly change and reactive autonomic management techniques are applied to mitigate the consequences of the change. The model we propose is able to appropriately evaluate performance metrics in such critical situations making it suitable as a design tool for IaaS cloud systems.},
  doi       = {10.1109/CLOUD.2015.110},
  issn      = {2159-6190},
}

@InProceedings{Meyer2020,
  author    = {Meyer, Vinícius and Kirchoff, Dionatrã F. and da Silva, Matheus L. and De Rose, César A.F.},
  booktitle = {2020 28th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)},
  title     = {An Interference-Aware Application Classifier Based on Machine Learning to Improve Scheduling in Clouds},
  year      = {2020},
  month     = {March},
  pages     = {80-87},
  abstract  = {To maximize resource utilization and system throughput in cloud platforms, hardware resources are often shared across multiple virtualized services or applications. In such a consolidated scenario, performance of applications running concurrently in the same physical host can be negatively affected due to interference caused by resource contention. This should be taken into account for efficient scheduling of such applications and performance prediction at user level. Nevertheless, resource scheduling in cloud computing is usually based solely on resource capacity, implemented by heuristics such as bin-packing. Our previous work has introduced an interference-aware scheduling model for web-applications considering their resource utilization profile, and to classify applications we applied fixed interference intervals based on common utilization patters. Although this resulted in placements with better overall results, we observed that some applications with more dynamic workload patterns were wrongly classified with intervals. In this paper, we propose an alternative to the use of intervals and present an interference-aware application classifier for cloud-based applications that deals better with dynamic workloads. Our classifier defines automatically interference levels ranges combining two well-known machine learning techniques: Support Vector Machines and K-Means. Preliminary experiments evaluated the applied machine learning techniques in three quality metrics: Accuracy, F1-Score and Rand Index, observing rates over 80%. The proposed solution creates a workload-aware fine-grained classification that was compared with previous work over different workload scenarios. The results demonstrate that our classification approach improves the placement efficiency by 23% on average.},
  doi       = {10.1109/PDP50117.2020.00019},
  issn      = {2377-5750},
}

@InProceedings{Wang2020c,
  author    = {Wang, Binyang and Li, Huifang and Lin, Zhiwei and Xia, Yuanqing},
  booktitle = {2020 International Joint Conference on Neural Networks (IJCNN)},
  title     = {Temporal Fusion Pointer network-based Reinforcement Learning algorithm for Multi-Objective Workflow Scheduling in the cloud},
  year      = {2020},
  month     = {July},
  pages     = {1-8},
  abstract  = {Cloud computing is emerging as a deployment promising environment for hosting exponentially increasing scientific and social media applications, but how to manage and execute these applications efficiently depends mainly on workflow scheduling. However, scheduling workflows in the cloud is an NP-hard problem and its existing solutions have certain limitations when applied to real-world scenarios. In this paper, a Temporal Fusion Pointer network-based Reinforcement Learning algorithm for multi-objective workflow scheduling (TFP-RL) is proposed. Through adopting reinforcement learning, our algorithm can discover its heuristics over time by continuous learning according to the rewards resulting from good scheduling solutions. To make more comprehensive scheduling decisions as the influence of historical actions, a novel temporal fusion pointer network (TFP) is designed for the reinforcement learning agent, which can improve the quality of our resulting solutions and the ability of our algorithm in dealing with versatile workflow applications. To decrease convergence time, we train the proposed TFP-RL model independently by the Asynchronous Advantage Actor-Critic method and use its resulting model for scheduling workflows. Finally, under a multi-agent reinforcement learning framework, a Pareto dominance-oriented criterion for reasonable action selection is established for a multi-objective optimization scenario. We first train our TFP-RL model by taking randomly generated workflows as inputs to validate its effectiveness in scheduling, then compare our trained model with other existing scheduling approaches through practical compute- and data-intensive workflows. Experimental results demonstrate that our proposed algorithm outperforms the benchmarking ones in terms of different metrics.},
  doi       = {10.1109/IJCNN48605.2020.9207151},
  issn      = {2161-4407},
}

@InProceedings{Alam2020,
  author    = {Alam, A B M Bodrul and Halabi, Talal and Haque, Anwar and Zulkernine, Mohammad},
  booktitle = {ICC 2020 - 2020 IEEE International Conference on Communications (ICC)},
  title     = {Multi-Objective Interdependent VM Placement Model based on Cloud Reliability Evaluation},
  year      = {2020},
  month     = {June},
  pages     = {1-7},
  abstract  = {Virtual Machine (VM) placement is considered as one of the crucial problems in Cloud Computing environments. From the perspective of Cloud Service Providers (CSPs), finding the optimal VM placement strategy is often related to optimal resource utilization, revenue maximization, and energy efficiency. However, to ensure the continuity of customer services, CSPs should also consider the reliability of deployed applications when placing VMs on their infrastructures. Existing research in this area either do not focus on the Cloud reliability evaluation aspect or do not account for the trade-off between reliability and performance in the VM placement process. In this paper, we propose a multi-objective placement model for interdependent VMs in the Cloud that considers both reliability and workload. Reliability in our model is quantitatively evaluated through a set of metrics that we propose. The model involves an Integer Linear Programming problem that aims at maximizing the reliability of the Cloud while minimizing network delay. A multi-objective genetic algorithm is then used to solve the problem heuristically. The proposed model introduces a level of flexibility and its parameters could be adjusted depending on the requirements of the infrastructure and services. The results show that our model achieves high Cloud reliability and allows to effectively control the trade-off between reliability and Quality of Service.},
  doi       = {10.1109/ICC40277.2020.9149347},
  issn      = {1938-1883},
}

@InProceedings{Klinaku2021,
  author    = {Klinaku, Floriment and Hakamian, Alireza and Becker, Steffen},
  booktitle = {2021 IEEE International Conference on Autonomic Computing and Self-Organizing Systems (ACSOS)},
  title     = {Architecture-based Evaluation of Scaling Policies for Cloud Applications},
  year      = {2021},
  month     = {Sep.},
  pages     = {151-157},
  abstract  = {The cloud computing model enables organizations to employ policies for the automated provisioning of computing resources. The impact on the quality, such as performance or cost, of such policies is often unknown for complex, large, and highly distributed cloud applications. Software architects lack a feasible approach to evaluate scaling policies for their cloud application quantitatively. While approaches exist in the literature, they are costly and require a high effort. We propose an approach that utilizes modeling and terminating simulations to evaluate alternative styles and configurations for cloud scaling policies. The approach aids the architect in understanding and explaining their dynamic behavior and the existing trade-offs. Third, we conduct simulation experiments on a representative case study model to show the approach&#x0027;s feasibility. We evaluate the performance, cost, efficiency, and complexity of three scaling policies of different styles (e.g., centralized vs. decentralized) on a model. Results show that the policies improve the performance for the selected scenario. However, no significant difference among them exists in terms of performance. Other metrics highlight the present trade-offs across policies. All in all, the case shows that the approach helps architects refine the style and find an appropriate policy for their context.},
  doi       = {10.1109/ACSOS52086.2021.00035},
}

@InProceedings{Li2021d,
  author    = {Li, Dian and Wang, Weidong and Kang, Yujian},
  booktitle = {2021 IEEE International Conference on Electronic Technology, Communication and Information (ICETCI)},
  title     = {A Hierarchical Approach for QoS-Aware Edge Service Scheduling and Composition},
  year      = {2021},
  month     = {Aug},
  pages     = {677-681},
  abstract  = {Edge computing is a new computing paradigm after cloud computing. Edge service scheduling and composition (ESC) has been well recognized as a convenient and flexible way of services sharing and integrating in industrial application fields. The ESC aims at selecting a set of existing edge service candidates with different Quality of Service (QoS) attributes (e.g., price), then compositing them to accomplish a complex task to meet users' QoS requirements, where each edge service may have multiple functionally equivalent, but different QoS metrics. A grand research challenge of the ESC based on QoS is to select proper service candidates to maximize QoS of the composited edge service and meanwhile meet the global QoS requirements. In this article, we focus on this challenge and propose a hierarchical solution for ESC. Specifically, we classify service candidates into specified grades based on their QoS attributes, and use hierarchical model to address service selection problem. Furthermore, in order to expand the flexibility of our approach, we design a near-optimal solution by decomposing the global end-to-end QoS constraints into local QoS constraints and adopting local service selecting and updating strategy based on the hierarchical model. The results of simulation-based experiments are conducted to show our approach is more efficient and valid compared to other existing approaches.},
  doi       = {10.1109/ICETCI53161.2021.9563355},
}

@InProceedings{Wangsom2018,
  author    = {Wangsom, Peerasak and Bouvry, Pascal and Lavangnananda, Kittichai},
  booktitle = {2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)},
  title     = {Extreme Solutions NSGA-III (E-NSGA-III) for Scientific Workflow Scheduling on Cloud},
  year      = {2018},
  month     = {Dec},
  pages     = {1139-1146},
  abstract  = {The execution of scientific workflows on dynamic environments such as cloud computing has become multi-objective scheduling in order to satisfy user demands from several perspectives. Among these objectives, Cost and Makespan are probably the most common. This research also includes Data Movement as an additional objective as it has significant effect to network utilization and energy consumption in network equipment in cloud data center. This paper proposes a multi-objective scheduling, Extreme Nondominated Sorting Genetic Algorithm (E-NSGA-III). It is an extension of the Nondominated Sorting Genetic Algorithm (NSGA-III). E-NSGA-III utilizes extreme solutions in the population generation module in order improve quality of solutions. Five well-known scientific workflows are selected as testbeds. Hypervolume and the Pareto front are chosen as the performance metrics. E-NSGA-III is evaluated by comparing its performance against the two previous versions (NSGA-II and NSGA-III). The comparison reveals that E-NSGA-III yields the best performance among them in multi-objective scheduling of the five scientific workflows.},
  doi       = {10.1109/ICMLA.2018.00184},
}

@InProceedings{Noureddine2021,
  author    = {Noureddine, Staifi and Meriem, Belguidoum},
  booktitle = {2021 International Conference on Information Systems and Advanced Technologies (ICISAT)},
  title     = {ML-SLA-IoT: an SLA Specification and Monitoring Framework for IoT applications},
  year      = {2021},
  month     = {Dec},
  pages     = {1-12},
  abstract  = {Service level agreement (SLA) is a formal contract between a service provider and a service consumer to guarantee the Quality of service (QoS) expectations, it is used in all areas of information technology, such as Cloud Computing, Internet of Things (IoT), networks and Web services. For IoT applications, the main challenges are: (1) how to describe the SLA terms, such as QoS properties, service levels, penalties in SLA violation, (2) how to monitor these terms, and (3) how to integrate an SLA into all the IoT application layers. Therefore, in this paper, we propose ML-SLA-IoT, a framework for SLA specification and monitoring. It covers the entire layers of an IoT application. It describes precisely QoS levels, provided services, and obligations. It differs from other SLA specification languages in the specification of user preferences, the use of microservices (for reusability, dynamism and ease of integration) and ML-SLA (multi-level metrics and QoS according to existing constraints and user preferences). Furthermore, ML-SLA-IoT monitors SLA terms in an automatic and decentralised manner using smart contracts and blockchain technologies without the intervention of the third-party. Finally, we present a comparative study and experiments with existing solutions regarding to some criteria for SLA specification and monitoring. Our results show that ML-SLA-IoT gives better performance in terms of dynamic pricing, obligation combination, and SLA monitoring.},
  doi       = {10.1109/ICISAT54145.2021.9678460},
}

@InProceedings{Afify2017,
  author    = {Afify, Yasmine M. and Badr, Nagwa L. and Moawad, Ibrahim F. and Tolba, Mohamed F.},
  booktitle = {2017 Eighth International Conference on Intelligent Computing and Information Systems (ICICIS)},
  title     = {Evaluation of cloud service ontologies},
  year      = {2017},
  month     = {Dec},
  pages     = {144-153},
  abstract  = {It is the cloud computing era. Substantial number of Cloud Services (CS) have emerged. The automation of the cloud services life cycle can be enhanced using domain ontologies in the cloud environment. Ontologies allow more efficient CS publication, discovery, selection, composition and recommendations. However, no broad cloud ontology for this purpose has dominated yet. This paper presents an in-depth analysis of existing cloud taxonomies and service ontologies. We present a comparison of the cloud service ontologies implementation features. Moreover, a semiotic metrics suite of ontology quality is used for the assessment process.},
  doi       = {10.1109/INTELCIS.2017.8260045},
}

@Article{Maia2016,
  author   = {Maia, Delano Jose Holanda and Moreira, Leonardo Oliveira and Coutinho, Emanuel Ferreira and Gomes, Danielo Goncalves},
  journal  = {IEEE Latin America Transactions},
  title    = {MILENA: a model for implementing distributed multiplayer games in computing clouds},
  year     = {2016},
  issn     = {1548-0992},
  month    = {Feb},
  number   = {2},
  pages    = {951-957},
  volume   = {14},
  abstract = {Cloud computing environments are characteristically composed of distributed infrastructure, heterogeneous and virtualized resources, besides serving concurrently a wide range of customers whose service level agreements may require different levels of Quality of Service (QoS). Distributed multiplayer games, in turn, are collaborative distributed applications that must have an acceptable level of QoS to maintain justice among its players. This article proposes MILENA, a model for implementing distributed multiplayer games on computer clouds. The proposed model meets the requirements of QoS, fault tolerance and scalability. As a case study for verification and validation of the proposal, we have developed a game and evaluated its performance by SLA violations and response time of requests metrics. The results show that the MILENA scales up to 100 players without QoS loss, thus improving justice in distributed multiplayer games.},
  doi      = {10.1109/TLA.2016.7437245},
}

@Article{Rahman2020a,
  author   = {Rahman, Sabidur and Ahmed, Tanjila and Huynh, Minh and Tornatore, Massimo and Mukherjee, Biswanath},
  journal  = {IEEE Transactions on Network and Service Management},
  title    = {Auto-Scaling Network Service Chains Using Machine Learning and Negotiation Game},
  year     = {2020},
  issn     = {1932-4537},
  month    = {Sep.},
  number   = {3},
  pages    = {1322-1336},
  volume   = {17},
  abstract = {Network Function Virtualization (NFV) enables Network Operators (NOs) to efficiently respond to the increasing dynamicity of network services. Virtual Network Functions (VNFs) running on commercial off-the-shelf servers are easy to deploy, update, monitor, and manage. Such virtualized services are often deployed as Service Chains (SCs), which require in-sequence placement of computing and memory resources as well as routing of traffic flows. Due to the ongoing migration towards cloudification of networks, the concept of auto-scaling which originated in Cloud Computing, is now receiving attention from networks professionals too. Prior studies on auto-scaling use measured load to dynamically react to traffic changes. Moreover, they often focus on only one of the resources (e.g., compute only, or network capacity only). In this study, we consider three different resource types: compute, memory, and network bandwidth. In prior studies, NO takes auto-scaling decisions, assuming tenants are always willing to auto-scale, and Quality of Service (QoS) requirements are homogeneous. Our study proposes a negotiation-game-based auto-scaling method where tenants and NO both engage in the auto-scaling decision, based on their willingness to participate, heterogeneous QoS requirements, and financial gain (e.g., cost savings). In addition, we propose a proactive Machine Learning (ML) based prediction method to perform SC auto-scaling in dynamic traffic scenario. Numerical examples show that our proposed SC auto-scaling methods powered by ML present a win-win situation for both NO and tenants (in terms of cost savings).},
  doi      = {10.1109/TNSM.2020.2995900},
}

@Article{Liu2021a,
  author   = {Liu, Li and Lu, Caiwu and Xiao, Fengjun and Liu, Ruimin and Xiong, Neal Naixue},
  journal  = {IEEE Access},
  title    = {A Practical, Integrated Multi-Criteria Decision-Making Scheme for Choosing Cloud Services in Cloud Systems},
  year     = {2021},
  issn     = {2169-3536},
  pages    = {88391-88404},
  volume   = {9},
  abstract = {Currently, with the rapid development and broad application of cloud computing technology, companies tend to use cloud services to build their applications or business systems. Selecting a trustworthy cloud service is a challenging multi-criteria decision-making (MCDM) problem. Moreover, decision makers are more inclined to use linguistic descriptions to assess the quality of service (QoS) for cloud services due to the limitation of the decision makers' knowledge and the vagueness of criteria information. Therefore, we propose a practical, integrated MCDM scheme for cloud service evaluation and selection of cloud systems, allowing decision makers to compare cloud services based on QoS criteria. First, to more accurately and effectively express the uncertainty of qualitative concepts, the cloud model is used as a conversion tool for qualitative and quantitative information to quantify linguistic terms. Second, given the shortcomings of traditional differentiating measures between cloud models, a more comprehensive distance measurement algorithm using cloud droplet distribution is proposed for the cloud model. The new distance measurement algorithm is applied to the calculation of cloud model similarity and the gray correlation coefficient. The dynamic expertise weights are determined by calculating the similarity between the expert evaluation cloud model and the arithmetic mean cloud model. Then, we propose a technique for order preference by similarity to an ideal solution (TOPSIS) improved by the grey relational analysis (GRA) to calculate the relative closeness of alternatives to the positive and negative ideal solutions and establish a multi-objective optimization model that maximizes the relative closeness of all alternatives to determine the weights of the criteria. Finally, we reconstructed the QoS evaluation criteria for cloud services from both application and service perspectives, and the classical TOPSIS is applied to generate alternative rankings. The practicability and robustness of the scheme were tested through the cloud service selection problem experienced by a real mining company's scheduling platform, which can provide practical references with the theoretical basis for the selection and evaluation of cloud services.},
  doi      = {10.1109/ACCESS.2021.3089991},
}

@InProceedings{Bhardwaj2020,
  author    = {Bhardwaj, Tushar and Upadhyay, Himanshu and Sharma, Subhash Chander},
  booktitle = {2020 10th International Conference on Cloud Computing, Data Science & Engineering (Confluence)},
  title     = {Framework for Quality Ranking of Components in Cloud Computing: Regressive Rank},
  year      = {2020},
  month     = {Jan},
  pages     = {598-604},
  abstract  = {As the popularity of cloud computing is increasing there is an urgent requirement of developing highly efficient and highly qualitative cloud applications (CA). Hence, it be-comes a big research problem. A recommender system recommends the suitable item to the user and almost all the systems provide a rating score for preference. Traditionally, algorithms predicts the ratings that a user should give to the unrated components to queue the item in recommended list. To select an optimal candidate from a set of function-ally equivalent candidates is crucial through approaches that follow a framework for component quality ranking. More-over, such framework helps in detecting the poor performing candidates from a highly distributed cloud applications. In this paper a novel technique is proposed to provide personalized component ranking for designers by employing the past usage of components by different users. In this approach the similarity between the users is measured based on their rankings for functionally equivalent components set instead of their rating values. In this approach no additional invocation of cloud component is required. Experimental results on real world web-service invocations data set shows that the proposed approach outperforms the previous approaches.},
  doi       = {10.1109/Confluence47617.2020.9058016},
}

@InProceedings{Liu2014a,
  author    = {Liu, Meng and Dou, Wanchun and Yu, Shui and Zhang, Zhensheng},
  booktitle = {2014 IEEE International Conference on Communications (ICC)},
  title     = {A clusterized firewall framework for cloud computing},
  year      = {2014},
  month     = {June},
  pages     = {3788-3793},
  abstract  = {Cloud computing is becoming popular as the next infrastructure of computing platform. However, with data and business applications outsourced to a third party, how to protect cloud data centers from numerous attacks has become a critical concern. In this paper, we propose a clusterized framework of cloud firewall, which characters performance and cost evaluation. To provide quantitative performance analysis of the cloud firewall, a novel M/Geo/1 analytical model is established. The model allows cloud defenders to extract key system measures such as request response time, and determine how many resources are needed to guarantee quality of service (QoS). Moreover, we give an insight into financial cost of the proposed cloud firewall. Finally, our analytical results are verified by simulation experiments.},
  doi       = {10.1109/ICC.2014.6883911},
  issn      = {1938-1883},
}

@InProceedings{Rahulamathavan2015,
  author    = {Rahulamathavan, Yogachandran and Rajarajan, Muttukrishnan and Rana, Omer F. and Awan, Malik S. and Burnap, Pete and Das, Sajal K.},
  booktitle = {2015 IEEE 7th International Conference on Cloud Computing Technology and Science (CloudCom)},
  title     = {Assessing Data Breach Risk in Cloud Systems},
  year      = {2015},
  month     = {Nov},
  pages     = {363-370},
  abstract  = {The emerging cloud market introduces a multitude of cloud service providers, making it difficult for consumers to select providers who are likely to be a low risk from a security perspective. Recently, significant emphasis has arisen on the need to specify Service Level Agreements that address security concerns of consumers (referred to as SecSLAs) -- these are intended to clarify security support in addition to Quality of Service characteristics associated with services. It has been found that such SecSLAs are not consistent among providers, even though they offer services with similar functionality. However, measuring security service levels and the associated risk plays an important role when choosing a cloud provider. Data breaches have been identified as a high priority threat influencing the adoption of cloud computing. This paper proposes a general analysis framework which can compute risk associated with data breaches based on pre-agreed SecSLAs for different cloud providers. The framework exploits a tree based structure to identify possible attack scenarios that can lead to data breaches in the cloud and a means of assessing the use of potential mitigation strategies to reduce such breaches.},
  doi       = {10.1109/CloudCom.2015.58},
}

@InProceedings{Xie2015,
  author    = {Xie, Xiongwei and Wang, Weichao and Qin, Tuanfa},
  booktitle = {2015 24th International Conference on Computer Communication and Networks (ICCCN)},
  title     = {Detection of Service Level Agreement (SLA) Violation in Memory Management in Virtual Machines},
  year      = {2015},
  month     = {Aug},
  pages     = {1-8},
  abstract  = {In cloud computing, quality of services is often enforced through Service Level Agreement (SLA) between end users and cloud providers. While SLAs on hardware resources such as CPU cycles or bandwidth can be monitored by low layer sensors, the enforcement of security SLAs stays a very challenging problem. Several high level architectures for security SLAs have been proposed. However, details still need to be filled before they can be deployed. In this paper, we propose to design mechanisms to detect violations of security SLAs. Specifically, we focus on unauthorized accesses to memory pages of a virtual machine and violation of the memory deduplication policies. Through measuring the accumulated memory access latency, we try to derive out whether or not the memory pages have been swapped out and the order of accesses to them. These events will then be compared to access commands issued by the local VM. In this way, unauthorized memory accesses or violation of deduplication policies can be detected. Compared to existing approaches, our mechanisms do not need explicit help from the hypervisor or third parties. Therefore, it can detect SLA violations even when they are initiated by the hypervisor. We implement our approaches under VMWare with Windows virtual machines. Our experiment results show that the VM can effectively detect the violations with small increases in overhead.},
  doi       = {10.1109/ICCCN.2015.7288394},
  issn      = {1095-2055},
}

@InProceedings{Chen2015,
  author    = {Chen, Wei and Chen, Jiming and Tang, Jine and Wang, Liangmin},
  booktitle = {2015 Third International Conference on Advanced Cloud and Big Data},
  title     = {A QoS Guarantee Framework for Cloud Services Based on Bayesian Prediction},
  year      = {2015},
  month     = {Oct},
  pages     = {117-124},
  abstract  = {With the quality of service (QoS) of cloud services becoming increasingly concerned, how to ensure that the QoS of cloud services can meet the users' QoS requirement has become a focus of the study on cloud computing. However, the QoS of cloud services is dynamic regularly, we propose a QoS guarantee framework for cloud services and the Bayesian prediction method is used to predict QoS of cloud service. In our framework, cloud system can monitor and predict the QoS of cloud services in real-time, not only during the selection of cloud services, but also during the execution of cloud services. Once QoS prediction results show that some QoS violations will occur, cloud system will take measures to avoid the occurrence of QoS violations. We use the cloud simulation software called CloudSim for the experiment and the results demonstrate that compared with ARIMA and other prediction methods, our Bayesian prediction method has higher accuracy. Moreover, our QoS guarantee framework can greatly reduce the probability of QoS violation.},
  doi       = {10.1109/CBD.2015.28},
}

@InProceedings{Shan2020,
  author    = {Shan, Nanliang and Cui, Xiaolong and Gao, Zhiqiang and Li, Yu},
  booktitle = {2020 IEEE 4th Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)},
  title     = {Multi-User Multi-Server Multi-Channel Computation Offloading Strategy for Mobile Edge Computing},
  year      = {2020},
  month     = {June},
  pages     = {1389-1400},
  volume    = {1},
  abstract  = {Mobile edge computing is a new computing paradigm that can extend cloud computing capabilities to the edge network, supporting computation-intensive applications such as face recognition, natural language processing, augmented reality. Notably, computation offloading is a key technology of mobile edge computing to improve mobile devices performance and user experience by offloading local tasks to edge servers. In this paper, we study the problem of computation offloading under multi-user, multi-server, and multi-channel scenarios, and propose a computation offloading strategy considering the quality of service (QoS) of users, server resources, and channel interference. This strategy consists of three stages: (1) In offloading decision stage, the offloading decision is made based on the beneficial degree of computation offloading, which is measured by the total cost of local computing of mobile device in comparison with the edge-side server. (2) In the server selection stage, the candidate is comprehensively evaluated and selected by a multi-objective decision based on Cov-AHP for computation offloading. (3) In the channel selection stage, a multi-user and multi-channel distributed computation offloading model based on potential game is proposed by considering the influence of channel interference on the user's overall overhead. The corresponding multi-user and multi-channel task scheduling algorithm is designed to maximize the overall benefit by finding the Nash equilibrium point of the potential game. Amounts of experimental results show that the proposed method can greatly increase the number of beneficial computation offloading users, and effectively reduce the energy consumption and time delay.},
  doi       = {10.1109/ITNEC48623.2020.9084760},
}

@Article{Nam2014,
  author   = {Nam, Yunyoung and Park, Hyung Ju and Cho, Chae Ho and Park, Jong Hyuk},
  journal  = {IEEE Systems Journal},
  title    = {An Interactive IPTV System With Community Participation in Cloud Computing Environments},
  year     = {2014},
  issn     = {1937-9234},
  month    = {March},
  number   = {1},
  pages    = {174-183},
  volume   = {8},
  abstract = {This paper presents a video communication system that provides real-time participating services to audiences using Internet Protocol television (IPTV) and mobile devices on cloud computing environments. High-quality video processing and bidirectional multimedia communication technologies are combined for videoconferencing and interactive user participation. The P-module has been developed to encode and decode 1080i high-definition video data on a system simultaneously. A video communication protocol is applied to exchanging information between distributed and heterogeneous devices. The developed system has been deployed in a public service center in Seoul, Korea. In the experiments, we will show the implemented system using IPTV and a mobile phone, as well as the experiment results of the measured CPU overhead and mixing time in our system.},
  doi      = {10.1109/JSYST.2013.2258745},
}

@InProceedings{Kyriazis2018,
  author    = {Kyriazis, Dimosthenis},
  booktitle = {2018 32nd International Conference on Advanced Information Networking and Applications Workshops (WAINA)},
  title     = {BYOS: Bring Your Own Security in Clouds and Service Oriented Infrastructures},
  year      = {2018},
  month     = {May},
  pages     = {374-379},
  abstract  = {Cloud computing is widely being used by users, tenants and enterprises. However, the major concern and barrier for its adoption are the security and privacy concerns of end users. To this end, in this paper an approach is presented that proposes the use of security mechanisms, as plugins that are custom / tailored and potentially developed by the end users themselves. The latter is proposed as a means to overcome users concerns about the quality of security offered by the providers through their deployed security and privacy measures. As a concept, it builds on top of the well-established Bring Your Own Device (BYOD) paradigm and adopts it in the context of security and privacy. The potential challenges and an architecture with the corresponding key building blocks that address these challenges are presented.},
  doi       = {10.1109/WAINA.2018.00114},
}

@InProceedings{Li2021e,
  author    = {Li, Guo and Liu, Ling and Liang, Zhengping and Ma, Xiaoliang and Zhu, Zexuan},
  booktitle = {2021 IEEE 32nd Annual International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC)},
  title     = {Memetic Algorithm Based on Community Detection for Energy-Efficient Service Migration Optimization in 5G Mobile Edge Computing},
  year      = {2021},
  month     = {Sep.},
  pages     = {1-7},
  abstract  = {Mobile edge computing (MEC) can supplement cloud computing by helping to overcome the limitations of long physical transmission distances and accelerating the responsiveness of edge computing servers. In 5G (fifth generation) cellular networks, adopting MEC can guarantee ultralow latency. To enhance the MEC quality, optimization of the user service profile migration according to the user mobility is essential. However, this optimization establishes an NP-hard problem. Moreover, high-speed 5G base stations with MEC servers often experience high energy consumption. As conventional service migration algorithms such as those based on profile tracking and game theory tend to fall in local optima and neglect energy consumption constraints, we propose a memetic algorithm based on community detection local search (MA-CDLS) to continuously optimize the service migration in 5G MEC scenarios. During busy periods or in crowded areas, MA-CDLS adopts a single-objective optimization of user-perceived latency to achieve high-performance 5G services. During light-load periods or in uncrowded areas, MA-CDLS uses two measures, namely the user-perceived latency and energy consumption, to realize energy-efficient 5G services. MA-CDLS effectively reduces the search space and speeds up the elite selection in the meme operator. Experiments in simulated scenarios show that MA-CDLS achieves a lower user-perceived latency and energy consumption, than the traditional profile tracking and game theory methods, especially during congestion.},
  doi       = {10.1109/PIMRC50174.2021.9569577},
  issn      = {2166-9589},
}

@InProceedings{Falasi2016,
  author    = {Falasi, Asma Al and Serhani, Mohamed Adel},
  booktitle = {2016 Intl IEEE Conferences on Ubiquitous Intelligence & Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People, and Smart World Congress (UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld)},
  title     = {SLA Specification and Negotiation Model for a Network of Federated Clouds: CloudLend},
  year      = {2016},
  month     = {July},
  pages     = {772-779},
  abstract  = {The Cloud computing paradigm is remarkably evolving. Cloud customers have become more conscious about the QoS expectation from Cloud providers' services. Accordingly, Cloud providers are required to be responsive to customers' demands, be open to establishing federations with other providers in order to retain their shares in the competitive Cloud market. Cloud customers are always searching for optimized services, irrespective of which providers are taking part in a federation to deliver these services. They seek federated Cloud services to attain the maximum satisfaction level, which is measured by the degree of adherence to customers' quality of service (QoS). Such federations of Cloud services are typically governed by service level agreements (SLAs) that are negotiated between the Cloud customer, provider prior to service provisioning. This paper tackles the challenges related to SLA specification, negotiation in a federated network of Clouds, CloudLend. We first propose a weighted SLA specification model that captures customers' QoS, manages multi-level SLAs specification. We then introduce an autonomous SLA negotiation model that adopts an enhanced fair division game. The model enables federated Cloud services to examine SLAs, react to SLA offers, eventually sign an SLA contract. It autonomously detects changes in Clouds federations, revises SLA specifications accordingly. The proposed model is evaluated using a CloudLend simulator, which we developed for this purpose. Several test cases were executed,, the results we have achieved verified the fairness, efficiency of our proposed SLA specification, negotiation models in CloudLend.},
  doi       = {10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0124},
}

@InProceedings{Samarakoon2023,
  author    = {Samarakoon, Sahan and Bandara, Shashika and Jayasanka, Nishan and Hettiarachchi, Chathuranga},
  booktitle = {2023 Moratuwa Engineering Research Conference (MERCon)},
  title     = {Self-Healing and Self-Adaptive Management for IoT-Edge Computing Infrastructure},
  year      = {2023},
  month     = {Nov},
  pages     = {473-478},
  abstract  = {Containerized micro-service oriented computing deployment strategies have proven to possess resilience, selfadaptive, and self-healing properties in cloud computing environments. The rapid growth of smart Internet of Things (IoT) deployments necessitates a similar approach to mitigate the challenges associated with manually managing large fleets of IoT devices. To address these challenges, we propose a novel software framework that extends Kubernetes(K8s) to collect and integrate IoT device performance metrics. By leveraging this framework, a set of self-healing and self-adaptive strategies can be deployed, taking into account the status of IoT devices. In our research, we evaluate the impact of IoT device-to-edge compute latency, bandwidth, and jitter information using the proposed software framework, including a metrics collection plugin and a custom scheduler. The results demonstrate significant enhancements in Quality of Service measures for a benchmark application scenario, emphasizing the framework’s ability to reduce manual intervention efforts through extended adaptation strategies.},
  doi       = {10.1109/MERCon60487.2023.10355514},
  issn      = {2691-364X},
}

@InProceedings{Nguyen2023,
  author    = {Nguyen, Michael and Sood, Kanika and Avery, Kenytt and Bein, Doina},
  booktitle = {2023 5th International Conference on Robotics and Computer Vision (ICRCV)},
  title     = {Deep Learning-based Super-Resolution on the Cloud: Focus on Face and Text Enhancement},
  year      = {2023},
  month     = {Sep.},
  pages     = {124-129},
  abstract  = {Real-ESRGAN and SwinIR are two deep learning models for Single-Image Super-Resolution (SISR), which attempt to address real-world scenarios for image enhancement. However, the pre-trained models do not effectively handle LR images containing human faces and text. An experiment is conducted to expand upon the training performed in their respective studies and improve the image enhancement using a cloud computing environment. Traditional image quality metrics, Peak Signal-toNoise Ratio (PSNR), and Structural Similarity (SSIM), are used to objectively evaluate the image quality. Three learning-based perceptual metrics, the Blind / Referenceless Image Spatial Quality Evaluator (BRISQUE), Naturalness Image Quality Evaluator (NIQE), and the Learned Perceptual Image Patch Similarity (LPIPS), are also incorporated to assess how images would be subjectively perceived based on human perception. To evaluate the model performance of Real-ESRGAN and SwinIR, specifically for face and text images, both traditional and perceptual metrics are taken into consideration, in addition to the cost associated with model training using Microsoft Azure. The findings show that with additional fine-tuning, SwinIR has slightly improved PSNR and SSIM values while taking less training time compared to Real-ESRGAN at the cost of perceptual quality.},
  doi       = {10.1109/ICRCV59470.2023.10329061},
}

@InProceedings{Volkov2022,
  author    = {Volkov, A. O. and Korobkina, A. V. and Stepanov, S. N.},
  booktitle = {2022 Systems of Signals Generating and Processing in the Field of on Board Communications},
  title     = {Development of a Model and Algorithms for Servicing Real-Time and Data Traffic in a Cloud Computing System},
  year      = {2022},
  month     = {March},
  pages     = {1-5},
  abstract  = {Today, modern low earth orbit (LEO) mobile satellite systems require constant data exchange with cloud computing centers located on Earth to work correctly. Moreover, there is both real-time data transmission and data that allows for a delay, this, for example, may be telemetry data. In the described model the key performance features of the conjoint traffic processing were defined. They are defined using values of probabilities of the model’s stationary states. The numerical algorithm of measuring of designed performance metrics by solving the state equations system with the help of the Gauss-Zeidel algorithm is presented. The model and the resulting algorithms can be used to assess the service quality and load levels of a small cloud computing node. One of the possible options for future research on this topic may be to restrict the access of applications for data processing to prioritize the processing of real-time applications.},
  doi       = {10.1109/IEEECONF53456.2022.9744289},
  issn      = {2768-0118},
}

@InProceedings{Rajesh2022,
  author    = {Rajesh, K.N.V.S.S.K. and Redd, K. Thammi and Murthy, N.V.E.S. and Sarma, M. Subrahmanya},
  booktitle = {2022 IEEE 2nd Mysore Sub Section International Conference (MysuruCon)},
  title     = {Augmenting Additional Quality of Services for Adaptability and Reliability of Cloud Infrastructure},
  year      = {2022},
  month     = {Oct},
  pages     = {1-6},
  abstract  = {Adoption of Cloud computing has been increased by multi fold in the recent past in order to cope up with business requirements. There are few Quality of Service (QoS) metrics which augment the availability of cloud hosted applications. However, still there are quite a few challenges to be addressed in order to improve degree of trust in cloud computing. One of the key challenges observed is, there were no quality of services (QoS) metrics augmented with the PaaS which checks certain parameters covering Disk space utilization and Memory utilization etc., which are the root cause for any priority incidents pertaining to cloud hosted service availability. This paper aims to study the current quality of services available and augment additional quality of services to scale up the services for need of the hour requirements covering site reliability engineering (SRE). Experimentation has been done with the help of major cloud services platforms such as AWS and results were analyzed and attached to this paper.},
  doi       = {10.1109/MysuruCon55714.2022.9972509},
}

@InProceedings{Alkhazali2023,
  author    = {Alkhazali, Abdel Rahman Mohammad and Khasawneh, Ahmad M. and Alzoubi, Sharaf and Magableh, Murad and Mohamed, Rajina R. and Pandey, Bishwajeet},
  booktitle = {2023 International Conference on Computer Science and Emerging Technologies (CSET)},
  title     = {Cloud Computing in Smart Cities: Privacy, Ethical and Social Issues},
  year      = {2023},
  month     = {Oct},
  pages     = {1-7},
  abstract  = {The rapid development of cloud computing technologies has revolutionized various sectors, and smart cities are no exception. Smart cities leverage cloud computing to optimize urban services, enhance resource management, and improve the overall quality of life for their inhabitants. However, as these technological advancements proliferate, concerns about privacy, ethical considerations, and social implications have emerged. This research paper critically examines the multifaceted challenges associated with the integration of cloud computing in smart cities, shedding light on the potential risks and highlighting the need for comprehensive solutions. The research employs a mixed-methods approach, combining quantitative data analysis and qualitative case studies to offer a comprehensive perspective on the identified issues. The primary focus lies in identifying privacy risks, ethical dilemmas, and social disparities that arise due to the extensive use of cloud-based systems and data in smart cities. Furthermore, the study investigates the role of key stakeholders, including governments, technology providers, and citizens, in mitigating or exacerbating these challenges. Key findings reveal that while cloud computing empowers smart cities with unparalleled capabilities, it also exposes residents' personal information to potential breaches and misuse. Ethical concerns arise from the handling of sensitive data, data ownership, and algorithmic biases that could perpetuate discrimination. Moreover, social issues like the digital divide and access disparities may further exacerbate existing inequalities in smart city implementation. This research paper concludes by proposing a comprehensive framework of guidelines and best practices to address the identified issues effectively. These recommendations encompass enhanced data privacy measures, transparent and accountable data governance, the promotion of ethical data usage, and inclusive strategies to bridge social disparities. By adopting these measures, smart cities can harness the full potential of cloud computing while safeguarding individual rights and fostering a more equitable and inclusive urban environment. Overall, this study underscores the critical importance of addressing privacy, ethical, and social challenges in the context of cloud computing in smart cities. By adopting a holistic and proactive approach, city planners, policymakers, and technology providers can build sustainable and responsible smart cities that ensure the well-being and dignity of their residents in the digital era.},
  doi       = {10.1109/CSET58993.2023.10346675},
}

@Article{Lin2022b,
  author   = {Lin, Weiwei and Wu, Wentai and He, Ligang},
  journal  = {IEEE Transactions on Services Computing},
  title    = {An On-Line Virtual Machine Consolidation Strategy for Dual Improvement in Performance and Energy Conservation of Server Clusters in Cloud Data Centers},
  year     = {2022},
  issn     = {1939-1374},
  month    = {March},
  number   = {2},
  pages    = {766-777},
  volume   = {15},
  abstract = {As data centers are consuming massive amount of energy, improving the energy efficiency of cloud computing has emerged as a focus of research. However, it is challenging to reduce energy consumption while maintaining system performance without increasing the risk of Service Level Agreement violations. Most of the existing consolidation approaches for virtual machines (VMs) consider system performance and Quality of Service (QoS) metrics as constraints, which usually results in large scheduling overhead and impossibility to achieve effective improvement in energy efficiency without sacrificing some system performance and cloud service quality. In this article, we first define the metrics of peak power efficiency and optimal utilization for heterogeneous physical machines (PMs). Then we propose Peak Efficiency Aware Scheduling (PEAS), a novel strategy of VM placement and reallocation for achieving dual improvement in performance and energy conservation from the perspective of server clusters. PEAS allocates and reallocates VMs in an on-line manner and always attempts to maintain PMs working in their peak power efficiency via VM consolidation. Extensive experiments on Cloudsim show that PEAS outperforms several energy-aware consolidation algorithms with regard to energy consumption, system performance as well as multiple QoS metrics.},
  doi      = {10.1109/TSC.2019.2961082},
}

@InProceedings{JonatasdosPassos2022,
  author    = {Jônatas dos Passos, Edenilson and Fiorese, Adriano},
  booktitle = {2022 18th International Conference on Network and Service Management (CNSM)},
  title     = {Monitoring Metrics for Load Balancing over Video Content Distribution Servers},
  year      = {2022},
  month     = {Oct},
  pages     = {247-253},
  abstract  = {Cloud computing and video streaming services have been in constant expansion in recent years. Along with it, the demand for computing resources has also increased significantly. In this context, monitoring the use of these resources is crucial to maintain a satisfactory level of Quality of Service and, consequently, Quality of Experience, especially in video transmission services. This work discusses a new method of monitoring resources and quality of service metrics on content servers involving CPU utilization and server throughput, which is obtained in a distributed way. For that, a distributed collector system that is based on a modified version of the ring election algorithm is developed to retrieve the Quality of Service metrics in each server. Evaluation experiment results show that there are no performance gains on the system such as the content loading faster for the user, there are however, improvements in terms of the whole system scalability. The greater the number of servers for monitoring, the better the approach is compared to the traditional method of monitoring resources through request and response.},
  doi       = {10.23919/CNSM55787.2022.9964896},
  issn      = {2165-963X},
}

@InProceedings{Mangalampalli2022,
  author    = {Mangalampalli, Sudheer and Pokkuluri, Kiran Sree and Satish, G. Naga and Swain, Sangram Keshari},
  booktitle = {2022 International Conference on Computing, Communication and Power Technology (IC3P)},
  title     = {Effective VM Placement Mechanism in Cloud Computing using Cuckoo Search Optimization},
  year      = {2022},
  month     = {Jan},
  pages     = {238-241},
  abstract  = {Effective VM placement mechanism is needed for Cloud Computing as incoming flow of tasks were dynamic when they are coming onto cloud console. Incoming requests for any cloud console were large in number then there is a chance of decay in quality of service. Quality of service will be degraded when these number of requests were not properly handled i.e. SLA violations and more number of migrations. Quality of Service will be directly affected by these parameters. Many of the authors addressed these metrics but still there is a chance to improve the VM placement in cloud computing. In this paper, we have used a nature inspired algorithm i.e. cuckoo search to design the VM placement strategy and we have used a threshold value to identify the physical host whet her it is overloaded, under loaded or balanced based on the utilization of CPU. Cloudsim toolkit is used as a simulator to conduct simulation and our proposed mechanism minimizes violation of SLA and there is a great improvement in makespan when it was compared with PSO and GA algorithms.},
  doi       = {10.1109/IC3P52835.2022.00057},
}

@Article{Mahmoudi2022,
  author   = {Mahmoudi, Nima and Khazaei, Hamzeh},
  journal  = {IEEE Transactions on Cloud Computing},
  title    = {Performance Modeling of Serverless Computing Platforms},
  year     = {2022},
  issn     = {2168-7161},
  month    = {Oct},
  number   = {4},
  pages    = {2834-2847},
  volume   = {10},
  abstract = {Analytical performance models have been leveraged extensively to analyze and improve the performance and cost of various cloud computing services. However, in the case of serverless computing, which is projected to be the dominant form of cloud computing in the future, we have not seen analytical performance models to help with the analysis and optimization of such platforms. In this work, we propose an analytical performance model that captures the unique details of serverless computing platforms. The model can be leveraged to improve the quality of service and resource utilization and reduce the operational cost of serverless platforms. Also, the proposed performance model provides a framework that enables serverless platforms to become workload-aware and operate differently for different workloads to provide a better trade-off between the cost and performance depending on the user's preferences. The current serverless offerings require the user to have extensive knowledge of the internals of the platform to perform efficient deployments. Using the proposed analytical model, the provider can simplify the deployment process by calculating the performance metrics for users even before physical deployments. We validate the applicability and accuracy of the proposed model by extensive experimentation on AWS Lambda. We show that the proposed model can calculate essential performance metrics such as average response time, probability of cold start, and the average number of function instances in the steady-state. Also, we show how the performance model can be used to tune the serverless platform for each workload, which will result in better performance or lower cost without scarifying the other. The presented model assumes no non-realistic restrictions, so that it offers a high degree of fidelity while maintaining tractability at large scale.},
  doi      = {10.1109/TCC.2020.3033373},
}

@InProceedings{Bai2023,
  author    = {Bai, Yiming and Chen, Lei and Lei, Ying and Xie, Hongjuan},
  booktitle = {2023 5th International Conference on Data-driven Optimization of Complex Systems (DOCS)},
  title     = {A Deep Learning Prediction Approach for Machine Workload in Cloud Computing},
  year      = {2023},
  month     = {Sep.},
  pages     = {1-8},
  abstract  = {Accurate workload prediction for cloud computing clusters is essential to ensure Quality of Service (QoS), meet Service Level Agreements (SLAs), and minimize energy consumption. In a cloud computing environment, cloud servers collect and store large sets of time series data, including metrics such as CPU usage, network traffic, and disk I/O at each point in time. The fluctuations in these metrics show noticeable temporal correlations. Therefore, these data can be used in time series data prediction models to predict upcoming workload scenarios. However, traditional statistical methods have limitations such as requiring manual feature extraction, high data requirements, and limited generalizability, leading to inaccurate predictions. In addition, most standard deep learning models ignore the problem of sequence noise. To overcome these hurdles, we have created a hybrid deep learning model utilizing advanced techniques. This model integrates Time Convolutional Networks (TCN), Gated Recurrent Units (GRU), and self-attention mechanism to achieve a more accurate workload prediction. Additionally, we perform a comparative analysis of different methods during the preprocessing stage and select the optimal one to effectively remove noise from the original sequences. Experimental results demonstrate that our proposed model outperforms other workload prediction algorithms in terms of prediction accuracy.},
  doi       = {10.1109/DOCS60977.2023.10294685},
}

@InProceedings{Mokhtari2023,
  author    = {Mokhtari, Ali and Rawls, Drake and Huynh, Tony and Green, Jeremiah and Salehi, Mohsen Amini},
  booktitle = {2023 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)},
  title     = {E2C: A Visual Simulator to Reinforce Education of Heterogeneous Computing Systems},
  year      = {2023},
  month     = {May},
  pages     = {270-277},
  abstract  = {Heterogeneity has been an indispensable aspect of distributed computing throughout the history of these systems. ln particular, with the increasing popularity of accelerator technologies (eg., GPUs and TPUs) and the emergence of domain-specific computing via ASlCs and FPGA, the matter of heterogeneity and understanding its ramifications on the system performance has become more critical than ever before. However, it is challenging to effectively educate students about the potential impacts of heterogeneity on: (a) the performance of distributed systems; and (b) the logic of resource allocation methods to efficiently utilize the resources. Making use of the real infrastructure (such as those offered by the public cloud providers) for benchmarking the performance of heterogeneous machines, for different applications, with respect to different obiectives, and under various workload intensities is cost- and time-prohibitive. Moreover, not all students (globally and nationally) have access or can afford such real infrastructure. To reinforce the quality of learning about various dimensions of heterogeneity, and to decrease the widening gap in education, we develop an open-source simulation tool, called E2C, that can help students researchers and practitioners to study any type of heterogeneous (or homogeneous) computing system and measure its performance under various system configurations. To make the learning curve shallow, E2C is equipped with an intuitive graphical user interface (GU1) that enables its users to easily examine system-level solutions (scheduling, load balancing, scalability, etc.) in a controlled environment within a short time and at no cost. In particular, E2C is a discrete event simulator that offers the following features: (i) simulating a heterogeneous computing system; (ii) implementing a newly developed scheduling method and plugging it into the system, (iii) measuring energy consumption and other output-related metrics; and (iv) powerful visual aspects to ease the learning curve for students. We used E2C as an assignment in the Distributed and Cloud Computing course. Our anonymous survey study indicates that students rated E2C with the score of 87 out of 10 for its usefulness in understanding the concepts of scheduling in heterogeneous computing. Moreover, our pre- and post-evaluations indicate that E2C has improved the students’ understanding of heterogeneous computing systems by around 18%.},
  doi       = {10.1109/IPDPSW59300.2023.00052},
}

@InProceedings{AlShammare2022,
  author    = {Al-Shammare, Haifa and Al-Otaiby, Nehal},
  booktitle = {2022 14th International Conference on Computational Intelligence and Communication Networks (CICN)},
  title     = {An Implementation of a New Proposed Round-Robin Algorithm with Smart Time Quantum in Cloud Computing Environment},
  year      = {2022},
  month     = {Dec},
  pages     = {289-296},
  abstract  = {The popularity of cloud computing platforms has risen dramatically in recent years. As cloud computing serves millions of users at the same time, it must be able to handle all those users' demands efficiently. Thus, choosing a suitable scheduling algorithm is crucial in the cloud computing environment in order to ensure efficient performance with a reasonable degree of quality of service (QoS). The primary goal of this research is to empirically implement and evaluate a recently proposed Round-Robin algorithm with smart time quantum (RR-STQ) in a cloud computing environment, as well as, to enhance the RR-STQ with a dynamic smart time quantum. The CloudSim tool was used to simulate the cloud computing platform to implement RR-STQ and evaluate it with several algorithms using different scenarios. In addition, three scheduling performance metrics were used in the evaluation process. In all comparison scenarios, the (RR-STQ) achieved a significant improvement rate in terms of average response time (RT). Moreover, (RR-STQ) has a better performance in the average turnaround time (TAT), waiting time (WT), and response time (RT) than the traditional RR algorithm. Also, the implemented algorithm (RR-STQ) with dynamic time quantum has a better performance than static time quantum. Based on the evaluation results, it is beneficial to integrate the RR algorithm with other scheduling models such as shortest job first (SJF) to enhance the WT and TAT. Furthermore, the investigations revealed that the dynamic time quantum improves the performance of the RR algorithm.},
  doi       = {10.1109/CICN56167.2022.10008330},
  issn      = {2472-7555},
}

@Article{AlEidi2023,
  author   = {Al-Eidi, Shorouq and Amsaad, Fathi and Darwish, Omar and Tashtoush, Yahya and Alqahtani, Ali and Niveshitha, Niveshitha},
  journal  = {IEEE Access},
  title    = {Comparative Analysis Study for Air Quality Prediction in Smart Cities Using Regression Techniques},
  year     = {2023},
  issn     = {2169-3536},
  pages    = {115140-115149},
  volume   = {11},
  abstract = {In smart cities, air pollution has detrimental impacts on human physical health and the quality of living environment. Therefore, correctly predicting air quality plays an important effective action plan to mitigate air pollution and create healthier and more sustainable environments. Monitoring and predicting air pollution is crucial to empower individuals to make informed decisions that protect their health. This research presents a comprehensive comparative analysis focused on air quality prediction using three distinct regression techniques- Random Forest regression, Linear regression, and Decision Tree regression. The main goal of this study is to discern the most effective model by considering a range of evaluation criteria, including Mean Absolute Error and  $R^{2}$  measures. Moreover, it considers the crucial aspects of minimizing prediction errors and enhancing computational efficiency by evaluating the regression models within two frameworks. The findings of this study underscore the superiority of the Decision Tree regression approach over the other models, demonstrating its exceptional accuracy with a high  $R^{2}$  score and a minimal error rate. Moreover, integrating cloud computing technology has resulted in substantial improvements in the execution time of these approaches. This technology enhancement significantly affects the overall efficiency of the air quality prediction process. By leveraging distributed computing resources, real-time air quality forecasting becomes feasible, enabling timely decision-making and proactive measures to address air pollution episodes effectively.},
  doi      = {10.1109/ACCESS.2023.3323447},
}

@InProceedings{Yιlmaz2023,
  author    = {Yιlmaz, Ömer Zekvan and Alagöz, Fatih},
  booktitle = {2023 14th International Conference on Network of the Future (NoF)},
  title     = {Shared Network Function Placement for Cloud Native 5G Core Networks},
  year      = {2023},
  month     = {Oct},
  pages     = {103-107},
  abstract  = {Providing adequate operating resources for Network Functions (NFs) with minimal costs has been one of the primary concerns for cloud providers. The adequate operating resources definition has to cover the quality of service (QoS) constraints, which result in ‘underutilized resources’. Studies in the NF placement domain that make use of these resources through sharing, employ NP-Hard algorithms. In this study, we propose an NF placement scheme called Cloud Native Network Function Sharing (CNFSH) using a priority-based load balancer and a polynomial time algorithm for dynamic 5G settings. Using CNFSH, the number of satisfied slice requests increases by 36%, and the average resource consumption per network slice drops by 28% compared to the NoShare model. Besides being dynamic and sustainable, CNFSH outperforms a previous sharing scheme [1], with 5% success rate for both of the metrics.},
  doi       = {10.1109/NoF58724.2023.10302780},
  issn      = {2833-0072},
}

@InProceedings{Jeevitha2022,
  author    = {B K, Jeevitha and J, Thriveni},
  booktitle = {2022 IEEE International Conference for Women in Innovation, Technology & Entrepreneurship (ICWITE)},
  title     = {Data Storage Security and Privacy in Cloud Computing},
  year      = {2022},
  month     = {Dec},
  pages     = {1-10},
  abstract  = {The world has seen a quick transition from hard devices for local storage to massive virtual data centers, all possible because of cloud storage technology. Businesses have grown to be scalable, meeting consumer demands on every turn. Cloud computing has transforming the way we do business making IT more efficient and cost effective that leads to new types of cybercrimes. Securing the data in cloud is a challenging task. Cloud security is a mixture of art and science. Art is to create your own technique and technologies in such a way that the user should be authenticated. Science is because you have to come up with ways of securing your application. Data security refers to a broad set of policies, technologies and controls deployed to protect data application and the associated infrastructure of cloud computing. It ensures that the data has not been accessed by any unauthorized person. Cloud storage systems are considered to be a network of distributed data centers which typically uses cloud computing technologies like virtualization and offers some kind of interface for storing data. Virtualization is the process of grouping the physical storage from multiple network storage devices so that it looks like a single storage device.Storing the important data in the cloud has become an essential argument in the computer territory. The cloud enables the user to store the data efficiently and access the data securely. It avoids the basic expenditure on hardware, software and maintenance. Protecting the cloud data has become one of the burdensome tasks in today’s environment. Our proposed scheme "Certificateless Compressed Data Sharing in Cloud through Partial Decryption" (CCDSPD) makes use of Shared Secret Session (3S) key for encryption and double decryption process to secure the information in the cloud. CC does not use pairing concept to solve the key escrow problem. Our scheme provides an efficient secure way of sharing data to the cloud and reduces the time consumption nearly by 50 percent as compared to the existing mCL-PKE scheme in encryption and decryption process.Distributed Cloud Environment (DCE) has the ability to store the da-ta and share it with others. One of the main issues arises during this is, how safe the data in the cloud while storing and sharing. Therefore, the communication media should be safe from any intruders residing between the two entities. What if the key generator compromises with intruders and shares the keys used for both communication and data? Therefore, the proposed system makes use of the Station-to-Station (STS) protocol to make the channel safer. The concept of encrypting the secret key confuses the intruders. Duplicate File Detector (DFD) checks for any existence of the same file before uploading. The scheduler as-signs the work of generating keys to the key manager who has less task to complete or free of any task. By these techniques, the proposed system makes time-efficient, cost-efficient, and resource efficient compared to the existing system. The performance is analysed in terms of time, cost and resources. It is necessary to safeguard the communication channel between the entities before sharing the data. In this process of sharing, what if the key manager’s compromises with intruders and reveal the information of the user’s key that is used for encryption. The process of securing the key by using the user’s phrase is the key concept used in the proposed system "Secure Storing and Sharing of Data in Cloud Environment using User Phrase" (S3DCE). It does not rely on any key managers to generate the key instead the user himself generates the key. In order to provide double security, the encryption key is also encrypted by the public key derived from the user’s phrase. S3DCE guarantees privacy, confidentiality and integrity of the user data while storing and sharing. The proposed method S3DCE is more efficient in terms of time, cost and resource utilization compared to the existing algorithm DaSCE (Data Security for Cloud Environment with Semi Trusted Third Party) and DACESM (Data Security for Cloud Environment with Scheduled Key Managers).For a cloud to be secure, all of the participating entities must be secure. The security of the assets does not solely depend on an individual's security measures. The neighbouring entities may provide an opportunity to an attacker to bypass the user's defences. The data may compromise due to attacks by other users and nodes within the cloud. Therefore, high security measures are required to protect data within the cloud. Cloudsim allows to create a network that contains a set of Intelligent Sense Point (ISP) spread across an area. Each ISPs will have its own unique position and will be different from other ISPs. Cloud is a cost-efficient solution for the distribution of data but has the challenge of a data breach. The data can be compromised of attacks of ISPs. Therefore, in OSNQSC (Optimized Selection of Nodes for Enhanced in Cloud Environment), an optimized method is proposed to find the best ISPs to place the data fragments that considers the channel quality, distance and the remaining energy of the ISPs. The fragments are encrypted before storing. OSNQSC is more efficient in terms of total upload time, total download time, throughput, storage and memory consumption of the node with the existing Betweenness centrality, Eccentricity and Closeness centrality methods of DROPS (Division and Replication of Data in the Cloud for Optimal Performance and Security).},
  doi       = {10.1109/ICWITE57052.2022.10176237},
}

@InProceedings{Thirunavukkarasu2022,
  author    = {Thirunavukkarasu, M. and Shanmugapriya, P.},
  booktitle = {2022 4th International Conference on Inventive Research in Computing Applications (ICIRCA)},
  title     = {Energy Efficient Mobile Cloud offloading for Image Processing Applications using Transfer Learning},
  year      = {2022},
  month     = {Sep.},
  pages     = {910-916},
  abstract  = {Processing real-time images in the digital era is a complex task that requires the use of more sophisticated tools and consumes more energy. With the introduction of Hybrid model, Mobile and Cloud Computing, called as Mobile and Cloud Computing (MCC), this becomes an easy task in which the end user connects using the virtual instance in the Cloud environment. MCC enable the execution of cloud applications through mobile terminals. However, the mobile devices cannot process high end applications as they have limited energy. We propose Mobile Cloud offloading technique that excludes the execution on the Mobile terminal by deploying the applications on Cloud. Identification and decision on the energy aware applications are playing a vital role to improve Quality of Services (QoS). The proposed model introduces the Transfer Learning- based Energy efficient Mobile Cloud offloading framework. The proposed model predicts whether to move the applications towards the Mobile Cloud environment. The proposed model uses InceptionResNetV2 as pre-trained transfer learning approach.. The CNN based classifier used to classify the type of application and the respective energy consumption ratio based on the pre-trained model. The proposed model reduces training period to identify the application and effectively handle the offload process to improve the QoS metrics.},
  doi       = {10.1109/ICIRCA54612.2022.9985529},
}

@Article{Singh2023,
  author   = {Singh, Jaspreet and Walia, Navpreet Kaur},
  journal  = {IEEE Access},
  title    = {A Comprehensive Review of Cloud Computing Virtual Machine Consolidation},
  year     = {2023},
  issn     = {2169-3536},
  pages    = {106190-106209},
  volume   = {11},
  abstract = {In the last decade, users have been able to access their applications, data, and services via the cloud from any location with an internet connection. The scale of heterogeneous cloud environments is continuously growing due to the development of computing-intensive smart devices. The cloud computing system is managed by a data center, which consists of physical machines (PMs) or servers and software-based emulation of PMs called virtual machines(VMs). The deployment of a huge number of physical servers as a result of the exponential development in demand for cloud services has resulted in high energy consumption and ineffective resource usage. Efficient utilization of resources and minimizing power consumption in any data center have become crucial challenges. Virtual machine consolidation (VMC) is a method of optimizing computing resources by consolidating multiple VMs onto a reduced number of PMs. By consolidating VMs and running fewer physical servers, VM consolidation can reduce power consumption and improve resource utilization. This review paper presents a comprehensive analysis of cloud computing virtual machine consolidation, exploring various strategies, benefits, challenges and future trends in this domain. By examining a wide range of literature from the year 2015 to 2023, this review attempts to provide insight into the current state of VM consolidation and its possible effects on the performance and sustainability of cloud computing. The main flaw in the articles is that the various authors focused on different assessment metrics when the emphasis should have been on increasing cloud system service quality and energy efficiency. Future research can be aimed at developing a multi-objective system that emphasizes minimizing cloud energy usage without sacrificing service quality and preventing service level agreements with cloud users from being compromised.},
  doi      = {10.1109/ACCESS.2023.3314613},
}

@InProceedings{Das2022,
  author    = {Das, Souptik and Chakraborty, Sourish and Jana, Dipanjan and Nandy, Rahul and Bhattacharya, Srijan},
  booktitle = {2022 Second International Conference on Computer Science, Engineering and Applications (ICCSEA)},
  title     = {IoT Based Industrial Air Quality Monitoring System},
  year      = {2022},
  month     = {Sep.},
  pages     = {1-4},
  abstract  = {In the past two decades, researchers have accelerated a number of different methods to monitor and reduce air contamination leading to the development of efficient and effective air quality measuring systems using air purifiers. Although, recent technological advancements such as IoT (Internet of Things) with Cloud Computing have allowed researchers to obtain and monitor real-time data. In this report, an IoT-enabled industrial air quality monitoring device is proposed. This device is enabled with an MQ-135 gas sensor for precisely monitoring the air quality and detecting the presence of foreign contaminants such as alcohol. The proposed device also uses a Node MCU ESP S266 Wi-Fi module to efficiently transmit real time data to a smart device (E.g. Smartphone) using an IoT platform.},
  doi       = {10.1109/ICCSEA54677.2022.9936294},
}

@InProceedings{Vidhya2022,
  author    = {Vidhya, M. and Devi, R.},
  booktitle = {2022 11th International Conference on System Modeling & Advancement in Research Trends (SMART)},
  title     = {Comparative Analysis of Scheduling Algorithms in Cloud Computing using CloudSim},
  year      = {2022},
  month     = {Dec},
  pages     = {7-12},
  abstract  = {Cloud computing restructured the entire world of IT by providing shared scalable resources to the organization. Cloud establishes a huge path to find the solution for many major problems found in the industry. Cloud offers virtualized resources such as applications, software, networks, servers, and storage services. Cloud enables all the virtualized resources to clients on a pay-per-use basis. Because of handling the vast request sent by multiple clients and providing more versatile services to the organization, the cloud faces many critical problems such as security issues, dissatisfied Quality-Of-Services, and sometimes an unbalanced load arises. Among those, the most serious problem is balancing the load across the network. Load balancing issues can be handled by scheduling the work eventually to all nodes without overloading any single node. This paper gives an overview idea of different load balancing algorithms and provides comparative results on its quality metrics.},
  doi       = {10.1109/SMART55829.2022.10047689},
  issn      = {2767-7362},
}

@InProceedings{AlSit2022,
  author    = {Al-Sit, Waleed T. and Ateeq, Karamath and Moinuddin, Syed Quadir and Aslam, Shoukat and Rehman, Abdur and Asgher, Tayba and Thawabeh, Ossma Ali},
  booktitle = {2022 International Conference on Cyber Resilience (ICCR)},
  title     = {Direct Trust in Cloud Computing Based on Fuzzy Logic},
  year      = {2022},
  month     = {Oct},
  pages     = {1-6},
  abstract  = {Trust is a powerful aspect, particularly for services using processes in the fields of cybersecurity and information technology. Concerns concerning the dependability of the cloud platform have been raised by individuals and creativity on a number of occasions. In cloud computing, it is advantageous for the customer to select a cloud provider's service for the storing and distribution of their thoughtful content. In this research, a trust model is put forth that evaluates trust using Quality of Service (QoS) metrics. The trust-fuzzy environment has inspired us to employ fuzzy logic to estimate a beneficiary's trustworthiness in a cloudy environment, hence increasing the scheme's effectiveness. Reliability, security, accessibility, response time, and cost make up Quality of Service. All work was completed in MATLAB.},
  doi       = {10.1109/ICCR56254.2022.9995753},
}

@InProceedings{Kumar2022,
  author    = {Kumar, G Suvarna and Priyadarshini, R. and Parmenas, Naik Henokh and Tannady, Hendy and Rabbi, Fazle and Andiyan, Andiyan},
  booktitle = {2022 Sixth International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)},
  title     = {Design of Optimal Service Scheduling based Task Allocation for Improving CRM in Cloud Computing},
  year      = {2022},
  month     = {Nov},
  pages     = {438-445},
  abstract  = {Cloud computing is a service level computing that provide various service to the customers in order to establish an effective customer Relationship management (CRM). This offers various services like virtual machine, self-service provisioning, elasticity computing and storage (pay-as-you-go). Cloud computing provides shared services by enhancing resource management scalability, interoperability and prediction resources as a key to realize the resource utilization with high-performance management metrics. However, when the number of users increase, the process of task scheduling and service allocation using a traditional computing environment will degrade the CRM. In order to address this challenge, this research study proposes an Optimal Service Level Scheduling (OSLS) based task allocation design for improving CRM in cloud computing environment. The Adaptive Service Level Scheduling Algorithm (ASLSA) and the Support Level Load Balancer (SLLB) will reduce the workload in cloud computing environment in order to improve the Quality of Service (QoS) of CRM. This process will optimize the resource utilization in cloud platform based on the service requirement. It provides optimal scheduling features to CRM in order to improve the service optimality based on task and enhance the computational processes such as service load management, heterogeneous service delivery, pricing, resource pools and elasticity. The proposed system leverages high performance when compared to the existing models.},
  doi       = {10.1109/I-SMAC55078.2022.9987392},
  issn      = {2768-0673},
}

@InProceedings{Sandhiya2023,
  author    = {Sandhiya, B and Canessane, R.Aroul},
  booktitle = {2023 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)},
  title     = {An Extensive Study of Scheduling the Task using Load Balance in Fog Computing},
  year      = {2023},
  month     = {March},
  pages     = {1586-1593},
  abstract  = {The proliferation of IoT has resulted in a rise in the demand for services provided by the fog layer, a novel dispersed computing pattern that supplements cloud computing. The fog system enables location awareness and mobility assistance by extending storage and multiplication to the network’s edge, dramatically reducing the issue of service computing in delay-sensitive applications. More requests from more users means more stress for the VMs running in the fog layer. When it comes to fog networks, Load Balancing (LB) is crucial since it prevents some fog nodes from being under- or overworked. Fairly dividing up the fog layer’s burden across the available virtual machines (VMs) is now an absolute must. LB can enhance quality-of-service metrics including cost, response time, performance, and energy ingesting. Although there has been limited investigation of load complementary techniques in fog networks in recent years, no comprehensive analysis has been conducted to compile this information. This article takes a systematic look at the various load-balancing procedures in fog computing, categorizing it as either approximate, precise, fundamental, or hybrid. In addition, the study explores (Load Balancing) LB metrics, including the benefits and drawbacks of the techniques used for fog networks. There is also an examination of the methods and instruments used in the aforementioned evaluations of each research under consideration. The most unanswered questions and emerging tendencies for these algorithms are also covered. In the final section, the study suggests potential avenues for further research.},
  doi       = {10.1109/ICSCDS56580.2023.10105030},
}

@Article{Singh2023a,
  author   = {Singh, Jagdeep and Singh, Parminder and Hedabou, Mustapha and Kumar, Neeraj},
  journal  = {IEEE Transactions on Vehicular Technology},
  title    = {An Efficient Machine Learning-Based Resource Allocation Scheme for SDN-Enabled Fog Computing Environment},
  year     = {2023},
  issn     = {1939-9359},
  month    = {June},
  number   = {6},
  pages    = {8004-8017},
  volume   = {72},
  abstract = {Fog computing is an emerging technology which enables computing resources accessibility close to the end-users. It overcomes the drawbacks of available network bandwidth and delay in accessing the computing resources as observed in cloud computing environment. Resource allocation plays an important role in resource management in a fog computing environment. However, the existing traditional resource allocation techniques in fog computing do not guarantee less execution time, reduced energy consumption, and low latency requirements which is a pre-requisite for most of the modern fog computing-based applications. The complex fog computing environment requires a robust resource allocation technique to ensure the quality and optimal resource usage. Motivated from the aforementioned challenges and constraints, in this article, we propose a resource allocation technique for SDN-enabled fog computing with Collaborative Machine Learning (CML). The proposed CML model is integrated with the resource allocation technique for the SDN-enabled fog computing environment. The FogBus and iFogSim are deployed to test the results of the proposed technique using various performance evaluation metrics such as bandwidth usage, power consumption, latency, delay, and execution time. The results obtained are compared with other existing state-of-the-art techniques using the aforementioned performance evaluation metrics. The results obtained show that the proposed scheme reduces 19.35% processing time, 18.14% response time, and 25.29% time delay. Moreover, compared to the existing techniques, it reduces 21% execution time, 9% network usage, and 7% energy consumption.},
  doi      = {10.1109/TVT.2023.3242585},
}

@InProceedings{Tiwana2023,
  author    = {Tiwana, Pardeep Singh and Singh, Jaspreet},
  booktitle = {2023 International Conference on Artificial Intelligence and Smart Communication (AISC)},
  title     = {Load Optimization Accessions, Ramification the QoS in Software Defined Networking},
  year      = {2023},
  month     = {Jan},
  pages     = {1013-1017},
  abstract  = {It is difficult to manage traditional networks due to network growth, an increase in user numbers, and the emergence of new technologies like big data and cloud computing. Consequently, it is required to alter the current network design. SDN is a well-liked architecture because it offers customizable control and centralized management in data centers. To achieve scalability and dependability, it was necessary to propose the geographical dispersal of a logically centralized control plane due to the huge scale of networks. Software-defined networking (SDN) load-balancing optimization has been studied for a long time. Many approaches to the load-balancing conundrum have been put forth by researchers, but very few have taken the impact of transmission delay between controllers and switches under heavy network load into account. In this article we elaborate the various techniques of load balancing in SDN those working on different areas like multi-controller, switch migration, multi-agent, strategy, time sharing, prediction, reinforcement learning etc. We discuss the methods used along with the advantages and disadvantages of various costs, service quality, and network performance metrics.},
  doi       = {10.1109/AISC56616.2023.10085328},
}

@InProceedings{Srivastava2023,
  author    = {Srivastava, Manoj Kumar and Joshi, Vijay K.},
  booktitle = {2023 10th International Conference on Computing for Sustainable Global Development (INDIACom)},
  title     = {Efficient Consolidation of VMs Systems in the Cloud to Reduce Energy Use},
  year      = {2023},
  month     = {March},
  pages     = {1510-1514},
  abstract  = {The energy needs of cloud computing systems are very high. Cloud suppliers, in order to keep their services available, need to reduce the amount of power their platforms need without sacrificing quality of service. As a result, studies have recommended a cloud-specific architecture that optimizes energy use throughout the whole computer infrastructure. The suggested method was developed in the CloudSim simulator, and the results of the associated simulations suggest that power consumption may be substantial and varies depending on parameters like the quantum variable, data size, and the number of VMs operating on a host. It is possible to establish a variety of resource allocation and planning methods for amassing virtual machines (VMs) on fewer hosts while still maintaining critical metrics, making cloud technology the first step towards sustainable energy. In this study, we first outline the taxonomy of VM placement approaches before proposing new iterative placement strategies that dynamically adjust their placement judgments based on host load Swarm Bee inspired improved Threshold.},
}

@InProceedings{Kavitha2023,
  author    = {Kavitha, J and Rao, P S V Srinivasa and Babu, G Charles},
  booktitle = {2023 Second International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)},
  title     = {Energy Efficient Resource Utilization of Cloud Computing Environments for Deployment Models},
  year      = {2023},
  month     = {Aug},
  pages     = {1111-1119},
  abstract  = {This research study focuses on optimizing resource allocation to reduce energy consumption in cloud-based systems. This study explores various techniques and algorithms employed to achieve energy efficiency, such as dynamic workload consolidation, virtual machine migration, and power-aware scheduling. This study emphasizes the importance of considering energy efficiency alongside performance metrics while making resource management decisions. The proposed methods intend to minimize energy wastage and carbon footprint while maintaining Quality of Service (QoS) and cost-effectiveness. Ultimately, this research contributes to the sustainable development and greener operation of cloud computing infrastructures.},
  doi       = {10.1109/ICAISS58487.2023.10250648},
}

@InProceedings{Saadouni2023,
  author    = {Saadouni, Rafika and Khacha, Amina and Harbi, Yasmine and Gherbi, Chirihane and Harous, Saad and Aliouat, Zibouda},
  booktitle = {2023 15th International Conference on Innovations in Information Technology (IIT)},
  title     = {Secure IIoT networks with hybrid CNN-GRU model using Edge-IIoTset},
  year      = {2023},
  month     = {Nov},
  pages     = {150-155},
  abstract  = {Industrial Internet of Things (IIoT), or Industry 4.0, is an application of IoT in the industrial sector. Its main objective is to enhance product quality and optimize production costs by leveraging advanced technologies such as edge/fog/cloud computing, 5G/6G, and artificial intelligence. In the context of Industry 4.0, numerous devices and systems are interconnected to provide seamless services to users. However, with this interconnection comes the need to protect these devices and the information they transmit from cyberthreats and intrusions. In order to tackle this challenge, our proposed solution involves the utilization of deep learning (DL) models to develop an anomaly-based detection system. Our approach involves two powerful DL models, namely Convolutional Neural Networks (CNN) and Gated Recurrent Units (GRU). The proposed model’s performance is studied within binary and multiclass classification using a new real-world industrial traffic dataset called Edge-IIoTset. The outcomes of our experiments showcased the efficacy of the CNN-GRU model that we proposed, surpassing the performance of recent related works in terms of performance metrics, including accuracy, precision, false positive rate, and detection cost. The combination of the two models CNN and GRU outperforms the GRU model with 88% of detection cost in multiclass classification for one traffic flow.},
  doi       = {10.1109/IIT59782.2023.10366486},
  issn      = {2473-2052},
}

@InProceedings{Khayyat2023,
  author    = {Khayyat, Mashael M. and Aboulola, Omar A.},
  booktitle = {2023 International Conference on Smart Computing and Application (ICSCA)},
  title     = {Implementing an Ambient Air Quality Monitoring System in Spaces with Inadequate Ventilation using the Internet of Things},
  year      = {2023},
  month     = {Feb},
  pages     = {1-6},
  abstract  = {Improving quality of life can be one of the most important outcomes of health care policies. Researchers have proven the role of technology in enhancing the quality of life. The Internet of Things (IoT) concept employs technology in an integrated manner by connecting smart devices, sensors, data, and channels, in order to enhance communication between things and to facilitate life in a smart way. Thus, IoT utilizes a great amount of data coming from these devices and produces stories and clear pictures about what is going on especially since the emergence of big data and cloud computing paradigms. The objective of this paper is to introduce IoT, explain how to calculate the Air Quality Index for Gulf Cooperation Council countries, and to provide evidence of the importance of implementing air quality monitoring systems in tunnels since their architecture limits airflow; therefore it can be assumed that pollutants are trapped. Results from the data generated by the system implemented measures air quality in the tunnel on King Abdulaziz Road in Makkah that shows air quality in such spaces should be monitored and proper actions need to be considered to avoid health problems to ensure quality of life.},
  doi       = {10.1109/ICSCA57840.2023.10087523},
}

@InProceedings{Yekta2023,
  author    = {Yekta, Mohammad and Shahhoseini, Hadi Shahriar},
  booktitle = {2023 13th International Conference on Computer and Knowledge Engineering (ICCKE)},
  title     = {A Review on Machine Learning Methods for Workload Prediction in Cloud Computing},
  year      = {2023},
  month     = {Nov},
  pages     = {306-311},
  abstract  = {Workload prediction is one of the critical parts of resource provisioning in cloud computing and its evolved branches such as serverless and edge computing. Effective resource provisioning stands as a crucial element within the realm of edge-cloud computing. Accurate prediction of cloud workloads is essential for the effective allocation of resources. Workload prediction plays a crucial role in enhancing efficiency, reducing costs, optimizing cloud performance, maintaining a high level of quality of service, and minimizing energy consumption. In this paper, we conduct a comprehensive review of state-of-the-art Machine Learning (ML) and Deep Learning (DL) algorithms employed in workload prediction in cloud computing and other similar platforms such as edge computing. We compared the selected papers in terms of utilized methods and techniques, predicted factors, accuracy metrics, and the dataset. Additionally, to facilitate usability and comparison, articles sharing similar advantages and disadvantages are organized into a table. Finally, the paper concludes by addressing current challenges and future research directions.},
  doi       = {10.1109/ICCKE60553.2023.10326297},
  issn      = {2643-279X},
}

@InProceedings{GayathriHegde2022,
  author    = {M, Gayathri Hegde and M, Shrishti Bekal and Prasad, Srinidhi S and Shenoy, P Deepa and K R, Venugopal},
  booktitle = {2022 IEEE 7th International Conference on Recent Advances and Innovations in Engineering (ICRAIE)},
  title     = {Analysis of Secure EHR Storage Methods on Blockchain and Integrating ML to Predict Chronic Kidney Disease},
  year      = {2022},
  month     = {Dec},
  pages     = {250-255},
  volume    = {7},
  abstract  = {An Electronic Health Record(EHR) is the digital form of the patient’s health data, including vital signs, demographic details, clinical notes, X-rays, medical images, etc. When discussing EHR processing and management, storing this vast information is the main challenge. Although cloud computing’s centralized storage model is one of the best ways to store large amounts of data, it is not secure. Blockchain technology has the potential to revolutionize EHR storage systems and provide data security. Directly keeping the vast EHR data on blockchain may be costly and inefficient. The best method to store the data is off-chain in a Blockchain-based EHR system. Implementing machine learning (ML) in the healthcare industry aims to anticipate diseases earlier so patients can receive higher-quality medical care. Integrating these two disruptive data-driven technologies can highly improve the quality of healthcare. First, this paper analyzes three different off-chain EHR storage methods: Storj, InterPlanetary File System(IPFS), and CosmosDB, based on their Storage and Access Time. From the experimental results, IPFS has the fastest Storage and Access Time. Second, we integrate blockchain and ML technology to predict Chronic Kidney Disease(CKD) from the CKD dataset stored on the IPFS. Finally, using IPFS storage, a record is accessed, and the prediction time is 0.4 sec for detecting CKD or NOCKD is measured.},
  doi       = {10.1109/ICRAIE56454.2022.10054247},
}

@InProceedings{Sefati2023,
  author    = {Sefati, Seyed Salar and Halunga, Simona},
  booktitle = {2023 12th International Conference on Modern Circuits and Systems Technologies (MOCAST)},
  title     = {Service Recommendation for a Group of Users on the Internet of Things Using the Most Popular Service},
  year      = {2023},
  month     = {June},
  pages     = {1-4},
  abstract  = {With the emergence of the Internet of Things (IoT), advanced technologies like fog and cloud computing have been harnessed to create dynamic, real-time platforms addressing the needs of modern decision-makers. Crucial to this process is the recommendation of services tailored to each user's requirements in IoT settings, with the potential for improved Quality of Service (QoS) and Quality of Experience (QoE). The presented method in this paper leverages sensors, services, and fog computing within IoT systems to enhance QoS and adapt to user feedback. The approach involves ranking QoS of services based on Reliability, Availability, and Cost (RAC), and identifying the Most Popular Service (MPS) previously selected by the user. Comparison with Co-Scheduling System for Fog-node Recommendation and Load Management (CoS_FRLM) and User Characteristics-Collaborative Filtering (UCCF) demonstrates our method's effectiveness in maximizing recall, precision, and f-measure, as tested with the Network Simulator (NS3).},
  doi       = {10.1109/MOCAST57943.2023.10176696},
}

@Article{Qin2022,
  author   = {Qin, Zhenquan and Ye, Jin and Meng, Jie and Lu, Bingxian and Wang, Lei},
  journal  = {IEEE Transactions on Computational Social Systems},
  title    = {Privacy-Preserving Blockchain-Based Federated Learning for Marine Internet of Things},
  year     = {2022},
  issn     = {2329-924X},
  month    = {Feb},
  number   = {1},
  pages    = {159-173},
  volume   = {9},
  abstract = {The marine Internet of things (MIoT) is the application of the Internet of things technology in the marine field. Nowadays, with the arrival of the era of big data, the MIoT architecture has been transformed from cloud computing architecture to edge computing architecture. However, due to the lack of trust among edge computing participants, new solutions with higher security need to be proposed. In the current solutions, some use blockchain technology to solve data security problems while some use federated learning technology to solve privacy problems, but these methods neither combine with the special environment of the ocean nor consider the security of task publishers. In this article, we propose a secure sharing method of MIoT data under an edge computing framework based on federated learning and blockchain technology. Combining its special distributed architecture with the MIoT edge computing architecture, federated learning ensures the privacy of nodes. The blockchain serves as a decentralized way, which stores federated learning workers to achieve nontampering and security. We propose a concept of quality and reputation as the metrics of selection for federated learning workers. Meanwhile, we design a quality proof mechanism [proof of quality (PoQ)] and apply it to the blockchain, making the edge nodes recorded in the blockchain more high-quality. In addition, a marine environment model is built in this article, and the analysis based on this model makes the method proposed in this article more applicable to the marine environment. The numerical results obtained from the simulation experiments clearly show that the proposed scheme can significantly improve the learning accuracy under the premise of ensuring the safety and reliability of the marine environment.},
  doi      = {10.1109/TCSS.2021.3100258},
}

@InProceedings{Abbasi2022,
  author    = {Abbasi, Rabiya and Martinez, Pablo and Ahmad, Rafiq},
  booktitle = {2022 10th International Conference on Control, Mechatronics and Automation (ICCMA)},
  title     = {Data Acquisition and Monitoring Dashboard for IoT Enabled Aquaponics Facility},
  year      = {2022},
  month     = {Nov},
  pages     = {168-172},
  abstract  = {Aquaponics is an emerging field of agriculture that has great potential to ensure food security and sustainability. It presents a closed-loop ecosystem that synergizes fish farming (aquaculture) and soilless plant growing (hydroponics). As aquaponics is a simulation of a natural ecosystem, a significant number of factors are involved in its management. For instance, constant monitoring of water quality, environmental parameters, and illumination is required to achieve healthy growth of fish and plants. In combination with cloud computing technology, the internet of things (IoT) provides a platform to collect data, monitor systems, detect abnormal conditions, and rectify problems in the system without human intervention. This research project presents a framework that involves the development of a cloud-based dashboard for data acquisition and monitoring of an aquaponics facility. The data from a wireless sensing module (measuring pH, water temperature, electroconductivity, light intensity, air humidity, and air temperature) and several cameras installed in an aquaponics farm are uploaded wirelessly to the dashboard. These images are saved on the dashboard with their relevant sensor measurements. The user (farmer or aquaponics practitioner) can get real-time insights regarding the farm’s performance with this information. It can also be used for the creation of future smart applications that can perform and showcase short and long-term predictions.},
  doi       = {10.1109/ICCMA56665.2022.10011594},
}

@InProceedings{ChangoCanaveral2022,
  author    = {Chango - Cañaveral, Patricia Marisol and Esperanza Jaya- Jaramillo, Doris and Quezada- Sarmiento, Pablo Alejandro and Teodomiro Salas - Álvarez, Wilson},
  booktitle = {2022 17th Iberian Conference on Information Systems and Technologies (CISTI)},
  title     = {Analysis of the Quality Service of the Hotel Villa Colonial through the Servqual method and Cloud Computing tools},
  year      = {2022},
  month     = {June},
  pages     = {1-7},
  abstract  = {The objective of this article was to analyze the quality service through the Servqual model at the Villa Colonial Hotel in the Malacatos parish. The methodology used established as an object of study the application of the Servqual model, which allowed measuring customer service satisfaction, which is made up of five dimensions such as: reliability, responsiveness, security, empathy, and tangible elements. The information was collected through the application of structured interviews to 218 guests in two phases: in the first phase, data was acquired regarding the expectation of the services offered by the hotel and in the second phase, data was collected on the perception of the services provided. In the evaluation of the gap, it was possible to identify 11 shortcomings in customer service, ¿the most punctuated deficiency is item 16 Does the staff care about satisfying the needs of the clients? the perception does not exceed the expectations of the client and is qualified as dissatisfied. The results obtained were used to design an improvement plan to overcome the shortcomings identified in the hotel. Finally, it should be noted that the entire development and implementation process was supported with cloud computing tools.},
  doi       = {10.23919/CISTI54924.2022.9820438},
  issn      = {2166-0727},
}

@InProceedings{Thakur2023,
  author    = {Thakur, Rahul},
  booktitle = {2023 2nd International Conference on Edge Computing and Applications (ICECAA)},
  title     = {Bioinspired Sensory Gating in the Artificial Vision System},
  year      = {2023},
  month     = {July},
  pages     = {1163-1167},
  abstract  = {When viewed as an enterprise, the healthcare system has important security and privacy requirements, such as protecting patient medical records from unauthorized access, tracking protected drugs, securely connecting to transportation such as ambulances, and conducting secure and intelligent e-health surveillance. Blockchain has introduced new ideas in medical data security and safety, and with the right security measures, it may eliminate the tension between sharing data and maintaining anonymity. In this study, the benefits of cloud computing are integrated with blockchain to offer a secrecy technique for blockchain and IoT. In addition to incorporating IoT and providing IoT solutions to blockchain nodes, this method also collects, analyzes, uses, and maintains identity authentication for health information. Interface and overcomes the insufficient computer power of particular blockchain chain routers to verify the data's feasibility and authenticity order to verify the feasibility and authenticity of the data. The simulation experiment shows that the suggested technique is effective. It may handle problems like high computer intricacy, data interchange, and privacy protection while maintaining and confirming the quality of medical data.},
  doi       = {10.1109/ICECAA58104.2023.10212187},
}

@InProceedings{Srivastava2023a,
  author    = {Srivastava, Arun Pratap and Madan, Parul and Sharma, Gunjan and Shrivastava, Anurag and Singh, Yograj and Salim, Mohd.},
  booktitle = {2023 IEEE World Conference on Applied Intelligence and Computing (AIC)},
  title     = {Bioinspired Sensory Gating in the Artificial Vision System},
  year      = {2023},
  month     = {July},
  pages     = {735-739},
  abstract  = {When viewed as an enterprise, the healthcare system has important security and privacy requirements, such as protecting patient medical records from unauthorized access, tracking protected drugs, connecting to transportation such as ambulances securely, and conducting secure and intelligent e-health surveillance. Block chain has introduced new ideas in medical data security and safety, and with the right security measures, it may eliminate the tension between sharing data and maintaining anonymity. In this study, we integrate the benefits of cloud computing with block chain to offer a secrecy technique for block chain and IoT. In addition to incorporating IoT and providing Iot solutions to block chain nodes, this method also collects, analyzes, uses, and maintains identity authentication for health information. Interface and overcomes the insufficient computer power of particular blockchainchain routers to verify the data's feasibility and authenticity order to verify the feasibility and authenticity of the data. The simulation experiment shows that the suggested technique is effective. It may handle problems like high computer intricacy, data interchange, and privacy protection while maintaining and confirming the quality of medical data.},
  doi       = {10.1109/AIC57670.2023.10263944},
}

@Article{Huang2023c,
  author   = {Huang, Siqi and Xie, Jiang and Muslam, Muhana Magboul Ali},
  journal  = {IEEE Transactions on Cloud Computing},
  title    = {A Cloud Computing Based Deep Compression Framework for UHD Video Delivery},
  year     = {2023},
  issn     = {2168-7161},
  month    = {April},
  number   = {2},
  pages    = {1562-1574},
  volume   = {11},
  abstract = {Ultra-high-definition (UHD) videos are enjoying increased popularity in people's daily usage because of the good visual experience. However, the data size of UHD videos is 4-16 times larger of HD videos. This will bring many challenges to existing video delivery systems, such as the shortage of network bandwidth resources and longer network transmission latency. In this article, we propose a cloud computing based deep compression framework named Pearl, which utilizes the power of deep learning and cloud computing to compress UHD videos. Pearl compresses UHD videos from two respects: the frame resolution and the colorful information. In pearl, an optimal compact representation of the original UHD video is learned with two deep convolutional neural networks (DCNNs): super resolution CNN (SR-CNN) and colorization CNN (CL-CNN). SR-CNN is used to reconstruct a high resolution video from a low resolution video while CL-CNN is adopted to preserve the color information of the video. Pearl focuses on video content compression in two new directions. Thus, it can be integrated with any existing video compression system. With Pearl, the data size of UHD videos can be significantly reduced. We evaluate the performance of Pearl with a wide variety of network conditions, quality of experience (QoE) metrics, and video properties. In all considered scenarios, Pearl can further compress 84% of video size and reduce 73% of network transmission latency.},
  doi      = {10.1109/TCC.2022.3149420},
}

@InProceedings{Lokesh2023,
  author    = {Lokesh, Gudivada and Baseer, K. K.},
  booktitle = {2023 2nd International Conference on Edge Computing and Applications (ICECAA)},
  title     = {An Architecture for Dynamic Load Balancing in Cloud Environment},
  year      = {2023},
  month     = {July},
  pages     = {84-91},
  abstract  = {Clouds are highly customizable infrastructures that offer a platform as a service and let customers subscribe on a pay-as-you-go basis to their requirements. The straightforward service-oriented cloud computing model is gaining popularity around the world. The number of people using the Cloud is constantly growing. Clouds use modern data centers to manage a massive number of users. The reliability of the Cloud depends on load balancing. Balancing virtual machine loads lowers energy consumption and task rejections by optimizing resource utilization. One can increase performance while using fewer resources using load balancing, resource management, quality of service, etc. The difficulty of overloading and underloading virtual machines in cloud computing can be lessened by load balancing in the Cloud.This research study thoroughly examined the load-balancing algorithms found in the literature. First, the traditional approaches are analyzed before moving on to more recent work on load balancing with heterogeneous techniques. Along with the tools available for the current investigation, various metrics are used to evaluate the load-balancing algorithms. The proposed article will primarily serve to assist in the development of new algorithms in the future.},
  doi       = {10.1109/ICECAA58104.2023.10212311},
}

@InProceedings{Chen2022b,
  author    = {Chen, Fan and Du, Yugen and Zhong, Wenhao and Wang, Hanting},
  booktitle = {2022 IEEE Smartworld, Ubiquitous Intelligence & Computing, Scalable Computing & Communications, Digital Twin, Privacy Computing, Metaverse, Autonomous & Trusted Vehicles (SmartWorld/UIC/ScalCom/DigitalTwin/PriComp/Meta)},
  title     = {Web Service QoS Prediction Based on Reputation and Location Aware Matrix Factorization},
  year      = {2022},
  month     = {Dec},
  pages     = {1722-1729},
  abstract  = {With the development of cloud computing and Internet technologies, the number of Web services has increased dramatically. It is increasingly difficult for users to locate applicable services among a large number of functionally equivalent candidates. Considering the high cost of time and resources, users cannot invoke all Web services to obtain the desired quality of service (QoS). Therefore, the problem of QoS prediction of Web services has attracted much attention in recent years. Although QoS is often used as a measure of Web service performance, the value of QoS may vary significantly between users depending on their network and geographical location. Furthermore, most traditional approaches perform QoS prediction directly based on historical QoS values provided by users. However, these historical QoS data may contain unreliable values from unreliable users, resulting in significantly lower prediction accuracy. To overcome the above limitations, we propose a reputation and location aware matrix factorization (RLMF) approach for QoS prediction of Web services in this paper. First, we cluster the users and calculate their reputation based on the clustering information through Dirichlet distribution. Then, we integrate the user’s reputation and location information into the matrix factorization model to obtain more accurate prediction results. Additionally, we use Cauchy loss to measure the difference between the observed and predicted QoS values, which makes our approach robust to even outliers. We conducted experiments on a largescale dataset of 1,974,675 QoS values to evaluate our approach. The experimental results show that our approach performs better than state-of-the-art baseline approaches.},
  doi       = {10.1109/SmartWorld-UIC-ATC-ScalCom-DigitalTwin-PriComp-Metaverse56740.2022.00245},
}

@InProceedings{Cao2023a,
  author    = {Cao, Junling and Xu, Yichuan and Qian, Yuxuan and Chai, Tingyi and Liu, Chang},
  booktitle = {2023 5th Asia Energy and Electrical Engineering Symposium (AEEES)},
  title     = {Multidimensional Full State Water Quality - Electrical Data Mining Method for Intelligent Fishing Grounds Based on Cloud Edge Collaboration},
  year      = {2023},
  month     = {March},
  pages     = {1117-1123},
  abstract  = {Aiming at the problem that the intelligent analysis technology of aquaculture characteristics is difficult to meet the practical application needs of the market, a multi-dimensional full state water quality-electrical data mining method of intelligent fishing grounds based on cloud edge collaboration is proposed. First, based on the cloud edge collaboration architecture, an intelligent fishing ground awareness operation and maintenance system is designed. Through the collaboration of edge computing and cloud computing, the real-time performance of system data monitoring and processing is improved. Then, in the system edge layer, the weighted least square method and BP neural network are used for multidimensional data fusion to ensure the accuracy of monitoring data. Finally, the grey correlation analysis method is applied to the fuzzy comprehensive evaluation, and an improved fuzzy association rule analysis and evaluation model is constructed for the deep mining of full state data, so as to obtain the water quality and electrical safety level. Based on the experimental analysis of the proposed method in Taizhou Jiangyan Fishing Light Complementary Fishing Ground, the results show that the error of the heterogeneous data fusion method is smaller, and its water quality electrical comprehensive evaluation value is between 0.751-0.928, which is the closest to the measured value.},
  doi       = {10.1109/AEEES56888.2023.10114347},
}

@Article{Singhal2023,
  author   = {Singhal, Saurabh and Gupta, Nakul and Berwal, Parveen and Naveed, Quadri Noorulhasan and Lasisi, Ayodele and Wodajo, Anteneh Wogasso},
  journal  = {IEEE Access},
  title    = {Energy Efficient Resource Allocation in Cloud Environment Using Metaheuristic Algorithm},
  year     = {2023},
  issn     = {2169-3536},
  pages    = {126135-126146},
  volume   = {11},
  abstract = {Utility-based computing popularly known as “cloud computing” offers several computing services to the users. Due to the proliferation in the users of cloud computing, there is an unprecedented increase in the demand for computation resources to execute cloud services. Thus, there is a requirement to investigate currently available resources like virtual machines, CPU, RAM, and storage to allocate cloud services. The allocation and QoS of cloud services are highly dependent on allocation schemes. The optimized solutions allocate resources to submitted jobs to reduce the overall cost to the end-users/service provider without degrading the performance of virtual machines. The allocation techniques also consider the harvesting of energy consumption required for running the cloud services. In this paper, we have utilized a Rock Hyrax-based optimization technique to allocate resources to the submitted jobs with reduced energy consumption. The proposed Rock Hyrax algorithm has been simulated on the CloudSim simulator for various scenarios. The performance of the proposed algorithm has been measured over various Quality of Service (QoS) parameters such as makespan, energy efficiency, response time, throughput, and cost. The gathered results validate the proposed algorithm that improves the QoS parameters by 3%-8% as compared to algorithms when both jobs and resources are considered to be dynamic in nature.},
  doi      = {10.1109/ACCESS.2023.3330434},
}

@InProceedings{ZalokostasDiplas2022,
  author    = {Zalokostas-Diplas, Vasileios and Makris, Nikos and Passas, Virgilios and Korakis, Thanasis},
  booktitle = {2022 IEEE Conference on Standards for Communications and Networking (CSCN)},
  title     = {Experimental Evaluation of ML Models for Dynamic VNF Autoscaling},
  year      = {2022},
  month     = {Nov},
  pages     = {157-162},
  abstract  = {Network Functions Virtualization (NFV) is a key aspect deeply integrated in the latest 5G networks, allowing for the provisioning of elastic resources that adapt in a flexible manner based on the overall network demand. The adoption of NFV architectures is empowered through the evolution of cloud-native and hypervisor tools to support service monitoring, and orchestrate the appropriate decisions for provisioning the scale of the network. Such decisions may directly impact the overall quality of service and experience for users, as well as the energy consumption that the resources use. To this aim, machine learning (ML) - driven optimization for these decisions, relying on inferring the values of future monitored metrics, can assist in deciding proactively on the network scale. In this work, we employ three different candidate solutions (statistical, tree- and CNN-based) for determining the scale of network functions deployed within a cluster of resources, subject to the user demand. We compare and evaluate the different schemes in a real testbed environment, and discuss the benefits of ML-driven optimizations against existing state-of-the-art approaches.},
  doi       = {10.1109/CSCN57023.2022.10051112},
}

@InProceedings{Pandey2023,
  author    = {Pandey, Shivani and Mishra, Satanand and Jain, Ravi Kant},
  booktitle = {2023 International Conference on Recent Advances in Electrical, Electronics & Digital Healthcare Technologies (REEDCON)},
  title     = {IoT Interface Device for Sensing Arsenic in Contaminated Water},
  year      = {2023},
  month     = {May},
  pages     = {1-6},
  abstract  = {Water pollution is a serious problem in different parts of the world. In addition, water quality must be monitored to ensure that the water is provided safely for drinking and other purposes. Too high a concentration of Arsenic ions in drinking water is the cause of many health problems, including heart problems, neurological problems, etc. Water sampling and laboratory analysis are required for traditional water quality monitoring. In this paper, we discussed an IoT-based interfacing sensor device for sensing arsenic contaminants in water where IoT cloud computing networks enable the integration of a variety range of mechanical and electronic devices. A Node MCU device is used for data transmission which emphasizes on Wi-Fi-controlled interface devices and IoT-enabled communication protocol for the detection of water contaminants. This system is connected to an IoT cloud platform to store the data for analyzing purposes where Red-Green-Blue (RGB) color detection occurs by identifying the wavelength of contaminants. The system makes use of IoT to display the output in real-time for on-site and off-site monitoring via mobile phone. The system makes use of IoT to display the output in real-time for on-site and off-site monitoring via mobile phone, The major advantage of IoT technology is that it easily connects devices and stores the generated data in the cloud. With the help of command control systems, data can be used for appropriate applications to make human life easier and safer while considering Industry's impact. The acceptable limits set by WHO and the Bureau of Indian Standards for Arsenic are 0.05 mg/litres and 0.01 mg/l respectively. Therefore, a smart and intelligent device that can be used for measuring Arsenic content which is very necessary today to ensure the health of human life in society.},
  doi       = {10.1109/REEDCON57544.2023.10151287},
}

@InProceedings{Manova2022,
  author    = {Manova, Rd Yovi and Sukmadirana, Edi and Nurmanah, Nurma Siti},
  booktitle = {2022 1st International Conference on Information System & Information Technology (ICISIT)},
  title     = {Comparative Analysis of Quality of Service and Performance of MPLS, EoIP and SD-WAN},
  year      = {2022},
  month     = {July},
  pages     = {403-408},
  abstract  = {Software Defined – Wide Area Network (SDWAN) implementation is growing each year as one of the options for enterprise to have hybrid and redundant connection between traditional WAN and Internet. The cloud computing services, whether it is IaaS, PaaS, or SaaS has attracted most of enterprise to separate the corporate data connection from private WAN to public internet securely. This dual data traffic still can be managed by enterprise router, but it will require manual routing or at lease delay with complicated rule to mitigate any link problem. SD-WAN as the development of SDN in wide area network, have the solution to solve the manual routing data, by putting the control plane in a software environment to manage the data traffic virtually. In Indonesia, the SD-WAN technology has been introduced by several vendors and operators, some enterprise still reluctance considering the security of enterprise data through public internet service, and some of them still questioning the Quality of Services compare to legacy or traditional WAN services. Therefore, this research will perform the Quality of Service and Performance of SD-WAN, compare to traditional Multiprotocol Label Switching (MPLS) link and Ethernet over Internet Protocol (EoIP) as one of the contenders. The object of the research is an active WAN of one of Indonesian company, that having those three connections between Jakarta and Surabaya. The QoS and performance are measured using ITU- T G.1010 standard as the reference.},
  doi       = {10.1109/ICISIT54091.2022.9872806},
}

@Article{Kashani2023,
  author   = {Kashani, Mostafa Haghi and Mahdipour, Ebrahim},
  journal  = {IEEE Transactions on Services Computing},
  title    = {Load Balancing Algorithms in Fog Computing},
  year     = {2023},
  issn     = {1939-1374},
  month    = {March},
  number   = {2},
  pages    = {1505-1521},
  volume   = {16},
  abstract = {Recently, fog computing has been introduced as a modern distributed paradigm and complement to cloud computing to provide services. The fog system extends storing and computing to the edge of the network, which can remarkably solve the problem of service computing in delay-sensitive applications besides enabling location awareness and mobility support. Load balancing is an important aspect of fog networks that avoids a situation with some under-loaded or overloaded fog nodes. Quality of service parameters such as resource utilization, throughput, cost, response time, performance, and energy consumption can be improved by load balancing. In recent years, some research in load balancing algorithms in fog networks has been carried out, but there is no systematic study to consolidate these works. This article investigates the load-balancing algorithms systematically in fog computing in four classifications, including approximate, exact, fundamental, and hybrid algorithms. Also, this article investigates load balancing metrics with all advantages and disadvantages related to chosen load balancing algorithms in fog networks. The evaluation techniques and tools applied for each reviewed study are explored as well. Additionally, the essential open challenges and future trends of these algorithms are discussed.},
  doi      = {10.1109/TSC.2022.3174475},
}

@Article{Kong2022b,
  author   = {Kong, Cuiyu and Rimal, Bhaskar Prasad and Reisslein, Martin and Maier, Martin and Bayram, Islam Safak and Devetsikiotis, Michael},
  journal  = {IEEE Transactions on Services Computing},
  title    = {Cloud-Based Charging Management of Heterogeneous Electric Vehicles in a Network of Charging Stations: Price Incentive Versus Capacity Expansion},
  year     = {2022},
  issn     = {1939-1374},
  month    = {May},
  number   = {3},
  pages    = {1693-1706},
  volume   = {15},
  abstract = {This article presents a novel cloud-based charging management system for electric vehicles (EVs). Two levels of cloud computing, i.e., local and remote clouds, are employed to meet the different latency requirements of the heterogeneous EVs while exploiting the lower-cost computing in remote clouds. Specifically, we consider time-sensitive EVs at highway exit charging stations and EVs with relaxed timing constraints at parking lot charging stations. We propose algorithms for the interplay among EVs, charging stations, system operator, and clouds. Considering the contention-based random access for EVs to a 4G Long-Term Evolution network, and the quality of service metrics (average waiting time and blocking probability), the model is composed of: queuing-based cloud server planning, capacity planning in charging stations, delay analysis, and profit maximization. We propose and analyze a price-incentive method that shifts heavy load from peak to off-peak hours, a capacity expansion method that accommodates the peak demand by purchasing additional electricity, and a hybrid method of price incentives and capacity expansion that balances the immediate charging needs of customers with the alleviation of the peak power grid load through price-incentive based demand control. Numerical results demonstrate the effectiveness of the proposed methods and elucidate the tradeoffs between the methods.},
  doi      = {10.1109/TSC.2020.3009084},
}

@Article{Okegbile2022,
  author   = {Okegbile, Samuel D. and Maharaj, Bodhaswar T. and Alfa, Attahiru S.},
  journal  = {IEEE Transactions on Vehicular Technology},
  title    = {A Multi-User Tasks Offloading Scheme for Integrated Edge-Fog-Cloud Computing Environments},
  year     = {2022},
  issn     = {1939-9359},
  month    = {July},
  number   = {7},
  pages    = {7487-7502},
  volume   = {71},
  abstract = {This paper presents a multi-user, multi-class and multi-layer edge computing-based framework for effective task offloading and computation processes. Important system requirements that were not captured in the existing multi-layer solutions such as offloading, computations and deadline requirements were captured in the system modeling, while both wireless communications and task computation constraints were considered. We considered three layers system, where each device offloads its generated tasks in each time slot to any selected layer for computation. On its arrival at such a selected layer, the task is only accepted if the queue size is below the pre-defined threshold, otherwise, such a task is offloaded to the next layer. Tasks were classified into class 1 and class 2 tasks following tasks’ quality of service requirements. We adopted stochastic geometry, parallel computing and queueing theory techniques to model the performance of the considered integrated edge-fog-cloud computing environment and obtained analysis for various performance metrics of interest. The obtained analyses demonstrate the importance of multi-layer and multi-class edge computing systems towards improving the experience of both delay-sensitive and mission-critical applications in any task offloading environment.},
  doi      = {10.1109/TVT.2022.3167892},
}

@InProceedings{Morel2023,
  author    = {Morel, Alicia Esquivel and Calyam, Prasad and Qu, Chengyi and Gafurov, Durbek and Wang, Cong and Thareja, Komal and Mandal, Anirban and Lyons, Eric and Zink, Michael and Papadimitriou, George and Deelman, Ewa},
  booktitle = {2023 International Conference on Computing, Networking and Communications (ICNC)},
  title     = {Network Services Management using Programmable Data Planes for Visual Cloud Computing},
  year      = {2023},
  month     = {Feb},
  pages     = {130-136},
  abstract  = {Visual Cloud Computing (VCC) applications provide highly efficient solutions in video data processing pipelines on edge/cloud infrastructures. These applications and their infrastructures demand end-to-end monitoring and fine-grained application traffic control to meet user quality of experience requirements. In this paper, we propose a novel network services management methodology for VCC applications by leveraging the advantages of programmable data planes enabled by Protocol-independent Packet Processors (P4). Specifically, we define a custom fixed-length application header and use it to improve the performance of a video streaming application through congestion avoidance using Multi-Hop Route Inspection (MRI), a variant of In-band Network Telemetry (INT), and switch port forwarding (tunneling) capabilities. For evaluation experiments, we use P4 per-packet telemetry metadata for routing paths, ingress/egress timestamps, queue occupancy in a given node, and egress port link utilization in a VCC testbed on the NSF-supported FABRIC infrastructure. Our experiment results demonstrate performance improvement obtained with our methodology in terms of both packet loss and throughput metrics.},
  doi       = {10.1109/ICNC57223.2023.10074183},
}

@InProceedings{Gritto2022,
  author    = {Gritto, D. and Muthulakshmi, P.},
  booktitle = {2022 11th International Conference on System Modeling & Advancement in Research Trends (SMART)},
  title     = {Scheduling Cloudlets in a Cloud Computing Environment: A Priority-based Cloudlet Scheduling Algorithm (PBCSA)},
  year      = {2022},
  month     = {Dec},
  pages     = {80-86},
  abstract  = {Cloud computing is a service model that has evolved in its stature beyond its traditional bounds of infrastructure, platform and software as a service. As the surge in resource demand may hit the cloud service provider at any time, a ceaseless monitoring system is vital. The allocation of an appropriate virtual machine for the cloudlet i.e., the user workload and maintaining the work load equilibrium among the resources is the most challenging operation in the cloud environment. The proper utilization of the cloud resources can be ensured by selecting the right cloudlet scheduling and load balancing algorithm(s). The cloudlet scheduling algorithm selection is based on the combination of two or more Quality of Service (QoS) and performance metrics like makespan, throughput, cost, power consumption, virtual machine or resource utilization and load balancing etc. The load balancer module takes the responsibility of dispersing the cloudlets evenly among the virtual machines by considering various features like CPU utilization, number of processing elements, bandwidth, memory and the load limit of the virtual machines. In this paper, an effort has been made to comprehend the most persisting cloudlet scheduling and load balancing algorithms that have been proposed by the researchers. Compiling the load balancing technologies that are integrated with the contemporary cloud platforms such as Amazon Web Services (AWS), Microsoft Azure and Google Cloud Platform (GCP) has also been prioritized. This study suggests a Priority Based Cloudlet Scheduling Algorithm (PBCSA) that schedules the cloudlet according to the user priority. The Min-Min scheduler is used to schedule the high priority cloudlets and the Max-Min scheduler is used to schedule the low priority cloudlets. The experimental findings reveals that, in the majority of scenarios, the proposed algorithm outperforms the Min-Min and Max-Min scheduling in terms of makespan and virtual machine utilization ratio.},
  doi       = {10.1109/SMART55829.2022.10047622},
  issn      = {2767-7362},
}

@Article{Chang2023,
  author   = {Chang, Jiaxin and Wang, Jian and Li, Bing and Zhao, Yuqi and Li, Duantengchuan},
  journal  = {IEEE Transactions on Network and Service Management},
  title    = {Attention-Based Deep Reinforcement Learning for Edge User Allocation},
  year     = {2023},
  issn     = {1932-4537},
  pages    = {1-1},
  abstract = {Edge computing, a recently developed computing paradigm, seeks to extend cloud computing by providing users minimal latency. In a mobile edge computing (MEC) environment, edge servers are placed close to edge users to offer computing resources, and the coverage of adjacent edge servers may partially overlap. Because of the restricted resource and coverage of each edge server, edge user allocation (EUA), i.e., determining the optimal way to allocate users to different servers in the overlapping area, has emerged as a major challenge in edge computing. Despite the NP-hardness of obtaining an optimal solution, it is possible to evaluate the quality of a solution in a short amount of time with given metrics. Consequently, deep reinforcement learning (DRL) can be used to solve EUA by attempting numerous allocations and optimizing the allocation strategy depending on the rewards of those allocations. In this study, we propose the Dual-sequence Attention Model (DSAM) as the DRL agent, which encodes users using self-attention mechanisms and directly outputs the probability of matching between users and servers using an attention-based pointer mechanism, enabling the selection of the most suitable server for each user. Experimental results show that our method outperforms the baseline approaches in terms of allocated users, required servers, and resource utilization, and its running speed meets real-time requirements.},
  doi      = {10.1109/TNSM.2023.3292272},
}

@InProceedings{Sankaran2022,
  author    = {Sankaran, Lakshmi and Saleema, J S and Suleiman, Basem},
  booktitle = {2022 IEEE/ACIS 7th International Conference on Big Data, Cloud Computing, and Data Science (BCD)},
  title     = {Analysis of Workloads for Cloud Services},
  year      = {2022},
  month     = {Aug},
  pages     = {117-123},
  abstract  = {Capturing best quality datasets for a study is the first evidence for better outcomes of research. If the analysis are based on such datasets, then the metrics, the characteristics and few factors determines proof point for well proven theories. Hence it is obvious that we rely on the best possible ways to arrive at such data acquiring sources. It can be either based on historical techniques or from the innovations in application of it to industry. This paper introduces a mapping framework for analyzing, and characterizing data previously used by research community and how they are made to fit for Cloud systems, i.e. using “workloads” and “datasets” as the “refined definitions”. It was contributed in the past two decades within the scientific community setting their own workflow analysis mechanisms. The framework thus is validated by acquiring a sample workload per layer of cloud. The sources are form the literature that are available from existing scientific theories. These workloads are then experimented against the three tiers of the cloud computing ie., IaaS(Infrastructure as a Service), PaaS(Platform as a Service), & SaaS(Software as a Service). The selected data is analyzed by the authors for an offline model presented here based on the Machine Learning tool-kits. There are future studies planned for and to be experimented in a cloud auto scaled environment with online model as well.},
  doi       = {10.1109/BCD54882.2022.9900564},
}

@Article{Deebak2023,
  author   = {Deebak, Bakkiam David and Hwang, Seong Oun},
  journal  = {IEEE Systems Journal},
  title    = {A Cloud-Assisted Medical Cyber-Physical System Using a Privacy-Preserving Key Agreement Framework and a Chebyshev Chaotic Map},
  year     = {2023},
  issn     = {1937-9234},
  month    = {Dec},
  number   = {4},
  pages    = {5543-5554},
  volume   = {17},
  abstract = {At present, communication networks like the Internet of Things (IoT) are emerging with some of the latest technologies, such as artificial intelligence, big data, and cloud computing, to enable wireless edge infrastructures and seamless data migration. In particular, edge-based wireless communications help to gain new insights into the mitigation of potential communicable infections, e.g., COVID-19, via the use of IoT sensing devices. Of late, an evolving technology known as the cloud-assisted medical cyber-physical system (MCPS) has explored various key agreement protocols to examine security weaknesses between sensing devices and medical experts. Unfortunately, the existing schemes address vulnerabilities such as impersonation, privileged insider, and password guessing, whereby the behavior of the system becomes nondeterministic when guarding against malicious intent. Also, failures, faults, and attacks may vary in the characteristic forms of the IoT and the MCPS, causing unforeseen impairments in the system and for users. Thus, this article develops a privacy-preserving key agreement framework (PP-KAF) using the Chebyshev chaotic map mechanism to avoid privacy data disclosures and to protect session keys. The proposed PP-KAF exploits a strategy of two-way authentication not only to protect user identities but also to achieve untraceability from the remote server. Finally, a formal analytical model is applied to examine the properties of the key agreement protocol. Simulation results demonstrate that the proposed PP-KAF can offer better security efficiencies and can mitigate computation and communication overhead to guarantee improved quality metrics, namely, throughput rate and energy consumption.},
  doi      = {10.1109/JSYST.2023.3303460},
}

@InProceedings{Tuli2022a,
  author    = {Tuli, Shreshth and Casale, Giuliano and Jennings, Nicholas R.},
  booktitle = {2022 IEEE 15th International Conference on Cloud Computing (CLOUD)},
  title     = {MetaNet: Automated Dynamic Selection of Scheduling Policies in Cloud Environments},
  year      = {2022},
  month     = {July},
  pages     = {331-341},
  abstract  = {Task scheduling is a well-studied problem in the context of optimizing the Quality of Service (QoS) of cloud computing environments. In order to sustain the rapid growth of computational demands, one of the most important QoS metrics for cloud schedulers is the execution cost. In this regard, several data-driven deep neural networks (DNNs) based schedulers have been proposed in recent years to allow scalable and efficient resource management in dynamic workload settings. However, optimal scheduling frequently relies on sophisticated DNNs with high computational needs implying higher execution costs. Further, even in non-stationary environments, sophisticated schedulers might not always be required and we could briefly rely on low-cost schedulers in the interest of cost-efficiency. Therefore, this work aims to solve the non-trivial meta problem of online dynamic selection of a scheduling policy using a surrogate model called MetaNet. Unlike traditional solutions with a fixed scheduling policy, MetaNet on-the-fly chooses a scheduler from a large set of DNN based methods to optimize task scheduling and execution costs in tandem. Compared to state-of-the-art DNN schedulers, this allows for improvement in execution costs, energy consumption, response time and service level agreement violations by up to 11, 43, 8 and 13 percent, respectively.},
  doi       = {10.1109/CLOUD55607.2022.00056},
  issn      = {2159-6190},
}

@InProceedings{Malti2023,
  author    = {Malti, Arslan Nedhir and Benmammar, Badr and Hakem, Mourad},
  booktitle = {2023 5th International Conference on Pattern Analysis and Intelligent Systems (PAIS)},
  title     = {Task Scheduling Optimization in Cloud Computing: A Comparative Study Between Flower Pollination and Butterfly Optimization Algorithms},
  year      = {2023},
  month     = {Oct},
  pages     = {1-7},
  abstract  = {The No Free Lunch theorem states that no single algorithm can universally serve as the best solution for all optimization purposes. Consequently, it becomes imperative to adapt or combine the fundamental structures of metaheuristic optimization algorithms to fit with specific problem-solving requirements. In this paper, we conduct a comparative analysis of two widely recognized metaheuristic algorithms, namely the Butterfly Optimization Algorithm (BOA) and the Flower Pollination Algorithm (FPA) to deal with the task scheduling problem in cloud computing systems. Our objective is to orchestrate the most effective assignment of tasks across the available virtual machines in the system. Performance evaluation encompasses standard and synthetic workloads, focusing on conflicting quality of service metrics, namely time makespan or schedule length and resource utilization. The experiments conducted through the CloudSim framework demonstrate compelling outcomes, highlighting the importance of this study as a basis for future optimization research.},
  doi       = {10.1109/PAIS60821.2023.10322008},
}

@InProceedings{Caon2023,
  author    = {Caon, Cristiano E. and Li, Jie and Chen, Yong},
  booktitle = {2023 IEEE 16th International Conference on Cloud Computing (CLOUD)},
  title     = {Effective Management of Time Series Data},
  year      = {2023},
  month     = {July},
  pages     = {408-414},
  abstract  = {Cloud computing systems, consisting of numerous nodes and components, require constant monitoring to satisfy the Quality-of-Service (QoS), making the management of large-scale time series data challenging. To address this issue, age threshold retention policies have been implemented to remove historical data, but this eliminates valuable information from older periods. In this paper, we proposed an alternative approach that applies time series deduplication with metric-based tolerance to discard readings that stabilize within a calculated tolerance window. This approach can reduce the data volume by 70.38% on average. Once the data-reduced interval is queried, the readings can be reconstructed to retrieve the original granularity with low query runtime overhead and a Mean Absolute Percentage Error of 0.74%.},
  doi       = {10.1109/CLOUD60044.2023.00055},
  issn      = {2159-6190},
}

@Article{Tuli2023,
  author   = {Tuli, Shreshth and Casale, Giuliano and Jennings, Nicholas R.},
  journal  = {IEEE Transactions on Computers},
  title    = {SciNet: Codesign of Resource Management in Cloud Computing Environments},
  year     = {2023},
  issn     = {1557-9956},
  month    = {Dec},
  number   = {12},
  pages    = {3590-3602},
  volume   = {72},
  abstract = {The rise of distributed cloud computing technologies has been pivotal for the large-scale adoption of Artificial Intelligence (AI) based applications for high fidelity and scalable service delivery. Systematic resource management is central in maintaining optimal Quality of Service (QoS) in cloud platforms and is divided into three fundamental types: resource provisioning, AI model deployment and workload placement. To exploit the synergy among these decision types, it becomes imperative to concurrently design (co-design) the provisioning, deployment and placement decisions for optimal QoS. As users and cloud service providers shift to non-stationary AI-based workloads, frequent decision making imposes severe time constraints on the resource management models. Existing AI-based solutions often optimize decision types independently and tend to ignore the dependencies across various system performance aspects such as energy consumption and CPU utilization, making them perform poorly in large-scale cloud systems. To address this, we propose a novel method, called SciNet, that leverages a co-simulated digital-twin of the infrastructure to capture inter-metric dependencies and accurately estimate QoS scores. To avoid expensive simulation overheads at test time, SciNet trains a neural network based imitation learner that aims to mimic an oracle, which takes optimal decisions based on co-simulated QoS estimates. Offline model training and online decision making based on the imitation learner, enables SciNet to take optimal decisions while being time-efficient. Experiments with real-life AI-based benchmark applications on a public cloud testbed show that SciNet gives up to 48% lower execution cost, 79% higher inference accuracy, 71% lower energy consumption and 56% lower response times compared to the current state-of-the-art methods.},
  doi      = {10.1109/TC.2023.3310678},
}

@InProceedings{Sripavithra2022,
  author    = {Sripavithra, C K and Kirubanand, V B},
  booktitle = {2022 International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME)},
  title     = {ESSA Scheduling Algorithm for Optimizing Budget-Constrained Workflows},
  year      = {2022},
  month     = {Nov},
  pages     = {1-8},
  abstract  = {Workflows are a systematic approach for defining various scientific applications of distributed systems. They break down complicated, data-intensive processes into minor activities that can be executed serially or in parallel according to the type of application. Cloud systems need to allocate resources and schedule workflows efficiently. Despite many studies on job scheduling and resource provisioning, an efficient solution isn't found. Therefore, techniques are required to enhance resource utilization for optimal cloud computing platforms. Hence, user and provider quality of service (QoS) goals, like shortening workflows and ensuring budget limits with low energy utilization, must be considered. Enhanced Salp Swarm Optimization (ESSA) is designed to optimize makespan and QoS metrics in cloud systems. A Virtual Machine (VM's) compute capacity is related to Central Processing Unit (CPU) and memory. Size and memory demand is considered for tasks in the workflow, and task execution time is evaluated using both CPU and memory. The collated experimental outcomes convey that the newly presented technique boosts the workflows' energy utilization (up to 89%) and pushes the normalized makespan results to 3.2ms.},
  doi       = {10.1109/ICECCME55909.2022.9988009},
}

@Article{Hidayetoglu2022,
  author   = {Hidayetoğlu, Mert and Biçer, Tekin and de Gonzalo, Simon Garcia and Ren, Bin and Gürsoy, Doğa and Kettimuthu, Rajkumar and Foster, Ian T. and Hwu, Wen-Mei W.},
  journal  = {IEEE Transactions on Parallel and Distributed Systems},
  title    = {MemXCT: Design, Optimization, Scaling, and Reproducibility of X-Ray Tomography Imaging},
  year     = {2022},
  issn     = {1558-2183},
  month    = {Sep.},
  number   = {9},
  pages    = {2014-2031},
  volume   = {33},
  abstract = {This work extends our previous research entitled “MemXCT: Memory-centric X-ray CT Reconstruction with Massive Parallelization” that was originally published at SC19 conference (Hidayetoğlu et al., 2019) with reproducibility of the computational imaging performance. X-ray computed tomography (XCT) is regularly used at synchrotron light sources to study the internal morphology of materials at high resolution. However, experimental constraints, such as radiation sensitivity, can result in noisy or undersampled measurements. Further, depending on the resolution, sample size and data acquisition rates, the resulting noisy dataset can be in the order of terabytes. Advanced iterative reconstruction techniques can produce high-quality images from noisy measurements, but their computational requirements have made their use an exception rather than the rule. We propose a novel memory-centric approach that avoids redundant computations at the expense of additional memory complexity. We develop a memory-centric iterative reconstruction system, MemXCT, that uses an optimized SpMV implementation with two-level pseudo-Hilbert ordering and multi-stage input buffering. We evaluate MemXCT on various supercomputer architectures involving KNL and GPU. MemXCT can reconstruct a large (11K×11K) mouse brain tomogram in 10 seconds using 4096 KNL nodes (256K cores). The results presented in our original article at the SC19 were based on large-scale supercomputing resources. The MemXCT application was selected for the Student Cluster Competition (SCC) Reproducibility Challenge and evaluated on a variety of cloud computing resources by universities around the world in the SC20 conference. We summarize the results of the top-ranked SCC Reproducibility Challenge teams and identify the most pertinent measures for ensuring the reproducibility of our experiments in this article.},
  doi      = {10.1109/TPDS.2021.3128032},
}

@Article{Zhou2023a,
  author   = {Zhou, Jun and Kondo, Masaaki},
  journal  = {IEEE Transactions on Emerging Topics in Computing},
  title    = {An Edge-Cloud Collaboration Framework for Graph Processing in Smart Society},
  year     = {2023},
  issn     = {2168-6750},
  month    = {Oct},
  number   = {4},
  pages    = {985-1001},
  volume   = {11},
  abstract = {Due to the limitations of cloud computing on latency, bandwidth and data confidentiality, edge computing has emerged as a novel location-aware way to provide the capacity-constrained portable terminals with more processing capacity to improve the computing performance and quality of service (QoS) in several typical domains of the human activity in smart society, such as social networks, medical diagnosis, telecommunications, recommendation systems, internal threat detection, transportation, Internet of Things (IoT), etc. These application domains often manage a vast collection of entities with various relationships, which can be naturally represented by the graph data structure. Graph processing is a powerful tool to model and optimize complex problems where graph-based data is involved. In consideration of the relatively insufficient resource provisioning of the edge devices, in this article, for the first time to our knowledge, we propose a reliable edge-cloud collaboration framework that facilitates the graph primitives based on a lightweight interactive graph processing library (GPL), especially for shortest path search (SPS) operations as the demonstrative example. Two types of different practical cases are also presented to show the typical application scenarios of our graph processing strategy. Experimental evaluations indicate that the acceleration rate of performance can reach 6.87x via graph reduction, and less than 3% and 20% extra latency is required for much better user experiences for navigation and pandemic control, respectively, while the online security measures merely consume about 1% extra time of the overall data transmission. Our framework can efficiently execute the applications with considering of user-friendliness, low-latency response, interactions among edge devices, collaboration between edge and cloud, and privacy protection at an acceptable overhead.},
  doi      = {10.1109/TETC.2023.3297066},
}

 
@Article{Rajput2020,
  author    = {Rajput, Pushpendra Kumar and Sikka, Geeta},
  journal   = {Journal of Ambient Intelligence and Humanized Computing},
  title     = {Multi-agent architecture for fault recovery in self-healing systems},
  year      = {2020},
  issn      = {1868-5145},
  month     = aug,
  number    = {2},
  pages     = {2849–2866},
  volume    = {12},
  doi       = {10.1007/s12652-020-02443-8},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s12652-020-02443-8},
}

 
@Article{Rajaram2018,
  author    = {Rajaram, Gangothri and Karnatak, Harish Chandra and Venkatraman, Swaminathan and Manjula, K. R. and Krithivasan, Kannan},
  journal   = {GeoInformatica},
  title     = {A novel computational knowledge-base framework for visualization and quantification of geospatial metadata in spatial data infrastructures},
  year      = {2018},
  issn      = {1573-7624},
  month     = feb,
  number    = {2},
  pages     = {269–305},
  volume    = {22},
  doi       = {10.1007/s10707-018-0317-6},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s10707-018-0317-6},
}

 
@Article{Alaeddini2016,
  author    = {Alaeddini, Morteza and Asgari, Hamed and Gharibi, Arash and Rashidi Rad, Mona},
  journal   = {Information Technology and Management},
  title     = {Leveraging business-IT alignment through enterprise architecture—an empirical study to estimate the extents},
  year      = {2016},
  issn      = {1573-7667},
  month     = mar,
  number    = {1},
  pages     = {55–82},
  volume    = {18},
  doi       = {10.1007/s10799-016-0256-6},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s10799-016-0256-6},
}

 
@Article{Wijerathna2021,
  author    = {Wijerathna, Laksri and Aleti, Aldeida and Bi, Tingting and Tang, Antony},
  journal   = {Empirical Software Engineering},
  title     = {Mining and relating design contexts and design patterns from Stack Overflow},
  year      = {2021},
  issn      = {1573-7616},
  month     = oct,
  number    = {1},
  volume    = {27},
  doi       = {10.1007/s10664-021-10034-0},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s10664-021-10034-0},
}

 
@Article{Garriga2016,
  author    = {Garriga, Martin and Renzis, Alan De and Lizarralde, Ignacio and Flores, Andres and Mateos, Cristian and Cechich, Alejandra and Zunino, Alejandro},
  journal   = {Information Systems Frontiers},
  title     = {A structural-semantic web service selection approach to improve retrievability of web services},
  year      = {2016},
  issn      = {1572-9419},
  month     = dec,
  number    = {6},
  pages     = {1319–1344},
  volume    = {20},
  doi       = {10.1007/s10796-016-9731-1},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s10796-016-9731-1},
}

 
@Article{Haoues2016,
  author    = {Haoues, Mariem and Sellami, Asma and Ben-Abdallah, Hanêne and Cheikhi, Laila},
  journal   = {International Journal of System Assurance Engineering and Management},
  title     = {A guideline for software architecture selection based on ISO 25010 quality related characteristics},
  year      = {2016},
  issn      = {0976-4348},
  month     = nov,
  number    = {S2},
  pages     = {886–909},
  volume    = {8},
  doi       = {10.1007/s13198-016-0546-8},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s13198-016-0546-8},
}

 
@Article{Zhang2015c,
  author    = {Zhang, Yingfeng and Xi, Dong and Li, Rui and Sun, Shudong},
  journal   = {The International Journal of Advanced Manufacturing Technology},
  title     = {Task-driven manufacturing cloud service proactive discovery and optimal configuration method},
  year      = {2015},
  issn      = {1433-3015},
  month     = sep,
  number    = {1–4},
  pages     = {29–45},
  volume    = {84},
  doi       = {10.1007/s00170-015-7731-9},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s00170-015-7731-9},
}

 
@Article{Gao2019a,
  author    = {Gao, Honghao and Duan, Yucong and Shao, Lixu and Sun, Xiaobing},
  journal   = {Wireless Networks},
  title     = {Transformation-based processing of typed resources for multimedia sources in the IoT environment},
  year      = {2019},
  issn      = {1572-8196},
  month     = nov,
  number    = {5},
  pages     = {3377–3393},
  volume    = {27},
  doi       = {10.1007/s11276-019-02200-6},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s11276-019-02200-6},
}

 
@Article{Hou2018,
  author    = {Hou, Jing-wei and Sun, Shi-qin and Liu, Ren-tao and Li, Jian-hua and Zhang, Ming-xin},
  journal   = {Journal of Central South University},
  title     = {Design and achievement of cloud geodatabase for a sponge city},
  year      = {2018},
  issn      = {2227-5223},
  month     = oct,
  number    = {10},
  pages     = {2423–2437},
  volume    = {25},
  doi       = {10.1007/s11771-018-3926-1},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s11771-018-3926-1},
}

 
@Article{Calvaresi2016,
  author    = {Calvaresi, Davide and Cesarini, Daniel and Sernani, Paolo and Marinoni, Mauro and Dragoni, Aldo Franco and Sturm, Arnon},
  journal   = {Journal of Ambient Intelligence and Humanized Computing},
  title     = {Exploring the ambient assisted living domain: a systematic review},
  year      = {2016},
  issn      = {1868-5145},
  month     = may,
  number    = {2},
  pages     = {239–257},
  volume    = {8},
  doi       = {10.1007/s12652-016-0374-3},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s12652-016-0374-3},
}

 
@Article{Kim2014b,
  author    = {Kim, Jongsung and Chao, Han-Chieh and Nguyen, Uyen Trang},
  journal   = {Electronic Commerce Research},
  title     = {Recent advanced applications and services for intelligent ubiquitous environments},
  year      = {2014},
  issn      = {1572-9362},
  month     = sep,
  number    = {3},
  pages     = {217–221},
  volume    = {14},
  doi       = {10.1007/s10660-014-9142-7},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s10660-014-9142-7},
}

 
@Article{Semenov2018,
  author    = {Semenov, Ilia and Kopanitsa, Georgy and Denisov, Dmitry and Alexandr, Yakovenko and Osenev, Roman and Andreychuk, Yury},
  journal   = {Journal of Medical Systems},
  title     = {Patients Decision Aid System Based on FHIR Profiles},
  year      = {2018},
  issn      = {1573-689X},
  month     = jul,
  number    = {9},
  volume    = {42},
  doi       = {10.1007/s10916-018-1016-4},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s10916-018-1016-4},
}

 
@Article{Previtali2018,
  author    = {Previtali, Mattia and Latre, Miguel Ángel},
  journal   = {Applied Geomatics},
  title     = {A brokered Virtual Hub approach for the generation of web applications based on historical maps},
  year      = {2018},
  issn      = {1866-928X},
  month     = sep,
  number    = {4},
  pages     = {453–472},
  volume    = {10},
  doi       = {10.1007/s12518-018-0235-1},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s12518-018-0235-1},
}

 
@Article{Cognini2016,
  author    = {Cognini, Riccardo and Corradini, Flavio and Gnesi, Stefania and Polini, Andrea and Re, Barbara},
  journal   = {Information Systems Frontiers},
  title     = {Business process flexibility - a systematic literature review with a software systems perspective},
  year      = {2016},
  issn      = {1572-9419},
  month     = jul,
  number    = {2},
  pages     = {343–371},
  volume    = {20},
  doi       = {10.1007/s10796-016-9678-2},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s10796-016-9678-2},
}

 
@Article{SuarezMeza2013,
  author    = {Suarez-Meza, Luis Javier and Zúñiga, Julián Andrés and Pedraza, Edgar Camilo and Corrales, Juan Carlos},
  journal   = {Information Systems Frontiers},
  title     = {Fully automated resource retrieval in telecommunications and internet converged environments},
  year      = {2013},
  issn      = {1572-9419},
  month     = oct,
  number    = {1},
  pages     = {77–93},
  volume    = {16},
  doi       = {10.1007/s10796-013-9457-2},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s10796-013-9457-2},
}

 
@Article{Vahidnia2019,
  author    = {Vahidnia, Mohammad H. and Hosseinali, Farhad and Shafiei, Maryam},
  journal   = {Applied Geomatics},
  title     = {Crowdsource mapping of target buildings in hazard: the utilization of smartphone technologies and geographic services},
  year      = {2019},
  issn      = {1866-928X},
  month     = jul,
  number    = {1},
  pages     = {3–14},
  volume    = {12},
  doi       = {10.1007/s12518-019-00280-9},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s12518-019-00280-9},
}

 
@Article{Redelinghuys2019,
  author    = {Redelinghuys, A. J. H. and Basson, A. H. and Kruger, K.},
  journal   = {Journal of Intelligent Manufacturing},
  title     = {A six-layer architecture for the digital twin: a manufacturing case study implementation},
  year      = {2019},
  issn      = {1572-8145},
  month     = dec,
  number    = {6},
  pages     = {1383–1402},
  volume    = {31},
  doi       = {10.1007/s10845-019-01516-6},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s10845-019-01516-6},
}

 
@InBook{Ntentos2021,
  author    = {Ntentos, Evangelos and Zdun, Uwe and Plakidas, Konstantinos and Geiger, Sebastian},
  pages     = {188–203},
  publisher = {Springer International Publishing},
  title     = {Evaluating and Improving Microservice Architecture Conformance to Architectural Design Decisions},
  year      = {2021},
  isbn      = {9783030914318},
  booktitle = {Lecture Notes in Computer Science},
  doi       = {10.1007/978-3-030-91431-8_12},
  issn      = {1611-3349},
  url       = {http://dx.doi.org/10.1007/978-3-030-91431-8_12},
}

 
@InBook{Deepika2021,
  author    = {Deepika and Sangwan, Om Prakash},
  pages     = {463–473},
  publisher = {Springer Singapore},
  title     = {A Software Reusability Paradigm for Assessing Software-as-a-Service for Cloud Computing},
  year      = {2021},
  isbn      = {9789813369818},
  booktitle = {Congress on Intelligent Systems},
  doi       = {10.1007/978-981-33-6981-8_37},
  issn      = {2194-5365},
  url       = {http://dx.doi.org/10.1007/978-981-33-6981-8_37},
}

 
@InBook{Brandenburger2021,
  author    = {Brandenburger, Jens and Schirm, Christoph and Melcher, Josef and Hancke, Edgar and Vannucci, Marco and Colla, Valentina and Cateni, Silvia and Sellami, Rami and Dupont, Sébastien and Majchrowski, Annick and Arteaga, Asier},
  pages     = {54–66},
  publisher = {Springer International Publishing},
  title     = {Quality 4.0 - Transparent Product Quality Supervision in the Age of Industry 4.0},
  year      = {2021},
  isbn      = {9783030693671},
  booktitle = {Impact and Opportunities of Artificial Intelligence Techniques in the Steel Industry},
  doi       = {10.1007/978-3-030-69367-1_5},
  issn      = {2194-5365},
  url       = {http://dx.doi.org/10.1007/978-3-030-69367-1_5},
}

 
@InBook{Huynh2015,
  author    = {Huynh, Khai T. and Bui, Thang H. and Quan, Tho T.},
  pages     = {513–524},
  publisher = {Springer International Publishing},
  title     = {A Lightweight Formal Approach for Component Reuse},
  year      = {2015},
  isbn      = {9783319116808},
  booktitle = {Knowledge and Systems Engineering},
  doi       = {10.1007/978-3-319-11680-8_41},
  issn      = {2194-5365},
  url       = {http://dx.doi.org/10.1007/978-3-319-11680-8_41},
}

 
@InBook{Marins2014,
  author    = {Marins, Fernando and Cardoso, Luciana and Portela, Filipe and Santos, Manuel F. and Abelha, António and Machado, José},
  pages     = {207–216},
  publisher = {Springer International Publishing},
  title     = {Improving High Availability and Reliability of Health Interoperability Systems},
  year      = {2014},
  isbn      = {9783319059488},
  booktitle = {New Perspectives in Information Systems and Technologies, Volume 2},
  doi       = {10.1007/978-3-319-05948-8_20},
  issn      = {2194-5365},
  url       = {http://dx.doi.org/10.1007/978-3-319-05948-8_20},
}

 
@InBook{AlvaradoValiente2023,
  author    = {Alvarado-Valiente, Jaime and Romero-Álvarez, Javier and Díaz, Ana and Rodríguez, Moisés and García-Rodríguez, Ignacio and Moguel, Enrique and Garcia-Alonso, Jose and Murillo, Juan M.},
  pages     = {200–214},
  publisher = {Springer Nature Switzerland},
  title     = {Quantum Services Generation and Deployment Process: A Quality-Oriented Approach},
  year      = {2023},
  isbn      = {9783031437038},
  booktitle = {Quality of Information and Communications Technology},
  doi       = {10.1007/978-3-031-43703-8_15},
  issn      = {1865-0937},
  url       = {http://dx.doi.org/10.1007/978-3-031-43703-8_15},
}

 
@InBook{Wentzel2023,
  author    = {Wentzel, Bianca and Kirstein, Fabian and Jastrow, Torben and Sturm, Raphael and Peters, Michael and Schimmler, Sonja},
  pages     = {262–278},
  publisher = {Springer Nature Switzerland},
  title     = {An Extensive Methodology and Framework for Quality Assessment of DCAT-AP Datasets},
  year      = {2023},
  isbn      = {9783031411380},
  booktitle = {Electronic Government},
  doi       = {10.1007/978-3-031-41138-0_17},
  issn      = {1611-3349},
  url       = {http://dx.doi.org/10.1007/978-3-031-41138-0_17},
}

 
@InBook{Quattrocchi2022,
  author    = {Quattrocchi, Giovanni and Tamburri, Damian Andrew and Heuvel, Willem-Jan Van Den},
  pages     = {384–391},
  publisher = {Springer Nature Switzerland},
  title     = {Blockchain-Oriented Services Computing in Action: Insights from a User Study},
  year      = {2022},
  isbn      = {9783031209840},
  booktitle = {Lecture Notes in Computer Science},
  doi       = {10.1007/978-3-031-20984-0_27},
  issn      = {1611-3349},
  url       = {http://dx.doi.org/10.1007/978-3-031-20984-0_27},
}

 
@Article{ReyesDelgado2021,
  author    = {Reyes-Delgado, Paola Y. and Duran-Limon, Hector A. and Mora, Manuel and Rodriguez-Martinez, Laura C.},
  journal   = {Software and Systems Modeling},
  title     = {SOCAM: a service-oriented computing architecture modeling method},
  year      = {2021},
  issn      = {1619-1374},
  month     = nov,
  number    = {4},
  pages     = {1551–1581},
  volume    = {21},
  doi       = {10.1007/s10270-021-00946-2},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s10270-021-00946-2},
}

 
@Article{Krishnamoorthy2021,
  author    = {Krishnamoorthy, Sreelakshmi and Dua, Amit and Gupta, Shashank},
  journal   = {Journal of Ambient Intelligence and Humanized Computing},
  title     = {Role of emerging technologies in future IoT-driven Healthcare 4.0 technologies: a survey, current challenges and future directions},
  year      = {2021},
  issn      = {1868-5145},
  month     = may,
  number    = {1},
  pages     = {361–407},
  volume    = {14},
  doi       = {10.1007/s12652-021-03302-w},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s12652-021-03302-w},
}

 
@Article{Zouari2023,
  author    = {Zouari, Firas and Ghedira-Guegan, Chirine and Boukadi, Khouloud and Kabachi, Nadia},
  journal   = {World Wide Web},
  title     = {A semantic and service-based approach for adaptive mutli-structured data curation in data lakehouses},
  year      = {2023},
  issn      = {1573-1413},
  month     = nov,
  number    = {6},
  pages     = {4001–4023},
  volume    = {26},
  doi       = {10.1007/s11280-023-01218-3},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s11280-023-01218-3},
}

 
@Article{Wang2021e,
  author    = {Wang, Ronghan and Lu, Junwei},
  journal   = {Wireless Personal Communications},
  title     = {QoS-Aware Service Discovery and Selection Management for Cloud-Edge Computing Using a Hybrid Meta-Heuristic Algorithm in IoT},
  year      = {2021},
  issn      = {1572-834X},
  month     = aug,
  number    = {3},
  pages     = {2269–2282},
  volume    = {126},
  doi       = {10.1007/s11277-021-09052-4},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s11277-021-09052-4},
}

 
@Article{BenitezGuijarro2019,
  author    = {Benítez-Guijarro, Antonio and Callejas, Zoraida and Noguera, Manuel and Benghazi, Kawtar},
  journal   = {Journal of Ambient Intelligence and Humanized Computing},
  title     = {Architecting dietary intake monitoring as a service combining NLP and IoT},
  year      = {2019},
  issn      = {1868-5145},
  month     = nov,
  number    = {11},
  pages     = {5377–5389},
  volume    = {13},
  doi       = {10.1007/s12652-019-01553-2},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s12652-019-01553-2},
}

 
@Article{Shamsa2023,
  author    = {Shamsa, Zari and Rezaee, Ali and Adabi, Sahar and Rahmani, Amir Masoud},
  journal   = {Computing},
  title     = {A decentralized prediction-based workflow load balancing architecture for cloud/fog/IoT environments},
  year      = {2023},
  issn      = {1436-5057},
  month     = aug,
  doi       = {10.1007/s00607-023-01216-3},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s00607-023-01216-3},
}

 
@Article{Lagana2023,
  author    = {Laganà, Antonio},
  journal   = {Rendiconti Lincei. Scienze Fisiche e Naturali},
  title     = {From molecular beam technologies to virtual experiments and communities},
  year      = {2023},
  issn      = {1720-0776},
  month     = nov,
  number    = {4},
  pages     = {1013–1020},
  volume    = {34},
  doi       = {10.1007/s12210-023-01203-y},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s12210-023-01203-y},
}

 
@Article{Iqbal2023,
  author    = {Iqbal, Asif and Khan, Siffat Ullah and Niazi, Mahmood and Humayun, Mamoona and Sama, Najm Us and Khan, Arif Ali and Ahmad, Aakash},
  journal   = {Wireless Networks},
  title     = {Advancing database security: a comprehensive systematic mapping study of potential challenges},
  year      = {2023},
  issn      = {1572-8196},
  month     = jul,
  doi       = {10.1007/s11276-023-03436-z},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s11276-023-03436-z},
}

 
@Article{Oztemel2018,
  author    = {Oztemel, Ercan and Gursev, Samet},
  journal   = {Journal of Intelligent Manufacturing},
  title     = {Literature review of Industry 4.0 and related technologies},
  year      = {2018},
  issn      = {1572-8145},
  month     = jul,
  number    = {1},
  pages     = {127–182},
  volume    = {31},
  doi       = {10.1007/s10845-018-1433-8},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s10845-018-1433-8},
}

 
@Article{Cormier2019,
  author    = {Cormier, Dave and Jandrić, Petar and Childs, Mark and Hall, Richard and White, David and Phipps, Lawrie and Truelove, Ian and Hayes, Sarah and Fawns, Tim},
  journal   = {Postdigital Science and Education},
  title     = {Ten Years of the Postdigital in the 52group: Reflections and Developments 2009–2019},
  year      = {2019},
  issn      = {2524-4868},
  month     = jun,
  number    = {2},
  pages     = {475–506},
  volume    = {1},
  doi       = {10.1007/s42438-019-00049-8},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s42438-019-00049-8},
}

 
@Article{Kosinska2023,
  author    = {Kosińska, Joanna and Zieliński, Krzysztof},
  journal   = {Journal of Grid Computing},
  title     = {Enhancement of Cloud-native applications with Autonomic Features},
  year      = {2023},
  issn      = {1572-9184},
  month     = jul,
  number    = {3},
  volume    = {21},
  doi       = {10.1007/s10723-023-09675-w},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s10723-023-09675-w},
}

 
@Article{Arulappan2023,
  author    = {Arulappan, Arunkumar and Raja, Gunasekaran and Bashir, Ali Kashif and Mahanti, Aniket and Omar, Marwan},
  journal   = {Mobile Networks and Applications},
  title     = {ZTMP: Zero Touch Management Provisioning Algorithm for the On-boarding of Cloud-native Virtual Network Functions},
  year      = {2023},
  issn      = {1572-8153},
  month     = nov,
  doi       = {10.1007/s11036-023-02260-1},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s11036-023-02260-1},
}

 
@Article{ZargarAzad2023,
  author    = {ZargarAzad, Matineh and Ashtiani, Mehrdad},
  journal   = {Journal of Grid Computing},
  title     = {An Auto-Scaling Approach for Microservices in Cloud Computing Environments},
  year      = {2023},
  issn      = {1572-9184},
  month     = nov,
  number    = {4},
  volume    = {21},
  doi       = {10.1007/s10723-023-09713-7},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s10723-023-09713-7},
}

 
@Article{Bento2023,
  author    = {Bento, Andre and Araujo, Filipe and Barbosa, Raul},
  journal   = {Journal of Grid Computing},
  title     = {Cost-Availability Aware Scaling: Towards Optimal Scaling of Cloud Services},
  year      = {2023},
  issn      = {1572-9184},
  month     = dec,
  number    = {4},
  volume    = {21},
  doi       = {10.1007/s10723-023-09718-2},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s10723-023-09718-2},
}

 
@Article{Ullah2023,
  author    = {Ullah, Amjad and Kiss, Tamas and Kovács, József and Tusa, Francesco and Deslauriers, James and Dagdeviren, Huseyin and Arjun, Resmi and Hamzeh, Hamed},
  journal   = {Journal of Cloud Computing},
  title     = {Orchestration in the Cloud-to-Things compute continuum: taxonomy, survey and future directions},
  year      = {2023},
  issn      = {2192-113X},
  month     = sep,
  number    = {1},
  volume    = {12},
  doi       = {10.1186/s13677-023-00516-5},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1186/s13677-023-00516-5},
}

 
@Article{Mitropoulou2023,
  author    = {Mitropoulou, Katerina and Kokkinos, Panagiotis and Soumplis, Polyzois and Varvarigos, Emmanouel},
  journal   = {Journal of Grid Computing},
  title     = {Anomaly Detection in Cloud Computing using Knowledge Graph Embedding and Machine Learning Mechanisms},
  year      = {2023},
  issn      = {1572-9184},
  month     = dec,
  number    = {1},
  volume    = {22},
  doi       = {10.1007/s10723-023-09727-1},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s10723-023-09727-1},
}

 
@Article{Georgara2023,
  author    = {Georgara, Athina and Kazhamiakin, Raman and Mich, Ornella and Palmero Aprosio, Alessio and Pazzaglia, Jean-Christoph and Rodríguez Aguilar, Juan Antonio and Sierra, Carles},
  journal   = {Applied Intelligence},
  title     = {The AI4Citizen pilot: Pipelining AI-based technologies to support school-work alternation programmes},
  year      = {2023},
  issn      = {1573-7497},
  month     = jul,
  number    = {20},
  pages     = {24157–24186},
  volume    = {53},
  doi       = {10.1007/s10489-023-04758-3},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s10489-023-04758-3},
}

 
@InBook{Jiang2023a,
  author    = {Jiang, Xu and Cai, Zhicheng},
  pages     = {263–275},
  publisher = {Springer Nature Singapore},
  title     = {Performance Curve Profiling and Gated Recurrent Unit Based State Detection for Cloud Native Microservices},
  year      = {2023},
  isbn      = {9789819944026},
  booktitle = {Service Science},
  doi       = {10.1007/978-981-99-4402-6_19},
  issn      = {1865-0937},
  url       = {http://dx.doi.org/10.1007/978-981-99-4402-6_19},
}

 
@InBook{Abdelfattah2023,
  author    = {Abdelfattah, Amr S. and Cerny, Tomas and Salazar, Jorge Yero and Lehman, Austin and Hunter, Joshua and Bickham, Ashley and Taibi, Davide},
  pages     = {35–51},
  publisher = {Springer Nature Switzerland},
  title     = {End-to-End Test Coverage Metrics in Microservice Systems: An Automated Approach},
  year      = {2023},
  isbn      = {9783031462351},
  booktitle = {Lecture Notes in Computer Science},
  doi       = {10.1007/978-3-031-46235-1_3},
  issn      = {1611-3349},
  url       = {http://dx.doi.org/10.1007/978-3-031-46235-1_3},
}

 
@InBook{Riccio2023,
  author    = {Riccio, Vincenzo and Sorrentino, Giancarlo and Camilli, Matteo and Mirandola, Raffaela and Scandurra, Patrizia},
  pages     = {227–242},
  publisher = {Springer Nature Switzerland},
  title     = {Engineering Self-adaptive Microservice Applications: An Experience Report},
  year      = {2023},
  isbn      = {9783031484216},
  booktitle = {Lecture Notes in Computer Science},
  doi       = {10.1007/978-3-031-48421-6_16},
  issn      = {1611-3349},
  url       = {http://dx.doi.org/10.1007/978-3-031-48421-6_16},
}

@InProceedings{CruzFilipe2019,
  author    = {Cruz-Filipe, Lu\'{\i}s and Di Nitto, Elisabetta and Mauro, Jacopo},
  booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
  title     = {Session Details: Theme: Distributed Systems: MiDOS - Microservices, DevOps, and Service-Oriented Architecture Track},
  year      = {2019},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {SAC '19},
  abstract  = {Service-oriented architectures have changed our vision of the Web, bringing a paradigmatic shift in the methodologies when designing and implementing distributed systems. Originally, the Web was mainly seen as a means of presenting information to a wide spectrum of people, but service-oriented programming triggered a radical transformation of the Web towards a computational fabric where loosely coupled services interact, can be discovered and then invoked. More recently, the microservices architectural style has been proposed, where applications are developed as a collection of fine-grained services running as independent processes. Distributed applications can then be constructed from independently deployable services taking advantage of the properties of the microservice architecture (e.g., flexibility, maintainability, reusability, compositionality, and scalability) as well as the elasticity of cloud infrastructure. From the practical point of view, the deployment and maintenance of (micro)services architectures are performed using DevOps, i.e., a collection of practices linking software development (Dev) with software operations (Ops). DevOps strongly advocates for automation and monitoring at all steps of software construction, from integration, testing, releasing to deployment and infrastructure management. By using the DevOps methodology, it is possible to reduce the time between committing a change to a system and the change being placed into normal production, while ensuring high quality.},
  doi       = {10.1145/3329379},
  isbn      = {9781450359337},
  location  = {Limassol, Cyprus},
  url       = {https://doi.org/10.1145/3329379},
}

@InProceedings{Kalia2021,
  author    = {Kalia, Anup K. and Xiao, Jin and Krishna, Rahul and Sinha, Saurabh and Vukovic, Maja and Banerjee, Debasish},
  booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  title     = {Mono2Micro: A Practical and Effective Tool for Decomposing Monolithic Java Applications to Microservices},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {1214–1224},
  publisher = {Association for Computing Machinery},
  series    = {ESEC/FSE 2021},
  abstract  = {In migrating production workloads to cloud, enterprises often face the daunting task of evolving monolithic applications toward a microservice architecture. At IBM, we developed a tool called Mono2Micro to assist with this challenging task. Mono2Micro performs spatio-temporal decomposition, leveraging well-defined business use cases and runtime call relations to create functionally cohesive partitioning of application classes. Our preliminary evaluation of Mono2Micro showed promising results.  How well does Mono2Micro perform against other decomposition techniques, and how do practitioners perceive the tool? This paper describes the technical foundations of Mono2Micro and presents results to answer these two questions. To answer the first question, we evaluated Mono2Micro against four existing techniques on a set of open-source and proprietary Java applications and using different metrics to assess the quality of decomposition and tool’s efficiency. Our results show that Mono2Micro significantly outperforms state-of-the-art baselines in specific metrics well-defined for the problem domain. To answer the second question, we conducted a survey of twenty-one practitioners in various industry roles who have used Mono2Micro. This study highlights several benefits of the tool, interesting practitioner perceptions, and scope for further improvements. Overall, these results show that Mono2Micro can provide a valuable aid to practitioners in creating functionally cohesive and explainable microservice decompositions.},
  doi       = {10.1145/3468264.3473915},
  isbn      = {9781450385626},
  keywords  = {dynamic analysis, microservices, clustering},
  location  = {Athens, Greece},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3468264.3473915},
}

@InProceedings{Wu2014,
  author    = {Wu, Jie and Jansen, Christoph and Beier, Maximilian and Witt, Michael and Krefting, Dagmar},
  booktitle = {Proceedings of the 14th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
  title     = {Extending XNAT towards a Cloud-Based Quality Assessment Platform for Retinal Optical Coherence Tomographies},
  year      = {2014},
  address   = {Chicago, Illinois},
  pages     = {764–773},
  publisher = {IEEE Press},
  series    = {CCGRID '14},
  abstract  = {Neurosciencific research is increasingly based on image analysis methods. Large sets of imaging data are processed using complex image analysis tools. While today magnetic resonance imaging (MRI) is widely used for both functional and anatomical analysis of the human brain, new imaging modalities are beginning to prove their capabilities for neurological research. Among them, optical coherence tomography (OCT) allows for noninvasive visualization of anatomical structures on a micrometer scale. Becoming a standard diagnostic tool in ophthalmology, it is of rising interest for neurological research. Crucial to all data analysis methods is the quality of the input data. The platform presented in this paper is designed for automatic quality assessment of retinal OCTs. It extends the image management platform XNAT by services to calculate and store quality measures. It is also extensible regarding new quality measure algorithms, allowing the developer to upload Matlab code, compile it for the infrastructure's hardware architecture and test it in the system. The image processing tools to calculate the quality measures are provided as a cloud-based service employing OpenStack as underlying IT infrastructure. The prototype implementation encompassing security and performance aspects are presented.},
  doi       = {10.1109/CCGrid.2014.103},
  isbn      = {9781479927838},
  keywords  = {SaaS, XNAT, cloud, medical imaging, neuroimaging, IaaS, OCT},
  numpages  = {10},
  url       = {https://doi.org/10.1109/CCGrid.2014.103},
}

@InProceedings{Mekuria2018,
  author    = {Mekuria, Rufael and McGrath, Michael J. and Riccobene, Vincenzo and Bayon-Molino, Victor and Tselios, Christos and Thomson, John and Dobrodub, Artem},
  booktitle = {Proceedings of the 9th ACM Multimedia Systems Conference},
  title     = {Automated Profiling of Virtualized Media Processing Functions Using Telemetry and Machine Learning},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {150–161},
  publisher = {Association for Computing Machinery},
  series    = {MMSys '18},
  abstract  = {Most media streaming services are composed by different virtualized processing functions such as encoding, packaging, encryption, content stitching etc. Deployment of these functions in the cloud is attractive as it enables flexibility in deployment options and resource allocation for the different functions. Yet, most of the time overprovisioning of cloud resources is necessary in order to meet demand variability. This can be costly, especially for large scale deployments. Prior art proposes resource allocation based on analytical models that minimize the costs of cloud deployments under a quality of service (QoS) constraint. However, these models do not sufficiently capture the underlying complexity of services composed of multiple processing functions. Instead, we introduce a novel methodology based on full-stack telemetry and machine learning to profile virtualized or cloud native media processing functions individually. The basis of the approach consists of investigating 4 categories of performance metrics: throughput, anomaly, latency and entropy (TALE) in offline (stress tests) and online setups using cloud telemetry. Machine learning is then used to profile the media processing function in the targeted cloud/NFV environment and to extract the most relevant cloud level Key Performance Indicators (KPIs) that relate to the final perceived quality and known client side performance indicators. The results enable more efficient monitoring, as only KPI related metrics need to be collected, stored and analyzed, reducing the storage and communication footprints by over 85\%. In addition a detailed overview of the functions behavior was obtained, enabling optimized initial configuration and deployment, and more fine-grained dynamic online resource allocation reducing overprovisioning and avoiding function collapse. We further highlight the next steps towards cloud native carrier grade virtualized processing functions relevant for future network architectures such as in emerging 5G architectures.},
  doi       = {10.1145/3204949.3204976},
  isbn      = {9781450351928},
  keywords  = {performance, characterization, video streaming, experimentation, telemetry, cloud computing},
  location  = {Amsterdam, Netherlands},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3204949.3204976},
}

@InProceedings{Thirunavukkarasu2018,
  author    = {Thirunavukkarasu, Gokul Sidarth and Champion, Benjamin and Horan, Ben and Seyedmahmoudian, Mehdi and Stojcevski, Alex},
  booktitle = {Proceedings of the 2018 International Conference on Cloud Computing and Internet of Things},
  title     = {IoT-Based System Health Management Infrastructure as a Service},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {55–61},
  publisher = {Association for Computing Machinery},
  series    = {CCIOT '18},
  abstract  = {Customization, enhanced quality of streamlined maintenance services and uplifted productivity are some of the key highlights from the rapidly evolving concept of Industry 4.0. IoT (Internet of things) based service infrastructure models designed for delivering enterprise services with capabilities of pro-actively sensing malfunctions and responding with preventive measures to streamline the automated service offered is one of the prime application of this concept. Continuous maintenance services increase the optimum through-life cost and in-service life cycle of the product providing the customer with the feel of full ownership. In-service feedbacks also help the manufactures to identify issues with respect to the designs and improve it in the future versions. In this paper, as a proof of concept a cloud-based IoT service infrastructure for providing real-time prognostic and supervised vehicle maintenance system is proposed. This proposed system aims at providing an enterprise service infrastructure to the registered vehicle service centers to keep track of the real-time vehicle diagnostic information of their client's vehicle over cloud and use prognostic algorithms to identify any malfunctions or abnormal behavior of the vehicles for automatically scheduling a service appointment and automating the maintenance cycle of the vehicle. In addition to this, the system provides features like remote supervision and diagnostics maintenance enabling technicians to fix issues remotely, ensuring streamlined and reliable service. Initially, before building the proposed prototype system, a few experimental trails where conducted for analyzing the use of different IoT models used in the development to identify the best-suited approach. The results indicated that the publisher-subscriber (NodeJS) based model outperforms the request-response (PHP) based model in terms of the hits per second and mean request time for an increased number of active users. The results of the initial tests justify the reason for the using the publisher-subscriber based IOT architecture. The conceptualized enterprise infrastructure illustrated in the manuscript aims at providing a streamlined maintenance service.},
  doi       = {10.1145/3291064.3291070},
  isbn      = {9781450365765},
  keywords  = {prognostic maintenance, vehicle diagnosis, internet of things, System health management infrastructure as a service, streamlined remote supervision},
  location  = {Singapore, Singapore},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3291064.3291070},
}

@InProceedings{Ming2019,
  author    = {Ming, Fan Xiu and Habeeb, Riyaz Ahamed Ariyaluran and Md Nasaruddin, Fariza Hanum Binti and Gani, Abdullah Bin},
  booktitle = {Proceedings of the 2019 8th International Conference on Software and Computer Applications},
  title     = {Real-Time Carbon Dioxide Monitoring Based on IoT \&amp; Cloud Technologies},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {517–521},
  publisher = {Association for Computing Machinery},
  series    = {ICSCA '19},
  abstract  = {In recent years, environment monitoring are of greater importance towards the area of climate monitoring, analysis, agricultural productivity management, quality assurance of water, air, alongside with other potential factors that are closely connected to industrial development and convenience of living. This research is motivated by creating awareness of smart home residents on indoor air quality, as well as providing insight of carbon dioxide emissions for industries and environmental organizations.This paper proposes an efficient solution towards environment monitoring of carbon dioxide integrated with Internet of Things capability and cloud computing technology. Aforementioned techniques will deliver highly accessible and real-time data visualization which would be greatly beneficial for Smart Homes efficiency of analysis actualization and counter-measures deployment. A monitoring architecture was developed to generate, accumulate, store and visualize carbon dioxide concentration using MQ135 carbon dioxide sensor, ESP8266 Wi-Fi module, Firebase Cloud Storage Service and Android mobile application Carbon Insight for data visualization. 2880 data points in the time frame of 10 days with a 30-second interval was collected, stored and visualized with the application of this system.},
  doi       = {10.1145/3316615.3316622},
  isbn      = {9781450365734},
  keywords  = {cloud, Internet of things, environment monitoring},
  location  = {Penang, Malaysia},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3316615.3316622},
}

@Article{AlAbbasi2021,
  author     = {Al-Abbasi, Abubakr O. and Aggarwal, Vaneet},
  journal    = {ACM Trans. Model. Perform. Eval. Comput. Syst.},
  title      = {VidCloud: Joint Stall and Quality Optimization for Video Streaming over Cloud},
  year       = {2021},
  issn       = {2376-3639},
  month      = {jan},
  number     = {4},
  volume     = {5},
  abstract   = {As video-streaming services have expanded and improved, cloud-based video has evolved into a necessary feature of any successful business for reaching internal and external audiences. In this article, video streaming over distributed storage is considered where the video segments are encoded using an erasure code for better reliability. We consider a representative system architecture for a realistic (typical) content delivery network (CDN). Given multiple parallel streams/link between each server and the edge router, we need to determine, for each client request, the subset of servers to stream the video, as well as one of the parallel streams from each chosen server. To have this scheduling, this article proposes a two-stage probabilistic scheduling. The selection of video quality is also chosen with a certain probability distribution that is optimized in our algorithm. With these parameters, the playback time of video segments is determined by characterizing the download time of each coded chunk for each video segment. Using the playback times, a bound on the moment generating function of the stall duration is used to bound the mean stall duration. Based on this, we formulate an optimization problem to jointly optimize the convex combination of mean stall duration and average video quality for all requests, where the two-stage probabilistic scheduling, video quality selection, bandwidth split among parallel streams, and auxiliary bound parameters can be chosen. This non-convex problem is solved using an efficient iterative algorithm. Based on the offline version of our proposed algorithm, an online policy is developed where servers selection, quality, bandwidth split, and parallel streams are selected in an online manner. Experimental results show significant improvement in QoE metrics for cloud-based video as compared to the considered baselines.},
  address    = {New York, NY, USA},
  articleno  = {17},
  doi        = {10.1145/3442187},
  issue_date = {December 2020},
  keywords   = {two-stage probabilistic scheduling, erasure codes, video quality, mean stall duration, Video streaming over cloud},
  numpages   = {32},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3442187},
}

@Article{Adhikari2015,
  author     = {Adhikari, Vijay K. and Guo, Yang and Hao, Fang and Hilt, Volker and Zhang, Zhi-Li and Varvello, Matteo and Steiner, Moritz},
  journal    = {IEEE/ACM Trans. Netw.},
  title      = {Measurement Study of Netflix, Hulu, and a Tale of Three CDNs},
  year       = {2015},
  issn       = {1063-6692},
  month      = {dec},
  number     = {6},
  pages      = {1984–1997},
  volume     = {23},
  abstract   = {Netflix and Hulu are leading Over-the-Top (OTT) content service providers in the US and Canada. Netflix alone accounts for 29.7\% of the peak downstream traffic in the US in 2011. Understanding the system architectures and performance of Netflix and Hulu can shed light on the design of such large-scale video streaming platforms, and help improving the design of future systems. In this paper, we perform extensive measurement study to uncover their architectures and service strategies. Netflix and Hulu bear many similarities. Both Netflix and Hulu video streaming platforms rely heavily on the third-party infrastructures, with Netflix migrating that majority of its functions to the Amazon cloud, while Hulu hosts its services out of Akamai. Both service providers employ the same set of three content distribution networks (CDNs) in delivering the video contents. Using active measurement study, we dissect several key aspects of OTT streaming platforms of Netflix and Hulu, e.g., employed streaming protocols, CDN selection strategy, user experience reporting, etc. We discover that both platforms assign the CDN to a video request without considering the network conditions and optimizing the user-perceived video quality. We further conduct the performance measurement studies of the three CDNs employed by Netflix and Hulu. We show that the available bandwidths on all three CDNs vary significantly over the time and over the geographic locations. We propose a measurement-based adaptive CDN selection strategy and a multiple-CDN-based video delivery strategy that can significantly increase users' average available bandwidth.},
  doi        = {10.1109/TNET.2014.2354262},
  issue_date = {December 2015},
  keywords   = {over-the-top (OTT) content service, Netflix, CDN selection strategy, video streaming, content distribution networks (CDN), Hulu},
  numpages   = {14},
  publisher  = {IEEE Press},
  url        = {https://doi.org/10.1109/TNET.2014.2354262},
}

@InProceedings{Megyesi2016,
  author    = {Megyesi, P\'{e}ter and Botta, Alessio and Aceto, Giuseppe and Pescap\`{e}, Antonio and Moln\'{a}r, S\'{a}ndor},
  booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},
  title     = {Available Bandwidth Measurement in Software Defined Networks},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {651–657},
  publisher = {Association for Computing Machinery},
  series    = {SAC '16},
  abstract  = {Software Defined Networking (SDN) is an emerging paradigm that is expected to revolutionize computer networks. With the decoupling of data and control plane and the introduction of open communication interfaces between layers, SDN enables programmability over the entire network, promising rapid innovation in this area. The SDN concept was already proven to work successfully in cloud and data center environments thus the proper monitoring of such networks is already in the focus of the research community. Methods for measuring Quality of Service (QoS) parameters such as bandwidth utilization, packet loss, and delay have been recently introduced in literature, but they lack a solution for tackling down the question of available bandwidth. In this paper, we attempt to fill this gap and introduce a novel mechanism for measuring available bandwidth in SDN networks. We take advantage of the SDN architecture and build an application over the Network Operating System (NOS). Our application can track the topology of the network and the bandwidth utilization over the network links, and thus it is able to calculate the available bandwidth between any two points in the network. We validate our method using the popular Mininet network emulation environment and the widely used NOS called Floodlight. We present results providing insights into the measurement accuracy and showing its relationship with the delay in the control network and the polling frequency.},
  doi       = {10.1145/2851613.2851727},
  isbn      = {9781450337397},
  keywords  = {software defined networks, floodlight, network operating system, OpenFlow, available bandwidth, mininet},
  location  = {Pisa, Italy},
  numpages  = {7},
  url       = {https://doi.org/10.1145/2851613.2851727},
}

@InProceedings{Chauvel2014,
  author    = {Chauvel, Franck and Song, Hui and Ferry, Nicolas and Fleurey, Franck},
  booktitle = {Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing},
  title     = {Robustness Indicators for Cloud-Based Systems Topologies},
  year      = {2014},
  address   = {USA},
  pages     = {307–316},
  publisher = {IEEE Computer Society},
  series    = {UCC '14},
  abstract  = {Various services are now available in the Cloud, ranging from turnkey databases and application servers to high-level services such as continuous integration or source version control. To stand out of this diversity, robustness of service compositions is an important selling argument, but which remains difficult to understand and estimate as it does not only depend on services but also on the underlying platform and infrastructure. Yet, choosing a specific service composition may fail to deliver the expected robustness, but reverting early choices may jeopardise the success of any Cloud project. Inspired by existing models used in Biology to quantify the robustness of ecosystems, we show how to tailor them to obtain early indicators of robustness for cloud-based deployments. This technique helps identify weakest services in the overall architecture and in turn mitigates the risk of having to revert key architectural choices. We illustrate our approach by comparing the robustness of four alternative deployments of the Sens App application, which includes a Mongo DB database, four REST services and a graphical web-front end.},
  doi       = {10.1109/UCC.2014.40},
  isbn      = {9781479978816},
  keywords  = {robustness indicators, failures sequences, extinction sequences, cloud topologies, deployment, bio-inspired},
  numpages  = {10},
  url       = {https://doi.org/10.1109/UCC.2014.40},
}

@InProceedings{Coutinho2014,
  author    = {Coutinho, Emanuel F. and Moreira, Leonardo O. and Paillard, Gabriel A. L. and Maia, Jos\'{e} G. R.},
  booktitle = {Proceedings of the 7th Euro American Conference on Telematics and Information Systems},
  title     = {How to Deploy a Virtual Learning Environment in the Cloud?},
  year      = {2014},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {EATIS '14},
  abstract  = {Cloud computing is a trend of technology aimed at providing on-demand services with payment based on usage. Virtual Learning Environments (VLEs) are applications that require a highly scalable architecture that provides for its users an acceptable level of Quality of Service (QoS). This work aims to show the steps needed to install a VLE in a cloud computing infrastructure. The VLE's migration to this new type of execution environment allows the increase of its use but also brings some performance issues that must be considered. The case study will consider the Moodle VLE which was chosen for its widespread use.},
  articleno = {25},
  doi       = {10.1145/2590651.2590675},
  isbn      = {9781450324359},
  keywords  = {cloud computing, moodle, virtual learning environment},
  location  = {Valparaiso, Chile},
  numpages  = {4},
  url       = {https://doi.org/10.1145/2590651.2590675},
}

@Article{Rolin2019,
  author     = {Rolin, Raphael and Antaluca, Eduard and Batoz, Jean-Louis and Lamarque, Fabien and Lejeune, Mathieu},
  journal    = {J. Comput. Cult. Herit.},
  title      = {From Point Cloud Data to Structural Analysis Through a Geometrical HBIM-Oriented Model},
  year       = {2019},
  issn       = {1556-4673},
  month      = {may},
  number     = {2},
  volume     = {12},
  abstract   = {The assessment of the structural behavior of historic masonry structures like Gothic cathedrals is an important engineering and architectural issue, because of the economic and cultural relevance of such buildings. In this article, we present a complete numerical methodology for point clouds processing, geometrical and parametric 3D modeling, and finite element structural analysis of the spire of the Cathedral of Senlis, France. Our work highlights the particular difficulties linked with digitization and geometrical modeling of highly complex Gothic structures, as well as the need to find compromises between quality and accuracy of extracted data used for geometrical modeling and structural analysis.The methodology enables the semi-automatic transformation of a three-dimensional points cloud, surveyed through terrestrial laser scanner, into a three-dimensional geometrical historic building information modeling (hBIM)-oriented model, and its use to propose a consistent 3D finite element mesh suitable for advanced structural analysis. A full software chain is integrated in the proposed numerical process, so as to use the most important data contained in the real geometry and accurately transposed in the point clouds. After a successful data processing step with 3DReshaper software that proved to be necessary for enhancement of point clouds, a semi-automated geometrical hBIM-oriented modeling step with Rhinoceros5 software and VisualARQ plugin has allowed the construction of a hybrid model by reverse engineering from the point clouds. This 3D model, containing both geometrical and parametric data of the structure, has been exported to the Hyperworks suite for finite element structural analysis under self-weight. Our computations focused on the estimation of the structure deformation and on the distribution of compression and traction stresses in all components of the complex structure. It is found that the spire is safe. Based on reliable and properly detailed results, our study provides significant information for understanding the behavior of the structure and potential damage monitoring.},
  address    = {New York, NY, USA},
  articleno  = {9},
  doi        = {10.1145/3242901},
  issue_date = {June 2019},
  keywords   = {cultural heritage, finite element structural analysis, point clouds, building information modeling, geometrical modeling, Historical buildings, terrestrial laser scanning},
  numpages   = {26},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3242901},
}

@InProceedings{Zhang2014c,
  author    = {Zhang, Yunqi and Laurenzano, Michael A. and Mars, Jason and Tang, Lingjia},
  booktitle = {Proceedings of the 47th Annual IEEE/ACM International Symposium on Microarchitecture},
  title     = {SMiTe: Precise QoS Prediction on Real-System SMT Processors to Improve Utilization in Warehouse Scale Computers},
  year      = {2014},
  address   = {USA},
  pages     = {406–418},
  publisher = {IEEE Computer Society},
  series    = {MICRO-47},
  abstract  = {One of the key challenges for improving efficiency in warehouse scale computers (WSCs) is to improve server utilization while guaranteeing the quality of service (QoS) of latency-sensitive applications. To this end, prior work has proposed techniques to precisely predict performance and QoS interference to identify 'safe' application co-locations. However, such techniques are only applicable to resources shared across cores. Achieving such precise interference prediction on real-system simultaneous multithreading (SMT) architectures has been a significantly challenging open problem due to the complexity introduced by sharing resources within a core.In this paper, we demonstrate through a real-system investigation that the fundamental difference between resource sharing behaviors on CMP and SMT architectures calls for a redesign of the way we model interference. For SMT servers, the interference on different shared resources, including private caches, memory ports, as well as integer and floating-point functional units, do not correlate with each other. This insight suggests the necessity of decoupling interference into multiple resource sharing dimensions. In this work, we propose SMiTe, a methodology that enables precise performance prediction for SMT co-location on real-system commodity processors. With a set of Rulers, which are carefully designed software stressors that apply pressure to a multidimensional space of shared resources, we quantify application sensitivity and contentiousness in a decoupled manner. We then establish a regression model to combine the sensitivity and contentiousness in different dimensions to predict performance interference. Using this methodology, we are able to precisely predict the performance interference in SMT co-location with an average error of 2.80\% on SPEC CPU2006 and 1.79\% on Cloud Suite. Our evaluation shows that SMiTe allows us to improve the utilization of WSCs by up to 42.57\% while enforcing an application's QoS requirements.},
  doi       = {10.1109/MICRO.2014.53},
  isbn      = {9781479969982},
  keywords  = {quality of service, simultaneous multithreading, warehouse scale computer, datacenter},
  location  = {Cambridge, United Kingdom},
  numpages  = {13},
  url       = {https://doi.org/10.1109/MICRO.2014.53},
}

@InProceedings{Chavarriaga2014,
  author    = {Chavarriaga, Jaime and Noguera, Carlos A. and Casallas, Rubby and Jonckers, Viviane},
  booktitle = {Proceedings of the 10th International ACM Sigsoft Conference on Quality of Software Architectures},
  title     = {Architectural Tactics Support in Cloud Computing Providers: The Jelastic Case},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {13–22},
  publisher = {Association for Computing Machinery},
  series    = {QoSA '14},
  abstract  = {When developing and deploying applications in the cloud, architects face the challenge of conciliating architectural decisions with the options and restrictions imposed by the chosen cloud provider. An architectural decision can be seen as a two-step process: selecting architectural tactics to promote quality attributes and choosing design alternatives to implement those tactics. Available design alternatives are limited by the offer of the cloud provider. When configuring the cloud platform and its services as directed by the chosen tactics, the architect must be mindful of conflicts among the available alternatives. These trade-offs amongst the desired quality attributes can be difficult to detect, understand and ultimately solve. In this paper, we consider the case of Jelastic, a particular cloud platform provider, to illustrate: 1) the modeling of architectural tactics and their corresponding design alternatives using cloud configuration options, and 2) a process that exploits these models to determine which options to use in order to implement a combination of tactics. Furthermore, we present an analysis for this cloud provider that explains which combinations of tactics and configurations lead to trade-offs.},
  doi       = {10.1145/2602576.2602580},
  isbn      = {9781450325769},
  keywords  = {feature model, quality attributes, cloud computing, architectural tactics},
  location  = {Marcq-en-Bareul, France},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2602576.2602580},
}

@InProceedings{Paleyes2022,
  author    = {Paleyes, Andrei and Cabrera, Christian and Lawrence, Neil D.},
  booktitle = {Proceedings of the 1st International Conference on AI Engineering: Software Engineering for AI},
  title     = {An Empirical Evaluation of Flow Based Programming in the Machine Learning Deployment Context},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {54–64},
  publisher = {Association for Computing Machinery},
  series    = {CAIN '22},
  abstract  = {As use of data driven technologies spreads, software engineers are more often faced with the task of solving a business problem using data-driven methods such as machine learning (ML) algorithms. Deployment of ML within large software systems brings new challenges that are not addressed by standard engineering practices and as a result businesses observe high rate of ML deployment project failures. Data Oriented Architecture (DOA) is an emerging approach that can support data scientists and software developers when addressing such challenges. However, there is a lack of clarity about how DOA systems should be implemented in practice. This paper proposes to consider Flow-Based Programming (FBP) as a paradigm for creating DOA applications. We empirically evaluate FBP in the context of ML deployment on four applications that represent typical data science projects. We use Service Oriented Architecture (SOA) as a baseline for comparison. Evaluation is done with respect to different application domains, ML deployment stages, and code quality metrics. Results reveal that FBP is a suitable paradigm for data collection and data science tasks, and is able to simplify data collection and discovery when compared with SOA. We discuss the advantages of FBP as well as the gaps that need to be addressed to increase FBP adoption as a standard design paradigm for DOA.},
  doi       = {10.1145/3522664.3528601},
  isbn      = {9781450392754},
  keywords  = {machine learning, service-oriented architecture, flow-based programming, software engineering},
  location  = {Pittsburgh, Pennsylvania},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3522664.3528601},
}

@InProceedings{Sapin2023,
  author    = {Sapin, Etienne and Menon, Suraj and Ge, Jingquan and Habib, Sheikh Mahbub and Heymann, Maurice and Li, Yuekang and Palige, Rene and Byman, Gabriel and Liu, Yang},
  booktitle = {Proceedings of the 7th ACM Computer Science in Cars Symposium},
  title     = {Monitoring Automotive Software Security Health through Trustworthiness Score},
  year      = {2023},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {CSCS '23},
  abstract  = {The automotive industry is drastically moving towards autonomous. This trend constitutes in a fundamental change of going from mechanical and electrical engineering towards software-driven approaches. Modern vehicles can embed more than hundred electronic control units (ECUs). As autonomous vehicles require more intelligence as well as more computing power, high-performance computers (HPCs) bring the data management capabilities for cloud and IoT services to support the transition to a service-oriented vehicle system architecture. With this growing reliance on software in vehicles, software reliability and trustworthiness are increasingly critical to vehicle security. Measuring security trustworthiness in automotive software is even more valuable as cybersecurity is shifting to the left, i.e. in the early phase of development and design process. In this article, we propose a novel method for evaluating security trustworthiness of automotive software by leveraging a computational trust model. The method consists of selecting different domains contributing to software security, calculating their respective expectation value (trustworthiness score) and combining it using operators from the computational trust model. We evaluate the method using an automotive use case, i.e. over-the-air (OTA) update software. We describe a possible integration of the proposed method into a solution which would be valuable for cybersecurity stakeholders, e.g. cybersecurity managers, cybersecurity architects and software quality managers, aiming to monitor security health of automotive software throughout its development life cycle.},
  articleno = {1},
  doi       = {10.1145/3631204.3631859},
  isbn      = {9798400704543},
  keywords  = {Software health, Trustworthiness, Data visualization},
  location  = {<conf-loc>, <city>Darmstadt</city>, <country>Germany</country>, </conf-loc>},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3631204.3631859},
}

@InProceedings{Alzboon2022,
  author    = {Alzboon, Ghufran and Al-Said Ahmad, Amro},
  booktitle = {Proceedings of the 2022 6th International Conference on Cloud and Big Data Computing},
  title     = {A Performance Evaluation Approach for N-Tier Cloud-Based Software Services},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {31–36},
  publisher = {Association for Computing Machinery},
  series    = {ICCBDC '22},
  abstract  = {Cloud computing and cloud testing are vast fields that have attracted significant attention recently. In addition, the need to find an approach for measuring cloud-based applications' effectiveness has also increased. In this work, we introduced an approach to testing the performance of the cloud software services on the Amazon cloud. We used two cloud-based applications hosted in the Amazon cloud to demonstrate the approach depending on five technical performance metrics. We applied the testing methodology using a JMeter test script. The two selected applications represent two different taxonomies: 2-tier and 3-tier architectures. Following the testing process, we found that the WordPress application (i.e., 3-tier architecture) performs better than Ghost and is more stable in terms of the selected performance metrics. Practitioners would benefit from this study by a better understanding of the assessment and testing of n-tier Cloud-Based Software Services using technical arguments.},
  doi       = {10.1145/3555962.3555968},
  isbn      = {9781450396578},
  keywords  = {evaluation method, Cloud computing, n-tier, Software services, performance},
  location  = {Birmingham, United Kingdom},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3555962.3555968},
}

@Article{Bachiega2023,
  author     = {Bachiega, Joao and Costa, Breno and Carvalho, Leonardo R. and Rosa, Michel J. F. and Araujo, Aleteia},
  journal    = {ACM Comput. Surv.},
  title      = {Computational Resource Allocation in Fog Computing: A Comprehensive Survey},
  year       = {2023},
  issn       = {0360-0300},
  month      = {jul},
  number     = {14s},
  volume     = {55},
  abstract   = {Fog computing is a paradigm that allows the provisioning of computational resources and services at the edge of the network, closer to the end devices and users, complementing cloud computing. The heterogeneity and large number of devices are challenges to obtaining optimized resource allocation in this environment. Over time, some surveys have been presented on resource management in fog computing. However, they now lack a broader and deeper view about this subject, considering the recent publications. This article presents a systematic literature review with a focus on resource allocation for fog computing, and in a more comprehensive way than the existing works. The survey is based on 108 selected publications from 2012 to 2022. The analysis has exposed their main techniques, metrics used, evaluation tools, virtualization methods, architecture, and domains where the proposed solutions were applied. The results show an updated and comprehensive view about resource allocation in fog computing. The main challenges and open research questions are discussed, and a new fog computing resource management cycle is proposed.},
  address    = {New York, NY, USA},
  articleno  = {336},
  doi        = {10.1145/3586181},
  issue_date = {December 2023},
  keywords   = {resource allocation, Fog computing, resource management, resource provisioning},
  numpages   = {31},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3586181},
}

@InProceedings{Cornacchia2023,
  author    = {Cornacchia, Alessandro and Benson, Theophilus A. and Bilal, Muhammad and Canini, Marco},
  booktitle = {Proceedings of the on CoNEXT Student Workshop 2023},
  title     = {MicroView: Cloud-Native Observability with Temporal Precision},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {7–8},
  publisher = {Association for Computing Machinery},
  series    = {CoNEXT-SW '23},
  abstract  = {We present MicroView, a system designed to improve the accuracy and timeliness of observability in cloud-native applications, while minimizing overhead. MicroView stands out from conventional observability tools by incorporating metrics processing stages at every node within a local lightweight data-plane. We preliminary demonstrate its benefits for distributed tracing and outline a set of architectural choices focused on offloading the MicroView data-plane to IPU accelerators, such as a BlueField-3 SmartNIC, thus limiting the interference with running services.},
  doi       = {10.1145/3630202.3630233},
  isbn      = {9798400704529},
  keywords  = {SmartNIC, programmable networks, microservices observability, cloud-native},
  location  = {<conf-loc>, <city>Paris</city>, <country>France</country>, </conf-loc>},
  numpages  = {2},
  url       = {https://doi.org/10.1145/3630202.3630233},
}

@InProceedings{Wen2023,
  author    = {Wen, Hao and Li, Yuanchun and Zhang, Zunshuai and Jiang, Shiqi and Ye, Xiaozhou and Ouyang, Ye and Zhang, Yaqin and Liu, Yunxin},
  booktitle = {Proceedings of the 29th Annual International Conference on Mobile Computing and Networking},
  title     = {AdaptiveNet: Post-Deployment Neural Architecture Adaptation for Diverse Edge Environments},
  year      = {2023},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ACM MobiCom '23},
  abstract  = {Deep learning models are increasingly deployed to edge devices for real-time applications. To ensure stable service quality across diverse edge environments, it is highly desirable to generate tailored model architectures for different conditions. However, conventional pre-deployment model generation approaches are not satisfactory due to the difficulty of handling the diversity of edge environments and the demand for edge information. In this paper, we propose to adapt the model architecture after deployment in the target environment, where the model quality can be precisely measured and private edge data can be retained. To achieve efficient and effective edge model generation, we introduce a pretraining-assisted on-cloud model elastification method and an edge-friendly on-device architecture search method. Model elastification generates a high-quality search space of model architectures with the guidance of a developer-specified oracle model. Each subnet in the space is a valid model with different environment affinity, and each device efficiently finds and maintains the most suitable subnet based on a series of edge-tailored optimizations. Extensive experiments on various edge devices demonstrate that our approach is able to achieve significantly better accuracy-latency tradeoffs (e.g. 46.74\% higher on average accuracy with a 60\% latency budget) than strong baselines with minimal overhead (13 GPU hours in the cloud and 2 minutes on the edge server).},
  articleno = {28},
  doi       = {10.1145/3570361.3592529},
  isbn      = {9781450399906},
  keywords  = {edge environments, post-deployment adaptation, neural networks, model elastification},
  location  = {Madrid, Spain},
  numpages  = {17},
  url       = {https://doi.org/10.1145/3570361.3592529},
}

@InProceedings{Liu2023a,
  author    = {Liu, Xin and Wang, Jibin and Qin, Shuwei},
  booktitle = {Proceedings of the 2022 4th International Conference on Robotics, Intelligent Control and Artificial Intelligence},
  title     = {An Anomaly Detection Framework Based on Data Center Operation and Maintenance Data},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {883–889},
  publisher = {Association for Computing Machinery},
  series    = {RICAI '22},
  abstract  = {Data centers need to monitor various metrics of their different application platforms and applications in real-time. As the system architectures and application services of different application platforms within them become more complex, the requirements for their anomaly detection capabilities are higher. Therefore, this paper proposes an anomaly detection framework based on data center operation and maintenance data. The framework in this paper consists of three parts, including operation and maintenance data cleaning, data feature extraction, and model routing. It is used to select the appropriate model through model routing based on the indicators such as stability and periodicity obtained from data feature extraction of each application platform. At the same time, in order to enhance the expansion capability of the detection algorithm, a cloud-ground hybrid framework is used and a module for algorithm model management is designed to facilitate interaction with the cloud. After testing on SWAT and WADI datasets, the anomaly detection algorithm with the addition of model routing in the framework has good accuracy and recall performance compared to a single anomaly algorithm model, showing advantages in the task of identifying anomalies.},
  doi       = {10.1145/3584376.3584534},
  isbn      = {9781450398343},
  location  = {Dongguan, China},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3584376.3584534},
}

@InProceedings{Li2022f,
  author    = {Li, Zhuoran and Zhao, Dan},
  booktitle = {Proceedings of the 2022 Conference \&amp; Exhibition on Design, Automation \&amp; Test in Europe},
  title     = {ThingNet: A Lightweight Real-Time Mirai IoT Variants Hunter through CPU Power Fingerprinting},
  year      = {2022},
  address   = {Leuven, BEL},
  pages     = {310–315},
  publisher = {European Design and Automation Association},
  series    = {DATE '22},
  abstract  = {Internet of Things (IoT) devices have become attractive targets of cyber criminals, whereas attackers have been leveraging these vulnerable devices most notably via the infamous Mirai-based botnets, accounting for nearly 90\% of IoT malware attacks in 2020. In this work, we propose a robust, universal and non-invasive Mirai-based malware detection engine employing a compact deep neural network architecture. Our design allows programmatic collection of CPU power footprints with integrated current sensors under various device states, such as idle, service and attack. A lightweight online inference model is deployed in the CPU for on-the-fly classification. Our model is robust against noisy environment with a lucid design of noise reduction function. This work appears to be the first step towards a viable CPU malware detection engine based on power fingerprinting. The extensive simulation study under ARM architecture that is widely used in IoT devices, demonstrates a high detection accuracy of 99.1\% at a speed less than 1ms. By analyzing Mirai-based infection under distinguishable phases for power feature extraction, our model has further demonstrated an accuracy of 96.3\% on model-unknown variants detection.},
  isbn      = {9783981926361},
  keywords  = {lightweight deep learning, noise reduction, mirai IoT variants detection, power side-channel auditing},
  location  = {Antwerp, Belgium},
  numpages  = {6},
}

@Article{Burckhardt2022,
  author     = {Burckhardt, Sebastian and Chandramouli, Badrish and Gillum, Chris and Justo, David and Kallas, Konstantinos and McMahon, Connor and Meiklejohn, Christopher S. and Zhu, Xiangfeng},
  journal    = {Proc. VLDB Endow.},
  title      = {Netherite: Efficient Execution of Serverless Workflows},
  year       = {2022},
  issn       = {2150-8097},
  month      = {apr},
  number     = {8},
  pages      = {1591–1604},
  volume     = {15},
  abstract   = {Serverless is a popular choice for cloud service architects because it can provide scalability and load-based billing with minimal developer effort. Functions-as-a-service (FaaS) are originally stateless, but emerging frameworks add stateful abstractions. For instance, the widely used Durable Functions (DF) allow developers to write advanced serverless applications, including reliable workflows and actors, in a programming language of choice. DF implicitly and continuosly persists the state and progress of applications, which greatly simplifies development, but can create an IOps bottleneck.To improve efficiency, we introduce Netherite, a novel architecture for executing serverless workflows on an elastic cluster. Netherite groups the numerous application objects into a smaller number of partitions, and pipelines the state persistence of each partition. This improves latency and throughput, as it enables workflow steps to group commit, even if causally dependent. Moreover, Netherite leverages FASTER's hybrid log approach to support larger-than-memory application state, and to enable efficient partition movement between compute hosts.Our evaluation shows that (a) Netherite achieves lower latency and higher throughput than the original DF engine, by more than an order of magnitude in some cases, and (b) that Netherite has lower latency than some commonly used alternatives, like AWS Step Functions or cloud storage triggers.},
  doi        = {10.14778/3529337.3529344},
  issue_date = {April 2022},
  numpages   = {14},
  publisher  = {VLDB Endowment},
  url        = {https://doi.org/10.14778/3529337.3529344},
}

@InProceedings{Sekar2023,
  author    = {Sekar, Santhoshini and Mishra, Ashok Kumar and Giladi, Alex and Grois, Dan},
  booktitle = {Proceedings of the 2nd Mile-High Video Conference},
  title     = {Novel Motion-Compensated Spatio-Temporal Filtering Scheme for X265 Open-Source Video Encoder},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {126–127},
  publisher = {Association for Computing Machinery},
  series    = {MHV '23},
  abstract  = {There is a strong demand to decrease the video transmission bitrate without reducing visual quality [1]. The x265 encoder [2]-[4] is a popular open-source encoder, which generates bitstreams compliant with the H.265/MPEG-HEVC video coding standard [5]. Built on top of x264[6], the x265 encoder is integrated into several popular open-source frameworks, such as ffmpeg [7], GStreamer [8], and Handbrake [9]. In addition, the x265 is used by a variety of broadcast and streaming service providers who leverage the benefits of HEVC for streaming live and over-the-top (OTT) content. In addition to implementing nearly all the tools defined in HEVC, it implements many algorithmic optimizations that enable trading off encoder performance for quality [2]-[4]. The performance-critical kernels are implemented with hand-coded assembly kernels that use AVX2 and AVX-512 single instruction, multiple data instructions to improve performance on x86 CPUs. This flexible architecture of x265 makes it a popular choice for HEVC encoding for both on-premises and cloud services.Recent x265 development efforts have been focused on further improving the coding gains. Specifically, the motion compensated spatio-temporal filtering (MCSTF) employed within the coding loop is especially useful for pictures that contain a high level of noise. It utilizes previously generated motion vectors across different video content resolutions to find the best temporal correspondence for low-pass filtering, while the temporal filtering is applied to the I- and P-frames. Figure 1 schematically illustrates the motion estimation process for temporal filtering in a temporal window, which consists of 5 adjacent pictures: two past, two future and one central picture used for producing a single filtered picture. Motion estimation is applied between the central picture and each future or past picture, thereby generating multiple motion-compensated predictions, which are then combined by using adaptive filtering to produce a final noise-reduced picture. Thus, a hierarchical motion estimation scheme is employed (layers L0, L1 and L2, are illustrated in Figure 2). Subsampled pictures are generated for all reference picturesand the original picture as well: i.e., L1, while L2 is derived from L1 by using the same subsampling method. First, the motion estimation is done for each 16x16 block in L2. Then, the selected motion vector is used as an initial value for estimating the motion in L1. After that, the same is performed for estimating the motion in L0.As a final step, the subpixel motion is estimated for each 8x8 block by using an interpolation filter on L0. Particularly, the motion of reference pictures before and after, relative to the original picture, is estimated per the 8x8 picture block. In turn, the motion compensation is applied on the pictures before and after the original picture according to the best matching motion for each block. i.e., such that pixel coordinates of the original picture in each block have the best matching coordinates within the referenced pictures. The filter is then applied to the current pixels, and after that, the filtered picture is encoded. Note that the pixels are processed one by one for the luma and chroma channels. The new sample value, is calculated by using the following equation:[EQUATION]where Io is the original pixel, Ir(i) is the intensity of the corresponding pixel within the motion compensated picture i, and wr(i, a) is the weight of the motion compensated picture where a is the number of available motion compensated pictures. The conducted extensive experimental results show significant bit-rate savings in terms of BD-BR [10].},
  doi       = {10.1145/3588444.3591024},
  isbn      = {9798400701603},
  keywords  = {open-source, computational complexity, MCSTF, H.265, HEVC, coding gain, x265, HM},
  location  = {Denver, CO, USA},
  numpages  = {2},
  url       = {https://doi.org/10.1145/3588444.3591024},
}

@InProceedings{VanSinh2016,
  author    = {Van Sinh, Nguyen and Ha, Tran Manh and Thanh, Nguyen Tien},
  booktitle = {Proceedings of the 7th Symposium on Information and Communication Technology},
  title     = {Filling Holes on the Surface of 3D Point Clouds Based on Tangent Plane of Hole Boundary Points},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {331–338},
  publisher = {Association for Computing Machinery},
  series    = {SoICT '16},
  abstract  = {Filling the holes of a triangular mesh has been studied for many years in the field of geometric modeling. This research is one of the reconstructing steps of a triangular mesh (or called refinement of a mesh) in order to improve the quality of a 3D triangular surface. With the same idea of hole filling in a mesh, filling in the holes of a 3D point cloud is still a challenge to the researchers. This paper describes a method for filling holes in an elevation surface of 3D point clouds structured in a 3D grid. The novelty of the method is processed directly on the 3D point clouds consisting of two steps. In the first step, we determine the boundary of hole. In the second step, we fill the holes based on the computation of tangent plane for each boundary point. Following clock-wise direction on the hole boundary, we compute and insert missing points on each tangent plane. This process is repeated and refined ring by ring from the hole boundary to the inside of the hole. The obtained results show that the processing time of algorithm is very fast, the output surfaces preserve their initial shapes and local curvatures.},
  doi       = {10.1145/3011077.3011126},
  isbn      = {9781450348157},
  keywords  = {hole filling, elevation surface, boundary point, tangent plane, 3D point cloud},
  location  = {Ho Chi Minh City, Vietnam},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3011077.3011126},
}

@InProceedings{Weerasinghe2021,
  author    = {Weerasinghe, L. D. S. B. and Perera, Indika},
  booktitle = {2021 International Research Conference on Smart Computing and Systems Engineering (SCSE)},
  title     = {An exploratory evaluation of replacing ESB with microservices in service-oriented architecture},
  year      = {2021},
  month     = {Sep.},
  pages     = {137-144},
  volume    = {4},
  abstract  = {With the continuous progress in technology during the past few decades, cloud computing has become a fast-growing technology in the world, making computerized systems widespread. The emergence of Cloud Computing has evolved towards microservice concepts, which are highly demanded by corporates for enterprise application level. Most enterprise applications have moved away from traditional unified models of software programs like monolithic architecture and traditional SOA architecture to microservice architecture to ensure better scalability, lesser investment in hardware, and high performance. The monolithic architecture is designed in a manner that all the components and the modules are packed together and deployed on a single binary. However, in the microservice architecture, components are developed as small services so that horizontally and vertically scaling is made easier in comparison to monolith or SOA architecture. SOA and monolithic architecture are at a disadvantage compared to Microservice architecture, as they require colossal hardware specifications to scale the software. In general terms, the system performance of these architectures can be measured considering different aspects such as system capacity, throughput, and latency. This research focuses on how scalability and performance software quality attributes behave when converting the SOA system to microservice architecture. Experimental results have shown that microservice architecture can bring more scalability with a minimum cost generation. Nevertheless, specific gaps in performance are identified in the perspective of the final user experiences due to the interservice communication in the microservice architecture in a distributed environment.},
  doi       = {10.1109/SCSE53661.2021.9568289},
  issn      = {2613-8662},
}

@InProceedings{Mazlami2017,
  author    = {Mazlami, Genc and Cito, Jürgen and Leitner, Philipp},
  booktitle = {2017 IEEE International Conference on Web Services (ICWS)},
  title     = {Extraction of Microservices from Monolithic Software Architectures},
  year      = {2017},
  month     = {June},
  pages     = {524-531},
  abstract  = {Driven by developments such as mobile computing, cloud computing infrastructure, DevOps and elastic computing, the microservice architectural style has emerged as a new alternative to the monolithic style for designing large software systems. Monolithic legacy applications in industry undergo a migration to microservice-oriented architectures. A key challenge in this context is the extraction of microservices from existing monolithic code bases. While informal migration patterns and techniques exist, there is a lack of formal models and automated support tools in that area. This paper tackles that challenge by presenting a formal microservice extraction model to allow algorithmic recommendation of microservice candidates in a refactoring and migration scenario. The formal model is implemented in a web-based prototype. A performance evaluation demonstrates that the presented approach provides adequate performance. The recommendation quality is evaluated quantitatively by custom microservice-specific metrics. The results show that the produced microservice candidates lower the average development team size down to half of the original size or lower. Furthermore, the size of recommended microservice conforms with microservice sizing reported by empirical surveys and the domain-specific redundancy among different microservices is kept at a low rate.},
  doi       = {10.1109/ICWS.2017.61},
}

@InProceedings{Khan2020,
  author    = {Khan, Michel Gokan and Taheri, Javid and Khoshkholghi, Mohammad Ali and Kassler, Andreas and Cartwright, Carolyn and Darula, Marian and Deng, Shuiguang},
  booktitle = {2020 6th IEEE Conference on Network Softwarization (NetSoft)},
  title     = {A Performance Modelling Approach for SLA-Aware Resource Recommendation in Cloud Native Network Functions},
  year      = {2020},
  month     = {June},
  pages     = {292-300},
  abstract  = {Network Function Virtualization (NFV) becomes the primary driver for the evolution of 5G networks, and in recent years, Network Function Cloudification (NFC) proved to be an inevitable part of this evolution. Microservice architecture also becomes the de facto choice for designing a modern Cloud Native Network Function (CNF) due to its ability to decouple components of each CNF into multiple independently manageable microservices. Even though taking advantage of microservice architecture in designing CNFs solves specific problems, this additional granularity makes estimating resource requirements for a Production Environment (PE) a complex task and sometimes leads to an over-provisioned PE. Traditionally, performance engineers dimension each CNF within a Service Function Chain (SFC) in a smaller Performance Testing Environment (PTE) through a series of performance benchmarks. Then, considering the Quality of Service (QoS) constraints of a Service Provider (SP) that are guaranteed in the Service Level Agreement (SLA), they estimate the required resources to set up the PE. In this paper, we used a machine learning approach to model the impact of each microservice's resource configuration (i.e., CPU and memory) on the QoS metrics (i.e. serving throughput and latency) of each SFC in a PTE. Then, considering an SP's Service Level Objectives (SLO), we proposed an algorithm to predict each microservice's resource capacities in a PE. We evaluated the accuracy of our prediction on a prototype of a cloud native 5G Home Subscriber Server (HSS). Our model showed 95%-78% accuracy in a PE that has 2-5 times more computing resources than the PTE.},
  doi       = {10.1109/NetSoft48620.2020.9165482},
}

@InProceedings{Heideker2021,
  author    = {Heideker, Alexandre and Kamienski, Carlos},
  booktitle = {2021 IEEE 18th Annual Consumer Communications & Networking Conference (CCNC)},
  title     = {Towards a Network Queuing Assessment for Elasticity Management of Virtualized Services},
  year      = {2021},
  month     = {Jan},
  pages     = {1-6},
  abstract  = {With the increasing adoption of cloud computing, microservice architecture, and network function virtualization (NFV), addressing scalability and elasticity management becomes essential. The high demand for these services challenges the research community to create new automated management techniques, from which an essential part is the detection of bottlenecks in infrastructures and application boxes. The traditional approach based on hardware resource metrics (CPU and RAM) is the most straightforward strategy, providing independence from particular applications but may not capture the application's behavior in terms of workload variations. On the other hand, using an application-oriented approach provides a significant correlation with the end-user quality of experience but needs to be tailored for each case. We propose the Network Queuing Assessment (NQA) that breaks away with this tradeoff, capturing the application's workload variations and providing a significant correlation with the end-user quality of experience. Also, similarly to CPU and RAM, it is independent of particular applications. Our performance analysis results for CPU, RAM, and NQA metrics using virtualized applications and network functions in a cloud environment confirm this approach's usefulness.},
  doi       = {10.1109/CCNC49032.2021.9369609},
  issn      = {2331-9860},
}

@InProceedings{Yu2019a,
  author    = {Yu, Guangba and Chen, Pengfei and Zheng, Zibin},
  booktitle = {2019 IEEE International Conference on Web Services (ICWS)},
  title     = {Microscaler: Automatic Scaling for Microservices with an Online Learning Approach},
  year      = {2019},
  month     = {July},
  pages     = {68-75},
  abstract  = {Recently, the microservice becomes a popular architecture to construct cloud native systems due to its agility. In cloud native systems, autoscaling is a core enabling technique to adapt to workload changes by scaling out/in. However, it becomes a challenging problem in a microservice system, since such a system usually comprises a large number of different micro services with complex interactions. When bursty and unpredictable workloads arrive, it is difficult to pinpoint the scaling-needed services which need to scale and evaluate how much resource they need. In this paper, we present a novel system named Microscaler to automatically identify the scaling-needed services and scale them to meet the service level agreement (SLA) with an optimal cost for micro-service systems. Microscaler collects the quality of service metrics (QoS) with the help of the service mesh enabled infrastructure. Then, it determines the under-provisioning or over-provisioning services with a novel criterion named service power. By combining an online learning approach and a step-by-step heuristic approach, Microscaler could achieve the optimal service scale satisfying the SLA requirements. The experimental evaluations in a micro-service benchmark show that Microscaler converges to the optimal service scale faster than several state-of-the-art methods.},
  doi       = {10.1109/ICWS.2019.00023},
}

@InProceedings{Keserwani2017,
  author    = {Keserwani, Pankaj Kumar and Samaddar, Shefalika Ghosh},
  booktitle = {2017 Ninth International Conference on Advanced Computing (ICoAC)},
  title     = {An SLA Design with Digital Forensic Capabilities},
  year      = {2017},
  month     = {Dec},
  pages     = {109-113},
  abstract  = {Cloud computing is getting rapid momentum as an alternative to traditional and professional Infrastructure of Information Technology due to its attractive features of getting everything in a service mode rather than in a product mode. Service mode using cloud makes the products and services cost effective. As consumers willing to pass on their tasks as services provider to cloud providers, trust factor is required especially when consumers have critical data. The Service Level Agreements (SLA) between cloud service consumers (CSCs) and cloud service providers (CSPs) play important role for building up trust between involved parties. SLA between parties is established in a satisfactory way upon agreements. Cloud computing is very dynamic in nature, hence continuous monitoring on Quality of Service (QoS) attributes as mentioned in SLA is required to be implemented dynamically. Managing SLAs is complicated due to complex nature of the cloud due to multi-tenancy and distributed resource sharing. The paper proposes a methodology for SLAs to be signed digitally and its further management in a single or multi cloud computing environment. The framework had been used in Web Service Level Agreement (WSLA) for monitoring and enforcement of SLA using Service Oriented Architecture (SOA) environment. Cloud broker agents have the capability of automatic extraction of metrics from SLAs. The use of the third party support feature to manage the digital forensics in case of requirement of any violation of SLAs suggested in the present paper and it is also solving the trust issues as demonstrated in digital forensics usage from the initiation of SLA; making the SLA naturally forensic enabled.},
  doi       = {10.1109/ICoAC.2017.8441460},
}

@InProceedings{Yaqub2014,
  author    = {Yaqub, Edwin and Yahyapour, Ramin and Wieder, Philipp and Kotsokalis, Constantinos and Lu, Kuan and Jehangiri, Ali Imran},
  booktitle = {2014 IEEE International Conference on Services Computing},
  title     = {Optimal Negotiation of Service Level Agreements for Cloud-Based Services through Autonomous Agents},
  year      = {2014},
  month     = {June},
  pages     = {59-66},
  abstract  = {Cloud-based services have become a cornerstone of today's IT. The self-service feature inherent in Cloud systems allows customers to play a greater role in service procurement. However, this restricts the value propositions and Service Level Agreements (SLAs) that Cloud providers offer because Quality of Service (QoS) and Non Functional Property (NFP) requirements vary from customer to customer. In feature-rich SLA templates, the contract space gets large, objectives are confidential and preferences over QoS and NFP often conflict between providers and customers. Hence, an SLA-gap exists between the two and contemporary providers bind their offerings to the inflexible take-it-or-leave-it SLAs. In this work, we address this problem by presenting a robust and computationally inexpensive negotiation strategy, using which agents can efficiently create near-optimal SLAs under time constraints. Experimental evaluations validate that our strategy performs at par with state of the art learning and non-learning strategies against a variety of metrics including utility, social welfare, social utility and the Pareto-optimal bids. This enables a dynamic SLA negotiation mechanism on top of our OpenShift (PaaS) based Cloud system designed using Service Oriented Cloud Computing Infrastructure (SOCCI) architecture. Negotiated procurement of services is shown to improve satisfaction of participants and reducing the SLA-gap.},
  doi       = {10.1109/SCC.2014.17},
}

@InProceedings{Zhang2023d,
  author    = {Zhang, Yang and Li, Yang and Yang, Yilong and Chen, Shuang and Gao, Juntao and Wang, Weiru and Yin, Yongfeng},
  booktitle = {2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)},
  title     = {RapidMS: A Tool for Supporting Rapid Microservices Generation and Refinement from Requirements Model},
  year      = {2023},
  month     = {Oct},
  pages     = {45-49},
  abstract  = {Microservices is a crucial architecture design pat-tern for developing cloud-native applications, which focuses on decomposing a large and complex software system into autonomous components that can be independently developed and deployed. However, microservices design is not a trivial task, which highly depends on the profound knowledge and experience of system design and target domain. This is a challenge for novice software architects. In this paper, we propose a microservices design tool named RapidMS, which only requires architects to specify potential context boundaries on the requirements model. The microservices architecture design model with component structure and interaction views can be automatically generated without extra human effort. Moreover, the proposed tool can automatically calculate the characteristic metrics of the microservices, which indicate the quality of the different aspects of models to support rapid architecture refinements. We demonstrate the tool's effectiveness through five case studies. The experimental result shows that architects can get better decomposition of requirement model within four iterations and over 90% of microservice architecture diagrams can be correctly generated within 10 seconds. RapidMS can be further extended and applied in the software industry to reduce the cost and difficulty of microservices decomposition and design. The tool can be downloaded at https://rm2pt.com/advs/ rapidms, and a demo video casting its features is at https://youtu.be/AoIM41FTnFO},
  doi       = {10.1109/MODELS-C59198.2023.00017},
}

@Article{Sebrechts2022,
  author   = {Sebrechts, Merlijn and Volckaert, Bruno and De Turck, Filip and Yang, Kun and Al-Naday, Mays},
  journal  = {IEEE Communications Magazine},
  title    = {Fog Native Architecture: Intent-Based Workflows to Take Cloud Native toward the Edge},
  year     = {2022},
  issn     = {1558-1896},
  month    = {August},
  number   = {8},
  pages    = {44-50},
  volume   = {60},
  abstract = {The cloud native approach is rapidly transforming how applications are developed and operated, turning monolithic applications into microservice applications, allowing teams to release faster, increase reliability, and expedite operations by taking full advantage of cloud resources and their elasticity. At the same time, “fog computing” is emerging, bringing the cloud toward the edge, near the end user, in order to increase privacy, improve resource efficiency, and reduce latency. Combining these two trends, however, proves difficult because of four fundamental disconnects between the cloud native paradigm and fog computing. This article identifies these disconnects and proposes a fog native architecture along with a set of design patterns to take full advantage of the fog. Central to this approach is turning microservice applications into microservice workflows, constructed dynamically by the system using an intent-based approach taking into account a number of factors such as user requirements, request location, and available infrastructure and microservices. The architecture introduces a novel softwarized fog mesh facilitating both inter-microservice connectivity, external communication, and end-user aggregation. Our evaluation analyzes the impact of distributing microservice-based applications over a fog ecosystem, illustrating the impact of CPU and network latency and application metrics on perceived quality of service of fog native workflows compared to the cloud. The results show the fog can offer superior application performance given the right conditions.},
  doi      = {10.1109/MCOM.003.2101075},
}

@Article{Yu2022,
  author   = {Yu, Guangba and Chen, Pengfei and Zheng, Zibin},
  journal  = {IEEE Transactions on Cloud Computing},
  title    = {Microscaler: Cost-Effective Scaling for Microservice Applications in the Cloud With an Online Learning Approach},
  year     = {2022},
  issn     = {2168-7161},
  month    = {April},
  number   = {2},
  pages    = {1100-1116},
  volume   = {10},
  abstract = {Recently, the microservice becomes a popular architecture to construct cloud native systems due to its agility. In cloud native systems, autoscaling is a key enabling technique to adapt to workload changes by acquiring or releasing the right amount of computing resources. However, it becomes a challenging problem in microservice applications, since such an application usually comprises a large number of different microservices with complex interactions. When the performance decreases due to an unpredictable workload peak, it is difficult to pinpoint the scaling-needed services which need to scale out and evaluate how many resources they need. In this article, we present a novel system named Microscaler to automatically identify the scaling-needed services and scale them to meet the Service Level Agreement (SLA) with an optimal cost for microservice applications. Microscaler first collects the quality of service (QoS) metrics in the service mesh enabled microservice infrastructure. Then, it determines under-provisioning or over-provisioning service instances along the service dependency graph with a novel scaling-needed service criterion named service power. The service dependency graph could be obtained by correlating each request flow in the service mesh. By combining an online learning approach and a step-by-step heuristic approach, Microscaler can precisely reach the optimal service scale meeting the SLA requirements. The experimental evaluations in a microservice benchmark show that Microscaler achieves an average 93 percent precision in scaling-needed service determination and converges to the optimal service scale faster than several state-of-the-art methods. Moreover, Microscaler is lightweight and flexible enough to work in a large-scale microservice system.},
  doi      = {10.1109/TCC.2020.2985352},
}

 @Comment{jabref-meta: databaseType:bibtex;}
