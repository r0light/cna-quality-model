@inproceedings{10.5555/3615924.3615929,
author = {Joydeep, Mukherjee and Sumona, Mukhopadhyay and Marin, Litoiu},
title = {Detecting Software Anomalies Using Spectrograms and Convolutional Neural Network},
year = {2023},
publisher = {IBM Corp.},
address = {USA},
abstract = {Microservice applications are increasingly embracing cloud platforms to run their services. These applications can often be impacted by anomalies. Detecting anomalies at runtime is vital to ensure that cloud-native applications meet specified requirements and ensure good Quality-of-Service. However, this is challenging to do since application owners do not always have access to the underlying cloud infrastructure and hence can not use host level metrics and hardware counters as done in the past. One potential way to address this challenge is to use a machine learning based anomaly detection approach which uses metrics that can be easily collected from applications running on public cloud platforms. In this paper, we develop a classifier using deep learning for pattern recognition of anomalies for detecting runtime software anomalies in cloud-native applications. We use textured images known as spectrograms that are obtained from time series measurement readily available from cloud-native applications. These spectrogram images are used to train a Convolutional Neural Network (CNN) classifier for anomaly detection. We evaluate our approach on two real-world datasets that capture known software anomalies in public cloud platforms. Results show that the proposed spectrogram based CNN classifier yields detection accuracy of 99\% for both datasets at runtime and outperforms a competing non-image based classifier.},
booktitle = {Proceedings of the 33rd Annual International Conference on Computer Science and Software Engineering},
pages = {44–53},
numpages = {10},
keywords = {Cloud Computing, Deep Learning, Software Anomalies},
location = {Las Vegas, NV, USA},
series = {CASCON '23}
}

@inproceedings{10.1145/3543507.3583460,
author = {Feng, Binbin and Ding, Zhijun},
title = {GROUP: An End-to-End Multi-Step-Ahead Workload Prediction Approach Focusing on Workload Group Behavior},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583460},
doi = {10.1145/3543507.3583460},
abstract = {Accurately forecasting workloads can enable web service providers to achieve proactive runtime management for applications and ensure service quality and cost efficiency. For cloud-native applications, multiple containers collaborate to handle user requests, making each container’s workload changes influenced by workload group behavior. However, existing approaches mainly analyze the individual changes of each container and do not explicitly model the workload group evolution of containers, resulting in sub-optimal results. Therefore, we propose a workload prediction method, GROUP, which implements the shifts of workload prediction focus from individual to group, workload group behavior representation from data similarity to data correlation, and workload group behavior evolution from implicit modeling to explicit modeling. First, we model the workload group behavior and its evolution from multiple perspectives. Second, we propose a container correlation calculation algorithm that considers static and dynamic container information to represent the workload group behavior. Third, we propose an end-to-end multi-step-ahead prediction method that explicitly portrays the complex relationship between the evolution of workload group behavior and the workload changes of each container. Lastly, enough experiments on public datasets show the advantages of GROUP, which provides an effective solution to achieve workload prediction for cloud-native applications.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {3098–3108},
numpages = {11},
keywords = {deep learning., workload prediction, Cloud Computing},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3630202.3630233,
author = {Cornacchia, Alessandro and Benson, Theophilus A. and Bilal, Muhammad and Canini, Marco},
title = {MicroView: Cloud-Native Observability with Temporal Precision},
year = {2023},
isbn = {9798400704529},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630202.3630233},
doi = {10.1145/3630202.3630233},
abstract = {We present MicroView, a system designed to improve the accuracy and timeliness of observability in cloud-native applications, while minimizing overhead. MicroView stands out from conventional observability tools by incorporating metrics processing stages at every node within a local lightweight data-plane. We preliminary demonstrate its benefits for distributed tracing and outline a set of architectural choices focused on offloading the MicroView data-plane to IPU accelerators, such as a BlueField-3 SmartNIC, thus limiting the interference with running services.},
booktitle = {Proceedings of the on CoNEXT Student Workshop 2023},
pages = {7–8},
numpages = {2},
keywords = {SmartNIC, cloud-native, microservices observability, programmable networks},
location = {<conf-loc>, <city>Paris</city>, <country>France</country>, </conf-loc>},
series = {CoNEXT-SW '23}
}

@inproceedings{10.1145/3578244.3583726,
author = {Straesser, Martin and Mathiasch, Jonas and Bauer, Andr\'{e} and Kounev, Samuel},
title = {A Systematic Approach for Benchmarking of Container Orchestration Frameworks},
year = {2023},
isbn = {9798400700682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578244.3583726},
doi = {10.1145/3578244.3583726},
abstract = {Container orchestration frameworks play a critical role in modern cloud computing paradigms such as cloud-native or serverless computing. They significantly impact the quality and cost of service deployment as they manage many performance-critical tasks such as container provisioning, scheduling, scaling, and networking. Consequently, a comprehensive performance assessment of container orchestration frameworks is essential. However, until now, there is no benchmarking approach that covers the many different tasks implemented in such platforms and supports evaluating different technology stacks. In this paper, we present a systematic approach that enables benchmarking of container orchestrators. Based on a definition of container orchestration, we define the core requirements and benchmarking scope for such platforms. Each requirement is then linked to metrics and measurement methods, and a benchmark architecture is proposed. With COFFEE, we introduce a benchmarking tool supporting the definition of complex test campaigns for container orchestration frameworks. We demonstrate the potential of our approach with case studies of the frameworks Kubernetes and Nomad in a self-hosted environment and on the Google Cloud Platform. The presented case studies focus on container startup times, crash recovery, rolling updates, and more.},
booktitle = {Proceedings of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {187–198},
numpages = {12},
keywords = {nomad, performance, benchmarking, kubernetes, container orchestration},
location = {Coimbra, Portugal},
series = {ICPE '23}
}

@inproceedings{10.1145/3578245.3584728,
author = {Klinaku, Floriment and Speth, Sandro and Zilch, Markus and Becker, Steffen},
title = {Hitchhiker's Guide for Explainability in Autoscaling},
year = {2023},
isbn = {9798400700729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578245.3584728},
doi = {10.1145/3578245.3584728},
abstract = {Cloud-native applications force increasingly powerful and complex autoscalers to guarantee the applications' quality of service. For software engineers with operational tasks understanding the autoscalers' behavior and applying appropriate reconfigurations is challenging due to their internal mechanisms, inherent distribution, and decentralized decision-making. Hence, engineers seek appropriate explanations. However, engineers' expectations on feedback and explanations of autoscalers are unclear. In this paper, through a workshop with a representative sample of engineers responsible for operating an autoscaler, we elicit requirements for explainability in autoscaling. Based on the requirements, we propose an evaluation scheme for evaluating explainability as a non-functional property of the autoscaling process and guide software engineers in choosing the best-fitting autoscaler for their scenario. The evaluation scheme is based on a Goal Question Metric approach and contains three goals, nine questions to assess explainability, and metrics to answer these questions. The evaluation scheme should help engineers choose a suitable and explainable autoscaler or guide them in building their own.},
booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {277–282},
numpages = {6},
keywords = {elasticity, explainability, requirements, cloud, evaluation},
location = {Coimbra, Portugal},
series = {ICPE '23 Companion}
}

@inproceedings{10.1145/3491204.3527467,
author = {Kousiouris, George and Giannakos, Chris and Tserpes, Konstantinos and Stamati, Teta},
title = {Measuring Baseline Overheads in Different Orchestration Mechanisms for Large FaaS Workflows},
year = {2022},
isbn = {9781450391597},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491204.3527467},
doi = {10.1145/3491204.3527467},
abstract = {Serverless environments have attracted significant attention in recent years as a result of their agility in execution as well as inherent scaling capabilities as a cloud-native execution model. While extensive analysis has been performed in various critical performance aspects of these environments, such as cold start times, the aspect of workflow orchestration delays has been neglected. Given that this paradigm has become more mature in recent years and application complexity has started to rise from a few functions to more complex application structures, the issue of delays in orchestrating these functions may become severe. In this work, one of the main open source FaaS platforms, Openwhisk, is utilized in order to measure and investigate its orchestration delays for the main sequence operator of the platform. These are compared to delays included in orchestration of functions through two alternative means, including the execution of orchestrator logic functions in supporting runtimes based on Node-RED. The delays inserted by each different orchestration mode are measured and modeled, while boundary points of selection between each mode are presented, based on the number and expected delay of the functions that constitute the workflow. It is indicative that in certain cases, the orchestration overheads might range from 0.29\% to 235\% compared to the beneficial computational time needed for the workflow functions. The results can extend simulation and estimation mechanisms with information on the orchestration overheads.},
booktitle = {Companion of the 2022 ACM/SPEC International Conference on Performance Engineering},
pages = {61–68},
numpages = {8},
keywords = {performance, serverless, orchestration, faas, overhead, openwhisk},
location = {Bejing, China},
series = {ICPE '22}
}

@inproceedings{10.1145/3491204.3527490,
author = {Tuli, Shreshth and Casale, Giuliano},
title = {Optimizing the Performance of Fog Computing Environments Using AI and Co-Simulation},
year = {2022},
isbn = {9781450391597},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491204.3527490},
doi = {10.1145/3491204.3527490},
abstract = {This tutorial presents a performance engineering approach for optimizing the Quality of Service (QoS) of Edge/Fog/Cloud Computing environments using AI and Coupled-Simulation being developed as part of the Co-Simulation based Container Orchestration (COSCO) framework. It introduces fundamental AI and co-simulation concepts, their importance in QoS optimization and performance engineering challenges in the context of Fog computing. It also discusses how AI models, specifically, deep neural networks (DNNs), can be used in tandem with simulated estimates to take optimal resource management decisions. Additionally, we discuss a few use cases of training DNNs as surrogates to estimate key QoS metrics and utilize such models to build policies for dynamic scheduling in a distributed fog environment. The tutorial demonstrates these concepts using the COSCO framework. Metric monitoring and simulation primitives in COSCO demonstrates the efficacy of an AI and simulation based scheduler on a fog/cloud platform. Finally, we provide AI baselines for resource management problems that arise in the area of fog management.},
booktitle = {Companion of the 2022 ACM/SPEC International Conference on Performance Engineering},
pages = {25–28},
numpages = {4},
keywords = {co-simulation., performance engineering, fog computing, artificial intelligence},
location = {Bejing, China},
series = {ICPE '22}
}

@inproceedings{10.1145/3493700.3493731,
author = {Lodha, Ishaan and Kolur, Lakshana and Krishnan, Keerthan and Dheenadayalan, Kumar and Sitaram, Dinkar and Nandi, Siddhartha},
title = {Cost-Optimized Video Transfer Using Real-Time Super Resolution Convolutional Neural Networks},
year = {2022},
isbn = {9781450385824},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3493700.3493731},
doi = {10.1145/3493700.3493731},
abstract = {The explosion of video generation and consumption, coupled with an inadequate rise in network bandwidth has led to network delays and decreased Quality of Experience, limiting the opportunities to tap into the full potential of video data. These deficiencies in network resources with a shift to cloud computing models have resulted in the need to revisit the overall mechanism for video transfer and storage of videos between edge devices and the cloud. We propose a novel multi-scale real-time super-resolution convolutional neural network to achieve the composite task of optimizing the entire cost of video transfer with minimal loss of quality that can be used for any application involving the transfer of video data. To achieve this, we develop a cost-optimized video transfer system that optimizes the metrics of video transfer to give the best quality video output, given the user budget. The model makes use of Convolution blocks for extracting features and output creation with multiple sub-pixel convolutions in a novel structure. For upscaling to full High Definition video at 30 fps, the model successfully retained the frame rate while the system achieved savings in transfer time and bandwidth usage. This model has been trained on surveillance videos (VIRAT dataset), but consistent results were obtained during testing even on feature films and sports videos which demonstrates its content invariance. The evaluation of our approach averaged over 376 videos, yielded meager quality losses of 8\%, measured by a novel non-referential quality metric, also proposed in this paper. Additionally, average network bandwidth savings of 80\% and average video transfer time reduction of 52\% were achieved.},
booktitle = {Proceedings of the 5th Joint International Conference on Data Science \&amp; Management of Data (9th ACM IKDD CODS and 27th COMAD)},
pages = {213–221},
numpages = {9},
keywords = {super resolution, cost optimization, CNN, video transfer, deep neural networks, GAN},
location = {<conf-loc>, <city>Bangalore</city>, <country>India</country>, </conf-loc>},
series = {CODS-COMAD '22}
}

@inproceedings{10.1145/3555962.3555968,
author = {Alzboon, Ghufran and Al-Said Ahmad, Amro},
title = {A Performance Evaluation Approach for N-Tier Cloud-Based Software Services},
year = {2022},
isbn = {9781450396578},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3555962.3555968},
doi = {10.1145/3555962.3555968},
abstract = {Cloud computing and cloud testing are vast fields that have attracted significant attention recently. In addition, the need to find an approach for measuring cloud-based applications' effectiveness has also increased. In this work, we introduced an approach to testing the performance of the cloud software services on the Amazon cloud. We used two cloud-based applications hosted in the Amazon cloud to demonstrate the approach depending on five technical performance metrics. We applied the testing methodology using a JMeter test script. The two selected applications represent two different taxonomies: 2-tier and 3-tier architectures. Following the testing process, we found that the WordPress application (i.e., 3-tier architecture) performs better than Ghost and is more stable in terms of the selected performance metrics. Practitioners would benefit from this study by a better understanding of the assessment and testing of n-tier Cloud-Based Software Services using technical arguments.},
booktitle = {Proceedings of the 2022 6th International Conference on Cloud and Big Data Computing},
pages = {31–36},
numpages = {6},
keywords = {n-tier, Cloud computing, evaluation method, performance, Software services},
location = {Birmingham, United Kingdom},
series = {ICCBDC '22}
}

@inproceedings{10.5555/3581644.3581660,
author = {Passos, Edenilson J\^{o}natas dos and Fiorese, Adriano},
title = {Monitoring Metrics for Load Balancing over Video Content Distribution Servers},
year = {2023},
isbn = {9783903176515},
publisher = {International Federation for Information Processing},
address = {Laxenburg, AUT},
abstract = {Cloud computing and video streaming services have been in constant expansion in recent years. Along with it, the demand for computing resources has also increased significantly. In this context, monitoring the use of these resources is crucial to maintain a satisfactory level of Quality of Service and, consequently, Quality of Experience, especially in video transmission services. This work discusses a new method of monitoring resources and quality of service metrics on content servers involving CPU utilization and server throughput, which is obtained in a distributed way. For that, a distributed collector system that is based on a modified version of the ring election algorithm is developed to retrieve the Quality of Service metrics in each server. Evaluation experiment results show that there are no performance gains on the system such as the content loading faster for the user, there are however, improvements in terms of the whole system scalability. The greater the number of servers for monitoring, the better the approach is compared to the traditional method of monitoring resources through request and response.},
booktitle = {Proceedings of the 18th International Conference on Network and Service Management},
articleno = {13},
numpages = {7},
keywords = {load balancing, monitoring, SDN},
location = {Thessaloniki, Greece},
series = {CNSM '22}
}

@inproceedings{10.1145/3543712.3543715,
author = {Petrov, Valerii and Gennadinik, Anna and Avksentieva, Elena},
title = {Metrics for Machine Learning Evaluation Methods in Cloud Monitoring Systems},
year = {2022},
isbn = {9781450396226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543712.3543715},
doi = {10.1145/3543712.3543715},
abstract = {During the machine learning pipeline development, engineers need to validate the efficiency of the machine learning methods in order to assess the quality of the made forecast.Due to the wide deployment and implementation of the machine learning models and methods across monitoring systems, the actual scientific problem is the assessment of these methods in the monitoring systems. This research has concluded that the current standard metrics are not sufficient to get the accurate assessment for the used machine learning methods.This research has provided the new complex rating for anomaly detection regarding the use-cases of cloud monitoring systems. The main difference from the standard metrics is that the new approach includes better integration to the business processes, demanding resources, and a critical glance to the false-positive alerts. The new approach might be used in the model assessment in monitoring systems with the similar requirements:Cost-effective use of computing resourcesLow amount of false-positivesFast detection of anomaliesFurthermore, the current research proposes new methods of computation capacity planning for different anomaly detection methods. These methods are not even limited to anomaly detection and could be used as a basis for developing capacity planning for other machine learning techniques and approaches.· Applied computing∼Operations research∼Forecasting · Computer systems organization∼Architectures∼Distributed architectures ∼Cloud computing∼Forecasting · Computing methodologies∼Machine learning},
booktitle = {Proceedings of the 2022 8th International Conference on Computer Technology Applications},
pages = {168–175},
numpages = {8},
keywords = {capacity planning, machine learning metrics, quality assessment, monitoring},
location = {Vienna, Austria},
series = {ICCTA '22}
}

@article{10.1145/3512893,
author = {Ming, Zhao and Li, Xiuhua and Sun, Chuan and Fan, Qilin and Wang, Xiaofei and Leung, Victor C. M.},
title = {Sleeping Cell Detection for Resiliency Enhancements in 5G/B5G Mobile Edge-Cloud Computing Networks},
year = {2022},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {3},
issn = {1550-4859},
url = {https://doi.org/10.1145/3512893},
doi = {10.1145/3512893},
abstract = {The rapid increase of data traffic has brought great challenges to the maintenance and optimization of 5G and beyond, and some smart critical infrastructures, e.g., small base stations (SBSs) in cellular cells, are facing serious security and failure threats, causing resiliency degradation concerns. Among special smart critical infrastructure failures, the sleeping cell failure is hard to address since no alarm is generally triggered. Sleeping cells can remain undetected for a long time and can severely affect the quality of service/quality of experience to users. To enhance the resiliency of the SBSs in sleeping cells, we design a mobile edge-cloud computing system and propose a semi-supervised learning-based framework to dynamically detect the sleeping cells. Particularly, we consider two indicators, recovery proportion and recovery speed, to measure the resiliency of the SBSs. Moreover, in the proposed scheme, experts’ optimization experience and each period’s detection results can be utilized to iteratively improve the performance. Then we adopt a dataset from real-world networks for performance evaluation. Trace-driven evaluation results demonstrate that the proposed scheme outperforms existing sleeping cell detection schemes, and can also reduce the communication and runtime costs and enhance the resiliency of the SBSs.},
journal = {ACM Trans. Sen. Netw.},
month = {apr},
articleno = {42},
numpages = {30},
keywords = {resiliency enhancement, semi-supervised learning, sleeping cell detection, Smart critical infrastructures, 5G/B5G, mobile edge-cloud computing}
}

@inproceedings{10.1145/3629479.3629502,
author = {Andrade, \'{A}lan J\'{u}nior da Cruz and Veloso, Ednilson and Santos, Gleison},
title = {What We Know About Software Dependability in DevOps - A Tertiary Study},
year = {2023},
isbn = {9798400707865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3629479.3629502},
doi = {10.1145/3629479.3629502},
abstract = {Background: DevOps is viewed as an alternative approach to achieving high-quality software products. Dependability is recognized as a crucial aspect of software product quality. Existing literature highlights the lack of established standards, models, or methods for evaluating product quality within the DevOps paradigm. This emphasizes the need for further research to investigate the impact of DevOps on software quality attributes, particularly in relation to dependability.Objective: Our objective is to evaluate the scope of research on dependability in DevOps and identify what is known about this context by relating DevOps practices with dependability attributes. Method: We conducted a tertiary study to enhance the understanding of dependability in the context of DevOps. Results: We found 13 secondary studies that address dependability in DevOps. Within these studies, we identified 16 DevOps practices that have an impact on dependability and 12 attributes that are affected by DevOps practices. Additionally, we identified 6 measures related to dependability in the context of DevOps. Among the DevOps practices, the most commonly reported ones that impact dependability are Automation Practices, including deployment, testing, and infrastructure automation, as well as Cloud Computing Implementation. Conclusions: The results show that DevOps practices contribute to improve software dependability, mainly due to the impacts of these practices on dependability attributes. However, even though the literature reports some measures related to dependability, there is still a gap in understanding how organizations can assess dependability in DevOps.},
booktitle = {Proceedings of the XXII Brazilian Symposium on Software Quality},
pages = {178–187},
numpages = {10},
keywords = {Dependability, Software Product Quality, DevOps},
location = {<conf-loc>, <city>Bras\'{\i}lia</city>, <country>Brazil</country>, </conf-loc>},
series = {SBQS '23}
}

@inproceedings{10.1145/3578244.3583728,
author = {Volpert, Simon and Erb, Benjamin and Eisenhart, Georg and Seybold, Daniel and Wesner, Stefan and Domaschka, J\"{o}rg},
title = {A Methodology and Framework to Determine the Isolation Capabilities of Virtualisation Technologies},
year = {2023},
isbn = {9798400700682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578244.3583728},
doi = {10.1145/3578244.3583728},
abstract = {The capability to isolate system resources is an essential characteristic of virtualisation technologies and is therefore important for research and industry alike. It allows the co-location of experiments and workloads, the partitioning of system resources and enables multi-tenant business models such as cloud computing. Poor isolation among tenants bears the risk of noisy-neighbour and contention effects which negatively impacts all of those use-cases. These effects describe the negative impact of one tenant onto another by utilising shared resources. Both industry and research provide many different concepts and technologies to realise isolation. Yet, the isolation capabilities of all these different approaches are not well understood; nor is there an established way to measure the quality of their isolation capabilities. Such an understanding, however, is of uttermost importance in practice to elaborately decide on a suited implementation. Hence, in this work, we present a novel methodology to measure the isolation capabilities of virtualisation technologies for system resources, that fulfils all requirements to benchmarking including reliability. It relies on an immutable approach, based on Experiment-as-Code. The complete process holistically includes everything from bare metal resource provisioning to the actual experiment enactment.The results determined by this methodology help in the decision for a virtualisation technology regarding its capability to isolate given resources. Such results are presented here as a closing example in order to validate the proposed methodology.},
booktitle = {Proceedings of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {149–160},
numpages = {12},
keywords = {virtualisation, framework, benchmarking, isolation},
location = {Coimbra, Portugal},
series = {ICPE '23}
}

@article{10.1145/3586181,
author = {Bachiega, Joao and Costa, Breno and Carvalho, Leonardo R. and Rosa, Michel J. F. and Araujo, Aleteia},
title = {Computational Resource Allocation in Fog Computing: A Comprehensive Survey},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {14s},
issn = {0360-0300},
url = {https://doi.org/10.1145/3586181},
doi = {10.1145/3586181},
abstract = {Fog computing is a paradigm that allows the provisioning of computational resources and services at the edge of the network, closer to the end devices and users, complementing cloud computing. The heterogeneity and large number of devices are challenges to obtaining optimized resource allocation in this environment. Over time, some surveys have been presented on resource management in fog computing. However, they now lack a broader and deeper view about this subject, considering the recent publications. This article presents a systematic literature review with a focus on resource allocation for fog computing, and in a more comprehensive way than the existing works. The survey is based on 108 selected publications from 2012 to 2022. The analysis has exposed their main techniques, metrics used, evaluation tools, virtualization methods, architecture, and domains where the proposed solutions were applied. The results show an updated and comprehensive view about resource allocation in fog computing. The main challenges and open research questions are discussed, and a new fog computing resource management cycle is proposed.},
journal = {ACM Comput. Surv.},
month = {jul},
articleno = {336},
numpages = {31},
keywords = {Fog computing, resource allocation, resource management, resource provisioning}
}

@inproceedings{10.1145/3590837.3590922,
author = {M, Saravanan and S, Shiva Prasad},
title = {A Blockchain-Based, Distributed, Self Hosted And End To End Encrypted Cloud Storage System},
year = {2023},
isbn = {9781450399937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3590837.3590922},
doi = {10.1145/3590837.3590922},
abstract = {Cloud computing is fast taking over due to its convenience and greater safety. You may access your files anytime you need them by using the cloud. Having a large following makes things simpler for consumers. Computing makes phase, programming, and system structure all possible. With the aid of these components, increased cloud-based information and profits might be obtained. It is great to plan and arrange work based on data. The most difficult issue for people with a background in logical thinking is planning work procedures to achieve customer service goals while keeping expenses in control. Although leveraging cloud storage to reduce expenses has been suggested, doing so can be difficult. Although leveraging cloud storage to reduce expenses has been suggested, doing so can be difficult. To handle cloud resources efficiently, a modular infrastructure is needed. Utilizing standards and calculations, parallel resource and service management is maximized in the cloud. Using different work flows to structure work processes is the most entertaining activity in cloud computing. Timing and price have an influence on service quality (tasks). Workflow-based relocation of virtual machines is more effective. NP-hard algorithms for subset and choice issues. Making a choice allows the server to save time and money. PSO and GWO interactions that are advantageous. In this undertaking, both time and money are considerations. The new approach should be used. The study affects the validity of process parameters. intuition with a convex shape. utilizing the PEFT technique. GWO analyses the time and money spent on cloud processes. It is suggested that VMs be optimized as hybrid, both locally and globally. heuristic algorithm based on PEFT. Optimization reduces the likelihood of making a mistake right away. The Grey Wolf Optimization and Floral pollination algorithm outperforms genetic and flower pollination techniques. Biomimicry is compared with swarm intelligence. For our analysis, we use LIGO, GENOME, CYBER SHAKE, and SIPHT. The difficulty and quantity of the jobs have an impact on workflow. A bio-inspired GA, GWO, and FPA are used in the optimization process. In an experimental arrangement, time and cost analysis for two to twenty VMs and workflows may be done. Compared to FPA with PEFT, GWO requires less time and money. In hybrid optimization, GWO and FPA are combined. In this project, efficiency and speed are highly valued. GWO optimizes VM globally, whereas FPA concentrates on local enhancements. FPA GA uses the collective wisdom of the group to identify correlations. As labor prices grow, more virtual machines (VMs) are employed for processing and tasks. Wait times drop and costs rise. Local and global optimization have an impact on virtual machine (VM) and compute time. ACO and PSO are used to accomplish local and global optimization, however employing them requires more time.},
booktitle = {Proceedings of the 4th International Conference on Information Management \&amp; Machine Intelligence},
articleno = {85},
numpages = {7},
keywords = {Cryptography, Cloud storage, Peer to Peer Network, Blockchain, IPFS},
location = {Jaipur, India},
series = {ICIMMI '22}
}

@article{10.14778/3611540.3611566,
author = {Pan, Zhicheng and Wang, Yihang and Zhang, Yingying and Yang, Sean Bin and Cheng, Yunyao and Chen, Peng and Guo, Chenjuan and Wen, Qingsong and Tian, Xiduo and Dou, Yunliang and Zhou, Zhiqiang and Yang, Chengcheng and Zhou, Aoying and Yang, Bin},
title = {MagicScaler: Uncertainty-Aware, Predictive Autoscaling},
year = {2023},
issue_date = {August 2023},
publisher = {VLDB Endowment},
volume = {16},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3611540.3611566},
doi = {10.14778/3611540.3611566},
abstract = {Predictive autoscaling is a key enabler for optimizing cloud resource allocation in Alibaba Cloud's computing platforms, which dynamically adjust the Elastic Compute Service (ECS) instances based on predicted user demands to ensure Quality of Service (QoS). However, user demands in the cloud are often highly complex, with high uncertainty and scale-sensitive temporal dependencies, thus posing great challenges for accurate prediction of future demands. These in turn make autoscaling challenging---autoscaling needs to properly account for demand uncertainty while maintaining a reasonable trade-off between two contradictory factors, i.e., low instance running costs vs. low QoS violation risks.To address the above challenges, we propose a novel predictive autoscaling framework MagicScaler, consisting of a Multi-scale attentive Gaussian process based predictor and an uncertainty-aware scaler. First, the predictor carefully bridges the best of two successful prediction methodologies---multi-scale attention mechanisms, which are good at capturing complex, multi-scale features, and stochastic process regression, which can quantify prediction uncertainty, thus achieving accurate demand prediction with quantified uncertainty. Second, the scaler takes the quantified future demand uncertainty into a judiciously designed loss function with stochastic constraints, enabling flexible trade-off between running costs and QoS violation risks. Extensive experiments on three clusters of Alibaba Cloud in different Chinese cities demonstrate the effectiveness and efficiency of MagicScaler, which outperforms other commonly adopted scalers, thus justifying our design choices.},
journal = {Proc. VLDB Endow.},
month = {aug},
pages = {3808–3821},
numpages = {14}
}

@inproceedings{10.1145/3510513.3510534,
author = {Zhao, Yuhan and Chong, Zheng and Han, Xueying and Du, Zongpeng and Yu, Ke and Huang, Xiaohong},
title = {Simulation Study of Routing Mechanism in the Computing-Aware Network},
year = {2022},
isbn = {9781450385848},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510513.3510534},
doi = {10.1145/3510513.3510534},
abstract = {Traditional routing algorithms select the path based on the cost, hop, or other network-related metrics. However, with cloud computing and edge computing development, it is essential to develop a computing-aware routing mechanism to distribute the task to the computing nodes with better capabilities. In order to achieve the combined scheduling of computing resources and network resources, Computing-aware Network (CAN) is proposed. The solution aims to comprehensively consider the computing resources and network resources existing when routing and forwarding user requests, which is essential to improve the current situation of uneven utilization of edge computing resources. As many theories and structures are proposed, the requirements for experimental verification of CAN are gradually increasing. However, there is still a lack of experimental simulation prototypes available for study. In this work, motivated by the gap, we propose a simulation prototype based on the idea of the CAN, where routing nodes can incorporate both the computing status and network status into routing and forward packets to an edge server according to the computing demand service type. We verified the effectiveness of the CAN prototype from simulation experiments on a cross-domain topology. From the results, we can conclude that the utilization rate of computing resources has been effectively improved compared to not considering computing status.},
booktitle = {Proceedings of the 2021 10th International Conference on Networks, Communication and Computing},
pages = {126–134},
numpages = {9},
keywords = {computing resources, utilization rate, Computing-aware Network, simulation prototype},
location = {Beijing, China},
series = {ICNCC '21}
}

@inproceedings{10.1145/3487552.3487854,
author = {Dang, The Khang and Mohan, Nitinder and Corneo, Lorenzo and Zavodovski, Aleksandr and Ott, J\"{o}rg and Kangasharju, Jussi},
title = {Cloudy with a Chance of Short RTTs: Analyzing Cloud Connectivity in the Internet},
year = {2021},
isbn = {9781450391290},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3487552.3487854},
doi = {10.1145/3487552.3487854},
abstract = {Cloud computing has seen continuous growth over the last decade. The recent rise in popularity of next-generation applications brings forth the question: "Can current cloud infrastructure support the low latency requirements of such apps?" Specifically, the interplay of wireless last-mile and investments of cloud operators in setting up direct peering agreements with ISPs globally to current cloud reachability and latency has remained largely unexplored.This paper investigates the state of end-user to cloud connectivity over wireless media through extensive measurements over six months. We leverage 115,000 wireless probes on the Speed-checker platform and 195 cloud regions from 9 well-established cloud providers. We evaluate the suitability of current cloud infrastructure to meet the needs of emerging applications and highlight various hindering pressure points. We also compare our results to a previous study over RIPE Atlas. Our key findings are: (i) the most impact on latency comes from the geographical distance to the datacenter; (ii) the choice of a measurement platform can significantly influence the results; (iii) wireless last-mile access contributes significantly to the overall latency, almost surpassing the impact of the geographical distance in many cases. We also observe that cloud providers with their own private network backbone and direct peering agreements with serving ISPs offer noticeable improvements in latency, especially in its consistency over longer distances.},
booktitle = {Proceedings of the 21st ACM Internet Measurement Conference},
pages = {62–79},
numpages = {18},
keywords = {cloud connectivity, edge computing, peering, last-mile latency},
location = {Virtual Event},
series = {IMC '21}
}

@article{10.1145/3554735,
author = {Huang, Lihua and Zheng, Peng},
title = {Human-Computer Collaborative Visual Design Creation Assisted by Artificial Intelligence},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {9},
issn = {2375-4699},
url = {https://doi.org/10.1145/3554735},
doi = {10.1145/3554735},
abstract = {With the support and promotion of big data and cloud computing, AI has penetrated into every field of people's lives more and more deeply, with its characteristics of sustainable work, extremely fast computing speed, and a certain intelligence. This is an effective way to solve the general lack of demand and productivity of visual design, and relieve the pressure off designers to deal with relatively low-quality and high-demand designs. Therefore, the combination of design and artificial intelligence technology is a necessity. Research on the application of artificial intelligence technology for visual design is also in full swing at home and abroad However, at present, teams at home and abroad are in the exploratory stage. This paper considers whether it is possible to build an intelligent visual design and creation system by using artificial intelligence technology to help graphic communication designers achieve high-quality, high-efficiency, and high-quantity design output. Additionally, this paperexplores how to combine artificial intelligence technology with designers' design workflow so as to form a complementary human-computer cooperation mode. We will explore how to integrate AI technology with designers' design workflow and then create a human-machine collaboration model with complementary advantages to achieve the high quality, high efficiency, and high quantity of design output required by the intelligent visual design creation system being built. Finally, a basic framework of a generative smart human-computer collaborative visual design creation system based on a subset of neural network expert systems in multiple domains and an aggregate of different modules supported by the system is formed, and the working principle and usage process of the system are further elaborated with the example of packaging design.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = {sep},
articleno = {221},
numpages = {21},
keywords = {cooperation mode, creation system, visual design creation, collaboration model, Artificial intelligence, packaging design, human-computer collaboration}
}

@inproceedings{10.1145/3590837.3590950,
author = {V, Vanjipriya and Annamalai, Suresh},
title = {Machine Learning Technique for Energy, Performance and Cost-Effective Resource Management in Multi-Access Edge Computing},
year = {2023},
isbn = {9781450399937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3590837.3590950},
doi = {10.1145/3590837.3590950},
abstract = {Modern cloud interconnects on efficient resource allocation and provisioning to reduce their energy footprint. Resource management is complicated by factors such as data centre energy utilisation, virtual machine migration, operating expense, and overhead. Researchers have been using virtualized technologies and methods as optimal-Multi-objective particle swarm optimization, Dynamic Power Saving Resource Allocation (DPRA), Least Squares Regression, etc. to improve the management of their study. Accurately allocating resources to cloud users to meet their requests and offer QoS is a difficult task because of the preceding steps. Allocating cloud infrastructure's resources in the most efficient way possible benefits both users and service providers. The difficulties of resource management are tackled in this study by employing novel approaches, heuristics, authentication, and virtualization. In order to distribute workloads over several physical nodes, cloud computing relies on dynamic scheduling with load balancing. Using the help of host load prediction and a Markov chain model with Particle Swarm Optimization (PSO), VM resources are dynamically allocated to appropriate input requests. High quality of service (QoS) for cloud applications is achieved by SLA-based resource optimization with deadline, cost, storage, and bandwidth targets. Compliance with Service Level Agreements (SLAs), efficient use of resources, and low energy consumption are all achieved using a prioritisation technique based on SLAs. Scheduled users can receive resources in a predetermined order thanks to queuing. We developed the M/M/c/K queuing paradigm for numerous users per server to lessen the burden on data centres. Hardware resource models, such as CPU, I/O, and memory use, reveal VM resource allocation. Information gathering enhances resource utilisation and reduces energy consumption.},
booktitle = {Proceedings of the 4th International Conference on Information Management \&amp; Machine Intelligence},
articleno = {113},
numpages = {7},
keywords = {Load balancing, Service Level Agreements, Quality of Service, Virtual machine, Dynamic Power Saving Resource Allocation},
location = {Jaipur, India},
series = {ICIMMI '22}
}

@inproceedings{10.1145/3491418.3530295,
author = {Rochlin, Nick and Gardner, Jeff and Kinney, Elizabeth},
title = {Evaluating Research Computing Training and Support as Part of a Broader Digital Research Infrastructure Needs Assessment},
year = {2022},
isbn = {9781450391610},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491418.3530295},
doi = {10.1145/3491418.3530295},
abstract = {Digital Research Infrastructure (DRI) refers to the suite of tools and services that enables the collection, processing, dissemination, and disposition of research data. This includes strategies for planning, organizing, storing, sharing, computing, and ultimately archiving or destroying one's research data.&nbsp; These services must be supported by highly qualified personnel with the appropriate expertise.&nbsp; From May 17 - June 12, 2021, the University of British Columbia (UBC) Advanced Research Computing (UBC ARC) and the UBC Library from both Vancouver and Okanagan Campuses launched the DRI Needs Assessment Survey to investigate UBC researchers’ needs in 25 distinct DRI tools and services.&nbsp; The survey received a total of 241 responses, and following the survey, three focus groups were conducted with survey respondents to gain additional insights.This paper outlines the DRI Needs Assessment Survey and its findings, focusing on those directly related to UBC ARC services and training in high-performance computing (HPC) and cloud computing (“Cloud”), and discusses next steps for implementing a more collaborative, comprehensive research computing training and support model. Key findings suggest that while advanced research computing infrastructure is a key pillar of DRI, researchers utilizing UBC ARC also rely on a number of other DRI tools and services to conduct their research.&nbsp; These services are widely scattered across various departments and groups within and outside the institution and are oftentimes not well communicated, impacting researchers’ ability to find them.&nbsp; Current research training and support has been found to be inadequate, and there are duplicated service efforts occurring in silos, resulting in an inefficient service model and wasted funds.},
booktitle = {Practice and Experience in Advanced Research Computing},
articleno = {28},
numpages = {8},
keywords = {advanced research computing, user community, training, hpc, education, collaboration, cloud, digital research infrastructure},
location = {Boston, MA, USA},
series = {PEARC '22}
}

@article{10.1145/3550274,
author = {Liu, Yipeng and Yang, Qi and Xu, Yiling and Yang, Le},
title = {Point Cloud Quality Assessment: Dataset Construction and Learning-Based No-Reference Metric},
year = {2023},
issue_date = {April 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {2s},
issn = {1551-6857},
url = {https://doi.org/10.1145/3550274},
doi = {10.1145/3550274},
abstract = {Full-reference (FR) point cloud quality assessment (PCQA) has achieved impressive progress in recent years. However, in many cases, obtaining the reference point clouds is difficult, so no-reference (NR) metrics have become a research hotspot. Few researches about NR-PCQA are carried out due to the lack of a large-scale PCQA dataset. In this article, we first build a large-scale PCQA dataset named LS-PCQA, which includes 104 reference point clouds and more than 22,000 distorted samples. In the dataset, each reference point cloud is augmented with 31 types of impairments (e.g., Gaussian noise, contrast distortion, local missing, and compression loss) at 7 distortion levels. Besides, each distorted point cloud is assigned with a pseudo-quality score as its substitute of Mean Opinion Score. Inspired by the hierarchical perception system and considering the intrinsic attributes of point clouds, we propose a NR metric ResSCNN based on sparse convolutional neural network (CNN) to accurately estimate the subjective quality of point clouds. We conduct several experiments to evaluate the performance of the proposed NR metric. The results demonstrate that ResSCNN exhibits the state-of-the-art performance among all the existing NR-PCQA metrics and even outperforms some FR metrics. The dataset presented in this work will be made publicly accessible at . The source code for the proposed ResSCNN can be found at .},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = {feb},
articleno = {80},
numpages = {26},
keywords = {sparse convolution, large-scale dataset, point cloud, Blind quality assessment, learning-based metric}
}

@inproceedings{10.1145/3592834.3592877,
author = {Lee, Kuan-Yu and Fang, Jia-Wei and Sun, Yuan-Chun and Hsu, Cheng-Hsin},
title = {Modeling Gamer Quality-of-Experience Using a Real Cloud VR Gaming Testbed},
year = {2023},
isbn = {9798400701894},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3592834.3592877},
doi = {10.1145/3592834.3592877},
abstract = {Cloud Virtual Reality (VR) gaming offloads computationally-intensive VR games to resourceful data centers. Ensuring good Quality of Experience (QoE) in cloud VR gaming, however, is inherently challenging as VR gamers demand high visual quality, short response time, and low cybersickness. In this paper, we investigate the QoE of cloud VR gaming in multiple steps. First, we build a cloud VR gaming testbed, which allows us to measure various Quality of Service (QoS) metrics. Second, we carry out a user study to understand the effects of diverse factors, including encoding settings, network conditions, and game genres on gamer QoE, quantified by Mean Opinion Score (MOS). Using our user study results, we construct QoE models for cloud VR gaming, which to the best of our knowledge, has not been done in the literature. Last, we apply our QoE models to develop a bitrate allocation algorithm for multiple cloud VR gamers to achieve better overall QoE compared to the bandwidth-fair bitrate allocation.},
booktitle = {Proceedings of the 15th International Workshop on Immersive Mixed and Virtual Environment Systems},
pages = {12–17},
numpages = {6},
keywords = {QoE modeling, bitrate allocation, VR gaming, cloud gaming},
location = {Vancouver, BC, Canada},
series = {MMVE '23}
}

@inproceedings{10.1145/3469877.3490578,
author = {Zhang, Ke-xin and Jiang, Gang-yi and Yu, Mei},
title = {FQM-GC: Full-Reference Quality Metric for Colored Point Cloud Based on Graph Signal Features and Color Features},
year = {2022},
isbn = {9781450386074},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3469877.3490578},
doi = {10.1145/3469877.3490578},
abstract = {Colored Point Cloud (CPC) is often distorted in the processes of its acquisition, processing, and compression, so reliable quality assessment metrics are required to estimate the perception of distortion of CPC. We propose a Full-reference Quality Metric for colored point cloud based on Graph signal features and Color features (FQM-GC). For geometric distortion, the normal and coordinate information of the sub-clouds divided via geometric segmentation is used to construct their underlying graphs, then, the geometric structure features are extracted. For color distortion, the corresponding color statistical features are extracted from regions divided with color attribution. Meanwhile, the color features of different regions are weighted to simulate the visual masking effect. Finally, all the extracted features are formed into a feature vector to estimate the quality of CPCs. Experimental results on three databases (CPCD2.0, IRPC and SJTU-PCQA) show that the proposed metric FQM-GC is more consistent with human visual perception.},
booktitle = {Proceedings of the 3rd ACM International Conference on Multimedia in Asia},
articleno = {48},
numpages = {5},
keywords = {graph signal processing, visual quality assessment, Colored point cloud, point cloud segmentation},
location = {<conf-loc>, <city>Gold Coast</city>, <country>Australia</country>, </conf-loc>},
series = {MMAsia '21}
}

@inproceedings{10.1145/3552482.3556552,
author = {Freitas, Pedro G. and Lucafo, Giovani D. and Gon\c{c}alves, Mateus and Homonnai, Johann and Diniz, Rafael and Farias, Myl\`{e}ne C.Q.},
title = {Comparative Evaluation of Temporal Pooling Methods for No-Reference Quality Assessment of Dynamic Point Clouds},
year = {2022},
isbn = {9781450395007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3552482.3556552},
doi = {10.1145/3552482.3556552},
abstract = {Point Cloud Quality Assessment (PCQA) has become an important task in immersive multimedia since it is fundamental for improving computer graphics applications and ensuring the best Quality of Experience(QoE) for the end user. In recent years, the field of PCQA has made exemplary progress, with state-of-the-art methods achieving better predictive performance at lower computational complexity. However, most of this progress was made using Full Reference (FR) metrics. Since, in many cases, the reference point cloud is not available, the design of No-Reference (NR) methods has become increasingly important. In this paper, we investigate the suitability of geometric-aware texture descriptors to blindly assess the quality of colored Dynamic Point Cloud (DPC). The proposed metric first uses a descriptor to extract features of the assessed Point Cloud (PC) frames. Then, the descriptor statistics are used to extract quality-aware features. Finally, a machine learning algorithm is employed to regress the quality-aware features into visual quality scores, and these scores are aggregated using a temporal pooling function. Then we study the effects of different temporal pooling strategies on the performance of DPC quality assessment methods. Our experimental tests were carried out using the latest publicly available database and demonstrated the efficiency of the evaluated temporal pooling models. This work aims to provide a direction on how to apply a temporal pooling function to combine per-frame quality predictions generated with descriptor based PC quality assessment methods to estimate the quality of dynamic PCs. An implementation of the metric described in this paper can be found in https://gitlab.com/gpds-unb/no-referencedpcqa-temporal-pooling.},
booktitle = {Proceedings of the 1st Workshop on Photorealistic Image and Environment Synthesis for Multimedia Experiments},
pages = {35–41},
numpages = {7},
keywords = {quality assessment, quality metric, qoe methods, point cloud},
location = {Lisboa, Portugal},
series = {PIES-ME '22}
}

@inproceedings{10.1145/3552469.3555710,
author = {Tliba, Marouane and Chetouani, Aladine and Valenzise, Giuseppe and Dufaux, Frederic},
title = {Point Cloud Quality Assessment Using Cross-Correlation of Deep Features},
year = {2022},
isbn = {9781450394994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3552469.3555710},
doi = {10.1145/3552469.3555710},
abstract = {3D point clouds have emerged as a preferred format for recent immersive communication systems, due to the six degrees of freedom they offer. The huge data size of point clouds, which consists of both geometry and color information, has motivated the development of efficient compression schemes recently. To support the optimization of these algorithms, adequate and efficient perceptual quality metrics are needed. In this paper we propose a novel end-to-end deep full-reference framework for 3D point cloud quality assessment, considering both the geometry and color information. We use two identical neural networks, based on a residual permutation-invariant architecture, for extracting local features from a sparse set of patches extracted from the point cloud. Afterwards, we measure the cross-correlation between the embedding of pristine and distorted point clouds to quantify the global shift in the features due to visual distortion. The proposed scheme achieves comparable results to state-of-the-art metrics even when a small number of centroids are used, reducing the computational complexity.},
booktitle = {Proceedings of the 2nd Workshop on Quality of Experience in Visual Multimedia Applications},
pages = {63–68},
numpages = {6},
keywords = {cross correlation, deep learning, point cloud, quality assessment},
location = {Lisboa, Portugal},
series = {QoEVMA '22}
}

@inproceedings{10.1145/3569052.3578907,
author = {Hogan, Taylor},
title = {Goal Driven PCB Synthesis Using Machine Learning and CloudScale Compute},
year = {2023},
isbn = {9781450399784},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3569052.3578907},
doi = {10.1145/3569052.3578907},
abstract = {X AI is a cloud-based system that leverages machine learning, and search to place and route printed circuit boards using physics-based analysis and high-level design. We propose a feedback-based Monte Carlo Tree Search (MCTS) algorithm to explore the space of possible designs. A metric, or metrics, is given to evaluate the quality of designs as MCTS learns about possible solutions. A policy and value network are trained during exploration to learn to accurately weight quality actions and identify useful design states. This is performed as a feedback loop in conjunction with other feedforward tools for placement and routing.},
booktitle = {Proceedings of the 2023 International Symposium on Physical Design},
pages = {80},
numpages = {1},
keywords = {monte carlo tree search, si/pi driven synthesis, reinforcement learning, machine learning, pcb design},
location = {Virtual Event, USA},
series = {ISPD '23}
}

@inproceedings{10.1145/3581783.3613847,
author = {Zhang, Junteng and Chen, Tong and Ding, Dandan and Ma, Zhan},
title = {YOGA: Yet Another Geometry-Based Point Cloud Compressor},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3613847},
doi = {10.1145/3581783.3613847},
abstract = {A learning-based YOGA (Yet Another Geometry-based Point Cloud Compressor) is proposed. It is flexible, allowing for the separable lossy compression of geometry and color attributes, and variable-rate coding using a single neural model; it is high-efficiency, significantly outperforming the latest G-PCC standard quantitatively and qualitatively, e.g., 25\% BD-BR gains using PCQM (Point Cloud Quality Metric) as the distortion assessment, and it is lightweight, e.g., similar runtime as the G-PCC codec, owing to the use of sparse convolution and parallel entropy coding. To this end, YOGA adopts a unified end-to-end learning-based backbone for separate geometry and attribute compression. The backbone uses a two-layer structure, where the downscaled thumbnail point cloud is encoded using G-PCC at the base layer, and upon G-PCC compressed priors, multiscale sparse convolutions are stacked at the enhancement layer to effectively characterize spatial correlations to compactly represent the full-resolution sample. In addition, YOGA integrates the adaptive quantization and entropy model group to enable variable-rate control, as well as adaptive filters for better quality restoration.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {9070–9081},
numpages = {12},
keywords = {point cloud compression, layered coding, attribute, geometry},
location = {<conf-loc>, <city>Ottawa ON</city>, <country>Canada</country>, </conf-loc>},
series = {MM '23}
}

@inproceedings{10.1145/3507623.3507628,
author = {Bhambani, Krisha and Takalikar, Mukta},
title = {DeCloud GAN: An Advanced Generative Adversarial Network for Removing Cloud Cover in Optical Remote Sensing Imagery},
year = {2022},
isbn = {9781450385930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3507623.3507628},
doi = {10.1145/3507623.3507628},
abstract = {Optical Remote Sensing imagery has several applications in monitoring the states of natural and man-made features around the globe. However, due to clouds and other climatic conditions, information extracted from the imagery retrieved is very limited. Deep learning has often been used in several image processing and remote sensing tasks. In this work, we propose the usage of generative adversarial networks to remove clouds and other climatic interference from high-resolution remote sensing imagery. We have trained and tested upon the Remote sensing Image Cloud rEmoving dataset (RICE). The novel network(DeCloud GAN) we propose, makes use of residual UNets and pixel shuffle layers in the generator, which yield high quality cloudless satellite images. We have tested 4 methods for comparison, and have found that DeCloudGAN achieves the best performance on two main metrics, peak signal to noise ratio (PSNR) and structural similarity index (SSIM), to measure similarity in visual perception of the produced and target images.},
booktitle = {Proceedings of the 2021 4th International Conference on Computational Intelligence and Intelligent Systems},
pages = {25–30},
numpages = {6},
keywords = {Remote Sensing, Generative Adversarial Networks, Image generation, Deep Learning, Optical Imagery},
location = {Tokyo, Japan},
series = {CIIS '21}
}

@inproceedings{10.1145/3615452.3617942,
author = {Yin, Haofei and Xiao, Mengbai and Yu, Dongxiao},
title = {Preserving High Quality in A Learning-Based Compression Model for Point Cloud Videos},
year = {2023},
isbn = {9798400703393},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615452.3617942},
doi = {10.1145/3615452.3617942},
abstract = {High-resolution point cloud videos combined with 3D scenes can create creative viewing modes. However, their enormous data volume demands effective compression techniques. In this work, we propose a deep learning-based model for compressing point cloud videos. Compared to D-PCC, the state-of-the-art model designed for preserving high quality after decompression, the reconstruction result of our method achieves up to a 29.73\% improvement in the density metric and a noticeable improvement in human visual perception. We also discuss extending our model to compress color information and effectively remove inter-frame redundancy.},
booktitle = {Proceedings of the 1st ACM Workshop on Mobile Immersive Computing, Networking, and Systems},
pages = {215–221},
numpages = {7},
location = {Madrid, Spain},
series = {ImmerCom '23}
}

@inproceedings{10.1145/3479986.3480000,
author = {Couto, Luis and Teixeira Lopes, Carla},
title = {Equal Opportunities in the Access to Quality Online Health Information? A Multi-Lingual Study on Wikipedia},
year = {2021},
isbn = {9781450385008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3479986.3480000},
doi = {10.1145/3479986.3480000},
abstract = {Wikipedia is a free, multilingual, and collaborative online encyclopedia. Nowadays, it is one of the largest sources of online knowledge, often appearing at the top of the results of the major search engines, being one of the most sought-after resources by the public searching for health information. The collaborative nature of Wikipedia raises security concerns since this information is used for decision-making, especially in the health area. Despite being available in hundreds of idioms, there are asymmetries between idioms, namely regarding their quality. In this work, we compare the quality of health information on Wikipedia between idioms with 100 million native speakers or more, and also in Greek, Italian, Korean, Turkish, Persian, Catalan and Hebrew, for historical tradition. Quality metrics are applied to health and medical articles in English, maintained by WikiProject Medicine, and their versions in the above idioms. With this, we contribute to a clarification of the role of Wikipedia in the access to health information. We demonstrate differences in both the quantity and quality of information available between idioms. English is the idiom with the highest quality in general. Urdu, Greek, Indonesian, and Hindi achieved lower values of quality.},
booktitle = {Proceedings of the 17th International Symposium on Open Collaboration},
articleno = {13},
numpages = {13},
keywords = {Information Quality, Health information, Wikipedia, Multilingual information access},
location = {Online, Spain},
series = {OpenSym '21}
}

@inproceedings{10.1145/3552469.3555713,
author = {Bourbia, Salima and Karine, Ayoub and Chetouani, Aladine and El Hassouni, Mohammed and Jridi, Maher},
title = {No-Reference Point Clouds Quality Assessment Using Transformer and Visual Saliency},
year = {2022},
isbn = {9781450394994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3552469.3555713},
doi = {10.1145/3552469.3555713},
abstract = {Quality estimation of 3D objects/scenes represented by cloud point is a crucial and challenging task in computer vision. In real-world applications, reference data is not always available, which motivates the development of new point cloud quality assessment (PCQA) metrics that do not require the original 3D point cloud (3DPC). This family of methods is called no-reference or blind PCQA. In this context, we propose a deep-learning-based approach that benefits from the advantage of the self-attention mechanism in transformers to accurately predict the perceptual quality score for each degraded 3DPC. Additionally, we introduce the use of saliency maps to reflect the human visual system behavior that is attracted to some specific regions compared to others during the evaluation. To this end, we first render 2D projections (i.e. views) of a 3DPC from different viewpoints. Then, we weight the obtained projected images with their corresponding saliency maps. After that, we discard the majority of the background information by extracting sub-salient images. The latter is introduced as a sequential input of the vision transformer in order to extract the global contextual information and to predict the quality scores of the sub-images. Finally, we average the scores of all the salient sub-images to obtain the perceptual 3DPC quality score. We evaluate the performance of our model on the ICIP2020 and SJTU point cloud quality assessment benchmarks. Experimental results show that our model achieves promising performance compared to the state-of-the-art point cloud quality assessment metrics.},
booktitle = {Proceedings of the 2nd Workshop on Quality of Experience in Visual Multimedia Applications},
pages = {57–62},
numpages = {6},
keywords = {attention, visual saliency, 3d point clouds, objective quality assessment, transformer},
location = {Lisboa, Portugal},
series = {QoEVMA '22}
}

@inproceedings{10.1145/3552457.3555730,
author = {Prazeres, Joao and Rodrigues, Rafael and Pereira, Manuela and Pinheiro, Antonio M.G.},
title = {Quality Evaluation of Machine Learning-Based Point Cloud Coding Solutions},
year = {2022},
isbn = {9781450394918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3552457.3555730},
doi = {10.1145/3552457.3555730},
abstract = {In this paper, a quality evaluation of three point cloud coding solutions based on machine learning technology is presented, notably, ADLPCC, PCC_GEO_CNN, and PCGC, as well as LUT_SR, which uses multi-resolution Look-Up Tables. Moreover, the MPEG G-PCC was used as an anchor. A set of six point clouds, representing both landscapes and objects were coded using the five encoders at different bit rates, and a subjective test, where the distorted and reference point clouds were rotated in a video sequence side by side, is carried out to assess their performance. Furthermore, the performance of point cloud objective quality metrics that usually provide a good representation of the coded content is analyzed against the subjective evaluation results. The obtained results suggest that some of these metrics fail to provide a good representation of the perceived quality, and thus are not suitable to evaluate some distortions created by machine learning-based solutions. A comparison between the analyzed metrics and the type of represented scene or codec is also presented.},
booktitle = {Proceedings of the 1st International Workshop on Advances in Point Cloud Compression, Processing and Analysis},
pages = {57–65},
numpages = {9},
keywords = {machine learning, point clouds, quality evaluation, coding},
location = {Lisboa, Portugal},
series = {APCCPA '22}
}

@inproceedings{10.1145/3503161.3548374,
author = {Jamshidi Avanaki, Nasim and Schmidt, Steven and Michael, Thilo and Zadtootaghaj, Saman and M\"{o}ller, Sebastian},
title = {Deep-BVQM: A Deep-Learning Bitstream-Based Video Quality Model},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3548374},
doi = {10.1145/3503161.3548374},
abstract = {With the rapid increase of video streaming content, high-quality video quality metrics, mainly signal-based video quality metrics, are emerging, notably VMAF, SSIMPLUS, and AVQM. Besides signal-based video quality metrics, within the standardization body, ITU-T Study Group 12, two well-known bitstream-based video quality metrics are developed named P.1203 and P.1204.3. Due to the low complexity and low level of access to the bitstream data, these models gained attention from network providers and service providers. In this paper, we proposed a new bitstream-based model named Deep-BVQM, which outperforms the standard models on the tested datasets. While the model comes with slightly higher computational complexity, it offers a frame-level quality prediction which is essential diagnostic information for some video streaming services such as cloud gaming. Deep-BVQM is developed in two layers; first, the frame quality was predicted using a lightweight CNN model. Next, the latent features of the CNN were used to train an LSTM network to predict the video quality in a short-term duration.},
booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
pages = {915–923},
numpages = {9},
keywords = {bitstream-based quality model, quality of experience, video quality},
location = {<conf-loc>, <city>Lisboa</city>, <country>Portugal</country>, </conf-loc>},
series = {MM '22}
}

@inproceedings{10.1145/3489517.3530496,
author = {Yayla, Mikail and Chen, Jian-Jia},
title = {Memory-Efficient Training of Binarized Neural Networks on the Edge},
year = {2022},
isbn = {9781450391429},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3489517.3530496},
doi = {10.1145/3489517.3530496},
abstract = {A visionary computing paradigm is to train resource efficient neural networks on the edge using dedicated low-power accelerators instead of cloud infrastructures, eliminating communication overheads and privacy concerns. One promising resource-efficient approach for inference is binarized neural networks (BNNs), which binarize parameters and activations. However, training BNNs remains resource demanding. State-of-the-art BNN training methods, such as the binary optimizer (Bop), require to store and update a large number of momentum values in the floating point (FP) format.In this work, we focus on memory-efficient FP encodings for the momentum values in Bop. To achieve this, we first investigate the impact of arbitrary FP encodings. When the FP format is not properly chosen, we prove that the updates of the momentum values can be lost and the quality of training is therefore dropped. With the insights, we formulate a metric to determine the number of unchanged momentum values in a training iteration due to the FP encoding. Based on the metric, we develop an algorithm to find FP encodings that are more memory-efficient than the standard FP encodings. In our experiments, the memory usage in BNN training is decreased by factors 2.47x, 2.43x, 2.04x, depending on the BNN model, with minimal accuracy cost (smaller than 1\%) compared to using 32-bit FP encoding.},
booktitle = {Proceedings of the 59th ACM/IEEE Design Automation Conference},
pages = {661–666},
numpages = {6},
location = {San Francisco, California},
series = {DAC '22}
}

@inproceedings{10.1145/3617233.3617247,
author = {Bourbia, Salima and Karine, Ayoub and Chetouani, Aladine and El Hassouni, Mohammed and Jridi, Maher},
title = {Multi-Stream Point-Based Model for Blind Geometric Point Cloud Quality Assessment},
year = {2023},
isbn = {9798400709128},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617233.3617247},
doi = {10.1145/3617233.3617247},
abstract = {The evaluation of 3D point cloud quality is a critical component in the development of immersive multimedia systems for real-world applications. While perceptual quality evaluation technics for 2D images and videos have reached high performances, developing robust and efficient blind metrics for point cloud quality assessment is still challenging. In this paper, we propose a no-reference point cloud quality assessment method that evaluates the quality of degraded 3D objects using an end-to-end point-based multi-stream model. To capture the geometric degradation of the point cloud, we incorporate normals, curvatures and geometric coordinates. Then, we divide the distorted object into sub-objects, which are fed to a multi-stream network to extract significant features of the geometric degradation. Afterward, these features are used to predict the quality of each sub-object, and the perceptual quality score of the point cloud is obtained by averaging the quality scores of all sub-objects. Experimental results demonstrate that the proposed model achieves promising performance compared to state-of-the- art full and reduced methods.},
booktitle = {Proceedings of the 20th International Conference on Content-Based Multimedia Indexing},
pages = {224–228},
numpages = {5},
keywords = {Quality assessment, 3D point cloud, Multi-stream, Deep learning., Point-based model},
location = {<conf-loc>, <city>Orleans</city>, <country>France</country>, </conf-loc>},
series = {CBMI '23}
}

@inproceedings{10.1145/3611643.3616316,
author = {Agarwal, Shubham and Chakraborty, Sarthak and Garg, Shaddy and Bisht, Sumit and Jain, Chahat and Gonuguntla, Ashritha and Saini, Shiv},
title = {Outage-Watch: Early Prediction of Outages Using Extreme Event Regularizer},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616316},
doi = {10.1145/3611643.3616316},
abstract = {Cloud services are omnipresent and critical cloud service failure is a fact of life. In order to retain customers and prevent revenue loss, it is important to provide high reliability guarantees for these services. One way to do this is by predicting outages in advance, which can help in reducing the severity as well as time to recovery. It is difficult to forecast critical failures due to the rarity of these events. Moreover, critical failures are ill-defined in terms of observable data. Our proposed method, Outage-Watch, defines critical service outages as deteriorations in the Quality of Service (QoS) captured by a set of metrics. Outage-Watch detects such outages in advance by using current system state to predict whether the QoS metrics will cross a threshold and initiate an extreme event. A mixture of Gaussian is used to model the distribution of the QoS metrics for flexibility and an extreme event regularizer helps in improving learning in tail of the distribution. An outage is predicted if the probability of any one of the QoS metrics crossing threshold changes significantly. Our evaluation on a real-world SaaS company dataset shows that Outage-Watch significantly outperforms traditional methods with an average AUC of 0.98. Additionally, Outage-Watch detects all the outages exhibiting a change in service metrics and reduces the Mean Time To Detection (MTTD) of outages by up to 88\% when deployed in an enterprise cloud-service system, demonstrating efficacy of our proposed method.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {682–694},
numpages = {13},
keywords = {Distribution Learning, Mixture Density Network, Outage Forecasting, System reliability and monitoring},
location = {<conf-loc>, <city>San Francisco</city>, <state>CA</state>, <country>USA</country>, </conf-loc>},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1109/ISCA52012.2021.00044,
author = {Zha, Yue and Li, Jing},
title = {Hetero-ViTAL: A Virtualization Stack for Heterogeneous FPGA Clusters},
year = {2021},
isbn = {9781450390866},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ISCA52012.2021.00044},
doi = {10.1109/ISCA52012.2021.00044},
abstract = {With field-programmable gate arrays (FPGAs) being widely deployed into data centers, an efficient virtualization support is required to fully unleash the potential of cloud FPGAs. Nevertheless, existing FPGA virtualization solutions only support a homogeneous FPGA cluster comprising identical FPGA devices. Representative work such as ViTAL provides sufficient system support for scale-out acceleration and improves the overall resource utilization through a fine-grained spatial sharing. While these existing solutions (including ViTAL) can efficiently virtualize a homogeneous cluster, it is hard to extend them to virtualizing a heterogeneous cluster which comprises multiple types of FPGAs. We expect the future cloud FPGAs are likely to be more heterogeneous due to hardware rolling upgrade.In this paper, we rethink FPGA virtualization from ground up and propose HETERO-VITAL to virtualize heterogeneous FPGA clusters. We identify the conflicting requirements of runtime management and offline compilation when designing the abstraction for a heterogeneous cluster, which is also the fundamental reason why the single-level abstraction as proposed in ViTAL (and other prior works) cannot be trivially extended to the heterogeneous case. To decouple these conflicting requirements, we provide a two-level system abstraction in HETERO-VITAL. Specifically, the high-level abstraction is FPGA-agnostic and provides a simple and homogeneous view of the FPGA resources to simplify the runtime management. On the contrary, the low-level abstraction is FPGA-specific and exposes sufficient spatial resource constraints to the compilation framework to ensure the mapping quality. Rather than simply adding a layer on top of the single-level abstraction as proposed in ViTAL and other prior work, we judiciously determine how much hardware details should be exposed at each level to balance the management complexity, mapping quality and compilation cost. We then develop a compilation framework to map applications onto this two-level abstraction with several optimization techniques to further improve the mapping quality. We also provide a runtime management policy to alleviate the fragmentation issue, which becomes more severe in a heterogeneous cluster due to the distinct resource capacities of diverse FPGAs.We evaluate HETERO-VITAL on a custom-built FPGA cluster and demonstrate its effectiveness using machine learning and image processing applications. Results show that HETERO-VITAL reduces the average response time (a critical metric for QoS) by 79.2\% for a heterogeneous cluster compared to the non-virtualized baseline. When virtualizing a homogeneous cluster, HETERO-VITAL also reduces the average response time by 42.0\% compared with ViTAL due to a better system design.},
booktitle = {Proceedings of the 48th Annual International Symposium on Computer Architecture},
pages = {470–483},
numpages = {14},
location = {Virtual Event, Spain},
series = {ISCA '21}
}

@inproceedings{10.1145/3474085.3475294,
author = {Zhang, Yujie and Yang, Qi and Xu, Yiling},
title = {MS-GraphSIM: Inferring Point Cloud Quality via Multiscale Graph Similarity},
year = {2021},
isbn = {9781450386517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474085.3475294},
doi = {10.1145/3474085.3475294},
abstract = {To address the point cloud quality assessment (PCQA) problem, GraphSIM was proposed via jointly considering geometrical and color features, which shows compelling performance in multiple distortion detection. However, GraphSIM does not take into account the mutiscale characteristics of human perception. In this paper, we propose a multiscale PCQA model, called Multiscale Graph Similarity (MS-GraphSIM), that can better predict human subjective perception. First, exploring the multiscale processing method used in image processing, we introduce a multiscale representation of point clouds based on graph signal processing. Second, we extend GraphSIM into multiscale version based on the proposed multiscale representation. Specifically, MS-GraphSIM constructs a multiscale representation for each local patch extracted from the reference point cloud or the distorted point cloud, and then fuses GraphSIM at different scales to obtain an overall quality score. Experiment results demonstrate that the proposed MS-GraphSIM outperforms the state-of-the-art PCQA metrics over two fairly large and independent databases. Ablation studies further prove the proposed MS-GraphSIM is robust to different model hyperparameter settings. The code is available at https://github.com/zyj1318053/MS_GraphSIM.},
booktitle = {Proceedings of the 29th ACM International Conference on Multimedia},
pages = {1230–1238},
numpages = {9},
keywords = {graph signal processing, multiscale representation, quality assessment, point cloud},
location = {Virtual Event, China},
series = {MM '21}
}

@article{10.1145/3595244.3595257,
author = {Prakash, R Sri and Karamchandani, Nikhil and Moharir, Sharayu},
title = {On the Regret of Online Edge Service Hosting},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {4},
issn = {0163-5999},
url = {https://doi.org/10.1145/3595244.3595257},
doi = {10.1145/3595244.3595257},
abstract = {We consider the problem of service hosting where a service provider can dynamically rent edge resources via short term contracts to ensure better quality of service to its customers. The total cost incurred by the system is modeled as a combination of the rent cost, the service cost incurred due to latency in serving customers, and the fetch cost incurred as a result of the bandwidth used to fetch the code/databases of the service from the cloud servers to host the service at the edge. In this paper, we compare multiple hosting policies with regret as a metric, defined as the difference in the cost incurred by the policy and the optimal policy over some time horizon T. In particular we consider the Retro Renting (RR) and Follow The Perturbed Leader (FTPL) policies proposed in the literature and provide performance guarantees on the regret of these policies. We show that under i.i.d Bernoulli arrivals, RR policy has linear regret while FTPL policy has constant regret. Next, we propose a variant of FTPL, namely Wait then FTPL (W-FTPL), which also has constant regret while demonstrating much better dependence on the fetch cost. We also show that under adversarial arrivals, RR policy has linear regret while both FTPL and W-FTPL have regret O(pT) which is order-optimal.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {apr},
pages = {35–37},
numpages = {3}
}

@inproceedings{10.1145/3578244.3583721,
author = {Straesser, Martin and Eismann, Simon and von Kistowski, J\'{o}akim and Bauer, Andr\'{e} and Kounev, Samuel},
title = {Autoscaler Evaluation and Configuration: A Practitioner's Guideline},
year = {2023},
isbn = {9798400700682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578244.3583721},
doi = {10.1145/3578244.3583721},
abstract = {Autoscalers are indispensable parts of modern cloud deployments and determine the service quality and cost of a cloud application in dynamic workloads. The configuration of an autoscaler strongly influences its performance and is also one of the biggest challenges and showstoppers for the practical applicability of many research autoscalers. Many proposed cloud experiment methodologies can only be partially applied in practice, and many autoscaling papers use custom evaluation methods and metrics. This paper presents a practical guideline for obtaining meaningful and interpretable results on autoscaler performance with reasonable overhead. We provide step-by-step instructions for defining realistic usage behaviors and traffic patterns. We divide the analysis of autoscaler performance into a qualitative antipattern-based analysis and a quantitative analysis. To demonstrate the applicability of our guideline, we conduct several experiments with a microservice of our industry partner in a realistic test environment.},
booktitle = {Proceedings of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {31–41},
numpages = {11},
keywords = {antipatterns, evaluation, methodology, autoscaling, guideline},
location = {Coimbra, Portugal},
series = {ICPE '23}
}

@article{10.1145/3510415,
author = {Zhong, Zhiheng and Xu, Minxian and Rodriguez, Maria Alejandra and Xu, Chengzhong and Buyya, Rajkumar},
title = {Machine Learning-Based Orchestration of Containers: A Taxonomy and Future Directions},
year = {2022},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {10s},
issn = {0360-0300},
url = {https://doi.org/10.1145/3510415},
doi = {10.1145/3510415},
abstract = {Containerization is a lightweight application virtualization technology, providing high environmental consistency, operating system distribution portability, and resource isolation. Existing mainstream cloud service providers have prevalently adopted container technologies in their distributed system infrastructures for automated application management. To handle the automation of deployment, maintenance, autoscaling, and networking of containerized applications, container orchestration is proposed as an essential research problem. However, the highly dynamic and diverse feature of cloud workloads and environments considerably raises the complexity of orchestration mechanisms. Machine learning algorithms are accordingly employed by container orchestration systems for behavior modeling and prediction of multi-dimensional performance metrics. Such insights could further improve the quality of resource provisioning decisions in response to the changing workloads under complex environments. In this article, we present a comprehensive literature review of existing machine learning-based container orchestration approaches. Detailed taxonomies are proposed to classify the current researches by their common features. Moreover, the evolution of machine learning-based container orchestration technologies from the year 2016 to 2021 has been designed based on objectives and metrics. A comparative analysis of the reviewed techniques is conducted according to the proposed taxonomies, with emphasis on their key characteristics. Finally, various open research challenges and potential future directions are highlighted.},
journal = {ACM Comput. Surv.},
month = {sep},
articleno = {217},
numpages = {35},
keywords = {machine learning, systematic review, Container orchestration, cloud computing, resource provisioning}
}

@inproceedings{10.1145/3526059.3533617,
author = {Makris, Antonios and Psomakelis, Evangelos and Theodoropoulos, Theodoros and Tserpes, Konstantinos},
title = {Towards a Distributed Storage Framework for Edge Computing Infrastructures},
year = {2022},
isbn = {9781450393102},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3526059.3533617},
doi = {10.1145/3526059.3533617},
abstract = {Due to the continuous development of Internet of Things (IoT), the volume of the data these devices generate are expected to grow dramatically in the future. As a result, managing and processing such massive data amounts at the edge becomes a vital issue. Edge computing moves data and computation closer to the client enabling latency- and bandwidth-sensitive applications, that would not be feasible using cloud and remote processing alone. Nevertheless, implementing an efficient edge-enabled storage system is challenging due to the distributed and heterogeneous nature of the edge and its limited resource capabilities. To this end, we propose a lightweight hybrid distributed edge/cloud storage framework which aims to improve the Quality of Experience (QoE) of the end-users by migrating data close to them, thus reducing data transfers delays and network utilization. The proposed edge storage component (ESC) exploits the Dynamic Lifecycle Framework, in order to enable transparent and automated access for containerized applications to remote workloads. The effectiveness of the ESC is evaluated by employing a number of resource utilization and Quality of Service (QoS) metrics.},
booktitle = {Proceedings of the 2nd Workshop on Flexible Resource and Application Management on the Edge},
pages = {9–14},
numpages = {6},
keywords = {edge computing, edge storage, cloud computing, kubernetes, internet of things, container-based, minio, virtualization},
location = {Minneapolis, MN, USA},
series = {FRAME '22}
}

@inproceedings{10.1145/3487552.3487862,
author = {Mok, Ricky K. P. and Zou, Hongyu and Yang, Rui and Koch, Tom and Katz-Bassett, Ethan and Claffy, K C},
title = {Measuring the Network Performance of Google Cloud Platform},
year = {2021},
isbn = {9781450391290},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3487552.3487862},
doi = {10.1145/3487552.3487862},
abstract = {Public cloud platforms are vital in supporting online applications for remote learning and telecommuting during the COVID-19 pandemic. The network performance between cloud regions and access networks directly impacts application performance and users' quality of experience (QoE). However, the location and network connectivity of vantage points often limits the visibility of edge-based measurement platforms (e.g., RIPE Atlas).We designed and implemented the CLoud-based Applications Speed Platform (CLASP) to measure performance to various networks from virtual machines in cloud regions with speed test servers that have been widely deployed on the Internet. In our five-month longitudinal measurements in Google Cloud Platform (GCP), we found that 30-70\% of ISPs we measured showed severe throughput degradation from the peak throughput of the day.},
booktitle = {Proceedings of the 21st ACM Internet Measurement Conference},
pages = {54–61},
numpages = {8},
keywords = {cloud networking, network throughput, speed test},
location = {Virtual Event},
series = {IMC '21}
}

@inproceedings{10.1145/3581783.3611998,
author = {Xie, Wuyuan and Wang, Kaimin and Ju, Yakun and Wang, Miaohui},
title = {PmBQA: Projection-Based Blind Point Cloud Quality Assessment via Multimodal Learning},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3611998},
doi = {10.1145/3581783.3611998},
abstract = {With the increasing communication and storage of point cloud data, there is an urgent need for an effective objective method to measure the quality before and after processing. To address this difficulty, we propose a projection-based blind quality indicator via multimodal learning for point cloud data, which can perceive both geometric distortion and texture distortion by using four homogeneous modalities (i.e., texture, normal, depth and roughness). To fully exploit the multimodal information, we further develop a deformable convolutionbased alignment module and a graph-based feature fusion module, and investigate a graph node attention-based evaluation method to forecast the quality score. Extensive experimental results on three benchmark databases show that our method achieves more accurate evaluation performance in comparison with 12 competitive methods.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {3250–3258},
numpages = {9},
keywords = {quality assessment, no reference, point cloud, multimodal information},
location = {<conf-loc>, <city>Ottawa ON</city>, <country>Canada</country>, </conf-loc>},
series = {MM '23}
}

@inproceedings{10.5555/3539845.3539878,
author = {Ruan, Shaolun and Wang, Yong and Jiang, Hailong and Xu, Weijia and Guan, Qiang},
title = {BatchLens: A Visualization Approach for Analyzing Batch Jobs in Cloud Systems},
year = {2022},
isbn = {9783981926361},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
abstract = {Cloud systems are becoming increasingly powerful and complex. It is highly challenging to identify anomalous execution behaviors and pinpoint problems by examining the overwhelming intermediate results/states in complex application workflows. Domain scientists urgently need a friendly and functional interface to understand the quality of the computing services and the performance of their applications in real time. To meet these needs, we explore data generated by job schedulers and investigate general performance metrics (e.g., utilization of CPU, memory and disk I/O). Specifically, we propose an interactive visual analytics approach, BatchLens, to provide both providers and users of cloud service with an intuitive and effective way to explore the status of system batch jobs and help them conduct root-cause analysis of anomalous behaviors in batch jobs. We demonstrate the effectiveness of BatchLens through a case study on the public Alibaba bench workload trace datasets.},
booktitle = {Proceedings of the 2022 Conference \&amp; Exhibition on Design, Automation \&amp; Test in Europe},
pages = {108–111},
numpages = {4},
keywords = {cloud computing, human-computer interaction, visual analytics},
location = {Antwerp, Belgium},
series = {DATE '22}
}

@inproceedings{10.1145/3630590.3630602,
author = {Mukhia, Raunak and Sarambage Jayarathna, Kalana Gayashan and Lertsinsrubtavee, Adisorn},
title = {Performance Evaluation of LoRaWAN Forest Fire Monitoring Network in the Wild},
year = {2023},
isbn = {9798400709395},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630590.3630602},
doi = {10.1145/3630590.3630602},
abstract = {To leverage the potential of LoRaWAN, we have successfully developed a real-world field wireless sensor network dedicated to monitoring forest fires and air quality. This network operates across remote forested regions and semi-urban areas. The development effort encompasses the complete LoRaWAN network stack, including a tailored circuit board designed for LoRa communication and multi-sensor nodes, the establishment of network infrastructure, and a cloud-based data collection platform that strictly adheres to the LoRaWAN standard. In this context, we have introduced a retransmission mechanism in the LoRaWAN application layer for sensor data completeness, along with lorawanatd which operates the LoRaWAN hardware. This extension serves to enhance communication robustness between end nodes and the network cloud, ensuring a seamless and reliable data transmission. Our initiative also involved a comprehensive series of experiments, conducted using sensor nodes situated in proximity to forest fire-prone areas. These experiments were conducted to delve into optimal configurations and constraints related to radio wave propagation. Key performance metrics guiding these investigations include the Received Signal Strength Indicator (RSSI), Signal to Noise Ratio (SNR), Packet Delivery Ratio (PDR), and Data Completeness Ratio (DCR).},
booktitle = {Proceedings of the 18th Asian Internet Engineering Conference},
pages = {96–104},
numpages = {9},
keywords = {LoRaWAN, Low Power Wide Area Networks, Forest Fire, Wireless Sensor Network, Internet of Things},
location = {<conf-loc>, <city>Hanoi</city>, <country>Vietnam</country>, </conf-loc>},
series = {AINTEC '23}
}

@article{10.1145/3470972,
author = {Dias, Alexandre H. T. and Correia, Luiz. H. A. and Malheiros, Neumar},
title = {A Systematic Literature Review on Virtual Machine Consolidation},
year = {2021},
issue_date = {November 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {8},
issn = {0360-0300},
url = {https://doi.org/10.1145/3470972},
doi = {10.1145/3470972},
abstract = {Virtual machine consolidation has been a widely explored topic in recent years due to Cloud Data Centers’ effect on global energy consumption. Thus, academia and companies made efforts to achieve green computing, reducing energy consumption to minimize environmental impact. By consolidating Virtual Machines into a fewer number of Physical Machines, resource provisioning mechanisms can shutdown idle Physical Machines to reduce energy consumption and improve resource utilization. However, there is a tradeoff between reducing energy consumption while assuring the Quality of Service established on the Service Level Agreement. This work introduces a Systematic Literature Review of one year of advances in virtual machine consolidation. It provides a discussion on methods used in each step of the virtual machine consolidation, a classification of papers according to their contribution, and a quantitative and qualitative analysis of datasets, scenarios, and metrics.},
journal = {ACM Comput. Surv.},
month = {oct},
articleno = {176},
numpages = {38},
keywords = {systematic literature review, virtual machines consolidation, Cloud computing, green computing}
}

@inproceedings{10.1145/3615453.3616511,
author = {Kak, A. and Thieu, H. -T. and Pham, V. -Q. and Sheshadri, R. K. and Choi, N. and Guan, Y. and Yin, M. and Han, T.},
title = {AweRAN: Making a Case for Application-Aware Radio Access Network Slicing},
year = {2023},
isbn = {9798400703409},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615453.3616511},
doi = {10.1145/3615453.3616511},
abstract = {As communications service providers ponder ways to cater to the diverse traffic requirements of mobile applications that range from the classic telephony to modern augmented reality (AR)-related use cases, the traditional quality of service (QoS)-based radio resource management (RRM) techniques for RAN slicing that are agnostic to the intrinsic workings of applications can result in a poor quality of experience (QoE) for the end-user. We argue that in addition to QoS, RAN slicing strategies should also consider QoE for efficient resource utilization. However, without comprehensively understanding the interplay between QoS, QoE and how various RRM techniques can potentially influence them, it is impossible to incorporate QoE-driven feedback for resource allocation. Consequently, in this work, we conduct a first-of-its-kind in-depth experimental campaign on an O-RAN compliant 5G cellular testbed to evaluate the performance of the QoE metrics of three varied applications---video-enabled voice calling, cloud gaming, and AR---under various RAN slice configurations. We discuss the key findings of this elaborate study, and motivate the need for a QoE-aware RRM framework for RAN slicing.},
booktitle = {Proceedings of the 17th ACM Workshop on Wireless Network Testbeds, Experimental Evaluation \&amp; Characterization},
pages = {41–48},
numpages = {8},
keywords = {Open RAN (O-RAN), Mobile Networks, Wireless Networks},
location = {Madrid, Spain},
series = {WiNTECH '23}
}

