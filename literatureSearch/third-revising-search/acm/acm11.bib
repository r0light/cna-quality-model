@inproceedings{10.1145/3549823.3549824,
author = {Chen, Hui and Ye, Xingmao and Zhang, Libo and Bu, Qian},
title = {The Construction of Government Information Open Platform: Research and Practice of the Ministry of Natural Resources},
year = {2023},
isbn = {9781450397919},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3549823.3549824},
doi = {10.1145/3549823.3549824},
abstract = {The rapid development of information technology has provided strong technical support for China to promote the construction of service-oriented government. The government information open platform(GIOP) uses information technology to enable the public to obtain government information in the most convenient way and make government information better serve the public, which is an important measure to promote the construction of service-oriented and transparent government. The Ministry of Natural Resources (MNR), which was established in 2018, was studied to analyse the significance and construction requirements of the GIOP. The content system, functions, system architecture, key technical methods and achievements are described. Real-life cases are provided to illustrate the series of technological means and mechanism support for breaking the barriers between platforms, thereby promoting the innovation of government information services.},
booktitle = {Proceedings of the 9th International Conference on Management of E-Commerce and e-Government},
pages = {1–6},
numpages = {6},
keywords = {Ministry of Natural Resources, government information, open platform, policy document},
location = {<conf-loc>, <city>Seoul</city>, <country>Republic of Korea</country>, </conf-loc>},
series = {ICMECG '22}
}

@inproceedings{10.1145/3444757.3485108,
author = {Morais, Gabriel and Bork, Dominik and Adda, Mehdi},
title = {Towards an Ontology-Driven Approach to Model and Analyze Microservices Architectures},
year = {2021},
isbn = {9781450383141},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3444757.3485108},
doi = {10.1145/3444757.3485108},
abstract = {Microservices Architectures (MSAs) are continuously replacing monolithic systems toward achieving more flexible and maintainable service-oriented software systems. However, the shift toward an MSA also requires a technological and managerial shift for its adopters. Architecting and managing MSAs represent unique challenges, including microservices' identification, interoperability, and reuse. To handle these challenges, we propose an Ontology-driven Conceptual Modelling approach, based on the Ontology of Microservices Architecture Concepts (OMSAC), for modelling and analyzing microservices-based systems. We show, how OMSAC-based conceptual models, stocked in a Stardog triple store, support Stakeholder-specific communication, documentation, and reuse. This paper reports on the application of our approach in three open-source MSA systems with a focus on microservices' discovery based on similarity metrics. Eventually, we compare the extracted similarity metrics derived from the application of machine learning techniques to the OMSAC models with a manual analysis performed by experts.},
booktitle = {Proceedings of the 13th International Conference on Management of Digital EcoSystems},
pages = {79–86},
numpages = {8},
keywords = {machine learning, Microservices, Stardog, ontology, OMSAC},
location = {Virtual Event, Tunisia},
series = {MEDES '21}
}

@article{10.14778/3583140.3583156,
author = {van Renen, Alexander and Leis, Viktor},
title = {Cloud Analytics Benchmark},
year = {2023},
issue_date = {February 2023},
publisher = {VLDB Endowment},
volume = {16},
number = {6},
issn = {2150-8097},
url = {https://doi.org/10.14778/3583140.3583156},
doi = {10.14778/3583140.3583156},
abstract = {The cloud facilitates the transition to a service-oriented perspective. This affects cloud-native data management in general, and data analytics in particular. Instead of managing a multi-node database cluster on-premise, end users simply send queries to a managed cloud data warehouse and receive results. While this is obviously very attractive for end users, database system architects still have to engineer systems for this new service model. There are currently many competing architectures ranging from self-hosted (Presto, PostgreSQL), over managed (Snowflake, Amazon Redshift) to query-as-a-service (Amazon Athena, Google BigQuery) offerings. Benchmarking these architectural approaches is currently difficult, and it is not even clear what the metrics for a comparison should be.To overcome these challenges, we first analyze a real-world query trace from Snowflake and compare its properties to that of TPC-H and TPC-DS. Doing so, we identify important differences that distinguish traditional benchmarks from real-world cloud data warehouse workloads. Based on this analysis, we propose the Cloud Analytics Benchmark (CAB). By incorporating workload fluctuations and multi-tenancy, CAB allows evaluating different designs in terms of user-centered metrics such as cost and performance.},
journal = {Proc. VLDB Endow.},
month = {feb},
pages = {1413–1425},
numpages = {13}
}

@inproceedings{10.1145/3522664.3528601,
author = {Paleyes, Andrei and Cabrera, Christian and Lawrence, Neil D.},
title = {An Empirical Evaluation of Flow Based Programming in the Machine Learning Deployment Context},
year = {2022},
isbn = {9781450392754},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3522664.3528601},
doi = {10.1145/3522664.3528601},
abstract = {As use of data driven technologies spreads, software engineers are more often faced with the task of solving a business problem using data-driven methods such as machine learning (ML) algorithms. Deployment of ML within large software systems brings new challenges that are not addressed by standard engineering practices and as a result businesses observe high rate of ML deployment project failures. Data Oriented Architecture (DOA) is an emerging approach that can support data scientists and software developers when addressing such challenges. However, there is a lack of clarity about how DOA systems should be implemented in practice. This paper proposes to consider Flow-Based Programming (FBP) as a paradigm for creating DOA applications. We empirically evaluate FBP in the context of ML deployment on four applications that represent typical data science projects. We use Service Oriented Architecture (SOA) as a baseline for comparison. Evaluation is done with respect to different application domains, ML deployment stages, and code quality metrics. Results reveal that FBP is a suitable paradigm for data collection and data science tasks, and is able to simplify data collection and discovery when compared with SOA. We discuss the advantages of FBP as well as the gaps that need to be addressed to increase FBP adoption as a standard design paradigm for DOA.},
booktitle = {Proceedings of the 1st International Conference on AI Engineering: Software Engineering for AI},
pages = {54–64},
numpages = {11},
keywords = {machine learning, service-oriented architecture, flow-based programming, software engineering},
location = {Pittsburgh, Pennsylvania},
series = {CAIN '22}
}

@inproceedings{10.1145/3543712.3543718,
author = {R\"{o}sch, Tobias and Sommer, Martin and Sax, Eric},
title = {Adaptive Application Development and Integration Process for Modern Automotive Software},
year = {2022},
isbn = {9781450396226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543712.3543718},
doi = {10.1145/3543712.3543718},
abstract = {Due to fast progress in information technologies and long lifecycles of vehicles, there are ever-increasing expectations in modern automotive software development regarding the flexibility to integrate updates and new functions quickly into already existing systems. This paper proposes a process, that is especially suitable for the development of new functions in higher programming languages and the usage of machine learning models. When developed in a tool like MATLAB, code generators can be used to integrate the function step-by-step into a service-oriented automotive E/E-architecture. It is based on a classic V-model process and uses integration steps according to the XiL approach. The key aspect is the frontloading of verification and validation into the steps as early as possible to keep iteration cycles fast. The proposed process is applied to the development of a Neural Network Model Predictive Control (NNMPC) for a Heating, Ventilation and Air-Conditioning (HVAC) unit of a city bus. The resulting NNMPC is then integrated into a system based on the AUTOSAR adaptive platform. That allowed the function to be developed and integrated quickly and seems to be a promising approach to bring new functions into already existing automotive E/E-architectures.},
booktitle = {Proceedings of the 2022 8th International Conference on Computer Technology Applications},
pages = {85–90},
numpages = {6},
keywords = {software development process, AUTOSAR Adaptive, automotive software, service-oriented architecture},
location = {Vienna, Austria},
series = {ICCTA '22}
}

@inproceedings{10.1145/3631204.3631859,
author = {Sapin, Etienne and Menon, Suraj and Ge, Jingquan and Habib, Sheikh Mahbub and Heymann, Maurice and Li, Yuekang and Palige, Rene and Byman, Gabriel and Liu, Yang},
title = {Monitoring Automotive Software Security Health through Trustworthiness Score},
year = {2023},
isbn = {9798400704543},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631204.3631859},
doi = {10.1145/3631204.3631859},
abstract = {The automotive industry is drastically moving towards autonomous. This trend constitutes in a fundamental change of going from mechanical and electrical engineering towards software-driven approaches. Modern vehicles can embed more than hundred electronic control units (ECUs). As autonomous vehicles require more intelligence as well as more computing power, high-performance computers (HPCs) bring the data management capabilities for cloud and IoT services to support the transition to a service-oriented vehicle system architecture. With this growing reliance on software in vehicles, software reliability and trustworthiness are increasingly critical to vehicle security. Measuring security trustworthiness in automotive software is even more valuable as cybersecurity is shifting to the left, i.e. in the early phase of development and design process. In this article, we propose a novel method for evaluating security trustworthiness of automotive software by leveraging a computational trust model. The method consists of selecting different domains contributing to software security, calculating their respective expectation value (trustworthiness score) and combining it using operators from the computational trust model. We evaluate the method using an automotive use case, i.e. over-the-air (OTA) update software. We describe a possible integration of the proposed method into a solution which would be valuable for cybersecurity stakeholders, e.g. cybersecurity managers, cybersecurity architects and software quality managers, aiming to monitor security health of automotive software throughout its development life cycle.},
booktitle = {Proceedings of the 7th ACM Computer Science in Cars Symposium},
articleno = {1},
numpages = {9},
keywords = {Software health, Trustworthiness, Data visualization},
location = {<conf-loc>, <city>Darmstadt</city>, <country>Germany</country>, </conf-loc>},
series = {CSCS '23}
}

@inproceedings{10.1145/3540250.3558951,
author = {Peng, Xin and Zhang, Chenxi and Zhao, Zhongyuan and Isami, Akasaka and Guo, Xiaofeng and Cui, Yunna},
title = {Trace Analysis Based Microservice Architecture Measurement},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3558951},
doi = {10.1145/3540250.3558951},
abstract = {Microservice architecture design highly relies on expert experience and may often result in improper service decomposition. Moreover, a microservice architecture is likely to degrade with the continuous evolution of services. Architecture measurement is thus important for the long-term evolution of microservice architectures. Due to the independent and dynamic nature of services, source code analysis based approaches cannot well capture the interactions between services. In this paper, we propose a trace analysis based microservice architecture measurement approach. We define a trace data model for microservice architecture measurement, which enables fine-grained analysis of the execution processes of requests and the interactions between interfaces and services. Based on the data model, we define 14 architectural metrics to measure the service independence and invocation chain complexity of a microservice system. We implement the approach and conduct three case studies with a student course project, an open-source microservice benchmark system, and three industrial microservice systems. The results show that our approach can well characterize the independence and invocation chain complexity of microservice architectures and help developers to identify microservice architecture issues caused by improper service decomposition and architecture degradation.},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1589–1599},
numpages = {11},
keywords = {Tracing, Architecture, Dynamic analysis, Microservice},
location = {<conf-loc>, <city>Singapore</city>, <country>Singapore</country>, </conf-loc>},
series = {ESEC/FSE 2022}
}

@inproceedings{10.1145/3483899.3483908,
author = {Santos, Ana and Paula, Hugo},
title = {Microservice Decomposition and Evaluation Using Dependency Graph and Silhouette Coefficient},
year = {2021},
isbn = {9781450384193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3483899.3483908},
doi = {10.1145/3483899.3483908},
abstract = {The benefits provided by microservices architecture in some application scenarios are a motivating factor for organizations to migrate their monoliths to this architecture. Extracting microservices from existing monolithic code bases presents a key challenge in this context, and there is a lack of tools that automate not only the decomposition processes but also the evaluation of the resulting architecture. This work presents a new approach for microservice decomposition that analyzes source code of a monolithic application and, with the combined use of approaches in the literature, suggests parts to be extracted in microservices considering the artifacts: classes, methods and/or history of modifications. The quality of the microservices’ suggestions are assessed, quantitatively, through the silhouette coefficient, a quality metric used in clustering analysis, and the microservice granularity. A tool was developed to automate the process of microservice decomposition for Java repositories. As a result, it was observed that the tool generated clusters with satisfactory results and can be used as an auxiliary instrument by experts during the migration process from monolithic architecture to microservices.},
booktitle = {Proceedings of the 15th Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {51–60},
numpages = {10},
keywords = {monolithic application, microservices, decomposition},
location = {Joinville, Brazil},
series = {SBCARS '21}
}

@inproceedings{10.1145/3543507.3583338,
author = {Jiang, Xinrui and Pan, Yicheng and Ma, Meng and Wang, Ping},
title = {Look Deep into the Microservice System Anomaly through Very Sparse Logs},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583338},
doi = {10.1145/3543507.3583338},
abstract = {Intensive monitoring and anomaly diagnosis have become a knotty problem for modern microservice architecture due to the dynamics of service dependency. While most previous studies rely heavily on ample monitoring metrics, we raise a fundamental but always neglected issue - the diagnostic metric integrity problem. This paper solves the problem by proposing MicroCU – a novel approach to diagnose microservice systems using very sparse API logs. We design a structure named dynamic causal curves to portray time-varying service dependencies and a temporal dynamics discovery algorithm based on Granger causal intervals. Our algorithm generates a smoother space of causal curves and designs the concept of causal unimodalization to calibrate the causality infidelities brought by missing metrics. Finally, a path search algorithm on dynamic causality graphs is proposed to pinpoint the root cause. Experiments on commercial system cases show that MicroCU outperforms many state-of-the-art approaches and reflects the superiorities of causal unimodalization to raw metric imputation.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {2970–2978},
numpages = {9},
keywords = {Dynamic Granger causality, Anomaly diagnosis, Root cause analysis, Microservice architecture},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3542929.3563477,
author = {Luo, Shutian and Xu, Huanle and Ye, Kejiang and Xu, Guoyao and Zhang, Liping and Yang, Guodong and Xu, Chengzhong},
title = {The Power of Prediction: Microservice Auto Scaling via Workload Learning},
year = {2022},
isbn = {9781450394147},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3542929.3563477},
doi = {10.1145/3542929.3563477},
abstract = {When deploying microservices in production clusters, it is critical to automatically scale containers to improve cluster utilization and ensure service level agreements (SLA). Although reactive scaling approaches work well for monolithic architectures, they are not necessarily suitable for microservice frameworks due to the long delay caused by complex microservice call chains. In contrast, existing proactive approaches leverage end-to-end performance prediction for scaling, but cannot effectively handle microservice multiplexing and dynamic microservice dependencies.In this paper, we present Madu, a proactive microservice auto-scaler that scales containers based on predictions for individual microservices. Madu learns workload uncertainty to handle the highly dynamic dependency between microservices. Additionally, Madu adopts OS-level metrics to optimize resource usage while maintaining good control over scaling overhead. Experiments on large-scale deployments of microservices in Alibaba clusters show that the overall prediction accuracy of Madu can reach as high as 92.3\% on average, which is 13\% higher than the state-of-the-art approaches. Furthermore, experiments running real-world microservice benchmarks in a local cluster of 20 servers show that Madu can reduce the overall resource usage by 1.7X compared to reactive solutions, while reducing end-to-end service latency by 50\%.},
booktitle = {Proceedings of the 13th Symposium on Cloud Computing},
pages = {355–369},
numpages = {15},
keywords = {microservices, proactive auto-scaler, workload uncertainty learning},
location = {San Francisco, California},
series = {SoCC '22}
}

@inproceedings{10.5555/3586210.3586383,
author = {Pearce, Glen and Pflaum, Alexis and Balasoiu, Dumitru Alin and Szabo, Claudia},
title = {Jeopardy Assessment for Dynamic Configuration of Collaborative Microservice Architectures},
year = {2023},
publisher = {IEEE Press},
abstract = {Microservice architectures, which are lightweight, flexible, and adapt easily to changes, have recently been considered for system development in military operations in contested and dynamic environments. However, in a military setting, the dynamic configuration of collaborative microservices execution becomes critical, and testing that microservice configurations behave as expected becomes paramount. In this paper, we propose a complex jeopardy metric and reconfiguration process that dynamically configures collaborative algorithms running on multiple nodes. Our metric and proposed scenarios will allow for the automated evaluation of microservice configurations and their re-configuration to suit operational needs. We evaluate our proposed scenario, metric, and various reconfiguration algorithms to show the benefits of this approach.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {2070–2081},
numpages = {12},
location = {Singapore, Singapore},
series = {WSC '22}
}

@inproceedings{10.1145/3575693.3575710,
author = {Switzer, Jennifer and Marcano, Gabriel and Kastner, Ryan and Pannuto, Pat},
title = {Junkyard Computing: Repurposing Discarded Smartphones to Minimize Carbon},
year = {2023},
isbn = {9781450399166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3575693.3575710},
doi = {10.1145/3575693.3575710},
abstract = {1.5 billion smartphones are sold annually, and most are decommissioned less than two years later. Most of these unwanted smartphones are neither discarded nor recycled but languish in junk drawers and storage units. This computational stockpile represents a substantial wasted potential: modern smartphones have increasingly high-performance and energy-efficient processors, extensive networking capabilities, and a reliable built-in power supply. This project studies the ability to reuse smartphones as "junkyard computers." Junkyard computers grow global computing capacity by extending device lifetimes, which supplants the manufacture of new devices. We show that the capabilities of even decade-old smartphones are within those demanded by modern cloud microservices and discuss how to combine phones to perform increasingly complex tasks. We describe how current operation-focused metrics do not capture the actual carbon costs of compute. We propose Computational Carbon Intensity---a performance metric that balances the continued service of older devices with the superlinear runtime improvements of newer machines. We use this metric to redefine device service lifetime in terms of carbon efficiency. We develop a cloudlet of reused Pixel 3A phones. We analyze the carbon benefits of deploying large, end-to-end microservice-based applications on these smartphones. Finally, we describe system architectures and associated challenges to scale to cloudlets with hundreds and thousands of smartphones.},
booktitle = {Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
pages = {400–412},
numpages = {13},
keywords = {life cycle assessment, sustainability, cloud computing},
location = {Vancouver, BC, Canada},
series = {ASPLOS 2023}
}

@inproceedings{10.1145/3578245.3585030,
author = {Belkhiri, Adel and Shahnejat Bushehri, Ahmad and Gohring de Magalhaes, Felipe and Nicolescu, Gabriela},
title = {Transparent Trace Annotation for Performance Debugging in Microservice-Oriented Systems (Work In Progress Paper)},
year = {2023},
isbn = {9798400700729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578245.3585030},
doi = {10.1145/3578245.3585030},
abstract = {Microservices is a cloud-native architecture in which a single application is implemented as a collection of small, independent, and loosely-coupled services. This architecture is gaining popularity in the industry as it promises to make applications more scalable and easier to develop and deploy. Nonetheless, adopting this architecture in practice has raised many concerns, particularly regarding the difficulty of diagnosing performance bugs and explaining abnormal software behaviour. Fortunately, many tools based on distributed tracing were proposed to achieve observability in microservice-oriented systems and address these concerns (e.g., Jaeger). Distributed tracing is a method for tracking user requests as they flow between services. While these tools can identify slow services and detect latency-related problems, they mostly fail to pinpoint the root causes of these issues.This paper presents a new approach for enacting cross-layer tracing of microservice-based applications. It also proposes a framework for annotating traces generated by most distributed tracing tools with relevant tracing data and metrics collected from the kernel. The information added to the traces aims at helping the practitioner get a clear insight into the operations of the application executing user requests. The framework we present is notably efficient in diagnosing the causes of long tail latencies. Unlike other solutions, our approach for annotating traces is completely transparent as it does not require the modification of the application, the tracer, or the operating system. Furthermore, our evaluation shows that this approach incurs low overhead costs.},
booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {25–32},
numpages = {8},
keywords = {microservices, performance analysis, distributed systems, software tracing},
location = {Coimbra, Portugal},
series = {ICPE '23 Companion}
}

@inproceedings{10.1145/3493649.3493656,
author = {Allen, Sadie and Toslali, Mert and Parthasarathy, Srinivasan and Oliveira, Fabio and Coskun, Ayse K.},
title = {Tritium: A Cross-Layer Analytics System for Enhancing Microservice Rollouts in the Cloud},
year = {2021},
isbn = {9781450391719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3493649.3493656},
doi = {10.1145/3493649.3493656},
abstract = {Microservice architectures are widely used in cloud-native applications as their modularity allows for independent development and deployment of components. With the many complex interactions occurring in between components, it is difficult to determine the effects of a particular microservice rollout. Site Reliability Engineers must be able to determine with confidence whether a new rollout is at fault for a concurrent or subsequent performance problem in the system so they can quickly mitigate the issue. We present Tritium, a cross-layer analytics system that synthesizes several types of data to suggest possible causes for Service Level Objective (SLO) violations in microservice applications. It uses event data to identify new version rollouts, tracing data to build a topology graph for the cluster and determine services potentially affected by the rollout, and causal impact analysis applied to metric time-series to determine if the rollout is at fault. Tritium works based on the principle that if a rollout is not responsible for a change in an upstream or neighboring SLO metric, then the rollout's telemetry data will do a poor job predicting the behavior of that SLO metric. In this paper, we experimentally demonstrate that Tritium can accurately attribute SLO violations to downstream rollouts and outline the steps necessary to fully realize Tritium.},
booktitle = {Proceedings of the Seventh International Workshop on Container Technologies and Container Clouds},
pages = {19–24},
numpages = {6},
keywords = {version rollouts, container systems, microservices, Fault diagnosis},
location = {Virtual Event, Canada},
series = {WoC '21}
}

@article{10.1145/3532183,
author = {Zdun, Uwe and Queval, Pierre-Jean and Simhandl, Georg and Scandariato, Riccardo and Chakravarty, Somik and Jelic, Marjan and Jovanovic, Aleksandar},
title = {Microservice Security Metrics for Secure Communication, Identity Management, and Observability},
year = {2023},
issue_date = {January 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3532183},
doi = {10.1145/3532183},
abstract = {Microservice architectures are increasingly being used to develop application systems. Despite many guidelines and best practices being published, architecting microservice systems for security is challenging. Reasons are the size and complexity of microservice systems, their polyglot nature, and the demand for the continuous evolution of these systems. In this context, to manually validate that security architecture tactics are employed as intended throughout the system is a time-consuming and error-prone task. In this article, we present an approach to avoid such manual validation before each continuous evolution step in a microservice system, which we demonstrate using three widely used categories of security tactics: secure communication, identity management, and observability. Our approach is based on a review of existing security guidelines, the gray literature, and the scientific literature, from which we derived Architectural Design Decisions (ADDs) with the found security tactics as decision options. In our approach, we propose novel detectors to detect these decision options automatically and formally defined metrics to measure the conformance of a system to the different options of the ADDs. We apply the approach to a case study data set of 10 open source microservice systems, plus another 20 variants of these systems, for which we manually inspected the source code for security tactics. We demonstrate and assess the validity and appropriateness of our metrics by performing an assessment of their conformance to the ADDs in our systems’ dataset through statistical methods.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {feb},
articleno = {16},
numpages = {34},
keywords = {microservice security, software architecture metrics, software architecture detectors, Microservice architecture}
}

@inproceedings{10.1145/3472883.3486999,
author = {Baarzi, Ataollah Fatahi and Kesidis, George},
title = {SHOWAR: Right-Sizing And Efficient Scheduling of Microservices},
year = {2021},
isbn = {9781450386388},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472883.3486999},
doi = {10.1145/3472883.3486999},
abstract = {Microservices architecture have been widely adopted in designing distributed cloud applications where the application is decoupled into multiple small components (i.e. "microservices"). One of the challenges in deploying microservices is finding the optimal amount of resources (i.e. size) and the number of instances (i.e. replicas) for each microservice in order to maintain a good performance as well as prevent resource wastage and under-utilization which is not cost-effective. This paper presents SHOWAR, a framework that configures the resources by determining the number of replicas (horizontal scaling) and the amount of CPU and Memory for each microservice (vertical scaling). For vertical scaling, SHOWAR uses empirical variance in the historical resource usage to find the optimal size and mitigate resource wastage. For horizontal scaling, SHOWAR uses basic ideas from control theory along with kernel level performance metrics. Additionally, once the size for each microservice is found, SHOWAR bridges the gap between optimal resource allocation and scheduling by generating affinity rules (i.e. hints) for the scheduler to further improve the performance. Our experiments, using a variety of microservice applications and real-world workloads, show that, compared to the state-of-the-art autoscaling and scheduling systems, SHOWAR on average improves the resource allocation by up to 22\% while improving the 99th percentile end-to-end user request latency by 20\%.},
booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
pages = {427–441},
numpages = {15},
keywords = {autoscaling, cloud computing, microservices},
location = {Seattle, WA, USA},
series = {SoCC '21}
}

@inproceedings{10.5555/3511065.3511076,
author = {Yoder, Joseph W. and Merson, Paulo},
title = {Strangler Patterns},
year = {2022},
isbn = {9781941652169},
publisher = {The Hillside Group},
address = {USA},
abstract = {Martin Fowler coined the term "Strangler Application" as a metaphor to describe a way of doing an evolutionary rewrite of a system, keeping it working while you evolve it. The main idea is to gradually create a new system around the edges of the old, letting it grow slowly over several years until the old system is strangled. The microservices architecture style has become very popular, and has been used to apply the strangler application to monolithic service-based systems. This paper describes different strategies (patterns) for applying the strangler application while evolving a monolith to use the microservices architecture style. The main ideas are: Wrap the monolith and protect services and system from change, Start Small and gradually evolve the system (baby steps), Pave the Road making microservices easier to create; Macroservice first then split to Microservice, Add new functionality as microservices, Extract Module / Component to Microservice, and Replace functionality with Microservice. As the system evolve it is common to Proxy Monolith Components and Add Fa\c{c}ade to the microservices},
booktitle = {Proceedings of the 27th Conference on Pattern Languages of Programs},
articleno = {8},
numpages = {25},
keywords = {pattern sequences, patterns, architecture, evolutionary architecture, continuous integration, DevOps, strangler, software development, sustainable delivery, microservices, monolith, pattern scenarios},
location = {Virtual Event},
series = {PLoP '20}
}

@inproceedings{10.1145/3559712.3559716,
author = {Moreira, Mateus Gabi and De Fran\c{c}a, Breno Bernard Nicolau},
title = {Analysis of Microservice Evolution Using Cohesion Metrics},
year = {2022},
isbn = {9781450397452},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3559712.3559716},
doi = {10.1145/3559712.3559716},
abstract = {The adoption of Microservices Architecture (MSA) has increased in recent years due to several claimed benefits, such as reducing deployment complexity, supporting technology diversity, and better scalability. However, MSA is not free from maintainability issues, especially the lack of cohesion, in which microservices possibly concentrate or miss responsibilities. Also, the lack of empirically-validated cohesion metrics for MSA makes the quantitative assessment even more challenging. In this paper, we empirically explore the practical applicability of service-level cohesion metrics in an open-source MSA application context. The qualitative results show the possibility of assessing MSA cohesion using these service-level metrics, the feasibility of tracking software evolution, and an indication of possible technical debts along the way.},
booktitle = {Proceedings of the 16th Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {40–49},
numpages = {10},
keywords = {Software evolution, Software architecture, Microservices, Cohesion Metrics},
location = {<conf-loc>, <city>Uberlandia</city>, <country>Brazil</country>, </conf-loc>},
series = {SBCARS '22}
}

@inproceedings{10.1145/3543507.3583274,
author = {Chakraborty, Sarthak and Garg, Shaddy and Agarwal, Shubham and Chauhan, Ayush and Saini, Shiv Kumar},
title = {CausIL: Causal Graph for Instance Level Microservice Data},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583274},
doi = {10.1145/3543507.3583274},
abstract = {AI-based monitoring has become crucial for cloud-based services due to its scale. A common approach to AI-based monitoring is to detect causal relationships among service components and build a causal graph. Availability of domain information makes cloud systems even better suited for such causal detection approaches. In modern cloud systems, however, auto-scalers dynamically change the number of microservice instances, and a load-balancer manages the load on each instance. This poses a challenge for off-the-shelf causal structure detection techniques as they neither incorporate the system architectural domain information nor provide a way to model distributed compute across varying numbers of service instances. To address this, we develop CausIL, which detects a causal structure among service metrics by considering compute distributed across dynamic instances and incorporating domain knowledge derived from system architecture. Towards the application in cloud systems, CausIL estimates a causal graph using instance-specific variations in performance metrics, modeling multiple instances of a service as independent, conditional on system assumptions. Simulation study shows the efficacy of CausIL over baselines by improving graph estimation accuracy by ∼ 25\% as measured by Structural Hamming Distance whereas the real-world dataset demonstrates CausIL’s applicability in deployment settings.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {2905–2915},
numpages = {11},
keywords = {Microservices, Causal Graph, Causal Structure Detection, System Monitoring},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3530019.3530040,
author = {Sellami, Khaled and Saied, Mohamed Aymen and Ouni, Ali},
title = {A Hierarchical DBSCAN Method for Extracting Microservices from Monolithic Applications},
year = {2022},
isbn = {9781450396134},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3530019.3530040},
doi = {10.1145/3530019.3530040},
abstract = {The microservices architectural style offers many advantages such as scalability, reusability and ease of maintainability. As such microservices has become a common architectural choice when developing new applications. Hence, to benefit from these advantages, monolithic applications need to be redesigned in order to migrate to a microservice based architecture. Due to the inherent complexity and high costs related to this process, it is crucial to automate this task. In this paper, we propose a method that can identify potential microservices from a given monolithic application. Our method takes as input the source code of the source application in order to measure the similarities and dependencies between all of the classes in the system using their interactions and the domain terminology employed within the code. These similarity values are then used with a variant of a density-based clustering algorithm to generate a hierarchical structure of the recommended microservices while identifying potential outlier classes. We provide an empirical evaluation of our approach through different experimental settings including a comparison with existing human-designed microservices and a comparison with 5 baselines. The results show that our method succeeds in generating microservices that are overall more cohesive and that have fewer interactions in-between them with up to 0.9 of precision score when compared to human-designed microservices.},
booktitle = {Proceedings of the 26th International Conference on Evaluation and Assessment in Software Engineering},
pages = {201–210},
numpages = {10},
keywords = {Legacy decomposition, Static Analysis, Clustering, Microservices},
location = {Gothenburg, Sweden},
series = {EASE '22}
}

@inproceedings{10.1145/3472883.3487003,
author = {Luo, Shutian and Xu, Huanle and Lu, Chengzhi and Ye, Kejiang and Xu, Guoyao and Zhang, Liping and Ding, Yu and He, Jian and Xu, Chengzhong},
title = {Characterizing Microservice Dependency and Performance: Alibaba Trace Analysis},
year = {2021},
isbn = {9781450386388},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472883.3487003},
doi = {10.1145/3472883.3487003},
abstract = {Loosely-coupled and light-weight microservices running in containers are replacing monolithic applications gradually. Understanding the characteristics of microservices is critical to make good use of microservice architectures. However, there is no comprehensive study about microservice and its related systems in production environments so far. In this paper, we present a solid analysis of large-scale deployments of microservices at Alibaba clusters. Our study focuses on the characterization of microservice dependency as well as its runtime performance. We conduct an in-depth anatomy of microservice call graphs to quantify the difference between them and traditional DAGs of data-parallel jobs. In particular, we observe that microservice call graphs are heavy-tail distributed and their topology is similar to a tree and moreover, many microservices are hot-spots. We reveal three types of meaningful call dependency that can be utilized to optimize microservice designs. Our investigation on microservice runtime performance indicates most microservices are much more sensitive to CPU interference than memory interference. To synthesize more representative microservice traces, we build a mathematical model to simulate call graphs. Experimental results demonstrate our model can well preserve those graph properties observed from Alibaba traces.},
booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
pages = {412–426},
numpages = {15},
location = {Seattle, WA, USA},
series = {SoCC '21}
}

@inproceedings{10.1145/3569902.3569916,
author = {Castro, Jessica and Laranjeiro, Nuno and Vieira, Marco},
title = {Detecting DoS Attacks in Microservice Applications: Approach&nbsp;and Case Study},
year = {2023},
isbn = {9781450397377},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3569902.3569916},
doi = {10.1145/3569902.3569916},
abstract = {A microservices-based architecture decreases the complexity of developing new systems, making them highly scalable and manageable. However, its distributed nature, the high granularity of services, and the large attack surface increase the need to secure those systems at runtime. This paper investigates the challenges of detecting low- and high-volume DoS attacks against microservices using application-level metrics. We conducted an exploratory study to evaluate how different services influence attack detection, the use of Machine Learning (ML) techniques to detect DoS attacks, and the application-level metrics that can be used to detect DoS attacks. The results show that, analysing the services in parallel improves the detection rate, ML models are promising in detecting DoS attacks, and the numbers of sockets and threads used by containers are valuable metrics to indicate high-volume DoS attacks.},
booktitle = {Proceedings of the 11th Latin-American Symposium on Dependable Computing},
pages = {73–78},
numpages = {6},
keywords = {attack detection, security, denial of service, microservices, machine learning, container},
location = {<conf-loc>, <city>Fortaleza/CE</city>, <country>Brazil</country>, </conf-loc>},
series = {LADC '22}
}

@inproceedings{10.1145/3531056.3542765,
author = {Peng, Xin},
title = {Large-Scale Trace Analysis for Microservice Anomaly Detection and Root Cause Localization},
year = {2022},
isbn = {9781450396639},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531056.3542765},
doi = {10.1145/3531056.3542765},
abstract = {Distributed tracing traces requests as they flow between services. It has been widely accepted and practiced in industry as an important means to achieve observability in microservice architecture for various purposes such as anomaly detection and root cause localization. However, trace analysis in an industrial microservice system is often challenging due to the huge number of traces produced by the system and the difficulties in combining traces with other types of operation data such as logs and metrics. In this talk, I will first analyze the background and describe the industrial practice of distributed tracing and trace analysis. Then I will introduce our explorations on large-scale trace analysis for microservice anomaly detection and root cause localization.},
booktitle = {Proceedings of the Federated Africa and Middle East Conference on Software Engineering},
pages = {93–94},
numpages = {2},
keywords = {Log, Metrics, Root Cause Analysis, Trace, Anomaly Detection, Microservice Architecture, Observability},
location = {Cairo-Kampala, Egypt},
series = {FAMECSE '22}
}

@inproceedings{10.1145/3570748.3570756,
author = {Lee, Chunghan and Yoshitani, Reina and Hirotsu, Toshio},
title = {Enhancing Packet Tracing of Microservices in Container Overlay Networks Using EBPF},
year = {2022},
isbn = {9781450399814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3570748.3570756},
doi = {10.1145/3570748.3570756},
abstract = {The microservices architecture has been rapidly adopted to latency-sensitive applications. The architecture of these applications and the container overlay networks on servers are also complex. Distributed tracing is widely adopted in microservice applications; it suffers from the drawback of only focusing on service discovery and latency-based monitoring at an application layer, making it still challenging to monitor container overlay networks using distributed tracing. In this paper, we present an extended Berkeley Packet Filter (eBPF)-based packet tracing method using distributed tracing for latency measurement in the container overlay network. To efficiently detect the trace context on a HTTP payload, we moved the trace context position just behind the HTTP request line using sidecar proxy. Our tracing method gathered the HTTP packets that had the trace context and measured the latency using eBPF. Our evaluation was conducted using open-source benchmarks on Kubernetes; the results showed that the proposed tracing header format reduced the HTTP payload search space by up to approximately 80, and there was no significant change in end-to-end latency. Moreover, our eBPF-based tracing method presented similar latency characteristics on the overlay network in comparison with the characteristics of the packet-level traces obtained under tcpdump.},
booktitle = {Proceedings of the 17th Asian Internet Engineering Conference},
pages = {53–61},
numpages = {9},
keywords = {Sidecar, ServiceMesh, Kubernetes, Latency, Distributed tracing, Microservices, eBPF},
location = {<conf-loc>, <city>Hiroshima</city>, <country>Japan</country>, </conf-loc>},
series = {AINTEC '22}
}

@inproceedings{10.1145/3611643.3613861,
author = {Xie, Zhe and Pei, Changhua and Li, Wanxue and Jiang, Huai and Su, Liangfei and Li, Jianhui and Xie, Gaogang and Pei, Dan},
title = {From Point-Wise to Group-Wise: A Fast and Accurate Microservice Trace Anomaly Detection Approach},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613861},
doi = {10.1145/3611643.3613861},
abstract = {As Internet applications continue to scale up, microservice architecture has become increasingly popular due to its flexibility and logical structure. Anomaly detection in traces that record inter-microservice invocations is essential for diagnosing system failures. Deep learning-based approaches allow for accurate modeling of structural features (i.e., call paths) and latency features (i.e., call response time), which can determine the anomaly of a particular trace sample. However, the point-wise manner employed by these methods results in substantial system detection overhead and impracticality, given the massive volume of traces (billion-level). Furthermore, the point-wise approach lacks high-level information, as identical sub-structures across multiple traces may be encoded differently. In this paper, we introduce the first Group-wise Trace anomaly detection algorithm, named GTrace. This method categorizes the traces into distinct groups based on their shared sub-structure, such as the entire tree or sub-tree structure. A group-wise Variational AutoEncoder (VAE) is then employed to obtain structural representations. Moreover, the innovative "predicting latency with structure" learning paradigm facilitates the association between the grouped structure and the latency distribution within each group. With the group-wise design, representation caching, and batched inference strategies can be implemented, which significantly reduces the burden of detection on the system. Our comprehensive evaluation reveals that GTrace outperforms state-of-the-art methods in both performances (2.64\% to 195.45\% improvement in AUC metrics and 2.31\% to 40.92\% improvement in best F-Score) and efficiency (21.9x to 28.2x speedup). We have deployed and assessed the proposed algorithm on eBay's microservices cluster, and our code is available at https://github.com/NetManAIOps/GTrace.git.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1739–1749},
numpages = {11},
keywords = {microservice trace, variational autoencoder, anomaly detection},
location = {<conf-loc>, <city>San Francisco</city>, <state>CA</state>, <country>USA</country>, </conf-loc>},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3580305.3599934,
author = {Wang, Lu and Zhang, Chaoyun and Ding, Ruomeng and Xu, Yong and Chen, Qihang and Zou, Wentao and Chen, Qingjun and Zhang, Meng and Gao, Xuedong and Fan, Hao and Rajmohan, Saravan and Lin, Qingwei and Zhang, Dongmei},
title = {Root Cause Analysis for Microservice Systems via Hierarchical Reinforcement Learning from Human Feedback},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599934},
doi = {10.1145/3580305.3599934},
abstract = {In microservice systems, the identification of root causes of anomalies is imperative for service reliability and business impact. This process is typically divided into two phases: (i)constructing a service dependency graph that outlines the sequence and structure of system components that are invoked, and (ii) localizing the root cause components using the graph, traces, logs, and Key Performance Indicators (KPIs) such as latency. However, both phases are not straightforward due to the highly dynamic and complex nature of the system, particularly in large-scale commercial architectures like Microsoft Exchange.In this paper, we propose a new framework that employs Hierarchical Reinforcement Learning from Human Feedback (HRLHF) to address these challenges. Our framework leverages the static topology of the microservice system and efficiently employs the feedback of engineers to reduce uncertainty in the discovery of the service dependency graph. The framework utilizes reinforcement learning to reduce the number of queries required from O(N2) to O(1), enabling the construction of the dependency graph with high accuracy and minimal human effort. Additionally, we extend the discovered dependency graphs to window causal graphs that capture the characteristics of time series over a specified time period, resulting in improved root cause analysis accuracy and robustness. Evaluations on both real datasets from Microsoft Exchange and synthetic datasets with injected anomalies demonstrate superior performance on various metrics compared to state-of-the-art methods. It is worth mentioning that, our framework has been integrated as a crucial component in Microsoft M365 Exchange service.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5116–5125},
numpages = {10},
keywords = {root cause analysis, causal discovery, reinforcement learning from human feedback},
location = {<conf-loc>, <city>Long Beach</city>, <state>CA</state>, <country>USA</country>, </conf-loc>},
series = {KDD '23}
}

@inproceedings{10.1145/3583780.3615195,
author = {Gong, Shengbo and Zhou, Jiajun and Xie, Chenxuan and Xuan, Qi},
title = {Neighborhood Homophily-Based Graph Convolutional Network},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615195},
doi = {10.1145/3583780.3615195},
abstract = {Graph neural networks (GNNs) have been proved powerful in graph-oriented tasks. However, many real-world graphs are heterophilous, challenging the homophily assumption of classical GNNs. To solve the universality problem, many studies deepen networks or concatenate intermediate representations, which does not inherently change neighbor aggregation and introduces noise. Recent studies propose new metrics to characterize the homophily, but rarely consider the correlation of the proposed metrics and models. In this paper, we first design a new metric, Neighborhood Homophily (NH), to measure the label complexity or purity in node neighborhoods. Furthermore, we incorporate the metric into the classical graph convolutional network (GCN) architecture and propose Neighborhood Homophily-based Graph Convolutional Network (NHGCN). In this framework, neighbors are grouped by estimated NH values and aggregated from different channels, and the resulting node predictions are then used in turn to estimate and update NH values. The two processes of metric estimation and model inference are alternately optimized to achieve better node classification. NHGCN achieves top overall performance on both homophilous and heterophilous benchmarks, with an improvement of up to 7.4\% compared to the current SOTA methods.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {3908–3912},
numpages = {5},
keywords = {graph neural networks, homophily, node classification},
location = {<conf-loc>, <city>Birmingham</city>, <country>United Kingdom</country>, </conf-loc>},
series = {CIKM '23}
}

@inproceedings{10.1145/3528229.3529382,
author = {Hrusto, Adha and Engstr\"{o}m, Emelie and Runeson, Per},
title = {Optimization of Anomaly Detection in a Microservice System through Continuous Feedback from Development},
year = {2022},
isbn = {9781450393348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3528229.3529382},
doi = {10.1145/3528229.3529382},
abstract = {Monitoring a microservice system may bring a lot of benefits to development teams such as early detection of run-time errors and various performance anomalies. In this study, we explore deep learning (DL) solutions for detection of anomalous system's behavior based on collected monitoring data that consists of applications' and systems' performance metrics. The study is conducted in a collaboration with a Swedish company responsible for ticket and payment management in public transportation. Moreover, we specifically address a shortage of approaches for evaluating DL models without any ground truth data. Hence, we propose a solution design for anomaly detection and reporting alerts inspired by state-of-the-art DL solutions. Furthermore, we propose a plan for its in-context implementation and evaluation empowered by feedback from the development team. Through continuous feedback from development, the labeled data is generated and used for optimization of the DL model. In this way, a microservice system may leverage DL solutions to address rising challenges within its architecture.},
booktitle = {Proceedings of the 10th IEEE/ACM International Workshop on Software Engineering for Systems-of-Systems and Software Ecosystems},
pages = {13–20},
numpages = {8},
keywords = {DevOps, anomaly detection, deep learning, microservices},
location = {Pittsburgh, Pennsylvania},
series = {SESoS '22}
}

@inproceedings{10.1145/3575693.3575751,
author = {Liang, Mingyu and Gan, Yu and Li, Yueying and Torres, Carlos and Dhanotia, Abhishek and Ketkar, Mahesh and Delimitrou, Christina},
title = {Ditto: End-to-End Application Cloning for Networked Cloud Services},
year = {2023},
isbn = {9781450399166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3575693.3575751},
doi = {10.1145/3575693.3575751},
abstract = {The lack of representative, publicly-available cloud services has been a recurring problem in the architecture and systems communities. While open-source benchmarks exist, they do not capture the full complexity of cloud services. Application cloning is a promising way to address this, however, prior work is limited to CPU-/cache-centric, single-node services, operating at user level.  

We present Ditto, an automated framework for cloning end-to-end cloud applications, both monolithic and microservices, which captures I/O and network activity, as well as kernel operations, in addition to application logic. Ditto takes a hierarchical approach to application cloning, starting with capturing the dependency graph across distributed services, to recreating each tier's control/data flow, and finally generating system calls and assembly that mimics the individual applications. Ditto does not reveal the logic of the original application, facilitating publicly sharing clones of production services with hardware vendors, cloud providers, and the research community.  

We show that across a diverse set of single- and multi-tier applications, Ditto accurately captures their CPU and memory characteristics as well as their high-level performance metrics, is portable across platforms, and facilitates a wide range of system studies.},
booktitle = {Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
pages = {222–236},
numpages = {15},
keywords = {cloud computing, microservices, architecture, benchmarking and emulation, software reverse engineering},
location = {Vancouver, BC, Canada},
series = {ASPLOS 2023}
}

@inproceedings{10.1145/3472883.3486986,
author = {Zhang, Jun and Ferydouni, Robert and Montana, Aldrin and Bittman, Daniel and Alvaro, Peter},
title = {3MileBeach: A Tracer with Teeth},
year = {2021},
isbn = {9781450386388},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472883.3486986},
doi = {10.1145/3472883.3486986},
abstract = {We present 3MileBeach, a tracing and fault injection platform designed for microservice-based architectures. 3Mile-Beach interposes on the message serialization libraries that are ubiquitous in this environment, avoiding the application code instrumentation that tracing and fault injection infrastructures typically require. 3MileBeach provides message-level distributed tracing at less than 50\% of the overhead of the state-of-the-art tracing frameworks, and fault injection that allows higher precision experiments than existing solutions. We measure the overhead of 3MileBeach as a tracer and its efficacy as a fault injector. We qualitatively measure its promise as a platform for tuning and debugging by sharing concrete use cases in the context of bottleneck identification, performance tuning, and bug finding. Finally, we use 3MileBeach to perform a novel type of fault injection - Temporal Fault Injection (TFI), which more precisely controls individual inter-service message flow with temporal prerequisites, and makes it possible to catch an entirely new class of fault tolerance bugs.},
booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
pages = {458–472},
numpages = {15},
keywords = {Temporal Fault Injection, Chaos Engineering, Application Tuning, Tracing, Bug Finding},
location = {Seattle, WA, USA},
series = {SoCC '21}
}

@article{10.1145/3582573,
author = {Chen, Jialuo and Wang, Jingyi and Ma, Xingjun and Sun, Youcheng and Sun, Jun and Zhang, Peixin and Cheng, Peng},
title = {QuoTe: Quality-Oriented Testing for Deep Learning Systems},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3582573},
doi = {10.1145/3582573},
abstract = {Recently, there has been significant growth of interest in applying software engineering techniques for the quality assurance of deep learning (DL) systems. One popular direction is DL testing—that is, given a property of test, defects of DL systems are found either by fuzzing or guided search with the help of certain testing metrics. However, recent studies have revealed that the neuron coverage metrics, which are commonly used by most existing DL testing approaches, are not necessarily correlated with model quality (e.g., robustness, the most studied model property), and are also not an effective measurement on the confidence of the model quality after testing. In this work, we address this gap by proposing a novel testing framework called QuoTe (i.e., Quality-oriented Testing). A key part of QuoTe is a quantitative measurement on (1) the value of each test case in enhancing the model property of interest (often via retraining) and (2) the convergence quality of the model property improvement. QuoTe utilizes the proposed metric to automatically select or generate valuable test cases for improving model quality. The proposed metric is also a lightweight yet strong indicator of how well the improvement converged. Extensive experiments on both image and tabular datasets with a variety of model architectures confirm the effectiveness and efficiency of QuoTe in improving DL model quality—that is, robustness and fairness. As a generic quality-oriented testing framework, future adaptations can be made to other domains (e.g., text) as well as other model properties.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {jul},
articleno = {125},
numpages = {33},
keywords = {Deep learning, fairness, testing, robustness}
}

@inproceedings{10.1109/ASE51524.2021.9678708,
author = {Wang, Hanzhang and Wu, Zhengkai and Jiang, Huai and Huang, Yichao and Wang, Jiamu and Kopru, Selcuk and Xie, Tao},
title = {Groot: An Event-Graph-Based Approach for Root Cause Analysis in Industrial Settings},
year = {2022},
isbn = {9781665403375},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE51524.2021.9678708},
doi = {10.1109/ASE51524.2021.9678708},
abstract = {For large-scale distributed systems, it is crucial to efficiently diagnose the root causes of incidents to maintain high system availability. The recent development of microservice architecture brings three major challenges (i.e., complexities of operation, system scale, and monitoring) to root cause analysis (RCA) in industrial settings. To tackle these challenges, in this paper, we present Groot, an event-graph-based approach for RCA. Groot constructs a real-time causality graph based on events that summarize various types of metrics, logs, and activities in the system under analysis. Moreover, to incorporate domain knowledge from site reliability engineering (SRE) engineers, Groot can be customized with user-defined events and domain-specific rules. Currently, Groot supports RCA among 5,000 real production services and is actively used by the SRE teams in eBay, a global e-commerce system serving more than 159 million active buyers per year. Over 15 months, we collect a data set containing labeled root causes of 952 real production incidents for evaluation. The evaluation results show that Groot is able to achieve 95\% top-3 accuracy and 78\% top-1 accuracy. To share our experience in deploying and adopting RCA in industrial settings, we conduct a survey to show that users of Groot find it helpful and easy to use. We also share the lessons learned from deploying and adopting Groot to solve RCA problems in production environments.},
booktitle = {Proceedings of the 36th IEEE/ACM International Conference on Automated Software Engineering},
pages = {419–429},
numpages = {11},
keywords = {microservices, root cause analysis, AIOps, observability},
location = {Melbourne, Australia},
series = {ASE '21}
}

@inproceedings{10.1145/3578245.3585032,
author = {Somashekar, Gagan and Kumar, Rajat},
title = {Enhancing the Configuration Tuning Pipeline of Large-Scale Distributed Applications Using Large Language Models (Idea Paper)},
year = {2023},
isbn = {9798400700729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578245.3585032},
doi = {10.1145/3578245.3585032},
abstract = {The performance of distributed applications implemented using microservice architecture depends heavily on the configuration of various parameters, which are hard to tune due to large configuration search space and inter-dependence of parameters. While the information in product manuals and technical documents guides the tuning process, manual collection of meta-data for all application parameters is laborious and not scalable. Prior works have largely overlooked the automated use of product manuals, technical documents and source code for extracting such meta-data. In the current work, we propose using large language models for automated meta-data extraction and enhancing the configuration tuning pipeline. We further ideate on building an in-house knowledge system using experimental data to learn important parameters in configuration tuning using historical data on parameter dependence, workload statistics, performance metrics and resource utilization. We expect productionizing the proposed system will reduce the total time and experimental iterations required for configuration tuning in new applications, saving an organization both developer time and money.},
booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {39–44},
numpages = {6},
keywords = {microservice architecture, information retrieval, parameter tuning, large language models},
location = {Coimbra, Portugal},
series = {ICPE '23 Companion}
}

@article{10.1145/3611312,
author = {Maschi, Fabio and Alonso, Gustavo},
title = {Strega: An HTTP Server for FPGAs},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1936-7406},
url = {https://doi.org/10.1145/3611312},
doi = {10.1145/3611312},
abstract = {The computer architecture landscape is being reshaped by the new opportunities, challenges and constraints brought by the cloud. On the one hand, high-level applications profit from specialised hardware to boost their performance and reduce deployment costs. On the other hand, cloud providers maximise the CPU time allocated to client applications by offloading infrastructure tasks to hardware accelerators. While it is well understood how to do this for, e.g., network function virtualisation and protocols such as TCP/IP, support for higher networking layers is still largely missing, limiting the potential of accelerators. In this paper, we present Strega, an open-source1 light-weight HTTP server that enables crucial functionality such as FPGA-accelerated functions being called through a RESTful protocol (FPGA-as-a-Function). Our experimental analysis shows that a single Strega node sustains a throughput of 1.7&nbsp;M HTTP requests per second with an end-to-end latency as low as 16μs, outperforming nginx running on 32 vCPUs in both metrics, and can even be an alternative to the traditional OpenCL flow over the PCIe bus. Through this work, we pave the way for running microservices directly on FPGAs, bypassing CPU overhead and realising the full potential of FPGA acceleration in distributed cloud applications.},
note = {Just Accepted},
journal = {ACM Trans. Reconfigurable Technol. Syst.},
month = {oct},
keywords = {FPGA, distributed systems, HTTP, RESTful API, Network on chip, disaggregated accelerator, Webserver}
}

@article{10.1145/3583563,
author = {Camilli, Matteo and Colarusso, Carmine and Russo, Barbara and Zimeo, Eugenio},
title = {Actor-Driven Decomposition of Microservices through Multi-Level Scalability Assessment},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3583563},
doi = {10.1145/3583563},
abstract = {The microservices architectural style has gained widespread acceptance. However, designing applications according to this style is still challenging. Common difficulties concern finding clear boundaries that guide decomposition while ensuring performance and scalability. With the aim of providing software architects and engineers with a systematic methodology, we introduce a novel actor-driven decomposition strategy to complement the domain-driven design and overcome some of its limitations by reaching a finer modularization yet enforcing performance and scalability improvements. The methodology uses a multi-level scalability assessment framework that supports decision-making over iterative steps. At each iteration, architecture alternatives are quantitatively evaluated at multiple granularity levels. The assessment helps architects to understand the extent to which architecture alternatives increase or decrease performance and scalability. We applied the methodology to drive further decomposition of the core microservices of a real data-intensive smart mobility application and an existing open-source benchmark in the e-commerce domain. The results of an in-depth evaluation show that the approach can effectively support engineers in (i) decomposing monoliths or coarse-grained microservices into more scalable microservices and (ii) comparing among alternative architectures to guide decision-making for their deployment in modern infrastructures that orchestrate lightweight virtualized execution units.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {jul},
articleno = {117},
numpages = {46},
keywords = {performance analysis, scalability assessment, architectural patterns, decomposition process, Microservices}
}

@inproceedings{10.1145/3628797.3628901,
author = {Le-Thanh, Phuc and Le-Anh, Tuan and Le-Trung, Quan},
title = {Research and Development of a Smart Solution for Runtime Web Application Self-Protection},
year = {2023},
isbn = {9798400708916},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628797.3628901},
doi = {10.1145/3628797.3628901},
abstract = {In contemporary times, ensuring web application security is a critical concern for organizations due to the prevalence of numerous types of attacks that serve diverse purposes. While traditional security measures such as web application firewalls (WAF) and intrusion detection systems (IDS) can help mitigate attacks, there is still a possibility of them being circumvented or compromised. A more efficacious approach is to adopt runtime application self-protection (RASP) solutions integrated within the web application. This solution has demonstrated its effectiveness by aiding in early attack detection and rapid attack mitigation. In this research, we propose a smart solution for runtime web application self-protection (RASP) to protect against vulnerabilities, attacks, and common weaknesses that have been rated among the top ten web security risks in 2021 by the Open Web Application Security Project (OWASP). The proposed solution leverages convolutional neural network (CNN) and a family of recurrent neural network (RNN) techniques. It builds a deep learning model with deep neural network architectures that scrutinizes user requests, thereby detecting potential SQL injection (SQLi), Cross-Site scripting (XSS), command injection (CMDi), and other types of attacks. The solution is designed to dynamically adapt to the application’s behavior and traffic, with the goal of minimizing false positives and preventing the blocking of legitimate traffic. Furthermore, the proposed solution, based on a microservices architecture, enhances the flexibility of the prediction module during upgrades and automated deployment. It is integrated with MLOps and DevSecOps and is also designed to be compatible with RESTful API servers. Our results have validated the efficacy of this solution in providing real-time application protection.},
booktitle = {Proceedings of the 12th International Symposium on Information and Communication Technology},
pages = {304–311},
numpages = {8},
keywords = {Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU)., Deep Learning, Convolutional Neural Network (CNN), Web Application Security, Runtime Application Self-Protection (RASP)},
location = {<conf-loc>, <city>Ho Chi Minh</city>, <country>Vietnam</country>, </conf-loc>},
series = {SOICT '23}
}

@inproceedings{10.1145/3491204.3527462,
author = {V, Thrivikraman and Dixit, Vishnu R. and S, Nikhil Ram and Gowda, Vikas K. and Vasudevan, Santhosh Kumar and Kalambur, Subramaniam},
title = {MiSeRTrace: Kernel-Level Request Tracing for Microservice Visibility},
year = {2022},
isbn = {9781450391597},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491204.3527462},
doi = {10.1145/3491204.3527462},
abstract = {With the evolution of microservice applications, the underlying architectures have become increasingly complex compared to their monolith counterparts. This mainly brings in the challenge of observability. By providing a deeper understanding into the functioning of distributed applications, observability enables improving the performance of the system by obtaining a view of the bottlenecks in the implementation. The observability provided by currently existing tools that perform dynamic tracing on distributed applications is limited to the user-space and requires the application to be instrumented to track request flows. In this paper, we present a new open-source framework MiSeRTrace that can trace the end-to-end path of requests entering a microservice application at the kernel space without requiring instrumentation or modification of the application. Observability at the comprehensiveness of the kernel space allows breaking down of various steps in activities such as network transfers and IO tasks, thus enabling root cause based performance analysis and accurate identification of hotspots. MiSeRTrace supports tracing user-enabled kernel events provided by frameworks such as bpftrace or ftrace and isolates kernel activity associated with each application request with minimal overheads. We then demonstrate the working of the solution with results on a benchmark microservice application.},
booktitle = {Companion of the 2022 ACM/SPEC International Conference on Performance Engineering},
pages = {77–80},
numpages = {4},
keywords = {thread state model, microservice, request tracing, misertrace, kernel tracing},
location = {Bejing, China},
series = {ICPE '22}
}

@inproceedings{10.1145/3479239.3485679,
author = {Hanzo, Lajos},
title = {Space-Air-Ground Integrated Networking: From Single- to Multi-Component Pareto Optimization},
year = {2021},
isbn = {9781450390774},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3479239.3485679},
doi = {10.1145/3479239.3485679},
abstract = {Thanks to the spectacular advances in signal processing and nano-technology, five wireless generations have been conceived over the past five decades. Indeed, near-capacity operation at an infinitesimally low error-rate has become feasible and flawless multimedia communications is supported in areas of high traffic-density, but how do we fill the huge coverage holes existing across the globe? As a promising system-architecture, the SAGIN concept constituted by an integrated terrestrial, UAV-aided, airplane-assisted as well as satellite-based global coverage-solution will be highlighted to pave the way for seamless next-generation service provision. However, these links exhibit strongly heterogeneous properties, hence requiring different enabling techniques. The joint optimization of the associated conflicting performance metrics of throughput, transmit power, latency, error probability, hand-over probability and link-lifetime poses an extremely challenging problem. Explicitly, sophisticated multi-component system optimization is required for finding the Pareto-front of all optimal solutions, where none of the above-mentioned metric can be improved without degrading at least one of the others [1] - [5]....},
booktitle = {Proceedings of the 24th International ACM Conference on Modeling, Analysis and Simulation of Wireless and Mobile Systems},
pages = {1},
numpages = {1},
location = {Alicante, Spain},
series = {MSWiM '21}
}

@inproceedings{10.1145/3468737.3494104,
author = {Lanciano, Giacomo and Galli, Filippo and Cucinotta, Tommaso and Bacciu, Davide and Passarella, Andrea},
title = {Predictive Auto-Scaling with OpenStack Monasca},
year = {2021},
isbn = {9781450385640},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468737.3494104},
doi = {10.1145/3468737.3494104},
abstract = {Cloud auto-scaling mechanisms are typically based on reactive automation rules that scale a cluster whenever some metric, e.g., the average CPU usage among instances, exceeds a predefined threshold. Tuning these rules becomes particularly cumbersome when scaling-up a cluster involves non-negligible times to bootstrap new instances, as it happens frequently in production cloud services.To deal with this problem, we propose an architecture for auto-scaling cloud services based on the status in which the system is expected to evolve in the near future. Our approach leverages on time-series forecasting techniques, like those based on machine learning and artificial neural networks, to predict the future dynamics of key metrics, e.g., resource consumption metrics, and apply a threshold-based scaling policy on them. The result is a predictive automation policy that is able, for instance, to automatically anticipate peaks in the load of a cloud application and trigger ahead of time appropriate scaling actions to accommodate the expected increase in traffic.We prototyped our approach as an open-source OpenStack component, which relies on, and extends, the monitoring capabilities offered by Monasca, resulting in the addition of predictive metrics that can be leveraged by orchestration components like Heat or Senlin. We show experimental results using a recurrent neural network and a multi-layer perceptron as predictor, which are compared with a simple linear regression and a traditional non-predictive auto-scaling policy. However, the proposed framework allows for the easy customization of the prediction policy as needed.},
booktitle = {Proceedings of the 14th IEEE/ACM International Conference on Utility and Cloud Computing},
articleno = {20},
numpages = {10},
keywords = {elasticity auto-scaling, time-series forecasting, OpenStack, predictive operations},
location = {Leicester, United Kingdom},
series = {UCC '21}
}

@inproceedings{10.5555/3535850.3535942,
author = {Liu, Wencong and Liu, Jiamou and Zhang, Zijian and Liu, Yiwei and Zhu, Liehuang},
title = {Residual Entropy-Based Graph Generative Algorithms},
year = {2022},
isbn = {9781450392136},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Classification and clustering are crucial tasks that recognize the identities and the communities of nodes in a graph. Several methods have been proposed to reduce the accuracy of node classification and clustering through graph neural networks (GNN). Existing defense methods usually modify the model architecture and adopt countermeasure training to enhance the robustness of the node classification and clustering. However, these defense methods are model-oriented and not robust.To alleviate the problem, this paper first proposes a robust node classification metric based on residual entropy. More concretely, we prove that maximizing the residual entropy helps to improve the robustness of the classification accuracy. We them propose two graph generative algorithms to resist against two kinds of GNN-based attacks, the untargeted and the targeted attacks. Finally, experimental analysis show that the proposed algorithms outperform the existing defense works under five classic datasets.},
booktitle = {Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems},
pages = {816–824},
numpages = {9},
keywords = {robustness, graph generative algorithm, graph adversarial learning, residual entropy, node classification},
location = {Virtual Event, New Zealand},
series = {AAMAS '22}
}

@inproceedings{10.1145/3477145.3477156,
author = {Balaji, Adarsha and Song, Shihao and Titirsha, Twisha and Das, Anup and Krichmar, Jeffrey and Dutt, Nikil and Shackleford, James and Kandasamy, Nagarajan and Catthoor, Francky},
title = {NeuroXplorer 1.0: An Extensible Framework for Architectural Exploration with Spiking Neural Networks},
year = {2021},
isbn = {9781450386913},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477145.3477156},
doi = {10.1145/3477145.3477156},
abstract = {Recently, both industry and academia have proposed many different neuromorphic architectures to execute applications that are designed with Spiking Neural Network (SNN). Consequently, there is a growing need for an extensible simulation framework that can perform architectural explorations with SNNs, including both platform-based design of today’s hardware, and hardware-software co-design and design-technology co-optimization of the future. We present NeuroXplorer, a fast and extensible framework that is based on a generalized template for modeling a neuromorphic architecture that can be infused with the specific details of a given hardware and/or technology. NeuroXplorer can perform both low-level cycle-accurate architectural simulations and high-level analysis with data-flow abstractions. NeuroXplorer’s optimization engine can incorporate hardware-oriented metrics such as energy, throughput, and latency, as well as SNN-oriented metrics such as inter-spike interval distortion and spike disorder, which directly impact SNN performance. We demonstrate the architectural exploration capabilities of NeuroXplorer through case studies with many state-of-the-art machine learning models.},
booktitle = {International Conference on Neuromorphic Systems 2021},
articleno = {10},
numpages = {9},
keywords = {Spiking Neural Networks (SNN), Design-Technology Co-Optimization, Neuromorphic Computing, Platform-Based Design, Hardware-Software Co-Design, Non Volatile Memory (NVM)},
location = {Knoxville, TN, USA},
series = {ICONS 2021}
}

@inproceedings{10.1145/3555962.3555968,
author = {Alzboon, Ghufran and Al-Said Ahmad, Amro},
title = {A Performance Evaluation Approach for N-Tier Cloud-Based Software Services},
year = {2022},
isbn = {9781450396578},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3555962.3555968},
doi = {10.1145/3555962.3555968},
abstract = {Cloud computing and cloud testing are vast fields that have attracted significant attention recently. In addition, the need to find an approach for measuring cloud-based applications' effectiveness has also increased. In this work, we introduced an approach to testing the performance of the cloud software services on the Amazon cloud. We used two cloud-based applications hosted in the Amazon cloud to demonstrate the approach depending on five technical performance metrics. We applied the testing methodology using a JMeter test script. The two selected applications represent two different taxonomies: 2-tier and 3-tier architectures. Following the testing process, we found that the WordPress application (i.e., 3-tier architecture) performs better than Ghost and is more stable in terms of the selected performance metrics. Practitioners would benefit from this study by a better understanding of the assessment and testing of n-tier Cloud-Based Software Services using technical arguments.},
booktitle = {Proceedings of the 2022 6th International Conference on Cloud and Big Data Computing},
pages = {31–36},
numpages = {6},
keywords = {evaluation method, Cloud computing, n-tier, Software services, performance},
location = {Birmingham, United Kingdom},
series = {ICCBDC '22}
}

@inproceedings{10.1145/3579371.3589052,
author = {Ning, August and Tziantzioulis, Georgios and Wentzlaff, David},
title = {Supply Chain Aware Computer Architecture},
year = {2023},
isbn = {9798400700958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579371.3589052},
doi = {10.1145/3579371.3589052},
abstract = {Progressively and increasingly, our society has become more and more dependent on semiconductors and semiconductor-enabled products and services. The importance of chips and their supply chains has been highlighted during the 2020-present chip shortage caused by manufacturing disruptions and increased demand due to the COVID-19 pandemic. However, semiconductor supply chains are inherently vulnerable to disruptions and chip crises can easily recur in the future.We present the first work that elevates supply chain conditions to be a first-class design constraint for future computer architectures. We characterize and model the chip creation process from standard tapeout to packaging to provide a framework for architects to quickly assess the time-to-market of their chips depending on their architecture and the current market conditions. In addition, we propose a novel metric, the Chip Agility Score (CAS) - a way to quantify a chip architecture's resilience against production-side supply changes.We utilize our proposed time-to-market model, CAS, and chip design/manufacturing economic models to evaluate prominent architectures in the context of current and speculative supply chain changes. We find that using an older process node to re-release chips can decrease time-to-market by 73\%-116\% compared to using the most advanced processes. Also, mixed-process chiplet architectures can be 24\%-51\% more agile compared to equivalent single-process chiplet and monolithic designs respectively. Guided by our framework, we present an architectural design methodology that minimizes time-to-market and chip creation costs while maximizing agility for mass-produced legacy node chips.Our modeling framework and data sets are open-sourced to advance supply chain aware computer architecture research. https://github.com/PrincetonUniversity/ttm-cas},
booktitle = {Proceedings of the 50th Annual International Symposium on Computer Architecture},
articleno = {17},
numpages = {15},
keywords = {chip shortage, semiconductor supply chain, economics, modeling},
location = {Orlando, FL, USA},
series = {ISCA '23}
}

@inproceedings{10.1109/DS-RT52167.2021.9576142,
author = {Victor, Carlos and Nguyen, Tuan Anh and Silva, Leonardo Augusto and Andrade, Ermeson and Santo, Guto Leoni and Min, Dugki and Lee, Jae Woo and Silva, Francisco Airton},
title = {Performability Assessment and Sensitivity Analysis of a Home Automation System},
year = {2022},
isbn = {9781665433266},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/DS-RT52167.2021.9576142},
doi = {10.1109/DS-RT52167.2021.9576142},
abstract = {Home automation or domotics is a typical representative of everything as a service (XaaS). Individual houses are equipped with Internet of Things (IoT) sensors and home facilities capable of self-assessment to offer comfortable, secure, and high-quality home services to their residents. However, assessing such systems with a high level of diversity is paramount of importance and challenging to assimilate. Domotics XaaS requires a high quality of service (QoS) in service performance and operational availability. In that regard, we propose, in this paper, a modeling approach based on stochastic Petri nets (SPN) for the performability quantification of domotics architectures. SPN performability models are developed following the architecture of a home automation system consisting of several IoT sensors/devices to evaluate the trade-offs between performance and availability of home automation services. The inter-dependency between performance and availability metrics is evaluated. The metrics include, for example, the mean response time (MRT) and the number of discarded packets. Sensitivity analysis using the design of experiments (DoE) is performed to identify the system's impacting components and performability bottleneck. Simulation results highlight the useful aspects of the proposed performability models for architectural and operational optimization of home automation XaaS infrastructures.},
booktitle = {Proceedings of the 2021 IEEE/ACM 25th International Symposium on Distributed Simulation and Real Time Applications},
articleno = {18},
numpages = {4},
keywords = {stochastic models, home automation, domotics},
location = {Valencia, Spain},
series = {DS-RT '21}
}

@inproceedings{10.1145/3484266.3487376,
author = {Qazi, Ihsan Ayyub and Qazi, Zafar Ayyub and Ali, Ayesha and Abdullah, Muhammad and Habib, Rumaisa},
title = {Rethinking Web for Affordability and Inclusion},
year = {2021},
isbn = {9781450390873},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3484266.3487376},
doi = {10.1145/3484266.3487376},
abstract = {Today's Web remains too expensive for many Internet users, especially in developing regions. Unfortunately, the rising complexity of the Web makes affordability an even bigger concern as it stands to limit users' access to Internet services. We propose a novel framework and fairness metric for rethinking Web architecture for affordability and inclusion. Our framework provides systematic guidelines for adapting Web complexity based on geographic variations in mobile broadband prices and income levels. Preliminary evaluation shows the resulting architecture can achieve a better balance between Web quality and affordability while preserving user privacy.},
booktitle = {Proceedings of the 20th ACM Workshop on Hot Topics in Networks},
pages = {9–15},
numpages = {7},
keywords = {Inclusion, Web, Affordability, User Privacy},
location = {<conf-loc>, <city>Virtual Event</city>, <country>United Kingdom</country>, </conf-loc>},
series = {HotNets '21}
}

@inproceedings{10.1145/3485983.3493356,
author = {Holzinger, Kilian and Stubbe, Henning and Biersack, Franz and Mari\~{n}o, Angela Gonzalez and Kane, Abdoul and Lluis, Francisco Fons and Haigang, Zhang and Wild, Thomas and Herkersdorf, Andreas and Carle, Georg},
title = {Precise Real-Time Monitoring of Time-Critical Flows},
year = {2021},
isbn = {9781450390989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485983.3493356},
doi = {10.1145/3485983.3493356},
abstract = {Ethernet is increasingly used in areas where time-critical and safety-relevant data are transported over the network along with best-effort flows, for example in intra vehicle networks or industrial networks. The resulting complex network architectures, time-sensitive networking configurations and system interactions are hard to foresee during the design phase. Therefore, it is hard to rule out any violations of flow specifications or timing and reliability requirements, especially in the presence of unpredictable failures.In this work, the design of a flow-oriented network monitoring system for time-sensitive applications is presented. It continuously supervises relevant performance metrics with high precision and short detection delay. Moreover, it allows to check compliance with flow specifications in real-time. Initial evaluations using intra vehicle network traffic yield a high measurement precision.},
booktitle = {Proceedings of the 17th International Conference on Emerging Networking EXperiments and Technologies},
pages = {489–490},
numpages = {2},
location = {Virtual Event, Germany},
series = {CoNEXT '21}
}

@inproceedings{10.1145/3578244.3583726,
author = {Straesser, Martin and Mathiasch, Jonas and Bauer, Andr\'{e} and Kounev, Samuel},
title = {A Systematic Approach for Benchmarking of Container Orchestration Frameworks},
year = {2023},
isbn = {9798400700682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578244.3583726},
doi = {10.1145/3578244.3583726},
abstract = {Container orchestration frameworks play a critical role in modern cloud computing paradigms such as cloud-native or serverless computing. They significantly impact the quality and cost of service deployment as they manage many performance-critical tasks such as container provisioning, scheduling, scaling, and networking. Consequently, a comprehensive performance assessment of container orchestration frameworks is essential. However, until now, there is no benchmarking approach that covers the many different tasks implemented in such platforms and supports evaluating different technology stacks. In this paper, we present a systematic approach that enables benchmarking of container orchestrators. Based on a definition of container orchestration, we define the core requirements and benchmarking scope for such platforms. Each requirement is then linked to metrics and measurement methods, and a benchmark architecture is proposed. With COFFEE, we introduce a benchmarking tool supporting the definition of complex test campaigns for container orchestration frameworks. We demonstrate the potential of our approach with case studies of the frameworks Kubernetes and Nomad in a self-hosted environment and on the Google Cloud Platform. The presented case studies focus on container startup times, crash recovery, rolling updates, and more.},
booktitle = {Proceedings of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {187–198},
numpages = {12},
keywords = {container orchestration, kubernetes, benchmarking, performance, nomad},
location = {Coimbra, Portugal},
series = {ICPE '23}
}

@inproceedings{10.1145/3546591.3547527,
author = {Shan, Yizhou and Lin, Will and Guo, Zhiyuan and Zhang, Yiying},
title = {Towards a Fully Disaggregated and Programmable Data Center},
year = {2022},
isbn = {9781450394413},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3546591.3547527},
doi = {10.1145/3546591.3547527},
abstract = {Today, we are seeing two trends in the data center. On the one hand, applications are becoming more fine-grained, driven by the recent trend of serverless computing and microservices. On the other hand, data-center hardware is becoming more heterogeneous and customized to different computing needs. Because of these trends and for better manageability, several major data centers are moving towards a disaggregated architecture, where different hardware resources like storage and accelerators are organized as independent, network-attached pools. However, data centers today are still server-centric and relies heavily on traditional CPU-based servers.In this paper, we take a step further and explore the possibility of building a fully disaggregated data center, where every type of resource is disaggregated. Moreover, we explore the requirements and implications of making each of the disaggregated device programmable. We present guidelines and initial solutions for data center designers to navigate design trade-offs. Specifically, we decompose the overarching problem into four sub-problems and propose solutions to each of them. At the top layer, we explore two types of abstractions and propose a disaggregation-native design methodology. At the bottom layer, we describe the hardware and key features required to build disaggregated devices as well as the networking infrastructure to connect them. To bridge these two layers, we propose a static-time component that compiles different user programs into heterogeneous disaggregated devices through a disaggregation-native intermediate representation. We also propose a run-time system that manages hardware resources and schedules compiler generated execution units. We hope our proposal can pave the way for future disaggregated and programmable data center deployment.},
booktitle = {Proceedings of the 13th ACM SIGOPS Asia-Pacific Workshop on Systems},
pages = {18–28},
numpages = {11},
keywords = {data-center network, resource disaggregation, data-center hardware architecture},
location = {Virtual Event, Singapore},
series = {APSys '22}
}

@inproceedings{10.1145/3616391.3622766,
author = {Makama, Aliyu and Kuladinithi, Koojana and Timm-Giel, Andreas},
title = {Evaluation of IEEE 802.11 Ad Hoc-Based Wireless Seismic Data Acquisition Networks},
year = {2023},
isbn = {9798400703683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616391.3622766},
doi = {10.1145/3616391.3622766},
abstract = {This paper investigates the performance of a proposed IEEE 802.11 ad hoc-based wireless seismic data acquisition (WSDA) network architecture. The study centers on examining the network performance in the 2.4 and 5 SI gigahertz bands with focus on addressing WSDA challenges such as scalability, reliability, self-configuration and organization, interference effects, and latency. Routing Protocol for Low-Power and Lossy Networks (RPL) is used as the enabling routing protocol employing the multiple Destination Oriented Directed Acyclic Graph (multi-DODAG) architecture. OMNeT++ discrete event simulator is used to evaluate the network performance, using metrics such as packet delivery ratio (PDR), end-to-end delay (E2ED), packet error rate (PER), retransmission ratio, packet dropped, etc. Results show that the proposed network architecture is scalable and reliable with large number of geophones in the network. In addition, Routing Protocol for Low-Power and Lossy Networks (RPL) proves to be a suitable candidate to enable self-configuration and organization in multi-hop ad hoc WSDA networks.},
booktitle = {Proceedings of the 19th ACM International Symposium on QoS and Security for Wireless and Mobile Networks},
pages = {25–32},
numpages = {8},
keywords = {wireless gateway (gw), geophones, wireless geophone network (wgn), routing protocol for low-power and lossy networks (rpl), central control unit (ccu), wireless seismic data acquisition (wsda), destination oriented directed acyclic graph (dodag).},
location = {<conf-loc>, <city>Montreal</city>, <state>Quebec</state>, <country>Canada</country>, </conf-loc>},
series = {Q2SWinet '23}
}

@inproceedings{10.1145/3508397.3564828,
author = {Chancusig, Cristian and Tumbaco, Sergio and Alulema, Darwin and Iribarne, Luis and Criado, Javier},
title = {Binary Classification Architecture for Edge Computing Based on Cognitive Services and Deep Neural Networks},
year = {2022},
isbn = {9781450392198},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3508397.3564828},
doi = {10.1145/3508397.3564828},
abstract = {Systems based on computer vision and artificial intelligence are an alternative for repetitive inspection processes. However, it is possible to extend the learning capacity of these systems to classify multiple objects using edge computing. This allows combining local processing with cloud processing to expand the possibilities and reduce the response time. In this work, a classification architecture based on remote web services and local neural networks is proposed. To test this architecture, Microsoft Azure cognitive web services and its Computer Vision API have been used, combined with the use of transfer learning and ResNet 50. The cloud service allows the identification and labelling of image content, while the Edge service, based on the neural network, allows the generation of classification models for those objects not identified or incorrectly identified by the remote service. The architecture allows to extend the possibility of image recognition by integrating web services that combined with edge processing accelerate the identification process. The proposed architecture is composed of three layers; (a) a physical layer, for the mechanical and electronic structure; (b) a logical layer, which defines the interaction of the remote and local image recognition web services, and (c) an application layer, for the integration of the monitoring and control interfaces. Finally, the architecture was evaluated through functionality testing and performance metrics of classification models, as well as load and usability testing.},
booktitle = {Proceedings of the 14th International Conference on Management of Digital EcoSystems},
pages = {148–155},
numpages = {8},
keywords = {edge computing, computer vision, cyber-physical systems, neural network, microservices},
location = {Venice, Italy},
series = {MEDES '22}
}

