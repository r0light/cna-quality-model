@inproceedings{10.1145/3349614.3356028,
author = {Tomei, Matthew and Schwing, Alexander and Narayanasamy, Satish and Kumar, Rakesh},
title = {Sensor Training Data Reduction for Autonomous Vehicles},
year = {2019},
isbn = {9781450369282},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3349614.3356028},
doi = {10.1145/3349614.3356028},
abstract = {Ensuring safety and reliability of autonomous vehicles requires good learning models which, in turn, require a large amount of real-world training data. Data produced by in-vehicle sensors (e.g., cameras, LIDARs, IMUs, etc.) can be used for training; however, both local storage and transmission of this sensor data to the cloud for subsequent use in training can be prohibitively expensive due to the staggering volume of data produced by these sensors, especially the cameras. In this paper, we perform the first exploration of techniques for reducing video frames in a way that the quality of training for autonomous vehicles is minimally affected. We particularly focus on utility aware data reduction schemes where the potential contribution of a video frame to enhancing the quality of learning (or utility) is explicitly considered during data reduction. Since actual utility of a video frame cannot be computed online, we use surrogate utility metrics to decide what video frames to keep for training and which ones to discard. Our results show that utility-aware data reduction schemes can reduce the amount of camera data required for training by as much as $16times$ compared to random sampling for the same quality of learning (in terms of IoU).},
booktitle = {Proceedings of the 2019 Workshop on Hot Topics in Video Analytics and Intelligent Edges},
pages = {45–50},
numpages = {6},
keywords = {autonomous vehicle, data reduction, active learning, semantic segmentation, compression, self driving car, sensor, machine learning},
location = {Los Cabos, Mexico},
series = {HotEdgeVideo'19}
}

@inproceedings{10.1145/3141128.3141132,
author = {Sastri, Yedhu and Feldhoff, Kim and Starru\ss{}, J\"{o}rn and J\"{a}kel, Ren\'{e} and M\"{u}ller-Pfefferkorn, Ralph},
title = {A Workflow for the Integral Performance Analysis of Cloud Applications Using Monitoring and Tracing Techniques},
year = {2017},
isbn = {9781450353434},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3141128.3141132},
doi = {10.1145/3141128.3141132},
abstract = {Considering the cost effectiveness, elasticity, and flexibility of virtualized cloud environments, porting HPC applications to those environments and executing them within these settings is becoming more and more popular. For this purpose, traditional HPC applications have to be redesigned as cloud applications. An analysis of the performance of the redesigned applications within the cloud environment is in-dispensable, if the applications should be efficiently executed in the cloud environment.This paper proposes a workflow for the integral performance analysis of cloud applications within a cloud environment using monitoring and tracing techniques. For this, collectd acts as a lightweight monitoring daemon for recording performance data from outside of the applications, Score-P as a profiling and tracing tool for recording the performance data from the inside. Thus, this workflow will help in answering the question "How and why an application behaves like this within the cloud environment?".In order to show the usability of the proposed workflow, a parallel client server application was selected and adapted for the execution in a private OpenStack cloud. Performance measurements of the example running in the cloud environment could be successfully done according to the proposed workflow. In particular, performance metrics from both the outside and the inside of the application could be obtained to analyze and evaluate the performance of the application in detail.},
booktitle = {Proceedings of the 2017 International Conference on Cloud and Big Data Computing},
pages = {73–78},
numpages = {6},
keywords = {Docker, Score-P, Container, Performance analysis, Micro services, Workflow, Tracing, Cloud application, Monitoring, collectd},
location = {London, United Kingdom},
series = {ICCBDC '17}
}

@inproceedings{10.1145/3468264.3473915,
author = {Kalia, Anup K. and Xiao, Jin and Krishna, Rahul and Sinha, Saurabh and Vukovic, Maja and Banerjee, Debasish},
title = {Mono2Micro: A Practical and Effective Tool for Decomposing Monolithic Java Applications to Microservices},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3473915},
doi = {10.1145/3468264.3473915},
abstract = {In migrating production workloads to cloud, enterprises often face the daunting task of evolving monolithic applications toward a microservice architecture. At IBM, we developed a tool called Mono2Micro to assist with this challenging task. Mono2Micro performs spatio-temporal decomposition, leveraging well-defined business use cases and runtime call relations to create functionally cohesive partitioning of application classes. Our preliminary evaluation of Mono2Micro showed promising results.  How well does Mono2Micro perform against other decomposition techniques, and how do practitioners perceive the tool? This paper describes the technical foundations of Mono2Micro and presents results to answer these two questions. To answer the first question, we evaluated Mono2Micro against four existing techniques on a set of open-source and proprietary Java applications and using different metrics to assess the quality of decomposition and tool’s efficiency. Our results show that Mono2Micro significantly outperforms state-of-the-art baselines in specific metrics well-defined for the problem domain. To answer the second question, we conducted a survey of twenty-one practitioners in various industry roles who have used Mono2Micro. This study highlights several benefits of the tool, interesting practitioner perceptions, and scope for further improvements. Overall, these results show that Mono2Micro can provide a valuable aid to practitioners in creating functionally cohesive and explainable microservice decompositions.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1214–1224},
numpages = {11},
keywords = {microservices, dynamic analysis, clustering},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@inproceedings{10.1145/3428502.3428618,
author = {Symeonidis, Panagiotis and Mitropoulos, Pantelis and Taskaris, Simeon and Vakkas, Theodoros and Adamopoulou, Eleni and Karakirios, Dimitrios and Salamalikis, Vasileios and Kosmopoulos, Georgios and Kazantzidis, Andreas},
title = {ThermiAir: An Innovative Air Quality Monitoring System for Airborne Particulate Matter in Thermi, Greece},
year = {2020},
isbn = {9781450376747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3428502.3428618},
doi = {10.1145/3428502.3428618},
abstract = {This paper presents the development of an innovative air quality monitoring platform for the Municipality of Thermi in Thessaloniki. The monitoring network consists of 25 low cost but very accurate IoT sensors measuring the concentration of Particulate Matter (PM 10, PM 2.5, PM 1.0). Using these new generation of sensors, it is feasible to monitor air quality at city block level, revealing the spatial pattern of air pollution, and thus allowing local and regional agencies to design and apply the most suitable policies and measures to tackle the air pollution problem. The real time measurements are stored in the Cloud and are disseminated to the citizens and the local authorities' stakeholders through a web and a mobile app. The web application provides an air quality dashboard which presents the overall air quality in the Municipality. Both the Air Quality Index (AQI) and raw concentration data are used. Various types of presentations are available including maps and charts. The web application provides also a three-day air quality forecast using the Copernicus forecast data. The mobile app provides easy access to the real time data in a simple to understand way, suitable for the public users.},
booktitle = {Proceedings of the 13th International Conference on Theory and Practice of Electronic Governance},
pages = {775–778},
numpages = {4},
keywords = {geographic information systems, data analytics, Air pollution, IoT sensors, Air quality},
location = {Athens, Greece},
series = {ICEGOV '20}
}

@article{10.1145/3047646,
author = {Chen, Qi and Liu, Ye and Liu, Guangchi and Yang, Qing and Shi, Xianming and Gao, Hongwei and Su, Lu and Li, Quanlong},
title = {Harvest Energy from the Water: A Self-Sustained Wireless Water Quality Sensing System},
year = {2017},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {1},
issn = {1539-9087},
url = {https://doi.org/10.1145/3047646},
doi = {10.1145/3047646},
abstract = {Water quality data is incredibly important and valuable, but its acquisition is not always trivial. A promising solution is to distribute a wireless sensor network in water to measure and collect the data; however, a drawback exists in that the batteries of the system must be replaced or recharged after being exhausted. To mitigate this issue, we designed a self-sustained water quality sensing system that is powered by renewable bioenergy generated from microbial fuel cells (MFCs). MFCs collect the energy released from native magnesium oxidizing microorganisms (MOMs) that are abundant in natural waters. The proposed energy-harvesting technology is environmentally friendly and can provide maintenance-free power to sensors for several years. Despite these benefits, an MFC can only provide microwatt-level power that is not sufficient to continuously power a sensor. To address this issue, we designed a power management module to accumulate energy when the input voltage is as low as 0.33V. We also proposed a radio-frequency (RF) activation technique to remotely activate sensors that otherwise are switched off in default. With this innovative technique, a sensor’s energy consumption in sleep mode can be completely avoided. Additionally, this design can enable on-demand data acquisitions from sensors. We implement the proposed system and evaluate its performance in a stream. In 3-month field experiments, we find the system is able to reliably collect water quality data and is robust to environment changes.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {sep},
articleno = {3},
numpages = {24},
keywords = {radio-frequency (RF) activation, Energy harvesting, water quality monitoring, microbial fuel cell, power management}
}

@inproceedings{10.1145/3388440.3414205,
author = {Vijayan, Vipin and Gu, Shawn and Krebs, Eric T. and Meng, Lei and Milenkovi\'{c}, Tijana},
title = {Pairwise Versus Multiple Global Network Alignment},
year = {2020},
isbn = {9781450379649},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3388440.3414205},
doi = {10.1145/3388440.3414205},
abstract = {This abstract is based on the following paper: Vijayan, Vipin, Shawn Gu, Eric T. Krebs, Lei Meng, and Tijana Milenkovi\'{c}. "Pairwise Versus Multiple Global Network Alignment." IEEE Access 8 (2020): 41961--41974.Proteins, the major macromolecules of life, interact with each other to carry out cellular functioning. Thus, analyses of protein-protein interaction (PPI) networks can yield important insights into biological function, disease, and evolution. While biotechnological advancements have made PPI network data available for many species, functions of many proteins in many of these species remain unknown. One way to uncover these functions is to transfer biological knowledge from a well-studied species to a poorly-studied one. Genomic sequence alignment, which has revolutionized our biomedical understanding, can be used for this purpose. However, sequence alignment has a major drawback: it does not consider interactions between proteins (which are ultimately what carry out function). So, biological network alignment (NA) can be used in a complementary fashion to predict protein functional knowledge that sequence alignment alone cannot predict. Specifically, NA compares PPI networks of different species to find regions of their similarity (or conservation), thus allowing for the transfer of functional knowledge across conserved network (rather than just sequence) regions.Like genomic sequence alignment, NA can be local or global. Just as the recent trend in the NA field, we also focus on global NA, which can be pairwise (PNA) and multiple (MNA). While PNA aligns two networks, MNA can align more than two networks at once. Since MNA can capture conserved network regions between more networks than PNA, it is hypothesized that MNA leads to deeper biological insights compared to PNA. However, due to different outputs of PNA and MNA, a PNA method is only compared to other PNA methods, and an MNA method is only compared to other MNA methods. Comparison of PNA against MNA must be done to evaluate whether MNA indeed yields more biologically meaningful alignments than PNA, as only this would justify MNA's higher computational complexity.We introduce a framework that allows for this. We evaluate eight prominent PNA and MNA methods, on synthetic and real-world biological networks, using topological and functional alignment quality measures. We compare PNA against MNA in both a pairwise (native to PNA) and multiple (native to MNA) manner. PNA is expected to lead to higher-quality alignments than MNA under the pairwise evaluation framework. Indeed, this is what we find. MNA is expected to lead to higher-quality alignments than PNA under the multiple evaluation framework. Shockingly, we find this not always to hold; PNA is often better than MNA in this framework, depending on the choice of evaluation test. Thus, we believe that any new MNA methods should be compared not just to existing MNA methods, but also to existing PNA methods using our evaluation framework, to properly judge the quality of alignments that they produce. Also, we confirm empirically that PNA is faster than MNA in both evaluation frameworks. These results indicate that currently, MNA offers little advantage over PNA; in order for MNA to gain an advantage, a drastic redesign of MNA's current algorithmic principles might be needed.},
booktitle = {Proceedings of the 11th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
articleno = {4},
numpages = {1},
keywords = {protein function prediction, biological network alignment, multi-network comparison},
location = {Virtual Event, USA},
series = {BCB '20}
}

@inproceedings{10.5555/2755535.2755555,
author = {K\"{a}m\"{a}r\"{a}inen, Teemu and Siekkinen, Matti and Xiao, Yu and Yl\"{a}-J\"{a}\"{a}ski, Antti},
title = {Towards Pervasive and Mobile Gaming with Distributed Cloud Infrastructure},
year = {2014},
publisher = {IEEE Press},
abstract = {Cloud gaming, where the game is rendered in the cloud and is streamed to an end-user device through a thin client, is rapidly gaining ground. Latency is still a key challenge to cloud gaming: highly interactive games can become unplayable even with response delays below 100 ms. To overcome this issue, we propose to deploy gaming services on a more distributed cloud infrastructure, and to instantiate gaming servers in close proximity of the user when necessary in order to shorten the response delay. Our prototype distributed cloud gaming platform also allows flexible configuration of gaming controls and video streams, enabling the use of public displays in mobile cloud gaming. We test our prototype with two games in different deployment scenarios, and measure the response delay and power consumption of the mobile devices. Our experiment results confirm that it is feasible to improve the quality of gaming experience through the deployment strategies provided by the proposed system.},
booktitle = {Proceedings of the 13th Annual Workshop on Network and Systems Support for Games},
articleno = {16},
numpages = {6},
location = {Nagoya, Japan},
series = {NetGames '14}
}

@inproceedings{10.1145/3349611.3355543,
author = {Loh, Frank and Vomhoff, Viktoria and Wamser, Florian and Metzger, Florian and Ho\ss{}feld, Tobias},
title = {Traffic Measurement Study on Video Streaming with the Amazon Echo Show},
year = {2019},
isbn = {9781450369275},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3349611.3355543},
doi = {10.1145/3349611.3355543},
abstract = {The Amazon Echo Show is one of the most widely used smart speakers with the ability to stream video. Due to its popularity, the traffic profiles of such devices are of interest to network operators and providers. This work presents a measurement study of the Amazon Echo Show in terms of network traffic and streaming behavior. More than 470,hours of streaming data are collected and analyzed at network layer. Based on this, streaming quality is derived at application layer. The study quantifies the traffic and shows that streaming with the Amazon Echo Show is comparable to streaming with a native web browser, but in a more conservative way.},
booktitle = {Proceedings of the 4th Internet-QoE Workshop on QoE-Based Analysis and Management of Data Communication Networks},
pages = {31–36},
numpages = {6},
keywords = {traffic analysis, qoe, amazon echo, alexa, streaming},
location = {Los Cabos, Mexico},
series = {Internet-QoE'19}
}

@article{10.1145/3391894,
author = {Wade, April W. and Kulkarni, Prasad A. and Jantz, Michael R.},
title = {Exploring Impact of Profile Data on Code Quality in the HotSpot JVM},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {6},
issn = {1539-9087},
url = {https://doi.org/10.1145/3391894},
doi = {10.1145/3391894},
abstract = {Managed language virtual machines (VM) rely on dynamic or just-in-time (JIT) compilation to generate optimized native code at run-time to deliver high execution performance. Many VMs and JIT compilers collect profile data at run-time to enable profile-guided optimizations (PGO) that customize the generated native code to different program inputs. PGOs are generally considered integral for VMs to produce high-quality and performant native code.In this work, we study and quantify the performance benefits of PGOs, understand the importance of profiling data quantity and quality/accuracy to effectively guide PGOs, and assess the impact of individual PGOs on VM performance. The insights obtained from this work can be used to understand the current state of PGOs, develop strategies to more efficiently balance the cost and exploit the potential of PGOs, and explore the implications of and challenges for the alternative ahead-of-time (AOT) compilation model used by VMs.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {oct},
articleno = {48},
numpages = {26},
keywords = {Program profiling, profile-guided optimizations}
}

@inproceedings{10.1145/3001913.3006645,
author = {Gibson, Marsalis T. and Rosa, Javier and Brewer, Eric A.},
title = {MDB: A Metadata Tracking Microcontroller Micro-Database},
year = {2016},
isbn = {9781450346498},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3001913.3006645},
doi = {10.1145/3001913.3006645},
abstract = {This work in progress explores a database designed to enable data sharing on custom hardware data collection devices and prototypes. Projects and systems are frequently based on the Arduino framework, examples include ODK's FoneAstra [3], the Open Energy Monitor [7], and the Grove system of sensors [5]. The Arduino platform is targeted because of its ease of use, community support, and low cost as a data collecting device compared to other off-the-shelf sensors. However, there is a need for a framework suitable for microcontrollers that enable ease of integration into other data collection systems. This includes the ability to synchronize data with collection and aggregation devices designed to work offline as well as the ability to track sensors and describe data sources for other machines and users. To address the issue, we propose a solution based on an existing small database usable on the Arduino platform that would integrate into the Mezuri [6] data collection system. The database is designed to fit within the running memory constraints on a microcontroller to store sensor data with relatively few fields per reading on flash media. This framework, with explicit support for metadata, enables users in emerging regions to directly measure physical quantities as well as indirectly measure human behavior in future development projects involving direct sensing. The database can be used by a non-expert. In particular, we investigate the qualities that a technically inclined social scientist would look for when storing such data on microcontrollers. To enable Mezuri integration we will support metadata as a first class object accessible with additional utility functions and native synchronization support.},
booktitle = {Proceedings of the 7th Annual Symposium on Computing for Development},
articleno = {36},
numpages = {4},
keywords = {Emerging Regions, Arduino, Metadata, Data Collection, Microcontroller, Embedded Databases, Sensors},
location = {Nairobi, Kenya},
series = {ACM DEV '16}
}

@inproceedings{10.1145/3018896.3025135,
author = {Saha, Debanshee and Shinde, Manasi and Thadeshwar, Shail},
title = {IoT Based Air Quality Monitoring System Using Wireless Sensors Deployed in Public Bus Services},
year = {2017},
isbn = {9781450347747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3018896.3025135},
doi = {10.1145/3018896.3025135},
abstract = {The ambient air quality monitoring network involves the measurement of a number of air pollutants at various locations in the city so as to maintain a sustainable air quality. It is the need of hour to monitor air quality in order to reduce air pollution. Exposure to air pollution can lead to respiratory and cardiovascular diseases, which is estimated to be the cause for 620,000 early deaths in 2010, and the impact on health due to air pollution in India has been calculated at 3 percent of its GDP. In recent years, air pollution has acquired critical dimensions and the air quality in most cities that monitor outdoor air pollution fail to meet WHO guidelines for safe levels. Air pollution is a major environmental change that causes many hazardous effects on human beings which need to be controlled. With the advancements in technology, several innovations have been made in the field of communications that are transitioning to the Internet of Things (IoT). In this domain, Wireless Sensor Networks (WSN) are one of those independent sensing devices to monitor physical and environmental conditions along with thousands of applications in other fields. In this paper, we are proposing the deployment of WSN sensor nodes in public transport buses for the constant monitoring of air pollution. The data regarding the air pollution particles such as emissions, smoke, and other pollutants will be collected via sensors on the public transport bus and the data will be aggregated and transmitted to the nearest sink node. Using the concept of the Internet of Things (IoT) the collected data will be uploaded on the cloud server also called as the IoT cloud where a large amount of the data is stored. This data can then be accessed at any point to analyze and accurate measures can be taken to map the air pollution.},
booktitle = {Proceedings of the Second International Conference on Internet of Things, Data and Cloud Computing},
articleno = {87},
numpages = {6},
keywords = {wireless sensor networks, internet of things (IoT), smart city, air pollution},
location = {Cambridge, United Kingdom},
series = {ICC '17}
}

@inproceedings{10.5555/3400397.3400622,
author = {Anagnostou, Anastasia and Taylor, Simon J. E. and Abubakar, Nura Tijjani and Kiss, Tamas and DesLauriers, James and Gesmier, Gregoire and Terstyanszky, Gabor and Kacsuk, Peter and Kovacs, Jozsef},
title = {Towards a Deadline-Based Simulation Experimentation Framework Using Micro-Services Auto-Scaling Approach},
year = {2020},
isbn = {9781728132839},
publisher = {IEEE Press},
abstract = {There is growing number of research efforts in developing auto-scaling algorithms and tools for cloud resources. Traditional performance metrics such as CPU, memory and bandwidth usage for scaling up or down resources are not sufficient for all applications. For example, modeling and simulation experimentation is usually expected to yield results within a specific timeframe. In order to achieve this often the quality of experiments is compromised either by restricting the parameter space to be explored or by limiting the number of replications required to give statistical confidence. In this paper, we present early stages of a deadline-based simulation experimentation framework using a micro-services auto-scaling approach. A case study of an agent-based simulation of a population physical activity behavior is used to demonstrate our framework.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {2749–2758},
numpages = {10},
location = {National Harbor, Maryland},
series = {WSC '19}
}

@inproceedings{10.1145/3472163.3472173,
author = {Zouari, Firas and Kabachi, Nadia and Boukadi, Khouloud and Ghedira Guegan, Chirine},
title = {Data Management in the Data Lake: A Systematic Mapping},
year = {2021},
isbn = {9781450389914},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472163.3472173},
doi = {10.1145/3472163.3472173},
abstract = {The computer science community is paying more and more attention to data due to its crucial role in performing analysis and prediction. Researchers have proposed many data containers such as files, databases, data warehouses, cloud systems, and recently data lakes in the last decade. The latter enables holding data in its native format, making it suitable for performing massive data prediction, particularly for real-time application development. Although data lake is well adopted in the computer science industry, its acceptance by the research community is still in its infancy stage. This paper sheds light on existing works for performing analysis and predictions on data placed in data lakes. Our study reveals the necessary data management steps, which need to be followed in a decision process, and the requirements to be respected, namely curation, quality evaluation, privacy-preservation, and prediction. This study aims to categorize and analyze proposals related to each step mentioned above.},
booktitle = {Proceedings of the 25th International Database Engineering \&amp; Applications Symposium},
pages = {280–284},
numpages = {5},
keywords = {Data management, Data lake, Systematic mapping},
location = {Montreal, QC, Canada},
series = {IDEAS '21}
}

@inproceedings{10.1109/CCGrid.2014.32,
author = {Balaji, Mahesh and Rao, G Subrahmanya Vrk and Kumar, Ch. Aswani},
title = {A Comparitive Study of Predictive Models for Cloud Infrastructure Management},
year = {2014},
isbn = {9781479927838},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGrid.2014.32},
doi = {10.1109/CCGrid.2014.32},
abstract = {Cloud service providers, monitor average resource (for e.g. CPU) consumption and based on predefined limits (for e.g. CPU-Idle-time &gt; 500 milliseconds), provision or de-provision resources. Traditionally this is a reactive approach and doesn't fully address the wide range of enterprise use cases. Implementation of predictive approach to resource management has been rarely reported even though they could perform potentially better than their counterpart. Identification of a suitable model for predicting the performance of the system under a load is an ideal precursor in managing resources on a cloud environment. The current study compares the performance of two such predictive models namely Holt-Winter and ARIMA using a public web server data set Request rate was used as the metric to monitor resource consumption. The experiment results show that Holt-Winter model performs better than a few selected ARIMA models, which could be subsequently used for managing resources on cloud if the data request rates follow a similar pattern},
booktitle = {Proceedings of the 14th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
pages = {923–926},
numpages = {4},
keywords = {holt-winter, resource management, cloud computing, ARIMA, predictive modeling},
location = {Chicago, Illinois},
series = {CCGRID '14}
}

@inproceedings{10.1145/2578260.2578273,
author = {Wang, Cong and Zink, Michael},
title = {On the Feasibility of DASH Streaming in the Cloud},
year = {2018},
isbn = {9781450327060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2578260.2578273},
doi = {10.1145/2578260.2578273},
abstract = {As shown in recent studies, video streaming is by far the biggest category of backbone Internet traffic in the US. As a measure to reduce the cost of highly over-provisioned physical infrastructures while remaining the quality of video services, many streaming service providers started to use cloud services where physical resources can be dynamically allocated based on current demand. This paper characterizes the performance of Dynamic Adaptive Streaming over HTTP (DASH), a new MPEG standard on adaptive streaming, in the cloud. We seek to answer the following questions that are critical to content providers that are hosting video in clouds: Which data center is the best to host videos? Does geographical distance matter? What type of instance is best suitable depending on different needs? How to efficiently solve the trade-off between performance and cost? The measurement methods and results presented in this paper can be easily expanded into other VoD services, and they allow us to i) characterize DASH behavior when streaming from the cloud; ii) identify the key factors that influence the DASH performance; and iii) suggest improvements for related services.},
booktitle = {Proceedings of Network and Operating System Support on Digital Audio and Video Workshop},
pages = {49–54},
numpages = {6},
keywords = {HTTP adaptive streaming, Cloud computing, video-on-demand, quality of experience},
location = {Singapore, Singapore},
series = {NOSSDAV '14}
}

@inproceedings{10.1145/2597176.2578273,
author = {Wang, Cong and Zink, Michael},
title = {On the Feasibility of DASH Streaming in the Cloud},
year = {2014},
isbn = {9781450327060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2597176.2578273},
doi = {10.1145/2597176.2578273},
abstract = {As shown in recent studies, video streaming is by far the biggest category of backbone Internet traffic in the US. As a measure to reduce the cost of highly over-provisioned physical infrastructures while remaining the quality of video services, many streaming service providers started to use cloud services where physical resources can be dynamically allocated based on current demand. This paper characterizes the performance of Dynamic Adaptive Streaming over HTTP (DASH), a new MPEG standard on adaptive streaming, in the cloud. We seek to answer the following questions that are critical to content providers that are hosting video in clouds: Which data center is the best to host videos? Does geographical distance matter? What type of instance is best suitable depending on different needs? How to efficiently solve the trade-off between performance and cost? The measurement methods and results presented in this paper can be easily expanded into other VoD services, and they allow us to i) characterize DASH behavior when streaming from the cloud; ii) identify the key factors that influence the DASH performance; and iii) suggest improvements for related services.},
booktitle = {Proceedings of Network and Operating System Support on Digital Audio and Video Workshop},
pages = {49–54},
numpages = {6},
keywords = {HTTP adaptive streaming, quality of experience, video-on-demand, Cloud computing},
location = {Singapore, Singapore},
series = {NOSSDAV '14}
}

@inproceedings{10.1145/2950290.2994157,
author = {Rossi, Chuck and Shibley, Elisa and Su, Shi and Beck, Kent and Savor, Tony and Stumm, Michael},
title = {Continuous Deployment of Mobile Software at Facebook (Showcase)},
year = {2016},
isbn = {9781450342186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2950290.2994157},
doi = {10.1145/2950290.2994157},
abstract = {Continuous deployment is the practice of releasing software updates to production as soon as it is ready, which is receiving increased adoption in industry. The frequency of updates of mobile software has traditionally lagged the state of practice for cloud-based services for a number of reasons. Mobile versions can only be released periodically. Users can choose when and if to upgrade, which means that several different releases coexist in production. There are hundreds of Android hardware variants, which increases the risk of having errors in the software being deployed.  Facebook has made significant progress in increasing the frequency of its mobile deployments. Over a period of 4 years, the Android release has gone from a deployment every 8 weeks to a deployment every week. In this paper, we describe in detail the mobile deployment process at FB. We present our findings from an extensive analysis of software engineering metrics based on data collected over a period of 7 years. A key finding is that the frequency of deployment does not directly affect developer productivity or software quality. We argue that this finding is due to the fact that increasing the frequency of continuous deployment forces improved release and deployment automation, which in turn reduces developer workload. Additionally, the data we present shows that dog-fooding and obtaining feedback from alpha and beta customers is critical to maintaining release quality.},
booktitle = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {12–23},
numpages = {12},
keywords = {Agile development, Mobile code testing, Continuous delivery, Software release, Continuous deployment},
location = {Seattle, WA, USA},
series = {FSE 2016}
}

@inproceedings{10.1145/3341105.3373915,
author = {Santos, Guilherme and Paulino, Herv\'{e} and Vardasca, Tom\'{e}},
title = {QoE-Aware Auto-Scaling of Heterogeneous Containerized Services (and Its Application to Health Services)},
year = {2020},
isbn = {9781450368667},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341105.3373915},
doi = {10.1145/3341105.3373915},
abstract = {Containerized service is currently a widely adopted solution to deploy services in the cloud. However, many companies offer a very diverse set of Web accessible services that are subjected to very distinctive workloads. Consequently, to correctly provision the right amount of resources for each of these services is a challenge. In this paper we propose the Autonomic ConTainerized Service Scaler (ACTS), an autonomic system able to horizontally and vertically scale a set of heterogeneous containerized services subjected to different workloads. The adaptation decisions depended on a set of high-level Quality of Experience (QoE) metrics centered on the services' end-user. We have applied ACTS to some of the digital services of the Shared Services of the Ministry of Health (SPMS) public company. The experimental results show that our solution is able to adequately adapt the configuration of each service, as a direct response to alterations on its workload.},
booktitle = {Proceedings of the 35th Annual ACM Symposium on Applied Computing},
pages = {242–249},
numpages = {8},
keywords = {auto-scaling, health care, containers, quality of experience},
location = {Brno, Czech Republic},
series = {SAC '20}
}

@inproceedings{10.1145/2940136.2940143,
author = {Wamser, Florian and Seufert, Michael and H\"{o}fner, Steffen and Tran-Gia, Phuoc},
title = {Concept for Client-Initiated Selection of Cloud Instances for Improving QoE of Distributed Cloud Services},
year = {2016},
isbn = {9781450344258},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2940136.2940143},
doi = {10.1145/2940136.2940143},
abstract = {We introduce a concept for client-initiated selection of service location and service quality for improving the Quality of Experience (QoE) of general cloud services. It is loosely based on the HTTP adaptive streaming approach (e.g., MPEG DASH). A manifest file compiled by the cloud service provider specifies the available service locations and qualities, from which the user selects the optimal service instance based on contextual information obtained from client measurements and user preferences. The proposed concept is defined and is implemented in two client-based decision algorithms for improving the QoE of a simple picture gallery cloud service. These decision algorithms are evaluated and their impact on the service delivery is discussed. The evaluation shows that it is possible to improve the service location and quality selection by light-weight client-based algorithms.},
booktitle = {Proceedings of the 2016 Workshop on QoE-Based Analysis and Management of Data Communication Networks},
pages = {49–54},
numpages = {6},
keywords = {Cloud Services, Quality of Experience, Client-based Access for Cloud Services},
location = {Florianopolis, Brazil},
series = {Internet-QoE '16}
}

@inproceedings{10.1145/3127479.3131614,
author = {Yadwadkar, Neeraja J. and Hariharan, Bharath and Gonzalez, Joseph E. and Smith, Burton and Katz, Randy H.},
title = {Selecting the Best VM across Multiple Public Clouds: A Data-Driven Performance Modeling Approach},
year = {2017},
isbn = {9781450350280},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3127479.3131614},
doi = {10.1145/3127479.3131614},
abstract = {Users of cloud services are presented with a bewildering choice of VM types and the choice of VM can have significant implications on performance and cost. In this paper we address the fundamental problem of accurately and economically choosing the best VM for a given workload and user goals. To address the problem of optimal VM selection, we present PARIS, a data-driven system that uses a novel hybrid offline and online data collection and modeling framework to provide accurate performance estimates with minimal data collection. PARIS is able to predict workload performance for different user-specified metrics, and resulting costs for a wide range of VM types and workloads across multiple cloud providers. When compared to sophisticated baselines, including collaborative filtering and a linear interpolation model using measured workload performance on two VM types, PARIS produces significantly better estimates of performance. For instance, it reduces runtime prediction error by a factor of 4 for some workloads on both AWS and Azure. The increased accuracy translates into a 45\% reduction in user cost while maintaining performance.},
booktitle = {Proceedings of the 2017 Symposium on Cloud Computing},
pages = {452–465},
numpages = {14},
keywords = {cloud computing, data-driven modeling, resource allocation, performance prediction},
location = {Santa Clara, California},
series = {SoCC '17}
}

@inproceedings{10.1145/3458305.3463384,
author = {Sethuraman, Manasvini and Sarma, Anirudh and Dhekne, Ashutosh and Ramachandran, Umakishore},
title = {Foresight: Planning for Spatial and Temporal Variations in Bandwidth for Streaming Services on Mobile Devices},
year = {2021},
isbn = {9781450384346},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458305.3463384},
doi = {10.1145/3458305.3463384},
abstract = {Spatiotemporal variation in cellular bandwidth availability is well-known and could affect a mobile user's quality of experience (QoE), especially while using bandwidth intensive streaming applications such as movies, podcasts, and music videos during commute. If such variations are made available to a streaming service in advance it could perhaps plan better to avoid sub-optimal performance while the user travels through regions of low bandwidth availability. The intuition is that such future knowledge could be used to buffer additional content in regions of higher bandwidth availability to tide over the deficits in regions of low bandwidth availability. Foresight is a service designed to provide this future knowledge for client apps running on a mobile device. It comprises three components: (a) a crowd-sourced bandwidth estimate reporting facility, (b) an on-cloud bandwidth service that records the spatiotemporal variations in bandwidth and serves queries for bandwidth availability from mobile users, and (c) an on-device bandwidth manager that caters to the bandwidth requirements from client apps by providing them with bandwidth allocation schedules. Foresight is implemented in the Android framework. As a proof of concept for using this service, we have modified an open-source video player---Exoplayer---to use the results of Foresight in its video buffer management. Our performance evaluation shows Foresight's scalability. We also showcase the opportunity that Foresight offers to ExoPlayer to enhance video quality of experience (QoE) despite spatiotemporal bandwidth variations for metrics such as overall higher bitrate of playback, reduction in number of bitrate switches, and reduction in the number of stalls during video playback.},
booktitle = {Proceedings of the 12th ACM Multimedia Systems Conference},
pages = {227–240},
numpages = {14},
keywords = {spatiotemporal bandwidth information, bandwidth management},
location = {Istanbul, Turkey},
series = {MMSys '21}
}

@inproceedings{10.1145/2835075.2835078,
author = {Adegboyega, Abiola},
title = {An Adaptive Resource Provisioning Scheme for Effective QoS Maintenance in the IaaS Cloud},
year = {2015},
isbn = {9781450337328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2835075.2835078},
doi = {10.1145/2835075.2835078},
abstract = {Effective bandwidth provisioning is of vital importance in the virtualized cloud where tenants with unique SLAs share a finite network. Different tenants collocated on the same physical server deployed with increasing VM density necessitates Quality of Service (QoS) provisioning beginning at the hypervisor. Recent efforts at provisioning the cloud network through various reservation methodologies have achieved some measure of success. However most of them do not account for the entire path over which application components communicate and cannot provide the necessary Service Level Agreement (SLA). Cloud applications components often communicate across multiple network devices aggregated into layers connected over finite bandwidth links that affect application response. Furthermore, traffic to and from tenant applications display volatility. In view of this, we design a virtual network reservation framework that is mindful of application performance across multiple network devices \&amp; traffic volatility. Our network reservation framework is based on a forecasting engine motivated by the volatility existent in traffic to and from virtualized cloud environments. This forecasting engine is able to maintain SLAs by employing dynamic time-series models to develop novel bandwidth provisioning thresholds that adapt to the time-variation in tenant workloads. We test the effectiveness of our methods in the OpenStack cloud environment focusing on traffic directionality in the datacenter network, VM density and QoS across multiple flows competing for finite bandwidth. Our forecasting method offers a 25\% improvement in prediction accuracy over existing methods while the reservation framework maintains SLAs at 95\%.},
booktitle = {Proceedings of the International Workshop on Virtualization Technologies},
articleno = {2},
numpages = {6},
keywords = {Volatility, SDN, Forecasting, Virtualization, QoS},
location = {Vancouver, BC, Canada},
series = {VT15}
}

@inproceedings{10.1145/3185768.3186297,
author = {Versluis, Laurens and van Eyk, Erwin and Iosup, Alexandru},
title = {An Analysis of Workflow Formalisms for Workflows with Complex Non-Functional Requirements},
year = {2018},
isbn = {9781450356299},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3185768.3186297},
doi = {10.1145/3185768.3186297},
abstract = {Cloud and datacenter operators offer progressively more sophisticated service level agreements to customers. The Quality-of-Service guarantees by these operators have started to entail non-functional requirements customers have regarding their applications. At the same time, expressing applications as workflows in datacenters is increasingly more common. Currently, non-functional requirements (NFRs) can only be defined on entire workflows and cannot be changed at runtime, possibly wasting valuable resources. To move towards modifiable NFRs at the task level, there is a need for a formalism capable of expressing this. Existing formalisms do not support this level of granularity or are restricted to a subset of NFRs. In this work, we investigate the current support for NFRs in existing formalisms. Using a library containing workflows with and without NFRs, we inspect the capability of existing formalisms to express these requirements. Additionally, we create and evaluate five metrics to qualitatively and quantitatively compare each formalism. Our main findings are that although current formalisms do not support arbitrary NFRs per-task, the Directed Acyclic Graphs (DAGs) formalism is the most suitable to extend.},
booktitle = {Companion of the 2018 ACM/SPEC International Conference on Performance Engineering},
pages = {107–112},
numpages = {6},
keywords = {formalism, datacenter, non-functional requirement, workflow, cloud},
location = {Berlin, Germany},
series = {ICPE '18}
}

@inproceedings{10.1109/SEAMS.2017.2,
author = {Moreno, Gabriel A. and Papadopoulos, Alessandro V. and Angelopoulos, Konstantinos and C\'{a}mara, Javier and Schmerl, Bradley},
title = {Comparing Model-Based Predictive Approaches to Self-Adaptation: CobRA and PLA},
year = {2017},
isbn = {9781538615508},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SEAMS.2017.2},
doi = {10.1109/SEAMS.2017.2},
abstract = {Modern software-intensive systems must often guarantee certain quality requirements under changing run-time conditions and high levels of uncertainty. Self-adaptation has proven to be an effective way to engineer systems that can address such challenges, but many of these approaches are purely reactive and adapt only after a failure has taken place. To overcome some of the limitations of reactive approaches (e.g., lagging behind environment changes and favoring short-term improvements), recent proactive self-adaptation mechanisms apply ideas from control theory, such as model predictive control (MPC), to improve adaptation. When selecting which MPC approach to apply, the improvement that can be obtained with each approach is scenario-dependent, and so guidance is needed to better understand how to choose an approach for a given situation. In this paper, we compare CobRA and PLA, two approaches that are inspired by MPC. CobRA is a requirements-based approach that applies control theory, whereas PLA is architecture-based and applies stochastic analysis. We compare the two approaches applied to RUBiS, a benchmark system for web and cloud application performance, discussing the required expertise needed to use both approaches and comparing their run-time performance with respect to different metrics.},
booktitle = {Proceedings of the 12th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {42–53},
numpages = {12},
keywords = {CobRA, latency, self-adaptation, adaptive system, model predictive control, PLA},
location = {Buenos Aires, Argentina},
series = {SEAMS '17}
}

@inproceedings{10.1145/2930238.2930249,
author = {Musto, Cataldo and Lops, Pasquale and Basile, Pierpaolo and de Gemmis, Marco and Semeraro, Giovanni},
title = {Semantics-Aware Graph-Based Recommender Systems Exploiting Linked Open Data},
year = {2016},
isbn = {9781450343688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2930238.2930249},
doi = {10.1145/2930238.2930249},
abstract = {The ever increasing interest in semantic technologies and the availability of several open knowledge sources have fueled recent progress in the field of recommender systems. In this paper we feed recommender systems with features coming from the Linked Open Data (LOD) cloud - a huge amount of machine-readable knowledge encoded as RDF statements - with the aim of improving recommender systems effectiveness. In order to exploit the natural graph-based structure of RDF data, we study the impact of the knowledge coming from the LOD cloud on the overall performance of a graph-based recommendation algorithm. In more detail, we investigate whether the integration of LOD-based features improves the effectiveness of the algorithm and to what extent the choice of different feature selection techniques influences its performance in terms of accuracy and diversity. The experimental evaluation on two state of the art datasets shows a clear correlation between the feature selection technique and the ability of the algorithm to maximize a specific evaluation metric. Moreover, the graph-based algorithm leveraging LOD-based features is able to overcome several state of the art baselines, such as collaborative filtering and matrix factorization, thus confirming the effectiveness of the proposed approach.},
booktitle = {Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization},
pages = {229–237},
numpages = {9},
keywords = {graphs, graph-based recommender systems, feature selection, diversity, linked open data, pagerank},
location = {Halifax, Nova Scotia, Canada},
series = {UMAP '16}
}

@inproceedings{10.1145/3070607.3070608,
author = {Hutchison, Dylan and Howe, Bill and Suciu, Dan},
title = {LaraDB: A Minimalist Kernel for Linear and Relational Algebra Computation},
year = {2017},
isbn = {9781450350198},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3070607.3070608},
doi = {10.1145/3070607.3070608},
abstract = {Analytics tasks manipulate structured data with variants of relational algebra (RA) and quantitative data with variants of linear algebra (LA). The two computational models have overlapping expressiveness, motivating a common programming model that affords unified reasoning and algorithm design. At the logical level we propose LARA, a lean algebra of three operators, that expresses RA and LA as well as relevant optimization rules. We show a series of proofs that position LARA at just the right level of expressiveness for a middleware algebra: more explicit than MapReduce but more general than RA or LA. At the physical level we find that the LARA operators afford efficient implementations using a single primitive that is available in a variety of backend engines: range scans over partitioned sorted maps.To evaluate these ideas, we implemented the LARA operators as range iterators in Apache Accumulo, a popular implementation of Google's BigTable. First we show how LARA expresses a sensor quality control task, and we measure the performance impact of optimizations LARA admits on this task. Second we show that the LARADB implementation outperforms Accumulo's native MapReduce integration on a core task involving join and aggregation in the form of matrix multiply, especially at smaller scales that are typically a poor fit for scale-out approaches. We find that LARADB offers a conceptually lean framework for optimizing mixed-abstraction analytics tasks, without giving up fast record-level updates and scans.},
booktitle = {Proceedings of the 4th ACM SIGMOD Workshop on Algorithms and Systems for MapReduce and Beyond},
articleno = {2},
numpages = {10},
location = {Chicago, IL, USA},
series = {BeyondMR'17}
}

@inproceedings{10.1145/3417113.3422184,
author = {Malavolta, Ivano and Grua, Eoin Martino and Lam, Cheng-Yu and de Vries, Randy and Tan, Franky and Zielinski, Eric and Peters, Michael and Kaandorp, Luuk},
title = {A Framework for the Automatic Execution of Measurement-Based Experiments on Android Devices},
year = {2021},
isbn = {9781450381284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417113.3422184},
doi = {10.1145/3417113.3422184},
abstract = {Conducting measurement-based experiments is fundamental for assessing the quality of Android apps in terms of, e.g., energy consumption, CPU, and memory usage. However, orchestrating such experiments is not trivial as it requires large boilerplate code, careful setup of measurement tools, and the adoption of various empirical best practices scattered across the literature. All together, those factors are slowing down the scientific advancement and harming experiments' replicability in the mobile software engineering area.In this paper we present Android Runner (AR), a framework for automatically executing measurement-based experiments on native and web apps running on Android devices. In AR, an experiment is defined once in a descriptive fashion, and then its execution is fully automatic, customizable, and replicable. AR is implemented in Python and it can be extended with third-party profilers.AR has been used in more than 25 scientific studies primarily targeting performance and energy efficiency.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {61–66},
numpages = {6},
location = {Virtual Event, Australia},
series = {ASE '20}
}

@article{10.1145/3408293,
author = {He, Xin and Liu, Qiong and Yang, You},
title = {Make Full Use of Priors: Cross-View Optimized Filter for Multi-View Depth Enhancement},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {4},
issn = {1551-6857},
url = {https://doi.org/10.1145/3408293},
doi = {10.1145/3408293},
abstract = {Multi-view video plus depth (MVD) is the promising and widely adopted data representation for future 3D visual applications and interactive media. However, compression distortions on depth videos impede the development of such applications, and filters are crucially needed for the quality enhancement at the terminal side. Cross-view priors can intuitively be involved in filter design, but these priors are also distorted in compression and thus the contribution of them can hardly be considered in previous research. In this article, we propose a cross-view optimized filter for depth map quality enhancement by making full use of inner- and cross-view priors. We dedicate to evaluate the contributions of distorted cross-view priors in filtering the current view of depth, and then both inner- and cross-view priors can be involved in the filter design. Thus, distortions of cross-view priors are not barriers again as before. For the purpose of that, mutual information guided cross-view consistency is designed to evaluate the contributions of cross-view priors from compression distortions of MVD. After that, under the framework of global optimization, both inner- and cross-view priors are modeled and taken to minimize the designed energy function where both data accuracy and spatial smoothness are modeled. The experimental results show that the proposed model outperforms state-of-the-art methods, where 3.289 dB and 0.0407 average gains on peak signal-to-noise ratio and structural similarity metrics can be obtained, respectively. For the subjective evaluations, object details and structure information are recovered in the compressed depth video. We also verify our method via several practical applications, including virtual view synthesis for smooth interaction and point cloud for 3D modeling for accuracy evaluation. In these verifications, the ringing and malposition artifacts on object contours are properly handled for interactive video, and discontinuous object surfaces are restored for 3D modeling. All of these results suggest that compression distortions in MVD can be properly filtered by the proposed model, which provides a promising solution for future bandwidth constrained 3D and interactive visual applications.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = {dec},
articleno = {127},
numpages = {19},
keywords = {global optimization, view consistency, Multi-view video plus depth}
}

@inproceedings{10.1145/3458306.3458873,
author = {Huang, Tianchi and Zhang, Rui-Xiao and Sun, Lifeng},
title = {Deep Reinforced Bitrate Ladders for Adaptive Video Streaming},
year = {2021},
isbn = {9781450384353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458306.3458873},
doi = {10.1145/3458306.3458873},
abstract = {In the typical transcoding pipeline for adaptive video streaming, raw videos are pre-chunked and pre-encoded according to a set of resolution-bitrate or resolution-quality pairs on the server-side, where the pair is often named as bitrate ladder. Different from existing heuristics, we argue that a good bitrate ladder should be optimized by considering video content features, network capacity, and storage costs on the cloud. We propose DeepLadder, a per-chunk optimization scheme which adopts state-of-the-art deep reinforcement learning (DRL) method to optimize the bitrate ladder w.r.t the above concerns. Technically, DeepLadder selects the proper setting for each video resolution autoregressively. We use over 8,000 video chunks, measure over 1,000,000 perceptual video qualities, collect real-world network traces for more than 50 hours, and invent faithful virtual environments to help train DeepLadder efficiently. Across a series of comprehensive experiments on both Constant Bitrate (CBR) and Variable Bitrate (VBR)-encoded videos, we demonstrate significant improvements in average video quality bandwidth utilization, and storage overhead in comparison to prior work as well as the ability to be deployed in the real-world transcoding framework.},
booktitle = {Proceedings of the 31st ACM Workshop on Network and Operating Systems Support for Digital Audio and Video},
pages = {66–73},
numpages = {8},
keywords = {bitrate ladder, adaptive video streaming},
location = {Istanbul, Turkey},
series = {NOSSDAV '21}
}

@inproceedings{10.1145/3277453.3277484,
author = {Shanthasheela, A. and Shanmugavadivu, P.},
title = {An Exploratory Analysis of Speckle Noise Removal Methods for Satellite Images},
year = {2018},
isbn = {9781450365413},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3277453.3277484},
doi = {10.1145/3277453.3277484},
abstract = {Satellite images captured in a variety of modalities serve as the primary source for many applications. Satellite image processing extracts the image /spectral information represented in the form of pixels, classifies those pixels based on the similarity measures and further analyzes the inherent data, as per the requirements. The foremost objective of satellite processing is to automatically categorize the pixels in an image into the respective land cover class labels or themes. These pixels are classified by its spectral information and it is determined by the relative reflectance in various bands of wavelength. The accuracy and outcomes of any satellite image processing procedure, irrespective of the application domain, directly depends on its quality. Satellite images are invariably degraded by speckle noise. Hence, preprocessing the images for speckle noise suppression and/or cloud removal is deemed an inevitable component in satellite image processing. Researchers have proposed a spectrum of methods for speckle noise/cloud removal. A detailed review on the significant research publications on speckle noise removal are summarized in this article. The consolidation of methodology merits and demerits of the select research articles are presented in this paper. This review article on speckle noise removal is designed as a ready-reference for those researchers working in satellite image processing.},
booktitle = {Proceedings of the 2018 International Conference on Electronics and Electrical Engineering Technology},
pages = {217–222},
numpages = {6},
keywords = {Literature Survey, Noise filters, RADAR, Speckle Noise, Review, SAR, Satellite images},
location = {Tianjin, China},
series = {EEET '18}
}

@inproceedings{10.1145/3349611.3355546,
author = {Schwind, Anika and Haberzettl, Lorenz and Wamser, Florian and Ho\ss{}feld, Tobias},
title = {QoE Analysis of Spotify Audio Streaming and App Browsing},
year = {2019},
isbn = {9781450369275},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3349611.3355546},
doi = {10.1145/3349611.3355546},
abstract = {Spotify is the most-listened audio streaming provider in 2019 with 217 million active users per month. Providers are therefore interested in the quality and functionality of Spotify in order to provide their users with the best possible streaming quality. While video streaming services such as Netflix and their streaming approach have been extensively explored in previous research, audio streaming services like Spotify and their corresponding behavior at certain network conditions have not been considered in detail yet. In this paper, we perform a QoE analysis under various network conditions and examine the app browsing performance of the audio streaming platform Spotify using its native Android mobile application. We have developed a measurement tool that emulates a user listening to audio through Spotify. While streaming, application and network layer parameters are captured that have a high correlation to the user's QoE. The paper shows a baseline scenario including the streaming of a single song as well as playlist streaming behavior. Next, the effect of interruptions on the streaming behavior is evaluated and finally, the influence of network impairments on QoE key performance indicators such as initial delay is shown.},
booktitle = {Proceedings of the 4th Internet-QoE Workshop on QoE-Based Analysis and Management of Data Communication Networks},
pages = {25–30},
numpages = {6},
keywords = {qoe, spotify, audio streaming, mobile application, browsing},
location = {Los Cabos, Mexico},
series = {Internet-QoE'19}
}

@article{10.1145/3106158,
author = {Willnecker, Felix and Krcmar, Helmut},
title = {Multi-Objective Optimization of Deployment Topologies for Distributed Applications},
year = {2018},
issue_date = {May 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3106158},
doi = {10.1145/3106158},
abstract = {Modern applications are typically implemented as distributed systems comprising several components. Deciding where to deploy which component is a difficult task that today is usually assisted by logical topology recommendations. Choosing inefficient topologies allocates the wrong amount of resources, leads to unnecessary operation costs, or results in poor performance. Testing different topologies to find good solutions takes a lot of time and might delay productive operations. Therefore, this work introduces a software-based deployment topology optimization approach for distributed applications. We use an enhanced performance model generator that extracts models from operational monitoring data of running applications. The extracted model is used to simulate performance metrics (e.g., resource utilization, response times, throughput) and runtime costs of distributed applications. Subsequently, we introduce a deployment topology optimizer, which selects an optimized topology for a specified workload and considers on-premise, cloud, and hybrid topologies. The following three optimization goals are presented in this work: (i) minimum response time for an optimized user experience, (ii) approximate resource utilization around certain peaks, and (iii) minimum cost for running the application. To evaluate the approach, we use the SPECjEnterpriseNEXT industry benchmark as distributed application in an on-premise and in a cloud/on-premise hybrid environment. The evaluation demonstrates the accuracy of the simulation compared to the actual deployment by deploying an optimized topology and comparing measurements with simulation results.},
journal = {ACM Trans. Internet Technol.},
month = {jan},
articleno = {21},
numpages = {21},
keywords = {performance model, performance model generation, Deployment topology optimzation, distributed enterprise applications, memory simulation}
}

@inproceedings{10.1145/3318396.3318427,
author = {Ho, P. C. W. and Fok, W. W. T. and Chan, C. K. K. and Yeung, H. H. Au and Ng, H. W. and Wong, S. L. and Ngai, S. Y. and Kwok, P. H. and Ho, Y. S. and Chan, K. H.},
title = {Flipping the Learning and Teaching of Reading Strategies and Comprehension through a Cloud-Based Interactive Big Data Reading Platform},
year = {2019},
isbn = {9781450362672},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318396.3318427},
doi = {10.1145/3318396.3318427},
abstract = {This study investigates the learning approach of the designed Flipped Reading Platform (FRP) and its effects on primary school students' general Chinese reading and comprehension capabilities. This study was undertaken as part of the Quality Education Fund project in Hong Kong, titled "Flipped Reading: Enhancing the Learning and Teaching of Reading Strategies and Comprehension in Chinese via an Interactive Cloud Platform."This paper presents the design of the Interactive Cloud Platform FRP, which incorporates elements of both reading strategies and learning activities, and investigates the changes in students' reading performance, applied strategies, and active learning level with the application of FRP. The results show the experimental students using the FRP in the pilot scheme generally gained more in three stages of reading comprehension, and that low-achieving students learned reading strategies better. Analysis of FRP log activities shows students' active engagement in reading and perceived competence. Different learning outcomes were also found within the experimental group, categorized by BYOD and non-BYOD classes. Implications of the study show the effectiveness of FRP, and the design demonstrates how the reading measures integrated the assessment indicators of both international and local standards in the domain of Chinese Language reading. Further research can be developed to examine individual online reading performance and learning behaviour on FRP.},
booktitle = {Proceedings of the 2019 8th International Conference on Educational and Information Technology},
pages = {185–191},
numpages = {7},
keywords = {reading strategy, Cloud Platform, e-Learning, Chinese Language, Flipped reading, Big data},
location = {Cambridge, United Kingdom},
series = {ICEIT 2019}
}

@inproceedings{10.1145/3229591.3229592,
author = {R\"{u}th, Jan and Glebke, Ren\'{e} and Wehrle, Klaus and Causevic, Vedad and Hirche, Sandra},
title = {Towards In-Network Industrial Feedback Control},
year = {2018},
isbn = {9781450359085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3229591.3229592},
doi = {10.1145/3229591.3229592},
abstract = {Controlling physical machinery and processes is at the core of production automation. However, challenged by inflexibility, automation and control is evaluating to outsource this control to resourceful cloud environments. While this enables to derive better control through a plethora of measurements, it challenges the control quality through delay introduced through networks.In this paper, we show how to unify control and communication by offloading delay sensitive control tasks from the cloud to local network elements --- a previously unexplored area for in-network processing --- enabling both, ultra-high quality-of-control and scalable orchestration through cloud environments. Our implementation demonstrates how we combine state of the art control with communication. We achieve this by expressing the control and the datapath in P4 which we synthesize to BPF programs that we execute in XDP environments on Netronome SmartNICs. Further, we highlight the demands of control towards communication to build more involved and complex in-network controllers.},
booktitle = {Proceedings of the 2018 Morning Workshop on In-Network Computing},
pages = {14–19},
numpages = {6},
location = {Budapest, Hungary},
series = {NetCompute '18}
}

@inproceedings{10.1145/3233547.3233666,
author = {Kotlar, Alex V. and Wingo, Thomas S.},
title = {Tutorial: Rapidly Identifying Disease-Associated Rare Variants Using Annotation and Machine Learning at Whole-Genome Scale Online},
year = {2018},
isbn = {9781450357944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233547.3233666},
doi = {10.1145/3233547.3233666},
abstract = {Accurately identifying disease-associated alleles from large sequencing experiments remains challenging. During this tutorial, participants will learn how to use a new variant annotation and filtering web app called Bystro (https://bystro.io/) to analyze sequencing experiments. Bystro is the first online, cloud-based application that makes variant annotation and filtering accessible to all researchers for even the largest, terabyte-sized whole-genome experiments containing thousands of samples. Using its general-purpose, natural-language filtering engine, attendees will be shown how to perform quality control measures and identify alleles of interest. They will then be guided in exporting those variants, and using them in both a regression context by performing rare-variant association tests in R, as well as classification context by training new machine learning models in Python's scikit-learn library.},
booktitle = {Proceedings of the 2018 ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics},
pages = {558},
numpages = {1},
keywords = {variant classification, bioinformatics, machine learning, rare-variant association tests},
location = {Washington, DC, USA},
series = {BCB '18}
}

@inproceedings{10.1145/3410992.3410996,
author = {Noura, Mahda and Heil, Sebastian and Gaedke, Martin},
title = {Natural Language Goal Understanding for Smart Home Environments},
year = {2020},
isbn = {9781450387583},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410992.3410996},
doi = {10.1145/3410992.3410996},
abstract = {One of the main challenges of the Internet of Things (IoT) is to enable end-users without technical experience to use, control or monitor smart devices. However, enabling end-users to interact with these smart devices in an intuitive and natural way becomes increasingly important as they become more pervasive in our homes, workplaces and public environments. Voice-based interfaces are the emerging trend to provide a more natural human-device interaction in smart environments. Such interfaces require Natural Language Understanding (NLU) approaches to identify the meaning of end-users' voice inputs. Designing voice interfaces that are not limited to a small, fixed set of pre-defined commands is far from trivial. Existing voice-based solutions in the smart home domain either restrict the end-users to follow a strict language pattern, do not support indirect goals, require a large training dataset, or need a voice assistant located in the cloud. In this paper, we propose an approach for understanding end-users goals from voice inputs in smart homes. Our approach alleviates the need for end-users to learn or remember concrete operations of the devices and specific words/pattern structures rather it enables them to control their smart homes based on the desired goals (effects). We evaluate the approach through application to a collection of 253 goals from real end-users and report on quality metrics. The results demonstrate that our solution provides a good accuracy, high precision and acceptable recall for understanding end-users goals in the smart home domain.},
booktitle = {Proceedings of the 10th International Conference on the Internet of Things},
articleno = {1},
numpages = {8},
keywords = {natural language understanding, internet of things, smart home, goal recognition, voice interface},
location = {Malm\"{o}, Sweden},
series = {IoT '20}
}

@article{10.1145/2930659,
author = {Papadopoulos, Alessandro Vittorio and Ali-Eldin, Ahmed and \r{A}rz\'{e}n, Karl-Erik and Tordsson, Johan and Elmroth, Erik},
title = {PEAS: A Performance Evaluation Framework for Auto-Scaling Strategies in Cloud Applications},
year = {2016},
issue_date = {September 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {4},
issn = {2376-3639},
url = {https://doi.org/10.1145/2930659},
doi = {10.1145/2930659},
abstract = {Numerous auto-scaling strategies have been proposed in the past few years for improving various Quality of Service (QoS) indicators of cloud applications, for example, response time and throughput, by adapting the amount of resources assigned to the application to meet the workload demand. However, the evaluation of a proposed auto-scaler is usually achieved through experiments under specific conditions and seldom includes extensive testing to account for uncertainties in the workloads and unexpected behaviors of the system. These tests by no means can provide guarantees about the behavior of the system in general conditions. In this article, we present a Performance Evaluation framework for Auto-Scaling (PEAS) strategies in the presence of uncertainties. The evaluation is formulated as a chance constrained optimization problem, which is solved using scenario theory. The adoption of such a technique allows one to give probabilistic guarantees of the obtainable performance. Six different auto-scaling strategies have been selected from the literature for extensive test evaluation and compared using the proposed framework. We build a discrete event simulator and parameterize it based on real experiments. Using the simulator, each auto-scaler’s performance is evaluated using 796 distinct real workload traces from projects hosted on the Wikimedia foundations’ servers, and their performance is compared using PEAS. The evaluation is carried out using different performance metrics, highlighting the flexibility of the framework, while providing probabilistic bounds on the evaluation and the performance of the algorithms. Our results highlight the problem of generalizing the conclusions of the original published studies and show that based on the evaluation criteria, a controller can be shown to be better than other controllers.},
journal = {ACM Trans. Model. Perform. Eval. Comput. Syst.},
month = {aug},
articleno = {15},
numpages = {31},
keywords = {Performance evaluation, auto-scaling, elasticity, cloud computing, randomized optimization}
}

@inproceedings{10.1145/3090354.3090366,
author = {Zertal, Soumia and Batouche, Mohamed Chawki},
title = {A Hybrid Approach for Optimized Composition of Cloud Services},
year = {2017},
isbn = {9781450348522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3090354.3090366},
doi = {10.1145/3090354.3090366},
abstract = {The increasing use of Cloud services as well as the increasing demands of complex cloud services creates the need for a dynamic and adaptive composition of services, in a decentralized and large scale environment, where the quality of services may increase or decrease. Early attempts for dynamic composition of services have been proposed. But they are limited by their ability to adapt when deploying in highly dynamic and open environments. For better performance measurements, we use, in this paper, the Particle Swarm Optimization (PSO) algorithm to find and provide the services that meets the user's query. To assess the utility of each service, we take into consideration its values of service quality provided in the past. The latter is represented by the mechanism of stigmergy which uses the pheromone as a means of communication between services.},
booktitle = {Proceedings of the 2nd International Conference on Big Data, Cloud and Applications},
articleno = {12},
numpages = {7},
keywords = {Particle Swarm Optimization, Service Composition, Optimization, Stigmegy, Cloud Computing},
location = {Tetouan, Morocco},
series = {BDCA'17}
}

@article{10.1145/3038919,
author = {Olson, Judith S. and Wang, Dakuo and Olson, Gary M. and Zhang, Jingwen},
title = {How People Write Together Now: Beginning the Investigation with Advanced Undergraduates in a Project Course},
year = {2017},
issue_date = {February 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {1},
issn = {1073-0516},
url = {https://doi.org/10.1145/3038919},
doi = {10.1145/3038919},
abstract = {Today's commercially available word processors allow people to write collaboratively in the cloud, both in the familiar asynchronous mode and now in synchronous mode as well. This opens up new ways of working together. We examined the data traces of collaborative writing behavior in student teams’ use of Google Docs to discover how they are writing together now. We found that student teams write both synchronously and asynchronously, take fluid roles in the writing and editing of the documents, and show a variety of styles of collaborative writing, including writing from scratch, beginning with an outline, pasting in a related example as a template to organize their own writing, and three more. We also found that the document serves as a place where they share a number of things not included in the final document, including links or references to related materials, the assignment requirements from the instructor, and informal discussions to coordinate the collaboration or to structure the document. We computed a number of measures to depict a group's collaboration behavior and asked external graders to score these documents for quality. We found that the documents that included balanced participation and/or exhibited leadership were judged higher in quality, as were those that were longer. We then suggested system design implications and behavioral guidelines to support people writing together better, and concluded the paper with future research directions.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = {mar},
articleno = {4},
numpages = {40},
keywords = {writing style, collaboration, co-authoring, Google docs}
}

@inproceedings{10.1109/CCGRID.2017.120,
author = {Shekhar, Shashank and Gokhale, Aniruddha},
title = {Dynamic Resource Management Across Cloud-Edge Resources for Performance-Sensitive Applications},
year = {2017},
isbn = {9781509066100},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGRID.2017.120},
doi = {10.1109/CCGRID.2017.120},
abstract = {A large number of modern applications and systems are cloud-hosted, however, limitations in performance assurances from the cloud, and the longer and often unpredictable end-to-end network latencies between the end user and the cloud can be detrimental to the response time requirements of the applications, specifically those that have stringent Quality of Service (QoS) requirements. Although edge resources, such as cloudlets, may alleviate some of the latency concerns, there is a general lack of mechanisms that can dynamically manage resources across the cloud-edge spectrum. To address these gaps, this research proposes Dynamic Data Driven Cloud and Edge Systems (D3CES). It uses measurement data collected from adaptively instrumenting the cloud and edge resources to learn and enhance models of the distributed resource pool. In turn, the framework uses the learned models in a feedback loop to make effective resource management decisions to host applications and deliver their QoS properties. D3CES is being evaluated in the context of a variety of cyber physical systems, such as smart city, online games, and augmented reality applications.},
booktitle = {Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
pages = {707–710},
numpages = {4},
keywords = {Resource Management, IoT, Fog Computing, DDDAS, CPS, Edge Computing, Cloud Computing},
location = {Madrid, Spain},
series = {CCGrid '17}
}

@inproceedings{10.1145/3417113.3423001,
author = {Pathania, Priyavanshi and Mithani, Rajan Dilavar},
title = {Sustainability in Migrating Workloads to Public Clouds},
year = {2021},
isbn = {9781450381284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417113.3423001},
doi = {10.1145/3417113.3423001},
abstract = {In recent times, there has been a considerable increase in Cloud-Based applications and infrastructure. This has led to quicker innovations, agile businesses, availability of new services over the internet, improved collaboration, and better security. With the growth of new technologies like blockchain, quantum computing, mobility-focused applications, and edge computing, there has been an increased interest in adopting cloud services. In this paper, we highlight the different sustainability metrics and benefits while migrating workloads from the on-prem data center to the public clouds. Also, the clouds are elastic, scalable, cost-efficient, robust, and overall a better alternative to host the client applications and services. We present how the major Cloud Service Providers (CSPs) are continuously working on improving their infrastructure for a more energy efficient cloud. But with so many factors like the cost of cloud services, the location of the data center to name a few, it becomes quite a tedious task for the clients to select a cloud service provider when moving from their on-premise data center(s). Hence, we also briefly propose our solution that we are currently working on. The final goal is to have a cross-platform advisory that based on a wide-range of client-based inputs and a rich repository of current energy efficient clouds and their sustainability metrics, aims to provide them a detailed recommendation about their preferred cloud service provider. In case the client does not provide any such preference, the advisory should also recommend an ideal cloud service provider for their particular workload. This suggested action will be able to fulfill the client's constraints as well as provide them an energy efficient cloud along with a sustainability score. This score is indicative of how much improvement in the energy consumed and carbon footprint can be achieved through this migration to the suggested cloud.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {166–169},
numpages = {4},
keywords = {pre-migration cloud sustainability, carbon footprint, cloud sustainability, cloud computing, energy efficient cloud},
location = {Virtual Event, Australia},
series = {ASE '20}
}

@inproceedings{10.1145/3030207.3053676,
author = {Chow, Kingsum and Zhu, Wanyi},
title = {Software Performance Analytics in the Cloud},
year = {2017},
isbn = {9781450344043},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030207.3053676},
doi = {10.1145/3030207.3053676},
abstract = {The emergence of large-scale software deployments in the cloud has led to several challenges: (1) measuring software performance in the data center, and (2) optimizing software for resource management. This tutorial addresses the two challenges by bringing the knowledge of software performance monitoring in the data center to the world of applying performance analytics. It introduces data transformations for software performance metrics. The transformations enable effective applications of analytics. This tutorial starts with software performance in the small and ends with applying analytics to software performance in the large. In software performance in the small, it summarizes performance tools, data collection and manual analysis. Then it describes monitoring tools that are helpful in performance analysis in the large. The tutorial will guide the audience in applying analytics to performance data obtained by common tools. This tutorial describes how to select analytical methods and what precautions should be taken to get effective results.},
booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering},
pages = {419–421},
numpages = {3},
keywords = {analytics, datacenter efficiency, software performance, capacity planning},
location = {L'Aquila, Italy},
series = {ICPE '17}
}

@inproceedings{10.1145/3339825.3393581,
author = {Taraghi, Babak and Zabrovskiy, Anatoliy and Timmerer, Christian and Hellwagner, Hermann},
title = {CAdViSE: Cloud-Based Adaptive Video Streaming Evaluation Framework for the Automated Testing of Media Players},
year = {2020},
isbn = {9781450368452},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3339825.3393581},
doi = {10.1145/3339825.3393581},
abstract = {Attempting to cope with fluctuations of network conditions in terms of available bandwidth, latency and packet loss, and to deliver the highest quality of video (and audio) content to users, research on adaptive video streaming has attracted intense efforts from the research community and huge investments from technology giants. How successful these efforts and investments are, is a question that needs precise measurements of the results of those technological advancements. HTTP-based Adaptive Streaming (HAS) algorithms, which seek to improve video streaming over the Internet, introduce video bitrate adaptivity in a way that is scalable and efficient. However, how each HAS implementation takes into account the wide spectrum of variables and configuration options, brings a high complexity to the task of measuring the results and visualizing the statistics of the performance and quality of experience. In this paper, we introduce CAdViSE, our Cloud-based Adaptive Video Streaming Evaluation framework for the automated testing of adaptive media players. The paper aims to demonstrate a test environment which can be instantiated in a cloud infrastructure, examines multiple media players with different network attributes at defined points of the experiment time, and finally concludes the evaluation with visualized statistics and insights into the results.},
booktitle = {Proceedings of the 11th ACM Multimedia Systems Conference},
pages = {349–352},
numpages = {4},
keywords = {quality of experience, media players, automated testing, network emulation, MPEG-DASH, HTTP adaptive streaming},
location = {Istanbul, Turkey},
series = {MMSys '20}
}

@inproceedings{10.1145/3428502.3428511,
author = {Branco, Te\'{o}filo T. and Kawashita, Ilka M. and de S\'{a}-Soares, Filipe and Monteiro, Cl\'{a}udio N.},
title = {An IoT Application Case Study to Optimize Electricity Consumption in the Government Sector},
year = {2020},
isbn = {9781450376747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3428502.3428511},
doi = {10.1145/3428502.3428511},
abstract = {This paper presents a case study where sensor modules supported by Internet of Things (IoT) technology were used to monitor and control electricity consumption of air conditioning units in an innovation center of a public government institution. This study evaluates alternatives to improve the management of electricity consumption in Salvador City Hall's facilities. To contribute to the economy and sustainability of the Administration, we aim to increase the efficiency of the processes currently adopted. Our focus is on minimizing electricity waste and reducing costs. Installed sensor modules measure electricity consumption and control the operation of air conditioning equipment, allowing the administrator to manage the operation of these devices. The installation of smart sensor modules connected to an IoT platform allows energy consumption data to be sent to a computing Cloud and to be monitored remotely through dashboards generated by specialized software. A quantitative analysis was conducted to measure the efficiency of the air conditioning control system and identify opportunities for applying the IoT solution to control natural resources in the public sector. The monitoring of these signals subsidized the analyzes required for informed decision making of interventions to improve the system's stability and promote the reduction of consumption. Also, the system has demonstrated its ability to protect air conditioners, monitor the quality of the power supplied, proactively control consumption, and establish appropriate user behaviors for reducing consumption. Results demonstrated the feasibility of implementing automated systems to improve the consumption of natural resources in the public sector. We also identified some managerial behaviors required to enable this type of technological solution.},
booktitle = {Proceedings of the 13th International Conference on Theory and Practice of Electronic Governance},
pages = {70–81},
numpages = {12},
keywords = {Innovation, Smart Technologies, Sustainability, E-government, Internet of Thinks (IoT)},
location = {Athens, Greece},
series = {ICEGOV '20}
}

@inproceedings{10.1145/3458305.3463380,
author = {Ramos-Chavez, Roberto and Mekuria, Rufael and Karagkioules, Theo and Griffioen, Dirk and Wagenaar, Arjen and Ogle, Mark},
title = {MPEG NBMP Testbed for Evaluation of Real-Time Distributed Media Processing Workflows at Scale},
year = {2021},
isbn = {9781450384346},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458305.3463380},
doi = {10.1145/3458305.3463380},
abstract = {Real-time Distributed Media Processing Workflows (DMPW) are popular for online media delivery. Combining distributed media sources and processing can reduce storage costs and increase flexibility. However, high request rates may result in unacceptable latency or even failures in incorrect configurations. Thus, testing DMPW deployments at scale is key, particularly for real-time cases. We propose the new MPEG Network Based Media Processing (NBMP) standard for this and present a testbed implementation that includes all the reference components. In addition, the testbed includes a set of configurable functions for load generation, monitoring, data-collection and visualization. The testbed is used to test Dynamic Adaptive HTTP streaming functions under different workloads in a standardized and reproducible manner. A total of 327 tests with different loads and Real-Time DMPW configurations were completed. The results provide insights in the performance, reliability and time-consistency of each configuration. Based on these tests, we selected the preferred cloud instance type, considering hypervisor options and different function implementation configurations. Further, we analyzed different processing tasks and options for distributed deployments on edge and centralized clouds. Last, a classifier was developed to detect if failures happen under a certain workload. Results also show that, normalized inter-experiment standard deviation of the metric means can be an indicator for unstable or incorrect configurations.},
booktitle = {Proceedings of the 12th ACM Multimedia Systems Conference},
pages = {173–185},
numpages = {13},
keywords = {standards, experimentation},
location = {Istanbul, Turkey},
series = {MMSys '21}
}

@article{10.1109/TNET.2020.2971587,
author = {Cheng, Yingying and Jia, Xiaohua},
title = {NAMP: Network-Aware Multipathing in Software-Defined Data Center Networks},
year = {2020},
issue_date = {April 2020},
publisher = {IEEE Press},
volume = {28},
number = {2},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2020.2971587},
doi = {10.1109/TNET.2020.2971587},
abstract = {Data center networks employ parallel paths to perform load balancing. Existing traffic splitting schemes propose weighted traffic distribution across multiple paths via a centralized view. An SDN controller computes the traffic splitting ratio of a flow group among all the paths, and implements the ratio by creating multiple rules in the flow table of OpenFlow switches. However, since the number of rules in TCAM-based flow table is limited, it is not scalable to implement the ideal splitting ratio for every flow group. Existing solutions, WCMP and Niagara, aim at reducing the maximum oversubscription of all egress ports and reducing traffic imbalance, respectively. However, the transmission time of flow groups, which measures the quality of cloud services, is sub-optimal in existing solutions that ignore heterogeneous network bandwidth. We propose and implement NAMP, a multipathing scheme considering the network heterogeneity, to efficiently optimize the transmission time of flow groups. Experimental results show that NAMP reduces the transmission time by up to 45.4% than Niagara, up to 50% than WCMP, and up to 60% than ECMP.},
journal = {IEEE/ACM Trans. Netw.},
month = {apr},
pages = {846–859},
numpages = {14}
}

@inproceedings{10.1109/CCGrid.2014.22,
author = {Byholm, Benjamin and Porres, Iv\'{a}n},
title = {Cost-Efficient, Reliable, Utility-Based Session Management in the Cloud},
year = {2014},
isbn = {9781479927838},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGrid.2014.22},
doi = {10.1109/CCGrid.2014.22},
abstract = {We present a model and system for cost-efficient and reliable management of sessions in a Cloud, based on the von Neumann-Morgenstern utility theorem. Our model enables a web application provider to maximize profit while maintaining a desired quality of service. The objective is to determine whether, when, where, and how long to store a session, given multiple storage options with various properties, e.g. cost, capacity, and reliability. Reliability is affected by three factors: how often session state is stored, how many stores are used, and how reliable those stores are. To account for these factors, we use a Markovian reliability model and treat the valid storage options for each session as a von Neumann-Morgenstern lottery. We proceed by representing the resulting problem as a knapsack problem, which can be heuristically solved for a good compromise between efficiency and effectiveness. We analyze the results from a discrete-event simulation involving multiple session management policies, including two utility-based policies: a greedy heuristic policy intended to give real-time performance and a reference policy based on solving the linear programming relaxation of the knapsack problem, giving a theoretical upper bound on achievable utility. As the focus of this work is exploratory, rather than performance-based, we do not directly measure the time required for solving the model. Instead, we give the computational complexity of the algorithms. Our results indicate that otherwise unprofitable services become profitable through utility-based session management in a cloud setting. However, if the costs are much lower than the expected revenues, all policies manage to turn a profit. Different policies performed the best under different circumstances.},
booktitle = {Proceedings of the 14th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
pages = {102–111},
numpages = {10},
keywords = {analytical models, utility theory, simulation, reliability, availability, web-based services, and serviceability, markov processes, distributed systems},
location = {Chicago, Illinois},
series = {CCGRID '14}
}

@inproceedings{10.1145/2801694.2801710,
author = {Ganesan, Deepak},
title = {Towards Ultra-Low Power Wearable Health Sensing with Sparse Sampling and Asymmetric Communication},
year = {2015},
isbn = {9781450337014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2801694.2801710},
doi = {10.1145/2801694.2801710},
abstract = {Wearable sensors offer tremendous opportunities for accelerating biomedical discovery, and improving population-scale health and wellness. There is a growing appetite for health analytics -- we are no longer content with wearables that count steps and calories, we want to measure physiology, behavior, activities, cognition, affect, and other parameters with the expectation that such data will lead to deep insights that can improve quality of life.But a chasm separates expectations and reality. How do we extract such insights from sensor platforms with tiny energy budgets? How do we communicate high-rate sensor data to the cloud for enabling deep analytics while operating within these energy budgets? How do we deal with noise, confounders, and artifacts that make insights hard to extract from signals collected in real-world settings?In this talk, I will discuss a few strategies to tackle these problems. I will discuss how we can design an low-power computational eyeglass that continually tracks eye and visual context by leveraging sparsity, how we can transfer data at Megabits/second from wearables while operating at tens of micro-watts of power, and how we can leverage these techniques in the context of mobile health.},
booktitle = {Proceedings of the 2015 Workshop on Wireless of the Students, by the Students, \&amp; for the Students},
pages = {34},
numpages = {1},
keywords = {backscatter communication, mobile health, eye tracking},
location = {Paris, France},
series = {S3 '15}
}

@inproceedings{10.1145/2996890.3007864,
author = {Muhammad-Bello, Bilkisu Larai and Aritsugi, Masayoshi},
title = {TCloud: A Transparent Framework for Public Cloud Service Comparison},
year = {2016},
isbn = {9781450346160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2996890.3007864},
doi = {10.1145/2996890.3007864},
abstract = {Whilst there are many attributes that need to be considered for cloud service selection, performance remains one of the most crucial aspects. Thus, we argue for a transparent cloud provider comparison framework in this study. We initiate the development of TCloud: a transparent framework for public cloud service comparison. Our framework helps prospective cloud users to decipher public cloud benchmarking data and appraise the performance of public cloud services relative to their performance goals. We carried out experiments on the real public cloud environment to implement our framework and demonstrated how prospective cloud users can use the TCloud framework in understanding how well virtualized public cloud resources meet their application requirements. Unlike previous studies, the TCloud framework presents a more realistic method of appraising the performance of virtualized resources in the public cloud. TCloud is unique in the sense that it collates public cloud benchmarking data and correlates the observed performance metrics to prospective cloud users' actual application workload requirements.},
booktitle = {Proceedings of the 9th International Conference on Utility and Cloud Computing},
pages = {228–233},
numpages = {6},
keywords = {cloud service selection, workload-based performance analysis, cloud performance benchmarking},
location = {Shanghai, China},
series = {UCC '16}
}

@inproceedings{10.1145/3213344.3213354,
author = {Khan, Jamal Ahmad and Shahzad, Muhammad and Butt, Ali R.},
title = {Sizing Buffers of IoT Edge Routers},
year = {2018},
isbn = {9781450358378},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3213344.3213354},
doi = {10.1145/3213344.3213354},
abstract = {In typical IoT systems, sensors and actuators are connected to small embedded computers, called IoT devices, and the IoT devices are connected to one or more appropriate cloud services over the internet through an edge access router. A very important design aspect of an IoT edge router is the size of the output packet buffer of its interface that connects to the access link. Selecting an appropriate size for this buffer is crucial because it directly impacts two key performance metrics: 1) access link utilization and 2) latency. In this paper, we calculate the size of the output buffer that ensures that the access link stays highly utilized and at the same time, significantly lowers the average latency experienced by the packets. To calculate this buffer size, we theoretically model the average TCP congestion window size of all IoT devices while eliminating three key assumptions of prior art that do not hold true for IoT TCP traffic, as we will demonstrate through a measurement study. We show that for IoT traffic, buffer size calculated by our method results in 50\% lower queuing delay compared to the state of the art schemes while achieving similar access link utilization and loss-rate.},
booktitle = {Proceedings of the 1st International Workshop on Edge Systems, Analytics and Networking},
pages = {55–60},
numpages = {6},
keywords = {IoT, Buffers, Edge Routers},
location = {Munich, Germany},
series = {EdgeSys'18}
}

