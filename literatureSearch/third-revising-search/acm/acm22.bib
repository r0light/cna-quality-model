@inproceedings{10.1145/2791405.2791446,
author = {Shrimali, Bela and Patel, Hiren},
title = {Performance Based Energy Efficient Techniques For VM Allocation In Cloud Environment},
year = {2015},
isbn = {9781450333610},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791405.2791446},
doi = {10.1145/2791405.2791446},
abstract = {Cloud computing is emerging as a new paradigm for providing different services like platform, infrastructure and software as a large scale distributed computing applications via Internet. Computing resources are available in Cloud through virtualization. It divides a physical machine into many half or full isolated machines (known as Virtual Machines-VMs) using various allocation techniques. To identify a technique that can satisfy a quality of service in consideration of energy consumption in Cloud environment is one of the challenging issues for Virtual Machine allocation in Cloud as there are tradeoffs between energy consumption and performance. In the present research, we aim to survey various techniques that combine energy efficiency and performance. Hence, different real world virtual machine allocation policies are explored and the performance based energy efficient techniques for VM allocation are discussed. This survey may assist the researchers who wish to step in to the domain of performance based energy efficient VM techniques.},
booktitle = {Proceedings of the Third International Symposium on Women in Computing and Informatics},
pages = {477–486},
numpages = {10},
keywords = {Virtual machine, Cloud computing, Energy efficient, Performance},
location = {Kochi, India},
series = {WCI '15}
}

@inproceedings{10.1145/3064911.3069397,
author = {Fujimoto, Richard M. and Hunter, Michael and Biswas, Aradhya and Jackson, Mark and Neal, SaBra},
title = {Power Efficient Distributed Simulation},
year = {2017},
isbn = {9781450344890},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3064911.3069397},
doi = {10.1145/3064911.3069397},
abstract = {Energy and power consumption have become important concerns for many computing systems ranging from embedded and mobile systems operating on battery-powered devices to high performance and cloud computing applications running on supercomputers and in data centers. To date, only a limited amount of work has considered power consumption in parallel and distributed simulations. A variety of options to analyze and explore power consumption in distributed simulations are discussed. These options range from design decisions in developing the simulation model to selection of algorithms in distributed simulation middleware to exploitation of hardware techniques. Work to characterize the power and energy consumed by different elements of parallel and distributed simulation systems are discussed and empirical measurements presented to quantify energy and power use, suggestive of directions for future research in this area.},
booktitle = {Proceedings of the 2017 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
pages = {77–88},
numpages = {12},
keywords = {power aware computing, distributed simulation, parallel discrete event simulation},
location = {Singapore, Republic of Singapore},
series = {SIGSIM-PADS '17}
}

@inproceedings{10.1145/3030207.3044530,
author = {Michael, Nicolas and Ramannavar, Nitin and Shen, Yixiao and Patil, Sheetal and Sung, Jan-Lung},
title = {CloudPerf: A Performance Test Framework for Distributed and Dynamic Multi-Tenant Environments},
year = {2017},
isbn = {9781450344043},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030207.3044530},
doi = {10.1145/3030207.3044530},
abstract = {The evolution of cloud-computing imposes many challenges on performance testing and requires not only a different approach and methodology of performance evaluation and analysis, but also specialized tools and frameworks to support such work. In traditional performance testing, typically a single workload was run against a static test configuration. The main metrics derived from such experiments included throughput, response times, and system utilization at steady-state. While this may have been sufficient in the past, where in many cases a single application was run on dedicated hardware, this approach is no longer suitable for cloud-based deployments. Whether private or public cloud, such environments typically host a variety of applications on distributed shared hardware resources, simultaneously accessed by a large number of tenants running heterogeneous workloads. The number of tenants as well as their activity and resource needs dynamically change over time, and the cloud infrastructure reacts to this by reallocating existing or provisioning new resources. Besides metrics such as the number of tenants and overall resource utilization, performance testing in the cloud must be able to answer many more questions: How is the quality of service of a tenant impacted by the constantly changing activity of other tenants? How long does it take the cloud infrastructure to react to changes in demand, and what is the effect on tenants while it does so? How well are service level agreements met? What is the resource consumption of individual tenants? How can global performance metrics on application- and system-level in a distributed system be correlated to an individual tenant's perceived performance?In this paper we present CloudPerf, a performance test framework specifically designed for distributed and dynamic multi-tenant environments, capable of answering all of the above questions, and more. CloudPerf consists of a distributed harness, a protocol-independent load generator and workload modeling framework, an extensible statistics framework with live-monitoring and post-analysis tools, interfaces for cloud deployment operations, and a rich set of both low-level as well as high-level workloads from different domains.},
booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering},
pages = {189–200},
numpages = {12},
keywords = {statistics collection, workload modeling, performance testing, cloud, multi-tenancy, load generation},
location = {L'Aquila, Italy},
series = {ICPE '17}
}

@inproceedings{10.1145/3299819.3299836,
author = {Zheng, Wanwan and Jin, Mingzhe},
title = {Do We Need More Training Samples For Text Classification?},
year = {2018},
isbn = {9781450366236},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3299819.3299836},
doi = {10.1145/3299819.3299836},
abstract = {In recent years, with the rise of exceptional cloud computing technologies, machine learning approach in solving complex problems has been greatly accelerated. In the field of text classification, machine learning is a technology of providing computers the ability to learn and predict tasks without being explicitly labeled, and it is said that enough data are needed in order to let a machine to learn. However, more data tend to cause overfitting in machine learning algorithms, and there is no object criteria in deciding how many samples are required to achieve a desired level of performance. This article addresses this problem by using feature selection method. In our experiments, feature selection is proved to be able to decrease 66.67\% at the largest of the required size of training dataset. Meanwhile, the kappa coefficient as a performance measure of classifiers could increase 11 points at the maximum. Furthermore, feature selection as a technology to remove irrelevant features was found be able to prevent overfitting to a great extent.},
booktitle = {Proceedings of the 2018 Artificial Intelligence and Cloud Computing Conference},
pages = {121–128},
numpages = {8},
keywords = {Size of Dataset, Text Classification, Feature Selection},
location = {Tokyo, Japan},
series = {AICCC '18}
}

@article{10.1145/3132041,
author = {Slivar, Ivan and Suznjevic, Mirko and Skorin-Kapov, Lea},
title = {Game Categorization for Deriving QoE-Driven Video Encoding Configuration Strategies for Cloud Gaming},
year = {2018},
issue_date = {June 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {3s},
issn = {1551-6857},
url = {https://doi.org/10.1145/3132041},
doi = {10.1145/3132041},
abstract = {Cloud gaming has been recognized as a promising shift in the online game industry, with the aim of implementing the “on demand” service concept that has achieved market success in other areas of digital entertainment such as movies and TV shows. The concepts of cloud computing are leveraged to render the game scene as a video stream that is then delivered to players in real-time. The main advantage of this approach is the capability of delivering high-quality graphics games to any type of end user device; however, at the cost of high bandwidth consumption and strict latency requirements. A key challenge faced by cloud game providers lies in configuring the video encoding parameters so as to maximize player Quality of Experience (QoE) while meeting bandwidth availability constraints. In this article, we tackle one aspect of this problem by addressing the following research question: Is it possible to improve service adaptation based on information about the characteristics of the game being streamed? To answer this question, two main challenges need to be addressed: the need for different QoE-driven video encoding (re-)configuration strategies for different categories of games, and how to determine a relevant game categorization to be used for assigning appropriate configuration strategies. We investigate these problems by conducting two subjective laboratory studies with a total of 80 players and three different games. Results indicate that different strategies should likely be applied for different types of games, and show that existing game classifications are not necessarily suitable for differentiating game types in this context. We thus further analyze objective video metrics of collected game play video traces as well as player actions per minute and use this as input data for clustering of games into two clusters. Subjective results verify that different video encoding configuration strategies may be applied to games belonging to different clusters.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = {jun},
articleno = {56},
numpages = {24},
keywords = {video codec configuration strategies, game categorization, Quality of Experience, Cloud gaming}
}

@article{10.1145/3164537,
author = {Ilyushkin, Alexey and Ali-Eldin, Ahmed and Herbst, Nikolas and Bauer, Andr\'{e} and Papadopoulos, Alessandro V. and Epema, Dick and Iosup, Alexandru},
title = {An Experimental Performance Evaluation of Autoscalers for Complex Workflows},
year = {2018},
issue_date = {June 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {2},
issn = {2376-3639},
url = {https://doi.org/10.1145/3164537},
doi = {10.1145/3164537},
abstract = {Elasticity is one of the main features of cloud computing allowing customers to scale their resources based on the workload. Many autoscalers have been proposed in the past decade to decide on behalf of cloud customers when and how to provision resources to a cloud application based on the workload utilizing cloud elasticity features. However, in prior work, when a new policy is proposed, it is seldom compared to the state-of-the-art, and is often compared only to static provisioning using a predefined quality of service target. This reduces the ability of cloud customers and of cloud operators to choose and deploy an autoscaling policy, as there is seldom enough analysis on the performance of the autoscalers in different operating conditions and with different applications. In our work, we conduct an experimental performance evaluation of autoscaling policies, using as application model workflows, a popular formalism for automating resource management for applications with well-defined yet complex structures. We present a detailed comparative study of general state-of-the-art autoscaling policies, along with two new workflow-specific policies. To understand the performance differences between the seven policies, we conduct various experiments and compare their performance in both pairwise and group comparisons. We report both individual and aggregated metrics. As many workflows have deadline requirements on the tasks, we study the effect of autoscaling on workflow deadlines. Additionally, we look into the effect of autoscaling on the accounted and hourly based charged costs, and we evaluate performance variability caused by the autoscaler selection for each group of workflow sizes. Our results highlight the trade-offs between the suggested policies, how they can impact meeting the deadlines, and how they perform in different operating conditions, thus enabling a better understanding of the current state-of-the-art.},
journal = {ACM Trans. Model. Perform. Eval. Comput. Syst.},
month = {apr},
articleno = {8},
numpages = {32},
keywords = {scientific workflows, Autoscaling, metrics, elasticity, benchmarking}
}

@inproceedings{10.1145/3123266.3123384,
author = {Zhu, Yifei and Liu, Jiangchuan and Wang, Zhi and Zhang, Cong},
title = {When Cloud Meets Uncertain Crowd: An Auction Approach for Crowdsourced Livecast Transcoding},
year = {2017},
isbn = {9781450349062},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3123266.3123384},
doi = {10.1145/3123266.3123384},
abstract = {In the emerging crowd sourced live cast services, numerous amateur broadcasters live stream their video contents to worldwide viewers and constantly interact with them through chat messages. Live video contents are transcoded into multiple quality versions to better service viewers with different network and device configurations. Cloud computing becomes a natural choice to handle these computational intensive tasks due to its elasticity and the "pay-as-you-go" billing model. However, given the significantly large number of concurrent channel numbers and the diverse viewer geo-distributions in this new crowd sourced live cast service, even the cloud becomes significantly expensive to cover the whole community and inadequate in fulfilling the latency requirement. In this paper, after observing the abundant computational resources residing in end viewers, we propose a Cloud-Crowd collaborative system, C2, which combines end viewers with cloud to perform video transcoding in a cost-efficient way. To quantify the heterogeneity and uncertainty of viewers and pass the asymmetric information barrier, we incorporate statistical descriptions into our bidding language and design truthful auctions to recruit stable viewers with appropriate incentives. We further tailor redundancy strategies for workloads with different Quality of Service requirements to improve the stability of our system. Desirable economic properties, like social efficiency, ex-post incentive compatibility, individual rationality, are proved to be guaranteed in our studied scenarios. Using traces captured from the popular Twitch platform, we show that C2 achieves up to 93\% more cost saving than a pure cloud-based solution, and significantly outperforms other baseline approaches in both social welfare and system stability.},
booktitle = {Proceedings of the 25th ACM International Conference on Multimedia},
pages = {1372–1380},
numpages = {9},
keywords = {cloud computing, auction mechanism, uncertainty, edge computing, crowdsourced livecast transcoding},
location = {Mountain View, California, USA},
series = {MM '17}
}

@inproceedings{10.1145/3069593.3069609,
author = {Khidzir, Nik Zulkarnaen and Ghani, Wan Safra Diyana Wan Abdul and Guan, Tan Tse},
title = {Cloud-Based Mobile-Retail Application for Textile Cyberpreneurs: Task-Technology Fit Perspective Analysis},
year = {2017},
isbn = {9781450348683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3069593.3069609},
doi = {10.1145/3069593.3069609},
abstract = {Cloud computing and mobile computing paradigms have enhanced the usage of current technology among people from various sectors to perform certain required tasks. The combination of these two paradigms have also created the existence of cloud-based mobile applications that are designed to be useful in business environments, such as to be used by textile cyberpreneurs for m-retail transaction. As cloud adoption was previously low among Malaysian entrepreneurs, the usage intention factors of related cloud technology and services should be determined for better clarification and future technology enhancements. Besides, studies on m-retail or m-shopping adoption in Malaysia were merely focused on customer's perspectives rather than retailer's perspectives. In measuring the suitability of Cloud-based M-Retail (CBMR) application with the task requirements of textile cyberpreneurs, Task-Technology Fit (TTF) model is used as the basis of this research. Results from a pilot study, through a survey of selected group of textile cyberpreneurs shows instrument's reliability and positive feedbacks to support the intention to use the technology. The future direction of the study in which to apply the instruments to a larger group of respondents is also discussed along with its potential contribution.},
booktitle = {Proceedings of the International Conference on High Performance Compilation, Computing and Communications},
pages = {65–70},
numpages = {6},
keywords = {mobile retail, cloud-based mobile application, cyberpreneurship, mobile shopping, behavioral intention, task-technology fit},
location = {Kuala Lumpur, Malaysia},
series = {HP3C-2017}
}

@inproceedings{10.1109/MICRO.2018.00056,
author = {Lv, Yirong and Sun, Bin and Luo, Qinyi and Wang, Jing and Yu, Zhibin and Qian, Xuehai},
title = {CounterMiner: Mining Big Performance Data from Hardware Counters},
year = {2018},
isbn = {9781538662403},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MICRO.2018.00056},
doi = {10.1109/MICRO.2018.00056},
abstract = {Modern processors typically provide a small number of hardware performance counters to capture a large number of microarchitecture events1. These counters can easily generate a huge amount (e.g., GB or TB per day) of data, which we call big performance data in cloud computing platforms with more than thousands of servers and millions of complex workloads running ina"24/7/365" manner. The big performance data provides a precious foundation for root cause analysis of performance bottlenecks, architecture and compiler optimization, and many more. However, it is challenging to extract value from the big performance data due to: 1) the many unperceivable errors (e.g., outliers and missing values); and 2) the difficulty of obtaining insights, e.g., relating events to performance.In this paper, we propose CounterMiner, a rigorous methodology that enables the measurement and understanding of big performance data by using data mining and machine learning techniques. It includes three novel components: 1) using data cleaning to improve data quality by replacing outliers and filling in missing values; 2) iteratively quantifying, ranking, and pruning events based on their importance with respect to performance; 3) quantifying interaction intensity between two events by residual variance. We use sixteen benchmarks (eight from CloudSuite and eight from the Spark 2 version of HiBench) to evaluate CounterMiner. The experimental results show that CounterMiner reduces the average error from 28.3\% to 7.7\% when multiplexing 10 events on 4 hardware counters. We also conduct a real-world case study, showing that identifying important configuration parameters of Spark programs by event importance is much faster than directly ranking the importance of these parameters.},
booktitle = {Proceedings of the 51st Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {613–626},
numpages = {14},
keywords = {performance counters, computer architecture, big data, data mining},
location = {Fukuoka, Japan},
series = {MICRO-51}
}

@inproceedings{10.1145/3199478.3199483,
author = {Castillo, Alexy Gene and Telan, Sherwin M. and Palaoag, Thelma},
title = {Cloud-Based Data Mining Framework: A Model to Improve Maternal Healthcare},
year = {2018},
isbn = {9781450363617},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3199478.3199483},
doi = {10.1145/3199478.3199483},
abstract = {The foundation of quality health care depends upon the presence of competent health personnel working in a situation where prescriptions and health supplies are accessible when required and in sufficient quantity and of guaranteed quality. This paper conduces to propound a decision support framework model for the Department of Health (DOH) which able to innovate the acquisition and allocation management of medicines and health supplies with the aim of improving the maternal healthcare in the Philippines.In-depth interviews were conducted to DOH officials and facility managers of Rural Health Units (RHU) and in the 3rd district of Albay, Bicol Philippines. Data triangulation and literature review are employed to design the framework. Finally to assess its applicability, a simulative-evaluation is conveyed.Respondents reported on the unreliability of obtaining healthcare supplies for RHU's, which results untimely and suboptimal rendering of healthcare services. Also, insufficient provision of medicines from the government and lack of accountability within the supply system due of inadequate and incoherent terminal reports were revealed to contribute to the current situation.To address the mentioned challenges, this study recommends the consideration of the proposed framework model employing cloud computing and data mining to remarkably improve the administration on the provision of medicines and health supplies, guaranteeing its auspicious accessibility for the benefit of Filipino pregnant women ensuring their health as carriers of the lives to be born as the future of the nation.},
booktitle = {Proceedings of the 2nd International Conference on Cryptography, Security and Privacy},
pages = {21–28},
numpages = {8},
keywords = {Maternal Health, Cloud Computing, Data Mining},
location = {Guiyang, China},
series = {ICCSP 2018}
}

@inproceedings{10.5555/3400397.3400612,
author = {Verghelet, Paula and Mocskos, Esteban},
title = {First Steps in Creating a Methodology to Develop and Test Scheduling Policies for Internet of Things},
year = {2020},
isbn = {9781728132839},
publisher = {IEEE Press},
abstract = {Internet of Things (IoT) refers to a paradigm in which all objects can send information and collaborate with their computing resources through the Internet. The combination of Fog and Cloud Computing defines a distributed system composed of heterogeneous resources interconnected by different communication technologies. Despite its theoretical capacity, using these computational resources poses a challenge to distributed applications and scheduling policies. In this work, we show the initial steps in developing a tool to support the creation of scheduling policies combining simulation and validation. We show the details to be considered when selecting and configuring the different layers of software. To evaluate the proposal, we use a segmentation method in both platforms and a theoretical model to predict the total compute time. Our results show that both simulation and validation platforms agree in the obtained results which also can be explained in terms of a theoretical model.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {2629–2640},
numpages = {12},
location = {National Harbor, Maryland},
series = {WSC '19}
}

@inproceedings{10.1145/2925426.2926276,
author = {Liu, Longjun and Sun, Hongbin and Li, Chao and Hu, Yang and Zheng, Nanning and Li, Tao},
title = {Towards an Adaptive Multi-Power-Source Datacenter},
year = {2016},
isbn = {9781450343619},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2925426.2926276},
doi = {10.1145/2925426.2926276},
abstract = {Big data and cloud computing are accelerating the capacity growth of datacenters all over the world. Their energy costs and environmental issues have pushed datacenter operators to explore and integrate alternative energy sources, such as various renewable energy supplies and energy storage devices. Designing datacenters powered by multi-power supplies in the smart grid environment is becoming a promising trend in the next few decades. However, gracefully provisioning various power sources and efficiently manage them in datacenter is a significant challenge.In this paper, we explore an unconventional fine-grained power distribution architecture for multi-source powered datacenters. We thoroughly investigate how to deliver and manage multiple power sources from the power generation plant outside of the datacenter to datacenter inside. We then propose a novel Power Switch Network (PSN) for datacenters. PSN is a reconfigurable multi-power-source distribution architecture which enables datacenter to distribute various power sources with a fine-grained manner. Moreover, a tailored machine learning based power sources management framework is proposed for PSN to dynamically select different power sources and optimize user-demanded performance metrics. Compared with the conventional single-switch system, evaluation results show that PSN could improve solar energy utilization by 39.6\%, reduce utility power cost by 11.1\% and improve workload performance by 33.8\%, meanwhile enhancing battery lifetime by 9.3\%. We expect that our work could provide valuable guidelines for the emerging multi-power-source datacenter to improve their efficiency, sustainability and economy.},
booktitle = {Proceedings of the 2016 International Conference on Supercomputing},
articleno = {11},
numpages = {11},
keywords = {Power Distribution Architecture, Multi-Power-Source Management, Renewable Energy, Datacenters},
location = {Istanbul, Turkey},
series = {ICS '16}
}

@inproceedings{10.1145/3078505.3078530,
author = {Cohen, Maxime C. and Keller, Philipp and Mirrokni, Vahab and Zadimoghadddam, Morteza},
title = {Overcommitment in Cloud Services Bin Packing with Chance Constraints},
year = {2017},
isbn = {9781450350327},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078505.3078530},
doi = {10.1145/3078505.3078530},
abstract = {This paper considers a traditional problem of resource allocation, scheduling jobs on machines. One such recent application is cloud computing, where jobs arrive in an online fashion with capacity requirements and need to be immediately scheduled on physical machines in data centers. It is often observed that the requested capacities are not fully utilized, hence offering an opportunity to employ an overcommitment policy, i.e., selling resources beyond capacity. Setting the right overcommitment level can induce a significant cost reduction for the cloud provider, while only inducing a very low risk of violating capacity constraints. We introduce and study a model that quantifies the value of overcommitment by modeling the problem as a bin packing with chance constraints. We then propose an alternative formulation that transforms each chance constraint into a submodular function. We show that our model captures the risk pooling effect and can guide scheduling and overcommitment decisions. We also develop a family of online algorithms that are intuitive, easy to implement and provide a constant factor guarantee from optimal. Finally, we calibrate our model using realistic workload data, and test our approach in a practical setting. Our analysis and experiments illustrate the benefit of overcommitment in cloud services, and suggest a cost reduction of 1.5\% to 17\% depending on the provider's risk tolerance.},
booktitle = {Proceedings of the 2017 ACM SIGMETRICS / International Conference on Measurement and Modeling of Computer Systems},
pages = {7},
numpages = {1},
keywords = {bin packing, job scheduling, chance constraints},
location = {Urbana-Champaign, Illinois, USA},
series = {SIGMETRICS '17 Abstracts}
}

@article{10.1145/3143314.3078530,
author = {Cohen, Maxime C. and Keller, Philipp and Mirrokni, Vahab and Zadimoghadddam, Morteza},
title = {Overcommitment in Cloud Services Bin Packing with Chance Constraints},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {1},
issn = {0163-5999},
url = {https://doi.org/10.1145/3143314.3078530},
doi = {10.1145/3143314.3078530},
abstract = {This paper considers a traditional problem of resource allocation, scheduling jobs on machines. One such recent application is cloud computing, where jobs arrive in an online fashion with capacity requirements and need to be immediately scheduled on physical machines in data centers. It is often observed that the requested capacities are not fully utilized, hence offering an opportunity to employ an overcommitment policy, i.e., selling resources beyond capacity. Setting the right overcommitment level can induce a significant cost reduction for the cloud provider, while only inducing a very low risk of violating capacity constraints. We introduce and study a model that quantifies the value of overcommitment by modeling the problem as a bin packing with chance constraints. We then propose an alternative formulation that transforms each chance constraint into a submodular function. We show that our model captures the risk pooling effect and can guide scheduling and overcommitment decisions. We also develop a family of online algorithms that are intuitive, easy to implement and provide a constant factor guarantee from optimal. Finally, we calibrate our model using realistic workload data, and test our approach in a practical setting. Our analysis and experiments illustrate the benefit of overcommitment in cloud services, and suggest a cost reduction of 1.5\% to 17\% depending on the provider's risk tolerance.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {jun},
pages = {7},
numpages = {1},
keywords = {bin packing, job scheduling, chance constraints}
}

@inproceedings{10.1145/2731186.2731202,
author = {Wang, Hui and Isci, Canturk and Subramanian, Lavanya and Choi, Jongmoo and Qian, Depei and Mutlu, Onur},
title = {A-DRM: Architecture-Aware Distributed Resource Management of Virtualized Clusters},
year = {2015},
isbn = {9781450334501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2731186.2731202},
doi = {10.1145/2731186.2731202},
abstract = {Virtualization technologies has been widely adopted by large-scale cloud computing platforms. These virtualized systems employ distributed resource management (DRM) to achieve high resource utilization and energy savings by dynamically migrating and consolidating virtual machines. DRM schemes usually use operating-system-level metrics, such as CPU utilization, memory capacity demand and I/O utilization, to detect and balance resource contention. However, they are oblivious to microarchitecture-level resource interference (e.g., memory bandwidth contention between different VMs running on a host), which is currently not exposed to the operating system.We observe that the lack of visibility into microarchitecture-level resource interference significantly impacts the performance of virtualized systems. Motivated by this observation, we propose a novel architecture-aware DRM scheme (ADRM), that takes into account microarchitecture-level resource interference when making migration decisions in a virtualized cluster. ADRM makes use of three core techniques: 1) a profiler to monitor the microarchitecture-level resource usage behavior online for each physical host, 2) a memory bandwidth interference model to assess the interference degree among virtual machines on a host, and 3) a cost-benefit analysis to determine a candidate virtual machine and a host for migration.Real system experiments on thirty randomly selected combinations of applications from the CPU2006, PARSEC, STREAM, NAS Parallel Benchmark suites in a four-host virtualized cluster show that ADRM can improve performance by up to 26.55\%, with an average of 9.67\%, compared to traditional DRM schemes that lack visibility into microarchitecture-level resource utilization and contention.},
booktitle = {Proceedings of the 11th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments},
pages = {93–106},
numpages = {14},
keywords = {virtualization, microarchitecture, resource management, live migration, performance counters},
location = {Istanbul, Turkey},
series = {VEE '15}
}

@article{10.1145/2817817.2731202,
author = {Wang, Hui and Isci, Canturk and Subramanian, Lavanya and Choi, Jongmoo and Qian, Depei and Mutlu, Onur},
title = {A-DRM: Architecture-Aware Distributed Resource Management of Virtualized Clusters},
year = {2015},
issue_date = {July 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {7},
issn = {0362-1340},
url = {https://doi.org/10.1145/2817817.2731202},
doi = {10.1145/2817817.2731202},
abstract = {Virtualization technologies has been widely adopted by large-scale cloud computing platforms. These virtualized systems employ distributed resource management (DRM) to achieve high resource utilization and energy savings by dynamically migrating and consolidating virtual machines. DRM schemes usually use operating-system-level metrics, such as CPU utilization, memory capacity demand and I/O utilization, to detect and balance resource contention. However, they are oblivious to microarchitecture-level resource interference (e.g., memory bandwidth contention between different VMs running on a host), which is currently not exposed to the operating system.We observe that the lack of visibility into microarchitecture-level resource interference significantly impacts the performance of virtualized systems. Motivated by this observation, we propose a novel architecture-aware DRM scheme (ADRM), that takes into account microarchitecture-level resource interference when making migration decisions in a virtualized cluster. ADRM makes use of three core techniques: 1) a profiler to monitor the microarchitecture-level resource usage behavior online for each physical host, 2) a memory bandwidth interference model to assess the interference degree among virtual machines on a host, and 3) a cost-benefit analysis to determine a candidate virtual machine and a host for migration.Real system experiments on thirty randomly selected combinations of applications from the CPU2006, PARSEC, STREAM, NAS Parallel Benchmark suites in a four-host virtualized cluster show that ADRM can improve performance by up to 26.55\%, with an average of 9.67\%, compared to traditional DRM schemes that lack visibility into microarchitecture-level resource utilization and contention.},
journal = {SIGPLAN Not.},
month = {mar},
pages = {93–106},
numpages = {14},
keywords = {performance counters, microarchitecture, live migration, virtualization, resource management}
}

@inproceedings{10.1145/3285017.3285019,
author = {Meloni, P. and Loi, D. and Deriu, G. and Pimentel, A. D. and Sapra, D. and Moser, B. and Shepeleva, N. and Conti, F. and Benini, L. and Ripolles, O. and Solans, D. and Pintor, M. and Biggio, B. and Stefanov, T. and Minakova, S. and Fragoulis, N. and Theodorakopoulos, I. and Masin, M. and Palumbo, F.},
title = {ALOHA: An Architectural-Aware Framework for Deep Learning at the Edge},
year = {2018},
isbn = {9781450365987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3285017.3285019},
doi = {10.1145/3285017.3285019},
abstract = {Novel Deep Learning (DL) algorithms show ever-increasing accuracy and precision in multiple application domains. However, some steps further are needed towards the ubiquitous adoption of this kind of instrument. First, effort and skills required to develop new DL models, or to adapt existing ones to new use-cases, are hardly available for small- and medium-sized businesses. Second, DL inference must be brought at the edge, to overcome limitations posed by the classically-used cloud computing paradigm. This requires implementation on low-energy computing nodes, often heterogenous and parallel, that are usually more complex to program and to manage. This work describes the ALOHA framework, that proposes a solution to these issue by means of an integrated tool flow that automates most phases of the development process. The framework introduces architecture-awareness, considering the target inference platform very early, already during algorithm selection, and driving the optimal porting of the resulting embedded application. Moreover it considers security, power efficiency and adaptiveness as main objectives during the whole development process.},
booktitle = {Proceedings of the Workshop on INTelligent Embedded Systems Architectures and Applications},
pages = {19–26},
numpages = {8},
keywords = {convolutional neural networks, deep learning, computer aided design},
location = {Turin, Italy},
series = {INTESA '18}
}

@article{10.1145/2675353,
author = {Chen, Jinzhu and Tan, Rui and Wang, Yu and Xing, Guoliang and Wang, Xiaorui and Wang, Xiaodong and Punch, Bill and Colbry, Dirk},
title = {A Sensor System for High-Fidelity Temperature Distribution Forecasting in Data Centers},
year = {2014},
issue_date = {February 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {2},
issn = {1550-4859},
url = {https://doi.org/10.1145/2675353},
doi = {10.1145/2675353},
abstract = {Data centers have become a critical computing infrastructure in the era of cloud computing. Temperature monitoring and forecasting are essential for preventing server shutdowns because of overheating and improving a data center’s energy efficiency. This article presents a novel cyber-physical approach for temperature forecasting in data centers, one that integrates Computational Fluid Dynamics (CFD) modeling, in situ wireless sensing, and real-time data-driven prediction. To ensure forecasting fidelity, we leverage the realistic physical thermodynamic models of CFD to generate transient temperature distribution and calibrate it using sensor feedback. Both simulated temperature distribution and sensor measurements are then used to train a real-time prediction algorithm. As a result, our approach reduces not only the computational complexity of online temperature modeling and prediction, but also the number of deployed sensors, which enables a portable, noninvasive thermal monitoring solution that does not rely on the infrastructure of a monitored data center. We extensively evaluated the proposed system on a rack of 15 servers and a testbed of five racks and 229 servers in a small-scale production data center. Our results show that our system can predict the temperature evolution of servers with highly dynamic workloads at an average error of 0.52○C, within a duration up to 10 minutes. Moreover, our approach can reduce the required number of sensors by 67\% while maintaining desirable prediction fidelity.},
journal = {ACM Trans. Sen. Netw.},
month = {dec},
articleno = {30},
numpages = {25},
keywords = {computational fluid dynamics, cyber-physical system, temperature prediction, Data center, wireless sensor network}
}

@inproceedings{10.1145/3200947.3208069,
author = {Georgakopoulos, Spiros V. and Tasoulis, Sotiris K. and Vrahatis, Aristidis G. and Plagianakos, Vassilis P.},
title = {Convolutional Neural Networks for Toxic Comment Classification},
year = {2018},
isbn = {9781450364331},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3200947.3208069},
doi = {10.1145/3200947.3208069},
abstract = {Flood of information is produced in a daily basis through the global internet usage arising from the online interactive communications among users. While this situation contributes significantly to the quality of human life, unfortunately it involves enormous dangers, since online texts with high toxicity can cause personal attacks, online harassment and bullying behaviors. This has triggered both industrial and research community in the last few years while there are several attempts to identify an efficient model for online toxic comment prediction. However, these steps are still in their infancy and new approaches and frameworks are required. On parallel, the data explosion that appears constantly, makes the construction of new machine learning computational tools for managing this information, an imperative need. Thankfully advances in hardware, cloud computing and big data management allow the development of Deep Learning approaches appearing very promising performance so far. For text classification in particular the use of Convolutional Neural Networks (CNN) have recently been proposed approaching text analytics in a modern manner emphasizing in the structure of words in a document. In this work, we employ this approach to discover toxic comments in a large pool of documents provided by a current Kaggle's competition regarding Wikipedia's talk page edits. To justify this decision we choose to compare CNNs against the traditional bag-of-words approach for text analysis combined with a selection of algorithms proven to be very effective in text classification. The reported results provide enough evidence that CNN enhance toxic comment classification reinforcing research interest towards this direction.},
booktitle = {Proceedings of the 10th Hellenic Conference on Artificial Intelligence},
articleno = {35},
numpages = {6},
keywords = {CNN for Text Mining, Word Embeddings, word2vec, Text Classification, Text mining, Toxic Text Classification, Convolutional Neural Networks},
location = {Patras, Greece},
series = {SETN '18}
}

@inproceedings{10.1145/3313150.3313228,
author = {Tange, Koen and De Donno, Michele and Fafoutis, Xenofon and Dragoni, Nicola},
title = {Towards a Systematic Survey of Industrial IoT Security Requirements: Research Method and Quantitative Analysis},
year = {2019},
isbn = {9781450366984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313150.3313228},
doi = {10.1145/3313150.3313228},
abstract = {Industry 4.0 and, in particular, Industrial Internet of Things (IIoT) represent two of the major automation and data exchange trends of the 21st century, driving a steady increase in the number of smart embedded devices used by industrial applications. However, IoT devices suffer from numerous security flaws, resulting in a number of large scale cyber-attacks. In this light, Fog computing, a relatively new paradigm born from the necessity of bridging the gap between Cloud computing and IoT, can be used as a security solution for the IIoT. To achieve this, the first step is to clearly identify the security requirements of the IIoT that can be subsequently used to design security solutions based on Fog computing. With this in mind, our paper represents a preliminary work towards a systematic literature review of IIoT security requirements. We focus on two key steps of the review: (1) the research method that will be used in the systematic work and (2) a quantitative analysis of the results produced by the study selection process. This lays the necessary foundations to enable the use of Fog computing as a security solution for the IIoT.},
booktitle = {Proceedings of the Workshop on Fog Computing and the IoT},
pages = {56–63},
numpages = {8},
keywords = {industry 4.0, fog computing, security, systematic literature review, industrial internet of things, IIoT},
location = {Montreal, Quebec, Canada},
series = {IoT-Fog '19}
}

@inproceedings{10.1145/2846012.2846052,
author = {Norta, Alex and Othman, Anis Ben and Taveter, Kuldar},
title = {Conflict-Resolution Lifecycles for Governed Decentralized Autonomous Organization Collaboration},
year = {2015},
isbn = {9781450340700},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2846012.2846052},
doi = {10.1145/2846012.2846052},
abstract = {Recent blockchain-technology related innovations enable the governance of collaborating decentralized autonomous organizations (DAO) to engage in agile business-network collaborations that are based on the novel concept of smart contracting. DAOs utilize service-oriented cloud computing in a loosely coupled collaboration lifecycle with the main steps of setup, enactment, possible rollbacks and finally, an orderly termination. This lifecycle supports the selection of services provided and used by DAOs, smart contract negotiations, and behavior monitoring during enactment with the potential for breach management. Based on a sound understanding of the collaboration lifecycle in a Governance- as-a-Service (GaaS)-platform, a new type of conflict management must safeguard business-semantics induced consistency rules. This conflict management involves breach detection with recovery aspects. To fill the detected gap, we employ a formal design-notation that comprises the definition of structural and behavioral properties for exploring conflict-related exception- and compensation management during a decentralized collaboration. With the formal approach, we generate a highly dependable DAO-GaaS conflict model that does not collapse under left-behind clutter such as orphaned processes and exponentially growing database entries that require an unacceptable periodic GaaS reset.},
booktitle = {Proceedings of the 2015 2nd International Conference on Electronic Governance and Open Society: Challenges in Eurasia},
pages = {244–257},
numpages = {14},
keywords = {smart contract, business process, conflict resolution, service orientation, e-governance, Industry 4.0, open cloud ecosystem, Decentralized autonomous organization},
location = {St. Petersburg, Russian Federation},
series = {EGOSE '15}
}

@inproceedings{10.5555/2722129.2722142,
author = {Buchet, Micka\"{e}l and Chazal, Fr\'{e}d\'{e}ric and Oudot, Steve Y. and Sheehy, Donald R.},
title = {Efficient and Robust Persistent Homology for Measures},
year = {2015},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
abstract = {A new paradigm for point cloud data analysis has emerged recently, where point clouds are no longer treated as mere compact sets but rather as empirical measures. A notion of distance to such measures has been defined and shown to be stable with respect to perturbations of the measure. This distance can easily be computed pointwise in the case of a point cloud, but its sublevel-sets, which carry the geometric information about the measure, remain hard to compute or approximate. This makes it challenging to adapt many powerful techniques based on the Euclidean distance to a point cloud to the more general setting of the distance to a measure on a metric space.We propose an efficient and reliable scheme to approximate the topological structure of the family of sublevel-sets of the distance to a measure. We obtain an algorithm for approximating the persistent homology of the distance to an empirical measure that works in arbitrary metric spaces. Precise quality and complexity guarantees are given with a discussion on the behavior of our approach in practice.},
booktitle = {Proceedings of the Twenty-Sixth Annual ACM-SIAM Symposium on Discrete Algorithms},
pages = {168–180},
numpages = {13},
location = {San Diego, California},
series = {SODA '15}
}

@proceedings{10.1145/2676733,
title = {MW4NG '14: Proceedings of the 9th Workshop on Middleware for Next Generation Internet Computing},
year = {2014},
isbn = {9781450332224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {While dependability and security become cornerstones of the information society, they are impaired by change, imprecision, and emerging behavior due to scale, dynamism, and heterogeneity. To address these challenges for next generation Internet computing, key extrafunctional properties should not be an "add on" or an "end to end task" anymore, but rather built in by means of Middleware.Service oriented computing, cloud computing, socio-technical systems, and Web 2.0-style applications are important steps for next generation Internet computing, but still fall short when non functional (a.k.a. extra-functional) quality properties (e.g., dependability, security, performance, and scalability) need to be addressed. The emerging Internet communication architecture (e.g., from projects on the Internet of Things, the Future Internet, etc.) also requires middleware support for delivering computing applications and services. We can see many Internet Computing systems following proprietary end-to-end solutions and being weaved with application-specific approaches. This clearly hinders re-use, which can only be successfully leveraged by Middleware-based solutions. This in turn requires new flexibility for Middleware (adaptivity, elasticity, resilience) and new ways of collaboration between Middleware and applications/services.Therefore, extra-functional quality properties need to be addressed not only by interfacing and communication standards, but also in terms of actual mechanisms, protocols, and algorithms. Some of the challenges are the administrative heterogeneity, the loose coupling between coarsegrained operations and long-running interactions, high dynamism, and the required flexibility during run-time. Recently, massive-scale (e.g., big data, millions of participating parties in different roles) and mobility were added to the crucial challenges for Internet computing middleware. The workshop consequently comprises contributions on how specifically middleware can address the above challenges of next generation Internet computing.},
location = {Bordeaux, France}
}

@inproceedings{10.1145/3017680.3017820,
author = {Siever, Bill and Rogers, Michael P.},
title = {An IoTa of IoT (Abstract Only)},
year = {2017},
isbn = {9781450346986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3017680.3017820},
doi = {10.1145/3017680.3017820},
abstract = {Internet of Things (IoT) devices -- networked microcontrollers with attached sensors and outputs (LEDs, actuators, etc.) -- are becoming ubiquitous in the home (e.g., smart light bulbs, security systems), on the road (e.g., smart parking meters, traffic control), in industry (e.g., equipment monitoring, asset tracking) and in healthcare (e.g., fitness monitors, drug monitors). Consequently, IoT provides an opportunity to demonstrate the pervasiveness and social relevance of computing. Moreover, today's hobbyist- oriented IoT platforms empower entry-level students to create meaningful, real-world IoT applications. This allows rich computer science topics, such as event driven programming, concurrency, networking, information representation, cloud computing, etc., to be introduced earlier in the curriculum. Most importantly, IoT examples provide a compelling context for students to hone their critical thinking skills while solving engaging, real-world problems. Faculty interested in including IoT topics face several challenges: selecting a suitable set of topics, identifying an appropriate pedagogical approach, and, perhaps most daunting, choosing a cost-effective platform that lends itself to classroom use. This workshop will introduce the basic terms and technologies in IoT, discuss issues that arise when including IoT topics in classes, compare and contrast the most popular platforms for IoT, and walk participants through several classroom-tested, hands-on examples using a classroom-friendly platform (Particle's Photon) where they create both Wi-Fi-based IoT devices and corresponding web apps. Participants will need a laptop (any OS) with Internet access.},
booktitle = {Proceedings of the 2017 ACM SIGCSE Technical Symposium on Computer Science Education},
pages = {742},
numpages = {1},
keywords = {CS1, IoT, intro. C.S.},
location = {Seattle, Washington, USA},
series = {SIGCSE '17}
}

@inproceedings{10.1145/3318464.3383130,
author = {Khandelwal, Anurag and Kejariwal, Arun and Ramasamy, Karthikeyan},
title = {Le Taureau: Deconstructing the Serverless Landscape \&amp; A Look Forward},
year = {2020},
isbn = {9781450367356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318464.3383130},
doi = {10.1145/3318464.3383130},
abstract = {Akin to the natural evolution of programming in assembly language to high-level languages, serverless computing represents the next frontier in the evolution of cloud computing: bare metal -&gt; virtual machines -&gt; containers -&gt; serverless. The genesis of serverless computing can be traced back to the fundamental need of enabling a programmer to singularly focus on writing application code in a high-level language and isolating all facets of system management (for example, but not limited to, instance selection, scaling, deployment, logging, monitoring, fault tolerance and so on). This is particularly critical in light of today's, increasingly tightening, time-to-market constraints. Currently, serverless computing is supported by leading public cloud vendors, such as AWS Lambda, Google Cloud Functions, Azure Cloud Functions and others. While this is an important step in the right direction, there are many challenges going forward. For instance, but not limited to, how to enable support for dynamic optimization, how to extend support for stateful computation, how to efficiently bin-pack applications, how to support hardware heterogeneity (this will be key especially in light of the emergence of hardware accelerators for deep learning workloads). Inspired by Picasso's Le Taureau, in the tutorial proposed herein, we shall deconstruct evolution of serverless --- the overarching intent being to facilitate better understanding of the serverless landscape. This, we hope, would help push the innovation frontier on both fronts, the paradigm itself and the applications built atop of it.},
booktitle = {Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data},
pages = {2641–2650},
numpages = {10},
keywords = {ephemeral storage, distributed systems, serverless computing, real-time streaming, data analytics, cloud computing},
location = {Portland, OR, USA},
series = {SIGMOD '20}
}

@article{10.1145/3019596,
author = {Kistowski, J\'{o}akim Von and Herbst, Nikolas and Kounev, Samuel and Groenda, Henning and Stier, Christian and Lehrig, Sebastian},
title = {Modeling and Extracting Load Intensity Profiles},
year = {2017},
issue_date = {February 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {4},
issn = {1556-4665},
url = {https://doi.org/10.1145/3019596},
doi = {10.1145/3019596},
abstract = {Today’s system developers and operators face the challenge of creating software systems that make efficient use of dynamically allocated resources under highly variable and dynamic load profiles, while at the same time delivering reliable performance. Autonomic controllers, for example, an advanced autoscaling mechanism in a cloud computing context, can benefit from an abstracted load model as knowledge to reconfigure on time and precisely. Existing workload characterization approaches have limited support to capture variations in the interarrival times of incoming work units over time (i.e., a variable load profile). For example, industrial and scientific benchmarks support constant or stepwise increasing load, or interarrival times defined by statistical distributions or recorded traces. These options show shortcomings either in representative character of load variation patterns or in abstraction and flexibility of their format.In this article, we present the Descartes Load Intensity Model (DLIM) approach addressing these issues. DLIM provides a modeling formalism for describing load intensity variations over time. A DLIM instance is a compact formal description of a load intensity trace. DLIM-based tools provide features for benchmarking, performance, and recorded load intensity trace analysis. As manually obtaining and maintaining DLIM instances becomes time consuming, we contribute three automated extraction methods and devised metrics for comparison and method selection. We discuss how these features are used to enhance system management approaches for adaptations during runtime, and how they are integrated into simulation contexts and enable benchmarking of elastic or adaptive behavior.We show that automatically extracted DLIM instances exhibit an average modeling error of 15.2\% over 10 different real-world traces that cover between 2 weeks and 7 months. These results underline DLIM model expressiveness. In terms of accuracy and processing speed, our proposed extraction methods for the descriptive models are comparable to existing time series decomposition methods. Additionally, we illustrate DLIM applicability by outlining approaches of workload modeling in systems engineering that employ or rely on our proposed load intensity modeling formalism.},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = {jan},
articleno = {23},
numpages = {28},
keywords = {load profile, model extraction, Load intensity variation, transformation, metamodeling, open workloads}
}

@proceedings{10.1145/2859889,
title = {ICPE '16 Companion: Companion Publication for ACM/SPEC on International Conference on Performance Engineering},
year = {2016},
isbn = {9781450341479},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The 7th ACM/SPEC International Conference on Performance Engineering (ICPE 2016) takes place in Delft in The Netherlands in March 2016. The conference grew out of the ACM Workshop on Software Performance (WOSP since 1998) and the SPEC International Performance Engineering Workshop (SIPEW since 2008), with the goal of integrating theory and practice in the field of performance engineering. It is a great pleasure for us to offer an outstanding technical program this year, which we believe will allow researchers and practitioners to present their visions and latest innovation, and to exchange ideas within the community.Overall, we received 89 high quality submissions across all three tracks. The main Research Track attracted 57 submissions with 19 accepted (33\% acceptance rate) for presentation at the conference. Among them were 16 full papers and three short papers. Each paper received at least three reviews from experienced program committee members. In the Work-In-Progress and Vision Track, six out of 15 contributions were selected. The Industry and Experience Track received 17 submissions, of which seven were selected for inclusion in the program. The accepted papers were organized into five research track sessions, two industry track sessions, and one WiP and vision track session. Three best paper candidates were also selected: two research papers and one industry paper.We are proud to have three excellent keynote speakers as part of our technical program: Bianca Schroeder from University of Toronto, Canada, presenting "Case studies from the real world: The importance of measurement and analysis in building better systems"Wilhelm Hasselbring from Kiel University, Germany, discussing "Microservices for Scalability"Angelo Corsaro, Chief Technology Officer at PrismTech, talking about "Cloudy, Foggy and Misty Internet of Things"In addition, the program includes four tutorials, a doctoral symposium, a poster and demo track, the SPEC Distinguished Dissertation Award, and three interesting workshops, including the International Workshop on Large-Scale Testing (LT), the 2nd International Workshop on Performance Analysis of Big data Systems (PABS), and the 2nd Workshop on Challenges in Performance Methods for Software Development (WOSPC).The program covers traditional ICPE topics such as software and systems performance modeling and prediction, analysis and optimization, characterization and profiling, as well as application of performance engineering theory and techniques to several practical fields, including distributed systems, cloud computing, storage, energy, big data, virtualized systems and containers.},
location = {Delft, The Netherlands}
}

@proceedings{10.1145/2851553,
title = {ICPE '16: Proceedings of the 7th ACM/SPEC on International Conference on Performance Engineering},
year = {2016},
isbn = {9781450340809},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The 7th ACM/SPEC International Conference on Performance Engineering (ICPE 2016) takes place in Delft in The Netherlands in March 2016. The conference grew out of the ACM Workshop on Software Performance (WOSP since 1998) and the SPEC International Performance Engineering Workshop (SIPEW since 2008), with the goal of integrating theory and practice in the field of performance engineering. It is a great pleasure for us to offer an outstanding technical program this year, which we believe will allow researchers and practitioners to present their visions and latest innovation, and to exchange ideas within the community.Overall, we received 89 high quality submissions across all three tracks. The main Research Track attracted 57 submissions with 19 accepted (33\% acceptance rate) for presentation at the conference. Among them were 16 full papers and three short papers. Each paper received at least three reviews from experienced program committee members. In the Work-In-Progress and Vision Track, six out of 15 contributions were selected. The Industry and Experience Track received 17 submissions, of which seven were selected for inclusion in the program. The accepted papers were organized into five research track sessions, two industry track sessions, and one WiP and vision track session. Three best paper candidates were also selected: two research papers and one industry paper.We are proud to have three excellent keynote speakers as part of our technical program: Bianca Schroeder from University of Toronto, Canada, presenting "Case studies from the real world: The importance of measurement and analysis in building better systems"Wilhelm Hasselbring from Kiel University, Germany, discussing "Microservices for Scalability"Angelo Corsaro, Chief Technology Officer at PrismTech, talking about "Cloudy, Foggy and Misty Internet of Things"In addition, the program includes four tutorials, a doctoral symposium, a poster and demo track, the SPEC Distinguished Dissertation Award, and three interesting workshops, including the International Workshop on Large-Scale Testing (LT), the 2nd International Workshop on Performance Analysis of Big data Systems (PABS), and the 2nd Workshop on Challenges in Performance Methods for Software Development (WOSPC).The program covers traditional ICPE topics such as software and systems performance modeling and prediction, analysis and optimization, characterization and profiling, as well as application of performance engineering theory and techniques to several practical fields, including distributed systems, cloud computing, storage, energy, big data, virtualized systems and containers.},
location = {Delft, The Netherlands}
}

@article{10.1145/3264284,
author = {Squillante, Mark S.},
title = {Session Details: Special Issue on the Workshop on MAthematical Performance Modeling and Analysis (MAMA 2014)},
year = {2014},
issue_date = {September 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {2},
issn = {0163-5999},
url = {https://doi.org/10.1145/3264284},
doi = {10.1145/3264284},
abstract = {The complexity of computer systems, networks and applications, as well as the advancements in computer technology, continue to grow at a rapid pace. Mathematical analysis, modeling and optimization have been playing, and continue to play, an important role in research studies to investigate fundamental issues and trade-offs at the core of performance problems in the design and implementation of complex computer systems, networks and applications.On June 20, 2014, the 16th Workshop on MAthematical performance Modeling and Analysis (MAMA 2014) was held in Austin TX, USA, sponsored by ACM SIGMETRICS, and held in conjunction with SIGMETRICS 2014. This workshop seeks to bring together researchers working on the mathematical, methodological and theoretical aspects of performance analysis, modeling and optimization. It is intended to provide a forum at SIGMETRICS conferences for talks on early research in the more mathematical areas of computer performance analysis. These talks tend to be based on very recent research results (including work in progress) or on new research results that will be otherwise submitted only to a journal (or recently have been submitted to a journal). Thus, part of the goal is to complement and supplement the SIGMETRICS Conference program with such talks without removing any theoretical contributions from the main technical program. Furthermore, we continue to experience the desired result of having abstracts from previous MAMA workshops appear as full papers in the main program of subsequent SIGMETRICS and related conferences.All submissions were reviewed by at least 4 members of the program committee, from which a total of 13 were selected for presentation at the MAMA 2014 workshop. This special issue of Performance Evaluation Review includes extended abstracts relating to these presentations (arranged in the order of their presentation), which cover a wide range of topics in the area of mathematical performance analysis, modeling and optimization.The study of Gelenbe examines the backlog of energy and of data packets in a sensor node that harvests energy, computing the properties of energy and data backlogs and discussing system stability. Meyfroyt derives asymptotic results for the coverage ratio under a specific class of spatial stochastic models (Cooperative Sequential Adsorption) and investigates the scalability of the Trickle communication protocol algorithm. The study of Tune and Roughan applies the principle of maximum entropy to develop fast traffic matrix synthesis models, with the future goal of developing realistic spatio-temporal traffic matrices. Bradonji\'{c} et al. compare and contrast the capacity, congestion and reliability requirements for alternative connectivity models of large-scale data centers relative to fat trees. The study of Rochman et al. considers the problem of resource placement in network applications, based on a largescale service faced with regionally distributed demands for various resources in cloud computing. Xie and Lui investigate the design and analysis of a rating system and a mechanism to encourage users to participate in crowdsourcing and to incentivize workers to develop high-quality solutions. The study of Asadi et al. formulates a general problem for the joint per-user mode selection, connection activation and resource scheduling of connections using both LTE and WiFi resources within the context of device-todevice communications. Zheng and Tan consider a nonconvex joint rate and power control optimization to achieve egalitarian fairness (max-min weighted fairness) in wireless networks, exploiting the nonlinear Perron-Frobenius theory and nonnegative matrix theory. The study of Goldberg et al. derives an asymptotically optimal control policy for a stochastic capacity problem of dynamically matching supply resources and uncertain demand, based on connections with lost-sales inventory models. Ghaderi et al. investigate a dynamic stochastic bin packing problem, analyzing the fluid limits of the system under an asymptotic best-fit algorithm and showing it asymptotically minimizes the number of servers used in steady state. The study of Tizghadam and Leon-Garcia examines the impact of overlaying or removing a subgraph on the Moore-Penrose inverse of the Laplacian matrix of an existing network topology and proposes an iterative method to find key performance measures. Miyazawa considers a two-node generalized Jackson network in a phase-type setting as a special case of a Markov-modulated twodimensional reflecting random walk and analyzes the tail asymptotics for this reflecting process. The study of Squillante et al. investigates improvement in scalability of search in networks through the use of multiple random walks, deriving bounds on the hitting time to a set of nodes and on various performance metrics.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {sep},
numpages = {1}
}

@proceedings{10.1145/3183713,
title = {SIGMOD '18: Proceedings of the 2018 International Conference on Management of Data},
year = {2018},
isbn = {9781450347037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our pleasure to share with you the proceedings of SIGMOD 2018, the 44th ACM SIGMOD International Conference on Management of Data, in Houston, Texas. For many people, the words 'Houston, Texas' conjure up images of cowboy hats and oil rigs. This is not without reason. More than 20 Fortune 500 oil and gas companies are headquartered in Houston, and Texas beef is legendary. But less appreciated is that Houston is a vibrant and diverse city. By the usual metrics it is the most racially and ethnically diverse city in the United States. That diversity helps to make Houston a foodie's paradise, with wonderful Mexican, Tex-Mex, Vietnamese, and Chinese restaurants, and great Southern options, such as soul food and Cajun. Not to mention the best Texas-style barbecue!The SIGMOD conference is being held at the Marriott Marquis Houston, overlooking downtown Houston's Discovery Green park. Adjacent to Discovery Green are Minute Maid Park and the Toyota Center, home of baseball's Houston Astros and basketball's Houston Rockets, respectively. The conference banquet is at Minute Maid Park. Downtown Houston is a short car or train ride from great Houston museum district attractions such as the Menil Collection and the world-class shopping of the Houston Galleria area. And to repeat, everywhere you go in Houston, you'll find great food!This year's technical program features 90 research papers selected from 461 submissions, 15 industrial papers selected from 40 submissions, two invited industrial papers, 35 demonstration papers selected from 108 submissions, and 5 tutorials selected from 14 submissions (two of which were merged into a 2-session tutorial). There are 15 research sessions, 4 industry sessions, an invited special session, and two demonstration sessions. The two invited keynotes were chosen to broaden the SIGMOD community's understanding of areas having a major effect on data management: Eric Brewer, VP of Infrastructure at Google and faculty member at UC Berkeley, talking about the effect of container technology on cloud computing; and Pedro Domingos, Professor at University of Washington, talking about machine learning-what works, what doesn't, and where the field is headed. Like last year, the keynotes are followed by a plenary session of teaser talks, where each presenter gives a one-minute summary of their paper, to give attendees a high-level view of the conference and help them decide which sessions to attend.There are two changes in the session organization from recent years, whose goal is to make the program more compact and interesting for attendees. First, tutorials are presented during the main conference on Tuesday through Thursday, rather than on Friday after the main conference is over. Second, to ensure there are at most four parallel sessions in each time slot, each research paper presentation is allocated either 20 minutes or 10 minutes. The decision of long vs. short presentations had several phases. During the reviewing process, PC members were asked to recommend whether each paper, if accepted, should be a long or short presentation. Then research PC group leaders made a recommendation for each of the accepted papers they supervised -- definitely 20 minutes, 20 minutes if there's time available, borderline, or definitely 10 minutes -- based on reviews, reviewer discussions, and their own judgment, without knowing the identity of authors. Their recommendation is not necessarily a quality metric. They recommended 'definitely 10' for some papers highly-rated by reviewers, because the topic was narrow, could be explained in 10 minutes, or couldn't be explained in 20 minutes so extra time wouldn't help. For borderline papers, the final decision was based on many factors, such as topic diversity, institutional diversity, and the time available in the relevant session.The Research Program Committee consisted of a Program Chair, two Program Vice Chairs, 15 group leaders, and 173 Program Committee Members. There were two rounds of submissions, with deadlines in July and November, respectively. Initially, each paper received three reviews. Additional reviews were solicited in cases where the reviewers did not have enough confidence, or where there was a significant score discrepancy in the first three reviews. Papers were extensively discussed online. Of the 458 submissions, 20 were desk rejected (i.e., without reviews), 9 were accepted based on the first round of reviews, and 327 were rejected. Authors of the remaining 102 papers were asked to revise their papers to address reviewers' criticisms; 81 of those revisions were ultimately accepted. While the entire program committee worked hard to select an excellent program, the chairs and area leaders are especially grateful to the following program committee members for their very high quality work on the committee: Ashraf Aboulnaga, Manos Athanassoulis, Sebastian Breβ, Graham Cormode, Sudipto Das, Khuzaima Daudjee, Aaron Elmore, Ada Fu, Michael Hay, Yuxiong He, Yannis Katsis, Alexandra Meliou, Dan Olteanu, Andrew Pavlo, Peter Pietzuch, Lucian Popa, Semih Salihoglu, Ryan Stutsman, Yufei Tao, and Alexander Thomson.The program also includes industry papers, demonstrations, tutorials, workshops, a Student Research Competition, and a New Researcher Symposium. We thank the organizers of all the technical events, including research PC vice-chairs Xin Luna Dong and Mohamed Mokbel, industrial PC chairs Samuel Madden and Neoklis Polyzotis, demonstration chairs Georgia Koutrika and Feifei Li, tutorial chairs Ihab Ilyas and Stratis Viglas, workshop chairs Ihab Ilyas and Benny Kimelfeld, Student Research Competition chairs Alvin Cheung and Jana Giceva, and New Research Symposium chairs Katja Hose and Eugene Wu. We are also grateful to the CMT team, who modified their reviewing system to accommodate new aspects of this year's PC process.},
location = {Houston, TX, USA}
}

@inproceedings{10.1145/3151848.3151850,
author = {Karadimce, Aleksandar and Davcev, Danco},
title = {Bayesian Network Model for Estimating User Satisfaction of Multimedia Cloud Services},
year = {2017},
isbn = {9781450353007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3151848.3151850},
doi = {10.1145/3151848.3151850},
abstract = {The focus of this research is given to find a metric and determine the quality of the offered multimedia cloud services from an end users perception. The Quality of Experience (QoE) has been introduced to measure the quality features, which is used to determine the end-to-end user perceived quality of the used multimedia service. In this study, we have used students satisfaction survey, which provides direct subjective data on need, habits, and frequency of using different multimedia services. This data has been used for validation of the proposed Bayesian Network model for interactive estimation of the acceptability of multimedia cloud services based on the user preferences.},
booktitle = {Proceedings of the 15th International Conference on Advances in Mobile Computing \&amp; Multimedia},
pages = {3–12},
numpages = {10},
keywords = {survey evaluation, Bayesian Network, mobile cloud services, Quality of Experience},
location = {Salzburg, Austria},
series = {MoMM2017}
}

@inproceedings{10.1145/3329391,
author = {Esposito, Christian and Pop, Florin and Choi, Chang},
title = {Session Details: Theme: Information Systems: SFECS - Sustainability of Fog/Edge Computing Systems Track},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3329391},
doi = {10.1145/3329391},
abstract = {Fog/Edge Computing paradigms are widely used in enterprises to address the emerging challenges of big data analysis, because of their underlying scalable, flexible and distributed data management schemes. The data centers in the Clouds are facing great challenges on the burden of the consequent increasing the amount of data to be man- aged and the additional requirements of location awareness and low latency at the edge of network necessary by smart cites and factories. These are the reasons why a centralized model cannot be an efficient solution for generated or required data by the IoT devices in those applications and there is the progressive shift towards fog nodes and smarted edge nodes mediating between the cloud and the IoT devices. The Fog/Edge computing paradigm is a decentralized model that transfers a part of low computing data analysis from the cloud to the intermediate (fog) nodes or the edges, performing only high computing tasks in the cloud. This new approach tries to minimize the three factors that negatively compromise the effective and efficient application of the Cloud computing to smart cities and factories, or similar application domains: the network bandwidth usage, decentralization of the data processing tasks and reduced response latency for clients (IoT devices). Fog/Edge computing is a hierarchical approach where the overall infrastructure is structured in multiple layers, each responsible of offering a good coordination and data management to the nodes at the lower layer. The lowest layer is usually composed of sensors and/or actuators that measure and/or control the environment or a given business process, implemented as mobile devices that are running a sensing/controlling application. In this case, combining Sustainable computing with Fog and Edge computing represents a new approach for increasing quality-of- service and efficiency of the system, creating the capability to present temporal and geo-coded information, and increasing innovation, and co-designing sustainable future large scale distributed systems. This new paradigm appears to offer a good approach in handling the scale factor of the data size, reducing the network bandwidth usage and the response latency of the system. In order to support specifically the Fog/Edge architectures, there is a need, for instance, of location-awareness and computation placement, replication and recovery. In many cases Edge resources would be required for both computation and data storage to address the time and locality constraints. There are multiple kinds of orchestration management solutions for virtualization in this type of architecture with different characteristics and drawbacks. This results in different restrictions for application definition, scalability, availability, load balancing and so on. Also, virtualization may be needed at multiple levels in a Fog/Edge architecture as it consists of the following levels of abstraction: at the sensing level we have the IoT devices/smart things, at the Edge level there are the gateways to a first collection and the data from the IoT devices and their preliminary processing, at the Fog level we have an additional data management layer, and at the Cloud level there is the compute/storage infrastructure with applications on top. Last, but not least, the energy efficiency is particularly important at the IoT and edge level since the devices may be equipped with a limited battery, possible difficult or impossible to be charged. So, optimizing the energy consumption is a must. To address several open research is- sues regarding sustainability of future Fog/Edge systems, this track aims at solicit contributions highlighting challenges, state-of-the-art, and solutions to a set of currently unresolved key questions including - but not limited to - performance, modeling, optimization, energy-efficiency, reliability, security, privacy and techno-economic aspects of Fog/Edge systems. Through addressing these concerns while understanding their impacts and limitations, technological advancements will be channeled toward more sustainable/efficient platforms for tomorrow's ever-connected systems.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1145/2713168.2723146,
author = {Pegus, Patrick and Cecchet, Emmanuel and Shenoy, Prashant},
title = {Video BenchLab Demo: An Open Platform for Video Realistic Streaming Benchmarking},
year = {2015},
isbn = {9781450333511},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2713168.2723146},
doi = {10.1145/2713168.2723146},
abstract = {In this demonstration, we present an open, flexible and realistic benchmarking platform named Video BenchLab to measure the performance of streaming media workloads. While Video BenchLab can be used with any existing media server, we provide a set of tools for researchers to experiment with their own platform and protocols. The components include a MediaDrop video server, a suite of tools to bulk insert videos and generate streaming media workloads, a dataset of freely available video and a client runtime to replay videos in the native video players of real Web browsers such as Firefox, Chrome and Internet Explorer. Various metrics are collected to capture the quality of video playback and identify issues that can happen during video replay. Finally, we provide a Dashboard to manage experiments, collect results and perform analytics to compare performance between experiments.The demonstration showcases all the BenchLab video components including a MediaDrop server accessed by real web browsers running locally and in the cloud. We demo the whole experiment lifecycle from creation to deployment as well as result collection and analysis.},
booktitle = {Proceedings of the 6th ACM Multimedia Systems Conference},
pages = {101–104},
numpages = {4},
keywords = {benchmarking, video, web browsers, streaming},
location = {Portland, Oregon},
series = {MMSys '15}
}

@inproceedings{10.1145/3183767.3183776,
author = {Nobre, Ricardo and Reis, Lu\'{\i}s and Bispo, Jo\~{a}o and Carvalho, Tiago and Cardoso, Jo\~{a}o M.P. and Cherubin, Stefano and Agosta, Giovanni},
title = {Aspect-Driven Mixed-Precision Tuning Targeting GPUs},
year = {2018},
isbn = {9781450364447},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183767.3183776},
doi = {10.1145/3183767.3183776},
abstract = {Writing mixed-precision kernels allows to achieve higher throughput together with outputs whose precision remain within given limits. The recent introduction of native half-precision arithmetic capabilities in several GPUs, such as NVIDIA P100 and AMD Vega 10, contributes to make precision-tuning even more relevant as of late. However, it is not trivial to manually find which variables are to be represented as half-precision instead of single- or double-precision. Although the use of half-precision arithmetic can speed up kernel execution considerably, it can also result in providing non-usable kernel outputs, whenever the wrong variables are declared using the half-precision data-type. In this paper we present an automatic approach for precision tuning. Given an OpenCL kernel with a set of inputs declared by a user (i.e., the person responsible for programming and/or tuning the kernel), our approach is capable of deriving the mixed-precision versions of the kernel that are better improve upon the original with respect to a given metric (e.g., time-to-solution, energy-to-solution). We allow the user to declare and/or select a metric to measure and to filter solutions based on the quality of the output. We implement a proof-of-concept of our approach using an aspect-oriented programming language called LARA. It is capable of generating mixed-precision kernels that result in considerably higher performance when compared with the original single-precision floating-point versions, while generating outputs that can be acceptable in some scenarios.},
booktitle = {Proceedings of the 9th Workshop and 7th Workshop on Parallel Programming and RunTime Management Techniques for Manycore Architectures and Design Tools and Architectures for Multicore Embedded Computing Platforms},
pages = {26–31},
numpages = {6},
keywords = {mixed-precision, aspect-driven, GPGPU},
location = {Manchester, United Kingdom},
series = {PARMA-DITAM '18}
}

@article{10.1145/3437881,
author = {Huang, Chun-ying and Cheng, Yun-chen and Huang, Guan-zhang and Fan, Ching-ling and Hsu, Cheng-hsin},
title = {On the Performance Comparisons of Native and Clientless Real-Time Screen-Sharing Technologies},
year = {2021},
issue_date = {May 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {2},
issn = {1551-6857},
url = {https://doi.org/10.1145/3437881},
doi = {10.1145/3437881},
abstract = {Real-time screen-sharing provides users with ubiquitous access to remote applications, such as computer games, movie players, and desktop applications (apps), anywhere and anytime. In this article, we study the performance of different screen-sharing technologies, which can be classified into native and clientless ones. The native ones dictate that users install special-purpose software, while the clientless ones directly run in web browsers. In particular, we conduct extensive experiments in three steps. First, we identify a suite of the most representative native and clientless screen-sharing technologies. Second, we propose a systematic measurement methodology for comparing screen-sharing technologies under diverse and dynamic network conditions using different performance metrics. Last, we conduct extensive experiments and perform in-depth analysis to quantify the performance gap between clientless and native screen-sharing technologies. We found that our WebRTC-based implementation achieves the best overall performance. More precisely, it consumes a maximum of 3 Mbps bandwidth while reaching a high decoding ratio and delivering good video quality. Moreover, it leads to a steadily high decoding ratio and video quality under dynamic network conditions. By presenting the very first rigorous comparisons of the native and clientless screen-sharing technologies, this article will stimulate more exciting studies on the emerging clientless screen-sharing technologies.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = {may},
articleno = {54},
numpages = {26},
keywords = {performance optimization, performance evaluations, measurements, Live video streaming, real-time encoding}
}

@inproceedings{10.1109/CCGrid.2016.56,
author = {Ibrahim, Abdallah Ali Zainelabden A. and Kliazovich, Dzmitry and Bouvry, Pascal},
title = {Service Level Agreement Assurance between Cloud Services Providers and Cloud Customers},
year = {2016},
isbn = {9781509024520},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGrid.2016.56},
doi = {10.1109/CCGrid.2016.56},
abstract = {Cloud services providers deliver cloud services to cloud customers on pay-per-use model while the quality of the provided services are defined using service level agreements also known as SLAs. Unfortunately, there is no standard mechanism which exists to verify and assure that delivered services satisfy the signed SLA agreement in an automatic way. There is no guarantee in terms of quality. Those applications have many performance metrics. In this doctoral thesis, we propose a framework for SLA assurance, which can be used by both cloud providers and cloud users. Inside the proposed framework, we will define the performance metrics for the different applications. We will assess the applications performance in different testing environment to assure good services quality as mentioned in SLA. The proposed framework will be evaluated through simulations and using testbed experiments. After testing the applications performance by measuring the performance metrics, we will review the time correlations between those metrics.},
booktitle = {Proceedings of the 16th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
pages = {588–591},
numpages = {4},
keywords = {applications, cloud computing, performance, data centers, quality of experience, metrics, quality of services, service level agreement, simulation},
location = {Cartagena, Columbia},
series = {CCGRID '16}
}

@article{10.1109/TNET.2016.2614129,
author = {Zhao, Zhiwei and Dong, Wei and Bu, Jiajun and Gu, Tao and Min, Geyong},
title = {Accurate and Generic Sender Selection for Bulk Data Dissemination in Low-Power Wireless Networks},
year = {2017},
issue_date = {April 2017},
publisher = {IEEE Press},
volume = {25},
number = {2},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2016.2614129},
doi = {10.1109/TNET.2016.2614129},
abstract = {Data dissemination is a fundamental service offered by low-power wireless networks. Sender selection is the key to the dissemination performance and has been extensively studied. Sender impact metric plays a significant role in sender selection, since it determines which senders are selected for transmission. Recent studies have shown that spatial link diversity has a significant impact on the efficiency of broadcast. However, the existing metrics overlook such impact. Besides, they consider only gains but ignore the costs of sender candidates. As a result, existing works cannot achieve accurate estimation of the sender impact. Moreover, they cannot well support data dissemination with network coding, which is commonly used for lossy environments. In this paper, we first propose a novel sender impact metric, namely,  $gamma $ , which jointly exploits link quality and spatial link diversity to calculate the gain/cost ratio of the sender candidates. Then, we develop a generic sender selection scheme based on the  $gamma $  metric called  $gamma $ -component that can generally support both types of dissemination using native packets and network coding. Extensive evaluations are conducted through real testbed experiments and large-scale simulations. The performance results and analysis show that  $gamma $  achieves far more accurate impact estimation than the existing works. In addition, the dissemination protocols based on  $gamma $ -component outperform the existing protocols in terms of completion time and transmissions by 20.5\% and 23.1\%, respectively.},
journal = {IEEE/ACM Trans. Netw.},
month = {apr},
pages = {948–959},
numpages = {12}
}

@article{10.1145/2998454,
author = {Li, Ning and Jiang, Hong and Feng, Dan and Shi, Zhan},
title = {Customizable SLO and Its Near-Precise Enforcement for Storage Bandwidth},
year = {2017},
issue_date = {February 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {1553-3077},
url = {https://doi.org/10.1145/2998454},
doi = {10.1145/2998454},
abstract = {Cloud service is being adopted as a utility for large numbers of tenants by renting Virtual Machines (VMs). But for cloud storage, unpredictable IO characteristics make accurate Service-Level-Objective (SLO) enforcement challenging. As a result, it has been very difficult to support simple-to-use and technology-agnostic SLO specifying a particular value for a specific metric (e.g., storage bandwidth). This is because the quality of SLO enforcement depends on performance error and fluctuation that measure the precision of SLO enforcement. High precision of SLO enforcement is critical for user-oriented performance customization and user experiences. To address this challenge, this article presents V-Cup, a framework for VM-oriented customizable SLO and its near-precise enforcement. It consists of multiple auto-tuners, each of which exports an interface for a tenant to customize the desired storage bandwidth for a VM and enable the storage bandwidth of the VM to converge on the target value with a predictable precision. We design and implement V-Cup in the Xen hypervisor based on the fair sharing scheduler for VM-level resource management. Our V-Cup prototype evaluation shows that it achieves satisfying performance guarantees through near-precise SLO enforcement.},
journal = {ACM Trans. Storage},
month = {feb},
articleno = {6},
numpages = {25},
keywords = {end-to-end control, storage management, Cloud storage, service-level objective}
}

@inproceedings{10.1145/2713168.2723145,
author = {Pegus, Patrick and Cecchet, Emmanuel and Shenoy, Prashant},
title = {Video BenchLab: An Open Platform for Realistic Benchmarking of Streaming Media Workloads},
year = {2015},
isbn = {9781450333511},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2713168.2723145},
doi = {10.1145/2713168.2723145},
abstract = {In this paper, we present an open, flexible and realistic benchmarking platform named Video BenchLab to measure the performance of streaming media workloads. While Video BenchLab can be used with any existing media server, we provide a set of tools for researchers to experiment with their own platform and protocols. The components include a MediaDrop video server, a suite of tools to bulk insert videos and generate streaming media workloads, a dataset of freely available video and a client runtime to replay videos in the native video players of real Web browsers such as Firefox, Chrome and Internet Explorer. We define simple metrics that are able to capture the quality of video playback and identify issues that can happen during video replay. Finally, we provide a Dashboard to manage experiments, collect results and perform analytics to compare performance between experiments.We present a series of experiments with Video BenchLab to illustrate how the video specific metrics can be used to measure the user perceived experience in real browsers when streaming videos. We also show Internet scale experiments by deploying clients in data centers distributed all over the globe. All the software, datasets, workloads and results used in this paper are made freely available on SourceForge for anyone to reuse and expand.},
booktitle = {Proceedings of the 6th ACM Multimedia Systems Conference},
pages = {165–176},
numpages = {12},
keywords = {benchmarking, web browsers, streaming, video},
location = {Portland, Oregon},
series = {MMSys '15}
}

@article{10.1145/3093893,
author = {Garc\'{\i}a-Dorado, Jos\'{e} Luis},
title = {Bandwidth Measurements within the Cloud: Characterizing Regular Behaviors and Correlating Downtimes},
year = {2017},
issue_date = {November 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {1533-5399},
url = {https://doi.org/10.1145/3093893},
doi = {10.1145/3093893},
abstract = {The search for availability, reliability, and quality of service has led cloud infrastructure customers to disseminate their services, contents, and data over multiple cloud data centers, often involving several Cloud service providers (CSPs). The consequence of this is that a large amount of data must be transmitted across the public Cloud. However, little is known about the bandwidth dynamics involved. To address this, we have conducted a measurement campaign for bandwidth between 18 data centers of four major CSPs. This extensive campaign allowed us to characterize the resulting time series of bandwidth as the addition of a stationary component and some infrequent excursions (typically downtimes). While the former provides a description of the bandwidth users can expect in the Cloud, the latter is closely related to the robustness of the Cloud (i.e., the occurrence of downtimes is correlated). Both components have been studied further by applying factor analysis, specifically analysis of variance, as a mechanism to formally compare data centers’ behaviors and extract generalities. The results show that the stationary process is closely related to the data center locations and CSPs involved in transfers that, fortunately, make the Cloud more predictable and allow the set of reported measurements to be extrapolated. On the other hand, although correlation in the Cloud is low, that is, only 10\% of the measured pair of paths showed some correlation, we found evidence that such correlation depends on the particular relationships between pairs of data centers with little connection to more general factors. Positively, this implies that data centers either in the same area or within the same CSP do not show qualitatively more correlation than other data centers, which eases the deployment of robust infrastructures. On the downside, this metric is scarcely generalizable and, consequently, calls for exhaustive monitoring.},
journal = {ACM Trans. Internet Technol.},
month = {aug},
articleno = {39},
numpages = {25},
keywords = {inter-cloud, TCP bandwidth, Public cloud, traffic correlation, ANOVA}
}

@article{10.1109/TNET.2018.2851379,
author = {Al-Abbasi, Abubakr O. and Aggarwal, Vaneet},
title = {Video Streaming in Distributed Erasure-Coded Storage Systems: Stall Duration Analysis},
year = {2018},
issue_date = {August 2018},
publisher = {IEEE Press},
volume = {26},
number = {4},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2018.2851379},
doi = {10.1109/TNET.2018.2851379},
abstract = {The demand for global video has been burgeoning across industries. With the expansion and improvement of video-streaming services, cloud-based video is evolving into a necessary feature of any successful business for reaching internal and external audiences. This paper considers video streaming over distributed systems where the video segments are encoded using an erasure code for better reliability, thus being the first work to our best knowledge that considers video streaming over erasure-coded distributed cloud systems. The download time of each coded chunk of each video segment is characterized, and the ordered statistics over the choice of the erasure-coded chunks is used to obtain the playback time of different video segments. Using the playback times, bounds on the moment generating function on the stall duration are used to bound the mean stall duration. Moment generating function-based bounds on the ordered statistics are also used to bound the stall duration tail probability, which determines the probability that the stall time is greater than a pre-defined number. These two metrics, mean stall duration and the stall duration tail probability, are important quality of experience QoE measures for the end users. Based on these metrics, we formulate an optimization problem to jointly minimize the convex combination of both the QoE metrics averaged over all requests over the placement and access of the video content. The non-convex problem is solved using an efficient iterative algorithm. Numerical results show a significant improvement in QoE metrics for cloud-based video compared to the considered baselines.},
journal = {IEEE/ACM Trans. Netw.},
month = {aug},
pages = {1921–1932},
numpages = {12}
}

@inproceedings{10.1145/2882903.2882943,
author = {Kalyvianaki, Evangelia and Fiscato, Marco and Salonidis, Theodoros and Pietzuch, Peter},
title = {THEMIS: Fairness in Federated Stream Processing under Overload},
year = {2016},
isbn = {9781450335317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2882903.2882943},
doi = {10.1145/2882903.2882943},
abstract = {Federated stream processing systems, which utilise nodes from multiple independent domains, can be found increasingly in multi-provider cloud deployments, internet-of-things systems, collaborative sensing applications and large-scale grid systems. To pool resources from several sites and take advantage of local processing, submitted queries are split into query fragments, which are executed collaboratively by different sites. When supporting many concurrent users, however, queries may exhaust available processing resources, thus requiring constant load shedding. Given that individual sites have autonomy over how they allocate query fragments on their nodes, it is an open challenge how to ensure global fairness on processing quality experienced by queries in a federated scenario.We describe THEMIS, a federated stream processing system for resource-starved, multi-site deployments. It executes queries in a globally fair fashion and provides users with constant feedback on the experienced processing quality for their queries. THEMIS associates stream data with its source information content (SIC), a metric that quantifies the contribution of that data towards the query result, based on the amount of source data used to generate it. We provide the BALANCE-SIC distributed load shedding algorithm that balances the SIC values of result data. Our evaluation shows that the BALANCE-SIC algorithm yields balanced SIC values across queries, as measured by Jain's Fairness Index. Our approach also incurs a low execution time overhead.},
booktitle = {Proceedings of the 2016 International Conference on Management of Data},
pages = {541–553},
numpages = {13},
keywords = {tuple shedding, approximate data processing, fairness, federated data stream processing},
location = {San Francisco, California, USA},
series = {SIGMOD '16}
}

@inproceedings{10.1145/3147234.3148103,
author = {Roloff, Eduardo and Diener, Matthias and Carre\~{n}o, Emmanuell D. and Moreira, Francis B. and Gaspary, Luciano P. and Navaux, Philippe O.A.},
title = {Exploiting Price and Performance Tradeoffs in Heterogeneous Clouds},
year = {2017},
isbn = {9781450351959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3147234.3148103},
doi = {10.1145/3147234.3148103},
abstract = {Parallel applications are composed of several tasks, which have different computational demands among them. Moreover, most cloud providers offer multiple instance configurations, with large variations of computational power and cost. A combination between the application requirements and the variety of instance types of the cloud could be explored to improve the cost efficiency of the application execution. In this paper, we introduce the cost-delay product as a metric to measure the cost efficiency of cloud systems. With this metric, cloud tenants can evaluate different tradeoffs between cost and performance for their application, depending on their preferences. We explore the use of multiple instance types to create heterogeneous cluster systems in the cloud. Our results show that heterogeneous clouds can have a better cost efficiency than homogeneous systems, reducing the price of execution while maintaining a similar application performance. Furthermore, by comparing the cost-delay product, the user can select an instance mix that is most suitable for his needs.},
booktitle = {Companion Proceedings of The10th International Conference on Utility and Cloud Computing},
pages = {71–76},
numpages = {6},
keywords = {cost efficiency, cloud computing, performance, heterogeneity},
location = {Austin, Texas, USA},
series = {UCC '17 Companion}
}

@inproceedings{10.1145/2872427.2883053,
author = {Zhou, Ke and Redi, Miriam and Haines, Andrew and Lalmas, Mounia},
title = {Predicting Pre-Click Quality for Native Advertisements},
year = {2016},
isbn = {9781450341431},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872427.2883053},
doi = {10.1145/2872427.2883053},
abstract = {Native advertising is a specific form of online advertising where ads replicate the look-and-feel of their serving platform. In such context, providing a good user experience with the served ads is crucial to ensure long-term user engagement. In this work, we explore the notion of ad quality, namely the effectiveness of advertising from a user experience perspective. We design a learning framework to predict the pre-click quality of native ads. More specifically, we look at detecting offensive native ads, showing that, to quantify ad quality, ad offensive user feedback rates are more reliable than the commonly used click-through rate metrics. We then conduct a crowd-sourcing study to identify which criteria drive user preferences in native advertising. We translate these criteria into a set of ad quality features that we extract from the ad text, image and advertiser, and then use them to train a model able to identify offensive ads. We show that our model is very effective in detecting offensive ads, and provide in-depth insights on how different features affect ad quality. Finally, we deploy a preliminary version of such model and show its effectiveness in the reduction of the offensive ad feedback rate.},
booktitle = {Proceedings of the 25th International Conference on World Wide Web},
pages = {299–310},
numpages = {12},
keywords = {ad quality, ad feedback, image and text, pre-click experience, native advertising, features, offensive rate},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16}
}

@inproceedings{10.1109/IPSN.2018.00030,
author = {Islam, Bashima and Islam, Md Tamzeed and Nirjon, Shahriar},
title = {A Motion-Triggered Stereo Camera for 3D Experience Capture: Demo Abstract},
year = {2018},
isbn = {9781538652985},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IPSN.2018.00030},
doi = {10.1109/IPSN.2018.00030},
abstract = {This demo is an implementation of our motion-triggered camera system that captures, processes, stores, and transmits 3D visual information of a real-world environment using a low-cost camera-based sensor system that is constrained by its limited processing capability, storage, and battery life. This system can be used in applications such as capturing and sharing 3D content in the social media, training people in different professions, and post-facto analysis of an event. This system uses off-the-shelf hardware and standard computer vision algorithms. Its novelty lies in the ability to optimally control camera data acquisition and processing stages to guarantee the desired quality of captured information and battery life. The design of the controller is based on extensive measurements and modeling of the relationships between the linear and angular motion of a camera and the quality of generated 3D point clouds as well as the battery life of the system. To achieve this, we 1) devise a new metric to quantify the quality of generated 3D point clouds, 2) formulate an optimization problem to find an optimal trigger point for the camera system and prolongs its battery life while maximizing the quality of captured 3D environment, and 3) make the model adaptive so that the system evolves and its performance improves over time.},
booktitle = {Proceedings of the 17th ACM/IEEE International Conference on Information Processing in Sensor Networks},
pages = {134–135},
numpages = {2},
location = {Porto, Portugal},
series = {IPSN '18}
}

@inproceedings{10.1109/IPSN.2018.00046,
author = {Islam, Bashima and Islam, Md Tamzeed and Nirjon, Shahriar},
title = {Glimpse.3D: A Motion-Triggered Stereo Body Camera for 3D Experience Capture and Preview},
year = {2018},
isbn = {9781538652985},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IPSN.2018.00046},
doi = {10.1109/IPSN.2018.00046},
abstract = {The Glimpse.3D is a body-worn camera that captures, processes, stores, and transmits 3D visual information of a real-world environment using a low cost camera-based sensor system that is constrained by its limited processing capability, storage, and battery life. The 3D content is viewed on a mobile device such as a smartphone or a virtual reality headset. This system can be used in applications such as capturing and sharing 3D content in the social media, training people in different professions, and post-facto analysis of an event. Glimpse.3D uses off-the-shelf hardware and standard computer vision algorithms. Its novelty lies in the ability to optimally control camera data acquisition and processing stages to guarantee the desired quality of captured information and battery life. The design of the controller is based on extensive measurements and modeling of the relationships between the linear and angular motion of a body-worn camera and the quality of generated 3D point clouds as well as the battery life of the system. To achieve this, we 1) devise a new metric to quantify the quality of generated 3D point clouds, 2) formulate an optimization problem to find an optimal trigger point for the camera system that prolongs its battery life while maximizing the quality of captured 3D environment, and 3) make the model adaptive so that the system evolves and its performance improves over time.},
booktitle = {Proceedings of the 17th ACM/IEEE International Conference on Information Processing in Sensor Networks},
pages = {176–187},
numpages = {12},
keywords = {3D-reconstruction, body camera},
location = {Porto, Portugal},
series = {IPSN '18}
}

@inproceedings{10.1145/3383812.3383838,
author = {Pacot, Mark Phil B. and Marcos, Nelson},
title = {Cloud Removal from Aerial Images Using Generative Adversarial Network with Simple Image Enhancement},
year = {2020},
isbn = {9781450377201},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383812.3383838},
doi = {10.1145/3383812.3383838},
abstract = {The atmospheric condition of the presence of clouds is one of the biggest problems in most aerial imaging systems. It degrades the visual quality of images leading to the loss of information for ground scenes. Hence, an effective cloud removal algorithm is a significant factor for this kind of problem and other related applications. The proposed cloud removal technique using the generative adversarial network with simple image enhancement (SIE-GAN) is a useful tool in removing cloud formations, most notably in images acquired using Unmanned Aerial Vehicle System (UAVs). This technique showed flexibility in performing the given task with satisfactory results, which is a gauge based on No-Reference Image Quality Metric, specifically the Perception-based Image Quality Evaluator (PIQE). Also, the proposed algorithm outperformed some of existing cloud removal algorithms by producing a better quality output when tested on the too-cloudy satellite images. Overall, the authors introduced a new frontier in generating cloud-free aerial images and added a valuable contribution to the array of cloud removal algorithms.},
booktitle = {Proceedings of the 2020 3rd International Conference on Image and Graphics Processing},
pages = {77–81},
numpages = {5},
keywords = {generative adversarial network, cloud removal, simple image enhancement, no-reference image quality metric, unmanned aerial vehicle system},
location = {Singapore, Singapore},
series = {ICIGP '20}
}

@inproceedings{10.1109/AST.2019.000-2,
author = {Martinez-Ortiz, Andres-Leonardo and Lizcano, David and Ortega, Miguel},
title = {Software Metrics Artifacts Making Web Quality Measurable: AST 2019 Invited Paper},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/AST.2019.000-2},
doi = {10.1109/AST.2019.000-2},
abstract = {Mining open source repositories introduces an effective approach to put in practice empirical software engineering in a variety of technologies. Kernel development (Linux) first and then Internet (Chromium) and more recently cloud orchestration (Kubernetes) and machine learning (TensorFlow) are fundamental pieces not just for open source ecosystem but also for the industry leading software innovation. Empirical software engineering sustains a better understanding of these projects, reducing even more the barriers for adoption. In this work we focus on empirical quality assessment developing software metrics artifacts to make web components quality measurable. After reviewing the state of the art and main frameworks for software measurement, we will present our proposal for the empirical evaluation of quality metrics for web components, data collection, measurement and prediction, discussing main benefits and some drawback of the selected approach, which will be aimed at future works.},
booktitle = {Proceedings of the 14th International Workshop on Automation of Software Test},
pages = {1–6},
numpages = {6},
keywords = {software engineering, web technologies, open source, quality metrics},
location = {Montreal, Quebec, Canada},
series = {AST '19}
}

@inproceedings{10.1145/3319647.3325849,
author = {Nagin, Kenneth and Kassis, Andre and Lorenz, Dean and Barabash, Katherine and Raichstein, Eran},
title = {Estimating Client QoE from Measured Network QoS},
year = {2019},
isbn = {9781450367493},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3319647.3325849},
doi = {10.1145/3319647.3325849},
abstract = {This research is done in the context of the SliceNet project [4] that aims to extend 5G infrastructure with cognitive management of cross-domain, cross-layer network slices [1], with emphasis on Quality of Experience (QoE) for vertical industries. The provisioning of network slices with proper QoE guarantees is seen as one of the key enablers of future 5G-enabled networks. The challenge is to assess the QoE experienced by the vertical application and its users without requiring the applications or the users to measure and report QoE related metrics back to the provider. To address this challenge, we propose a method for deriving application-level QoE from network-level Quality of Service (QoS) measurements, easily accessible by the provider. In particular, we describe a PoC where QoE, perceived by application users, is estimated from low level network monitoring data, by applying cognitive methods. Our main goal is enabling the cloud provider to support the desired E2E QoE-based Service Level Agreements (SLAs), e.g. by monitoring QoS metrics within the provider's domain to optimize resource allocation through provider's actuators. Additional benefit can be achieved by applying the same technique to troubleshoot issues in the provider's infrastructure. In this work, we employed classical statistical methods to assess the relationship between the application-level QoE and the network-level QoS.},
booktitle = {Proceedings of the 12th ACM International Conference on Systems and Storage},
pages = {188},
numpages = {1},
location = {Haifa, Israel},
series = {SYSTOR '19}
}

@inproceedings{10.1145/2649563.2649571,
author = {Weber, Andreas and Herbst, Nikolas and Groenda, Henning and Kounev, Samuel},
title = {Towards a Resource Elasticity Benchmark for Cloud Environments},
year = {2014},
isbn = {9781450330596},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2649563.2649571},
doi = {10.1145/2649563.2649571},
abstract = {Auto-scaling features offered by today's cloud infrastructures provide increased flexibility especially for customers that experience high variations in the load intensity over time. However, auto-scaling features introduce new system quality attributes when considering their accuracy, timing, and boundaries. Therefore, distinguishing between different offerings has become a complex task, as it is not yet supported by reliable metrics and measurement approaches. In this paper, we discuss shortcomings of existing approaches for measuring and evaluating elastic behavior and propose a novel benchmark methodology specifically designed for evaluating the elasticity aspects of modern cloud platforms. The benchmark is based on open workloads with realistic load variation profiles that are calibrated to induce identical resource demand variations independent of the underlying hardware performance. Furthermore, we propose new metrics that capture the accuracy of resource allocations and de-allocations, as well as the timing aspects of an auto-scaling mechanism explicitly.},
booktitle = {Proceedings of the 2nd International Workshop on Hot Topics in Cloud Service Scalability},
articleno = {5},
numpages = {8},
keywords = {Supply, Load Profile, Resource, Demand, Elasticity},
location = {Dublin, Ireland},
series = {HotTopiCS '14}
}

@inproceedings{10.1145/3466772.3467048,
author = {Kassir, Saadallah and de Veciana, Gustavo and Wang, Nannan and Wang, Xi and Palacharla, Paparao},
title = {Joint Update Rate Adaptation in Multiplayer Cloud-Edge Gaming Services: Spatial Geometry and Performance Tradeoffs},
year = {2021},
isbn = {9781450385589},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3466772.3467048},
doi = {10.1145/3466772.3467048},
abstract = {In this paper, we analyze the performance of Multiplayer Cloud Gaming (MCG) systems. To that end, we introduce a model and new MCG-Quality of Service (QoS) metric that captures the freshness of the players' updates and fairness in their gaming experience. We introduce an efficient measurement-based Joint Multiplayer Rate Adaptation (JMRA) algorithm that optimizes the MCG-QoS by overcoming large (possibly varying) network transport delays by increasing the associated players' update rates. The resulting MCG-QoS is shown to be Schur-concave in the network delays, leading to natural characterizations and performance comparisons associated with the players' spatial geometry and network congestion. In particular, joint rate adaptation enables service providers to combat variability in network delays and players' geographic spread to achieve high service coverage. This, in turn, allows us to explore the spatial density and capacity of compute resources that need to be provisioned. Finally, we leverage tools from majorization theory, to show how service placement decisions can be made to improve the robustness of the MCG-QoS to stochastic network delays.},
booktitle = {Proceedings of the Twenty-Second International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing},
pages = {191–200},
numpages = {10},
keywords = {Multiplayer Cloud Gaming, Service Placement, Network Resource Provisioning, Rate Adaptation, Edge Computing},
location = {Shanghai, China},
series = {MobiHoc '21}
}

@inproceedings{10.5555/2755535.2755542,
author = {Huang, Chun-Ying and Chen, Po-Han and Huang, Yu-Ling and Chen, Kuan-Ta and Hsu, Cheng-Hsin},
title = {Measuring the Client Performance and Energy Consumption in Mobile Cloud Gaming},
year = {2014},
publisher = {IEEE Press},
abstract = {Mobile cloud gaming allows gamers to play games on resource-constrained mobile devices, and a measurement study to quality the client performance and energy consumption is crucial to attract and retain the gamers. In this paper, we adopt an open source cloud gaming platform to conduct extensive experiments on real mobile clients. Our experiment results show two major findings that are of interests to researchers, developers, and gamers. First, compared to mobile native games, mobile cloud games save energy by up to 30\%. Second, the frame rate, bit rate, and resolution all affect the decoders' resource consumption, while frame rate imposes the highest impact. These findings shed some light on the further enhancements of the emerging mobile cloud gaming platforms.},
booktitle = {Proceedings of the 13th Annual Workshop on Network and Systems Support for Games},
articleno = {5},
numpages = {3},
location = {Nagoya, Japan},
series = {NetGames '14}
}

