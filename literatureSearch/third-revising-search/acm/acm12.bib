@inproceedings{10.1145/3531056.3542769,
author = {Mwotil, Alex and Bainomugisha, Engineer and Araka, Stephen G.M.},
title = {Mira: An Application Containerisation Pipeline for Small Software Development Teams in Low Resource Settings},
year = {2022},
isbn = {9781450396639},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531056.3542769},
doi = {10.1145/3531056.3542769},
abstract = {Cloud native applications leverage Development and Operation (DevOps), microservice architectures and containerisation for primarily availability, resilience and scalability reasons. Small developer teams in low resource settings have unique DevOps needs and harnessing its principles and practices is technically challenging and distinctly difficult in these contexts. We conducted a survey with professional developers, students and researchers situated and working in a low resource setting and the results indicate that these principles and practices are relatively new. In application containerisation, an operating system virtualisation method that can significantly optimize the use of computing resources, the respondents indicated challenges in the process steps. Particularly, small developer teams in low resource settings require custom tools and abstractions for software development and delivery automation. Informed by the developer needs, we designed and developed a custom automated containerisation pipeline, mira, for a managed cloud native platform situated in a low-resource setting. We validate mira against 6 major application frameworks, tools and/or languages and successful deployment of the resultant applications onto a cloud native platform.},
booktitle = {Proceedings of the Federated Africa and Middle East Conference on Software Engineering},
pages = {31–38},
numpages = {8},
keywords = {cloud, cloud native, orchestration, automation, containers, docker},
location = {Cairo-Kampala, Egypt},
series = {FAMECSE '22}
}

@inproceedings{10.1145/3603269.3604872,
author = {Habib, Rumaisa and Tanveer, Sarah and Inam, Aimen and Ahmed, Haseeb and Ali, Ayesha and Uzmi, Zartash Afzal and Qazi, Zafar Ayyub and Qazi, Ihsan Ayyub},
title = {A Framework for Improving Web Affordability and Inclusiveness},
year = {2023},
isbn = {9798400702365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603269.3604872},
doi = {10.1145/3603269.3604872},
abstract = {Today's Web remains too expensive for many Internet users, especially in developing regions. Unfortunately, the rising complexity of the Web makes affordability an even bigger concern as it stands to limit users' access to Internet services. We propose a novel framework and a fairness metric for rethinking Web architecture for affordability and inclusion. Our proposed framework systematically adapts Web complexity based on geographic variations in mobile broadband prices and income levels. We conduct a cross-country analysis of 99 countries, showing that our framework can better balance affordability and webpage quality while preserving user privacy. To adapt Web complexity, our framework solves an optimization problem to produce webpages that maximize page quality while reducing the webpage to a given target size.},
booktitle = {Proceedings of the ACM SIGCOMM 2023 Conference},
pages = {592–607},
numpages = {16},
keywords = {inclusion, user privacy, transcoding service, web, affordability},
location = {New York, NY, USA},
series = {ACM SIGCOMM '23}
}

@inproceedings{10.1145/3511808.3557068,
author = {Li, Sen and Lv, Fuyu and Jin, Taiwei and Li, Guiyang and Zheng, Yukun and Zhuang, Tao and Liu, Qingwen and Zeng, Xiaoyi and Kwok, James and Ma, Qianli},
title = {Query Rewriting in TaoBao Search},
year = {2022},
isbn = {9781450392365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511808.3557068},
doi = {10.1145/3511808.3557068},
abstract = {In e-commerce search engines, query rewriting (QR) is a crucial technique that improves shopping experience by reducing the vocabulary gap between user queries and product catalog. Recent works have mainly adopted the generative paradigm. However, they hardly ensure high-quality generated rewrites and do not consider personalization, which leads to degraded search relevance. In this work, we present Contrastive Learning Enhanced Query Rewriting (CLE-QR), the solution used in Taobao product search. It uses a novel contrastive learning enhanced architecture based on "query retrieval-semantic relevance ranking-online ranking". It finds the rewrites from hundreds of millions of historical queries while considering relevance and personalization. Specifically, we first alleviate the representation degeneration problem during the query retrieval stage by using an unsupervised contrastive loss, and then further propose an interaction-aware matching method to find the beneficial and incremental candidates, thus improving the quality and relevance of candidate queries. We then present a relevance-oriented contrastive pre-training paradigm on the noisy user feedback data to improve semantic ranking performance. Finally, we rank these candidates online with the user profile to model personalization for the retrieval of more relevant products. We evaluate CLE-QR on Taobao Product Search, one of the largest e-commerce platforms in China. Significant metrics gains are observed in online A/B tests. CLE-QR has been deployed to our large-scale commercial retrieval system and serviced hundreds of millions of users since December 2021. We also introduce its online deployment scheme, and share practical lessons and optimization tricks of our lexical match system.},
booktitle = {Proceedings of the 31st ACM International Conference on Information \&amp; Knowledge Management},
pages = {3262–3271},
numpages = {10},
keywords = {e-commerce search, query rewriting, lexical match},
location = {Atlanta, GA, USA},
series = {CIKM '22}
}

@inproceedings{10.1145/3582197.3582240,
author = {Gao, Qihong and Wu, Yuxuan and Hao, Yi},
title = {Design and Implementation of an Edge Container Management Platform Based on Artificial Intelligence},
year = {2023},
isbn = {9781450397438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3582197.3582240},
doi = {10.1145/3582197.3582240},
abstract = {The deployment and maintenance of IoT applications require a lot of manual work. To reduce the workload of the operation and maintenance personnel of the edge IoT system and improve the efficiency of edge applications, containerization technology based on K3s is more and more widely used. However, the existing edge container management platforms are not convenient in terms of application deployment and overall maintenance. This paper designs and implements an edge container management platform that supports AI operation and maintenance. In terms of design concepts, the abstract concepts involved in containerization technology are embodied as projects, which are easy to understand. In terms of management and control subsystems, the construction of the overall architecture and the interaction of various modules have been completed, thus, users can conveniently deploy and schedule edge applications and services. In terms of operation and maintenance subsystems, real-time collection, persistence, and analysis of logs, metric data, and trace data at all levels of the system are realized. In terms of visualization, the front-end display and monitoring of the system status are completed, which is convenient for project developers and platform operators to understand the running status of the project and platform in real-time, and provides a better solution for deployment and maintenance of IoT applications.},
booktitle = {Proceedings of the 2022 10th International Conference on Information Technology: IoT and Smart City},
pages = {257–261},
numpages = {5},
keywords = {AIOps, Containerization technology, Edge computing, K3s},
location = {<conf-loc>, <city>Shanghai</city>, <country>China</country>, </conf-loc>},
series = {ICIT '22}
}

@article{10.1145/3480935,
author = {Anzt, Hartwig and Cojean, Terry and Flegar, Goran and G\"{o}bel, Fritz and Gr\"{u}tzmacher, Thomas and Nayak, Pratik and Ribizel, Tobias and Tsai, Yuhsiang Mike and Quintana-Ort\'{\i}, Enrique S.},
title = {Ginkgo: A Modern Linear Operator Algebra Framework for High Performance Computing},
year = {2022},
issue_date = {March 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {1},
issn = {0098-3500},
url = {https://doi.org/10.1145/3480935},
doi = {10.1145/3480935},
abstract = {In this article, we present Ginkgo, a modern C++ math library for scientific high performance computing. While classical linear algebra libraries act on matrix and vector objects, Ginkgo’s design principle abstracts all functionality as “linear operators,” motivating the notation of a “linear operator algebra library.” Ginkgo’s current focus is oriented toward providing sparse linear algebra functionality for high performance graphics processing unit (GPU) architectures, but given the library design, this focus can be easily extended to accommodate other algorithms and hardware architectures. We introduce this sophisticated software architecture that separates core algorithms from architecture-specific backends and provide details on extensibility and sustainability measures. We also demonstrate Ginkgo’s usability by providing examples on how to use its functionality inside the MFEM and deal.ii finite element ecosystems. Finally, we offer a practical demonstration of Ginkgo’s high performance on state-of-the-art GPU architectures.},
journal = {ACM Trans. Math. Softw.},
month = {feb},
articleno = {2},
numpages = {33},
keywords = {High performance computing, multi-core and manycore architectures, healthy software lifecycle}
}

@inproceedings{10.1145/3617023.3617039,
author = {Viegas, Felipe and Canuto, Sergio and Cunha, Washington and Fran\c{c}a, Celso and Valiense, Claudio and Rocha, Leonardo and Gon\c{c}alves, Marcos Andr\'{e}},
title = {CluSent – Combining Semantic Expansion and De-Noising for Dataset-Oriented Sentiment Analysis of Short Texts},
year = {2023},
isbn = {9798400709081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617023.3617039},
doi = {10.1145/3617023.3617039},
abstract = {The lack of sufficient information, mainly in short texts, is a major challenge to building effective sentiment models. Short texts can be enriched with more complex semantic relationships that better capture affective information, with a potential undesired side effect of noise introduced into the data. This work proposes a new strategy for customized dataset-oriented sentiment analysis – CluSent – that exploits a powerful, recently proposed concept for representing semantically related words – CluWords. CluSent tackles the issues mentioned above of information shortage and noise by: (i) exploiting the semantic neighborhood of a given pre-trained word embedding to enrich document representation and (ii) introducing dataset-oriented filtering and weighting mechanisms to cope with noise, which takes advantage of the polarity and intensity information from lexicons. In our experimental evaluation, considering 19 datasets, five state-of-the-art baselines (including modern transformer architectures), and two metrics, CluSent was the best method in 30 out of 38 possibilities, with significant gains over the strongest baselines (over 14\%).},
booktitle = {Proceedings of the 29th Brazilian Symposium on Multimedia and the Web},
pages = {110–118},
numpages = {9},
keywords = {Sentiment Analysis, Classification, Natural Language Processing},
location = {<conf-loc>, <city>Ribeir\~{a}o Preto</city>, <country>Brazil</country>, </conf-loc>},
series = {WebMedia '23}
}

@inproceedings{10.1145/3534678.3539041,
author = {Li, Mingjie and Li, Zeyan and Yin, Kanglin and Nie, Xiaohui and Zhang, Wenchi and Sui, Kaixin and Pei, Dan},
title = {Causal Inference-Based Root Cause Analysis for Online Service Systems with Intervention Recognition},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539041},
doi = {10.1145/3534678.3539041},
abstract = {Fault diagnosis is critical in many domains, as faults may lead to safety threats or economic losses. In the field of online service systems, operators rely on enormous monitoring data to detect and mitigate failures. Quickly recognizing a small set of root cause indicators for the underlying fault can save much time for failure mitigation. In this paper, we formulate the root cause analysis problem as a new causal inference task namedintervention recognition. We proposed a novel unsupervised causal inference-based method namedCausal Inference-based Root Cause Analysis (CIRCA). The core idea is a sufficient condition for a monitoring variable to be a root cause indicator,i.e., the change of probability distribution conditioned on the parents in the Causal Bayesian Network (CBN). Towards the application in online service systems, CIRCA constructs a graph among monitoring metrics based on the knowledge of system architecture and a set of causal assumptions. The simulation study illustrates the theoretical reliability of CIRCA. The performance on a real-world dataset further shows that CIRCA can improve the recall of the top-1 recommendation by 25\% over the best baseline method.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3230–3240},
numpages = {11},
keywords = {online service systems, causal inference, intervention recognition, root cause analysis},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3569966.3571190,
author = {Hu, Wei},
title = {The Design and Implementation of Civil Aviation Meteorological Emergency Service Platform Based on 5G},
year = {2022},
isbn = {9781450397780},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3569966.3571190},
doi = {10.1145/3569966.3571190},
abstract = {In view of the problem that users cannot obtain meteorological data in time due to the interruption of Internet line in the current civil aviation meteorological external service system. Designing and implementing a civil aviation meteorological emergency service platform based on 5G. The platform is built based on C/S architecture. Firstly, designing and implementing the whole business module of the platform, and then establishing the corresponding protective measures for the security of the platform. Finally, deploying the 5G module between the data upload and the client, meanwhile, realizing the underlying switching logic between the Internet and 5G line. The application result shows that due to the use of 5G technology, The platform can provide users with meteorological emergency service in case of Internet interruption},
booktitle = {Proceedings of the 5th International Conference on Computer Science and Software Engineering},
pages = {691–694},
numpages = {4},
keywords = {5G, meteorological service, emergency, civil aviation meteorological},
location = {<conf-loc>, <city>Guilin</city>, <country>China</country>, </conf-loc>},
series = {CSSE '22}
}

@article{10.1145/3587095,
author = {Lee, JunKyu and Mukhanov, Lev and Molahosseini, Amir Sabbagh and Minhas, Umar and Hua, Yang and Martinez del Rincon, Jesus and Dichev, Kiril and Hong, Cheol-Ho and Vandierendonck, Hans},
title = {Resource-Efficient Convolutional Networks: A Survey on Model-, Arithmetic-, and Implementation-Level Techniques},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {13s},
issn = {0360-0300},
url = {https://doi.org/10.1145/3587095},
doi = {10.1145/3587095},
abstract = {Convolutional neural networks (CNNs) are used in our daily life, including self-driving cars, virtual assistants, social network services, healthcare services, and face recognition, among others. However, deep CNNs demand substantial compute resources during training and inference. The machine learning community has mainly focused on model-level optimizations such as architectural compression of CNNs, whereas the system community has focused on implementation-level optimization. In between, various arithmetic-level optimization techniques have been proposed in the arithmetic community. This article provides a survey on resource-efficient CNN techniques in terms of model-, arithmetic-, and implementation-level techniques, and identifies the research gaps for resource-efficient CNN techniques across the three different level techniques. Our survey clarifies the influence from higher- to lower-level techniques based on our resource efficiency metric definition and discusses the future trend for resource-efficient CNN research.},
journal = {ACM Comput. Surv.},
month = {jul},
articleno = {276},
numpages = {36},
keywords = {neural networks, arithmetic utilization, Convolutional neural networks, resource efficiency}
}

@inproceedings{10.1145/3503161.3547883,
author = {Zhang, Jingjing and Fang, Shancheng and Mao, Zhendong and Zhang, Zhiwei and Zhang, Yongdong},
title = {Fine-Tuning with Multi-Modal Entity Prompts for News Image Captioning},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3547883},
doi = {10.1145/3503161.3547883},
abstract = {News Image Captioning aims to generate descriptions for images embedded in news articles, including plentiful real-world concepts, especially about named entities. However, existing methods are limited in the entity-level template. Not only is it labor-intensive to craft the template, but it is error-prone due to local entity-aware, which solely constrains the prediction output at each language model decoding step with corrupted entity relationship. To overcome the problem, we investigate a concise and flexible paradigm to achieve global entity-aware by introducing a prompting mechanism with fine-tuning pre-trained models, named Fine-tuning with Multi-modal Entity Prompts for News Image Captioning (NewsMEP). Firstly, we incorporate two pre-trained models: (i) CLIP, translating the image with open-domain knowledge; (ii) BART, extended to encode article and image simultaneously. Moreover, leveraging the BART architecture, we can easily take the end-to-end fashion. Secondly, we prepend the target caption with two prompts to utilize entity-level lexical cohesion and inherent coherence in the pre-trained language model. Concretely, the visual prompts are obtained by mapping CLIP embeddings, and contextual vectors automatically construct the entity-oriented prompts. Thirdly, we provide an entity chain to control caption generation that focuses on entities of interest. Experiments results on two large-scale publicly available datasets, including detailed ablation studies, show that our NewsMEP not only outperforms state-of-the-art methods in general caption metrics but also achieves significant performance in precision and recall of various named entities.},
booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
pages = {4365–4373},
numpages = {9},
keywords = {fine-tuning, entity prompts, news image captioning, named entity},
location = {<conf-loc>, <city>Lisboa</city>, <country>Portugal</country>, </conf-loc>},
series = {MM '22}
}

@inproceedings{10.1145/3577065.3577094,
author = {Li, Dejian and Cui, Bingrong and Li, Kaixin and Shen, Tianjun and Sun, Yi and Chang, Shaonan},
title = {Energy Efficient Offloading Strategy Faced to Edge Computing-Enhanced Distributed Photovoltaic Smart Meter},
year = {2023},
isbn = {9781450397797},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3577065.3577094},
doi = {10.1145/3577065.3577094},
abstract = {With the rapid development of Power Internet of Things and the increase in the number of distributed photovoltaic smart meter (DPSM) technology, edge computing is required to support the low-latency computing service. Current works mainly focus on task offloading, the cooperation among smart meter devices is lack of attention. In order to reduce the task execution delay in of the network, a computing resource sharing architecture based on D2D is proposed. In order to reduce the processing delay and energy consumption of DPSM, we propose a task offloading model faced to DPSM. To minimize the total task execution delay, we formulate a Mixed-Integer Non-Linear Programming (MINLP) problem which optimizing task offloading and resource allocation jointly. Then, a generalized Benders decomposition algorithm combined with particle swarm optimization is proposed to solve the problem. Simulation results show that the proposed strategy can effectively improve the measurement efficiency and reduce the computational cost.},
booktitle = {Proceedings of the 2022 5th International Conference on Telecommunications and Communication Engineering},
pages = {161–164},
numpages = {4},
keywords = {Edge computing, Cost optimization, Task offloading, Smart meter},
location = {<conf-loc>, <city>Chengdu</city>, <country>China</country>, </conf-loc>},
series = {ICTCE '22}
}

@inproceedings{10.1145/3582016.3582031,
author = {Duraisamy, Padmapriya and Xu, Wei and Hare, Scott and Rajwar, Ravi and Culler, David and Xu, Zhiyi and Fan, Jianing and Kennelly, Christopher and McCloskey, Bill and Mijailovic, Danijela and Morris, Brian and Mukherjee, Chiranjit and Ren, Jingliang and Thelen, Greg and Turner, Paul and Villavieja, Carlos and Ranganathan, Parthasarathy and Vahdat, Amin},
title = {Towards an Adaptable Systems Architecture for Memory Tiering at Warehouse-Scale},
year = {2023},
isbn = {9781450399180},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3582016.3582031},
doi = {10.1145/3582016.3582031},
abstract = {Fast DRAM increasingly dominates infrastructure spend in large scale computing environments and this trend will likely worsen without an architectural shift. The cost of deployed memory can be reduced by replacing part of the conventional DRAM with lower cost albeit slower memory media, thus creating a tiered memory system where both tiers are directly addressable and cached. But, this poses numerous challenges in a highly multi-tenant warehouse-scale computing setting. The diversity and scale of its applications motivates an application-transparent solution in the general case, adaptable to specific workload demands.  

This paper presents TMTS(Transparent Memory Tiering System), an application-transparent memory tiering management system that implements an adaptive, hardware-guided architecture to dynamically optimize access to the various directly-addressed memory tiers without faults. TMTS has been deployed at scale for two years serving thousands of production services, successfully meeting service level objectives (SLOs) across diverse application classes in the fleet. The solution is developed in terms of system level metrics it seeks to optimize and evaluated across the diverse workload mix to guide advanced policies embodied in a user-level agent. It sustains less than 5\% overall performance degradation while replacing 25\% of DRAM with a much slower medium.},
booktitle = {Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
pages = {727–741},
numpages = {15},
keywords = {Memory Tiering, Warehouse-Scale Computing, Memory Management},
location = {Vancouver, BC, Canada},
series = {ASPLOS 2023}
}

@inproceedings{10.1145/3593434.3593442,
author = {Arcelli Fontana, Francesca and Camilli, Mateo and Rendina, Davide and Taraboi, Andrei Gabriel and Trubiani, Catia},
title = {Impact of Architectural Smells on Software Performance: An Exploratory Study},
year = {2023},
isbn = {9798400700446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593434.3593442},
doi = {10.1145/3593434.3593442},
abstract = {Architectural smells have been studied in the literature looking at several aspects, such as their impact on maintainability as a source of architectural debt, their correlations with code smells, and their evolution in the history of complex projects. The goal of this paper is to extend the study of architectural smells from a different perspective. We focus our attention on software performance, and we aim to quantify the impact of architectural smells as support to explain the root causes of system performance hindrances. Our method consists of a study design matching the occurrence of architectural smells with performance metrics. We exploit state-of-the-art tools for architectural smell detection, software performance profiling, and testing the systems under analysis. The removal of architectural smells generates new versions of systems from which we derive some observations on design changes improving/worsening performance metrics. Our experimentation considers two complex open-source projects, and results show that the detection and removal of two common types of architectural smells yield lower response time (up to ) with a large effect size, i.e., for - of the hotspot methods. The median memory consumption is also lower (up to ) with a large effect size for all the services.},
booktitle = {Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering},
pages = {22–31},
numpages = {10},
keywords = {Software Architecture, Software Performance, Architectural Smells},
location = {Oulu, Finland},
series = {EASE '23}
}

@inproceedings{10.1145/3534678.3539132,
author = {Mangrulkar, Sourab and M S, Ankith and Sembium, Vivek},
title = {BE3R: BERT Based Early-Exit Using Expert Routing},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539132},
doi = {10.1145/3534678.3539132},
abstract = {Pre-trained language models like BERT have reported state-of-the-art performance on several Natural Language Processing (NLP) tasks, but high computational demands hinder its widespread adoption for large scale NLP tasks. In this work, we propose a novel routing based early exit model called BE3R (BERT based Early-Exit using Expert Routing), where we learn to dynamically exit in the earlier layers without needing to traverse through the entire model. Unlike the exiting early-exit methods, our approach can be extended to a batch inference setting. We consider the specific application of search relevance filtering in Amazon India marketplace services (a large e-commerce website). Our experimental results show that BE3R improves the batch inference throughput by 46.5\% over the BERT-Base model and 35.89\% over the DistilBERT-Base model on large dataset with 50 Million samples without any trade-off on the performance metric. We conduct thorough experimentation using various architectural choices, loss functions and perform qualitative analysis. We perform experiments on public GLUE Benchmark and demonstrate comparable performance to corresponding baseline models with 23\% average throughput improvement across tasks in batch inference setting.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3504–3512},
numpages = {9},
keywords = {attention models, transformers, relevance classification, natural language processing, deep learning, product search, e-commerce},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3583780.3615494,
author = {Tiady, Sambeet and Majumder, Anirban and Gupta, Deepak},
title = {PRODIGY: Product Design Guidance at Scale},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615494},
doi = {10.1145/3583780.3615494},
abstract = {Growth of e-commerce has enabled the creation of thousands of small-scale brands. However, these brands lack information on a) what new products to develop and b) how to refine existing products to improve on business metrics. We present a comprehensive Product Design Insights and Guidance service (named PRODIGY) that mines product attributes data available on e-commerce platforms and surface insights on a) new product development and b) product refinement. Our core contribution is a novel demand forecasting model for product designs based on a notable extension of the recently proposed FTTransformer architecture combined with a self-supervised pre-training task, akin to Masked Language Modeling (MLM) objective. For the product refinement use-case, we present a novel algorithm by embedding the design search in a data-density approximator, namely Conditional Variational Autoencoder. We run a thorough and comprehensive set of experiments and establish that PRODIGY achieves significant improvement in demand prediction as compared to state-of-the-art alternatives. Finally, we present our findings from an online experiment where PRODIGY helps to launch new products with +20\% lift in sales and +1.3\% lift in product ratings.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {4836–4842},
numpages = {7},
location = {<conf-loc>, <city>Birmingham</city>, <country>United Kingdom</country>, </conf-loc>},
series = {CIKM '23}
}

@inproceedings{10.1145/3578245.3586012,
author = {Pouchard, Line C.},
title = {FAIR Enabling Re-Use of Data-Intensive Workflows and Scientific Reproducibility},
year = {2023},
isbn = {9798400700729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578245.3586012},
doi = {10.1145/3578245.3586012},
abstract = {Scientific computing communities often run their experiments using complex data- and compute-intensive workflows that utilize high performance computing (HPC), distributed clusters and specialized architectures targeting machine learning and artificial intelligence. FAIR principles for data and software can be useful enablers for the reproducibility of performance (a key HPC metric) and that of scientific results (a crucial tenet of the scientific method) that are based in part on re-use, the R of FAIR principles. FAIR principles are under-used by HPC and data-intensive communities who have been slow to adopt them. This is due in part to the complexity of workflow life cycles, the numerous workflow management systems, the lack of integration of FAIR within existing technologies, and the specificity of managed systems that include rapidly evolving architectures and software stacks, and execution models that require resource managers and batch schedulers. Numerous challenges emerge for scientists attempting to publish FAIR datasets and software for the purpose of re-use and reproducibility, e.g. what data to publish and where due to sizes, how to "FAIRify" data subsetting, at what level of granularity to attribute persistent identifiers to software, what is the minimal amount of metadata needed to guarantee a certain level of reproducibility, what does reproducible AI actually mean? This talk will focus on such challenges and illustrate the negative impact of not applying FAIR on the reproducibility of experiments. We will introduce the notion of FAIR Digital Objects and present RECUP, a framework for data and metadata services for high performance workflows that proposes micro-solutions for adapting FAIR principles to HPC.},
booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {329},
numpages = {1},
keywords = {HPC, data intensive, reproducibility, FAIR, RECUP, FDO, high performance computing},
location = {Coimbra, Portugal},
series = {ICPE '23 Companion}
}

@inproceedings{10.1145/3589608.3595081,
author = {Kaven, Sascha and Skwarek, Volker},
title = {Poster: Attribute Based Access Control for IoT Devices in 5G Networks},
year = {2023},
isbn = {9798400701733},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589608.3595081},
doi = {10.1145/3589608.3595081},
abstract = {The deployment of 5G technology has the potential to usher in a new era for the internet of things (IoT). The introduction of new use cases, such as massive machine-type communications (mMTC), referring to a large number of IoT devices, resulting in the increasing importance of 5G as the basic communication infrastructure for IoT. However, the increasing connectivity of IoT devices coincides with a number of risks to security. Many IoT sensors have limited resources and, therefore, cannot perform the complex security measures required to protect them from attacks and data loss. Furthermore, IoT networks are very scattered, distributed and dynamic, so decentralised security measures are required. To address these challenges, this poster proposes the integration of attribute-based access control (ABAC) into the 5G service-based architecture. This approach aims to prevent unauthorized access to IoT devices at the network level, thereby alleviating the computational burden on resource-constrained IoT devices. By implementing ABAC, the proposed solution offers a more efficient method for managing access control within the IoT landscape in the context of 5G networks.},
booktitle = {Proceedings of the 28th ACM Symposium on Access Control Models and Technologies},
pages = {51–53},
numpages = {3},
keywords = {access control, abac, 5g},
location = {Trento, Italy},
series = {SACMAT '23}
}

@inproceedings{10.5555/3581644.3581646,
author = {Spatharakis, Dimitrios and Dimolitsas, Ioannis and Vlahakis, Eleftherios and Dechouniotis, Dimitrios and Athanasopoulos, Nikolaos and Papavassiliou, Symeon},
title = {Distributed Resource Autoscaling in Kubernetes Edge Clusters},
year = {2023},
isbn = {9783903176515},
publisher = {International Federation for Information Processing},
address = {Laxenburg, AUT},
abstract = {Maximizing the performance of modern applications requires timely resource management of the virtualized resources. However, proactively deploying resources for meeting specific application requirements subject to a dynamic workload profile of incoming requests is extremely challenging. To this end, the fundamental problems of task scheduling and resource autoscaling must be jointly addressed. This paper presents a scalable architecture compatible with the decentralized nature of Kubernetes [1], to solve both. Exploiting the stability guarantees of a novel AIMD-like task scheduling solution, we dynamically redirect the incoming requests towards the containerized application. To cope with dynamic workloads, a prediction mechanism allows us to estimate the number of incoming requests. Additionally, a Machine Learning-based (ML) Application Profiling Modeling is introduced to address the scaling, by co-designing the theoretically-computed service rates obtained from the AIMD algorithm with the current performance metrics. The proposed solution is compared with the state-of-the-art autoscaling techniques under a realistic dataset in a small edge infrastructure and the trade-off between resource utilization and QoS violations are analyzed. Our solution provides better resource utilization by reducing CPU cores by 8\% with only an acceptable increase in QoS violations.},
booktitle = {Proceedings of the 18th International Conference on Network and Service Management},
articleno = {1},
numpages = {7},
keywords = {machine learning, resource autoscaling, edge computing, resource management, kubernetes},
location = {Thessaloniki, Greece},
series = {CNSM '22}
}

@inproceedings{10.1145/3590777.3591405,
author = {Cali, Umit and Dynge, Marthe Fogstad and Idries, Ahmed and Mishra, Sambeet and Dmytro, Ivanko and Hashemipour, Naser and Kuzlu, Murat},
title = {Digital Energy Platforms Considering Digital Privacy and Security by Design Principles},
year = {2023},
isbn = {9781450398299},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3590777.3591405},
doi = {10.1145/3590777.3591405},
abstract = {The power system and markets have become increasingly complex, along with efforts to digitalize the energy sector. Accessing flexibility services, in particular, through digital energy platforms, has enabled communication between multiple entities within the energy system and streamlined flexibility market operations. However, digitalizing these vast and complex systems introduces new cybersecurity and privacy concerns, which must be properly addressed during the design of the digital energy platform ecosystems. More specifically, both privacy and cybersecurity measures should be embedded into all phases of the platform design and operation, based on the privacy and security by design principles. In this study, these principles are used to propose a holistic but generic architecture for digital energy platforms that are able to facilitate multiple use cases for flexibility services in the energy sector. A hybrid framework using both DLT and non-DLT solutions ensures trust throughout the layers of the platform architecture. Furthermore, an evaluation of numerous energy flexibility service use cases operating at various stages of the energy value chain is shown and graded in terms of digital energy platform technical maturity, privacy, and cybersecurity issues.},
booktitle = {Proceedings of the 2023 European Interdisciplinary Cybersecurity Conference},
pages = {167–173},
numpages = {7},
keywords = {privacy., Flexibility markets, cybersecurity, distributed ledger technology, digitalization},
location = {Stavanger, Norway},
series = {EICC '23}
}

@article{10.1145/3588704,
author = {Chacko, Jeeta Ann and Mayer, Ruben and Jacobsen, Hans-Arno},
title = {How To Optimize My Blockchain? A Multi-Level Recommendation Approach},
year = {2023},
issue_date = {May 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {1},
url = {https://doi.org/10.1145/3588704},
doi = {10.1145/3588704},
abstract = {Aside from the conception of new blockchain architectures, existing blockchain optimizations in the literature primarily focus on system or data-oriented optimizations within prevailing blockchains. However, since blockchains handle multiple aspects ranging from organizational governance to smart contract design, a holistic approach that encompasses all the different layers of a given blockchain system is required to ensure that all optimization opportunities are taken into consideration. In this vein, we define a multi-level optimization recommendation approach that identifies optimization opportunities within a blockchain at the system, data, and user level. Multiple metrics and attributes are derived from a blockchain log and nine optimization recommendations are formalized. We implement an automated optimization recommendation tool, BlockOptR, based on these concepts. The system is extensively evaluated with a wide range of workloads covering multiple real-world scenarios. After implementing the recommended optimizations, we observe an average of 20\% improvement in the success rate of transactions and an average of 40\% improvement in latency.},
journal = {Proc. ACM Manag. Data},
month = {may},
articleno = {24},
numpages = {27},
keywords = {process mining, performance optimization, blockchains}
}

@article{10.1145/3580815,
author = {Wang, Yanfei and Yu, Zhiwen and Liu, Sicong and Zhou, Zimu and Guo, Bin},
title = {Genie in the Model: Automatic Generation of Human-in-the-Loop Deep Neural Networks for Mobile Applications},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {1},
url = {https://doi.org/10.1145/3580815},
doi = {10.1145/3580815},
abstract = {Advances in deep neural networks (DNNs) have fostered a wide spectrum of intelligent mobile applications ranging from voice assistants on smartphones to augmented reality with smart-glasses. To deliver high-quality services, these DNNs should operate on resource-constrained mobile platforms and yield consistent performance in open environments. However, DNNs are notoriously resource-intensive, and often suffer from performance degradation in real-world deployments. Existing research strives to optimize the resource-performance trade-off of DNNs by compressing the model without notably compromising its inference accuracy. Accordingly, the accuracy of these compressed DNNs is bounded by the original ones, leading to more severe accuracy drop in challenging yet common scenarios such as low-resolution, small-size, and motion-blur. In this paper, we propose to push forward the frontiers of the DNN performance-resource trade-off by introducing human intelligence as a new design dimension. To this end, we explore human-in-the-loop DNNs (H-DNNs) and their automatic performance-resource optimization. We present H-Gen, an automatic H-DNN compression framework that incorporates human participation as a new hyperparameter for accurate and efficient DNN generation. It involves novel hyperparameter formulation, metric calculation, and search strategy in the context of automatic H-DNN generation. We also propose human participation mechanisms for three common DNN architectures to showcase the feasibility of H-Gen. Extensive experiments on twelve categories of challenging samples with three common DNN structures demonstrate the superiority of H-Gen in terms of the overall trade-off between performance (accuracy, latency), and resource (storage, energy, human labour).},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = {mar},
articleno = {36},
numpages = {29},
keywords = {reinforcement Learning, model generation, neural networks, Human in the Loop}
}

@inproceedings{10.1145/3472813.3473181,
author = {Alahmadi, Rawan and Almimony, Shoroog and Bahakeem, Rahaf and Alnahdi, Amany},
title = {Health Records Retrieval System: A Web-Service Approach},
year = {2021},
isbn = {9781450389846},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472813.3473181},
doi = {10.1145/3472813.3473181},
abstract = {Patients’ electronic health records are archived and collected on data repositories of medical data systems. This research paper proposes a system based on web service architecture that allows retrieving medical records by health care centers associated to the system. There will be no need to open a file in every health care center associated to the system. In addition, the doctor can see the lab radiological results and medications from any hospital by considering security and privacy of medical data. The system will provide patients with urgent medical treatment when transferred to any hospital, as the hospital can access the patient's electronic health records to be informed with health status and diagnostic history. For example, a person had an accident and was transferred to any hospital; the hospital can access the patient's own electronic health records and find out his health status and medication the patient's uses. The built web service-based system will maintain privacy and security measures.},
booktitle = {Proceedings of the 5th International Conference on Medical and Health Informatics},
pages = {145–149},
numpages = {5},
keywords = {Health record, Medical record, Web service},
location = {Kyoto, Japan},
series = {ICMHI '21}
}

@inproceedings{10.1145/3477495.3531942,
author = {Zou, Xinyu and Hu, Zhi and Zhao, Yiming and Ding, Xuchu and Liu, Zhongyi and Li, Chenliang and Sun, Aixin},
title = {Automatic Expert Selection for Multi-Scenario and Multi-Task Search},
year = {2022},
isbn = {9781450387323},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477495.3531942},
doi = {10.1145/3477495.3531942},
abstract = {Multi-scenario learning (MSL) enables a service provider to cater for users' fine-grained demands by separating services for different user sectors, e.g., by user's geographical region. Under each scenario there is a need to optimize multiple task-specific targets e.g., click through rate and conversion rate, known as multi-task learning (MTL). Recent solutions for MSL and MTL are mostly based on the multi-gate mixture-of-experts (MMoE) architecture. MMoE structure is typically static and its design requires domain-specific knowledge, making it less effective in handling both MSL and MTL. In this paper, we propose a novel Automatic Expert Selection framework for Multi-scenario and Multi-task search, named AESM2. AESM2 integrates both MSL and MTL into a unified framework with an automatic structure learning. Specifically, AESM2 stacks multi-task layers over multi-scenario layers. This hierarchical design enables us to flexibly establish intrinsic connections between different scenarios, and at the same time also supports high-level feature extraction for different tasks. At each multi-scenario/multi-task layer, a novel expert selection algorithm is proposed to automatically identify scenario-/task-specific and shared experts for each input. Experiments over two real-world large-scale datasets demonstrate the effectiveness of AESM2 over a battery of strong baselines. Online A/B test also shows substantial performance gain on multiple metrics. Currently, AESM2 has been deployed online for serving major traffic.},
booktitle = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1535–1544},
numpages = {10},
keywords = {search and ranking, multi-task learning, multi-scenario learning},
location = {<conf-loc>, <city>Madrid</city>, <country>Spain</country>, </conf-loc>},
series = {SIGIR '22}
}

@inproceedings{10.1145/3578245.3584725,
author = {Tocz\'{e}, Klervie and Abad, Cristina L. and Herbst, Nikolas and Iosup, Alexandru},
title = {HotCloudPerf'23 Workshop Chairs' Welcome},
year = {2023},
isbn = {9798400700729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578245.3584725},
doi = {10.1145/3578245.3584725},
abstract = {It is our great pleasure to welcome you to the 2023 edition of the Workshop on Hot Topics in Cloud Computing Performance - HotCloudPerf 2023.Cloud computing is emerging as one of the most profound changes in the way we build and use IT. The use of global services in public clouds is increasing, and the lucrative and rapidly growing global cloud market already supports over 1 million IT-related jobs. However, it is currently challenging to make the IT services offered by public and private clouds performant (in an extended sense) and efficient. Emerging architectures, techniques, and real-world systems include interactions with the computing continuum, serverless operation, everything as a service, complex workflows, auto-scaling and -tiering, etc. It is unclear to which extent traditional performance engineering, software engineering, and system design and analysis tools can help with understanding and engineering these emerging technologies. The community needs practical tools and powerful methods to address hot topics in cloud computing performance.Responding to this need, the HotCloudPerf workshop proposes a meeting venue for academics and practitioners, from experts to trainees, in the field of cloud computing performance. The workshop aims to engage this community and to lead to the development of new methodological aspects for gaining a deeper understanding not only of cloud performance, but also of cloud operation and behavior, through diverse quantitative evaluation tools, including benchmarks, metrics, and workload generators. The workshop focuses on novel cloud properties such as elasticity, performance isolation, dependability, and other non-functional system properties, in addition to classical performance-related metrics such as response time, throughput, scalability, and efficiency.},
booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {257–258},
numpages = {2},
keywords = {benchmarking, cloud/edge computing, performance},
location = {Coimbra, Portugal},
series = {ICPE '23 Companion}
}

@inproceedings{10.1145/3477495.3531965,
author = {Liu, Yuli and Walder, Christian and Xie, Lexing},
title = {Determinantal Point Process Likelihoods for Sequential Recommendation},
year = {2022},
isbn = {9781450387323},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477495.3531965},
doi = {10.1145/3477495.3531965},
abstract = {Sequential recommendation is a popular task in academic research and close to real-world application scenarios, where the goal is to predict the next action(s) of the user based on his/her previous sequence of actions. In the training process of recommender systems, the loss function plays an essential role in guiding the optimization of recommendation models to generate accurate suggestions for users. However, most existing sequential recommendation tech- niques focus on designing algorithms or neural network architectures, and few efforts have been made to tailor loss functions that fit naturally into the practical application scenario of sequential recommender systems.  Ranking-based losses, such as cross-entropy and Bayesian Personalized Ranking (BPR) are widely used in the sequential recommendation area. We argue that such objective functions suffer from two inherent drawbacks: i) the dependencies among elements of a sequence are overlooked in these loss formulations; ii) instead of balancing accuracy (quality) and diversity, only generating accurate results has been over emphasized. We therefore propose two new loss functions based on the Determinantal Point Process (DPP) likelihood, that can be adaptively applied to estimate the subsequent item or items. The DPP-distributed item set captures natural dependencies among temporal actions, and a quality vs. diversity decomposition of the DPP kernel pushes us to go beyond accuracy-oriented loss functions. Experimental results using the proposed loss functions on three real-world datasets show marked improvements over state-of-the-art sequential recommendation methods in both quality and diversity metrics.},
booktitle = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1653–1663},
numpages = {11},
keywords = {sequential recommendation, diversity, determinantal point process, loss function},
location = {<conf-loc>, <city>Madrid</city>, <country>Spain</country>, </conf-loc>},
series = {SIGIR '22}
}

@inproceedings{10.1145/3590837.3590904,
author = {E V, Sandeepkumar and Jayavel, Kayalvizhi},
title = {Effective and Light Weight Security System for Highly Confidential Cloud Data Such as PHR},
year = {2023},
isbn = {9781450399937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3590837.3590904},
doi = {10.1145/3590837.3590904},
abstract = {The server in a cloud storage system can hold a very large amount of Personal health records (PHR) data or information. The cloud platform's storage servers provide archival services for a lengthy time frame. The third party basically functions as an administrator for the efficiency of cloud storage. This is why we're starting up our cloud storage service. One of the biggest difficulties with the cloud is that it is vulnerable to hacking. Ordinary methods of encryption are used to safeguard the information from prying eyes. All of the secret messages' code words are kept in a system of varying symbols. Deletion coding is carried out in a manner analogous to that which is used to calculate the unequal code word cyphers required for a communication in a distributed setting. When the message symbols are stored in different servers in a dispersed environment, the cryptographic term signs are also calculated independently and stored. For this reason, we introduce and include a threshold proxy re-encryption scheme. Fully Homomorphic Encryption is a promising approach to securing sensitive PHR data by limiting who can view it. When sending encrypted PHR data, the proxy re-encryption mechanism re-encrypts the PHR data again before sending it on to the recipient or storage server. Allocation is completed when secure access control has maximised performance. In light of this, we expect to see the Schmidt-Samoa Public Key Encryption (SSPKE) method developed on the Enhanced v Boosting Algorithm (EBA) by PHR data Hiding Architecture. Additionally, in this initiative, we employ a procedure of multi-party protocol admission control to operate and access the user's PHR data without jeopardising the sensitive cloud PHR data privacy. The results of the experiments show the beneficial effect when various metrics, such as total processing time, server response time, and PHR data decomposition rate, are taken into account for the application of PHR.},
booktitle = {Proceedings of the 4th International Conference on Information Management \&amp; Machine Intelligence},
articleno = {67},
numpages = {7},
keywords = {EBA, Re-encryption,Security, PHR, SSPKE},
location = {Jaipur, India},
series = {ICIMMI '22}
}

@inproceedings{10.1145/3528535.3533273,
author = {Rocha, Isabelly and Felber, Pascal and Schiavoni, Valerio and Chen, Lydia},
title = {EdgeTune: Inference-Aware Multi-Parameter Tuning},
year = {2022},
isbn = {9781450393409},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3528535.3533273},
doi = {10.1145/3528535.3533273},
abstract = {Deep Neural Networks (DNNs) have demonstrated impressive performance on many machine-learning tasks such as image recognition and language modeling, and are becoming prevalent even on mobile platforms. Despite so, designing neural architectures still remains a manual, time-consuming process that requires profound domain knowledge. Recently, Parameter Tuning Servers have gathered the attention o industry and academia. Those systems allow users from all domains to automatically achieve the desired model accuracy for their applications. However, although the entire process of tuning and training models is performed solely to be deployed for inference, state-of-the-art approaches typically ignore system-oriented and inference-related objectives such as runtime, memory usage, and power consumption. This is a challenging problem: besides adding one more dimension to an already complex problem, the information about edge devices available to the user is rarely known or complete. To accommodate all these objectives together, it is crucial for tuning system to take a holistic approach to parameter tuning and consider all levels of parameters simultaneously into account. We present EdgeTune, a novel inference-aware parameter tuning server. It considers the tuning of parameters in all levels backed by an optimization function capturing multiple objectives. Our approach relies on inference estimated metrics collected from our emulation server running asynchronously from the main tuning process. The latter can then leverage the inference performance while still tuning the model. We propose a novel one-fold tuning algorithm that employs the principle of multi-fidelity and simultaneously explores multiple tuning budgets, which the prior art can only handle as suboptimal case of single type of budget. EdgeTune outputs inference recommendations to the user while improving tuning time and energy by at least 18\% and 53\% when compared to the baseline.},
booktitle = {Proceedings of the 23rd ACM/IFIP International Middleware Conference},
pages = {1–14},
numpages = {14},
keywords = {tuning, deep neural networks, training, inference},
location = {Quebec, QC, Canada},
series = {Middleware '22}
}

@inproceedings{10.1145/3565387.3565413,
author = {Kong, Xiangying and Kong, Xinran},
title = {Design of Embedded Trust Root Based on Dual-Kernel Architecture},
year = {2022},
isbn = {9781450396004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3565387.3565413},
doi = {10.1145/3565387.3565413},
abstract = {Given the characteristics and design constraints of the embedded system, a software trust root construction method based on dual kernel architecture and composed of bootloader and trusted kernel and a stem branch trust chain transmission model are proposed ,aiming at the requirements of the trusted environment of embedded applications, The Bootloader, solidified in the boot FLASH, embeds the SHA-1 engine, to measure and load the trusted kernel. Meanwhile, the trusted kernel realizes the protection of the Bootloader by prohibiting the user kernel and upper-layer applications from writing access to the FLASH. The interaction between them, as the root of trust, can resist non-physical attacks; the trusted kernel provides password service-related functions for the user kernel; the application system and the user kernel where it is lockated run as a process of the trusted kernel. Finally, based on predicate logic, a formal proof of trusted boot is given, and a prototype system is built to verify the availability of the scheme.},
booktitle = {Proceedings of the 6th International Conference on Computer Science and Application Engineering},
articleno = {26},
numpages = {6},
keywords = {Embedded system, Trust root, Dual-kernel, Predicate logic},
location = {Virtual Event, China},
series = {CSAE '22}
}

@inproceedings{10.1145/3532213.3532283,
author = {Mahenge, Shadrack Fred and Wambura, Stephen and Jiao, Licheng},
title = {A Modified U-Net Architecture for Road Surfaces Cracks Detection},
year = {2022},
isbn = {9781450396110},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3532213.3532283},
doi = {10.1145/3532213.3532283},
abstract = {Cracks on road surfaces causes inconveniences to drivers and passengers and may cause mechanical failure or even accidents. Good Road condition plays an important role in quick transportation of goods and services from one place to another and acts as a catalyst for the economic development. Road surfaces need to be maintained in good condition to ensure the safety of road users. Road damage detection is important for Structural Health Monitoring (SHM). Traditional manual inspection is normally performed through human visualization which is time consuming, expensive, dangerous because of the passing vehicles, suffers from subjective judgment of the inspector and pose difficulties in keeping records for future road maintenance and repair. The rapid emergency and development of AI has stimulated many experts to automate the process of crack detection through computer vision (CV) technology, though most of these studies faces challenge on getting good detection accuracy. In this study a novel modified U-Net Architecture for image classification and segmentation is proposed to detect cracks on the road surfaces by using detection and classification of the road images to determine whether they represent cracks or not. Extensive experiments are conducted on three publicly available road crack datasets to evaluate the performance of our proposed model, The performance of the proposed Modified U-Net architecture was verified with respect to different performance metrics such as accuracy, precision, recall and f1 score. Qualitative and Quantitative comparisons experimental results of the proposed approach were also compared with existing state of the art U-Net architectures. It can be inferred from results that the proposed approach achieves superior performance in terms of detection accuracy.},
booktitle = {Proceedings of the 8th International Conference on Computing and Artificial Intelligence},
pages = {464–471},
numpages = {8},
keywords = {object detection, deep learning, machine learning, Image processing, computer vision},
location = {Tianjin, China},
series = {ICCAI '22}
}

@article{10.1145/3626196,
author = {kumari, Rani and Sah, Dinesh Kumar and Cengiz, Korhan and Ivkovi\'{c}, Nikola and Balaji, Prasanalakshmi},
title = {Automatic Graph Construction and Exploring Different Types of LSTMs for Asian Hindi Languages for Medical Review Sentiment Analysis},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2375-4699},
url = {https://doi.org/10.1145/3626196},
doi = {10.1145/3626196},
abstract = {Sentiment Analysis (SA) of medical reviews is crucial for improving healthcare outcomes. However, analyzing sentiment in low-resource languages such as Asian Hindi presents significant challenges. In this study, we propose an automatic graph construction approach to extract relevant features from medical reviews in Asian Hindi languages. We explore different types of Long Short-Term Memory (LSTMs), including traditional LSTMs, bidirectional LSTMs, and attention-based LSTMs, to classify the sentiment of medical reviews. Our proposed approach uses attention-based LSTM architecture and pre-trained Word2Vec embeddings to achieve high accuracy. We compare the proposed approach with existing models using various evaluation metrics, including accuracy, precision, recall, and F1-score. The results demonstrate that our proposed approach outperforms all existing models in terms of accuracy, achieving an accuracy score of 81\%. These findings could have implications for improving healthcare outcomes by enabling better monitoring of patient feedback and identifying areas for improvement in medical services.},
note = {Just Accepted},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = {oct},
keywords = {Long short-term memory, Graph construction, Deep learning, Hindi language}
}

@inproceedings{10.1145/3579856.3595793,
author = {Zohaib, Ali and Sheffey, Jade and Houmansadr, Amir},
title = {Investigating Traffic Analysis Attacks on Apple ICloud Private Relay},
year = {2023},
isbn = {9798400700989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579856.3595793},
doi = {10.1145/3579856.3595793},
abstract = {The iCloud Private Relay (PR) is a new feature introduced by Apple in June 2021 that aims to enhance online privacy by protecting a subset of web traffic from both local eavesdroppers and websites that use IP-based tracking. The service is integrated into Apple’s latest operating systems and uses a two-hop architecture where a user’s web traffic is relayed through two proxies run by disjoint entities. PR’s multi-hop architecture resembles traditional anonymity systems such as Tor and mix networks. Such systems, however, are known to be susceptible to a vulnerability known as traffic analysis: an intercepting adversary (e.g., a malicious router) can attempt to compromise the privacy promises of such systems by analyzing characteristics (e.g., packet timings and sizes) of their network traffic. In particular, previous works have widely studied the susceptibility of Tor to website fingerprinting and flow correlation, two major forms of traffic analysis. In this work, we are the first to investigate the threat of traffic analysis against the recently introduced PR. First, we explore PR’s current architecture to establish a comprehensive threat model of traffic analysis attacks against PR. Second, we quantify the potential likelihood of these attacks against PR by evaluating the risks imposed by real-world AS-level adversaries through empirical measurement of Internet routes. Our evaluations show that some autonomous systems are in a particularly strong position to perform traffic analysis on a large fraction of PR traffic. Finally, having demonstrated the potential for these attacks to occur, we evaluate the performance of several flow correlation and website fingerprinting attacks over PR traffic. Our evaluations show that PR is highly vulnerable to state-of-the-art website fingerprinting and flow correlation attacks, with both attacks achieving high success rates. We hope that our study will shed light on the significance of traffic analysis to the current PR deployment, convincing Apple to perform design adjustments to alleviate the risks.},
booktitle = {Proceedings of the 2023 ACM Asia Conference on Computer and Communications Security},
pages = {773–784},
numpages = {12},
keywords = {Traffic Analysis, Anonymity Systems, iCloud Private Relay},
location = {Melbourne, VIC, Australia},
series = {ASIA CCS '23}
}

@inproceedings{10.1145/3563766.3564093,
author = {Anand, SVR and Arslan, Serhat and Chopra, Rajat and Katti, Sachin and Vaddiraju, Milind Kumar and Rana, Ranvir and Sheng, Peiyao and Tyagi, Himanshu and Viswanath, Pramod},
title = {Trust-Free Service Measurement and Payments for Decentralized Cellular Networks},
year = {2022},
isbn = {9781450398992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563766.3564093},
doi = {10.1145/3563766.3564093},
abstract = {Decentralized cellular networks have emerged to increase network accessibility by distributing infrastructure ownership over independent entities. Unlike the centralized setting, these architectures can allow users to connect to any untrusted base station without prior subscription. However, verification of the service is necessary in the absence of trust for commensurate payments by the user. Further, any method of verification must be non-intrusive and reliably agreed upon by the involved parties. To this end, we describe two-sided measurements where both the users and the providers independently assess the cellular service. We find that reconciling measurements from different layers of the cellular stack for a diverse set of matching observations is challenging but not impossible. Hence, new use cases such as a decentralized slicing marketplace, and contract-free roaming can be enabled by two-sided measurements. We envision applying two-sided measurements to real-time, on-demand network slicing and present an architecture that is capable of offering, as well as verifying, such slices in a scalable manner.},
booktitle = {Proceedings of the 21st ACM Workshop on Hot Topics in Networks},
pages = {68–75},
numpages = {8},
keywords = {cellular architecture, decentralization},
location = {Austin, Texas},
series = {HotNets '22}
}

@article{10.1145/3586181,
author = {Bachiega, Joao and Costa, Breno and Carvalho, Leonardo R. and Rosa, Michel J. F. and Araujo, Aleteia},
title = {Computational Resource Allocation in Fog Computing: A Comprehensive Survey},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {14s},
issn = {0360-0300},
url = {https://doi.org/10.1145/3586181},
doi = {10.1145/3586181},
abstract = {Fog computing is a paradigm that allows the provisioning of computational resources and services at the edge of the network, closer to the end devices and users, complementing cloud computing. The heterogeneity and large number of devices are challenges to obtaining optimized resource allocation in this environment. Over time, some surveys have been presented on resource management in fog computing. However, they now lack a broader and deeper view about this subject, considering the recent publications. This article presents a systematic literature review with a focus on resource allocation for fog computing, and in a more comprehensive way than the existing works. The survey is based on 108 selected publications from 2012 to 2022. The analysis has exposed their main techniques, metrics used, evaluation tools, virtualization methods, architecture, and domains where the proposed solutions were applied. The results show an updated and comprehensive view about resource allocation in fog computing. The main challenges and open research questions are discussed, and a new fog computing resource management cycle is proposed.},
journal = {ACM Comput. Surv.},
month = {jul},
articleno = {336},
numpages = {31},
keywords = {resource allocation, Fog computing, resource management, resource provisioning}
}

@article{10.1145/3476248,
author = {Ebrahimi, Maryam and Tadayon, Mohammad Hesam and Haghighi, Mohammad Sayad and Jolfaei, Alireza},
title = {A Quantitative Comparative Study of Data-Oriented Trust Management Schemes in Internet of Things},
year = {2022},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {3},
issn = {2158-656X},
url = {https://doi.org/10.1145/3476248},
doi = {10.1145/3476248},
abstract = {In the Internet of Things (IoT) paradigm, all entities in the IoT network, whether home users or industrial things, receive data from other things to make decisions. However, in the decentralized, heterogeneous, and rapidly changing IoT network with billions of devices, deciding about where to get the services or information from is critical, especially because malicious entities can exist in such an unmanaged network. Security provisioning alone cannot solve the issue of service quality or reliability. One way to elevate security and reliability in the IoT network is to bridge the gap of trust between objects, and also between humans and objects, while taking into account the IoT network characteristics. Therefore, a proper trust management system must be established on top of the IoT network service architecture. Trust is related to the manner expected from objects in providing services and recommendations. Recommendations are the basis of decision making in every trust management system. Since trust management ideas in the IoT are still immature, the purpose of this article is to survey, analyze, and compare the approaches that have been taken in building trust management systems for the IoT. We break down the features of such systems by analysis and also do quantitative comparisons by simulation. This article is organized into two main parts. First, studies and approaches in this field are compared from four perspectives: (1) trust computation method, (2) resistance to attacks (3) adherence to the limitations of IoT networks and devices, and (4) performance of the trust management scheme. The second part is quantitative and simulates four major methods in this field and measures their performance. We also make extensive analytical comparisons to demonstrate the similarities and discrepancies of current IoT trust management schemes and extract the essence of a resilient trust management framework.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = {apr},
articleno = {24},
numpages = {30},
keywords = {trust management, cyber security, data mining, recommender systems, Internet of things, decision making}
}

@inproceedings{10.1145/3557915.3560948,
author = {Cuza, Carlos Enrique Muniz and Ho, Nguyen and Zacharatou, Eleni Tzirita and Pedersen, Torben Bach and Yang, Bin},
title = {Spatio-Temporal Graph Convolutional Network for Stochastic Traffic Speed Imputation},
year = {2022},
isbn = {9781450395298},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3557915.3560948},
doi = {10.1145/3557915.3560948},
abstract = {The rapid increase of traffic data generated by different sensing systems opens many opportunities to improve transportation services. An important opportunity is to enable stochastic routing that computes the arrival time probabilities for each suggested route instead of only the expected travel time. However, traffic datasets typically have many missing values, which prevents the construction of stochastic speeds. To address this limitation, we propose the Stochastic Spatio-Temporal Graph Convolutional Network (SST-GCN) architecture that accurately imputes missing speed distributions in a road network. SST-GCN combines Temporal Convolutional Networks and Graph Convolutional Networks into a single framework to capture both spatial and temporal correlations between road segments and time intervals. Moreover, to cope with datasets with many missing values, we propose a novel self-adaptive context-aware diffusion process that regulates the propagated information around the network, avoiding the spread of false information. We extensively evaluate the effectiveness of SST-GCN on real-world datasets, showing that it achieves from 4.6\% to 50\% higher accuracy than state-of-the-art baselines using three different evaluation metrics. Furthermore, multiple ablation studies confirm our design choices and scalability to large road networks.},
booktitle = {Proceedings of the 30th International Conference on Advances in Geographic Information Systems},
articleno = {14},
numpages = {12},
keywords = {graph convolutional networks, spatio-temporal, data imputation},
location = {<conf-loc>, <city>Seattle</city>, <state>Washington</state>, </conf-loc>},
series = {SIGSPATIAL '22}
}

@inproceedings{10.1145/3487553.3527149,
author = {Oraby, Shereen},
title = {Stylistic Control for Neural Natural Language Generation},
year = {2022},
isbn = {9781450391306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3487553.3527149},
doi = {10.1145/3487553.3527149},
abstract = {With the rise of conversational assistants, it has become more critical for dialog systems to keep users engaged by responding in a natural, interesting, and often personalized way, even in a task-oriented setting. Recent work has thus focused on stylistic control for natural language generation (NLG) systems in order to jointly control response semantics and style. In this talk, I will describe our work on automatic data curation and modeling approaches to facilitate style control for both personality-specific attributes of style (based on Big-Five personality traits), and other style attributes that are helpful for personalization, e.g., response length, descriptiveness, point-of-view, and sentiment. I will present work that incorporates these attributes into the training and generation pipelines for different NLG architectures, and will show how our data curation and modeling approaches are generalizable to new domains and style choices. Finally, I will describe how we use a combination of automatic and human evaluation methods to measure how well models successfully hit multiple style targets without sacrificing semantics.},
booktitle = {Companion Proceedings of the Web Conference 2022},
pages = {1179},
numpages = {1},
keywords = {natural language generation, stylistic variation, dialog systems},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3614321.3614322,
author = {Peniche, Eduardo and Miranda, Leandro and Bernardini, Flavia and Viterbo, Jose},
title = {FGT-SAMK-NN: Impact of the Right to Be Forgotten Using a Lazy Algorithm in Data Stream Learning},
year = {2023},
isbn = {9798400707421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3614321.3614322},
doi = {10.1145/3614321.3614322},
abstract = {“Right to Be Forgotten" is guaranteed by new international regulations on personal management data. This means that individuals can request the erasure of their data from third-party tools and services. However, this poses a challenge for machine learning estimators, who will need to forget parts of their knowledge. This paper examines the impact of learning and forgetting policies in Data Stream Learning. Storing data or retraining learning models from scratch in data stream mining is usually not feasible due to the large volume of instances. Therefore, more efficient solutions are necessary to deal with the dynamic nature of online machine learning. To address this issue, we implemented FGT-SAMK-NN, an incremental version of one of the most knowledgeable algorithms in Data Stream lazy algorithms: The SAMK-NN classifier. FGT-SAMK-NN can erase its past data, and we investigate the impact of data forgetting on predictive performance. Our proposal is compared to the original SAMK-NN algorithm using four non-stationary stream datasets. Our results demonstrate that evaluation metrics did not undergo significant changes, which may support the idea that has a good architecture for adaptations of the proposed nature. However, it was also noted that the processing time is very high for cases involving more forgettings, which may indicate that the high complexity of the model creates conflicts if the pattern of data streams, where the algorithm is used, involves a high forgetfulness rate.},
booktitle = {Proceedings of the 16th International Conference on Theory and Practice of Electronic Governance},
pages = {1–8},
numpages = {8},
keywords = {Right to Be Forgotten, Lazy Learning, SamK-NN, Data Stream, Data Stream Learning},
location = {<conf-loc>, <city>Belo Horizonte</city>, <country>Brazil</country>, </conf-loc>},
series = {ICEGOV '23}
}

@inproceedings{10.1145/3517745.3561426,
author = {Sattler, Patrick and Aulbach, Juliane and Zirngibl, Johannes and Carle, Georg},
title = {Towards a Tectonic Traffic Shift? Investigating Apple's New Relay Network},
year = {2022},
isbn = {9781450392594},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3517745.3561426},
doi = {10.1145/3517745.3561426},
abstract = {Apple recently published its first Beta of the iCloud Private Relay, a privacy protection service with promises resembling the ones of VPNs. The architecture consists of two layers (ingress and egress), operated by disjoint providers. The service is directly integrated into Apple's operating systems, providing a low entry-level barrier for a large user base. It seems to be set up for significant adoption with its relatively moderate entry-level price.This paper analyzes the iCloud Private Relay from a network perspective, its effect on the Internet, and future measurement-based research. We perform EDNS0 Client Subnet DNS queries to collect ingress relay addresses and find 1586 IPv4 addresses. Supplementary RIPE Atlas DNS measurements reveal 1575 IPv6 addresses. Knowing these addresses helps to detect clients communicating through the relay network passively. According to our scans, ingress addresses grew by 20\% from January through April. Moreover, according to our RIPE Atlas DNS measurements, 5.3\% of all probes use a resolver that blocks access to iCloud Private Relay.The analysis of our scans through the relay network verifies Apple's claim of rotating egress addresses. Nevertheless, it reveals that ingress and egress relays can be located in the same autonomous system, thus sharing similar routes, potentially allowing traffic correlation.},
booktitle = {Proceedings of the 22nd ACM Internet Measurement Conference},
pages = {449–457},
numpages = {9},
keywords = {relay networks, DNS ECS enumeration, overlay networks},
location = {Nice, France},
series = {IMC '22}
}

@inproceedings{10.1145/3544216.3544238,
author = {Miao, Rui and Zhu, Lingjun and Ma, Shu and Qian, Kun and Zhuang, Shujun and Li, Bo and Cheng, Shuguang and Gao, Jiaqi and Zhuang, Yan and Zhang, Pengcheng and Liu, Rong and Shi, Chao and Fu, Binzhang and Zhu, Jiaji and Wu, Jiesheng and Cai, Dennis and Liu, Hongqiang Harry},
title = {From Luna to Solar: The Evolutions of the Compute-to-Storage Networks in Alibaba Cloud},
year = {2022},
isbn = {9781450394208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544216.3544238},
doi = {10.1145/3544216.3544238},
abstract = {This paper presents the two generations of storage network stacks that reduced the average I/O latency of Alibaba Cloud's EBS service by 72\% in the last five years: Luna, a user-space TCP stack that corresponds the latency of network to the speed of SSD; and Solar, a storage-oriented UDP stack that enables both storage and network hardware accelerations.Luna is our first step towards a high-speed compute-to-storage network in the "storage disaggregation" architecture. Besides the tremendous performance gains and CPU savings compared with the legacy kernel TCP stack, more importantly, it teaches us the necessity of offloading both network and storage into hardware and the importance of recovering instantaneously from network failures.Solar provides a highly reliable and performant storage network running on hardware. For avoiding hardware's resource limitations and offloading storage's entire data path, Solar eliminates the superfluous complexity and the overfull states from the traditional architecture of the storage network. The core design of Solar is unifying the concepts of network packet and storage data block - each network packet is a self-contained storage data block. There are three remarkable advantages to doing so. First, it merges the packet processing and storage virtualization pipelines to bypass the CPU and PCIe; Second, since the storage processes data blocks independently, the packets in Solar become independent. Therefore, the storage (in hardware) does not need to maintain receiving buffers for assembling packets into blocks or handling packet reordering. Finally, due to the low resource requirement and the resilience to packet reordering, Solar inherently supports large-scale multi-path transport for fast failure recovery. Facing the future, Solar demonstrates that we can formalize the storage virtualization procedure into a P4-compatible packet processing pipeline. Hence, SOLAR's design perfectly applies to commodity DPUs (data processing units).},
booktitle = {Proceedings of the ACM SIGCOMM 2022 Conference},
pages = {753–766},
numpages = {14},
keywords = {storage network, data processing unit, in-network acceleration},
location = {Amsterdam, Netherlands},
series = {SIGCOMM '22}
}

@article{10.1145/3485129,
author = {Meneguette, Rodolfo and De Grande, Robson and Ueyama, Jo and Filho, Geraldo P. Rocha and Madeira, Edmundo},
title = {Vehicular Edge Computing: Architecture, Resource Management, Security, and Challenges},
year = {2021},
issue_date = {January 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3485129},
doi = {10.1145/3485129},
abstract = {Vehicular Edge Computing (VEC), based on the Edge Computing motivation and fundamentals, is a promising technology supporting Intelligent Transport Systems services, smart city applications, and urban computing. VEC can provide and manage computational resources closer to vehicles and end-users, providing access to services at lower latency and meeting the minimum execution requirements for each service type. This survey describes VEC’s concepts and technologies; we also present an overview of existing VEC architectures, discussing them and exemplifying them through layered designs. Besides, we describe the underlying vehicular communication in supporting resource allocation mechanisms. With the intent to overview the risks, breaches, and measures in VEC, we review related security approaches and methods. Finally, we conclude this survey work with an overview and study of VEC’s main challenges. Unlike other surveys in which they are focused on content caching and data offloading, this work proposes a taxonomy based on the architectures in which VEC serves as the central element. VEC supports such architectures in capturing and disseminating data and resources to offer services aimed at a smart city through their aggregation and the allocation in a secure manner.},
journal = {ACM Comput. Surv.},
month = {nov},
articleno = {4},
numpages = {46},
keywords = {Vehicular edge computer, architecture, resource management, security}
}

@inproceedings{10.1145/3488663.3493688,
author = {Ueda, Kazuaki and Tagami, Atsushi},
title = {Internet Flattening and Consolidation Considered Useful (for Deploying New Internet Architecture)},
year = {2021},
isbn = {9781450391382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3488663.3493688},
doi = {10.1145/3488663.3493688},
abstract = {Several new Internet architectures have been proposed to fill the gap between the original design of Internet and its current usage. These new architectures have been studied for more than 15 years, and their technical benefits have been widely validated. However, to date, these architectures have not been deployed in commercial networks. One of the reasons is that current Internet involves multiple players such as content providers and Internet Service Providers (ISPs), which makes it difficult to make significant changes. On the other hand, several studies have shown two trends of the current Internet, consolidation in web content delivery and flattening of the Internet topology. Web content delivery is dominated by the large Content Delivery Network (CDN) providers. Moreover, to improve communication quality, such providers connect directly to the eyeball ISPs, and this results in the flat topology. In this paper, we focus on whether these two trends, i.e., Internet flattening and consolidation, can ease the hurdle for deploying new architecture. Based on the measurements of DNS and network path, we verified the current trend of flattening and consolidation of content delivery on the Internet. We also investigated the incremental deployment scenario of new architecture under this environment. The results showed that a significant amount of traffic can be handled by a new architecture, if only a small set of autonomous systems cooperatively deploy it.},
booktitle = {Proceedings of the Interdisciplinary Workshop on (de) Centralization in the Internet},
pages = {11–17},
numpages = {7},
keywords = {Future Internet Architecture, Internet consolidation},
location = {Virtual Event, Germany},
series = {IWCI'21}
}

@inproceedings{10.1145/3487075.3487146,
author = {Zhang, Qingjun and Hu, Dong and Lin, Qiang},
title = {Design of High-Precision Island WebGIS Based on Cesium},
year = {2021},
isbn = {9781450389853},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3487075.3487146},
doi = {10.1145/3487075.3487146},
abstract = {In this paper, the design of a high-precision WebGIS system for island application is presented. The system is developed based on Cesium to support 2D, 2.5D and 3D map capabilities, and provide networked comprehensive geographic information service. Concerning the practical requirements for complicated configuration of island surface, improved methods for interpolation correction, data structure optimization, visible analysis and island path planning are introduced to improve system accuracy and performance. The system adopts B/S architecture and modular development ideas for easier access and further updates. The main functional modules of the island WebGIS provide basic operations, including multi-dimensional scene browsing, base map switching, multi-control operation, layer plotting, contour line, intervisibility and terrain factors measurement. Besides, the characteristic functions of key techniques such as profile analysis, viewshed analysis, and island path planning are implemented. The test examples show that the overall functional performance of the system is satisfactory for island 3D GIS service.},
booktitle = {Proceedings of the 5th International Conference on Computer Science and Application Engineering},
articleno = {71},
numpages = {7},
keywords = {WebGIS, Geographic information system, Cesium, Island},
location = {Sanya, China},
series = {CSAE '21}
}

@inproceedings{10.1145/3630202.3630233,
author = {Cornacchia, Alessandro and Benson, Theophilus A. and Bilal, Muhammad and Canini, Marco},
title = {MicroView: Cloud-Native Observability with Temporal Precision},
year = {2023},
isbn = {9798400704529},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630202.3630233},
doi = {10.1145/3630202.3630233},
abstract = {We present MicroView, a system designed to improve the accuracy and timeliness of observability in cloud-native applications, while minimizing overhead. MicroView stands out from conventional observability tools by incorporating metrics processing stages at every node within a local lightweight data-plane. We preliminary demonstrate its benefits for distributed tracing and outline a set of architectural choices focused on offloading the MicroView data-plane to IPU accelerators, such as a BlueField-3 SmartNIC, thus limiting the interference with running services.},
booktitle = {Proceedings of the on CoNEXT Student Workshop 2023},
pages = {7–8},
numpages = {2},
keywords = {SmartNIC, programmable networks, microservices observability, cloud-native},
location = {<conf-loc>, <city>Paris</city>, <country>France</country>, </conf-loc>},
series = {CoNEXT-SW '23}
}

@inproceedings{10.1145/3508072.3508114,
author = {Ofure Eichie, Julia and Oluwamayowa Agidi, Emmanuel and David Oyedum, Onyendi},
title = {Atmospheric Temperature Prediction across Nigeria Using Artificial Neural Network},
year = {2022},
isbn = {9781450387347},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3508072.3508114},
doi = {10.1145/3508072.3508114},
abstract = {Atmospheric temperature is one of the dominating atmospheric parameters that impact on the propagation of radio waves through the troposphere. Adequate knowledge of the atmospheric temperature of an environment is therefore essential for radio wave propagation planning. In this study, thirty-four (34)-year (1981-2014) atmospheric temperature data of 10 selected weather stations across the climatic zones of Nigeria, obtained from the Nigerian Meteorological Agency (NIMET) through the data bank of the West African Science Service Centre on Climate Change and Adaptive Land Use (WASCAL) of the Federal University of Technology Minna, Nigeria was used in Artificial Neural Network (ANN) for the prediction of mean monthly atmospheric temperature. The ANN architecture comprised of 2 inputs (the climatic zones and the corresponding month for the mean monthly atmospheric temperature), 1 hidden layer and 1 output (atmospheric temperature). Levenberg-Marquardt algorithm was used with 9 different pairs of activation functions formed from 3 activation functions (logsig, purelin and tansig). The number of neurons in the hidden layer was varied from 33-39 with an increasing steps of 2 (33, 35, 37 and 39). The network architecture of 2-37-1 (2 inputs, 37 neurons in the hidden layer and 1 output), with tansig/tansig pair of activation functions had the least mean square error value of 2.2280, and was used for the prediction process. The computed correlation values for measured and predicted atmospheric temperature ranged from 0.9733 to 0.8787, depicting strong positive correlation and good accuracy of the developed model. Comparisons of the measured and the ANN predicted atmospheric temperature across selected stations in the climatic zones of Nigeria, showed that the developed model can effectively predict mean monthly atmospheric temperature, using month and climatic zone as input parameters.},
booktitle = {The 5th International Conference on Future Networks \&amp; Distributed Systems},
pages = {280–286},
numpages = {7},
keywords = {Temperature, artificial neural network, refractive index, prediction},
location = {Dubai, United Arab Emirates},
series = {ICFNDS 2021}
}

@article{10.1145/3567826,
author = {Viola, Roberto and Mart\'{\i}n, \'{A}ngel and Zorrilla, Mikel and Montalb\'{a}n, Jon and Angueira, Pablo and Muntean, Gabriel-Miro},
title = {A Survey on Virtual Network Functions for Media Streaming: Solutions and Future Challenges},
year = {2023},
issue_date = {November 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {11},
issn = {0360-0300},
url = {https://doi.org/10.1145/3567826},
doi = {10.1145/3567826},
abstract = {Media services must ensure an enhanced user’s perceived quality during content playback to attract and retain audiences, especially while the streams are distributed remotely via networks. Thus, media streaming services rely heavily on good and predictable network performance when delivered to a large number of people. Furthermore, as the quality of media content gets high, the network performance demands are also increasing, and meeting them is challenging. Network functions devoted to improving media streaming services become essential to cope with the high dynamics of network performance and user mobility. Furthermore, new networking paradigms and architectures under the 5G networks umbrella are bringing new possibilities to deploy smart network functions, which monitor the media streaming services through live and objective metrics and boost them in real-time. This survey overviews the state-of-the-art technologies and solutions proposed to apply new network functions for enhancing media streaming.},
journal = {ACM Comput. Surv.},
month = {feb},
articleno = {221},
numpages = {37},
keywords = {Media streaming, network virtualization, network functions}
}

@inproceedings{10.1145/3578245.3585328,
author = {Iosup, Alexandru and Prodan, Radu},
title = {ICPE'23 GraphSys Workshop Chairs Introduction (Welcome)},
year = {2023},
isbn = {9798400700729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578245.3585328},
doi = {10.1145/3578245.3585328},
abstract = {It is our great pleasure to welcome you to the 2023 ACM/SPEC Workshop on Serverless, Extreme-Scale, and Sustainable Graph Processing Systems. This is the first such workshop, aiming to facilitate the exchange of ideas and expertise in the broad field of high-performance large-scale graph processing.Graphs and GraphSys - The use, interoperability, and analytical exploitation of graph data are essential for modern digital economies. Today, thousands of computational methods (algorithms) and findable, accessible, interoperable, and reusable (FAIR) graph datasets exist. However, current computational capabilities lag when faced with the complex workflows involved in graph processing, the extreme scale of existing graph datasets, and the need to consider sustainability metrics in graph-processing operations. Needs are emerging for graph-processing platforms to provide multilingual information processing and reasoning based on the massive graph representation of extreme data in the form of general graphs, knowledge graphs, and property graphs. Because graph workloads and graph datasets are strongly irregular, and involve one or several big data "Vs" (e.g., volume, velocity, variability, vicissitude), the community needs to reconsider traditional approaches in performance analysis and modeling, system architectures and techniques, serverless and "as a service" operation, real-world and simulation-driven experimentation, etc., and provide new tools and instruments to address emerging challenges in graph processing.Graphs or linked data are crucial to innovation, competition, and prosperity and establish a strategic investment in technical processing and ecosystem enablers. Graphs are universal abstractions that capture, combine, model, analyze, and process knowledge about real and digital worlds into actionable insights through item representation and interconnectedness. For societally relevant problems, graphs are extreme data that require further technological innovations to meet the needs of the European data economy. Digital graphs help pursue the United Nations Sustainable Development Goals (UN SDG) by enabling better value chains, products, and services for more profitable or green investments in the financial sector and deriving trustworthy insight for creating sustainable communities. All science, engineering, industry, economy, and society-at-large domains can leverage graph data for unique analysis and insight, but only if graph processing becomes easy to use, fast, scalable, and sustainable.GraphSys is a cross-disciplinary meeting venue focusing on state-of-the-art and the emerging (future) graph processing systems. We invite experts and trainees in the field, across academia, industry, governance, and society, to share experience and expertise leading to a shared body of knowledge, to formulate together a vision for the field, and to engage with the topics to foster new approaches, techniques, and solutions.},
booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {207–208},
numpages = {2},
keywords = {workshop, graph processing, graphsys serverless, extreme-scale, and sustainable graph processing systems},
location = {Coimbra, Portugal},
series = {ICPE '23 Companion}
}

@inproceedings{10.1145/3570361.3592529,
author = {Wen, Hao and Li, Yuanchun and Zhang, Zunshuai and Jiang, Shiqi and Ye, Xiaozhou and Ouyang, Ye and Zhang, Yaqin and Liu, Yunxin},
title = {AdaptiveNet: Post-Deployment Neural Architecture Adaptation for Diverse Edge Environments},
year = {2023},
isbn = {9781450399906},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3570361.3592529},
doi = {10.1145/3570361.3592529},
abstract = {Deep learning models are increasingly deployed to edge devices for real-time applications. To ensure stable service quality across diverse edge environments, it is highly desirable to generate tailored model architectures for different conditions. However, conventional pre-deployment model generation approaches are not satisfactory due to the difficulty of handling the diversity of edge environments and the demand for edge information. In this paper, we propose to adapt the model architecture after deployment in the target environment, where the model quality can be precisely measured and private edge data can be retained. To achieve efficient and effective edge model generation, we introduce a pretraining-assisted on-cloud model elastification method and an edge-friendly on-device architecture search method. Model elastification generates a high-quality search space of model architectures with the guidance of a developer-specified oracle model. Each subnet in the space is a valid model with different environment affinity, and each device efficiently finds and maintains the most suitable subnet based on a series of edge-tailored optimizations. Extensive experiments on various edge devices demonstrate that our approach is able to achieve significantly better accuracy-latency tradeoffs (e.g. 46.74\% higher on average accuracy with a 60\% latency budget) than strong baselines with minimal overhead (13 GPU hours in the cloud and 2 minutes on the edge server).},
booktitle = {Proceedings of the 29th Annual International Conference on Mobile Computing and Networking},
articleno = {28},
numpages = {17},
keywords = {edge environments, post-deployment adaptation, neural networks, model elastification},
location = {Madrid, Spain},
series = {ACM MobiCom '23}
}

@inproceedings{10.1145/3600211.3604754,
author = {Narayanan Venkit, Pranav},
title = {Towards a Holistic Approach: Understanding Sociodemographic Biases in NLP Models Using an Interdisciplinary Lens},
year = {2023},
isbn = {9798400702310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600211.3604754},
doi = {10.1145/3600211.3604754},
abstract = {The rapid growth in the usage and applications of Natural Language Processing (NLP) in various sociotechnical solutions has highlighted the need for a comprehensive understanding of bias and its impact on society. While research on bias in NLP has expanded, several challenges persist that require attention. These include the limited focus on sociodemographic biases beyond race and gender, the narrow scope of analysis predominantly centered on models, and the technocentric implementation approaches. This paper addresses these challenges and advocates for a more interdisciplinary approach to understanding bias in NLP. The work is structured into three facets, each exploring a specific aspect of bias in NLP. The first facet focuses on identifying sociodemographic bias in various NLP architectures, emphasizing the importance of considering both the models themselves and human computation to comprehensively understand and identify bias. In the second facet, we delve into the significance of establishing a shared vocabulary across different fields and disciplines involved in NLP. By highlighting the potential bias stemming from a lack of shared understanding, this facet emphasizes the need for interdisciplinary collaboration to bridge the gap and foster a more inclusive and accurate analysis of bias. Finally, the third facet investigates the development of a holistic solution by integrating frameworks from social science disciplines. This approach recognizes the complexity of bias in NLP and advocates for an interdisciplinary framework that goes beyond purely technical considerations, involving social and ethical perspectives to address bias effectively. The first facet includes the following of my published works [6, 7, 8, 9] to provide results into how the importance of understanding the presence of bias in various minority group that has not been in focus in the prior works of bias in NLP. The work also shows the need to create a method that considers both human and AI indicators of bias, showcasing the importance of the first facet of my research. In my study [9], I delve into sentiment analysis and toxicity detection models to identify explicit bias against race, gender, and people with disabilities (PWDs). Through statistical exploration of conversations on social media platforms such as Twitter and Reddit, I gain insights into how disability bias permeates real-world social settings. To quantify explicit sociodemographic bias in sentiment analysis and toxicity analysis models, I create the Bias Identification Test in Sentiment (BITS) corpus1. Applying BITS, I uncover significant biases in popular AIaaS sentiment analysis tools, including TextBlob, VADER, and Google Cloud Natural Language API, as well as toxicity analysis models like Toxic-BERT. Remarkably, all of these models exhibit statistically significant explicit bias against disability, underscoring the need for comprehensive understanding and mitigation of biases affecting such groups. The work also demonstrates the utility of BITS as a model-independent method of identifying bias by focusing on social groups instead. Expanding on this, my next work [8] delves into the realm of implicit bias in NLP models. While some models may not overtly exhibit bias, they can unintentionally perpetuate harmful stereotypes [4]. To measure and identify implicit bias in commonly used embedding and large language models, I propose a methodology to measure social biases in various NLP architectures. Focusing on people with disabilities (PWD) as a group with complex social dynamics, I analyze various word embedding-based and transformer-based LLMs, revealing significant biases against PWDs in all tested models. These findings expose how models trained on extensive corpora tend to favor ableist language, underscoring the urgency of detecting and addressing implicit bias. The above two works look at both the implicit and explicit nature of bias in NLP, showcasing the need to distinguish the efforts placed in understanding them. The results also demonstrate the utility of identifying such biases as it provides context to the black-box nature of such public models. As the field of NLP evolved from embedding-based models to large language models, the way these models are constructed underwent significant changes [5]. However, the concern arises from the fact that these models often reflect a populist viewpoint [1] that perpetuates majority-held ideas rather than objective truths. This difference in perception can lead to biases perpetuated by the majority’s worldview. To explore this aspect, I investigate how LLMs represent nationality and their impact on societal stereotypes [6]. By examining LLM-generated stories for various nationalities, I establish a correlation between sentiment and the population of internet users in a country. The study reveals the unintentional implicit and explicit nationality biases exhibited by GPT-2, with nations having lower internet representation and economic status generating negative sentiment stories and employing a greater number of negative adjectives. Additionally, I explore potential debiasing methods such as adversarial triggering and prompt engineering, demonstrating their efficacy in mitigating stereotype propagation through LLM models. While prior work predominantly relies on automatic indicators like sentiment scores or vector distances to identify bias [3], the next phase of my research emphasizes the importance of understanding biases through the lens of human readers [7], bringing to light the need for a human lens in understanding bias through human-aided indicators and mixed-method identification. By incorporating concepts of social computation, using human evaluation, we gain a better understanding of biases’ potential societal impact within the context of language models. To achieve this, I conduct open-ended interviews and employ qualitative coding and thematic analysis to comprehend the implications of biases on human readers. The findings demonstrate that biased NLP models tend to replicate and amplify existing societal biases, posing potential harm when utilized in sociotechnical settings. The qualitative analysis from the interviews provides valuable insights into readers’ experiences when encountering biased articles, highlighting the capacity to shift a reader’s perception of a country. These findings emphasize the critical role of public perception in shaping AI’s impact on society and the need to correct biases in AI systems. The second facet of my research aims to bridge the disparity between AI research and society. This disparity has resulted in a lack of shared understanding between these domains, leading to potential biases and harm toward specific groups. Employing an interdisciplinary approach that combines social informatics, philosophy, and AI, I will investigate the similarities and disparities in the concepts utilized by machine learning models. Existing research [2] highlights the insufficient interdisciplinary effort and motivation in comprehending social aspects of NLP. To commence this exploration, I will delve into the shared taxonomy of sentiment and fairness in natural language processing, sociology, and humanities. This research will first delve into the interdisciplinary nature of sentiment and its application in sentiment analysis models. Sentiment analysis, a popular machine learning application for text classification based on sentiment, opinion, and subjectivity, holds significant influence as a sociotechnical system that impacts both social and technical actors within a network. Nevertheless, the definition and connotation of sentiment vary vastly across different research fields, potentially leading to misconceptions regarding the utility of such systems. To address this issue, this study will examine how diverse fields, including psychology, sociology, and technology, define the concept of sentiment. By unraveling the divergent perspectives on sentiment within different fields, the paper will uncover discrepancies and varying applications of this interdisciplinary concept. Additionally, the research will survey commonly utilized sentiment analysis models, aiming to comprehend their standardized definitions and associated issues. Ultimately, the study will pose critical questions that should be considered during the development of social models to mitigate potential biases and harm stemming from an insufficiently defined comprehension of fundamental social concepts. Similar efforts will be dedicated to comprehending the disparity in bias and fairness as an interdisciplinary concept, shedding light on the imperative for inclusive research to cultivate superior AI models as sociotechnical solutions. The third facet of my study embarks upon an exploration of the intricate interplay between human and AI actors, employing the formidable theoretical lens of actor-network theory (ANT). Through the presentation of a robust framework, this facet aims to engender the formation of efficacious development networks that foster collaboration among developers, practitioners, and other essential stakeholders. Such inclusive networks serve as crucibles for the cultivation of holistic solutions that transcend the discriminatory trappings afflicting specific populations. A tangible outcome of this endeavor entails the creation of an all-encompassing bias analysis platform, poised to guide the discernment and amelioration of an array of sociodemographic biases manifesting within any machine-learning system. By catalyzing the development of socially aware and less pernicious technology, this research makes a substantial contribution to the realms of NLP and AI. The significance of this proposed research reverberates beyond the confines of NLP, resonating throughout the broader domain of AI, wherein analogous challenges about social biases loom large. Leveraging the proposed framework, developers, practitioners, and policymakers are empowered to forge practical solutions that embody inclusivity and reliability, especially when used as a service (AIaaS). Moreover, the platform serves as a centralized locus for the identification and rectification of social biases, irrespective of the underlying model or architecture. By furnishing a cogent narrative that underscores the imperative for a comprehensive and interdisciplinary approach, my work strives to propel the ongoing endeavors to comprehend and mitigate biases within the realm of NLP. With its potential to augment the equity, inclusivity, and societal ramifications of NLP technologies, the proposed framework catapults the field towards responsible and ethical practices.},
booktitle = {Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {1004–1005},
numpages = {2},
location = {<conf-loc>, <city>Montr\'{e}al</city>, <state>QC</state>, <country>Canada</country>, </conf-loc>},
series = {AIES '23}
}

@inproceedings{10.1145/3581783.3613777,
author = {Fernandez, Sergi and Montagud, Mario and Rinc\'{o}n, David and Moragues, Juame and Cernigliaro, Gianluca},
title = {Addressing Scalability for Real-Time Multiuser Holo-Portation: Introducing and Assessing a Multipoint Control Unit (MCU) for Volumetric Video},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3613777},
doi = {10.1145/3581783.3613777},
abstract = {Scalability, interoperability, and cost efficiency are key remaining challenges to successfully providing real-time holo-portation (and Metaverse-like) services. This paper, for the first time, presents the design and integration of a Multipoint Control Unit (MCU) in a pioneering real-time holo-portation platform, supporting realistic and volumetric user representations (i.e., 3D holograms), with the aim of overcoming such challenges. The feasibility and implications of adopting such an MCU, in comparison with state-of-the-art architectural approaches, are assessed through experimentation in two different deployment setups, by iteratively increasing the number of concurrent users in shared sessions. The obtained results are promising, as it is empirically proved that the newly adopted stream multiplexing together with the novel per-client and per-frame Volumetric Video (VV) processing optimization features provided by the MCU allow increasing the number of concurrent users, while: (i) significantly reducing resources consumption metrics (e.g., CPU, GPU, bandwidth) and frame rate degradation on the client side; and (ii) keeping the end-to-end latency within acceptable limits.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {9243–9251},
numpages = {9},
keywords = {multipoint control unit (mcu), social vr, virtual reality (vr), volumetric video, cloud computing, holo-portation},
location = {<conf-loc>, <city>Ottawa ON</city>, <country>Canada</country>, </conf-loc>},
series = {MM '23}
}

@inproceedings{10.1145/3426020.3426111,
author = {Rehman, Osama and Farrukh, Zaroon and Al-Busaidi, Asiya and Cha, Kyungjin and Park, Simon and Rahman, Ibrahim},
title = {IoT Powered Cancer Observation System.},
year = {2021},
isbn = {9781450389259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3426020.3426111},
doi = {10.1145/3426020.3426111},
abstract = {Cancer is a global challenge and the second leading cause of death worldwide as reported by the World Health Organization. With the current global pandemic caused by the novel coronavirus, cancer patients are identified as having increased risk of mortality. With the growing number of cancer patients every year, the need for a continuous and round the clock observation system has become quite imperative. An Internet of Things (IoT) based system for monitoring cancer patients has the potential to timely detect cancer related symptoms in its early stages, to continuously monitor cancer diagnosed patients and to monitor those that got cured for post-treatment measures. This paper proposes a multi-layered architecture of an IoT-based cancer observation system that can be utilized as a platform to remotely diagnose and monitor cancer patients. An implementation framework of the proposed system is also presented is this work, along with a prototype design of a Patient Side Unit (PSU) represented by a wearable wrist band. The proposed system has the potential to be applied as a solution for reducing expensive and exhausting hospital visits, while gaining similar quality of medical services when residing at home.},
booktitle = {The 9th International Conference on Smart Media and Applications},
pages = {313–318},
numpages = {6},
location = {Jeju, Republic of Korea},
series = {SMA 2020}
}

