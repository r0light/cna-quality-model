@inproceedings{10.1145/2661829.2661991,
author = {Anchuri, Pranay and Sumbaly, Roshan and Shah, Sam},
title = {Hotspot Detection in a Service-Oriented Architecture},
year = {2014},
isbn = {9781450325981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2661829.2661991},
doi = {10.1145/2661829.2661991},
abstract = {Large-scale websites are predominantly built as a service-oriented architecture. Here, services are specialized for a certain task, run on multiple machines, and communicate with each other to serve a user's request. Reducing latency and improving the cost to serve is quite important, but optimizing this service call graph is particularly challenging due to the volume of data and the graph's non-uniform and dynamic nature.In this paper, we present a framework to detect hotspots in a service-oriented architecture. The framework is general, in that it can handle arbitrary objective functions. We show that finding the optimal set of hotspots for a metric, such as latency, is NP-complete and propose a greedy algorithm by relaxing some constraints. We use a pattern mining algorithm to rank hotspots based on the impact and consistency. Experiments on real world service call graphs from LinkedIn, the largest online professional social network, show that our algorithm consistently outperforms baseline methods.},
booktitle = {Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management},
pages = {1749–1758},
numpages = {10},
keywords = {service-oriented architecture, monitoring, call graph, hotspots},
location = {Shanghai, China},
series = {CIKM '14}
}

@inproceedings{10.1145/3329379,
author = {Cruz-Filipe, Lu\'{\i}s and Di Nitto, Elisabetta and Mauro, Jacopo},
title = {Session Details: Theme: Distributed Systems: MiDOS - Microservices, DevOps, and Service-Oriented Architecture Track},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3329379},
doi = {10.1145/3329379},
abstract = {Service-oriented architectures have changed our vision of the Web, bringing a paradigmatic shift in the methodologies when designing and implementing distributed systems. Originally, the Web was mainly seen as a means of presenting information to a wide spectrum of people, but service-oriented programming triggered a radical transformation of the Web towards a computational fabric where loosely coupled services interact, can be discovered and then invoked. More recently, the microservices architectural style has been proposed, where applications are developed as a collection of fine-grained services running as independent processes. Distributed applications can then be constructed from independently deployable services taking advantage of the properties of the microservice architecture (e.g., flexibility, maintainability, reusability, compositionality, and scalability) as well as the elasticity of cloud infrastructure. From the practical point of view, the deployment and maintenance of (micro)services architectures are performed using DevOps, i.e., a collection of practices linking software development (Dev) with software operations (Ops). DevOps strongly advocates for automation and monitoring at all steps of software construction, from integration, testing, releasing to deployment and infrastructure management. By using the DevOps methodology, it is possible to reduce the time between committing a change to a system and the change being placed into normal production, while ensuring high quality.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1145/2593501.2593505,
author = {Miranda, Breno and Bertolino, Antonia},
title = {Social Coverage for Customized Test Adequacy and Selection Criteria},
year = {2014},
isbn = {9781450328586},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593501.2593505},
doi = {10.1145/2593501.2593505},
abstract = {Test coverage information can be very useful for guiding testers in enhancing their test suites to exercise possible uncovered entities and in deciding when to stop testing. However, for complex applications that are reused in different contexts and for emerging paradigms (e.g., component-based development, service-oriented architecture, and cloud computing), traditional coverage metrics may no longer provide meaningful information to help testers on these tasks. Various proposals are advocating to leverage information that come from the testing community in a collaborative testing approach. In this work we introduce a coverage metric, the Social Coverage, that customizes coverage information in a given context based on coverage data collected from similar users. To evaluate the potential of our proposed approach, we instantiated the social coverage metric in the context of a real world service oriented application. In this exploratory study, we were able to predict the entities that would be of interest for a given user with an average precision of 97\% and average recall of 75\%. Our results suggest that, in similar environments, social coverage can provide a better support to testers than traditional coverage.},
booktitle = {Proceedings of the 9th International Workshop on Automation of Software Test},
pages = {22–28},
numpages = {7},
keywords = {User Similarity, Coverage Testing, Service-Oriented Application, Relative Coverage},
location = {Hyderabad, India},
series = {AST 2014}
}

@article{10.1145/2579281.2579294,
author = {Castelluccia, Daniela and Boffoli, Nicola},
title = {Service-Oriented Product Lines: A Systematic Mapping Study},
year = {2014},
issue_date = {March 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {2},
issn = {0163-5948},
url = {https://doi.org/10.1145/2579281.2579294},
doi = {10.1145/2579281.2579294},
abstract = {Software product line engineering and service-oriented architectures both enable organizations to capitalize on reuse of existing software assets and capabilities and improve competitive advantage in terms of development savings, product flexibility, time-to-market. Both approaches accommodate variation of assets, including services, by changing the software being reused or composing services according a new orchestration. Therefore, variability management in Service-oriented Product Lines (SoPL) is one of the main challenges today. In order to highlight the emerging evidence-based results from the research community, we apply the well-defined method of systematic mapping in order to populate a classification scheme for the SoPL field of interest. The analysis of results throws light on the current open issues. Moreover, different facets of the scheme can be combined to answer more specific research questions. The report reveals the need for more empirical research able to provide new metrics measuring efficiency and efficacy of the proposed models, new methods and tools supporting variability management in SoPL, especially during maintenance and verification and validation. The mapping study about SoPL opens further investigations by means of a complete systematic review to select and validate the most efficient solutions to variability management in SoPL.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {mar},
pages = {1–6},
numpages = {6},
keywords = {empirical study, service-oriented architecture, product line development, mapping study, variability management, service-oriented computing, software product line}
}

@inproceedings{10.5555/3021955.3022024,
author = {Oliveira, Joyce Aline and Junior, Jose J.L.D.},
title = {A Three-Dimensional View of Reuse in Service Oriented Architecture},
year = {2016},
isbn = {9788576693178},
publisher = {Brazilian Computer Society},
address = {Porto Alegre, BRA},
abstract = {The reuse in Service Oriented Architecture (SOA) has been used strategically in organizations to reduce development costs and increase the quality of applications. This article reports a qualitative research realized with experts in order to identify goals, barriers, facilitators, strategies, metrics and benefits associated with reuse in SOA. The results were summarized in three dimensions (management, architecture, operation) and represented by a conceptual model that can serve as a preliminary roadmap to manage the reuse in SOA.},
booktitle = {Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1},
pages = {409–416},
numpages = {8},
keywords = {qualitative research, Services Oriented Architecture, SOA reuse},
location = {Florianopolis, Santa Catarina, Brazil},
series = {SBSI '16}
}

@inproceedings{10.1145/3018896.3018961,
author = {Lehmann, Martin and Sandnes, Frode Eika},
title = {A Framework for Evaluating Continuous Microservice Delivery Strategies},
year = {2017},
isbn = {9781450347747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3018896.3018961},
doi = {10.1145/3018896.3018961},
abstract = {The emergence of service-oriented computing, and in particular microservice architecture, has introduced a new layer of complexity to the already challenging task of continuously delivering changes to the end users. Cloud computing has turned scalable hardware into a commodity, but also imposes some requirements on the software development process. Yet, the literature mainly focuses on quantifiable metrics such as number of manual steps and lines of code required to make a change. The industry, on the other hand, appears to focus more on qualitative metrics such as increasing the productivity of their developers. These are common goals, but must be measured using different approaches. Therefore, based on interviews of industry stakeholders a framework for evaluating and comparing approaches to continuous microservice delivery is proposed. We show that it is possible to efficiently evaluate and compare strategies for continuously delivering microservices.},
booktitle = {Proceedings of the Second International Conference on Internet of Things, Data and Cloud Computing},
articleno = {64},
numpages = {9},
keywords = {continuous deployment, deployment strategy, cloud computing, microservices, evaluation framework, microservice architectures},
location = {Cambridge, United Kingdom},
series = {ICC '17}
}

@inproceedings{10.1145/3207677.3277935,
author = {Luo, Ning and Zhao, Jun},
title = {Storage System Based on Norm and BPMN Mapping Research on Business Process Modeling},
year = {2018},
isbn = {9781450365123},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3207677.3277935},
doi = {10.1145/3207677.3277935},
abstract = {Aiming1 at the problems of large variety of goods, large quantities of materials, and non-standard procurement and transportation in warehousing enterprises, a modeling method based on the specification and BPMN2.0 mapping was proposed. Through the analysis of the actual warehousing business process management, the service-oriented system modeling based on the warehouse management requirements, the study of the warehousing management system architecture based on the specification, the implementation of the warehousing system specification to BPMN mapping, a better implementation the purpose of warehousing service flexibility.},
booktitle = {Proceedings of the 2nd International Conference on Computer Science and Application Engineering},
articleno = {163},
numpages = {5},
keywords = {business process modeling, flexibility semantic loss, BPMN2, Norm},
location = {Hohhot, China},
series = {CSAE '18}
}

@inproceedings{10.1145/3034950.3034975,
author = {Ke, Weimao},
title = {Distributed Search Efficiency and Robustness in Service Oriented Multi-Agent Networks},
year = {2017},
isbn = {9781450348348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3034950.3034975},
doi = {10.1145/3034950.3034975},
abstract = {We study decentralized searches in a large service-oriented agent network and investigate the influences of multiple factors on search efficiency. In this study we focus on overall system robustness and examine search performance in unstable environments where individual agents may fail or a system-wide attack may occur. Experimental results show that searches continue to be efficient when a large number of service agents become unavailable. Surprisingly, overall system performance in terms of a search path length metric improves with an increasing number of unavailable agents. Service unavailability also has an impact on the load balance of service agents. We plan to conduct further research to verify observed patterns and to understand related implications on system architecture design.},
booktitle = {Proceedings of the 2017 International Conference on Management Engineering, Software Engineering and Service Sciences},
pages = {9–18},
numpages = {10},
keywords = {robustness, service agents, distributed search, information network},
location = {Wuhan, China},
series = {ICMSS '17}
}

@inproceedings{10.1145/3229345.3229419,
author = {Oliveira, Joyce Aline and Vargas, Matheus and Rodrigues, Roni},
title = {SOA Reuse: Systematic Literature Review Updating and Research Directions},
year = {2018},
isbn = {9781450365598},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3229345.3229419},
doi = {10.1145/3229345.3229419},
abstract = {Service Oriented Architecture (SOA) reuse has been used strategically in organizations to reduce development costs and increase the quality of applications. This article analyzes a systematic literature review in order to identify concepts, goals, strategies, and metrics of SOA reuse. The results show that the main goal of SOA reuse is to decrease development costs. The factor that most negatively influences SOA reuse is the existence of legacy systems. The strategy used most to potentialize SOA reuse is business process management. Metrics proposed by studies to measure SOA reuse are related to modularity and adaptability indicators. The study is relevant because it increases the body of knowledge of the area. Additionally, a set of gaps to be addressed by researchers and reuse practitioners was identified.},
booktitle = {Proceedings of the XIV Brazilian Symposium on Information Systems},
articleno = {71},
numpages = {8},
keywords = {systematic literature review, Service Oriented Architecture, SOA reuse},
location = {Caxias do Sul, Brazil},
series = {SBSI '18}
}

@inproceedings{10.1145/3284557.3284713,
author = {Rudorfer, Martin and Pannen, Tessa J. and Kr\"{u}ger, J\"{o}rg},
title = {A Case Study on Granularity of Industrial Vision Services},
year = {2018},
isbn = {9781450366281},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3284557.3284713},
doi = {10.1145/3284557.3284713},
abstract = {Software engineering paradigms such as service-oriented architectures are increasingly often applied in the field of factory automation. Functions like robot motion planning or object recognition are provided by cloud services. A crucial architectural aspect is the granularity, i.e. the scope and size of individual services. In our case study, we examine a service-based object recognition application for a robotic assembly use case. We implement three different granularity levels, measure their communication and computation times and discuss further architectural features. The fine-granular approach encapsulates individual image processing operations as services, which have high reusability but impose large communication overheads. The medium granularity approach is object-wise and offers best reuse efficiency and cohesion. The coarse solution offers the best performance.},
booktitle = {Proceedings of the 2nd International Symposium on Computer Science and Intelligent Control},
articleno = {59},
numpages = {6},
keywords = {Service-Oriented Architecture, Object Recognition, Granularity},
location = {Stockholm, Sweden},
series = {ISCSIC '18}
}

@inproceedings{10.1145/2568225.2568230,
author = {Akiki, Pierre A. and Bandara, Arosha K. and Yu, Yijun},
title = {Integrating Adaptive User Interface Capabilities in Enterprise Applications},
year = {2014},
isbn = {9781450327565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2568225.2568230},
doi = {10.1145/2568225.2568230},
abstract = {Many existing enterprise applications are at a mature stage in their development and are unable to easily benefit from the usability gains offered by adaptive user interfaces (UIs). Therefore, a method is needed for integrating adaptive UI capabilities into these systems without incurring a high cost or significantly disrupting the way they function. This paper presents a method for integrating adaptive UI behavior in enterprise applications based on CEDAR, a model-driven, service-oriented, and tool-supported architecture for devising adaptive enterprise application UIs. The proposed integration method is evaluated with a case study, which includes establishing and applying technical metrics to measure several of the method’s properties using the open-source enterprise application OFBiz as a test-case. The generality and flexibility of the integration method are also evaluated based on an interview and discussions with practitioners about their real-life projects.},
booktitle = {Proceedings of the 36th International Conference on Software Engineering},
pages = {712–723},
numpages = {12},
keywords = {model-driven engineering, software architectures, Adaptive user interfaces, enterprise systems, integration, software metrics},
location = {Hyderabad, India},
series = {ICSE 2014}
}

@inproceedings{10.1145/3143434.3143457,
author = {Ilin, I. and Levina, A. and Abran, A. and Iliashenko, O.},
title = {Measurement of Enterprise Architecture (EA) from an IT Perspective: Research Gaps and Measurement Avenues},
year = {2017},
isbn = {9781450348539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3143434.3143457},
doi = {10.1145/3143434.3143457},
abstract = {Reorganizational projects in general and software-related projects in particular, are often implemented with a focus only on the reorganized components within an organizational management system, not taking into account relationships with the other components of an enterprise architecture (EA). This paper first looks at the current state of EA measurement to identify weaknesses and gaps in aligning and measuring EA components, EA structures and EA interrelationships from an IT perspective. It then identifies from related works available innovative measurement concepts that could contribute for aligning, measuring and monitoring software-related projects within an EA strategy. This includes measurement avenues within a Balanced Scorecard (BSC), contributions of functional size measurement to the BSC, and measurement of software structures and functionality within a service-oriented architecture (SOA).},
booktitle = {Proceedings of the 27th International Workshop on Software Measurement and 12th International Conference on Software Process and Product Measurement},
pages = {232–243},
numpages = {12},
keywords = {functional size measurement (FSM), service-oriented architecture (SOA), function points (FP), enterprise architecture (EA), enterprise architecture measurement, balanced scorecard (BSC)},
location = {Gothenburg, Sweden},
series = {IWSM Mensura '17}
}

@inproceedings{10.1145/3194164.3194166,
author = {Bogner, Justus and Fritzsch, Jonas and Wagner, Stefan and Zimmermann, Alfred},
title = {Limiting Technical Debt with Maintainability Assurance: An Industry Survey on Used Techniques and Differences with Service- and Microservice-Based Systems},
year = {2018},
isbn = {9781450357135},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194164.3194166},
doi = {10.1145/3194164.3194166},
abstract = {Maintainability assurance techniques are used to control this quality attribute and limit the accumulation of potentially unknown technical debt. Since the industry state of practice and especially the handling of Service- and Microservice-Based Systems in this regard are not well covered in scientific literature, we created a survey to gather evidence for a) used processes, tools, and metrics in the industry, b) maintainability-related treatment of systems based on service-orientation, and c) influences on developer satisfaction w.r.t. maintainability. 60 software professionals responded to our online questionnaire. The results indicate that using explicit and systematic techniques has benefits for maintainability. The more sophisticated the applied methods the more satisfied participants were with the maintainability of their software while no link to a hindrance in productivity could be established. Other important findings were the absence of architecture-level evolvability control mechanisms as well as a significant neglect of service-oriented particularities for quality assurance. The results suggest that industry has to improve its quality control in these regards to avoid problems with long-living service-based software systems.},
booktitle = {Proceedings of the 2018 International Conference on Technical Debt},
pages = {125–133},
numpages = {9},
keywords = {service-based systems, microservice-based systems, maintainability, industry, survey, software quality control},
location = {Gothenburg, Sweden},
series = {TechDebt '18}
}

@inproceedings{10.1145/3018896.3036365,
author = {Ashrafi, Tasnia H. and Arefin, Sayed E. and Das, Kowshik D. J. and Hossain, Md. A. and Chakrabarty, Amitabha},
title = {FOG Based Distributed IoT Infrastructure},
year = {2017},
isbn = {9781450347747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3018896.3036365},
doi = {10.1145/3018896.3036365},
abstract = {The Internet of Things(IoT) can be defined as a network connectivity bridge between people, systems and physical world. With the increasing number of IoT devices and networks, dealing with enormous number of data efficiently is becoming more and more challenging for the present infrastructure which is a very big matter of concern. In this paper, we depicted the current infrastructure and proposed another model of IoT infrastructure to surpass the difficulties of the existing infrastructure, which will be a coordinated effort of Fog computing amalgamation with Machine-to-Machine(M2M) intelligent communication protocol followed by incorporation of Service Oriented Architecture(SOA) and finally integration of Agent based SOA. This model will have the capacity to exchange data by breaking down dependably and methodically with low latency, less bandwidth, heterogeneity in less measure of time maintaining the Quality of Service(QoS) precisely.},
booktitle = {Proceedings of the Second International Conference on Internet of Things, Data and Cloud Computing},
articleno = {124},
numpages = {13},
keywords = {M2M communication, quality of service (QoS), service oriented architecture(SOA), heterogeneous devices, internet of things (IoT), agent based SOA, fog computing},
location = {Cambridge, United Kingdom},
series = {ICC '17}
}

@inproceedings{10.1145/2577036.2577038,
author = {V\"{o}gele, Christian and Brunnert, Andreas and Danciu, Alexandru and Tertilt, Daniel and Krcmar, Helmut},
title = {Using Performance Models to Support Load Testing in a Large SOA Environment},
year = {2014},
isbn = {9781450327626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2577036.2577038},
doi = {10.1145/2577036.2577038},
abstract = {Load testing in large service-oriented architecture (SOA) environments is especially challenging when services are under the control of different teams. It gets even more difficult if services need to be scaled before a load test starts. It is thus important to estimate workloads for services involved in a load test. Service workloads can be specified by the amount of service operation invocations distributed over time. We propose the use of performance models to derive this information for SOA-based applications before executing load tests. In a first step, we use these models to select usage scenarios. Afterwards, these models are transformed in a way that each scenario can be simulated separately from each other. These simulations can predict service workloads for selected usage scenarios and different user counts.},
booktitle = {Proceedings of the Third International Workshop on Large Scale Testing},
pages = {5–6},
numpages = {2},
keywords = {performance models, service workload, usage scenario, service-oriented architecture, load testing},
location = {Dublin, Ireland},
series = {LT '14}
}

@inproceedings{10.1145/2642937.2653471,
author = {Miranda, Breno},
title = {A Proposal for Revisiting Coverage Testing Metrics},
year = {2014},
isbn = {9781450330138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2642937.2653471},
doi = {10.1145/2642937.2653471},
abstract = {Test coverage information can be very useful for guiding testers in enhancing their test suites to exercise possible uncovered entities and in deciding when to stop testing. Since the concept of test criterion was born, several contributions have been made by both academia and industry in the definition and adaptation of adequacy criteria aiming at ensuring the discovery of more failures. Numerous contributions have also been done in the development of coverage tools. However, for complex applications that are reused in different contexts and for emerging paradigms (e.g., component-based development, service-oriented architecture, and cloud computing), traditional coverage metrics may no longer provide meaningful information to help testers on these tasks. Inspired by the idea of relative coverage this research focuses on the introduction of meaningful coverage metrics to cope with the challenges imposed by the current programming paradigms as well as on the definition of a theoretical framework for the development of relative coverage metrics.},
booktitle = {Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering},
pages = {899–902},
numpages = {4},
keywords = {relative coverage, coverage testing, traditional coverage},
location = {Vasteras, Sweden},
series = {ASE '14}
}

@inproceedings{10.1145/3068126.3068128,
author = {Filelis-Papadopoulos, C. K. and Gravvanis, G. A. and Morrison, J. P.},
title = {CloudLightning Simulation and Evaluation Roadmap},
year = {2017},
isbn = {9781450349369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3068126.3068128},
doi = {10.1145/3068126.3068128},
abstract = {The CloudLightning (CL) system, designed in the frame of the CloudLightning project, is a service-oriented architecture for the emerging large scale heterogeneous cloud. It facilitates a clear distinction between service-lifecyle management and resource-lifecycle management. This separation of concerns is used to make resource management issues tractable at scale and to enable functionality that is currently not naturally covered by the cloud paradigm. In particular, the CL project seeks to maximize computational efficiency of the cloud in a number of specific ways; by exploiting prebuilt HPC environments, by dynamically building HPC instances, by improving server utilization, by reducing power consumption and by improving service delivery. Given the scale and complexity of this project, its utility can presently only be measured through simulation. This paper outlines the parameters, constraints and limitation being considered as part of the design and construction of that simulation environment.},
booktitle = {Proceedings of the 1st International Workshop on Next Generation of Cloud Architectures},
articleno = {2},
numpages = {6},
keywords = {Self - Management, Evaluation, Self - Organisation, CloudLightning},
location = {Belgrade, Serbia},
series = {CloudNG:17}
}

@inproceedings{10.1145/3019612.3019805,
author = {Abid, Ahmed and Messai, Nizar and Rouached, Mohsen and Abid, Mohamed and Devogele, Thomas},
title = {Semantic Similarity Based Web Services Composition Framework},
year = {2017},
isbn = {9781450344869},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3019612.3019805},
doi = {10.1145/3019612.3019805},
abstract = {Computing similarities between Web services is a main concern in Service Oriented Architecture as it allows to decide which services are likely to be matched into a composite workflow, or in other cases, which services can be substituted in order to ensure continuous service availability. With the high maturity achieved by the standards, tools and frameworks in the Semantic Web domain, measuring Web services similarities relies more than ever on semantic descriptions of services as well as on semantic relationships these descriptions may hold. In this paper we present a Framework for Web services composition based on computing semantic similarity between Web services. We particularly focus on Services Matching engine which uses the considered similarity measure first to classify Web services into classes of functionally similar Web services and then to propose a composite sequence of services that matches a requested goal. In both tasks, the presented framework appeals for best known techniques of similarity computing and data and knowledge extraction, respectively.},
booktitle = {Proceedings of the Symposium on Applied Computing},
pages = {1319–1325},
numpages = {7},
keywords = {semantic similarity, discovery and composition, web services, matching},
location = {Marrakech, Morocco},
series = {SAC '17}
}

@inproceedings{10.1145/3127479.3132020,
author = {Suresh, Lalith and Bodik, Peter and Menache, Ishai and Canini, Marco and Ciucu, Florin},
title = {Distributed Resource Management across Process Boundaries},
year = {2017},
isbn = {9781450350280},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3127479.3132020},
doi = {10.1145/3127479.3132020},
abstract = {Multi-tenant distributed systems composed of small services, such as Service-oriented Architectures (SOAs) and Micro-services, raise new challenges in attaining high performance and efficient resource utilization. In these systems, a request execution spans tens to thousands of processes, and the execution paths and resource demands on different services are generally not known when a request first enters the system. In this paper, we highlight the fundamental challenges of regulating load and scheduling in SOAs while meeting end-to-end performance objectives on metrics of concern to both tenants and operators. We design Wisp, a framework for building SOAs that transparently adapts rate limiters and request schedulers system-wide according to operator policies to satisfy end-to-end goals while responding to changing system conditions. In evaluations against production as well as synthetic workloads, Wisp successfully enforces a range of end-to-end performance objectives, such as reducing average latencies, meeting deadlines, providing fairness and isolation, and avoiding system overload.},
booktitle = {Proceedings of the 2017 Symposium on Cloud Computing},
pages = {611–623},
numpages = {13},
keywords = {scheduling, resource management, rate limiting, service-oriented architectures, microservices},
location = {Santa Clara, California},
series = {SoCC '17}
}

@inproceedings{10.1145/2739480.2754724,
author = {Ouni, Ali and Gaikovina Kula, Raula and Kessentini, Marouane and Inoue, Katsuro},
title = {Web Service Antipatterns Detection Using Genetic Programming},
year = {2015},
isbn = {9781450334723},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2739480.2754724},
doi = {10.1145/2739480.2754724},
abstract = {Service-Oriented Architecture (SOA) is an emerging paradigm that has radically changed the way software applications are architected, designed and implemented. SOA allows developers to structure their systems as a set of ready-made, reusable and compostable services. The leading technology used today for implementing SOA is Web Services. Indeed, like all software, Web services are prone to change constantly to add new user requirements or to adapt to environment changes. Poorly planned changes may risk introducing antipatterns into the system. Consequently, this may ultimately leads to a degradation of software quality, evident by poor quality of service (QoS). In this paper, we introduce an automated approach to detect Web service antipatterns using genetic programming. Our approach consists of using knowledge from real-world examples of Web service antipatterns to generate detection rules based on combinations of metrics and threshold values. We evaluate our approach on a benchmark of 310 Web services and a variety of five types of Web service antipatterns. The statistical analysis of the obtained results provides evidence that our approach is efficient to detect most of the existing antipatterns with a score of 85\% of precision and 87\% of recall.},
booktitle = {Proceedings of the 2015 Annual Conference on Genetic and Evolutionary Computation},
pages = {1351–1358},
numpages = {8},
keywords = {search-based software engineering, antipatterns, web services},
location = {Madrid, Spain},
series = {GECCO '15}
}

@inproceedings{10.1145/2996913.2997007,
author = {Chondrogiannis, Theodoros and Gamper, Johann and Cavaliere, Roberto and Ohnewein, Patrick},
title = {MoTrIS: A Framework for Route Planning on Multimodal Transportation Networks},
year = {2016},
isbn = {9781450345897},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2996913.2997007},
doi = {10.1145/2996913.2997007},
abstract = {In this paper, we present MoTrIS, a service-oriented framework which enables spatio-temporal query processing on multimodal networks that are composed of a road network and one or more schedule-based transportation networks. MoTrIS provides a remote access API, which allows for the development of applications that require the processing of routing queries on multimodal networks. We discuss the architecture of MoTrIS and we elaborate on each of its individual components. The data input module allows for the import of data from various sources into a spatial-enabled relational database. The network module builds a multimodal network by combining a road network with one or more transportation networks. The timetable module stores and queries the schedule for each transportation mode. The query processing module enables the execution of queries over the multimodal network. The visualization module exports the results into a visualizable format. Finally, we present a web application which allows users to create, modify and test advanced spatio-temporal services, and we demonstrate all the necessary steps for a user to build such a new service.},
booktitle = {Proceedings of the 24th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems},
articleno = {82},
numpages = {4},
keywords = {multimodal networks, route planning, query services},
location = {Burlingame, California},
series = {SIGSPACIAL '16}
}

@inproceedings{10.1145/3241403.3241430,
author = {de Amorim Silva, Rafael and Braga, Rosana T. V.},
title = {An Acknowledged System of Systems for Educational Internet of Everything Ecosystems},
year = {2018},
isbn = {9781450364836},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3241403.3241430},
doi = {10.1145/3241403.3241430},
abstract = {Internet of Everything (IoE) is the next evolutionary step of Internet of Things (IoT). This paradigm evolves IoT by transforming it into an accessed, monitored and controlled global pervasive network for all the Internet. The IoE network must integrate embedded devices, people, processes and data in order to provide relevant information for various application areas such as medical, industry, aerospace, agrobusiness, automation, education, among others. In this paper, we propose an acknowledged System of Systems (SoS) to integrate IoE ecosystems that operate into educational environments. This SoS implements a service-oriented architecture to provide services as interfaces between constituent systems (CS). A CS is mediated by a negotiator agent that can be requested by the SoS coordinator agent to identify the availability of specific resources demanded by other CS. This coordinator agent is responsible for recommending the CS with the best available resource for the requester CS and providing information about how access it. All the IoE components also may be mediated by intelligent agents thus increasing the robustness of an IoE ecosystem.},
booktitle = {Proceedings of the 12th European Conference on Software Architecture: Companion Proceedings},
articleno = {25},
numpages = {7},
keywords = {multi-agent systems, internet of everything, cyber-physical ecosystems, system of systems, service-oriented architecture},
location = {Madrid, Spain},
series = {ECSA '18}
}

@inproceedings{10.1145/3230833.3233278,
author = {Mathas, Christos M. and Segou, Olga E. and Xylouris, Georgios and Christinakis, Dimitris and Kourtis, Michail-Alexandros and Vassilakis, Costas and Kourtis, Anastasios},
title = {Evaluation of Apache Spot's Machine Learning Capabilities in an SDN/NFV Enabled Environment},
year = {2018},
isbn = {9781450364485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3230833.3233278},
doi = {10.1145/3230833.3233278},
abstract = {Software Defined Networking (SDN) and Network Function Virtualisation (NFV) are transforming modern networks towards a service-oriented architecture. At the same time, the cybersecurity industry is rapidly adopting Machine Learning (ML) algorithms to improve detection and mitigation of complex attacks. Traditional intrusion detection systems perform signature-based detection, based on well-known malicious traffic patterns that signify potential attacks. The main drawback of this method is that attack patterns need to be known in advance and signatures must be preconfigured. Hence, typical systems fail to detect a zero-day attack or an attack with unknown signature. This work considers the use of machine learning for advanced anomaly detection, and specifically deploys the Apache Spot ML framework on an SDN/NFV-enabled testbed running cybersecurity services as Virtual Network Functions (VNFs). VNFs are used to capture traffic for ingestion by the ML algorithm and apply mitigation measures in case of a detected anomaly. Apache Spot utilises Latent Dirichlet Allocation to identify anomalous traffic patterns in Netflow, DNS and proxy data. The overall performance of Apache Spot is evaluated by deploying Denial of Service (Slowloris, BoNeSi) and a Data Exfiltration attack (iodine).},
booktitle = {Proceedings of the 13th International Conference on Availability, Reliability and Security},
articleno = {52},
numpages = {10},
keywords = {Apache Spot, Software Defined Networking, SHIELD Project, Machine Learning, Penetration Testing, Latent Dirichlet Allocation, Network Function Virtualisation},
location = {Hamburg, Germany},
series = {ARES '18}
}

@inproceedings{10.1145/3330204.3330259,
author = {Mendes, Yan and Braga, Regina and Str\"{o}ele, Victor and de Oliveira, Daniel},
title = {Polyflow: A SOA for Analyzing Workflow Heterogeneous Provenance Data in Distributed Environments},
year = {2019},
isbn = {9781450372374},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3330204.3330259},
doi = {10.1145/3330204.3330259},
abstract = {In the last decade the (big) data-driven science paradigm became a wide-spread reality. However, this approach has some limitations such as a performance dependency on the quality of the data and the lack of reproducibility of the results. In order to enable this reproducibility, many tools such as Workflow Management Systems were developed to formalize process pipelines and capture execution traces. However, interoperating data generated by these solutions became a problem, since most systems adopted proprietary data models. To support interoperability across heterogeneous provenance data, we propose a Service Oriented Architecture with a polystore storage design in which provenance is conceptually represented utilizing the ProvONE model. A wrapper layer is responsible for transforming data described by heterogeneous formats into ProvONE-compliant. Moreover, we propose a query layer that provides location and access transparency to users. Furthermore, we conduct two feasibility studies, showcasing real usecase scenarios. Firstly, we illustrate how two research groups can compare their processes and results. Secondly, we show how our architecture can be used as a queriable provenance repository. We show Polyflow's viability for both scenarios using the Goal-Question-Metric methodology. Finally, we show our solution usability and extensibility appeal by comparing it to similar approaches.},
booktitle = {Proceedings of the XV Brazilian Symposium on Information Systems},
articleno = {49},
numpages = {8},
keywords = {Workflows interoperability, polystore, heterogeneous provenance data integration},
location = {Aracaju, Brazil},
series = {SBSI '19}
}

@inproceedings{10.1145/2691195.2691236,
author = {Dash, Shefali S. and Sethi, I. P. S. and Maurya, Ashutosh P.},
title = {Government Initiative for Automation of Co-Operative Banks Structure through Core Banking Solution},
year = {2014},
isbn = {9781605586113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2691195.2691236},
doi = {10.1145/2691195.2691236},
abstract = {National Informatics Centre (NIC) has developed a core banking software with name Co-operative Core Banking Solution (CCBS), considering requirement of Indian co-operative banking sector. Along with software development, NIC also provide implementation and hosting service of this software for co-operative sector under Software as a Service Model. Due to latest Service Oriented Architecture of software, NIC-CCBS is able to integrate other central / state government software/applications and can generate meaningful MIS for decision / policy making for management level. This can also provide a good platform for other e-governance projects by establishing network connectivity, computer awareness and capacity building.NIC-CCBS is implemented at more than 100 co-operative bank locations across two states of India i.e. Chhattisgarh \&amp; Meghalaya and serving more than 20000 banking transactions on daily basis. NIC -- CCBS implementation has been implemented in step wise process which includes Business understanding, Process engineering, Data digitization, Data quality, Data Migration, hands hold support. On completion of CCBS application for State Co-operative Bank, District Central Co-operative Bank, Primary Agriculture Co-operative societies, NIC is moving ahead to serve to Agricultural Land Development Banks, Treasury Banks and State financial corporations.},
booktitle = {Proceedings of the 8th International Conference on Theory and Practice of Electronic Governance},
pages = {478–479},
numpages = {2},
keywords = {cooperative, change process, banking solution, software, implementation},
location = {Guimaraes, Portugal},
series = {ICEGOV '14}
}

@inproceedings{10.5555/2819009.2819091,
author = {Lyons, Kelly and Oh, Christie},
title = {SOA4DM: Applying an SOA Paradigm to Coordination in Humanitarian Disaster Response},
year = {2015},
publisher = {IEEE Press},
abstract = {Despite efforts to achieve a sustainable state of control over the management of global crises, disasters are occurring with greater frequency, intensity, and affecting many more people than ever before while the resources to deal with them do not grow apace. As we enter 2015, with continued concerns that mega-crises may become the new normal, we need to develop novel methods to improve the efficiency and effectiveness of our management of disasters. Software engineering as a discipline has long had an impact on society beyond its role in the development of software systems. In fact, software engineers have been described as the developers of prototypes for future knowledge workers; tools such as Github and Stack Overflow have demonstrated applications beyond the domain of software engineering. In this paper, we take the potential influence of software engineering one-step further and propose using the software service engineering paradigm as a new approach to managing disasters. Specifically, we show how the underlying principles of service-oriented architectures (SOA) can be applied to the coordination of disaster response operations. We describe key challenges in coordinating disaster response and discuss how an SOA approach can address those challenges.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {519–522},
numpages = {4},
keywords = {SOA, disaster response},
location = {Florence, Italy},
series = {ICSE '15}
}

@article{10.14778/2733004.2733009,
author = {Poess, Meikel and Rabl, Tilmann and Jacobsen, Hans-Arno and Caufield, Brian},
title = {TPC-DI: The First Industry Benchmark for Data Integration},
year = {2014},
issue_date = {August 2014},
publisher = {VLDB Endowment},
volume = {7},
number = {13},
issn = {2150-8097},
url = {https://doi.org/10.14778/2733004.2733009},
doi = {10.14778/2733004.2733009},
abstract = {Historically, the process of synchronizing a decision support system with data from operational systems has been referred to as Extract, Transform, Load (ETL) and the tools supporting such process have been referred to as ETL tools. Recently, ETL was replaced by the more comprehensive acronym, data integration (DI). DI describes the process of extracting and combining data from a variety of data source formats, transforming that data into a unified data model representation and loading it into a data store. This is done in the context of a variety of scenarios, such as data acquisition for business intelligence, analytics and data warehousing, but also synchronization of data between operational applications, data migrations and conversions, master data management, enterprise data sharing and delivery of data services in a service-oriented architecture context, amongst others. With these scenarios relying on up-to-date information it is critical to implement a highly performing, scalable and easy to maintain data integration system. This is especially important as the complexity, variety and volume of data is constantly increasing and performance of data integration systems is becoming very critical. Despite the significance of having a highly performing DI system, there has been no industry standard for measuring and comparing their performance. The TPC, acknowledging this void, has released TPC-DI, an innovative benchmark for data integration. This paper motivates the reasons behind its development, describes its main characteristics including workload, run rules, metric, and explains key decisions.},
journal = {Proc. VLDB Endow.},
month = {aug},
pages = {1367–1378},
numpages = {12}
}

@inproceedings{10.1145/2642668.2642679,
author = {Hassam, Mickael and Kara, Nadjia and Belqasmi, Fatna and Glitho, Roch},
title = {Virtualized Infrastructure for Video Game Applications in Cloud Environments},
year = {2014},
isbn = {9781450330268},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2642668.2642679},
doi = {10.1145/2642668.2642679},
abstract = {Mobile video games are fast-growing and fast-evolving. Cloud computing's paradigm can bring several benefits to mobile video games, like cost reduction through an efficient usage of resources, or an easier and faster on-demand deployment of new applications. This paper focuses on the architecture aspects of mobile cloud-based video gaming and proposes a new service oriented and virtualized paradigm. The idea is to provide reusable game engines sub modules like the rendering or physics engines as cloud computing services. We call these sub modules substrates. Offered by different substrates providers as services, they can be dynamically discovered, used and composed. There are several motivations for substrates virtualization, including the rapid introduction of new video game applications and cost efficiency through resource sharing. This paper also describes the implementation of a prototype and the measurements performed to validate some aspects of our paradigm. As a preliminary validation of this solution, we analyze the effects of different parameters like virtualization or inner latency on the QoS. The performance analysis shows that the overhead introduced by substrate virtualization is acceptable, and reveals how the low-latency connectivity between substrates that compose a video game application and the limitation of the amount of these substrates are crucial to achieve a satisfactory level of QoS.},
booktitle = {Proceedings of the 12th ACM International Symposium on Mobility Management and Wireless Access},
pages = {109–114},
numpages = {6},
keywords = {infrastructure and platform as services, mobile video game applications, substrate, virtualization, cloud computing},
location = {Montreal, QC, Canada},
series = {MobiWac '14}
}

@inproceedings{10.1109/CCGrid.2015.148,
author = {Beier, Maximilian and Jansen, Christoph and Mayer, Geert and Penzel, Thomas and Rodenbeck, Andrea and Siewert, Ren\'{e} and Wu, Jie and Krefting, Dagmar},
title = {Multicenter Data Sharing for Collaboration in Sleep Medicine},
year = {2015},
isbn = {9781479980062},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGrid.2015.148},
doi = {10.1109/CCGrid.2015.148},
abstract = {Clinical Sleep Research is an inherent multidisciplinary field, as many health issues may affect a person's sleep conditions and sleep disorders may cause several health problems. Many patients with chronic sleep disorders suffer from different further medical conditions - called multimorbidity. Due to the high variety of the reasons and the courses of sleep disorders, individual cases are difficult to compare. Therefore there is a high demand for sleep researchers to collaborate with each other to reach necessary participant numbers and multidisciplinary expertise. To date, inter-institutional sleep research is poorly supported by IT systems. In particular the heterogeneity and the quality variations within the acquired biosignal data - caused by different biosignal recorders or different measurement procedures - are impeding common biosignal data processing. In this manuscript we introduce a virtual research platform supporting inter-institutional data sharing and processing. The infrastructure is based on XNAT - a free and open-source neuroimaging research platform - a loosely coupled service oriented architecture and scalable virtualization in the backend. The system is capable of local pseudonymization of biosignal data, mapping to a standardized set of parameters and automatic quality assessment. Terms and quality measures are derived from the "Manual for the Scoring of Sleep and Associated Events" of the American Academy of Sleep Medicine, the de-facto standard for diagnostic biosignal analysis in sleep medicine.},
booktitle = {Proceedings of the 15th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
pages = {880–889},
numpages = {10},
keywords = {cloud, sleep, REST, XNAT, OpenStack, biosignal, polysomnography},
location = {Shenzhen, China},
series = {CCGRID '15}
}

@article{10.1145/3386041,
author = {Shi, Min and Tang, Yufei and Zhu, Xingquan and Liu, Jianxun},
title = {Topic-Aware Web Service Representation Learning},
year = {2020},
issue_date = {May 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {1559-1131},
url = {https://doi.org/10.1145/3386041},
doi = {10.1145/3386041},
abstract = {The advent of Service-Oriented Architecture (SOA) has brought a fundamental shift in the way in which distributed applications are implemented. An overwhelming number of Web-based services (e.g., APIs and Mashups) have leveraged this shift and furthered development. Applications designed with SOA principles are typically characterized by frequent dependencies with one another in the form of heterogeneous networks, i.e., annotation relations between tags and services, and composition relations between Mashups and APIs. Although prior work has shown the utility gained by exploring these networks, their analysis is still in its infancy. This article develops an approach to learning representations of the Web service network, which seeks to embed Web services in low-dimensional continuous vectors with preserved information of the network structure, functional tags, and service descriptions, such that services with similar functional properties and network structures are mapped together in the learned latent space. We first propose a topic generative model for constructing two topic distribution networks (Mashup-Topic and API-Topic) from the service content. Then, we present an efficient optimization process to derive low-dimensional vector representations of Web services from a tri-layer bipartite network with the Mashup-Topic and API-Topic networks on two ends and the Mashup-API composition network in the middle. Experiments on real-word datasets have verified that our approach is effective to learn robust low-rank service representations, i.e., 25\% F1-measure gain over the state-of-the-art in Web service recommendation task.},
journal = {ACM Trans. Web},
month = {apr},
articleno = {9},
numpages = {23},
keywords = {Web services, Mashups, probabilistic topic model, network embedding, service representation}
}

@inproceedings{10.1145/3183519.3183537,
author = {Au\'{e}, Joop and Aniche, Maur\'{\i}cio and Lobbezoo, Maikel and van Deursen, Arie},
title = {An Exploratory Study on Faults in Web API Integration in a Large-Scale Payment Company},
year = {2018},
isbn = {9781450356596},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183519.3183537},
doi = {10.1145/3183519.3183537},
abstract = {Service-oriented architectures are more popular than ever, and increasingly companies and organizations depend on services offered through Web APIs. The capabilities and complexity of Web APIs differ from service to service, and therefore the impact of API errors varies. API problem cases related to Adyen's payment service were found to have direct considerable impact on API consumer applications. With more than 60,000 daily API errors, the potential impact is enormous. In an effort to reduce the impact of API related problems, we analyze 2.43 million API error responses to identify the underlying faults. We quantify the occurrence of faults in terms of the frequency and impacted API consumers. We also challenge our quantitative results by means of a survey with 40 API consumers. Our results show that 1) faults in API integration can be grouped into 11 general causes: invalid user input, missing user input, expired request data, invalid request data, missing request data, insufficient permissions, double processing, configuration, missing server data, internal and third party, 2) most faults can be attributed to the invalid or missing request data, and most API consumers seem to be impacted by faults caused by invalid request data and third party integration; and 3) insufficient guidance on certain aspects of the integration and on how to recover from errors is an important challenge to developers.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Software Engineering in Practice},
pages = {13–22},
numpages = {10},
keywords = {web engineering, web API integration, webservices},
location = {Gothenburg, Sweden},
series = {ICSE-SEIP '18}
}

@inproceedings{10.1145/3385032.3385042,
author = {Tummalapalli, Sahithi and Kumar, Lov and Murthy, N. L. Bhanu},
title = {Prediction of Web Service Anti-Patterns Using Aggregate Software Metrics and Machine Learning Techniques},
year = {2020},
isbn = {9781450375948},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3385032.3385042},
doi = {10.1145/3385032.3385042},
abstract = {Service-Oriented Architecture(SOA) can be characterized as an approximately coupled engineering intended to meet the business needs of an association/organization. Service-Based Systems (SBSs) are inclined to continually change to enjoy new client necessities and adjust the execution settings, similar to some other huge and complex frameworks. These changes may lead to the evolution of designs/products with poor Quality of Service (QoS), resulting in the bad practiced solutions, commonly known as Anti-patterns. Anti-patterns makes the evolution and maintenance of the software systems hard and complex. Early identification of modules, classes, or source code regions where anti-patterns are more likely to occur can help in amending and maneuvering testing efforts leading to the improvement of software quality. In this work, we investigate the application of three sampling techniques, three feature selection techniques, and sixteen different classification techniques to develop the models for web service anti-pattern detection. We report the results of an empirical study by evaluating the approach proposed, on a data set of 226 Web Service Description Language(i.e., WSDL)files, a variety of five types of web-service anti-patterns. Experimental results demonstrated that SMOTE is the best performing data sampling techniques. The experimental results also reveal that the model developed by considering Uncorrelated Significant Predictors(SUCP) as the input obtained better performance compared to the model developed by other metrics. Experimental results also show that the Least Square Support Vector Machine with Linear(LSLIN) function has outperformed all other classifier techniques.},
booktitle = {Proceedings of the 13th Innovations in Software Engineering Conference on Formerly Known as India Software Engineering Conference},
articleno = {8},
numpages = {11},
keywords = {Feature Selection, Classifiers, Service-Based Systems(SBS), Aggregation measures, Web-Services, Class imbalance distribution, Machine Learning, WSDL, Source Code Metrics, Anti-pattern},
location = {Jabalpur, India},
series = {ISEC 2020}
}

@inproceedings{10.1145/3030207.3030215,
author = {Bause, Falko and Buchholz, Peter and May, Johannes},
title = {A Tool Supporting the Analytical Evaluation of Service Level Agreements},
year = {2017},
isbn = {9781450344043},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030207.3030215},
doi = {10.1145/3030207.3030215},
abstract = {Quantitative aspects of modern IT systems are often specified by service level agreements (SLAs) which relate the maximal load of a system with guaranteed bounds for response times and delays. These quantities are specified for single services which are combined in a service oriented architecture (SOA) to composed services offered to potential users or other service providers. To derive SLAs for composed services and to plan the required capacity to guarantee SLAs, appropriate methods and tools have to be used that compute results based on information given in SLAs. In this paper it is argued that most available approaches are not sufficient to analyze systems based on SLA information. A new method and a tool are presented that support the efficient calculation of bounds for delays in composed systems based on bounds for the load and the delay of the individual components which are specified in the SLAs of the components. Furthermore, the presented tool can be used to generate bounds for the required processing capacity which a provider has to provide in order to guarantee the quality of service defined in the SLAs.The presented approach is in some sense a counterpart to mean value analysis for queueing networks but rather than mean values, worst case bounds for different quantities like response times or departure processes are computed. Analysis is based on min/+ algebra but the mathematical approach is hidden from the user by a graphical interface allowing a simple graphical specification and result representation for networks of composed services.},
booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering},
pages = {233–244},
numpages = {12},
keywords = {analytical evaluation, performance modeling tools, service level agreements},
location = {L'Aquila, Italy},
series = {ICPE '17}
}

@proceedings{10.1145/2676733,
title = {MW4NG '14: Proceedings of the 9th Workshop on Middleware for Next Generation Internet Computing},
year = {2014},
isbn = {9781450332224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {While dependability and security become cornerstones of the information society, they are impaired by change, imprecision, and emerging behavior due to scale, dynamism, and heterogeneity. To address these challenges for next generation Internet computing, key extrafunctional properties should not be an "add on" or an "end to end task" anymore, but rather built in by means of Middleware.Service oriented computing, cloud computing, socio-technical systems, and Web 2.0-style applications are important steps for next generation Internet computing, but still fall short when non functional (a.k.a. extra-functional) quality properties (e.g., dependability, security, performance, and scalability) need to be addressed. The emerging Internet communication architecture (e.g., from projects on the Internet of Things, the Future Internet, etc.) also requires middleware support for delivering computing applications and services. We can see many Internet Computing systems following proprietary end-to-end solutions and being weaved with application-specific approaches. This clearly hinders re-use, which can only be successfully leveraged by Middleware-based solutions. This in turn requires new flexibility for Middleware (adaptivity, elasticity, resilience) and new ways of collaboration between Middleware and applications/services.Therefore, extra-functional quality properties need to be addressed not only by interfacing and communication standards, but also in terms of actual mechanisms, protocols, and algorithms. Some of the challenges are the administrative heterogeneity, the loose coupling between coarsegrained operations and long-running interactions, high dynamism, and the required flexibility during run-time. Recently, massive-scale (e.g., big data, millions of participating parties in different roles) and mobility were added to the crucial challenges for Internet computing middleware. The workshop consequently comprises contributions on how specifically middleware can address the above challenges of next generation Internet computing.},
location = {Bordeaux, France}
}

@inproceedings{10.1145/2792838.2799499,
author = {N\'{e}meth, Botty\'{a}n},
title = {Scaling Up Recommendation Services in Many Dimensions},
year = {2015},
isbn = {9781450336925},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2792838.2799499},
doi = {10.1145/2792838.2799499},
abstract = {Gravity R&amp;D has been providing recommendation engines as SaaS solutions since 2009. The company has a strong research focus and recommendation quality has always been their primary differentiating factor. Widely used or open source recommendation algorithms are of little use to our technology team as a result of the superiority of our in-house developed, proprietary algorithms. Gravity R&amp;D experienced many challenges while scaling up their services. The sheer quantity of data handled on a daily basis increased exponentially. This presentation will cover how overcoming these challenges permanently shaped our algorithms and system architecture used to generate these recommendations. Serving personalized recommendations requires real-time computation and data access for every single request. To generate responses in real-time, current user inputs have to be compared against their history in order to deliver accurate recommendations. We then combine this user information with specific details about available items as the next step in the recommendation process. It becomes more difficult to provide accurate recommendations as the number of transactions and items increase. It also becomes difficult because this type of analysis requires the combination of multiple heterogeneous algorithms that all require different inputs. Initially, the architecture was designed for MF based models and serving huge numbers of requests but with a limited number of items. Now, Gravity is using MF, neighborhood based models and metadata based models to generate recommendations for millions of items within their databases. This required a shift from a monolithic architecture with in-process caching to a more service oriented architecture with multi-layer caching. As a result of an increase in the number of components and number of clients, managing the infrastructure can be quite difficult. Even with these challenges, we don't believe that it is worthwhile to use a fully distributed system. It adds unneeded complexity, resources, and overhead to the system. We prefer an approach of firstly optimizing current algorithms and architecture and only moving to a distributed system when no other options are left.},
booktitle = {Proceedings of the 9th ACM Conference on Recommender Systems},
pages = {233},
numpages = {1},
keywords = {scalability, performance, recommendation engine},
location = {Vienna, Austria},
series = {RecSys '15}
}

@proceedings{10.1145/2660190,
title = {FOSD '14: Proceedings of the 6th International Workshop on Feature-Oriented Software Development},
year = {2014},
isbn = {9781450329804},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Feature orientation is an emerging paradigm of software development. It supports the automatic generation of large-scale software systems from a set of units of functionality called features. The key idea of feature-oriented software development (FOSD) is to emphasize the similarities of a family of software systems for a given application domain (e.g., database systems, banking software, text processing systems) with the goal of reusing software artifacts among the family members. Features distinguish different members of the family. A feature is a unit of functionality that satisfies a requirement, represents a design decision, and provides a potential configuration option. A challenge in FOSD is that a feature does not map cleanly to an isolated module of code. Rather it may affect («cut across») many components/artifacts of a software system. Furthermore, the decomposition of a software system into its features gives rise to a combinatorial explosion of possible feature combinations and interactions. Research on FOSD has shown that the concept of features pervades all phases of the software life cycle and requires a proper treatment in terms of analysis, design, and programming techniques, methods, languages, and tools, as well as formalisms and theory.The goal of the workshop is to foster and strengthen the collaboration between the researchers and practitioners who work in the field of FOSD or in the related fields of software product lines, service-oriented architecture, model-driven engineering and feature interactions. The workshop's focus is on discussions, rather than on presenting technical content only. FOSD'14 was scheduled for one full day. After the keynote by Jo Atlee, the day was divided into two sessions. In the Research session, accepted research papers were presented. To stimulate discussions, each paper was assigned a "devil's advocate," who was supposed to prepare a set of one to three controversial questions, and to step into the discussion when appropriate. The FOSD in Practice session comprised practice-oriented "tech talks" that present or demonstrate the application of FOSD and respective technologies (methods, tools, analyses).},
location = {V\"{a}ster\r{a}s, Sweden}
}

@inproceedings{10.1145/3457913.3457939,
author = {Wei, Yuyang and Yu, Yijun and Pan, Minxue and Zhang, Tian},
title = {A Feature Table Approach to Decomposing Monolithic Applications into Microservices},
year = {2021},
isbn = {9781450388191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3457913.3457939},
doi = {10.1145/3457913.3457939},
abstract = {Microservice architecture refers to the use of numerous small-scale and independently deployed services, instead of encapsulating all functions into one monolith. It has been a challenge in software engineering to decompose a monolithic system into smaller parts. In this paper, we propose the Feature Table approach, a structured approach to service decomposition based on the correlation between functional features and microservices: (1) we defined the concept of Feature Cards and 12 instances of such cards; (2) we formulated Decomposition Rules to decompose monolithic applications; (3) we designed the Feature Table Analysis Tool to provide semi-automatic analysis for identification of microservices; and (4) we formulated Mapping Rules to help developers implement microservice candidates. We performed a case study on Cargo Tracking System to validate our microservice-oriented decomposition approach. Cargo Tracking System is a typical case that has been decomposed by other related methods (dataflow-driven approach, Service Cutter, and API Analysis). Through comparison with the related methods in terms of specific coupling and cohesion metrics, the results show that the proposed Feature Table approach can deliver more reasonable microservice candidates, which are feasible in implementation with semi-automatic support.},
booktitle = {Proceedings of the 12th Asia-Pacific Symposium on Internetware},
pages = {21–30},
numpages = {10},
keywords = {monolith decomposition, Microservices, microservice architecture},
location = {Singapore, Singapore},
series = {Internetware '20}
}

@inproceedings{10.1145/3425269.3425273,
author = {de Freitas Apolin\'{a}rio, Daniel Rodrigo and de Fran\c{c}a, Breno Bernard Nicolau},
title = {Towards a Method for Monitoring the Coupling Evolution of Microservice-Based Architectures},
year = {2020},
isbn = {9781450387545},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3425269.3425273},
doi = {10.1145/3425269.3425273},
abstract = {The microservice architecture is claimed to satisfy ongoing software development demands, such as resilience, flexibility, and velocity. However, developing applications based on microservices also brings some drawbacks, such as the increased software operational complexity. Recent studies have also pointed out the lack of methods to prevent problems related to the maintainability of these solutions. Disregarding established design principles during the software evolution may lead to the so-called architectural erosion, which can end up in a condition of unfeasible maintenance. As microservices can be considered a new architecture style, there are few initiatives to monitoring the evolution of software microservice-based architectures. In this paper, we introduce the SYMBIOTE method for monitoring the coupling evolution of microservice-based systems. More specifically, this method collects coupling metrics during runtime (staging or production environments) and monitors them throughout software evolution. The longitudinal analysis of the collected measures allows detecting an upward trend in coupling metrics that could be signs of architectural erosion. To develop the proposed method, we performed an experimental analysis of the coupling metrics behavior using artificially-generated data.},
booktitle = {Proceedings of the 14th Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {71–80},
numpages = {10},
keywords = {software evolution, microservices, maintainability, coupling metrics},
location = {Natal, Brazil},
series = {SBCARS '20}
}

@inproceedings{10.1145/3412841.3442016,
author = {Brito, Miguel and Cunha, J\'{a}come and Saraiva, Jo\~{a}o},
title = {Identification of Microservices from Monolithic Applications through Topic Modelling},
year = {2021},
isbn = {9781450381048},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3412841.3442016},
doi = {10.1145/3412841.3442016},
abstract = {Microservices emerged as one of the most popular architectural patterns in the recent years given the increased need to scale, grow and flexibilize software projects accompanied by the growth in cloud computing and DevOps. Many software applications are being submitted to a process of migration from its monolithic architecture to a more modular, scalable and flexible architecture of microservices. This process is slow and, depending on the project's complexity, it may take months or even years to complete.This paper proposes a new approach on microservice identification by resorting to topic modelling in order to identify services according to domain terms. This approach in combination with clustering techniques produces a set of services based on the original software. The proposed methodology is implemented as an open-source tool for exploration of monolithic architectures and identification of microservices. A quantitative analysis using the state of the art metrics on independence of functionality and modularity of services was conducted on 200 open-source projects collected from GitHub. Cohesion at message and domain level metrics' showed medians of roughly 0.6. Interfaces per service exhibited a median of 1.5 with a compact interquartile range. Structural and conceptual modularity revealed medians of 0.2 and 0.4 respectively.Our first results are positive demonstrating beneficial identification of services due to overall metrics' results.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on Applied Computing},
pages = {1409–1418},
numpages = {10},
location = {Virtual Event, Republic of Korea},
series = {SAC '21}
}

@inproceedings{10.1145/3366423.3380111,
author = {Ma, Meng and Xu, Jingmin and Wang, Yuan and Chen, Pengfei and Zhang, Zonghua and Wang, Ping},
title = {AutoMAP: Diagnose Your Microservice-Based Web Applications Automatically},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380111},
doi = {10.1145/3366423.3380111},
abstract = {The high complexity and dynamics of the microservice architecture make its application diagnosis extremely challenging. Static troubleshooting approaches may fail to obtain reliable model applies for frequently changing situations. Even if we know the calling dependency of services, we lack a more dynamic diagnosis mechanism due to the existence of indirect fault propagation. Besides, algorithm based on single metric usually fail to identify the root cause of anomaly, as single type of metric is not enough to characterize the anomalies occur in diverse services. In view of this, we design a novel tool, named AutoMAP, which enables dynamic generation of service correlations and automated diagnosis leveraging multiple types of metrics. In AutoMAP, we propose the concept of anomaly behavior graph to describe the correlations between services associated with different types of metrics. Two binary operations, as well as a similarity function on behavior graph are defined to help AutoMAP choose appropriate diagnosis metric in any particular scenario. Following the behavior graph, we design a heuristic investigation algorithm by using forward, self, and backward random walk, with an objective to identify the root cause services. To demonstrate the strengths of AutoMAP, we develop a prototype and evaluate it in both simulated environment and real-work enterprise cloud system. Experimental results clearly indicate that AutoMAP achieves over 90\% precision, which significantly outperforms other selected baseline methods. AutoMAP can be quickly deployed in a variety of microservice-based systems without any system knowledge. It also supports introduction of various expert knowledge to improve accuracy.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {246–258},
numpages = {13},
keywords = {web application, anomaly diagnosis, root cause, Microservice architecture, cloud computing},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/3147234.3148111,
author = {L\'{o}pez, Manuel Ram\'{\i}rez and Spillner, Josef},
title = {Towards Quantifiable Boundaries for Elastic Horizontal Scaling of Microservices},
year = {2017},
isbn = {9781450351959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3147234.3148111},
doi = {10.1145/3147234.3148111},
abstract = {One of the most useful features of a microservices architecture is its versatility to scale horizontally. However, not all services scale in or out uniformly. The performance of an application composed of microservices depends largely on a suitable combination of replica count and resource capacity. In practice, this implies limitations to the efficiency of autoscalers which often overscale based on an isolated consideration of single service metrics. Consequently, application providers pay more than necessary despite zero gain in overall performance. Solving this issue requires an application-specific determination of scaling limits due to the general infeasibility of an application-agnostic solution. In this paper, we study microservices scalability, the auto-scaling of containers as microservice implementations and the relation between the number of replicas and the resulting application task performance. We contribute a replica count determination solution with a mathematical approach. Furthermore, we offer a calibration software tool which places scalability boundaries into declarative composition descriptions of applications ready to be consumed by cloud platforms.},
booktitle = {Companion Proceedings of The10th International Conference on Utility and Cloud Computing},
pages = {35–40},
numpages = {6},
keywords = {scalability, microservices, replication, optimization},
location = {Austin, Texas, USA},
series = {UCC '17 Companion}
}

@inproceedings{10.1145/3011141.3011179,
author = {de Camargo, Andr\'{e} and Salvadori, Ivan and Mello, Ronaldo dos Santos and Siqueira, Frank},
title = {An Architecture to Automate Performance Tests on Microservices},
year = {2016},
isbn = {9781450348072},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3011141.3011179},
doi = {10.1145/3011141.3011179},
abstract = {The microservices architecture provides a new approach to develop applications. As opposed to monolithic applications, in which the application comprises a single software artifact, an application based on the microservices architecture is composed by a set of services, each one designed to perform a single and well-defined task. These services allow the development team to decouple several parts of the application using different frameworks, languages and hardware for each part of the system. One of the drawbacks for adopting the microservices architecture to develop applications is testability. In a single application test boundaries can be more easily established and tend to be more stable as the application evolves, while with microservices we can have a set of hundreds of services that operate together and are prone to change more rapidly. Each one of these services needs to be tested and updated as the service changes. In addition, the different characteristics of these services such as languages, frameworks or the used infrastructure have to be considered in the testing phase. Performance tests are applied to assure that a particular software complies with a set of non-functional requirements such as throughput and response time. These metrics are important to ensure that business constraints are respected and to help finding performance bottlenecks. In this paper, we present a new approach to allow the performance tests to be executed in an automated way, with each microservice providing a test specification that is used to perform tests. Along with the architecture, we also provide a framework that implements some key concepts of this architecture. This framework is available as an open source project1.},
booktitle = {Proceedings of the 18th International Conference on Information Integration and Web-Based Applications and Services},
pages = {422–429},
numpages = {8},
keywords = {test automation, performance test, microservices},
location = {Singapore, Singapore},
series = {iiWAS '16}
}

@inproceedings{10.1145/3308558.3313653,
author = {Shan, Huasong and Chen, Yuan and Liu, Haifeng and Zhang, Yunpeng and Xiao, Xiao and He, Xiaofeng and Li, Min and Ding, Wei},
title = {??-Diagnosis: Unsupervised and Real-Time Diagnosis of Small- Window Long-Tail Latency in Large-Scale Microservice Platforms},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313653},
doi = {10.1145/3308558.3313653},
abstract = {Microservice architectures and container technologies are broadly adopted by giant internet companies to support their web services, which typically have a strict service-level objective (SLO), tail latency, rather than average latency. However, diagnosing SLO violations, e.g., long tail latency problem, is non-trivial for large-scale web applications in shared microservice platforms due to million-level operational data and complex operational environments. We identify a new type of tail latency problem for web services, small-window long-tail latency (SWLT), which is typically aggregated during a small statistical window (e.g., 1-minute or 1-second). We observe SWLT usually occurs in a small number of containers in microservice clusters and sharply shifts among different containers at different time points. To diagnose root-causes of SWLT, we propose an unsupervised and low-cost diagnosis algorithm-?-Diagnosis, using two-sample test algorithm and ?-statistics for measuring similarity of time series to identify root-cause metrics from millions of metrics. We implement and deploy a real-time diagnosis system in our real-production microservice platforms. The evaluation using real web application datasets demonstrates that ?-Diagnosis can identify all the actual root-causes at runtime and significantly reduce the candidate problem space, outperforming other time-series distance based root-cause analysis algorithms.},
booktitle = {The World Wide Web Conference},
pages = {3215–3222},
numpages = {8},
keywords = {Root-cause analysis, tail latency, time series similarity},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@article{10.14778/3484224.3484232,
author = {Laigner, Rodrigo and Zhou, Yongluan and Salles, Marcos Antonio Vaz and Liu, Yijian and Kalinowski, Marcos},
title = {Data Management in Microservices: State of the Practice, Challenges, and Research Directions},
year = {2021},
issue_date = {September 2021},
publisher = {VLDB Endowment},
volume = {14},
number = {13},
issn = {2150-8097},
url = {https://doi.org/10.14778/3484224.3484232},
doi = {10.14778/3484224.3484232},
abstract = {Microservices have become a popular architectural style for data-driven applications, given their ability to functionally decompose an application into small and autonomous services to achieve scalability, strong isolation, and specialization of database systems to the workloads and data formats of each service. Despite the accelerating industrial adoption of this architectural style, an investigation of the state of the practice and challenges practitioners face regarding data management in microservices is lacking. To bridge this gap, we conducted a systematic literature review of representative articles reporting the adoption of microservices, we analyzed a set of popular open-source microservice applications, and we conducted an online survey to cross-validate the findings of the previous steps with the perceptions and experiences of over 120 experienced practitioners and researchers.Through this process, we were able to categorize the state of practice of data management in microservices and observe several foundational challenges that cannot be solved by software engineering practices alone, but rather require system-level support to alleviate the burden imposed on practitioners. We discuss the shortcomings of state-of-the-art database systems regarding microservices and we conclude by devising a set of features for microservice-oriented database systems.},
journal = {Proc. VLDB Endow.},
month = {sep},
pages = {3348–3361},
numpages = {14}
}

@inproceedings{10.1145/3126858.3126873,
author = {Brilhante, Jonathan and Costa, Rostand and Maritan, Tiago},
title = {Asynchronous Queue Based Approach for Building Reactive Microservices},
year = {2017},
isbn = {9781450350969},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3126858.3126873},
doi = {10.1145/3126858.3126873},
abstract = {To achieve scalability and flexibility in larger applications a new approach arises, named by Microservices (MS). However MS architectures are at their inception and are even more a concept than a fully mature design pattern. One of the hardest topics in this approach is how to properly migrate or develop a single microservice, in terms of scope, efficiency and dependability. In this sense, this work proposes a new architectural model based on high-level architecture pattern of reactive programming to the internal structure of a new microservice. The new model of microservices are internally coordinated by asynchronous queues, which allowed to preserve compatibility with most monolithic components and provide an encapsulation process to enable its continuity. A comparative study between the standard approach and the proposed architecture was carried out to measure the eventual performance improvement of the new strategy.},
booktitle = {Proceedings of the 23rd Brazillian Symposium on Multimedia and the Web},
pages = {373–380},
numpages = {8},
keywords = {reactive approach, micro services, refactoring, asynchronous queues},
location = {Gramado, RS, Brazil},
series = {WebMedia '17}
}

@inproceedings{10.1109/ECASE.2019.00013,
author = {Yuan, Eric},
title = {Architecture Interoperability and Repeatability with Microservices: An Industry Perspective},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ECASE.2019.00013},
doi = {10.1109/ECASE.2019.00013},
abstract = {Microservices, along with supporting technologies such as containers, have become a prevalent architecture approach for today's software systems, especially in enterprise environments. They represent the latest evolutionary step in the decades-old journey towards service- and component-based software architectures. Along with virtualization technologies, microservices have enabled the loose-coupling of both service interfaces (message passing) and service integration (form and fit). This paper attempts to explore the impact of microservices on software architecture interoperability and repeatability, based on our experiences in developing two microservice-based systems. Our central thesis is that, if we view software architecture as a set of principal design decisions, the microservices approach enable us to more elegantly separate these decisions from non-architectural, domain-specific ones, and thus make these decisions more interoperable, reusable, and repeatable across disparate problem domains. We therefore propose that a microservices based reference architecture (RA) and reference implementation (RI) be created for the community-wide infrastructure for software engineering and software architecture research, along with a set of detailed considerations.},
booktitle = {Proceedings of the 2nd International Workshop on Establishing a Community-Wide Infrastructure for Architecture-Based Software Engineering},
pages = {26–33},
numpages = {8},
keywords = {software architecture, DevOps, microservice, cloud computing},
location = {Montreal, Quebec, Canada},
series = {ECASE '19}
}

@inproceedings{10.1145/3297280.3297400,
author = {Cardarelli, Mario and Iovino, Ludovico and Di Francesco, Paolo and Di Salle, Amleto and Malavolta, Ivano and Lago, Patricia},
title = {An Extensible Data-Driven Approach for Evaluating the Quality of Microservice Architectures},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297400},
doi = {10.1145/3297280.3297400},
abstract = {Microservice architecture (MSA) is defined as an architectural style where the software system is developed as a suite of small services, each running in its own process and communicating with lightweight mechanisms. The benefits of MSA are many, ranging from an increase in development productivity, to better business-IT alignment, agility, scalability, and technology flexibility. The high degree of microservices distribution and decoupling is, however, imposing a number of relevant challenges from an architectural perspective. In this context, measuring, controlling, and keeping a satisfactory level of quality of the system architecture is of paramount importance.In this paper we propose an approach for the specification, aggregation, and evaluation of software quality attributes for the architecture of microservice-based systems. The proposed approach allows developers to (i) produce architecture models of the system, either manually or automatically via recovering techniques, (ii) contribute to an ecosystem of well-specified and automatically-computable software quality attributes for MSAs, and (iii) continuously measure and evaluate the architecture of their systems by (re-)using the software quality attributes defined in the ecosystem. The approach is implemented by using Model-Driven Engineering techniques.The current implementation of the approach has been validated by assessing the maintainability of a third-party, publicly available benchmark system.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {1225–1234},
numpages = {10},
keywords = {microservices, architecture recovery, model-driven, software quality},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1145/3460319.3464805,
author = {Pan, Yicheng and Ma, Meng and Jiang, Xinrui and Wang, Ping},
title = {Faster, Deeper, Easier: Crowdsourcing Diagnosis of Microservice Kernel Failure from User Space},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464805},
doi = {10.1145/3460319.3464805},
abstract = {With the widespread use of cloud-native architecture, increasing web applications (apps) choose to build on microservices. Simultaneously, troubleshooting becomes full of challenges owing to the high dynamics and complexity of anomaly propagation. Existing diagnostic methods rely heavily on monitoring metrics collected from the kernel side of microservice systems. Without a comprehensive monitoring infrastructure, application owners and even cloud operators cannot resort to these kernel-space solutions. This paper summarizes several insights on operating a top commercial cloud platform. Then, for the first time, we put forward the idea of user-space diagnosis for microservice kernel failures. To this end, we develop a crowdsourcing solution - DyCause, to resolve the asymmetric diagnostic information problem. DyCause deploys on the application side in a distributed manner. Through lightweight API log sharing, apps collect the operational status of kernel services collaboratively and initiate diagnosis on demand. Deploying DyCause is fast and lightweight as we do not have any architectural and functional requirements for the kernel. To reveal more accurate correlations from asymmetric diagnostic information, we design a novel statistical algorithm that can efficiently discover the time-varying causalities between services. This algorithm also helps us build the temporal order of the anomaly propagation. Therefore, by using DyCause, we can obtain more in-depth and interpretable diagnostic clues with limited indicators. We apply and evaluate DyCause on both a simulated test-bed and a real-world cloud system. Experimental results verify that DyCause running in the user-space outperforms several state-of-the-art algorithms running in the kernel on accuracy. Besides, DyCause shows superior advantages in terms of algorithmic efficiency and data sensitivity. Simply put, DyCause produces a significantly better result than other baselines when analyzing much fewer or sparser metrics. To conclude, DyCause is faster to act, deeper in analysis, and easier to deploy.},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {646–657},
numpages = {12},
keywords = {granger causal intervals, dynamic service dependency, microservice system, root cause analysis},
location = {Virtual, Denmark},
series = {ISSTA 2021}
}

@inproceedings{10.1145/3465480.3467838,
author = {Das, Prangshuman and Laigner, Rodrigo and Zhou, Yongluan},
title = {HawkEDA: A Tool for Quantifying Data Integrity Violations in Event-Driven Microservices},
year = {2021},
isbn = {9781450385558},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3465480.3467838},
doi = {10.1145/3465480.3467838},
abstract = {A microservice architecture advocates for subdividing an application into small and independent components, each communicating via well-defined APIs or asynchronous events, to allow for higher scalability, availability, and fault isolation. However, the implementation of substantial amount of data management logic at the application-tier and the existence of functional dependencies cutting across microservices create a great barrier for developers to reason about application safety and performance trade-offs.To fill this gap, this work presents HawkEDA, the first data management tool that allows practitioners to experiment their microservice applications with different real-world workloads to quantify the amount of data integrity anomalies. In our demonstration, we present a case study of a popular open-source event-driven microservice to showcase the interface through which developers specify application semantics and the flexibility of HawkEDA.},
booktitle = {Proceedings of the 15th ACM International Conference on Distributed and Event-Based Systems},
pages = {176–179},
numpages = {4},
keywords = {microservice, event-driven architecture, data integrity},
location = {Virtual Event, Italy},
series = {DEBS '21}
}

@article{10.1145/3418899,
author = {Brondolin, Rolando and Santambrogio, Marco D.},
title = {A Black-Box Monitoring Approach to Measure Microservices Runtime Performance},
year = {2020},
issue_date = {December 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {1544-3566},
url = {https://doi.org/10.1145/3418899},
doi = {10.1145/3418899},
abstract = {Microservices changed cloud computing by moving the applications’ complexity from one monolithic executable to thousands of network interactions between small components. Given the increasing deployment sizes, the architectural exploitation challenges, and the impact on data-centers’ power consumption, we need to efficiently track this complexity. Within this article, we propose a black-box monitoring approach to track microservices at scale, focusing on architectural metrics, power consumption, application performance, and network performance. The proposed approach is transparent w.r.t. the monitored applications, generates less overhead w.r.t. black-box approaches available in the state-of-the-art, and provides fine-grain accurate metrics.},
journal = {ACM Trans. Archit. Code Optim.},
month = {nov},
articleno = {34},
numpages = {26},
keywords = {cloud computing, power attribution, Microservices, docker, kubernetes, performance monitoring, network performance monitoring}
}

