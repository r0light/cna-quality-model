@inproceedings{10.1145/2809826.2809836,
author = {Khan, Yasir Imtiaz and Al-shaer, Ehab and Rauf, Usman},
title = {Cyber Resilience-by-Construction: Modeling, Measuring \&amp; Verifying},
year = {2015},
isbn = {9781450338219},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2809826.2809836},
doi = {10.1145/2809826.2809836},
abstract = {The need of cyber security is increasing as cyber attacks are escalating day by day. Cyber attacks are now so many and sophisticated that many will unavoidably get through. Therefore, there is an immense need to employ resilient architectures to defend known or unknown threats. Engineer- ing resilient system/infrastructure is a challenging task, that implies how to measure the resilience and how to obtain sufficient resilience necessary to maintain its service delivery under diverse situations. This paper has two fold objective, the first is to propose a formal approach to measure cyber resilience from different aspects (i.e., attacks, failures) and at different levels (i.e., pro-active, resistive and reactive). To achieve the first objective, we propose a formal frame- work named as: Cyber Resilience Engineering Framework (CREF). The second objective is to build a resilient system by construction. The idea is to build a formal model of a cyber system, which is initially not resilient with respect to attacks. Then by systematic refinements of the formal model and by its model checking, we attain resiliency. We exemplify our technique through the case study of simple cyber security device (i.e., network firewall).},
booktitle = {Proceedings of the 2015 Workshop on Automated Decision Making for Active Cyber Defense},
pages = {9–14},
numpages = {6},
keywords = {cyber resilience, algebraic petri nets, model checking, firewall},
location = {Denver, Colorado, USA},
series = {SafeConfig '15}
}

@inproceedings{10.1145/3219104.3219148,
author = {Ruan, Guangchen and Wernert, Eric and Gniady, Tassie and Tuna, Esen and Sherman, William},
title = {High Performance Photogrammetry for Academic Research},
year = {2018},
isbn = {9781450364461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219104.3219148},
doi = {10.1145/3219104.3219148},
abstract = {Photogrammetry is the process of computationally extracting a three-dimensional surface model from a set of two-dimensional photographs of an object or environment. It is used to build models of everything from terrains to statues to ancient artifacts. In the past, the computational process was done on powerful PCs and could take weeks for large datasets. Even relatively small objects often required many hours of compute time to stitch together. With the availability of parallel processing options in the latest release of state-of-the-art photogrammetry software, it is possible to leverage the power of high performance computing systems on large datasets. In this paper we present a particular implementation of a high performance photogrammetry service. Though the service is currently based on a specific software package (Agisoft's PhotoScan), our system architecture is designed around a general photogrammetry process that can be easily adapted to leverage other photogrammetry tools. In addition, we report on an extensive performance study that measured the relative impacts of dataset size, software quality settings, and processing cluster size. Furthermore, we share lessons learned that are useful to system administrators looking to establish a similar service, and we describe the user-facing support components that are crucial for the success of the service.},
booktitle = {Proceedings of the Practice and Experience on Advanced Research Computing},
articleno = {45},
numpages = {8},
keywords = {HPC, scalability, distributed processing, benchmarking, photogrammetry, performance evaluation},
location = {Pittsburgh, PA, USA},
series = {PEARC '18}
}

@article{10.1145/2699503,
author = {Patrignani, Marco and Agten, Pieter and Strackx, Raoul and Jacobs, Bart and Clarke, Dave and Piessens, Frank},
title = {Secure Compilation to Protected Module Architectures},
year = {2015},
issue_date = {April 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {2},
issn = {0164-0925},
url = {https://doi.org/10.1145/2699503},
doi = {10.1145/2699503},
abstract = {A fully abstract compiler prevents security features of the source language from being bypassed by an attacker operating at the target language level. Unfortunately, developing fully abstract compilers is very complex, and it is even more so when the target language is an untyped assembly language. To provide a fully abstract compiler that targets untyped assembly, it has been suggested to extend the target language with a protected module architecture—an assembly-level isolation mechanism which can be found in next-generation processors. This article provides a fully abstract compilation scheme whose source language is an object-oriented, high-level language and whose target language is such an extended assembly language. The source language enjoys features such as dynamic memory allocation and exceptions. Secure compilation of first-order method references, cross-package inheritance, and inner classes is also presented. Moreover, this article contains the formal proof of full abstraction of the compilation scheme. Measurements of the overhead introduced by the compilation scheme indicate that it is negligible.},
journal = {ACM Trans. Program. Lang. Syst.},
month = {apr},
articleno = {6},
numpages = {50},
keywords = {protected module architecture, Fully abstract compilation}
}

@inproceedings{10.1145/3286719.3286727,
author = {Coroller, Stevan and Chabridon, Sophie and Laurent, Maryline and Conan, Denis and Leneutre, Jean},
title = {Position Paper: Towards End-to-End Privacy for Publish/Subscribe Architectures in the Internet of Things},
year = {2018},
isbn = {9781450361187},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3286719.3286727},
doi = {10.1145/3286719.3286727},
abstract = {The Internet of Things paradigm lacks end-to-end privacy solutions to consider its full adoption in real life scenarios in the near future. The recent enactment of the EU General Data Protection Regulation (GDPR) indeed emphasises the need for stronger security and privacy measures for personal data processing and free movement, including consent management and accountability by the data controller and processor. In this paper, we suggest an architecture to enforce end-to-end data usage control in Distributed Event-Based Systems (DEBS), from data producers to consumer services, taking into account some of the GDPR requirements concerning consent management and data processing transparency. Our architecture proposal is based on UCONABC usage control models, which we overlap with a distributed hash table overlay for scalability and fault-tolerance concerns, and across and within systems data usage control. Our proposal highlights the benefits of combining both DEBS and end-user usage control architectures. To complete our approach, we quickly survey existing encryption models that ensure data confidentiality in topic-based Publish/Subscribe systems and highlight the remaining obstacles to transpose them to content-based DEBS with an overlay of brokers.},
booktitle = {Proceedings of the 5th Workshop on Middleware and Applications for the Internet of Things},
pages = {35–40},
numpages = {6},
keywords = {Content-based Distributed Event-Based Systems, Usage Control, Privacy, IoT},
location = {Rennes, France},
series = {M4IoT'18}
}

@inproceedings{10.5555/3195638.3195647,
author = {Caulfield, Adrian M. and Chung, Eric S. and Putnam, Andrew and Angepat, Hari and Fowers, Jeremy and Haselman, Michael and Heil, Stephen and Humphrey, Matt and Kaur, Puneet and Kim, Joo-Young and Lo, Daniel and Massengill, Todd and Ovtcharov, Kalin and Papamichael, Michael and Woods, Lisa and Lanka, Sitaram and Chiou, Derek and Burger, Doug},
title = {A Cloud-Scale Acceleration Architecture},
year = {2016},
publisher = {IEEE Press},
abstract = {Hyperscale datacenter providers have struggled to balance the growing need for specialized hardware (efficiency) with the economic benefits of homogeneity (manageability). In this paper we propose a new cloud architecture that uses reconfigurable logic to accelerate both network plane functions and applications. This Configurable Cloud architecture places a layer of reconfigurable logic (FPGAs) between the network switches and the servers, enabling network flows to be programmably transformed at line rate, enabling acceleration of local applications running on the server, and enabling the FPGAs to communicate directly, at datacenter scale, to harvest remote FPGAs unused by their local servers. We deployed this design over a production server bed, and show how it can be used for both service acceleration (Web search ranking) and network acceleration (encryption of data in transit at high-speeds). This architecture is much more scalable than prior work which used secondary rack-scale networks for inter-FPGA communication. By coupling to the network plane, direct FPGA-to-FPGA messages can be achieved at comparable latency to previous work, without the secondary network. Additionally, the scale of direct inter-FPGA messaging is much larger. The average round-trip latencies observed in our measurements among 24, 1000, and 250,000 machines are under 3, 9, and 20 microseconds, respectively. The Configurable Cloud architecture has been deployed at hyperscale in Microsoft's production datacenters worldwide.},
booktitle = {The 49th Annual IEEE/ACM International Symposium on Microarchitecture},
articleno = {7},
numpages = {13},
location = {Taipei, Taiwan},
series = {MICRO-49}
}

@inproceedings{10.1145/3424978.3425039,
author = {Li, Hailing and Zhang, Xiaohang and Cao, Shoufeng and He, Longtao and Zhang, Hui},
title = {Active Measurement of Open Resolver Service Nodes},
year = {2020},
isbn = {9781450377720},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3424978.3425039},
doi = {10.1145/3424978.3425039},
abstract = {Driven by the growing number of DNS requests on the Internet, the architecture of the recursive resolver has become more huge and complex, especially for open resolvers that provide resolution services to the public. There are many service nodes with different roles in the open resolver, and the nodes that directly communicate with the authoritative server are called recursive egress nodes. This paper proposed a distributed measurement system and performed active measurement and analysis on the characteristics of the egress node of open resolvers collected from passive DNS traffic and third party active scanning. The results from 65 vantage points show that (1) most open resolvers have dozens of recursive egress nodes, and (2) most open resolvers have deployed at least one IPv6 address egress node, while IPv4 address still dominates the service node configuration. (3) A small amount of recursive egress nodes is reused by a large number of open resolvers, so that a large amount of DNS request traffic on the Internet is concentrated on limited recursive egress nodes, which will reduce the redundancy of DNS and cause cyber security risks. (4) The median distances between most open resolvers with multiple egress nodes and the users usually exceed 1000 kilometers, which will bring negative effect on the scheduling accuracy of CDN.},
booktitle = {Proceedings of the 4th International Conference on Computer Science and Application Engineering},
articleno = {61},
numpages = {8},
keywords = {Open resolver, Distributed active measurement, Recursive egress node, DNS redirection},
location = {Sanya, China},
series = {CSAE '20}
}

@inproceedings{10.1145/3364544.3364824,
author = {Faye, S\'{e}bastien and Melakessou, Foued and Mtalaa, Wassila and Gautier, Prune and AlNaffakh, Neamah and Khadraoui, Djamel},
title = {SWAM: A Novel Smart Waste Management Approach for Businesses Using IoT},
year = {2019},
isbn = {9781450370158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3364544.3364824},
doi = {10.1145/3364544.3364824},
abstract = {The waste recycling industry has grown considerably in the recent years and many solutions have become democratized around smart waste collection. However, existing decision support systems generally rely on a limited flow of information and offer an often static or statistically based approach, focusing on specific use-cases (e.g., individuals, municipalities). This paper introduces SWAM, a new smart waste collection platform currently being elaborated in Luxembourg that targets businesses and large entities (e.g., restaurants, shopping centers). SWAM aims to consider multiple sources of combined information in its decision-making process and go further in the routing optimization process. The platform notably uses ultrasonic sensors to measure the filling level of containers, and smartphones with embedded intelligence to understand a driver's actions. This paper presents our experience on the development and deployment of this platform in Luxembourg, as well as the relevant options on the choice of sensing and communication technologies available in the market. It also presents the system architecture and two fundamental components. Firstly, a data management layer, which implements models for analyzing and predicting the filling patterns of the containers. Secondly, a multi-objective optimization layer, which compiles the collection routes that minimize the impact on the environment and maximize the service quality. This paper is intended to serve as a practical reference for the deployment of waste management systems, which have many technological components and can greatly fluctuate depending on the use cases to be covered.},
booktitle = {Proceedings of the 1st ACM International Workshop on Technology Enablers and Innovative Applications for Smart Cities and Communities},
pages = {38–45},
numpages = {8},
keywords = {WSN, Smart Waste Collection, Multi-Objective Optimization, IoT},
location = {New York, NY, USA},
series = {TESCA'19}
}

@inproceedings{10.1145/2693561.2693563,
author = {Klein, John and Gorton, Ian},
title = {Runtime Performance Challenges in Big Data Systems},
year = {2015},
isbn = {9781450333405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2693561.2693563},
doi = {10.1145/2693561.2693563},
abstract = {Big data systems are becoming pervasive. They are distributed systems that include redundant processing nodes, replicated storage, and frequently execute on a shared 'cloud' infrastructure. For these systems, design-time predictions are insufficient to assure runtime performance in production. This is due to the scale of the deployed system, the continually evolving workloads, and the unpredictable quality of service of the shared infrastructure. Consequently, a solution for addressing performance requirements needs sophisticated runtime observability and measurement. Observability gives real-time insights into a system's health and status, both at the system and application level, and provides historical data repositories for forensic analysis, capacity planning, and predictive analytics. Due to the scale and heterogeneity of big data systems, significant challenges exist in the design, customization and operations of observability capabilities. These challenges include economical creation and insertion of monitors into hundreds or thousands of computation and data nodes, efficient, low overhead collection and storage of measurements (which is itself a big data problem), and application-aware aggregation and visualization. In this paper we propose a reference architecture to address these challenges, which uses a model-driven engineering toolkit to generate architecture-aware monitors and application-specific visualizations.},
booktitle = {Proceedings of the 2015 Workshop on Challenges in Performance Methods for Software Development},
pages = {17–22},
numpages = {6},
keywords = {model-driven engineering, observability, big data},
location = {Austin, Texas, USA},
series = {WOSP '15}
}

@inproceedings{10.5555/2665671.2665678,
author = {Putnam, Andrew and Caulfield, Adrian M. and Chung, Eric S. and Chiou, Derek and Constantinides, Kypros and Demme, John and Esmaeilzadeh, Hadi and Fowers, Jeremy and Gopal, Gopi Prashanth and Gray, Jan and Haselman, Michael and Hauck, Scott and Heil, Stephen and Hormati, Amir and Kim, Joo-Young and Lanka, Sitaram and Larus, James and Peterson, Eric and Pope, Simon and Smith, Aaron and Thong, Jason and Xiao, Phillip Yi and Burger, Doug},
title = {A Reconfigurable Fabric for Accelerating Large-Scale Datacenter Services},
year = {2014},
isbn = {9781479943944},
publisher = {IEEE Press},
abstract = {Datacenter workloads demand high computational capabilities, flexibility, power efficiency, and low cost. It is challenging to improve all of these factors simultaneously. To advance datacenter capabilities beyond what commodity server designs can provide, we have designed and built a composable, reconfigurablefabric to accelerate portions of large-scale software services. Each instantiation of the fabric consists of a 6x8 2-D torus of high-end Stratix V FPGAs embedded into a half-rack of 48 machines. One FPGA is placed into each server, accessible through PCIe, and wired directly to other FPGAs with pairs of 10 Gb SAS cablesIn this paper, we describe a medium-scale deployment of this fabric on a bed of 1,632 servers, and measure its efficacy in accelerating the Bing web search engine. We describe the requirements and architecture of the system, detail the critical engineering challenges and solutions needed to make the system robust in the presence of failures, and measure the performance, power, and resilience of the system when ranking candidate documents. Under high load, the largescale reconfigurable fabric improves the ranking throughput of each server by a factor of 95\% for a fixed latency distribution--- or, while maintaining equivalent throughput, reduces the tail latency by 29\%},
booktitle = {Proceeding of the 41st Annual International Symposium on Computer Architecuture},
pages = {13–24},
numpages = {12},
location = {Minneapolis, Minnesota, USA},
series = {ISCA '14}
}

@article{10.1145/2678373.2665678,
author = {Putnam, Andrew and Caulfield, Adrian M. and Chung, Eric S. and Chiou, Derek and Constantinides, Kypros and Demme, John and Esmaeilzadeh, Hadi and Fowers, Jeremy and Gopal, Gopi Prashanth and Gray, Jan and Haselman, Michael and Hauck, Scott and Heil, Stephen and Hormati, Amir and Kim, Joo-Young and Lanka, Sitaram and Larus, James and Peterson, Eric and Pope, Simon and Smith, Aaron and Thong, Jason and Xiao, Phillip Yi and Burger, Doug},
title = {A Reconfigurable Fabric for Accelerating Large-Scale Datacenter Services},
year = {2014},
issue_date = {June 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {3},
issn = {0163-5964},
url = {https://doi.org/10.1145/2678373.2665678},
doi = {10.1145/2678373.2665678},
abstract = {Datacenter workloads demand high computational capabilities, flexibility, power efficiency, and low cost. It is challenging to improve all of these factors simultaneously. To advance datacenter capabilities beyond what commodity server designs can provide, we have designed and built a composable, reconfigurablefabric to accelerate portions of large-scale software services. Each instantiation of the fabric consists of a 6x8 2-D torus of high-end Stratix V FPGAs embedded into a half-rack of 48 machines. One FPGA is placed into each server, accessible through PCIe, and wired directly to other FPGAs with pairs of 10 Gb SAS cablesIn this paper, we describe a medium-scale deployment of this fabric on a bed of 1,632 servers, and measure its efficacy in accelerating the Bing web search engine. We describe the requirements and architecture of the system, detail the critical engineering challenges and solutions needed to make the system robust in the presence of failures, and measure the performance, power, and resilience of the system when ranking candidate documents. Under high load, the largescale reconfigurable fabric improves the ranking throughput of each server by a factor of 95\% for a fixed latency distribution--- or, while maintaining equivalent throughput, reduces the tail latency by 29\%},
journal = {SIGARCH Comput. Archit. News},
month = {jun},
pages = {13–24},
numpages = {12}
}

@article{10.1145/3442187,
author = {Al-Abbasi, Abubakr O. and Aggarwal, Vaneet},
title = {VidCloud: Joint Stall and Quality Optimization for Video Streaming over Cloud},
year = {2021},
issue_date = {December 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {4},
issn = {2376-3639},
url = {https://doi.org/10.1145/3442187},
doi = {10.1145/3442187},
abstract = {As video-streaming services have expanded and improved, cloud-based video has evolved into a necessary feature of any successful business for reaching internal and external audiences. In this article, video streaming over distributed storage is considered where the video segments are encoded using an erasure code for better reliability. We consider a representative system architecture for a realistic (typical) content delivery network (CDN). Given multiple parallel streams/link between each server and the edge router, we need to determine, for each client request, the subset of servers to stream the video, as well as one of the parallel streams from each chosen server. To have this scheduling, this article proposes a two-stage probabilistic scheduling. The selection of video quality is also chosen with a certain probability distribution that is optimized in our algorithm. With these parameters, the playback time of video segments is determined by characterizing the download time of each coded chunk for each video segment. Using the playback times, a bound on the moment generating function of the stall duration is used to bound the mean stall duration. Based on this, we formulate an optimization problem to jointly optimize the convex combination of mean stall duration and average video quality for all requests, where the two-stage probabilistic scheduling, video quality selection, bandwidth split among parallel streams, and auxiliary bound parameters can be chosen. This non-convex problem is solved using an efficient iterative algorithm. Based on the offline version of our proposed algorithm, an online policy is developed where servers selection, quality, bandwidth split, and parallel streams are selected in an online manner. Experimental results show significant improvement in QoE metrics for cloud-based video as compared to the considered baselines.},
journal = {ACM Trans. Model. Perform. Eval. Comput. Syst.},
month = {jan},
articleno = {17},
numpages = {32},
keywords = {two-stage probabilistic scheduling, erasure codes, video quality, mean stall duration, Video streaming over cloud}
}

@article{10.1145/3151123.3151125,
author = {Zeinalipour-Yazti, Demetrios and Laoudias, Christos},
title = {The Anatomy of the Anyplace Indoor Navigation Service},
year = {2017},
issue_date = {July 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
url = {https://doi.org/10.1145/3151123.3151125},
doi = {10.1145/3151123.3151125},
abstract = {The pervasiveness of smartphones is leading to the uptake of a new class of Internet-based Indoor Navigation (IIN) services, which might soon diminish the need of Satellite-based localization technologies in urban environments. These services rely on geo-location databases that store spatial models along with wireless, light and magnetic signals used to localize users and provide better power efficiency and wider coverage than predominant approaches. In this article we overview Anyplace, an open, modular, extensible and scalable navigation architecture that exploits crowdsourced Wi-Fi data to develop a novel navigation service that won several international research awards for its utility and accuracy (i.e., less than 2 meters). Our MIT-licenced open-source software stack has to this date been used by thaousands of researchers and practitioners around the globe, with the public Anyplace service reaching over 100,000 real user interactions.},
journal = {SIGSPATIAL Special},
month = {oct},
pages = {3–10},
numpages = {8}
}

@inproceedings{10.5555/2665049.2665054,
author = {Kofler, Klaus and Davis, Gregory and Gesing, Sandra},
title = {SAMPO: An Agent-Based Mosquito Point Model in OpenCL},
year = {2014},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {Agent-based modeling and simulations are applied for problems where population-level patterns arise from the interaction of many autonomous individuals. These problems are compute-intensive and excellent candidates for the use of parallel algorithms and architectures. As a cross-platform software development framework for parallel architectures, OpenCL appears as an ideal tool to implement such algorithms. However, OpenCL does not natively support object-oriented development, which most of the toolkits and frameworks used to build agent-based models require.The present work describes an OpenCL implementation of an existing agent-based model, simulating populations of the Anopheles gambiae mosquito, one of the most important vectors of malaria in Africa. Discussed are the methods and techniques used to overcome the design challenges, which arise when transitioning from an object-oriented program to an efficient OpenCL implementation. In particular, the parallelism inside the program has been maximized, dynamic divergent branching was reduced, and the number of data transfers between the OpenCL host and device has been minimized as far as possible.Even though our implementation was designed for this specific use case, the approach can be generalized to other contexts, as most agent-based point models would benefit from the same basic design decisions that we took for our implementation. Comparisons between the object-oriented and the OpenCL implementation illustrate that using an OpenCL approach offers two important performance benefits: an overall simulation time speedup of up to 576 with no measurable loss of accuracy, and better scalability as the agent-population size increases. The tradeoffs necessary to achieve these performance benefits and the implications for future agent-based software development frameworks are discussed.},
booktitle = {Proceedings of the 2014 Symposium on Agent Directed Simulation},
articleno = {5},
numpages = {10},
keywords = {OpenCL, GPGPU, agent-based modelling},
location = {Tampa, Florida},
series = {ADS '14}
}

@inproceedings{10.1145/3123878.3131999,
author = {Szabo, Marton and Majdan, Andras and Pongracz, Gergely and Toka, Laszlo and Sonkoly, Balazs},
title = {Making the Data Plane Ready for NFV: An Effective Way of Handling Resources},
year = {2017},
isbn = {9781450350570},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3123878.3131999},
doi = {10.1145/3123878.3131999},
abstract = {In order to enable carrier grade network services constructed from software-based network functions, we need a novel data plane supporting high performance packet processing, low latency and flexible, fine granular programmability and control. The network functions implemented as virtual machines or containers use the same hardware resources (cpu, memory) as the elements responsible for networking, therefore, a low-level resource orchestrator which is capable of jointly controlling these resources is an indispensable component. In this demonstration, we showcase our novel resource orchestrator (FERO) on top of a data plane making use of open-source components such as, Docker, DPDK and OVS. It is capable of i) generating an abstract model of the underlying hardware architecture during the bootstrap process, ii) mapping the incoming network service requests to available resources based on our recently proposed Service Graph embedding engine and the generated graph model. The impact of the orchestration decision is shown on-the-fly by real-time performance measurements on a graphical dashboard.},
booktitle = {Proceedings of the SIGCOMM Posters and Demos},
pages = {97–99},
numpages = {3},
keywords = {SDN, SFC, DPDK, Docker, NFV},
location = {Los Angeles, CA, USA},
series = {SIGCOMM Posters and Demos '17}
}

@inproceedings{10.1145/3320326.3320391,
author = {El Mrabet, Zakaria and Ezzari, Mehdi and Elghazi, Hassan and El Majd, Badr Abou},
title = {Deep Learning-Based Intrusion Detection System for Advanced Metering Infrastructure},
year = {2019},
isbn = {9781450366458},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3320326.3320391},
doi = {10.1145/3320326.3320391},
abstract = {Smart grid is an alternative solution of the conventional power grid which harnesses the power of the information technology to save the energy and meet todays' environment requirements. Due to the inherent vulnerabilities in the information technology, the smart grid is exposed to wide variety of threats that could be translated into cyber-attacks. In this paper, we develop a deep learning-based intrusion detection system to defend against cyber-attacks in the advanced metering infrastructure network. The proposed machine learning approach is trained and tested extensively on an empirical industrial dataset which is composed of several attack' categories including the scanning, buffer overflow, and denial of service attacks. Then, an experimental comparison in terms of detection accuracy is conducted to evaluate the performance of the proposed approach with Na\"{\i}ve Bayes, Support Vector Machine, and Random Forest. The obtained results suggest that the proposed approaches produce optimal results comparing to the other algorithms. Finally, we propose a network architecture to deploy the proposed anomaly-based intrusion detection system across the Advanced metering infrastructure network. In addition, we propose a network security architecture composed of two types of Intrusion detection system types, Host and Network based, deployed across the Advanced Metering Infrastructure network to inspect the traffic and detect the malicious one at all the levels.},
booktitle = {Proceedings of the 2nd International Conference on Networking, Information Systems \&amp; Security},
articleno = {58},
numpages = {7},
keywords = {Advanced Metering Infrastructure, Intrusion detection system, Deep learning, cross entropy loss, detection accuracy},
location = {Rabat, Morocco},
series = {NISS '19}
}

@inproceedings{10.1145/2949550.2949652,
author = {Hu, Hao and Hong, Xingchen and Terstriep, Jeff and Liu, Yan Y. and Finn, Michael P. and Rush, Johnathan and Wendel, Jeffrey and Wang, Shaowen},
title = {TopoLens: Building a CyberGIS Community Data Service for Enhancing the Usability of High-Resolution National Topographic Datasets},
year = {2016},
isbn = {9781450347556},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2949550.2949652},
doi = {10.1145/2949550.2949652},
abstract = {Geospatial data, often embedded with geographic references, are important to many application and science domains, and represent a major type of big data. The increased volume and diversity of geospatial data have caused serious usability issues for researchers in various scientific domains, which call for innovative cyberGIS solutions. To address these issues, this paper describes a cyberGIS community data service framework to facilitate geospatial big data access, processing, and sharing based on a hybrid supercomputer architecture. Through the collaboration between the CyberGIS Center at the University of Illinois at Urbana-Champaign (UIUC) and the U.S. Geological Survey (USGS), a community data service for accessing, customizing, and sharing digital elevation model (DEM) and its derived datasets from the 10-meter national elevation dataset, namely TopoLens, is created to demonstrate the workflow integration of geospatial big data sources, computation, analysis needed for customizing the original dataset for end user needs, and a friendly online user environment. TopoLens provides online access to precomputed and on-demand computed high-resolution elevation data by exploiting the ROGER supercomputer. The usability of this prototype service has been acknowledged in community evaluation.},
booktitle = {Proceedings of the XSEDE16 Conference on Diversity, Big Data, and Science at Scale},
articleno = {39},
numpages = {8},
keywords = {microservices, web-based gateway environment, CyberGIS, data sharing, elevation data, geospatial big data},
location = {Miami, USA},
series = {XSEDE16}
}

@inproceedings{10.1145/2996913.2996917,
author = {Chatterjee, Abhranil and Anjaria, Janit and Roy, Sourav and Ganguli, Arnab and Seal, Krishanu},
title = {SAGEL: Smart Address Geocoding Engine for Supply-Chain Logistics},
year = {2016},
isbn = {9781450345897},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2996913.2996917},
doi = {10.1145/2996913.2996917},
abstract = {With the recent explosion of e-commerce industry in India, the problem of address geocoding, that is, transforming textual address descriptions to geographic reference, such as latitude, longitude coordinates, has emerged as a core problem for supply chain management. Some of the major areas that rely on precise and accurate address geocoding are supply chain fulfilment, supply chain analytics and logistics. In this paper, we present some of the challenges faced in practice while building an address geocoding engine as a core capability at Flipkart. We discuss the unique challenges of building a geocoding engine for a rapidly developing country like India, such as, fuzzy region boundaries, dynamic topography and lack of convention in spellings of toponyms, to name a few. We motivate the need for building a reliable and precise address geocoding system from a business perspective and argue why some of the commercially available solutions do not suffice for our requirements. SAGEL has evolved through 3 cycles of solution prototypes and pilot experiments. We describe the learnings from each of these phases and how we incorporated them to get to the first production-ready version. We describe how we store and index map data on a SolrCloud cluster of Apache Solr, an open-source search platform, and the core algorithm for geocoding which works post-retrieval in order to determine the best matches among a set of candidate results. We give a brief description of the system architecture and provide accuracy results of our geocoding engine by measuring deviations of geocoded customer addresses across India, from verified latitude, longitude coordinates of those addresses, for a sizeable address set. We also measure and report our system's ability to geocode up to different region levels, like city, locality or building. We compare our results with those of the geocoding service provided by Google against a set of addresses for which we have verified latitude-longitude coordinates and show that our geocoding engine is almost as accurate as Google's, while having a higher coverage.},
booktitle = {Proceedings of the 24th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems},
articleno = {42},
numpages = {10},
keywords = {spatio-textual searching, geographic information retrieval, spatial data mining and knowledge discovery, storage and indexing},
location = {Burlingame, California},
series = {SIGSPACIAL '16}
}

@inproceedings{10.1145/2775088.2775100,
author = {You, Taewan and Martinez-Julia, Pedro and Skarmeta, Antonio and Jung, Heeyoung},
title = {Design and Deployment of Federation Testbed in EU-KR for Identifier-Based Communications},
year = {2015},
isbn = {9781450335645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2775088.2775100},
doi = {10.1145/2775088.2775100},
abstract = {SmartFIRE is the first intercontinental testbed, federating multiple small-scale testbeds in South Korea and Europe, which exploits the benefits and building blocks of an OpenFlow-based infrastructure. As a part of SmartFIRE, both ETRI and UMU designs and develops a federation testbed for Identifier-based communications that all of communication services are achieved by Identifier not by IP address. In order to manage and control the testbed, we deploy a Measurement and Management Framework (OMF), further we will deploy SFA aggregate manager to federate with other SmartFIRE testbed. In this paper we introduce the federation testbed for ID-based communications including network connectivity, architecture configuration, and federation architecture. Moreover, to exploit the testbed, we design and implement two mobility use cases that we show seamless network connection service under host's mobility, such as intra-domain handover and inter-domain handover. Thus we can show result of the experimentation that the communication session wouldn't be cut off even though communication entity moves to a different network. Finally we refer future works for federation to cooperate with other SmartFIRE testbeds and additional ID-based communication scenario.},
booktitle = {The 10th International Conference on Future Internet},
pages = {13–16},
numpages = {4},
keywords = {KR, EU, SmartFire, Federation Testbed, Deployment, Identifier-based communications},
location = {Seoul, Republic of Korea},
series = {CFI '15}
}

@inproceedings{10.1145/3154273.3154316,
author = {Talasila, Prasad and Kakrambe, Mihir and Rai, Anurag and Santy, Sebastin and Goveas, Neena and Deshpande, Bharat M.},
title = {BITS Darshini: A Modular, Concurrent Protocol Analyzer Workbench},
year = {2018},
isbn = {9781450363723},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3154273.3154316},
doi = {10.1145/3154273.3154316},
abstract = {Network measurements are essential for troubleshooting and active management of networks. Protocol analysis of captured network packet traffic is an important passive network measurement technique used by researchers and network operations engineers. In this work, we present a measurement workbench tool named BITS Darshini (Darshini in short) to enable scientific network measurements.We have created Darshini as a modular, concurrent web application that stores experimental meta-data and allows users to specify protocol parse graphs. Darshini performs protocol analysis on a concurrent pipeline architecture, persists the analysis to a database and provides the analysis results via a REST API service. We formulate the problem of mapping protocol parse graph to a concurrent pipeline as a graph embedding problem. Our tool, Darshini, performs protocol analysis up to transport layer and is suitable for the study of small and medium-sized networks. Darshini enables secure collaboration and consultations with experts.},
booktitle = {Proceedings of the 19th International Conference on Distributed Computing and Networking},
articleno = {54},
numpages = {10},
keywords = {measurement workbench, concurrent packet analysis, Network measurements, packet analyzer, graph embedding, protocol parse graph, collaborative analysis},
location = {Varanasi, India},
series = {ICDCN '18}
}

@inproceedings{10.1145/2996890.2996903,
author = {Sukhoroslov, Oleg and Volkov, Sergey and Afanasiev, Alexander},
title = {Program Autotuning as a Service: Opportunities and Challenges},
year = {2016},
isbn = {9781450346160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2996890.2996903},
doi = {10.1145/2996890.2996903},
abstract = {Program autotuning is becoming an increasingly valuable tool for improving performance portability across diverse target architectures, exploring trade-offs between several criteria, or meeting quality of service requirements. Recent work on general autotuning frameworks enabled rapid development of domain-specific autotuners reusing common libraries of parameter types and search techniques. In this work we explore the use of such frameworks to develop general-purpose online services for program autotuning using the Software as a Service model. Beyond the common benefits of this model, the proposed approach opens up a number of unique opportunities, such as collecting performance data and utilizing it to improve further runs, or enabling remote online autotuning. However, the proposed autotuning as a service approach also brings in several challenges, such as accessing target systems, dealing with measurement latency, and supporting execution of user-provided code. This paper presents the first step towards implementing the proposed approach and addressing these challenges. We describe an implementation of generic autotuning service that can be used for tuning arbitrary programs on user-provided computing systems. The service is based on OpenTuner autotuning framework and runs on Everest platform that enables rapid development of computational web services. In contrast to OpenTuner, the service doesn't require installation of the framework, allows users to avoid writing code and supports efficient parallel execution of measurement tasks across multiple machines. The performance of the service is evaluated by using it for tuning synthetic and real programs.},
booktitle = {Proceedings of the 9th International Conference on Utility and Cloud Computing},
pages = {148–155},
numpages = {8},
keywords = {software as a service, program autotuning, web services, distributed computing},
location = {Shanghai, China},
series = {UCC '16}
}

@inproceedings{10.1145/3426744.3431328,
author = {V\"{o}r\"{o}s, P\'{e}ter and Pongr\'{a}cz, Gergely and Laki, S\'{a}ndor},
title = {Towards a Hybrid Next Generation NodeB},
year = {2020},
isbn = {9781450381819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3426744.3431328},
doi = {10.1145/3426744.3431328},
abstract = {5G Radio Access Networks consists of two key services: User Plane Function (UPF) and next generation NodeB (gNB). Though several papers have recently demonstrated that the high-level UPF can be described in P4, for the lowest-level gNB service it is more challenging and cannot purely be done with existing programmable switches. In this paper, we show that gNB requires functionalities such as Automatic Repeat Request (ARQ) and ciphering/deciphering that are not supported by the high speed P4-programmable switches available in the market. To overcome these limitations, we propose a hybrid approach where the majority of packet processing is done by a high speed P4-programmable switch while the additional functionalities are solved by external services implemented in DPDK. The coordination of packets among the services is also handled by the P4-switch. Our preliminary results include the identification of functionalities required by a gNB node for delivering user data, the design of a hybrid architecture, and the performance evaluation of the buffering and re-transmission service. Finally, our measurements demonstrate that the proposed hybrid approach is scalable and could be an alternative to existing gNB solutions in the future.},
booktitle = {Proceedings of the 3rd P4 Workshop in Europe},
pages = {56–58},
numpages = {3},
location = {Barcelona, Spain},
series = {EuroP4'20}
}

@article{10.1145/2660768,
author = {Kim, Lok-Won and Lee, Dong-U and Villasenor, John},
title = {Automated Iterative Pipelining for ASIC Design},
year = {2015},
issue_date = {February 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {2},
issn = {1084-4309},
url = {https://doi.org/10.1145/2660768},
doi = {10.1145/2660768},
abstract = {We describe an automated pipelining approach for optimally balanced pipeline implementation that achieves low area cost as well as meeting timing requirements. Most previous automatic pipelining methods have focused on Instruction Set Architecture (ISA)-based designs and the main goal of such methods generally has been maximizing performance as measured in terms of instructions per clock (IPC). By contrast, we focus on datapath-oriented designs (e.g., DSP filters for image or communication processing applications) in ASIC design flows. The goal of the proposed pipelining approach is to find the optimally pipelined design that not only meets the user-specified target clock frequency, but also seeks to minimize area cost of a given design. Unlike most previous approaches, the proposed methods incorporate the use of accurate area and timing information (iteratively achieved by synthesizing every interim pipelined design) to achieve higher accuracy during design exploration. When compared with exhaustive design exploration that considers all possible pipeline patterns, the two heuristic pipelining methods presented here involve only a small area penalty (typically under 5\%) while offering dramatically reduced computational complexity. Experimental validation is performed with commercial ASIC design tools and described for applications including polynomial function evaluation, FIR filters, matrix multiplication, and discrete wavelet transform filter designs with a 90nm standard cell library.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = {mar},
articleno = {28},
numpages = {24},
keywords = {pipelined hardware architecture, ASIC designs, Timing error resolution, pipelining, design area optimization}
}

@article{10.1145/2845082,
author = {\"{A}ij\"{o}, Tomi and J\"{a}\"{a}skel\"{a}inen, Pekka and Elomaa, Tapio and Kultala, Heikki and Takala, Jarmo},
title = {Integer Linear Programming-Based Scheduling for Transport Triggered Architectures},
year = {2015},
issue_date = {January 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {4},
issn = {1544-3566},
url = {https://doi.org/10.1145/2845082},
doi = {10.1145/2845082},
abstract = {Static multi-issue machines, such as traditional Very Long Instructional Word (VLIW) architectures, move complexity from the hardware to the compiler. This is motivated by the ability to support high degrees of instruction-level parallelism without requiring complicated scheduling logic in the processor hardware. The simpler-control hardware results in reduced area and power consumption, but leads to a challenge of engineering a compiler with good code-generation quality.Transport triggered architectures (TTA), and other so-called exposed datapath architectures, take the compiler-oriented philosophy even further by pushing more details of the datapath under software control. The main benefit of this is the reduced register file pressure, with a drawback of adding even more complexity to the compiler side.In this article, we propose an Integer Linear Programming (ILP)-based instruction scheduling model for TTAs. The model describes the architecture characteristics, the particular processor resource constraints, and the operation dependencies of the scheduled program. The model is validated and measured by compiling application kernels to various TTAs with a different number of datapath components and connectivity. In the best case, the cycle count is reduced to 52\% when compared to a heuristic scheduler. In addition to producing shorter schedules, the number of register accesses in the compiled programs is generally notably less than those with the heuristic scheduler; in the best case, the ILP scheduler reduced the number of register file reads to 33\% of the heuristic results and register file writes to 18\%. On the other hand, as expected, the ILP-based scheduler uses distinctly more time to produce a schedule than the heuristic scheduler, but the compilation time is within tolerable limits for production-code generation.},
journal = {ACM Trans. Archit. Code Optim.},
month = {dec},
articleno = {59},
numpages = {22},
keywords = {transport triggered architectures, exposed datapath, instruction-level parallelism, integer linear programming, Code generation}
}

@inproceedings{10.1145/3052973.3053028,
author = {Inci, Mehmet Sinan and Eisenbarth, Thomas and Sunar, Berk},
title = {Hit by the Bus: QoS Degradation Attack on Android},
year = {2017},
isbn = {9781450349444},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3052973.3053028},
doi = {10.1145/3052973.3053028},
abstract = {Mobile apps need optimal performance and responsiveness to rise amongst numerous rivals on the market. Further, some apps like media streaming or gaming apps cannot even function properly with a performance below a certain threshold. In this work, we present the first performance degradation attack on Android OS that can target rival apps using a combination of logical channel leakages and low-level architectural bottlenecks in the underlying hardware. To show the viability of the attack, we design a proof-of-concept app and test it on various mobile platforms. The attack runs covertly and brings the target to the level of unresponsiveness. With less than 10\% CPU time in the worst case, it requires minimal computational effort to run as a background service, and requires only the UsageStats permission from the user. We quantify the impact of our attack using 11 popular benchmark apps, running 44 different tests.} The measured QoS degradation varies across platforms and applications, reaching a maximum of 90\% in some cases. The attack combines the leakage from logical channels with low-level architectural bottlenecks to design a malicious app that can covertly degrade Quality of Service (QoS) of any targeted app. Furthermore, our attack code has a small footprint and is not detected by the Android system as malicious. Finally, our app can pass the Google Play Store malware scanner, Google Bouncer, as well as the top malware scanners in the Play Store.},
booktitle = {Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security},
pages = {716–727},
numpages = {12},
keywords = {performance degradation, mobile security, mobile malware, QoS attack},
location = {Abu Dhabi, United Arab Emirates},
series = {ASIA CCS '17}
}

@inproceedings{10.1145/3302541.3310294,
author = {Scheuner, Joel and Leitner, Philipp},
title = {Performance Benchmarking of Infrastructure-as-a-Service (IaaS) Clouds with Cloud WorkBench},
year = {2019},
isbn = {9781450362863},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302541.3310294},
doi = {10.1145/3302541.3310294},
abstract = {The continuing growth of the cloud computing market has led to an unprecedented diversity of cloud services with different performance characteristics. To support service selection, researchers and practitioners conduct cloud performance benchmarking by measuring and objectively comparing the performance of different providers and configurations (e.g., instance types in different data center regions). In this tutorial, we demonstrate how to write performance tests for IaaS clouds using the Web-based benchmarking tool Cloud WorkBench (CWB). We will motivate and introduce benchmarking of IaaS cloud in general, demonstrate the execution of a simple benchmark in a public cloud environment, summarize the CWB tool architecture, and interactively develop and deploy a more advanced benchmark together with the participants.},
booktitle = {Companion of the 2019 ACM/SPEC International Conference on Performance Engineering},
pages = {53–56},
numpages = {4},
keywords = {cloud computing, performance, benchmarking},
location = {Mumbai, India},
series = {ICPE '19}
}

@inproceedings{10.1145/3378679.3394536,
author = {Liang, Yilei and O'Keeffe, Dan and Sastry, Nishanth},
title = {PAIGE: Towards a Hybrid-Edge Design for Privacy-Preserving Intelligent Personal Assistants},
year = {2020},
isbn = {9781450371322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3378679.3394536},
doi = {10.1145/3378679.3394536},
abstract = {Intelligent Personal Assistants (IPAs) such as Apple's Siri, Google Now, and Amazon Alexa are becoming an increasingly important class of web application. In contrast to previous keyword-oriented search applications, IPAs support a rich query interface that allows user interaction through images, audio, and natural language queries. However, modern IPAs rely heavily on compute-intensive machine-learning inference. To achieve acceptable performance, ML-driven IPAs increasingly depend on specialized hardware accelerators (e.g. GPUs, FPGAs or TPUs), increasing costs for IPA service providers. For end-users, IPAs also present considerable privacy risks given the sensitive nature of the data they capture.We present PAIGE, a hybrid edge-cloud architecture for privacy-preserving Intelligent Personal Assistants. PAIGE's design is founded on the assumption that recent advances in low-cost hardware for machine-learning inference offer an opportunity to offload compute-intensive IPA ML tasks to the network edge. To allow privacy-preserving access to large IPA databases for less compute-intensive pre-processed queries, PAIGE leverages trusted execution environments at the server side. PAIGE's hybrid design allows privacy-preserving hardware acceleration of compute-intensive tasks, while avoiding the need to move potentially large IPA question-answering databases to the edge. As a step towards realising PAIGE, we present a first systematic performance evaluation of existing edge accelerator hardware platforms for a subset of IPA workloads, and show they offer a competitive alternative to existing data-center alternatives.},
booktitle = {Proceedings of the Third ACM International Workshop on Edge Systems, Analytics and Networking},
pages = {55–60},
numpages = {6},
keywords = {intelligent personal assistants, edge computing, trusted execution environments},
location = {Heraklion, Greece},
series = {EdgeSys '20}
}

@inproceedings{10.1145/2749469.2750422,
author = {Zhang, Tianwei and Lee, Ruby B.},
title = {CloudMonatt: An Architecture for Security Health Monitoring and Attestation of Virtual Machines in Cloud Computing},
year = {2015},
isbn = {9781450334020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2749469.2750422},
doi = {10.1145/2749469.2750422},
abstract = {Cloud customers need guarantees regarding the security of their virtual machines (VMs), operating within an Infrastructure as a Service (IaaS) cloud system. This is complicated by the customer not knowing where his VM is executing, and on the semantic gap between what the customer wants to know versus what can be measured in the cloud. We present an architecture for monitoring a VM's security health, with the ability to attest this to the customer in an unforgeable manner. We show a concrete implementation of property-based attestation and a full prototype based on the OpenStack open source cloud software.},
booktitle = {Proceedings of the 42nd Annual International Symposium on Computer Architecture},
pages = {362–374},
numpages = {13},
location = {Portland, Oregon},
series = {ISCA '15}
}

@article{10.1145/2872887.2750422,
author = {Zhang, Tianwei and Lee, Ruby B.},
title = {CloudMonatt: An Architecture for Security Health Monitoring and Attestation of Virtual Machines in Cloud Computing},
year = {2015},
issue_date = {June 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {3S},
issn = {0163-5964},
url = {https://doi.org/10.1145/2872887.2750422},
doi = {10.1145/2872887.2750422},
abstract = {Cloud customers need guarantees regarding the security of their virtual machines (VMs), operating within an Infrastructure as a Service (IaaS) cloud system. This is complicated by the customer not knowing where his VM is executing, and on the semantic gap between what the customer wants to know versus what can be measured in the cloud. We present an architecture for monitoring a VM's security health, with the ability to attest this to the customer in an unforgeable manner. We show a concrete implementation of property-based attestation and a full prototype based on the OpenStack open source cloud software.},
journal = {SIGARCH Comput. Archit. News},
month = {jun},
pages = {362–374},
numpages = {13}
}

@inproceedings{10.1145/3281411.3281426,
author = {Xhonneux, Mathieu and Duchene, Fabien and Bonaventure, Olivier},
title = {Leveraging EBPF for Programmable Network Functions with IPv6 Segment Routing},
year = {2018},
isbn = {9781450360807},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3281411.3281426},
doi = {10.1145/3281411.3281426},
abstract = {With the advent of Software Defined Networks (SDN), Network Function Virtualisation (NFV) or Service Function Chaining (SFC), operators expect networks to support flexible services beyond the mere forwarding of packets. The network programmability framework which is being developed within the IETF by leveraging IPv6 Segment Routing enables the realisation of in-network functions.In this paper, we demonstrate that this vision of in-network programmability can be realised. By leveraging the eBPF support in the Linux kernel, we implement a flexible framework that allows network operators to encode their own network functions as eBPF code that is automatically executed while processing specific packets. Our lab measurements indicate that the overhead of calling such eBPF functions remains acceptable. Thanks to eBPF, operators can implement a variety of network functions. We describe the architecture of our implementation in the Linux kernel. This extension has been released with Linux 4.18. We illustrate the flexibility of our approach with three different use cases: delay measurements, hybrid networks and network discovery. Our lab measurements also indicate that the performance penalty of running eBPF network functions on Linux routers does not incur a significant overhead.},
booktitle = {Proceedings of the 14th International Conference on Emerging Networking EXperiments and Technologies},
pages = {67–72},
numpages = {6},
location = {Heraklion, Greece},
series = {CoNEXT '18}
}

@inproceedings{10.1145/2959100.2959122,
author = {Celma, Oscar},
title = {The Exploit-Explore Dilemma in Music Recommendation},
year = {2016},
isbn = {9781450340359},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2959100.2959122},
doi = {10.1145/2959100.2959122},
abstract = {Were The Rolling Stones right when they said, "You can't always get what you want; but if you try sometime you get what you need"? Recommendation systems are the crystal ball of the Internet: predicting user intentions, making sense of big data, and delivering what people are looking for before they even know they want it. Pandora radio is best known for the Music Genome Project; the most unique and richly labeled music catalog of 1.5 million+ tracks. While this content-based approach to music recommendation is extremely effective and still used today as the foundation to the leading online radio service, Pandora has also collected more than a decade of contextual listener feedback in the form of more than 65 billion thumbs from 79M+ monthly active users who have created more than 9 billion stations. This session will look at how the interdisciplinary team at Pandora goes about making sense of these massive data sets to successfully make large scale music recommendations to our listeners.As opposed to more traditional recommender systems which need only to recommend a single item or set of items, Pandora's recommenders must provide an evolving set of sequential items, which constantly keep the experience new and exciting. In this talk I will present a dynamic ensemble learning system that combines musicological data and machine learning models to provide a truly personalized experience. This approach allows us to switch from a lean back experience (exploitation) to a more exploration mode to discover new music tailored specifically to users individual tastes. To exemplify this, I will present a recently launched product led by the research team, Thumbprint Radio.Following this session the audience will have an in-depth understanding of how Pandora uses science to determine the perfect balance of familiarity, discovery, repetition and relevance for each individual listener, measures and evaluates user satisfaction, and how our online and offline architecture stack plays a critical role in our success.},
booktitle = {Proceedings of the 10th ACM Conference on Recommender Systems},
pages = {377},
numpages = {1},
keywords = {exploit-explore dilemma, ensemble learning, thumbprint radio, content-based recommendation, A/B online testing, offline evaluation, machine listening},
location = {Boston, Massachusetts, USA},
series = {RecSys '16}
}

@inproceedings{10.1145/2619239.2631461,
author = {Fiadino, Pierdomenico and Schiavone, Mirko and Casas, Pedro},
title = {Vivisecting Whatsapp through Large-Scale Measurements in Mobile Networks},
year = {2014},
isbn = {9781450328364},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2619239.2631461},
doi = {10.1145/2619239.2631461},
abstract = {WhatsApp, the new giant in instant multimedia messaging in mobile networks is rapidly increasing its popularity, taking over the traditional SMS/MMS messaging. In this paper we present the first large-scale characterization of WhatsApp, useful among others to ISPs willing to understand the impacts of this and similar applications on their networks. Through the combined analysis of passive measurements at the core of a national mobile network, worldwide geo-distributed active measurements, and traffic analysis at end devices, we show that: (i) the WhatsApp hosting architecture is highly centralized and exclusively located in the US; (ii) video sharing covers almost 40\% of the total WhatsApp traffic volume; (iii) flow characteristics depend on the OS of the end device; (iv) despite the big latencies to US servers, download throughputs are as high as 1.5 Mbps; (v) users react immediately and negatively to service outages through social networks feedbacks.},
booktitle = {Proceedings of the 2014 ACM Conference on SIGCOMM},
pages = {133–134},
numpages = {2},
keywords = {service outages, mobile networks, whatsapp, large-scale measurements, instant multimedia messaging},
location = {Chicago, Illinois, USA},
series = {SIGCOMM '14}
}

@article{10.1145/2740070.2631461,
author = {Fiadino, Pierdomenico and Schiavone, Mirko and Casas, Pedro},
title = {Vivisecting Whatsapp through Large-Scale Measurements in Mobile Networks},
year = {2014},
issue_date = {October 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {4},
issn = {0146-4833},
url = {https://doi.org/10.1145/2740070.2631461},
doi = {10.1145/2740070.2631461},
abstract = {WhatsApp, the new giant in instant multimedia messaging in mobile networks is rapidly increasing its popularity, taking over the traditional SMS/MMS messaging. In this paper we present the first large-scale characterization of WhatsApp, useful among others to ISPs willing to understand the impacts of this and similar applications on their networks. Through the combined analysis of passive measurements at the core of a national mobile network, worldwide geo-distributed active measurements, and traffic analysis at end devices, we show that: (i) the WhatsApp hosting architecture is highly centralized and exclusively located in the US; (ii) video sharing covers almost 40\% of the total WhatsApp traffic volume; (iii) flow characteristics depend on the OS of the end device; (iv) despite the big latencies to US servers, download throughputs are as high as 1.5 Mbps; (v) users react immediately and negatively to service outages through social networks feedbacks.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = {aug},
pages = {133–134},
numpages = {2},
keywords = {large-scale measurements, mobile networks, instant multimedia messaging, whatsapp, service outages}
}

@inproceedings{10.1145/2984393.2984398,
author = {Tomtsis, Dimitrios and Kontogiannis, Sotirios and Kokkonis, George and Zinas, Nicholas},
title = {IoT Architecture for Monitoring Wine Fermentation Process of Debina Variety Semi-Sparkling Wine},
year = {2016},
isbn = {9781450348102},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2984393.2984398},
doi = {10.1145/2984393.2984398},
abstract = {This paper proposes a new system architecture and HTTP communication mechanism called Smart Barrel System (Wine-SBS) for the process of monitoring Debina varietal sparkling wine fermenting conditions, produced at the area of Zitsa Epirus, Greece. The system includes microcontroller equipment with sensors that monitor wine attributes and storage conditions, called CBS-sensor transceivers, which are distributed among the debina fermentation vessels. The transmission of measurements, which occur periodically, are sent to a central cloud system application service. The CBS-sensor data are collected by a CBS-sensor collector and then follows an HTTP/2 request of multiplexed HTTP flows to a remote application server.},
booktitle = {Proceedings of the SouthEast European Design Automation, Computer Engineering, Computer Networks and Social Media Conference},
pages = {42–47},
numpages = {6},
keywords = {wine fermentation monitoring system, Precision enology, wireless sensor network},
location = {Kastoria, Greece},
series = {SEEDA-CECNSM '16}
}

@inproceedings{10.1145/3331076.3331108,
author = {Buccafurri, Francesco and Musarella, Lorenzo and Nardone, Roberto},
title = {Enabling Propagation in Web of Trust by Ethereum},
year = {2019},
isbn = {9781450362498},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3331076.3331108},
doi = {10.1145/3331076.3331108},
abstract = {Web of Trust offers a way to bind identities with the corresponding public keys. It relies on a distributed architecture, where each user could play the role of certificate signer. With the widespread diffusion of social networks, the trust propagation is a matter of growing interest. This paper proposes an approach enabling the propagation in Web of Trust by means of Ethereum. The usage of Ethereum eliminates the necessity of single-organization trusted services, which is, in general, not realistic. Although the information stored on Ethereum is public, the privacy of users is protected because trust chains involve only Ethereum addresses and strong measures are implemented to contrast their malicious de-anonymization. The approach relies on the usage of a smart contract for storing the status of certificate signatures and to manage revocations. When a user u wants to trust another user v, the smart contract checks the presence of trust chains originating from root nodes of u.},
booktitle = {Proceedings of the 23rd International Database Applications \&amp; Engineering Symposium},
articleno = {9},
numpages = {6},
keywords = {social network, trust propagation, smart contract, pretty good privacy, Ethereum, blockchain},
location = {Athens, Greece},
series = {IDEAS '19}
}

@inproceedings{10.1145/3297663.3309668,
author = {Talreja, Disha and Lahiri, Kanishka and Kalambur, Subramaniam and Raghavendra, Prakash},
title = {Performance Scaling of Cassandra on High-Thread Count Servers},
year = {2019},
isbn = {9781450362399},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297663.3309668},
doi = {10.1145/3297663.3309668},
abstract = {NoSQL databases are commonly used today in cloud deployments due to their ability to "scale-out" and effectively use distributed computing resources in a data center. At the same time, cloud servers are also witnessing rapid growth in CPU core counts, memory bandwidth, and memory capacity. Hence, apart from scaling out effectively, it's important to consider how such workloads "scale-up" within a single system, so that they can make the best use of available resources. In this paper, we describe our experiences studying the performance scaling characteristics of Cassandra, a popular open-source, column-oriented database, on a single high-thread count dual socket server. We demonstrate that using commonly used benchmarking practices, Cassandra does not scale well on such systems. Next, we show how by taking into account specific knowledge of the underlying topology of the server architecture, we can achieve substantial improvements in performance scalability. We report on how, during the course of our work, we uncovered an area for performance improvement in the official open-source implementation of the Java platform with respect to NUMA awareness. We show how optimizing this resulted in 27\% throughput gain for Cassandra under studied configurations. As a result of these optimizations, using standard workload generators, we obtained up to 1.44x and 2.55x improvements in Cassandra throughput over baseline single and dual-socket performance measurements respectively. On wider testing across a variety of workloads, we achieved excellent performance scaling, averaging 98\% efficiency within a socket and 90\% efficiency at the system-level.},
booktitle = {Proceedings of the 2019 ACM/SPEC International Conference on Performance Engineering},
pages = {179–187},
numpages = {9},
keywords = {cassandra, performance benchmarking, nosql databases, performance scalability},
location = {Mumbai, India},
series = {ICPE '19}
}

@inproceedings{10.1145/3241539.3241567,
author = {Marquez, Cristina and Gramaglia, Marco and Fiore, Marco and Banchs, Albert and Costa-Perez, Xavier},
title = {How Should I Slice My Network? A Multi-Service Empirical Evaluation of Resource Sharing Efficiency},
year = {2018},
isbn = {9781450359030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3241539.3241567},
doi = {10.1145/3241539.3241567},
abstract = {By providing especially tailored instances of a virtual network,network slicing allows for a strong specialization of the offered services on the same shared infrastructure. Network slicing has profound implications on resource management, as it entails an inherent trade-off between: (i) the need for fully dedicated resources to support service customization, and (ii) the dynamic resource sharing among services to increase resource efficiency and cost-effectiveness of the system. In this paper, we provide a first investigation of this trade-off via an empirical study of resource management efficiency in network slicing. Building on substantial measurement data collected in an operational mobile network (i) we quantify the efficiency gap introduced by non-reconfigurable allocation strategies of different kinds of resources, from radio access to the core of the network, and (ii) we quantify the advantages of their dynamic orchestration at different timescales. Our results provide insights on the achievable efficiency of network slicing architectures, their dimensioning, and their interplay with resource management algorithms.},
booktitle = {Proceedings of the 24th Annual International Conference on Mobile Computing and Networking},
pages = {191–206},
numpages = {16},
keywords = {network efficiency, network slicing, resource management},
location = {New Delhi, India},
series = {MobiCom '18}
}

@inproceedings{10.1109/CCGrid.2014.50,
author = {Tolosana-Calasanz, Rafael and Ba\~{n}ares, Jos\'{e} \'{A}ngel and Rana, Omer and Pham, Congduc and Xydas, Erotokritos and Marmaras, Charalampos and Papadopoulos, Panagiotis and Cipcigan, Liana},
title = {Enforcing Quality of Service on OpenNebula-Based Shared Clouds},
year = {2014},
isbn = {9781479927838},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGrid.2014.50},
doi = {10.1109/CCGrid.2014.50},
abstract = {With an increase in the number of monitoring sensors deployed on physical infrastructures, there is a corresponding increase in data volumes that need to be processed. Data measured or collected by sensors is typically processed at destination or "in-transit" (i.e. from data capture to delivery to a user). When such data are processed in-transit over a shared distributed computing infrastructure, it is useful to provide elastic computational capability which can be adapted based on processing requirements and demand. Where Service Level Agreements (SLAs) have been pre-agreed, such available computational capacity needs to be shared in such a way that any Quality of Service related constraints in such SLAs are not violated. This is particularly challenging for time critical applications and with highly variable and unpredictable rates of data generation (e.g. in Smart Grid applications where energy usage patterns may change unpredictably). Previously, we proposed a Reference net based architectural model for supporting QoS for multiple concurrent data streams being processed (prior to delivery to a user) over a shared infrastructure. In this paper, we describe a practical realisation of this architecture using the OpenNebula Cloud platform. We consider our infrastructure to be composed of a number of nodes, each of which has multiple processing units and data buffers. We utilize the "token bucket" model for regulating, on a per stream basis, the data injection rate into each node. We subsequently demonstrate how a streaming pipeline can be supported and managed using a dynamic control strategy at each node.},
booktitle = {Proceedings of the 14th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
pages = {651–659},
numpages = {9},
location = {Chicago, Illinois},
series = {CCGRID '14}
}

@article{10.1145/2968216,
author = {Maqsood, Tahir and Khalid, Osman and Irfan, Rizwana and Madani, Sajjad A. and Khan, Samee U.},
title = {Scalability Issues in Online Social Networks},
year = {2016},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2968216},
doi = {10.1145/2968216},
abstract = {The last decade witnessed a tremendous increase in popularity and usage of social network services, such as Facebook, Twitter, and YouTube. Moreover, advances in Web technologies coupled with social networks has enabled users to not only access, but also generate, content in many forms. The overwhelming amount of produced content and resulting network traffic gives rise to precarious scalability issues for social networks, such as handling a large number of users, infrastructure management, internal network traffic, content dissemination, and data storage. There are few surveys conducted to explore the different dimensions of social networks, such as security, privacy, and data acquisition. Most of the surveys focus on privacy or security-related issues and do not specifically address scalability challenges faced by social networks. In this survey, we provide a comprehensive study of social networks along with their significant characteristics and categorize social network architectures into three broad categories: (a) centralized, (b) decentralized, and (c) hybrid. We also highlight various scalability issues faced by social network architectures. Finally, a qualitative comparison of presented architectures is provided, which is based on various scalability metrics, such as availability, latency, interserver communication, cost of resources, and energy consumption, just to name a few.},
journal = {ACM Comput. Surv.},
month = {sep},
articleno = {40},
numpages = {42},
keywords = {decentralized social networks, social network, centralized social networks, hybrid social networks, Scalability}
}

@inproceedings{10.1145/3003733.3003756,
author = {Efthymiopoulos, Nikolaos and Efthymiopoulou, Maria and Christakidis, Athanasios},
title = {Experimentation on Low Delay and Stable Congestion Control for P2P Video Streaming},
year = {2016},
isbn = {9781450347891},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3003733.3003756},
doi = {10.1145/3003733.3003756},
abstract = {In recent years, a number of research efforts have focused on using peer-to-peer (P2P) systems in order to provide live streaming (LS) and Video-on-Demand (VoD) services. Most of them focused on the development of distributed P2P block schedulers for content exchange among the participating peers and on the architecture of the overlay graph (P2P overlay) that interconnects the set of these peers. Currently, the effort has shifted towards the combination of P2P systems with cloud infrastructures. By deploying monitoring and control architectures they use resources from the cloud in order to enhance the QoS, thus achieving an attractive trade-off between stability and low cost operation. However, there is a lack of research effort on the congestion control layer of these systems while the existing congestion control architectures in use are not suited for P2P traffic. This paper proposes a P2P congestion control protocol suitable for LS and VoD that: i) is capable to manage sequential traffic to multiple network destinations, ii) efficiently exploits the available bandwidth, iii) accurately measures the idle peers' resources, iv) it avoids network congestion, and v) is friendly to other TCP generated traffic. Our proposed algorithms and protocol have been implemented, tested and evaluated through a series of real experiments in the context of STEER [20].},
booktitle = {Proceedings of the 20th Pan-Hellenic Conference on Informatics},
articleno = {48},
numpages = {6},
keywords = {video streaming, congestion control, P2P},
location = {Patras, Greece},
series = {PCI '16}
}

@inproceedings{10.5555/2667510.2667516,
author = {Seneviratne, Janaka and Parampalli, Udaya and Kulik, Lars},
title = {An Authorised Pseudonym System for Privacy Preserving Location Proof Architectures},
year = {2014},
isbn = {9781921770326},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {An emerging class of Location Based Services (LBSs) needs verified mobile device locations for service provision. For example, an automated car park billing system requires verified locations of cars to confirm the place and the duration of parked cars. Location Proof Architectures (LPAs) allow a user (or a device on behalf of its user) to obtain a proof of its presence at a location from a trusted third party. A major concern in LPAs is to preserve user location privacy. To achieve this a user's identity and location data should be maintained separately with additional measures that prevent leaking sensitive identity and location data. In this paper, we present a privacy preserving LPA in which users appear under pseudonyms. Our main contribution is a third party free pseudonym registering protocol based on blind signature schemes. We show that our protocol allows to build a pseudonym system with a guaranteed degree of privacy agreed at the time of pseudonym registration. We also demonstrate that a pseudonym can be authenticated across different organizations in an LPA. Our system ensures that (i) only authenticated users can register their pseudonyms, (ii) the pseudonyms have a consistent degree of privacy at the point of registration and (iii) a user cannot take another user's pseudonym.},
booktitle = {Proceedings of the Twelfth Australasian Information Security Conference - Volume 149},
pages = {47–56},
numpages = {10},
keywords = {privacy, pseudonym, location proof architecture},
location = {Auckland, New Zealand},
series = {AISC '14}
}

@inproceedings{10.1145/2695664.2695835,
author = {Rrushi, Julian L. and Farhangi, Hassan and Nikolic, Radina and Howey, Clay and Carmichael, Kelly and Palizban, Ali},
title = {By-Design Vulnerabilities in the ANSI C12.22 Protocol Specification},
year = {2015},
isbn = {9781450331968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2695664.2695835},
doi = {10.1145/2695664.2695835},
abstract = {The ANSI C12.22 is a standard that specifies interfaces to data communication networks in the smart grid. In this paper we discuss several vulnerabilities by design that we discovered in the ANSI C12.22 protocol specification during an analysis of the overall protocol architecture. The consequences of an exploitation of those vulnerabilities consist of denial of service conditions and disruptions to ANSI C12.22 nodes and relays. We developed attack code to experiment with exploitations of most of the vulnerabilities that we discuss in this paper. Our research testbed consisted of meters that we emulated via the Trilliant TstBench software. The emulated meters were running on virtual Windows machines on a virtual network. In the paper, we provide details of the vulnerabilities by design that we identified, and thus propose a series of revisions of the ANSI C12.22 protocol specification with the objective of mitigating those vulnerabilities.},
booktitle = {Proceedings of the 30th Annual ACM Symposium on Applied Computing},
pages = {2231–2236},
numpages = {6},
keywords = {ANSI C12.22 protocol, smartgrid security, vulnerabilities},
location = {Salamanca, Spain},
series = {SAC '15}
}

@inproceedings{10.1145/3197768.3201560,
author = {Tzallas, Alexandros T. and Katertsidis, Nikolaos and Glykos, Konstantinos and Segkouli, Sofia and Votis, Konstantinos and Tzovaras, Dimitrios and Barru\'{e}, Cristian and Paliokas, Ioannis and Cort\'{e}s, Ulises},
title = {Designing a Gamified Social Platform for People Living with Dementia and Their Live-in Family Caregivers},
year = {2018},
isbn = {9781450363907},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3197768.3201560},
doi = {10.1145/3197768.3201560},
abstract = {In the current paper, a social gamified platform for people living with dementia and their live-in family caregivers, integrating a broader diagnostic approach and interactive interventions is presented. The CAREGIVERSPRO-MMD (C-MMD) platform constitutes a support tool for the patient and the informal caregiver - also referred to as the dyad - that strengthens self-care, and builds community capacity and engagement at the point of care. The platform is implemented to improve social collaboration, adherence to treatment guidelines through gamification, recognition of progress indicators and measures to guide management of patients with dementia, and strategies and tools to improve treatment interventions and medication adherence. Moreover, particular attention was provided on guidelines, considerations and user requirements for the design of a User-Centered Design (UCD) platform. The design of the platform has been based on a deep understanding of users, tasks and contexts in order to improve platform usability, and provide adaptive and intuitive User Interfaces with high accessibility. In this paper, the architecture and services of the C-MMD platform are presented, and specifically the gamification aspects.},
booktitle = {Proceedings of the 11th PErvasive Technologies Related to Assistive Environments Conference},
pages = {476–481},
numpages = {6},
keywords = {Interventions, Cloud Platform, Caregivers, Gamification, Social Networking, Self-management, Dementia},
location = {Corfu, Greece},
series = {PETRA '18}
}

@inproceedings{10.1145/3018896.3018934,
author = {Kokkonis, George and Kontogiannis, Sotirios and Tomtsis, Dimitrios},
title = {FITRA: A Neuro-Fuzzy Computational Algorithm Approach Based on an Embedded Water Planting System},
year = {2017},
isbn = {9781450347747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3018896.3018934},
doi = {10.1145/3018896.3018934},
abstract = {This paper proposes a novel neuro-fuzzy computational algorithm for embedded irrigation systems called FITRA. It presents a new system architecture for the process of continuously monitoring environmental conditions and efficient irrigation of arable areas. The system includes microcontroller equipment with multiple sensors interspersed all over the field. Transmissions of measurements, which occur periodically, send to a central cloud system Application Service (AS) assisted by a 3G network. The decision for irrigation or not is made by a neuro-fuzzy algorithm. As an input for that algorithm are the values taken from the interspersed sensors. As an output, this algorithm controls the central solenoid water valve of the water planting system. The irrigation system automatically adjusts to changing environmental conditions.},
booktitle = {Proceedings of the Second International Conference on Internet of Things, Data and Cloud Computing},
articleno = {39},
numpages = {8},
keywords = {soil sensor, agriculture, water planting systems, IoT, smart irrigation, smart farming, neuro-fuzzy algorithms},
location = {Cambridge, United Kingdom},
series = {ICC '17}
}

@article{10.1109/TNET.2014.2354262,
author = {Adhikari, Vijay K. and Guo, Yang and Hao, Fang and Hilt, Volker and Zhang, Zhi-Li and Varvello, Matteo and Steiner, Moritz},
title = {Measurement Study of Netflix, Hulu, and a Tale of Three CDNs},
year = {2015},
issue_date = {December 2015},
publisher = {IEEE Press},
volume = {23},
number = {6},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2014.2354262},
doi = {10.1109/TNET.2014.2354262},
abstract = {Netflix and Hulu are leading Over-the-Top (OTT) content service providers in the US and Canada. Netflix alone accounts for 29.7\% of the peak downstream traffic in the US in 2011. Understanding the system architectures and performance of Netflix and Hulu can shed light on the design of such large-scale video streaming platforms, and help improving the design of future systems. In this paper, we perform extensive measurement study to uncover their architectures and service strategies. Netflix and Hulu bear many similarities. Both Netflix and Hulu video streaming platforms rely heavily on the third-party infrastructures, with Netflix migrating that majority of its functions to the Amazon cloud, while Hulu hosts its services out of Akamai. Both service providers employ the same set of three content distribution networks (CDNs) in delivering the video contents. Using active measurement study, we dissect several key aspects of OTT streaming platforms of Netflix and Hulu, e.g., employed streaming protocols, CDN selection strategy, user experience reporting, etc. We discover that both platforms assign the CDN to a video request without considering the network conditions and optimizing the user-perceived video quality. We further conduct the performance measurement studies of the three CDNs employed by Netflix and Hulu. We show that the available bandwidths on all three CDNs vary significantly over the time and over the geographic locations. We propose a measurement-based adaptive CDN selection strategy and a multiple-CDN-based video delivery strategy that can significantly increase users' average available bandwidth.},
journal = {IEEE/ACM Trans. Netw.},
month = {dec},
pages = {1984–1997},
numpages = {14},
keywords = {over-the-top (OTT) content service, Netflix, CDN selection strategy, video streaming, content distribution networks (CDN), Hulu}
}

@inproceedings{10.1145/3297280.3297648,
author = {Koupaee, Mahnaz},
title = {Mortality Prediction Using Medical Notes: Student Research Abstract},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297648},
doi = {10.1145/3297280.3297648},
abstract = {Mortality prediction is a critical task for assessing patients' conditions in Intensive Care Units (ICU) of hospitals to improve decision-making and quality of care. Measurements taken and recorded at different time points are the main source of information to be used for tasks related to healthcare. However, the notes written by medical service providers during patients' stay in hospital as a rich source of detailed information is not sufficiently exploited. In this work, we propose a Convolutional Neural Network (CNN) architecture to utilize the unstructured texts to predict the pre-discharge and post-discharge mortality of ICU patients. Evaluations show high performance of the proposed method in terms of precision and recall. Moreover, our method outperforms the state of the art method by achieving a higher AUC.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {778–781},
numpages = {4},
keywords = {medical notes, convolutional neural network, MIMIC, mortality prediction},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1145/2699343.2699348,
author = {Achtzehn, Andreas and Riihihj\"{a}rvi, Janne and Barri\'{\i}a Castillo, Irving Antonio and Petrova, Marina and M\"{a}h\"{o}nen, Petri},
title = {CrowdREM: Harnessing the Power of the Mobile Crowd for Flexible Wireless Network Monitoring},
year = {2015},
isbn = {9781450333917},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2699343.2699348},
doi = {10.1145/2699343.2699348},
abstract = {High-speed mobile broadband connections have opened exciting new opportunities to collect sensor data from thousands or even millions of distributed mobile devices for the purpose of crowdsourced decision making. In this paper, we propose CrowdREM (crowdsourced radio environment mapping), a framework with the specific aim of monitoring and modelling wireless cellular networks. CrowdREM enables operator-independent and highly efficient collection of network performance data along all layers of the communications protocol stack. Such extensive information on network load, spectrum usage, or local coverage can help operators to optimize their networks and service quality and enable improved consumer decision making. In this paper, we introduce the mbox{CrowdREM} mobile architecture and show first results from a prototype implementation on open-source mobile phones. We demonstrate the versatility of using commodity devices for network and spectrum monitoring, and present the challenges originating from the use of uncalibrated and low-precision measurement equipment. We have acquired an extensive data set from using our prototype implementation in a 21-day measurement campaign covering more than 1,000 hours of measurement data. From this we present and discuss the potential derivation of tangible and relevant network performance and signal quality indicators, which could, e.g., be conducted by independent parties.},
booktitle = {Proceedings of the 16th International Workshop on Mobile Computing Systems and Applications},
pages = {63–68},
numpages = {6},
keywords = {cellular networks, drive testing, crowdsourcing, mobile},
location = {Santa Fe, New Mexico, USA},
series = {HotMobile '15}
}

@inproceedings{10.1145/2578153.2583037,
author = {Chrobot, Nina},
title = {The Role of Processing Fluency in Online Consumer Behavior: Evaluating Fluency by Tracking Eye Movements},
year = {2014},
isbn = {9781450327510},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2578153.2583037},
doi = {10.1145/2578153.2583037},
abstract = {The Internet enables people to extensively research products or services, and also easily compare prices between offers [e.g. Baker et al. 2001]. Taking into account the amount of information available on the Internet, acquisition of new information can face some difficulties, especially when one wants to make a purchase decision. Therefore, the ability to process relevant information fluently enables a user to create a better experience and to become more efficient in gathering information related to the purpose of the visit. This ability might be connected to the cognitive task that can either be effortless or effortful, and may lead to a metacognitive experience of either fluency or disfluency [Alter and Oppenheimer 2009]. Nevertheless, some e-commerce websites are preferred over others and this preference varies between individuals. This variation can be influenced by user's prior experience, cognitive sources but also graphics or information architecture on the web page. Presented project aims at applying the fluency concept to consumer behavior in online environment by studying eye movements and promoting eye tracking as an objective measure.},
booktitle = {Proceedings of the Symposium on Eye Tracking Research and Applications},
pages = {387–388},
numpages = {2},
location = {Safety Harbor, Florida},
series = {ETRA '14}
}

@inproceedings{10.1145/2851613.2851727,
author = {Megyesi, P\'{e}ter and Botta, Alessio and Aceto, Giuseppe and Pescap\`{e}, Antonio and Moln\'{a}r, S\'{a}ndor},
title = {Available Bandwidth Measurement in Software Defined Networks},
year = {2016},
isbn = {9781450337397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851613.2851727},
doi = {10.1145/2851613.2851727},
abstract = {Software Defined Networking (SDN) is an emerging paradigm that is expected to revolutionize computer networks. With the decoupling of data and control plane and the introduction of open communication interfaces between layers, SDN enables programmability over the entire network, promising rapid innovation in this area. The SDN concept was already proven to work successfully in cloud and data center environments thus the proper monitoring of such networks is already in the focus of the research community. Methods for measuring Quality of Service (QoS) parameters such as bandwidth utilization, packet loss, and delay have been recently introduced in literature, but they lack a solution for tackling down the question of available bandwidth. In this paper, we attempt to fill this gap and introduce a novel mechanism for measuring available bandwidth in SDN networks. We take advantage of the SDN architecture and build an application over the Network Operating System (NOS). Our application can track the topology of the network and the bandwidth utilization over the network links, and thus it is able to calculate the available bandwidth between any two points in the network. We validate our method using the popular Mininet network emulation environment and the widely used NOS called Floodlight. We present results providing insights into the measurement accuracy and showing its relationship with the delay in the control network and the polling frequency.},
booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},
pages = {651–657},
numpages = {7},
keywords = {software defined networks, floodlight, network operating system, OpenFlow, available bandwidth, mininet},
location = {Pisa, Italy},
series = {SAC '16}
}

@article{10.1145/3457143,
author = {Burny, Nicolas and Vanderdonckt, Jean},
title = {UiLab, a Workbench for Conducting and Reproducing Experiments in GUI Visual Design},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {EICS},
url = {https://doi.org/10.1145/3457143},
doi = {10.1145/3457143},
abstract = {With the continuously increasing number and variety of devices, the study of visual design of their Graphical User Interfaces grows in importance and scope, particularly for new devices, including smartphones, tablets, and large screens. Conducting a visual design experiment typically requires defining and building a GUI dataset with different resolutions for different devices, computing visual design measures for the various configurations, and analyzing their results. This workflow is very time- and resource-consuming, therefore limiting its reproducibility. To address this problem, we present UiLab, a cloud-based workbench that parameterizes the settings for conducting an experiment on visual design of Graphical User Interfaces, for facilitating the design of such experiments by automating some workflow stages, and for fostering their reproduction by automating their deployment. Based on requirements elicited for UiLab, we define its conceptual model to delineate the borders of services of the software architecture to support the new workflow. We exemplify it by demonstrating a system walkthrough and we assess its impact on experiment reproducibility in terms of design and development time saved with respect to a classical workflow. Finally, we discuss potential benefits brought by this workbench with respect to reproducing experiments in GUI visual design and existing shortcomings to initiate future avenues. We publicly release UiLab source code on a GitHub repository.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {may},
articleno = {196},
numpages = {31},
keywords = {aesthetics, usability evaluation, visual design, user interface evaluation}
}

@inproceedings{10.1145/3452918.3467815,
author = {Dijkstra-Soudarissanane, Sylvie and Klunder, Tessa and Brandt, Aschwin and Niamut, Omar},
title = {Towards XR Communication for Visiting Elderly at Nursing Homes},
year = {2021},
isbn = {9781450383899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452918.3467815},
doi = {10.1145/3452918.3467815},
abstract = {Due to the current pandemic, the elderly in care homes are greatly affected by the lack of contact with their families, resulting in various mental conditions (e.g., depression, feelings of loneliness) and deterioration of mental health for dementia patients. In response, residents and family members increasingly resorted to mediated communication to maintain social contact. To facilitate high-quality mediated social contact between residents in nursing homes and remote family members, we developed an Augmented Reality (AR)-based communication tool. The proposed demonstrator improved this situation by providing a working communication tool that enables the elderly to feel being together with their family by means of AR techniques. A complete end-to-end-chain architecture is defined, where the aspects of capture, transmission, and rendering are thoroughly investigated to fit the purpose of the use case. Based on an extensive user study comprising user experience (UX) and quality of service (QoS) measurements, each module is presented with the improvements made and the resulting higher quality AR communication platform.},
booktitle = {Proceedings of the 2021 ACM International Conference on Interactive Media Experiences},
pages = {319–321},
numpages = {3},
keywords = {Communication, Immersive Media, Augmented Reality, WebRTC, Conferencing, AR, Social XR, Volumetric video},
location = {Virtual Event, USA},
series = {IMX '21}
}

@inproceedings{10.1145/3075564.3075584,
author = {Xu, Dawen and Liao, Yi and Wang, Ying and Li, Huawei and Li, Xiaowei},
title = {Selective Off-Loading to Memory: Task Partitioning and Mapping for PIM-Enabled Heterogeneous Systems},
year = {2017},
isbn = {9781450344876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3075564.3075584},
doi = {10.1145/3075564.3075584},
abstract = {Processing-in-Memory (PIM) is returning as a promising solution to address the issue of memory wall as computing systems gradually step into the big data era. Researchers continually proposed various PIM architecture combined with novel memory device or 3D integration technology, but it is still a lack of universal task scheduling method in terms of the new heterogeneous platform. In this paper, we propose a formalized model to quantify the performance and energy of the PIM+CPU heterogeneous parallel system. In addition, we are the first to build a task partitioning and mapping framework to exploit different PIM engines. In this framework, an application is divided into subtasks and mapped onto appropriate execution units based on the proposed PIM-oriented Earliest-Finish-Time (PEFT) algorithm to maximize the performance gains brought by PIM. Experimental evaluations show our PIM-aware framework significantly improves the system performance compared to conventional processor architectures.},
booktitle = {Proceedings of the Computing Frontiers Conference},
pages = {255–258},
numpages = {4},
keywords = {Mapping, Architecture, Memory Wall, PIM},
location = {Siena, Italy},
series = {CF'17}
}

@inproceedings{10.1145/2976767.2987689,
author = {Falkner, Katrina and Szabo, Claudia and Chiprianov, Vanea},
title = {Model-Driven Performance Prediction of Systems of Systems},
year = {2016},
isbn = {9781450343213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2976767.2987689},
doi = {10.1145/2976767.2987689},
abstract = {Systems of Systems exhibit characteristics that pose difficulty in modelling and predicting their overall performance capabilities, including the presence of operational independence, emergent behaviour, and evolutionary development. When considering Systems of Systems within the autonomous defence systems context, these aspects become increasingly critical, as performance constraints are typically driven by hard constraints on space, weight and power.System execution modelling languages and tools permit early prediction of the performance of model-driven systems, however the focus to date has been on understanding the performance of a model rather than determining if it meets performance requirements, and only subsequently carrying out analysis to reveal the causes of any requirement violations. Such an analysis is even more difficult when applied to several systems cooperating to achieve a common goal - a System of Systems (SoS).The successful integration of systems within a SoS context has been identified as one of the most substantial challenges facing military systems development [2]. Accordingly, there is a critical need to understand the non-functional aspects of the SoS (such as quality of service, power, size, cost and scalable management of communications), and to explore how these non-functional aspects evolve under new conditions and deployment scenarios. It is crucial that we develop methodologies for modelling and understanding non-functional properties early in the development and integration cycle to better inform our understanding of the impact of emergent behaviour and evolution within the SoS.We propose an integrated approach to performance prediction of model-driven real time embedded defence systems and systems of systems [1]. Our architectural prototyping system supports a scenario-driven experimental platform for evaluating model suitability within a set of deployment and real-time performance constraints. We present an overview of our performance prediction system, demonstrating the integration of modelling, execution and performance analysis, and discuss a case study to illustrate our approach. Our work employs state-of-the-art model-driven engineering techniques to facilitate SoS performance prediction and analysis at design time, either before the SoS is built and deployed, or during its lifetime when required to evolve.Our model-driven performance prediction platform supports a scenario-driven experimental environment for evaluating a SoS within the context of a specific deployment (modelling geographical distribution) and integration constraints. The main contributions of our work are: (a) a modeling methodology that captures diverse perspectives of the performance modeling of Systems of Systems; (b) a performance analysis engine that captures metrics associated with these perspectives and (c) a case study showing the performance evaluaton of a system of systems and its evolution as a result of the performance analysis. We discuss how our approach to modelling supports the specific characteristics of an SoS, and illustrate this through a case study, based on a "Blue Ocean" scenario, demonstrating how we may obtain performance predictions within a SoS with emergent and evolutionary properties. Within the context of our environment, we define models for the individual systems within our System of Systems, defined for representative workload to predict execution costs, i.e. CPU, memory usage and network usage, within a generic situation. Our modelling environment supports the generation of executable forms of these models, which may then be executed above realistic deployment scenarios in order to obtain predictions of System of System performance.},
booktitle = {Proceedings of the ACM/IEEE 19th International Conference on Model Driven Engineering Languages and Systems},
pages = {44},
numpages = {1},
location = {Saint-malo, France},
series = {MODELS '16}
}

@inproceedings{10.1145/3005745.3005762,
author = {Tilmans, Olivier and B\"{u}hler, Tobias and Vissicchio, Stefano and Vanbever, Laurent},
title = {Mille-Feuille: Putting ISP Traffic under the Scalpel},
year = {2016},
isbn = {9781450346610},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3005745.3005762},
doi = {10.1145/3005745.3005762},
abstract = {For Internet Service Provider (ISP) operators, getting an accurate picture of how their network behaves is challenging. Given the traffic volumes that their networks carry and the impossibility to control end-hosts, ISP operators are typically forced to randomly sample traffic, and rely on aggregated statistics. This provides coarse-grained visibility, at a time resolution that is far from ideal (seconds or minutes). In this paper, we present Mille-Feuille, a novel monitoring architecture that provides fine-grained visibility over ISP traffic. Mille-Feuille schedules activation and deactivation of traffic-mirroring rules, that are then provisioned network-wide from a central location, within milliseconds. By doing so, Mille-Feuille combines the scalability of sampling with the visibility and controllability of traffic mirroring. As a result, it supports a set of monitoring primitives, ranging from checking key performance indicators (e.g., one-way delay) for single destinations to estimating traffic matrices in sub-seconds. Our preliminary measurements on existing routers confirm that Mille-Feuille is viable in practice.},
booktitle = {Proceedings of the 15th ACM Workshop on Hot Topics in Networks},
pages = {113–119},
numpages = {7},
location = {Atlanta, GA, USA},
series = {HotNets '16}
}

