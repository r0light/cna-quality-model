@Article{Laigner2021,
  author     = {Laigner, Rodrigo and Zhou, Yongluan and Salles, Marcos Antonio Vaz and Liu, Yijian and Kalinowski, Marcos},
  journal    = {Proc. VLDB Endow.},
  title      = {Data Management in Microservices: State of the Practice, Challenges, and Research Directions},
  year       = {2021},
  issn       = {2150-8097},
  month      = {sep},
  number     = {13},
  pages      = {3348–3361},
  volume     = {14},
  abstract   = {Microservices have become a popular architectural style for data-driven applications, given their ability to functionally decompose an application into small and autonomous services to achieve scalability, strong isolation, and specialization of database systems to the workloads and data formats of each service. Despite the accelerating industrial adoption of this architectural style, an investigation of the state of the practice and challenges practitioners face regarding data management in microservices is lacking. To bridge this gap, we conducted a systematic literature review of representative articles reporting the adoption of microservices, we analyzed a set of popular open-source microservice applications, and we conducted an online survey to cross-validate the findings of the previous steps with the perceptions and experiences of over 120 experienced practitioners and researchers.Through this process, we were able to categorize the state of practice of data management in microservices and observe several foundational challenges that cannot be solved by software engineering practices alone, but rather require system-level support to alleviate the burden imposed on practitioners. We discuss the shortcomings of state-of-the-art database systems regarding microservices and we conclude by devising a set of features for microservice-oriented database systems.},
  doi        = {10.14778/3484224.3484232},
  issue_date = {September 2021},
  numpages   = {14},
  publisher  = {VLDB Endowment},
  url        = {https://doi.org/10.14778/3484224.3484232},
}

@InProceedings{Yuan2019,
  author    = {Yuan, Eric},
  booktitle = {Proceedings of the 2nd International Workshop on Establishing a Community-Wide Infrastructure for Architecture-Based Software Engineering},
  title     = {Architecture Interoperability and Repeatability with Microservices: An Industry Perspective},
  year      = {2019},
  address   = {Montreal, Quebec, Canada},
  pages     = {26–33},
  publisher = {IEEE Press},
  series    = {ECASE '19},
  abstract  = {Microservices, along with supporting technologies such as containers, have become a prevalent architecture approach for today's software systems, especially in enterprise environments. They represent the latest evolutionary step in the decades-old journey towards service- and component-based software architectures. Along with virtualization technologies, microservices have enabled the loose-coupling of both service interfaces (message passing) and service integration (form and fit). This paper attempts to explore the impact of microservices on software architecture interoperability and repeatability, based on our experiences in developing two microservice-based systems. Our central thesis is that, if we view software architecture as a set of principal design decisions, the microservices approach enable us to more elegantly separate these decisions from non-architectural, domain-specific ones, and thus make these decisions more interoperable, reusable, and repeatable across disparate problem domains. We therefore propose that a microservices based reference architecture (RA) and reference implementation (RI) be created for the community-wide infrastructure for software engineering and software architecture research, along with a set of detailed considerations.},
  doi       = {10.1109/ECASE.2019.00013},
  keywords  = {software architecture, DevOps, microservice, cloud computing},
  numpages  = {8},
  url       = {https://doi.org/10.1109/ECASE.2019.00013},
}

@InProceedings{Santos2019,
  author    = {Santos, Nuno and Salgado, Carlos E. and Morais, Francisco and Melo, M\'{o}nica and Silva, Sara and Martins, Raquel and Pereira, Marco and Rodrigues, Helena and Machado, Ricardo J. and Ferreira, Nuno and Pereira, Manuel},
  booktitle = {Proceedings of the 13th European Conference on Software Architecture - Volume 2},
  title     = {A Logical Architecture Design Method for Microservices Architectures},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {145–151},
  publisher = {Association for Computing Machinery},
  series    = {ECSA '19},
  abstract  = {The use of microservices architectures has been widely adopted in software development, especially for cloud-based solutions. Developing such solutions faces several challenges beyond typical architecture and service design concerns, including service exposition (API), inter-service communication, and infrastructure deployment, among others. Although model-driven approaches allow abstracting microservices behavior from the business domain, there is a lack of proper methods for addressing the referred challenges. In this paper, the elicitation of microservices, their identification uses using functionally decomposed UML use cases as input within a logical architecture derivation method, namely an adapted version of the Four Step Rule Set (4SRS), using SoaML diagrams, that responds to microservices specific characteristics. We demonstrate the approach using a scenario within a live industrial project.},
  doi       = {10.1145/3344948.3344991},
  isbn      = {9781450371421},
  keywords  = {logical architectures, service participants, decomposition, SoaML, UML, microservices},
  location  = {Paris, France},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3344948.3344991},
}

@InProceedings{Aderaldo2017,
  author    = {Aderaldo, Carlos M. and Mendon\c{c}a, Nabor C. and Pahl, Claus and Jamshidi, Pooyan},
  booktitle = {Proceedings of the 1st International Workshop on Establishing the Community-Wide Infrastructure for Architecture-Based Software Engineering},
  title     = {Benchmark Requirements for Microservices Architecture Research},
  year      = {2017},
  address   = {Buenos Aires, Argentina},
  pages     = {8–13},
  publisher = {IEEE Press},
  series    = {ECASE '17},
  abstract  = {Microservices have recently emerged as a new architectural style in which distributed applications are broken up into small independently deployable services, each running in its own process and communicating via lightweight mechanisms. However, there is still a lack of repeatable empirical research on the design, development and evaluation of microservices applications. As a first step towards filling this gap, this paper proposes, discusses and illustrates the use of an initial set of requirements that may be useful in selecting a community-owned architecture benchmark to support repeatable microservices research.},
  isbn      = {9781538604175},
  keywords  = {software architecture, microservices, research benchmark},
  numpages  = {6},
}

@InProceedings{Avritzer2020a,
  author    = {Avritzer, Alberto},
  booktitle = {Companion of the ACM/SPEC International Conference on Performance Engineering},
  title     = {Automated Scalability Assessment in DevOps Environments},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {10},
  publisher = {Association for Computing Machinery},
  series    = {ICPE '20},
  abstract  = {In this extended abstract, we provide an outline of the presentation planned for WOSP-C 2020. The goal of the presentation is to provide an overview of the challenges and approaches for automated scalability assessment in the context of DevOps and microservices. The focus of this presentation is on approaches that employ automated identification of performance problems because these approaches can leverage performance anti-pattern[5] detection technology. In addition, we envision extending the approach to recommend component refactoring. In our previous work[1,2] we have designed a methodology and associated tool support for the automated scalability assessment of micro-service architectures, which included the automation of all the steps required for scalability assessment. The presentation starts with an introduction to dependability, operational Profile Data, and DevOps. Specifically, we provide an overview of the state of the art in continuous performance monitoring technologies[4] that are used for obtaining operational profile data using APM tools. We then present an overview of selected approaches for production and performance testing based on the application monitoring tool (PPTAM) as introduced in [1,2]. The presentation concludes by outlining a vision for automated performance anti-pattern[5] detection. Specifically, we present the approach introduced for automated anti-pattern detection based on load testing results and profiling introduced in[6] and provide recommendations for future research.},
  doi       = {10.1145/3375555.3384936},
  isbn      = {9781450371094},
  location  = {Edmonton AB, Canada},
  numpages  = {1},
  url       = {https://doi.org/10.1145/3375555.3384936},
}

@InProceedings{Spillner2019,
  author    = {Spillner, Josef},
  booktitle = {Proceedings of the 12th IEEE/ACM International Conference on Utility and Cloud Computing Companion},
  title     = {Serverless Computing and Cloud Function-Based Applications},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {177–178},
  publisher = {Association for Computing Machinery},
  series    = {UCC '19 Companion},
  abstract  = {Serverless computing is a growing industry trend with corresponding rise in interest by scholars and tinkerers. Increasingly, open source and academic system prototypes are being proposed especially in relation with cloud, edge and fog computing among other distributed computing specialisations. Due to the strict separation between elastically scalable stateless microservices bound to stateful backend services prevalent in this computing paradigm, the resulting applications are inherently distributed with favourable characteristics such as elastic scalability and disposability. Still, software application developers are confronted with a multitude of different methods and tools to build, test and deploy their function-based applications in today's serverless ecosystems. The logical next step is therefore a methodical development approach with key enablers based on a classification of languages, tools, systems, system behaviours, patterns, pitfalls, application architectures, compositions and cloud services around the serverless application development process.},
  doi       = {10.1145/3368235.3370269},
  isbn      = {9781450370448},
  keywords  = {tutorial, artefact quality, serverless computing, cloud functions},
  location  = {Auckland, New Zealand},
  numpages  = {2},
  url       = {https://doi.org/10.1145/3368235.3370269},
}

@InProceedings{Salama2015,
  author    = {Salama, Maria},
  booktitle = {Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering},
  title     = {Stability of Self-Adaptive Software Architectures},
  year      = {2015},
  address   = {Lincoln, Nebraska},
  pages     = {886–889},
  publisher = {IEEE Press},
  series    = {ASE '15},
  abstract  = {Stakeholders and organisations are increasingly looking for long-lived software. As architectures have a profound effect on the operational life-time of the software and the quality of the service provision, architectural stability could be considered a primary criterion towards achieving the long-livety of the software. Architectural stability is envisioned as the next step in quality attributes, combining many inter-related qualities. This research suggests the notion of behavioural stability as a primary criterion for evaluating whether the architecture maintains achieving the expected quality attributes, maintaining architecture robustness, and evaluating how well the architecture accommodates run-time evolutionary changes. The research investigates the notion of architecture stability at run-time in the context of self-adaptive software architectures. We expect to define, characterise and analyse this intuitive concept, as well as identify the consequent trade-offs to be dynamically managed and enhance the self-adaptation process for a long-lived software.},
  doi       = {10.1109/ASE.2015.93},
  isbn      = {9781509000241},
  numpages  = {4},
  url       = {https://doi.org/10.1109/ASE.2015.93},
}

@Article{Michel2021,
  author     = {Michel, Oliver and Bifulco, Roberto and R\'{e}tv\'{a}ri, G\'{a}bor and Schmid, Stefan},
  journal    = {ACM Comput. Surv.},
  title      = {The Programmable Data Plane: Abstractions, Architectures, Algorithms, and Applications},
  year       = {2021},
  issn       = {0360-0300},
  month      = {may},
  number     = {4},
  volume     = {54},
  abstract   = {Programmable data plane technologies enable the systematic reconfiguration of the low-level processing steps applied to network packets and are key drivers toward realizing the next generation of network services and applications. This survey presents recent trends and issues in the design and implementation of programmable network devices, focusing on prominent abstractions, architectures, algorithms, and applications proposed, debated, and realized over the past years. We elaborate on the trends that led to the emergence of this technology and highlight the most important pointers from the literature, casting different taxonomies for the field, and identifying avenues for future research.},
  address    = {New York, NY, USA},
  articleno  = {82},
  doi        = {10.1145/3447868},
  issue_date = {May 2022},
  keywords   = {Programmable data planes, programmable switches, packet processing, in-network computation, network programmability},
  numpages   = {36},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3447868},
}

@Article{Renen2023,
  author     = {van Renen, Alexander and Leis, Viktor},
  journal    = {Proc. VLDB Endow.},
  title      = {Cloud Analytics Benchmark},
  year       = {2023},
  issn       = {2150-8097},
  month      = {feb},
  number     = {6},
  pages      = {1413–1425},
  volume     = {16},
  abstract   = {The cloud facilitates the transition to a service-oriented perspective. This affects cloud-native data management in general, and data analytics in particular. Instead of managing a multi-node database cluster on-premise, end users simply send queries to a managed cloud data warehouse and receive results. While this is obviously very attractive for end users, database system architects still have to engineer systems for this new service model. There are currently many competing architectures ranging from self-hosted (Presto, PostgreSQL), over managed (Snowflake, Amazon Redshift) to query-as-a-service (Amazon Athena, Google BigQuery) offerings. Benchmarking these architectural approaches is currently difficult, and it is not even clear what the metrics for a comparison should be.To overcome these challenges, we first analyze a real-world query trace from Snowflake and compare its properties to that of TPC-H and TPC-DS. Doing so, we identify important differences that distinguish traditional benchmarks from real-world cloud data warehouse workloads. Based on this analysis, we propose the Cloud Analytics Benchmark (CAB). By incorporating workload fluctuations and multi-tenancy, CAB allows evaluating different designs in terms of user-centered metrics such as cost and performance.},
  doi        = {10.14778/3583140.3583156},
  issue_date = {February 2023},
  numpages   = {13},
  publisher  = {VLDB Endowment},
  url        = {https://doi.org/10.14778/3583140.3583156},
}

@InProceedings{Santos2021,
  author    = {Santos, Ana and Paula, Hugo},
  booktitle = {Proceedings of the 15th Brazilian Symposium on Software Components, Architectures, and Reuse},
  title     = {Microservice Decomposition and Evaluation Using Dependency Graph and Silhouette Coefficient},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {51–60},
  publisher = {Association for Computing Machinery},
  series    = {SBCARS '21},
  abstract  = {The benefits provided by microservices architecture in some application scenarios are a motivating factor for organizations to migrate their monoliths to this architecture. Extracting microservices from existing monolithic code bases presents a key challenge in this context, and there is a lack of tools that automate not only the decomposition processes but also the evaluation of the resulting architecture. This work presents a new approach for microservice decomposition that analyzes source code of a monolithic application and, with the combined use of approaches in the literature, suggests parts to be extracted in microservices considering the artifacts: classes, methods and/or history of modifications. The quality of the microservices’ suggestions are assessed, quantitatively, through the silhouette coefficient, a quality metric used in clustering analysis, and the microservice granularity. A tool was developed to automate the process of microservice decomposition for Java repositories. As a result, it was observed that the tool generated clusters with satisfactory results and can be used as an auxiliary instrument by experts during the migration process from monolithic architecture to microservices.},
  doi       = {10.1145/3483899.3483908},
  isbn      = {9781450384193},
  keywords  = {monolithic application, microservices, decomposition},
  location  = {Joinville, Brazil},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3483899.3483908},
}

@InProceedings{Pearce2023,
  author    = {Pearce, Glen and Pflaum, Alexis and Balasoiu, Dumitru Alin and Szabo, Claudia},
  booktitle = {Proceedings of the Winter Simulation Conference},
  title     = {Jeopardy Assessment for Dynamic Configuration of Collaborative Microservice Architectures},
  year      = {2023},
  address   = {Singapore, Singapore},
  pages     = {2070–2081},
  publisher = {IEEE Press},
  series    = {WSC '22},
  abstract  = {Microservice architectures, which are lightweight, flexible, and adapt easily to changes, have recently been considered for system development in military operations in contested and dynamic environments. However, in a military setting, the dynamic configuration of collaborative microservices execution becomes critical, and testing that microservice configurations behave as expected becomes paramount. In this paper, we propose a complex jeopardy metric and reconfiguration process that dynamically configures collaborative algorithms running on multiple nodes. Our metric and proposed scenarios will allow for the automated evaluation of microservice configurations and their re-configuration to suit operational needs. We evaluate our proposed scenario, metric, and various reconfiguration algorithms to show the benefits of this approach.},
  numpages  = {12},
}

@Article{Zdun2023,
  author     = {Zdun, Uwe and Queval, Pierre-Jean and Simhandl, Georg and Scandariato, Riccardo and Chakravarty, Somik and Jelic, Marjan and Jovanovic, Aleksandar},
  journal    = {ACM Trans. Softw. Eng. Methodol.},
  title      = {Microservice Security Metrics for Secure Communication, Identity Management, and Observability},
  year       = {2023},
  issn       = {1049-331X},
  month      = {feb},
  number     = {1},
  volume     = {32},
  abstract   = {Microservice architectures are increasingly being used to develop application systems. Despite many guidelines and best practices being published, architecting microservice systems for security is challenging. Reasons are the size and complexity of microservice systems, their polyglot nature, and the demand for the continuous evolution of these systems. In this context, to manually validate that security architecture tactics are employed as intended throughout the system is a time-consuming and error-prone task. In this article, we present an approach to avoid such manual validation before each continuous evolution step in a microservice system, which we demonstrate using three widely used categories of security tactics: secure communication, identity management, and observability. Our approach is based on a review of existing security guidelines, the gray literature, and the scientific literature, from which we derived Architectural Design Decisions (ADDs) with the found security tactics as decision options. In our approach, we propose novel detectors to detect these decision options automatically and formally defined metrics to measure the conformance of a system to the different options of the ADDs. We apply the approach to a case study data set of 10 open source microservice systems, plus another 20 variants of these systems, for which we manually inspected the source code for security tactics. We demonstrate and assess the validity and appropriateness of our metrics by performing an assessment of their conformance to the ADDs in our systems’ dataset through statistical methods.},
  address    = {New York, NY, USA},
  articleno  = {16},
  doi        = {10.1145/3532183},
  issue_date = {January 2023},
  keywords   = {microservice security, software architecture metrics, software architecture detectors, Microservice architecture},
  numpages   = {34},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3532183},
}

@InProceedings{Baarzi2021,
  author    = {Baarzi, Ataollah Fatahi and Kesidis, George},
  booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
  title     = {SHOWAR: Right-Sizing And Efficient Scheduling of Microservices},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {427–441},
  publisher = {Association for Computing Machinery},
  series    = {SoCC '21},
  abstract  = {Microservices architecture have been widely adopted in designing distributed cloud applications where the application is decoupled into multiple small components (i.e. "microservices"). One of the challenges in deploying microservices is finding the optimal amount of resources (i.e. size) and the number of instances (i.e. replicas) for each microservice in order to maintain a good performance as well as prevent resource wastage and under-utilization which is not cost-effective. This paper presents SHOWAR, a framework that configures the resources by determining the number of replicas (horizontal scaling) and the amount of CPU and Memory for each microservice (vertical scaling). For vertical scaling, SHOWAR uses empirical variance in the historical resource usage to find the optimal size and mitigate resource wastage. For horizontal scaling, SHOWAR uses basic ideas from control theory along with kernel level performance metrics. Additionally, once the size for each microservice is found, SHOWAR bridges the gap between optimal resource allocation and scheduling by generating affinity rules (i.e. hints) for the scheduler to further improve the performance. Our experiments, using a variety of microservice applications and real-world workloads, show that, compared to the state-of-the-art autoscaling and scheduling systems, SHOWAR on average improves the resource allocation by up to 22\% while improving the 99th percentile end-to-end user request latency by 20\%.},
  doi       = {10.1145/3472883.3486999},
  isbn      = {9781450386388},
  keywords  = {autoscaling, cloud computing, microservices},
  location  = {Seattle, WA, USA},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3472883.3486999},
}

@InProceedings{Luo2021a,
  author    = {Luo, Shutian and Xu, Huanle and Lu, Chengzhi and Ye, Kejiang and Xu, Guoyao and Zhang, Liping and Ding, Yu and He, Jian and Xu, Chengzhong},
  booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
  title     = {Characterizing Microservice Dependency and Performance: Alibaba Trace Analysis},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {412–426},
  publisher = {Association for Computing Machinery},
  series    = {SoCC '21},
  abstract  = {Loosely-coupled and light-weight microservices running in containers are replacing monolithic applications gradually. Understanding the characteristics of microservices is critical to make good use of microservice architectures. However, there is no comprehensive study about microservice and its related systems in production environments so far. In this paper, we present a solid analysis of large-scale deployments of microservices at Alibaba clusters. Our study focuses on the characterization of microservice dependency as well as its runtime performance. We conduct an in-depth anatomy of microservice call graphs to quantify the difference between them and traditional DAGs of data-parallel jobs. In particular, we observe that microservice call graphs are heavy-tail distributed and their topology is similar to a tree and moreover, many microservices are hot-spots. We reveal three types of meaningful call dependency that can be utilized to optimize microservice designs. Our investigation on microservice runtime performance indicates most microservices are much more sensitive to CPU interference than memory interference. To synthesize more representative microservice traces, we build a mathematical model to simulate call graphs. Experimental results demonstrate our model can well preserve those graph properties observed from Alibaba traces.},
  doi       = {10.1145/3472883.3487003},
  isbn      = {9781450386388},
  location  = {Seattle, WA, USA},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3472883.3487003},
}

@Article{Camilli2023,
  author     = {Camilli, Matteo and Colarusso, Carmine and Russo, Barbara and Zimeo, Eugenio},
  journal    = {ACM Trans. Softw. Eng. Methodol.},
  title      = {Actor-Driven Decomposition of Microservices through Multi-Level Scalability Assessment},
  year       = {2023},
  issn       = {1049-331X},
  month      = {jul},
  number     = {5},
  volume     = {32},
  abstract   = {The microservices architectural style has gained widespread acceptance. However, designing applications according to this style is still challenging. Common difficulties concern finding clear boundaries that guide decomposition while ensuring performance and scalability. With the aim of providing software architects and engineers with a systematic methodology, we introduce a novel actor-driven decomposition strategy to complement the domain-driven design and overcome some of its limitations by reaching a finer modularization yet enforcing performance and scalability improvements. The methodology uses a multi-level scalability assessment framework that supports decision-making over iterative steps. At each iteration, architecture alternatives are quantitatively evaluated at multiple granularity levels. The assessment helps architects to understand the extent to which architecture alternatives increase or decrease performance and scalability. We applied the methodology to drive further decomposition of the core microservices of a real data-intensive smart mobility application and an existing open-source benchmark in the e-commerce domain. The results of an in-depth evaluation show that the approach can effectively support engineers in (i) decomposing monoliths or coarse-grained microservices into more scalable microservices and (ii) comparing among alternative architectures to guide decision-making for their deployment in modern infrastructures that orchestrate lightweight virtualized execution units.},
  address    = {New York, NY, USA},
  articleno  = {117},
  doi        = {10.1145/3583563},
  issue_date = {September 2023},
  keywords   = {performance analysis, scalability assessment, architectural patterns, decomposition process, Microservices},
  numpages   = {46},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3583563},
}

@InProceedings{ArcelliFontana2023,
  author    = {Arcelli Fontana, Francesca and Camilli, Mateo and Rendina, Davide and Taraboi, Andrei Gabriel and Trubiani, Catia},
  booktitle = {Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering},
  title     = {Impact of Architectural Smells on Software Performance: An Exploratory Study},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {22–31},
  publisher = {Association for Computing Machinery},
  series    = {EASE '23},
  abstract  = {Architectural smells have been studied in the literature looking at several aspects, such as their impact on maintainability as a source of architectural debt, their correlations with code smells, and their evolution in the history of complex projects. The goal of this paper is to extend the study of architectural smells from a different perspective. We focus our attention on software performance, and we aim to quantify the impact of architectural smells as support to explain the root causes of system performance hindrances. Our method consists of a study design matching the occurrence of architectural smells with performance metrics. We exploit state-of-the-art tools for architectural smell detection, software performance profiling, and testing the systems under analysis. The removal of architectural smells generates new versions of systems from which we derive some observations on design changes improving/worsening performance metrics. Our experimentation considers two complex open-source projects, and results show that the detection and removal of two common types of architectural smells yield lower response time (up to ) with a large effect size, i.e., for - of the hotspot methods. The median memory consumption is also lower (up to ) with a large effect size for all the services.},
  doi       = {10.1145/3593434.3593442},
  isbn      = {9798400700446},
  keywords  = {Software Architecture, Software Performance, Architectural Smells},
  location  = {Oulu, Finland},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3593434.3593442},
}

@InProceedings{Quin2022,
  author    = {Quin, Federico and Weyns, Danny},
  booktitle = {Proceedings of the 17th Symposium on Software Engineering for Adaptive and Self-Managing Systems},
  title     = {SEAByTE: A Self-Adaptive Micro-Service System Artifact for Automating A/B Testing},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {77–83},
  publisher = {Association for Computing Machinery},
  series    = {SEAMS '22},
  abstract  = {Micro-services are a common architectural approach to software development today. An indispensable tool for evolving micro-service systems is A/B testing. In A/B testing, two variants, A and B, are applied in an experimental setting. By measuring the outcome of an evaluation criterion, developers can make evidence-based decisions to guide the evolution of their software. Recent studies highlight the need for enhancing the automation when such experiments are conducted in iterations. To that end, we contribute a novel artifact that aims at enhancing the automation of an experimentation pipeline of a micro-service system relying on the principles of self-adaptation. Concretely, we propose SEAByTE, an experimental framework for testing novel self-adaptation solutions to enhance the automation of continuous A/B testing of a micro-service based system. We illustrate the use of the SEAByTE artifact with a concrete example.},
  doi       = {10.1145/3524844.3528081},
  isbn      = {9781450393058},
  location  = {Pittsburgh, Pennsylvania},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3524844.3528081},
}

@Article{Herbst2018,
  author     = {Herbst, Nikolas and Bauer, Andr\'{e} and Kounev, Samuel and Oikonomou, Giorgos and Eyk, Erwin Van and Kousiouris, George and Evangelinou, Athanasia and Krebs, Rouven and Brecht, Tim and Abad, Cristina L. and Iosup, Alexandru},
  journal    = {ACM Trans. Model. Perform. Eval. Comput. Syst.},
  title      = {Quantifying Cloud Performance and Dependability: Taxonomy, Metric Design, and Emerging Challenges},
  year       = {2018},
  issn       = {2376-3639},
  month      = {aug},
  number     = {4},
  volume     = {3},
  abstract   = {In only a decade, cloud computing has emerged from a pursuit for a service-driven information and communication technology (ICT), becoming a significant fraction of the ICT market. Responding to the growth of the market, many alternative cloud services and their underlying systems are currently vying for the attention of cloud users and providers. To make informed choices between competing cloud service providers, permit the cost-benefit analysis of cloud-based systems, and enable system DevOps to evaluate and tune the performance of these complex ecosystems, appropriate performance metrics, benchmarks, tools, and methodologies are necessary. This requires re-examining old system properties and considering new system properties, possibly leading to the re-design of classic benchmarking metrics such as expressing performance as throughput and latency (response time). In this work, we address these requirements by focusing on four system properties: (i) elasticity of the cloud service, to accommodate large variations in the amount of service requested, (ii)&nbsp;performance isolation between the tenants of shared cloud systems and resulting performance variability, (iii)&nbsp;availability of cloud services and systems, and (iv) the operational risk of running a production system in a cloud environment. Focusing on key metrics for each of these properties, we review the state-of-the-art, then select or propose new metrics together with measurement approaches. We see the presented metrics as a foundation toward upcoming, future industry-standard cloud benchmarks.},
  address    = {New York, NY, USA},
  articleno  = {19},
  doi        = {10.1145/3236332},
  issue_date = {December 2018},
  keywords   = {Metrics, cloud, performance variability, performance isolation, elasticity, benchmarking, availability, operational risk},
  numpages   = {36},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3236332},
}

@InProceedings{Evangelidis2017,
  author    = {Evangelidis, Alexandros and Parker, David and Bahsoon, Rami},
  booktitle = {Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
  title     = {Performance Modelling and Verification of Cloud-Based Auto-Scaling Policies},
  year      = {2017},
  address   = {Madrid, Spain},
  pages     = {355–364},
  publisher = {IEEE Press},
  series    = {CCGrid '17},
  abstract  = {Auto-scaling, a key property of cloud computing, allows application owners to acquire and release resources on demand. However, the shared environment, along with the exponentially large configuration space of available parameters, makes configuration of auto-scaling policies a challenging task. In particular, it is difficult to quantify, a priori, the impact of a policy on Quality of Service (QoS) provision. To address this problem, we propose a novel approach based on performance modelling and formal verification to produce performance guarantees on particular rule-based auto-scaling policies. We demonstrate the usefulness and efficiency of our model through a detailed validation process on the Amazon EC2 cloud, using two types of load patterns. Our experimental results show that it can be very effective in helping a cloud application owner configure an auto-scaling policy in order to minimise the QoS violations.},
  doi       = {10.1109/CCGRID.2017.39},
  isbn      = {9781509066100},
  numpages  = {10},
  url       = {https://doi.org/10.1109/CCGRID.2017.39},
}

@InProceedings{Wang2015b,
  author    = {Wang, Hui and Isci, Canturk and Subramanian, Lavanya and Choi, Jongmoo and Qian, Depei and Mutlu, Onur},
  booktitle = {Proceedings of the 11th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments},
  title     = {A-DRM: Architecture-Aware Distributed Resource Management of Virtualized Clusters},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {93–106},
  publisher = {Association for Computing Machinery},
  series    = {VEE '15},
  abstract  = {Virtualization technologies has been widely adopted by large-scale cloud computing platforms. These virtualized systems employ distributed resource management (DRM) to achieve high resource utilization and energy savings by dynamically migrating and consolidating virtual machines. DRM schemes usually use operating-system-level metrics, such as CPU utilization, memory capacity demand and I/O utilization, to detect and balance resource contention. However, they are oblivious to microarchitecture-level resource interference (e.g., memory bandwidth contention between different VMs running on a host), which is currently not exposed to the operating system.We observe that the lack of visibility into microarchitecture-level resource interference significantly impacts the performance of virtualized systems. Motivated by this observation, we propose a novel architecture-aware DRM scheme (ADRM), that takes into account microarchitecture-level resource interference when making migration decisions in a virtualized cluster. ADRM makes use of three core techniques: 1) a profiler to monitor the microarchitecture-level resource usage behavior online for each physical host, 2) a memory bandwidth interference model to assess the interference degree among virtual machines on a host, and 3) a cost-benefit analysis to determine a candidate virtual machine and a host for migration.Real system experiments on thirty randomly selected combinations of applications from the CPU2006, PARSEC, STREAM, NAS Parallel Benchmark suites in a four-host virtualized cluster show that ADRM can improve performance by up to 26.55\%, with an average of 9.67\%, compared to traditional DRM schemes that lack visibility into microarchitecture-level resource utilization and contention.},
  doi       = {10.1145/2731186.2731202},
  isbn      = {9781450334501},
  keywords  = {virtualization, microarchitecture, resource management, live migration, performance counters},
  location  = {Istanbul, Turkey},
  numpages  = {14},
  url       = {https://doi.org/10.1145/2731186.2731202},
}

@InProceedings{Roloff2017,
  author    = {Roloff, Eduardo and Diener, Matthias and Carre\~{n}o, Emmanuell D. and Moreira, Francis B. and Gaspary, Luciano P. and Navaux, Philippe O.A.},
  booktitle = {Companion Proceedings of The10th International Conference on Utility and Cloud Computing},
  title     = {Exploiting Price and Performance Tradeoffs in Heterogeneous Clouds},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {71–76},
  publisher = {Association for Computing Machinery},
  series    = {UCC '17 Companion},
  abstract  = {Parallel applications are composed of several tasks, which have different computational demands among them. Moreover, most cloud providers offer multiple instance configurations, with large variations of computational power and cost. A combination between the application requirements and the variety of instance types of the cloud could be explored to improve the cost efficiency of the application execution. In this paper, we introduce the cost-delay product as a metric to measure the cost efficiency of cloud systems. With this metric, cloud tenants can evaluate different tradeoffs between cost and performance for their application, depending on their preferences. We explore the use of multiple instance types to create heterogeneous cluster systems in the cloud. Our results show that heterogeneous clouds can have a better cost efficiency than homogeneous systems, reducing the price of execution while maintaining a similar application performance. Furthermore, by comparing the cost-delay product, the user can select an instance mix that is most suitable for his needs.},
  doi       = {10.1145/3147234.3148103},
  isbn      = {9781450351959},
  keywords  = {cost efficiency, cloud computing, performance, heterogeneity},
  location  = {Austin, Texas, USA},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3147234.3148103},
}

@InProceedings{Sastri2017,
  author    = {Sastri, Yedhu and Feldhoff, Kim and Starru\ss{}, J\"{o}rn and J\"{a}kel, Ren\'{e} and M\"{u}ller-Pfefferkorn, Ralph},
  booktitle = {Proceedings of the 2017 International Conference on Cloud and Big Data Computing},
  title     = {A Workflow for the Integral Performance Analysis of Cloud Applications Using Monitoring and Tracing Techniques},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {73–78},
  publisher = {Association for Computing Machinery},
  series    = {ICCBDC '17},
  abstract  = {Considering the cost effectiveness, elasticity, and flexibility of virtualized cloud environments, porting HPC applications to those environments and executing them within these settings is becoming more and more popular. For this purpose, traditional HPC applications have to be redesigned as cloud applications. An analysis of the performance of the redesigned applications within the cloud environment is in-dispensable, if the applications should be efficiently executed in the cloud environment.This paper proposes a workflow for the integral performance analysis of cloud applications within a cloud environment using monitoring and tracing techniques. For this, collectd acts as a lightweight monitoring daemon for recording performance data from outside of the applications, Score-P as a profiling and tracing tool for recording the performance data from the inside. Thus, this workflow will help in answering the question "How and why an application behaves like this within the cloud environment?".In order to show the usability of the proposed workflow, a parallel client server application was selected and adapted for the execution in a private OpenStack cloud. Performance measurements of the example running in the cloud environment could be successfully done according to the proposed workflow. In particular, performance metrics from both the outside and the inside of the application could be obtained to analyze and evaluate the performance of the application in detail.},
  doi       = {10.1145/3141128.3141132},
  isbn      = {9781450353434},
  keywords  = {Docker, Score-P, Container, Performance analysis, Micro services, Workflow, Tracing, Cloud application, Monitoring, collectd},
  location  = {London, United Kingdom},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3141128.3141132},
}

@Article{Willnecker2018,
  author     = {Willnecker, Felix and Krcmar, Helmut},
  journal    = {ACM Trans. Internet Technol.},
  title      = {Multi-Objective Optimization of Deployment Topologies for Distributed Applications},
  year       = {2018},
  issn       = {1533-5399},
  month      = {jan},
  number     = {2},
  volume     = {18},
  abstract   = {Modern applications are typically implemented as distributed systems comprising several components. Deciding where to deploy which component is a difficult task that today is usually assisted by logical topology recommendations. Choosing inefficient topologies allocates the wrong amount of resources, leads to unnecessary operation costs, or results in poor performance. Testing different topologies to find good solutions takes a lot of time and might delay productive operations. Therefore, this work introduces a software-based deployment topology optimization approach for distributed applications. We use an enhanced performance model generator that extracts models from operational monitoring data of running applications. The extracted model is used to simulate performance metrics (e.g., resource utilization, response times, throughput) and runtime costs of distributed applications. Subsequently, we introduce a deployment topology optimizer, which selects an optimized topology for a specified workload and considers on-premise, cloud, and hybrid topologies. The following three optimization goals are presented in this work: (i) minimum response time for an optimized user experience, (ii) approximate resource utilization around certain peaks, and (iii) minimum cost for running the application. To evaluate the approach, we use the SPECjEnterpriseNEXT industry benchmark as distributed application in an on-premise and in a cloud/on-premise hybrid environment. The evaluation demonstrates the accuracy of the simulation compared to the actual deployment by deploying an optimized topology and comparing measurements with simulation results.},
  address    = {New York, NY, USA},
  articleno  = {21},
  doi        = {10.1145/3106158},
  issue_date = {May 2018},
  keywords   = {performance model, performance model generation, Deployment topology optimzation, distributed enterprise applications, memory simulation},
  numpages   = {21},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3106158},
}

@InProceedings{Chow2017,
  author    = {Chow, Kingsum and Zhu, Wanyi},
  booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering},
  title     = {Software Performance Analytics in the Cloud},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {419–421},
  publisher = {Association for Computing Machinery},
  series    = {ICPE '17},
  abstract  = {The emergence of large-scale software deployments in the cloud has led to several challenges: (1) measuring software performance in the data center, and (2) optimizing software for resource management. This tutorial addresses the two challenges by bringing the knowledge of software performance monitoring in the data center to the world of applying performance analytics. It introduces data transformations for software performance metrics. The transformations enable effective applications of analytics. This tutorial starts with software performance in the small and ends with applying analytics to software performance in the large. In software performance in the small, it summarizes performance tools, data collection and manual analysis. Then it describes monitoring tools that are helpful in performance analysis in the large. The tutorial will guide the audience in applying analytics to performance data obtained by common tools. This tutorial describes how to select analytical methods and what precautions should be taken to get effective results.},
  doi       = {10.1145/3030207.3053676},
  isbn      = {9781450344043},
  keywords  = {analytics, datacenter efficiency, software performance, capacity planning},
  location  = {L'Aquila, Italy},
  numpages  = {3},
  url       = {https://doi.org/10.1145/3030207.3053676},
}

@InProceedings{Davatz2017,
  author    = {Davatz, Christian and Inzinger, Christian and Scheuner, Joel and Leitner, Philipp},
  booktitle = {Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
  title     = {An Approach and Case Study of Cloud Instance Type Selection for Multi-Tier Web Applications},
  year      = {2017},
  address   = {Madrid, Spain},
  pages     = {534–543},
  publisher = {IEEE Press},
  series    = {CCGrid '17},
  abstract  = {A challenging problem for users of Infrastructure-as-a-Service (IaaS) clouds is selecting cloud providers, regions, and instance types cost-optimally for a given desired service level. Issues such as hardware heterogeneity, contention, and virtual machine (VM) placement can result in considerably differing performance across supposedly equivalent cloud resources. Existing research on cloud benchmarking helps, but often the focus is on providing low-level microbenchmarks (e.g., CPU or network speed), which are hard to map to concrete business metrics of enterprise cloud applications, such as request throughput of a multi-tier Web application. In this paper, we propose Okta, a general approach for fairly and comprehensively benchmarking the performance and cost of a multi-tier Web application hosted in an IaaS cloud. We exemplify our approach for a case study based on the two-tier AcmeAir application, which we evaluate for 11 real-life deployment configurations on Amazon EC2 and Google Compute Engine. Our results show that for this application, choosing compute-optimized instance types in the Web layer and small bursting instances for the database tier leads to the overall most cost-effective deployments. This result held true for both cloud providers. The least cost-effective configuration in our study provides only about 67\% of throughput per US dollar spent. Our case study can serve as a blueprint for future industrial or academic application benchmarking projects.},
  doi       = {10.1109/CCGRID.2017.12},
  isbn      = {9781509066100},
  numpages  = {10},
  url       = {https://doi.org/10.1109/CCGRID.2017.12},
}

@InProceedings{Liu2019b,
  author    = {Liu, Yang and Xu, Huanle and Lau, Wing Cheong},
  booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
  title     = {Accordia: Adaptive Cloud Configuration Optimization for Recurring Data-Intensive Applications},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {479},
  publisher = {Association for Computing Machinery},
  series    = {SoCC '19},
  abstract  = {Recognizing the diversity of big data analytic jobs, cloud providers offer a wide range of virtual machine (VM) instances for different use cases. The choice of cloud instance configurations can have significant impact on the response time and running cost of data-intensive, recurring jobs for production. A poor choice of cloud instance-type/configuration can substantially degrade the response time by 5x, or increase the cost by 10x. Identifying the best cloud configuration under low search budget is a challenging problem due to i) the large and high-dimensional configuration-parameters space, ii) the dynamically varying price of some instance types, iii) job response time variation even given the same configuration, and iv) gradual drifts/ unexpected changes of the characteristics of the recurring jobs. To tackle this problem, we have designed and implemented Accordia, a system which enables Adaptive Cloud Configuration Optimization for Recurring Data-Intensive Applications.Accordia extends the Gaussian-Process Upper Confidence Bound (GP-UCB) approach in [3] to search for and track the potentially dynamic optimal cloud configuration within a high-dimensional para-meter-space. Unlike other state-of-the-art schemes, such as CherryPick[1] and Arrow[2], Accordia can handle time-varying instance pricing while providing a performance guarantee of sub-linear regret when comparing with the static, offline optimial solution.Figure 1 depicts the system architecture of our implementation of Accordia for Apache Spark running over Kubernetes. When a job is submitted, a Spark driver and multiple Spark executors are deployed as containers, each within its own Kubernetes pod. Accordia then dynamically adjusts the resource types/ allocation for the containers within their respective pods to minimize the job completion cost using the GP-UCB online-learning approach.To evaluate the performance of Accordia, we have run different mixes of recurring Spark jobs over the Google public cloud. In our experiments, Accordia dynamically learns the best cloud configuration from over 7000 candidate choices within a 5-dimensional parameter space, covering the number of executors, as well as the number of CPU cores and memory (RAM) allocation for the driver and the executor pods. Empirical measurements show that Accordia can find a near-cost-optimal configuration for a recurring job (i.e. within 10\% of the optimal cost) with fewer than 20 runs, which translates to a 2X-speedup and a 20.9\% cost-savings, when comparing to CherryPick. To highlight Accordia's capability to handle abrupt/unexpected changes of the characteristics of a recurring job, we even dynamically switch the type of a recurring job (without notifying Accordia) over exponentially-distributed time-intervals. Under such cases, Accordia can still achieve on average a cost-savings of 18.4\% over CherryPick. The full technical report is available at http://mobitec.ie.cuhk.edu.hk/cloudComputing/Accordia.pdf.},
  doi       = {10.1145/3357223.3365441},
  isbn      = {9781450369732},
  keywords  = {Cloud configuration, Big data analytics, Kubernetes, Gaussian-Process UCB},
  location  = {Santa Cruz, CA, USA},
  numpages  = {1},
  url       = {https://doi.org/10.1145/3357223.3365441},
}

@InProceedings{Bersani2014,
  author    = {Bersani, Marcello M. and Bianculli, Domenico and Dustdar, Schahram and Gambi, Alessio and Ghezzi, Carlo and Krsti\'{c}, Sr\textcrd{}an},
  booktitle = {Proceedings of the 6th International Workshop on Principles of Engineering Service-Oriented and Cloud Systems},
  title     = {Towards the Formalization of Properties of Cloud-Based Elastic Systems},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {38–47},
  publisher = {Association for Computing Machinery},
  series    = {PESOS 2014},
  abstract  = {Cloud-based elastic systems run on a cloud infrastructure and have the capability of dynamically adjusting the allocation of their resources in response to changes in the workload, in a way that balances the trade-off between the desired quality-of-service and the operational costs. The actual elastic behavior of these systems is determined by a combination of factors, including the input workload, the logic of the elastic controller determining the type of resource adjustment, and the underlying technological platform implementing the cloud infrastructure. All these factors have to be taken into account to express the desired elastic behavior of a system, as well as to verify whether the system manifests or not such a behavior.  In this paper, we take a first step into these directions, by proposing a formalization, based on the CLTL^t(D) temporal logic, of several concepts and properties related to the behavior of cloud-based elastic systems. We also report on our preliminary evaluation of the feasibility to check the (formalized) properties on execution traces using an automated verification tool.},
  doi       = {10.1145/2593793.2593798},
  isbn      = {9781450328418},
  keywords  = {elastic systems, temporal logic, Cloud computing},
  location  = {Hyderabad, India},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2593793.2593798},
}

@Article{Seeger2020,
  author     = {Seeger, Jan and Br\"{o}ring, Arne and Carle, Georg},
  journal    = {ACM Trans. Internet Technol.},
  title      = {Optimally Self-Healing IoT Choreographies},
  year       = {2020},
  issn       = {1533-5399},
  month      = {jul},
  number     = {3},
  volume     = {20},
  abstract   = {In the industrial Internet of Things domain, applications are moving from the Cloud into the Edge, closer to the devices producing and consuming data. This means that applications move from the scalable and homogeneous Cloud environment into a potentially constrained heterogeneous Edge network. Making Edge applications reliable enough to fulfill Industry 4.0 use cases remains an open research challenge. Maintaining operation of an Edge system requires advanced management techniques to mitigate the failure of devices. This article tackles this challenge with a twofold approach: (1) a policy-enabled failure detector that enables adaptable failure detection and (2) an allocation component for the efficient selection of failure mitigation actions. The parameters and performance of the failure detection approach are evaluated, and the performance of an energy-efficient allocation technique is measured. Finally, a vision for a complete system and an example use case are presented.},
  address    = {New York, NY, USA},
  articleno  = {27},
  doi        = {10.1145/3386361},
  issue_date = {August 2020},
  keywords   = {optimization, IOT, failure detection},
  numpages   = {20},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3386361},
}

@InProceedings{Andrade2023,
  author    = {Andrade, \'{A}lan J\'{u}nior da Cruz and Veloso, Ednilson and Santos, Gleison},
  booktitle = {Proceedings of the XXII Brazilian Symposium on Software Quality},
  title     = {What We Know About Software Dependability in DevOps - A Tertiary Study},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {178–187},
  publisher = {Association for Computing Machinery},
  series    = {SBQS '23},
  abstract  = {Background: DevOps is viewed as an alternative approach to achieving high-quality software products. Dependability is recognized as a crucial aspect of software product quality. Existing literature highlights the lack of established standards, models, or methods for evaluating product quality within the DevOps paradigm. This emphasizes the need for further research to investigate the impact of DevOps on software quality attributes, particularly in relation to dependability.Objective: Our objective is to evaluate the scope of research on dependability in DevOps and identify what is known about this context by relating DevOps practices with dependability attributes. Method: We conducted a tertiary study to enhance the understanding of dependability in the context of DevOps. Results: We found 13 secondary studies that address dependability in DevOps. Within these studies, we identified 16 DevOps practices that have an impact on dependability and 12 attributes that are affected by DevOps practices. Additionally, we identified 6 measures related to dependability in the context of DevOps. Among the DevOps practices, the most commonly reported ones that impact dependability are Automation Practices, including deployment, testing, and infrastructure automation, as well as Cloud Computing Implementation. Conclusions: The results show that DevOps practices contribute to improve software dependability, mainly due to the impacts of these practices on dependability attributes. However, even though the literature reports some measures related to dependability, there is still a gap in understanding how organizations can assess dependability in DevOps.},
  doi       = {10.1145/3629479.3629502},
  isbn      = {9798400707865},
  keywords  = {Dependability, Software Product Quality, DevOps},
  location  = {<conf-loc>, <city>Bras\'{\i}lia</city>, <country>Brazil</country>, </conf-loc>},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3629479.3629502},
}

@Article{Pan2023,
  author     = {Pan, Zhicheng and Wang, Yihang and Zhang, Yingying and Yang, Sean Bin and Cheng, Yunyao and Chen, Peng and Guo, Chenjuan and Wen, Qingsong and Tian, Xiduo and Dou, Yunliang and Zhou, Zhiqiang and Yang, Chengcheng and Zhou, Aoying and Yang, Bin},
  journal    = {Proc. VLDB Endow.},
  title      = {MagicScaler: Uncertainty-Aware, Predictive Autoscaling},
  year       = {2023},
  issn       = {2150-8097},
  month      = {aug},
  number     = {12},
  pages      = {3808–3821},
  volume     = {16},
  abstract   = {Predictive autoscaling is a key enabler for optimizing cloud resource allocation in Alibaba Cloud's computing platforms, which dynamically adjust the Elastic Compute Service (ECS) instances based on predicted user demands to ensure Quality of Service (QoS). However, user demands in the cloud are often highly complex, with high uncertainty and scale-sensitive temporal dependencies, thus posing great challenges for accurate prediction of future demands. These in turn make autoscaling challenging---autoscaling needs to properly account for demand uncertainty while maintaining a reasonable trade-off between two contradictory factors, i.e., low instance running costs vs. low QoS violation risks.To address the above challenges, we propose a novel predictive autoscaling framework MagicScaler, consisting of a Multi-scale attentive Gaussian process based predictor and an uncertainty-aware scaler. First, the predictor carefully bridges the best of two successful prediction methodologies---multi-scale attention mechanisms, which are good at capturing complex, multi-scale features, and stochastic process regression, which can quantify prediction uncertainty, thus achieving accurate demand prediction with quantified uncertainty. Second, the scaler takes the quantified future demand uncertainty into a judiciously designed loss function with stochastic constraints, enabling flexible trade-off between running costs and QoS violation risks. Extensive experiments on three clusters of Alibaba Cloud in different Chinese cities demonstrate the effectiveness and efficiency of MagicScaler, which outperforms other commonly adopted scalers, thus justifying our design choices.},
  doi        = {10.14778/3611540.3611566},
  issue_date = {August 2023},
  numpages   = {14},
  publisher  = {VLDB Endowment},
  url        = {https://doi.org/10.14778/3611540.3611566},
}

@InProceedings{Dang2021,
  author    = {Dang, The Khang and Mohan, Nitinder and Corneo, Lorenzo and Zavodovski, Aleksandr and Ott, J\"{o}rg and Kangasharju, Jussi},
  booktitle = {Proceedings of the 21st ACM Internet Measurement Conference},
  title     = {Cloudy with a Chance of Short RTTs: Analyzing Cloud Connectivity in the Internet},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {62–79},
  publisher = {Association for Computing Machinery},
  series    = {IMC '21},
  abstract  = {Cloud computing has seen continuous growth over the last decade. The recent rise in popularity of next-generation applications brings forth the question: "Can current cloud infrastructure support the low latency requirements of such apps?" Specifically, the interplay of wireless last-mile and investments of cloud operators in setting up direct peering agreements with ISPs globally to current cloud reachability and latency has remained largely unexplored.This paper investigates the state of end-user to cloud connectivity over wireless media through extensive measurements over six months. We leverage 115,000 wireless probes on the Speed-checker platform and 195 cloud regions from 9 well-established cloud providers. We evaluate the suitability of current cloud infrastructure to meet the needs of emerging applications and highlight various hindering pressure points. We also compare our results to a previous study over RIPE Atlas. Our key findings are: (i) the most impact on latency comes from the geographical distance to the datacenter; (ii) the choice of a measurement platform can significantly influence the results; (iii) wireless last-mile access contributes significantly to the overall latency, almost surpassing the impact of the geographical distance in many cases. We also observe that cloud providers with their own private network backbone and direct peering agreements with serving ISPs offer noticeable improvements in latency, especially in its consistency over longer distances.},
  doi       = {10.1145/3487552.3487854},
  isbn      = {9781450391290},
  keywords  = {cloud connectivity, edge computing, peering, last-mile latency},
  location  = {Virtual Event},
  numpages  = {18},
  url       = {https://doi.org/10.1145/3487552.3487854},
}

@InProceedings{Mok2021,
  author    = {Mok, Ricky K. P. and Zou, Hongyu and Yang, Rui and Koch, Tom and Katz-Bassett, Ethan and Claffy, K C},
  booktitle = {Proceedings of the 21st ACM Internet Measurement Conference},
  title     = {Measuring the Network Performance of Google Cloud Platform},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {54–61},
  publisher = {Association for Computing Machinery},
  series    = {IMC '21},
  abstract  = {Public cloud platforms are vital in supporting online applications for remote learning and telecommuting during the COVID-19 pandemic. The network performance between cloud regions and access networks directly impacts application performance and users' quality of experience (QoE). However, the location and network connectivity of vantage points often limits the visibility of edge-based measurement platforms (e.g., RIPE Atlas).We designed and implemented the CLoud-based Applications Speed Platform (CLASP) to measure performance to various networks from virtual machines in cloud regions with speed test servers that have been widely deployed on the Internet. In our five-month longitudinal measurements in Google Cloud Platform (GCP), we found that 30-70\% of ISPs we measured showed severe throughput degradation from the peak throughput of the day.},
  doi       = {10.1145/3487552.3487862},
  isbn      = {9781450391290},
  keywords  = {cloud networking, network throughput, speed test},
  location  = {Virtual Event},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3487552.3487862},
}

@Article{Duboc2022,
  author     = {Duboc, Leticia and Bahsoon, Rami and Alrebeish, Faisal and Mera-G\'{o}mez, Carlos and Nallur, Vivek and Kazman, Rick and Bianco, Philip and Babar, Ali and Buyya, Rajkumar},
  journal    = {ACM Trans. Auton. Adapt. Syst.},
  title      = {Systematic Scalability Modeling of QoS-Aware Dynamic Service Composition},
  year       = {2022},
  issn       = {1556-4665},
  month      = {nov},
  number     = {3–4},
  volume     = {16},
  abstract   = {In Dynamic Service Composition (DSC), an application can be dynamically composed using web services to achieve its functional and Quality of Services (QoS) goals. DSC is a relatively mature area of research that crosscuts autonomous and services computing. Complex autonomous and self-adaptive computing paradigms (e.g., multi-tenant cloud services, mobile/smart services, services discovery and composition in intelligent environments such as smart cities) have been leveraging DSC to dynamically and adaptively maintain the desired QoS, cost and to stabilize long-lived software systems. While DSC is fundamentally known to be an NP-hard problem, systematic attempts to analyze its scalability have been limited, if not absent, though such analysis is of a paramount importance for their effective, efficient, and stable operations.This article reports on a new application of goal-modeling, providing a systematic technique that can support DSC designers and architects in identifying DSC-relevant characteristics and metrics that can potentially affect the scalability goals of a system. The article then applies the technique to two different approaches for QoS-aware dynamic services composition, where the article describes two detailed exemplars that exemplify its application. The exemplars hope to provide researchers and practitioners with guidance and transferable knowledge in situations where the scalability analysis may not be straightforward. The contributions provide architects and designers for QoS-aware dynamic service composition with the fundamentals for assessing the scalability of their own solutions, along with goal models and a list of application domain characteristics and metrics that might be relevant to other solutions. Our experience has shown that the technique was able to identify in both exemplars application domain characteristics and metrics that had been overlooked in previous scalability analyses of these DSC, some of which indeed limited their scalability. It has also shown that the experiences and knowledge can be transferable: The first exemplar was used as an example to inform and ease the work of applying the technique in the second one, reducing the time to create the model, even for a non-expert.},
  address    = {New York, NY, USA},
  articleno  = {10},
  doi        = {10.1145/3529162},
  issue_date = {December 2021},
  keywords   = {Scalability modelling, autonomous and adaptive systems, dynamic service composition},
  numpages   = {39},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3529162},
}

@InProceedings{Christofidi2023,
  author    = {Christofidi, Georgia and Papaioannou, Konstantinos and Doudali, Thaleia Dimitra},
  booktitle = {Proceedings of the 3rd Workshop on Machine Learning and Systems},
  title     = {Toward Pattern-Based Model Selection for Cloud Resource Forecasting},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {115–122},
  publisher = {Association for Computing Machinery},
  series    = {EuroMLSys '23},
  abstract  = {Cloud resource management solutions, such as autoscaling and overcommitment policies, often leverage robust prediction models to forecast future resource utilization at the task-, job- and machine-level. Such solutions maintain a collection of different models and at decision time select to use the model that provides the best performance, typically minimizing a cost function. In this paper, we explore a more generalizable model selection approach, based on the patterns of resource usage that are common across the tasks of a job. To learn such patterns, we train a collection of Long Short Term Memory (LSTM) neural networks, at the granularity of a job. During inference, we select which model to use to predict the resource usage of a given task via distance-based time series comparisons. Our experimentation with various time series data representations and similarity metrics reveals cases where even sophisticated approaches, such as dynamic time warping, lead to suboptimal model selection and as a result significantly lower prediction accuracy. Our analysis establishes the importance and impact of pattern-based model selection, and discusses relevant challenges, opportunities and future directions based on our findings.},
  doi       = {10.1145/3578356.3592588},
  isbn      = {9798400700842},
  keywords  = {deep neural network, cloud resource forecasting, long short term memory, cloud computing, timeseries comparison, pattern matching, machine learning},
  location  = {Rome, Italy},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3578356.3592588},
}

@Article{Ma2021a,
  author     = {Ma, Richard T. B.},
  journal    = {IEEE/ACM Trans. Netw.},
  title      = {Internet Transport Economics: Model and Analysis},
  year       = {2021},
  issn       = {1063-6692},
  month      = {dec},
  number     = {6},
  pages      = {2843–2854},
  volume     = {29},
  abstract   = {With the rise of video streaming and cloud services, the Internet has evolved into a content-centric service platform. Due to the best-effort service model of the Internet, the quality of service (QoS) of Internet services however cannot be guaranteed. Furthermore, characterizing QoS is challenging since it depends on the autonomous business decisions such as capacity planning, routing strategies and peering agreements of network providers. To quantify the QoS for Internet-based services, we regard the Internet infrastructure as a transport system for data packets and study the Internet ecosystem and the economics of transport services collectively provided by the autonomous network providers. In contrast to the traditional transport economics that studies the movement of people and goods over space and time, our focus in the &lt;italic&gt;Internet transport economics&lt;/italic&gt; is the movement of streams of data packets that create information services. In particular, we model the supply of network capacities and demands of throughput driven by network protocols and establish a macroscopic network equilibrium under which both the end-to-end delays and drop rates of Internet routes can be derived. We show that this equilibrium solution always exists and its uniqueness can be guaranteed under various realistic scenarios. We analyze the impacts of user demands and resource capacities on the network equilibrium and provide implications of Netflix-Comcast type of peering on the QoS of users. We demonstrate that our framework can be used as a building block to understand the routing strategies under a Wardrop equilibrium and to enable further studies such as Internet peering and in-network caching.},
  doi        = {10.1109/TNET.2021.3103796},
  issue_date = {Dec. 2021},
  numpages   = {12},
  publisher  = {IEEE Press},
  url        = {https://doi.org/10.1109/TNET.2021.3103796},
}

@Article{AlDebagy2020,
  author   = {Al-Debagy, O. and Martinek, P.},
  journal  = {Journal of Web Engineering},
  title    = {A Metrics Framework for Evaluating Microservices Architecture Designs},
  year     = {2020},
  issn     = {1544-5976},
  month    = {June},
  number   = {3–4},
  pages    = {341-370},
  volume   = {19},
  abstract = {Microservices are becoming a more popular software architecture among companies and developers. Therefore, there is a need to develop methods for quantifying the process of measuring the quality of microservices design. This paper has created a novel set of metrics for microservices architecture applications. The proposed metrics are the Service Granularity Metric “SGM”, the Lack of Cohesion Metric “LCOM”, and the Number of Operations “NOO”. The proposed metrics measure the granularity, cohesion, and complexity of individual microservices through analyzing the application programming interface “API”. Using these metrics, it is possible to evaluate the overall quality of the design of microservices applications. The proposed metrics were measured on 5 applications with different sizes and business cases. This research found that the value for the SGM metric needs to be between 0.2 and 0.6. Besides, the value of LCOM metric for a microservice needs to be between 0 and 0.8 with less than ten operations per microservice. These findings can be applied in the decomposition process of monolithic applications as well.},
  doi      = {10.13052/jwe1540-9589.19341},
}

@InProceedings{Levin2020,
  author    = {Levin, Joshua and Benson, Theophilus A.},
  booktitle = {2020 IEEE 9th International Conference on Cloud Networking (CloudNet)},
  title     = {ViperProbe: Rethinking Microservice Observability with eBPF},
  year      = {2020},
  month     = {Nov},
  pages     = {1-8},
  abstract  = {Recent shifts to microservice-based architectures and the supporting servicemesh radically disrupt the landscape of performance-oriented management tasks. While the adoption of frameworks like Istio and Kubernetes ease the management and organization of such systems, they do not themselves provide strong observability. Microservice observability requires diverse, highly specialized, and often adaptive, metrics and algorithms to monitor both the health of individual services and the larger application. However, modern metrics collection frameworks are relatively static and rigid. We introduce ViperProbe, an eBPF-based microservices collection framework that provides (1) dynamic sampling and (2) collection of deep, diverse, and precise system metrics. Viper-Probe builds on the observation that the adoption of a common set of design patterns, e.g., servicemesh, enables offline analysis. By examining the performance profile of these patterns before deploying on production, ViperProbe can effectively reduce the set of collected metrics, thereby improving the efficiency and effectiveness of those metrics. To the best of our knowledge, ViperProbe is the first scalable eBPF-based dynamic and adaptive microservices metrics collection framework. Our results show ViperProbe has limited overhead, while significantly more effective for traditional management tasks, e.g., horizontal autoscaling.},
  doi       = {10.1109/CloudNet51028.2020.9335808},
}

@InProceedings{Perera2018,
  author    = {Perera, K. J. P. G. and Perera, I.},
  booktitle = {2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS)},
  title     = {TheArchitect: A Serverless-Microservices Based High-level Architecture Generation Tool},
  year      = {2018},
  month     = {June},
  pages     = {204-210},
  abstract  = {Software is ubiquitous in today's systems and business operations. Most importantly the architecture of a software system determines its quality and longevity, because the development work related to the software system will be carried out to be in line with its architecture design. Hence, it's highly important to structure the high-level software architecture accordingly to deliver the expected customer requirements while accounting for quality measures such as scalability, high availability and high performance. We propose TheArchitect, a serverless-microservices based high-level architecture generation tool, which will auto generate serverless-microservices based high-level architecture for a given business application, preserving the highlighted quality measures providing a tool based support for the software architect with respect to designing the high-level architecture. TheArchitect will provide any software developer to generate a proper architecture minimizing the involvement of an experienced software architect. Furthermore, the positives that microservices and serverless technologies has brought to the world of software engineering has made the software engineering community shift from the era of building large monolith applications containing overly complex designs, to microservices and serverless based technologies. Hence TheArchitect focuses on generating best fitted microservices and serverless based high-level architecture for a given application.},
  doi       = {10.1109/ICIS.2018.8466390},
}

@InProceedings{Perera2018a,
  author    = {Perera, K. J. P. G. and Perera, I.},
  booktitle = {2018 IEEE International Systems Engineering Symposium (ISSE)},
  title     = {A Rule-based System for Automated Generation of Serverless-Microservices Architecture},
  year      = {2018},
  month     = {Oct},
  pages     = {1-8},
  abstract  = {Software being ubiquitous in today's systems and business operations, it's highly important to structure the high-level architecture of a software application accordingly to deliver the expected customer requirements while accounting for quality measures such as scalability, high availability and high performance. We propose The Architect, a rule-based system for serverless-microservices based high-level architecture generation. In the process of auto generating serverless-microservices high-level architecture, TheArchitect will preserve the highlighted quality measures. It will also provide a tool based support for the high-level architecture designing process of the software architect. Any software developer will be able to use TheArchitect to generate a proper architecture minimizing the involvement of a software architect. Furthermore, the positives of microservices and serverless technologies have made a significant impact on the software engineering community in terms of shifting from the era of building large monolith applications containing overly complex designs, to microservices and serverless based technologies. Hence The Architect focuses on generating best fitted microservices and serverless based high-level architecture for a given application.},
  doi       = {10.1109/SysEng.2018.8544423},
}

@InProceedings{Asik2017,
  author    = {Asik, Tugrul and Selcuk, Yunus Emre},
  booktitle = {2017 IEEE 15th International Conference on Software Engineering Research, Management and Applications (SERA)},
  title     = {Policy enforcement upon software based on microservice architecture},
  year      = {2017},
  month     = {June},
  pages     = {283-287},
  abstract  = {Microservice is an architectural style that has recently started gaining popularity to become a new architectural phenomenon. Microservice architecture provides new opportunities to deploy scalable, language free and dynamically adjustable applications. This type of applications consist of hundreds or more of service instances. So that, management, monitoring, refactoring and testing of applications are more complex than monolithic applications. Therefore, some metrics and policies for measuring the quality of an application which is based on microservice architecture is needed. Moreover, automated tools are needed to carry out those tasks and enforce those policies. This work represents such metrics and policies. Additionally, an automated tool is implemented for automatic analysis of those metrics and policies upon software.},
  doi       = {10.1109/SERA.2017.7965739},
}

@InProceedings{Zhang2020b,
  author    = {Zhang, Yukun and Liu, Bo and Dai, Liyun and Chen, Kang and Cao, Xuelian},
  booktitle = {2020 IEEE International Conference on Software Architecture (ICSA)},
  title     = {Automated Microservice Identification in Legacy Systems with Functional and Non-Functional Metrics},
  year      = {2020},
  month     = {March},
  pages     = {135-145},
  abstract  = {Since microservice has merged as a promising architectural style with advantages in maintainability, scalability, evolvability, etc., increasing companies choose to restructure their legacy monolithic software systems as the microservice architecture. However, it is quite a challenge to properly partitioning the systems into suitable parts as microservices. Most approaches perform microservices identification from a function-splitting perspective and with sufficient legacy software artifacts. That may be not realistic in industrial practices and possibly results in generating unexpected microservices. To address this, we proposed an automated microservice identification (AMI) approach that extracts microservices from the execution and performance logs without providing documentation, models or source codes, while taking both functional and non-functional metrics into considerations. Our work firstly collects logs from the executable legacy system. Then, controller objects (COs) are identified as the key objects to converge strongly related subordinate objects (SOs). Subsequently, the relation between each pair of CO and SO is evaluated by a relation matrix from both the functional and non-functional perspective. We ultimately cluster classes(objects) into the microservices by optimizing the multi-objective of high-cohesion-low-coupling and load balance. The usefulness of the proposed approach is illustrated by applying to a case study.},
  doi       = {10.1109/ICSA47634.2020.00021},
}

@InProceedings{Selmadji2020,
  author    = {Selmadji, Anfel and Seriai, Abdelhak-Djamel and Bouziane, Hinde Lilia and Oumarou Mahamane, Rahina and Zaragoza, Pascal and Dony, Christophe},
  booktitle = {2020 IEEE International Conference on Software Architecture (ICSA)},
  title     = {From Monolithic Architecture Style to Microservice one Based on a Semi-Automatic Approach},
  year      = {2020},
  month     = {March},
  pages     = {157-168},
  abstract  = {Due to its tremendous advantages, microservice architectural style has become an essential element for the development of applications deployed on the cloud and for those adopting the DevOps practices. Nevertheless, while microservices can be used to develop new applications, there are monolithic ones, that are not well adapted neither to the cloud nor to DevOps. Migrating these applications towards microservices appears as a solution to adapt them to both. In this context, we propose an approach aiming to achieve this objective by focusing on the step of microservices identification. The proposed identification, in this paper, is based on an analysis of the relationships between source code elements, their relationships with the persistent data manipulated in this code and finally the knowledge, often partial, of the architect concerning the system to migrate. A function that measures the quality of a microservice based on its ability to provide consistent service and its interdependence with others microservice in the resulting architecture was defined. Moreover, the architect recommendations are used, when available, to guide the identification process. The conducted experiment shows the relevance of the obtained microservices by our approach.},
  doi       = {10.1109/ICSA47634.2020.00023},
}

@InProceedings{Tang2021,
  author    = {Tang, Ming and Xia, Fei and Zou, Haodong and Hu, Youjun and Liu, Jun and Liu, Sai},
  booktitle = {2021 IEEE 4th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)},
  title     = {Cloud platform load balancing mechanism for microservice architecture},
  year      = {2021},
  month     = {June},
  pages     = {435-439},
  volume    = {4},
  abstract  = {In response to the increase in request response latency under the microservice architecture, from the perspective of cloud platform load balancing, the average request latency and host load on the microservice chain are used as metrics to formalize the latency and problem environment. A request load balancing algorithm perceived by the microservice chain is proposed as the load balancing strategy of the load balancer. Simulation experiments prove that the algorithm in this paper can effectively reduce request latency in a complex microservice chain environment, and it can also maintain relatively good performance in an environment where instances are unevenly distributed, and for workloads between hosts.},
  doi       = {10.1109/IMCEC51613.2021.9482273},
  issn      = {2693-2776},
}

@InProceedings{Toledo2021,
  author    = {de Toledo, Saulo S. and Martini, Antonio and Sjøberg, Dag I.K. and Przybyszewska, Agata and Frandsen, Johannes Skov},
  booktitle = {2021 47th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)},
  title     = {Reducing Incidents in Microservices by Repaying Architectural Technical Debt},
  year      = {2021},
  month     = {Sep.},
  pages     = {196-205},
  abstract  = {Architectural technical debt (ATD) may create a substantial extra effort in software development, which is called interest. There is little evidence about whether repaying ATD in microservices reduces such interest. Objectives: We wanted to conduct a first study on investigating the effect of removing ATD on the occurrence of incidents in a microservices architecture. Method: We conducted a quantitative and qualitative case study of a project with approximately 1000 microservices in a large, international financing services company. We measured and compared the number of software incidents of different categories before and after repaying ATD. Results: The total number of incidents was reduced by 84%, and the numbers of critical- and high-priority incidents were both reduced by approximately 90% after the architectural refactoring. The number of incidents in the architecture with the ATD was mainly constant over time, but we observed a slight increase of low priority incidents related to inaccessibility and the environment in the architecture without the ATD. Conclusion: This study shows evidence that refactoring ATDs, such as lack of communication standards, poor management of dead-letter queues, and the use of inadequate technologies in microservices, reduces the number of critical- and high-priority incidents and, thus, part of its interest, although some low priority incidents may increase.},
  doi       = {10.1109/SEAA53835.2021.00033},
}

@InProceedings{Hou2021,
  author    = {Hou, Chuanjia and Jia, Tong and Wu, Yifan and Li, Ying and Han, Jing},
  booktitle = {2021 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)},
  title     = {Diagnosing Performance Issues in Microservices with Heterogeneous Data Source},
  year      = {2021},
  month     = {Sep.},
  pages     = {493-500},
  abstract  = {Microservices architecture is vulnerable to performance issues due to its highly fine-grained decomposition of an application. To diagnose performance issues in microservices, existing works utilize system metrics as the specific indicator and do a lot of heavy computation such as building service dependency graphs during the diagnosing process.To improve the effectiveness and efficiency of issue diagnosing, we propose PDiagnose, a practical approach using multiple data sources including metrics, logs and traces jointly to diagnose performance issues in microservices systems. Through combining lightweight unsupervised anomaly detection algorithms and vote-based issue localization strategy, PDiagnose is application-agnostic and can localize root cause indicators accurately. Our evaluation on two public-available datasets shows that PDiagnose can achieve an overall recall of 84.8%, outperforming the best baseline approach. Meanwhile, the diagnosis duration of PDiagnose is also promising.},
  doi       = {10.1109/ISPA-BDCloud-SocialCom-SustainCom52081.2021.00074},
}

@InProceedings{Rossi2020a,
  author    = {Rossi, Fabiana and Cardellini, Valeria and Presti, Francesco Lo},
  booktitle = {2020 IEEE International Conference on Autonomic Computing and Self-Organizing Systems (ACSOS)},
  title     = {Hierarchical Scaling of Microservices in Kubernetes},
  year      = {2020},
  month     = {Aug},
  pages     = {28-37},
  abstract  = {In the last years, we have seen the increasing adoption of the microservice architectural style where applications satisfy user requests by invoking a set of independently deployable services. Software containers and orchestration tools, such as Kubernetes, have simplified the development and management of microservices. To manage containers' horizontal elasticity, Kubernetes uses a decentralized threshold-based policy that requires to set thresholds on system-oriented metrics (i.e., CPU utilization). This might not be well-suited to scale latency-sensitive applications, which need to express requirements in terms of response time. Moreover, being a fully decentralized solution, it may lead to frequent and uncoordinated application reconfigurations. In this paper, we present me-kube (Multi-level Elastic Kubernetes), a Kubernetes extension that introduces a hierarchical architecture for controlling the elasticity of microservice-based applications. At higher level, a centralized per-application component coordinates the run-time adaptation of subordinated distributed components, which, in turn, locally control the adaptation of each microservice. Then, we propose novel proactive and reactive hierarchical control policies, based on queuing theory. To show that me-kube provides general mechanisms, we also integrate reinforcement learning-based scaling policies. Using me-kube, we perform a large set of experiments, aimed to show the advantages of a hierarchical control over the default Kubernetes autoscaler.},
  doi       = {10.1109/ACSOS49614.2020.00023},
}

@InProceedings{Valdivia2019,
  author    = {Valdivia, José A. and Limón, Xavier and Cortes-Verdin, Karen},
  booktitle = {2019 7th International Conference in Software Engineering Research and Innovation (CONISOFT)},
  title     = {Quality attributes in patterns related to microservice architecture: a Systematic Literature Review},
  year      = {2019},
  month     = {Oct},
  pages     = {181-190},
  abstract  = {Microservices is an interesting option for those who want to migrate their systems to improve performance, maintainability, scalability, and interoperability. Microservice architecture is a collection of self-sufficient services working together to provide functionalities. Nowadays, there are many options to build microservices, some of them are lead by patterns. However, the mapping between quality attributes and patterns is not clear yet. This systematic literature review presents a microservice pattern collection, it describes their benefits and the association between patterns and quality attributes. Finally, some metrics of quality attributes are identified.},
  doi       = {10.1109/CONISOFT.2019.00034},
}

@InProceedings{AlDebagy2020a,
  author    = {Al-Debagy, Omar and Martinek, Péter},
  booktitle = {2020 IEEE 15th International Conference of System of Systems Engineering (SoSE)},
  title     = {Extracting Microservices’ Candidates from Monolithic Applications: Interface Analysis and Evaluation Metrics Approach},
  year      = {2020},
  month     = {June},
  pages     = {289-294},
  abstract  = {There is a migration trend toward microservices architecture coming from the monolithic applications. This research proposes a decomposition method that extracts microservices’ candidates through analyzing the application programming interface in order to extract the operations and the parameters. Then the operation names are converted into word representations using word embedding models. Next, semantically similar operations are clustered together to provide a microservice’ candidate. Additional step is to evaluate the proposed candidate using cohesion and complexity metrics. The proposed algorithm improved the decomposition approach for big applications but did not affect the decomposition of smaller applications.},
  doi       = {10.1109/SoSE50414.2020.9130466},
}

@InProceedings{Guaman2018,
  author    = {Guaman, Daniel and Yaguachi, Lady and Samanta, Cueva C. and Danilo, Jaramillo H. and Soto, Fernanda},
  booktitle = {2018 13th Iberian Conference on Information Systems and Technologies (CISTI)},
  title     = {Performance evaluation in the migration process from a monolithic application to microservices},
  year      = {2018},
  month     = {June},
  pages     = {1-8},
  abstract  = {Microservices are considered as a software architecture that allows the decomposition of a system, its components or its functionalities into a set of small services, which are implemented, deployed and managed independently. In this study, the models that allow migrating a Monolith to Microservices such as NGINX and IBM are analyzed. From these models, activities that allow such migration are carefully selected and identified. In order to implement and evaluate the activities proposed in those models, an application that initially does not have any structure at the design and coding level (using PHP programming language) is applied. Then, the application's coding language changes to Java and the classes and libraries are distributed into packages. Subsequently, as it is suggested in the models, services are identified and implemented using RESTful Web Services to finally implement the microservices using technologies such as Spring Boot, Eureka, and Zuul. In the migration process, the application under study is modified at the code and design level, including patterns such as Singleton, Façade, Strangler, Single Service per Host, Service Discovery, and API Gateway, which are used to evaluate performance as a quality attribute in each migration phase. In order to obtain the performance related metrics and to analyze the advantages and disadvantages of each migration phase, Apache JMeter as tool is used. This tool is set up to generate results regarding the use of resources such as CPU, memory, network, and database access. Finally, the results show scenarios of several concurrent users who access to consult records in the database that uses the aforementioned application in each migration phase.},
  doi       = {10.23919/CISTI.2018.8399148},
}

@InProceedings{Orduz2019,
  author    = {Orduz, Juan S. and Orozco, Gabriel D. and Tobar-Arteaga, Carlos H. and Rendon, Oscar Mauricio Caicedo},
  booktitle = {2019 IEEE 44th LCN Symposium on Emerging Topics in Networking (LCN Symposium)},
  title     = {μvIMS: A Finer-Scalable Architecture Based on Microservices},
  year      = {2019},
  month     = {Oct},
  pages     = {141-148},
  abstract  = {The steps toward all over IP have defined to the IP Multimedia Subsystem (IMS) as the de facto technology for end-to-end multimedia service provisioning in 5G. However, the unpredictable growth of users in 5G requires to improve IMS scalability to handle dynamic user traffic. Several works have addressed this issue by introducing auto-scaling mechanisms in virtualized IMS (vIMS) architectures. However, the current vIMS deployments use monolithic designs that do not allow finer-scalability. In this paper, we present μvIMS, an architecture that uses microservices to provide finer-scalability and more effective resource usage than regular monolithic design. To test our architecture, we evaluate μvIMS prototype regarding CPU usage, RAM usage, Successful Call Rate (SCR), and latency metrics. Our test results reveal that μvIMS achieves a higher SCR, using the available resources effectively with a negligible latency increasing. Thus, we can state that dividing the monolithic vIMS architecture in microservices allows providing finer-scalability.},
  doi       = {10.1109/LCNSymposium47956.2019.9000664},
}

@InProceedings{Wu2021,
  author    = {Wu, Li and Tordsson, Johan and Bogatinovski, Jasmin and Elmroth, Erik and Kao, Odej},
  booktitle = {2021 IEEE/ACM International Workshop on Cloud Intelligence (CloudIntelligence)},
  title     = {MicroDiag: Fine-grained Performance Diagnosis for Microservice Systems},
  year      = {2021},
  month     = {May},
  pages     = {31-36},
  abstract  = {Microservice architecture has emerged as a popular pattern for developing large-scale applications for its benefits of flexibility, scalability, and agility. However, the large number of services and complex dependencies make it difficult and time-consuming to diagnose performance issues. We propose Micro-Diag, an automated system to localize root causes of performance issues in microservice systems at a fine granularity, including not only locating the faulty component but also discovering detailed information for its abnormality. MicroDiag constructs a component dependency graph and performs causal inference on diverse anomaly symptoms to derive a metrics causality graph, which is used to infer root causes. Our experimental evaluation on a microservice benchmark running in a Kubernetes cluster shows that MicroDiag localizes root causes well, with 97% precision of the top 3 most likely root causes, outperforming state-of-the-art methods by at least 31.1%.},
  doi       = {10.1109/CloudIntelligence52565.2021.00015},
}

@InProceedings{Choochotkaew2021,
  author    = {Choochotkaew, Sunyanan and Chiba, Tatsuhiro and Trent, Scott and Amaral, Marcelo},
  booktitle = {2021 IEEE 14th International Conference on Cloud Computing (CLOUD)},
  title     = {Run Wild: Resource Management System with Generalized Modeling for Microservices on Cloud},
  year      = {2021},
  month     = {Sep.},
  pages     = {609-618},
  abstract  = {Microservice architecture competes with the traditional monolithic design by offering benefits of agility, flexibility, reusability resilience, and ease of use. Nevertheless, due to the increase in internal communication complexity, care must be taken for resource-usage scaling in harmony with placement scheduling, and request balancing to prevent cascading performance degradation across microservices. We prototype Run Wild, a resource management system that controls all mechanisms in the microservice-deployment process covering scaling, scheduling, and balancing to optimize for desirable performance on the dynamic cloud driven by an automatic, united, and consistent deployment plan. In this paper, we also highlight the significance of co-location aware metrics on predicting the resource usage and computing the deployment plan. We conducted experiments with an actual cluster on the IBM Cloud platform. RunWild reduced the 90th percentile response time by 11% and increased average throughput by 10% with more than 30% lower resource usage for widely used autoscaling benchmarks on Kubernetes clusters.},
  doi       = {10.1109/CLOUD53861.2021.00079},
  issn      = {2159-6190},
}

@InProceedings{Pulparambil2018,
  author    = {Pulparambil, Supriya and Baghdadi, Youcef and Al-Hamdani, Abdullah and Al-Badawi, Mohammed},
  booktitle = {2018 9th International Conference on Computing, Communication and Networking Technologies (ICCCNT)},
  title     = {Service Design Metrics to Predict IT-Based Drivers of Service Oriented Architecture Adoption},
  year      = {2018},
  month     = {July},
  pages     = {1-7},
  abstract  = {The key factors for deploying successful services is centered on the service design practices adopted by an enterprise. The design level information should be validated and measures are required to quantify the structural attributes. The metrics at this stage will support an early discovery of design flaws and help designers to predict the capabilities of service oriented architecture (SOA) adoption. In this work, we take a deeper look at how we can forecast the key SOA capabilities infrastructure efficiency and service reuse from the service designs modeled by SOA modeling language. The proposed approach defines metrics based on the structural and domain level similarity of service operations. The proposed metrics are analytically validated with respect to software engineering metrics properties. Moreover, a tool has been developed to automate the proposed approach and the results indicate that the metrics predict the SOA capabilities at the service design stage. This work can be further extended to predict the business based capabilities of SOA adoption such as flexibility and agility.},
  doi       = {10.1109/ICCCNT.2018.8494072},
}

@InProceedings{Gamage2021,
  author    = {Gamage, Isuru Udara Piyadigama and Perera, Indika},
  booktitle = {2021 Moratuwa Engineering Research Conference (MERCon)},
  title     = {Using dependency graph and graph theory concepts to identify anti-patterns in a microservices system: A tool-based approach},
  year      = {2021},
  month     = {July},
  pages     = {699-704},
  abstract  = {Microservice architecture (MSA) based application developments are becoming the common trend in implementing large-scale applications. Unlike the traditional monolith applications, MSA applications are composed of many services hence there is an immense possibility of anti-patterns introduced into the system. To identify these design problems, a detailed analysis of the architecture needs to be performed. We see great potential for adopting graph concepts and algorithms in this regard. However, the few tools proposed by existing work to find anti-patterns that adopt graph concepts are not up to providing developers with adequate statistical information such as metrics along with visualization techniques or they are not fully automated. In this research, we present a tool-based solution for this problem which is capable of utilizing traced data of an MSA system to generate dependency graphs and thereby extract metrics using graph theory concepts and algorithms. We analyze a sample MSA system for anti-patterns with the tool. To verify the usability of the tool further, a group of developers also analyze an open-source system with the tool.},
  doi       = {10.1109/MERCon52712.2021.9525743},
  issn      = {2691-364X},
}

@InProceedings{Wang2017a,
  author    = {Wang, Hanzhang and Kessentini, Marouane and Hassouna, Taghreed and Ouni, Ali},
  booktitle = {2017 IEEE International Conference on Web Services (ICWS)},
  title     = {On the Value of Quality of Service Attributes for Detecting Bad Design Practices},
  year      = {2017},
  month     = {June},
  pages     = {341-348},
  abstract  = {Service-Oriented Architectures (SOAs) successfully evolve over time to update existing exposed features to the users and fix possible bugs. This evolution process may have a negative impact on the design quality of Web services. Recent studies addressed the problem of Web service antipatterns detection (bad design practices). To the best of our knowledge, these studies focused only on the use of metrics extracted from the implementation details (source code) of the interface and the services. However, the quality of service (QoS) metrics, widely used to evaluate the overall performance, are never used in the context of Web service antipatterns detection. We start, in this work, from the hypothesis that these bad design practices may impact several QoS metrics such as the response time. Furthermore, the source code metrics of services may not be always available. Without the consideration of these QoS metrics, the current detection processes of antipatterns will still lack the integration of symptoms that could be extracted from the usage of services. In this paper, we propose an automated approach to generate Web service defect detection rules that consider not only the code/interface level metrics but also the quality of service attributes. Through multi-objective optimization, the proposed approach generates solutions (detection rules) that maximize the coverage of antipattern examples and minimize the coverage of well-designed service examples. An empirical validation is performed with eight different common types of Web design defects to evaluate our approach. We compared our results with three other state of the art techniques which are not using QoS metrics. The statistical analysis of the obtained results confirm that our approach outperforms other techniques and generates detection rules that are more meaningful from the services' user perspective.},
  doi       = {10.1109/ICWS.2017.126},
}

@InProceedings{Gomathy2014,
  author    = {Gomathy, C. K. and Rajalakshmi, S.},
  booktitle = {Second International Conference on Current Trends In Engineering and Technology - ICCTET 2014},
  title     = {A software quality metric performance of professional management in service oriented architecture},
  year      = {2014},
  month     = {July},
  pages     = {41-47},
  abstract  = {Service-oriented architecture (SOA) is generally the way of containing and examines to develop the information management needs in order to make dealing responsive and elastic in pace with forceful quality conditions. Adopting, implementing and running SOA require considerable thought and effort in order to distribute high-quality metrics data and become conscious the complete assessment of SOA. In this paper, inspect the sequentially and quality related metrics issues that have been investigated organizations in order to uncover the activities in regard to information quality within their initiatives of implementing SOA. In the succession of quality behavior that solve certain information quality and maintenance, development issues therefore, can be enthusiastically established across any industry to support the building of high quality and then making SOA solutions. In current days service oriented architecture design is also incorporated and potentially distributed with the quality metrics and to perform a superior evaluation of the representation.},
  doi       = {10.1109/ICCTET.2014.6966260},
}

@InProceedings{Alnahdi2017,
  author    = {Alnahdi, Amany and Liu, Shih-Hsi},
  booktitle = {2017 IEEE International Conference on Services Computing (SCC)},
  title     = {Identifying Characteristic Attributes for Estimating Cost of Service in Service Oriented Architecture},
  year      = {2017},
  month     = {June},
  pages     = {467-470},
  abstract  = {Web services are software modules that provide interoperability over a network. Web services provide Web service users platform independence while using software. It enables businesses to collaborate by using Web services from Web service providers. Estimating a Cost of Service (CoS) is essential when pricing, selecting, and monitoring a Web service. The concept of cost is not restricted to financial value of technology hardware and software. The cost concept can also include time, usability, and maintenance. Cost of a Web service can be estimated by identifying the attributes of cost from the perspective of different stakeholders such as Web service provider, Web service consumer, Web service repository moderator, and Web service policy maker. In addition, analyzing different roles in Service Oriented Architecture (SOA) will further provide more knowledge about different perspectives of cost concepts in SOA. This paper addresses the essential attributes of estimating cost of a Web service. Moreover, this paper specifies attributes of measuring CoS, defines these attributes, and defines metrics and units of these attributes. Additionally, it provides further hierarchy classification of Web service cost concepts. It also provides a model for evaluating Web service cost based on different cost criteria. By measuring CoS, Web service stakeholders will be able to estimate an accurate value to the CoS.},
  doi       = {10.1109/SCC.2017.66},
  issn      = {2474-2473},
}

@InProceedings{Bora2015,
  author    = {Bora, Abhijit and Bezboruah, Tulshi},
  booktitle = {2015 IEEE International Conference on Research in Computational Intelligence and Communication Networks (ICRCICN)},
  title     = {Some aspects of QoS for interoperability of multi service multi functional service oriented computing},
  year      = {2015},
  month     = {Nov},
  pages     = {363-368},
  abstract  = {Quality of service is the key indicator for service oriented architectures, because it directly expresses the operability and computational nature of the system. As such, we propose a quality evaluation framework for multi service multi functional hierarchical SOAP based web service. The overall interoperable quality is evaluated through load testing using Mercury Load Runner with Apache Tomcat web server and MySQL database engine. The recorded quality metrics are analyzed statistically. We present here in detail the architecture, observed metrics and analyzed results of the service oriented computing to validate the acceptability of the evaluation framework.},
  doi       = {10.1109/ICRCICN.2015.7434265},
}

@InProceedings{Streiffer2018,
  author    = {Streiffer, Christopher and Raghavendra, Ramya and Benson, Theophilus and Srivatsa, Mudhakar},
  booktitle = {2018 IEEE International Conference on Big Data (Big Data)},
  title     = {Learning to Simplify Distributed Systems Management},
  year      = {2018},
  month     = {Dec},
  pages     = {1837-1845},
  abstract  = {Managing large-scale distributed systems is a difficult task. System administrators are responsible for the upkeep and maintenance of numerous components with complex dependencies. With the shift to microservices-based architectures, these systems can consist of 100s to 1000s of interconnected nodes. To combat this difficulty, administrators rely on analyzing logs and metrics collected from the different services. However, the number of available metrics for large systems presents complexity and scaling issues. To combat these issues, we present Minerva, an unsupervised Machine Learning (ML) framework for performing network diagnosis analysis. Minerva is composed of a multi-stage pipeline, where each component can act individually or cohesively to perform various management tasks. Our system offers a unified and extensible framework for managing the complexity of large networks, and presents administrators with a swiss-army knife for diagnosing the overall health of their systems. To demonstrate the feasibility of Minerva, we evaluate its performance on a production-scale system. We present use cases for the various management tools made available by Minerva, and show how these tools can be used to make strong inferences about the system using unsupervised techniques.},
  doi       = {10.1109/BigData.2018.8622058},
}

@InProceedings{Bogner2018a,
  author    = {Bogner, Justus and Fritzsch, Jonas and Wagner, Stefan and Zimmermann, Alfred},
  booktitle = {2018 IEEE/ACM International Conference on Technical Debt (TechDebt)},
  title     = {Limiting Technical Debt with Maintainability Assurance – An Industry Survey on Used Techniques and Differences with Service- and Microservice-Based Systems},
  year      = {2018},
  month     = {May},
  pages     = {125-133},
  abstract  = {Maintainability assurance techniques are used to control this quality attribute and limit the accumulation of potentially unknown technical debt. Since the industry state of practice and especially the handling of Service-and Microservice-Based Systems in this regard are not well covered in scientific literature, we created a survey to gather evidence for a) used processes, tools, and metrics in the industry, b) maintainability-related treatment of systems based on service-orientation, and c) influences on developer satisfaction w.r.t. maintainability. 60 software professionals responded to our online questionnaire. The results indicate that using explicit and systematic techniques has benefits for maintainability. The more sophisticated the applied methods the more satisfied participants were with the maintainability of their software while no link to a hindrance in productivity could be established. Other important findings were the absence of architecture-level evolvability control mechanisms as well as a significant neglect of service-oriented particularities for quality assurance. The results suggest that industry has to improve its quality control in these regards to avoid problems with long-living service-based software systems.},
}

@InProceedings{Chituc2015,
  author    = {Chituc, Claudia-Melania},
  booktitle = {2015 IEEE 7th International Conference on Cloud Computing Technology and Science (CloudCom)},
  title     = {Towards a Methodology for Trade-off Analysis in a Multi-cloud Environment Considering Monitored QoS Metrics and Economic Performance Assessment Results},
  year      = {2015},
  month     = {Nov},
  pages     = {479-482},
  abstract  = {Cloud computing and service-oriented computing brought new opportunities for companies. However, numerous challenges, (e.g., related to application design and deployment, service monitoring) are associated with the cloud and provisioned services. Complex SLAs need to be established and monitored. Current approaches do not sufficiently address the challenges of QoS monitoring in multi-cloud environments in a holistic manner, tackling mainly technical aspects. This paper presents an on-going research project towards the development of a methodology for a trade-off analysis in a multi-cloud environment considering monitored QoS metrics and economic performance assessment results. The research methodology followed and partial results are presented, and directions for future work are discussed. Based on the needs identified, an architecture for SLA monitoring and dynamic runtime adaptations in multi-cloud environments is proposed, tackling technical and business-economic aspects.},
  doi       = {10.1109/CloudCom.2015.87},
}

@Article{Jin2021a,
  author   = {Jin, Hai and Li, Zhi and Zou, Deqing and Yuan, Bin},
  journal  = {IEEE Transactions on Dependable and Secure Computing},
  title    = {DSEOM: A Framework for Dynamic Security Evaluation and Optimization of MTD in Container-Based Cloud},
  year     = {2021},
  issn     = {1941-0018},
  month    = {May},
  number   = {3},
  pages    = {1125-1136},
  volume   = {18},
  abstract = {Due to the lightweight features, the combination of container technology and microservice architecture makes container-based cloud environment more efficient and agile than VM-based cloud environment. However, it also greatly amplifies the dynamism and complexity of the cloud environment and increases the uncertainty of security issues in the system concurrently. In this case, the effectiveness of defense mechanisms with fixed strategies would fluctuate as the updates occur in cloud environment. We refer this problem as effectiveness drift problem of defense mechanisms, which is particularly acute in the proactive defense mechanisms, such as moving target defense (MTD). To tackle this problem, we present DSEOM, a framework that can automatically perceive updates of container-based cloud environment, rapidly evaluate the effectiveness change of MTD and dynamically optimize MTD strategies. Specifically, we establish a multi-dimensional attack graphs model to formalize various complex attack scenarios. Combining with this model, we introduce the concept of betweenness centrality to effectively evaluate and optimize the implementation strategies of MTD. In addition, we present a series of security and performance metrics to quantify the effectiveness of MTD strategies in DSEOM. And we conduct extensive experiments to illustrate the existence of the effectiveness drift problem and demonstrate the usability and scalability of DSEOM.},
  doi      = {10.1109/TDSC.2019.2916666},
}

@Article{Herrera2020,
  author   = {Herrera, José and Moltó, Germán},
  journal  = {IEEE Access},
  title    = {Toward Bio-Inspired Auto-Scaling Algorithms: An Elasticity Approach for Container Orchestration Platforms},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {52139-52150},
  volume   = {8},
  abstract = {The wide adoption of microservices architectures has introduced an unprecedented granularisation of computing that requires the coordinated execution of multiple containers with diverse lifetimes and with potentially different auto-scaling requirements. These applications are managed by means of container orchestration platforms and existing centralised approaches for auto-scaling face challenges when used for the timely adaptation of the elasticity required for the different application components. This paper studies the impact of integrating bio-inspired approaches for dynamic distributed auto-scaling on container orchestration platforms. With a focus on running self-managed containers, we compare alternative configuration options for the container life cycle. The performance of the proposed models is validated through simulations subjected to both synthetic and real-world workloads. Also, multiple scaling options are assessed with the purpose of identifying exceptional cases and improvement areas. Furthermore, a nontraditional metric for scaling measurement is introduced to substitute classic analytical approaches. We found out connections for two related worlds (biological systems and software container elasticity procedures) and we open a new research area in software containers that features potential self-guided container elasticity activities.},
  doi      = {10.1109/ACCESS.2020.2980852},
}

@InProceedings{Torkura2017,
  author    = {Torkura, Kennedy A. and Sukmana, Muhammad I.H. and Cheng, Feng and Meinel, Christoph},
  booktitle = {2017 IEEE International Conference on Smart Cloud (SmartCloud)},
  title     = {Leveraging Cloud Native Design Patterns for Security-as-a-Service Applications},
  year      = {2017},
  month     = {Nov},
  pages     = {90-97},
  abstract  = {This paper discusses a new approach for designing and deploying Security-as-a-Service (SecaaS) applications using cloud native design patterns. Current SecaaS approaches do not efficiently handle the increasing threats to computer systems and applications. For example, requests for security assessments drastically increase after a high-risk security vulnerability is disclosed. In such scenarios, SecaaS applications are unable to dynamically scale to serve requests. A root cause of this challenge is employment of architectures not specifically fitted to cloud environments. Cloud native design patterns resolve this challenge by enabling certain properties e.g. massive scalability and resiliency via the combination of microservice patterns and cloud-focused design patterns. However adopting these patterns is a complex process, during which several security issues are introduced. In this work, we investigate these security issues, we redesign and deploy a monolithic SecaaS application using cloud native design patterns while considering appropriate, layered security counter-measures i.e. at the application and cloud networking layer. Our prototype implementation out-performs traditional, monolithic applications with an average Scanner Time of 6 minutes, without compromising security. Our approach can be employed for designing secure, scalable and performant SecaaS applications that effectively handle unexpected increase in security assessment requests.},
  doi       = {10.1109/SmartCloud.2017.21},
}

@InProceedings{Alzaghoul2014,
  author    = {Alzaghoul, Esra and Bahsoon, Rami},
  booktitle = {2014 23rd Australian Software Engineering Conference},
  title     = {Evaluating Technical Debt in Cloud-Based Architectures Using Real Options},
  year      = {2014},
  month     = {April},
  pages     = {1-10},
  abstract  = {A Cloud-based Service-Oriented Architecture (CBSOA) is typically composed of web services, which are offered off the cloud marketplace. CB-SOA can improve its utility and add value to its composition by switching among its constituent services. We look at the option to defer the decision of substitution under uncertainty. We exploit Binomial Options to the formulation. We quantify the time-value of the architecture decisions of switching web services and technical debt they can imply on the structure. As CB-SOA are market-sensitive, dynamic and "volatile", the decision of deferral tends to be sensitive to these dynamics. Henceforth, the structural complexity of a CB-SOAcan change over time and so the technical debt as its constituent web services are modified, replaced, upgraded, etc. The method builds on Design Structure Matrix (DSM) and introduces time and complexity aware propagation cost metrics to assess the value of deferral decisions relative to changes in the structure. Architects of CB-SOA can use our method to assess the time value of deferring the decisions to switch web services relative to complexity, technical debt and value creation. We demonstrate the applicability of the method using an illustrative example.},
  doi       = {10.1109/ASWEC.2014.27},
  issn      = {2377-5408},
}

@InProceedings{Hecht2014,
  author    = {Hecht, Geoffrey and Jose-Scheidt, Benjamin and De Figueiredo, Clement and Moha, Naouel and Khomh, Foutse},
  booktitle = {2014 IEEE 6th International Conference on Cloud Computing Technology and Science},
  title     = {An Empirical Study of the Impact of Cloud Patterns on Quality of Service (QoS)},
  year      = {2014},
  month     = {Dec},
  pages     = {278-283},
  abstract  = {Cloud patterns are described as good solutions to recurring design problems in a cloud context. These patterns are often inherited from Service Oriented Architectures or Object Oriented Architectures where they are considered good practices. However, there is a lack of studies that assess the benefits of these patterns for cloud applications. In this paper, we conduct an empirical study on a Restful application deployed in the cloud, to investigate the individual and the combined impact of three cloud patterns (i.e., Local Database proxy, Local Sharding-Based Router and Priority Queue Patterns) on Quality of Service (QoS). We measure the QoS using the application's response time, average, and maximum number of requests processed per seconds. Results show that cloud patterns doesn't always improve the response time of an application. In the case of the Local Database proxy pattern, the choice of algorithm used to route requests has an impact on response time, as well as the average and maximum number of requests processed per second. Combinations of patterns can significantly affect the QoS of applications. Developers and software architects can make use of these results to guide their design decisions.},
  doi       = {10.1109/CloudCom.2014.141},
}

@Article{Trang2018,
  author   = {Trang, Mai Xuan and Murakami, Yohei and Ishida, Toru},
  journal  = {IEEE Transactions on Services Computing},
  title    = {Policy-Aware Service Composition: Predicting Parallel Execution Performance of Composite Services},
  year     = {2018},
  issn     = {1939-1374},
  month    = {July},
  number   = {4},
  pages    = {602-615},
  volume   = {11},
  abstract = {With the increasing volume of data to be analysed, one of the challenges in Service Oriented Architecture (SOA) is to make web services efficient in processing large-scale data. Parallel execution and cloud technologies are the keys to speed-up the service invocation. In SOA, service providers typically employ policies to limit parallel execution of the services based on arbitrary decisions. In order to attain optimal performance improvement, users need to adapt to the services policies. A composite service is a combination of several atomic services provided by various providers. To use parallel execution for greater composite service efficiency, the degree of parallelism (DOP) of the composite services need to be optimized by considering the policies of all atomic services. We propose a model that embeds service policies into formulae to calculate composite service performance. From the calculation, we predict the optimal DOP for the composite service, where it attains the best performance. Extensive experiments are conducted on real-world translation services. We use several measures such as mean prediction error (MPE), mean absolute deviation (MAD) and tracking signal (TS) to evaluate our model. The analysis results show that our proposed model has good prediction accuracy in identifying optimal DOPs for composite services.},
  doi      = {10.1109/TSC.2015.2467330},
}

@InProceedings{Jack2023,
  author    = {Jack, Chang Hoong and Teck, See Kwee and Ming, Lim Tong and Hong, Ding Ying},
  booktitle = {2023 IEEE 8th International Conference On Software Engineering and Computer Systems (ICSECS)},
  title     = {An Overview Analysis of Authentication Mechanism in Microservices-Based Software Architecture: A Discussion Paper},
  year      = {2023},
  month     = {Aug},
  pages     = {1-6},
  abstract  = {Microservices-based software architecture promotes scalability and flexibility by breaking down a software application into smaller modules and making it more independent and loosely coupled services compared to monolith systems. However, securing microservices in a distributed nature has become one of the challenges. Authentication is one of the most critical components that should be focused in the microservices security measures. It helps to identify that only authenticated personnel and services can access sensitive information and secure the trust between microservices. This discussion paper aims to provide an overview analysis and extensive understanding on the authentication mechanism in microservices-based software architecture. In this study, we explore different authentication mechanisms including Mutual Transport Layer Security (mTLS), Token based authentication and API Gateway authentication. This study examines the strengths and limitations of different authentication mechanisms in microservices-based software architecture. It also emphasizes the importance of authentication and the need for having a well-designed authentication mechanism to ensure the integrity and security of microservices-based software architecture is crucial.},
  doi       = {10.1109/ICSECS58457.2023.10256409},
}

@InProceedings{Speth2022,
  author    = {Speth, Sandro and Stieß, Sarah and Becker, Steffen},
  booktitle = {2022 IEEE 19th International Conference on Software Architecture Companion (ICSA-C)},
  title     = {A Saga Pattern Microservice Reference Architecture for an Elastic SLO Violation Analysis},
  year      = {2022},
  month     = {March},
  pages     = {116-119},
  abstract  = {Reference architectures are becoming increasingly popular for industry and researchers as benchmark solutions to test their novel concepts and tools. While many reference architectures exist in the microservice domain, they are often not built on state-of-the-art technologies. Furthermore, many existing reference architectures do not use lightweight and asynchronous communications, such as messaging, do not have out-of-the-box self-adaptation and do not consider state-of-the-art microservice patterns. Therefore, this paper proposes a self-adaptive microservice reference architecture that implements the microservice saga pattern. The architecture is implemented in Java Spring Boot and uses the Eventuate Tram framework for the saga orchestration. Moreover, the architecture is instrumented to export performance metrics for monitoring and data for system-wide tracing to check for correct execution of the system and its adaptations. The objective of this reference architecture is to provide a benchmark for explaining self-adaptation and propagation of service-level objective (SLOs) violations across an architecture with complex patterns. In addition to the architecture, we provide defined SLOs and load profiles to stress the architecture.},
  doi       = {10.1109/ICSA-C54293.2022.00029},
  issn      = {2768-4288},
}

@InProceedings{Frank2022,
  author    = {Frank, Sebastian and Wagner, Lion and Hakamian, Alireza and Straesser, Martin and van Hoorn, André},
  booktitle = {2022 IEEE 22nd International Conference on Software Quality, Reliability and Security (QRS)},
  title     = {MiSim: A Simulator for Resilience Assessment of Microservice-Based Architectures},
  year      = {2022},
  month     = {Dec},
  pages     = {1014-1025},
  abstract  = {Increased resilience compared to monolithic architectures is both one of the key promises of microservice-based architectures and a big challenge, e.g., due to the systems’ distributed nature. Resilience assessment through simulation requires fewer resources than the measurement-based techniques used in practice. However, there is no existing simulation approach that is suitable for a holistic resilience assessment of microservices comprised of (i) representative fault injections, (ii) common resilience mechanisms, and (iii) time-varying workloads. This paper presents MiSim — an extensible simulator for resilience assessment of microservice-based architectures. It overcomes the stated limitations of related work. MiSim fits resilience engineering practices by supporting scenario-based experiments and requiring only lightweight input models. We demonstrate how MiSim simulates (1) common resilience mechanisms — i.e., circuit breaker, connection limiter, retry, load balancer, and autoscaler — and (2) fault injections — i.e., instance/service killing and latency injections. In addition, we use TeaStore, a reference microservice-based architecture, aiming to reproduce scaling behavior from an experiment by using simulation. Our results show that MiSim allows for quantitative insights into microservice-based systems’ complex transient behavior by providing up to 25 metrics.},
  doi       = {10.1109/QRS57517.2022.00105},
  issn      = {2693-9177},
}

@Article{Khazaei2022,
  author   = {Khazaei, Hamzeh and Mahmoudi, Nima and Barna, Cornel and Litoiu, Marin},
  journal  = {IEEE Transactions on Cloud Computing},
  title    = {Performance Modeling of Microservice Platforms},
  year     = {2022},
  issn     = {2168-7161},
  month    = {Oct},
  number   = {4},
  pages    = {2848-2862},
  volume   = {10},
  abstract = {Microservice architecture has transformed the way developers are building and deploying applications in the nowadays cloud computing centers. This new approach provides increased scalability, flexibility, manageability, and performance while reducing the complexity of the whole software development life cycle. The increase in cloud resource utilization also benefits microservice providers. Various microservice platforms have emerged to facilitate the DevOps of containerized services by enabling continuous integration and delivery. Microservice platforms deploy application containers on virtual or physical machines provided by public/private cloud infrastructures in a seamless manner. In this article, we study and evaluate the provisioning performance of microservice platforms by incorporating the details of all layers (i.e., both micro and macro layers) in the modeling process. To this end, we first build a microservice platform on top of Amazon EC2 cloud and then leverage it to develop a comprehensive performance model to perform what-if analysis and capacity planning for microservice platforms at scale. In other words, the proposed performance model provides a systematic approach to measure the elasticity of the microservice platform by analyzing the provisioning performance at both the microservice platform and the back-end macroservice infrastructures.},
  doi      = {10.1109/TCC.2020.3029092},
}

@Article{Abgaz2023,
  author   = {Abgaz, Yalemisew and McCarren, Andrew and Elger, Peter and Solan, David and Lapuz, Neil and Bivol, Marin and Jackson, Glenn and Yilmaz, Murat and Buckley, Jim and Clarke, Paul},
  journal  = {IEEE Transactions on Software Engineering},
  title    = {Decomposition of Monolith Applications Into Microservices Architectures: A Systematic Review},
  year     = {2023},
  issn     = {1939-3520},
  month    = {Aug},
  number   = {8},
  pages    = {4213-4242},
  volume   = {49},
  abstract = {Microservices architecture has gained significant traction, in part owing to its potential to deliver scalable, robust, agile, and failure-resilient software products. Consequently, many companies that use large and complex software systems are actively looking for automated solutions to decompose their monolith applications into microservices. This paper rigorously examines 35 research papers selected from well-known databases using a Systematic Literature Review (SLR) protocol and snowballing method, extracting data to answer the research questions, and presents the following four contributions. First, the Monolith to Microservices Decomposition Framework (M2MDF) which identifies the major phases and key elements of decomposition. Second, a detailed analysis of existing decomposition approaches, tools and methods. Third, we identify the metrics and datasets used to evaluate and validate monolith to microservice decomposition processes. Fourth, we propose areas for future research. Overall, the findings suggest that monolith decomposition into microservices remains at an early stage and there is an absence of methods for combining static, dynamic, and evolutionary data. Insufficient tool support is also in evidence. Furthermore, standardised metrics, datasets, and baselines have yet to be established. These findings can assist practitioners seeking to understand the various dimensions of monolith decomposition and the community's current capabilities in that endeavour. The findings are also of value to researchers looking to identify areas to further extend research in the monolith decomposition space.},
  doi      = {10.1109/TSE.2023.3287297},
}

@Article{Zdun2023a,
  author   = {Zdun, Uwe and Queval, Pierre-Jean and Simhandl, Georg and Scandariato, Riccardo and Chakravarty, Somik and Jelić, Marjan and Jovanović, Aleksandar},
  journal  = {IEEE Transactions on Dependable and Secure Computing},
  title    = {Detection Strategies for Microservice Security Tactics},
  year     = {2023},
  issn     = {1941-0018},
  pages    = {1-17},
  abstract = {Microservice architectures are widely used today to implement distributed systems. Securing microservice architectures is challenging because of their polyglot nature, continuous evolution, and various security concerns relevant to such architectures. This article proposes a novel, model-based approach providing detection strategies to address the automated detection of security tactics (or patterns and best practices) in a given microservice architecture decomposition model. Our novel detection strategies are metrics-based rules that decide conformance to a security recommendation based on a statistical predictor. The proposed approach models this recommendation using Architectural Design Decisions (ADDs). We apply our approach for four different security-related ADDs on access management, traffic control, and avoiding plaintext sensitive data in the context of microservice systems. We then apply our approach to a model data set of 10 open-source microservice systems and 20 variants of those systems. Our results are detection strategies showing a very low bias, a very high correlation, and a low prediction error in our model data set.},
  doi      = {10.1109/TDSC.2023.3276487},
}

@InProceedings{Raharjo2022,
  author    = {Raharjo, Agus Budi and Andyartha, Putu Krisna and Wijaya, William Handi and Purwananto, Yudhi and Purwitasari, Diana and Juniarta, Nyoman},
  booktitle = {2022 International Conference on Computer Engineering, Network, and Intelligent Multimedia (CENIM)},
  title     = {Reliability Evaluation of Microservices and Monolithic Architectures},
  year      = {2022},
  month     = {Nov},
  pages     = {1-7},
  abstract  = {Software is continuously evolving as business processes that needed to be solved become increasingly complex. Software architecture is an important aspect during software design, with monolithic and microservices being two of the most common with their own advantages and disadvantages. Monolithic is a unified system with a relatively fast development time. Meanwhile, microservices facilitates low coupling and high cohesion, prioritizing maintenance, and ease of modification post-development. This research compares microservices and monolithic API-based thesis monitoring systems. Implementations are done using PHP, Redis, PostgreSQL, Docker, and Heroku. Reliability evaluations are done through automated tests with Apache JMeter. Metrics used are maturity, availability, fault tolerance, and recoverability based on the ISO/IEC 25010 reliability quality characteristics. The conclusion section showed that microservices are more reliable than the monolithic by demonstrating much better fault tolerance and recoverability, with comparable maturity and availability.},
  doi       = {10.1109/CENIM56801.2022.10037281},
}

@InProceedings{Daniel2023,
  author    = {Daniel, João and Guerra, Eduardo and Rosa, Thatiane and Goldman, Alfredo},
  booktitle = {2023 49th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)},
  title     = {Towards the Detection of Microservice Patterns Based on Metrics},
  year      = {2023},
  month     = {Sep.},
  pages     = {132-139},
  abstract  = {Microservices is a popular architectural approach for complex systems in companies, despite its nature of decentralization. There is a comprehensive set of microservices architectural patterns that guides implementations and helps developers to overcome issues. However, the community still scarcely adopts these patterns and only has a theoretical understanding of them. In this work, in order to increase awareness of such patterns and provide aid to developers to better understand an architecture based on microservices, we propose a detection approach based on metrics for microservices patterns. We focused on structural or architectural patterns, and implemented detection for five of them. We conducted two case studies with real-world applications and evaluated the accuracy and applicability of our approach with the developers of those applications.},
  doi       = {10.1109/SEAA60479.2023.00029},
  issn      = {2376-9521},
}

@InProceedings{Jhingran2023,
  author    = {Jhingran, Sushant and Rakesh, Nitin},
  booktitle = {2023 International Conference on Sustainable Emerging Innovations in Engineering and Technology (ICSEIET)},
  title     = {Application Deployment and Performance Measurement in Serverless Cloud for Microservices},
  year      = {2023},
  month     = {Sep.},
  pages     = {173-177},
  abstract  = {The effectiveness of Cloud technology relies heavily on its ability to perform at a high level. To measure this performance, it is necessary to conduct a performance evaluation based on specific aims and applications and assess the capabilities of the cloud services. In the case of enterprise applications deployed on the cloud, the service provider must consider the application's deployment model, security, networking, and operational constraints. This evaluation involves identifying benchmarks, configuring the system, running tests, analyzing results, and providing recommendations. There are various performance metrics that can be applied to different aspects of the cloud services to evaluate their performance. The figures below display data on resource utilization and the impact of the load on the application. Microservices offer organizations the opportunity to deploy applications on the cloud by providing web service functions and an architecture that enables scaling and updating of applications with minimal inconsistency. Through public cloud technology such as Amazon Web Services, organizations can deploy secure and valuable applications to the cloud.},
  doi       = {10.1109/ICSEIET58677.2023.10303332},
}

@InProceedings{Garbi2023,
  author    = {Garbi, Giulio and Incerto, Emilio and Tribastone, Mirco},
  booktitle = {2023 IEEE 16th International Conference on Cloud Computing (CLOUD)},
  title     = {μP: A Development Framework for Predicting Performance of Microservices by Design},
  year      = {2023},
  month     = {July},
  pages     = {178-188},
  abstract  = {Microservice (MS) architecture has become a popular paradigm in software engineering and has been embraced in the industry (e.g., Amazon, Netflix) for cloud-based applications with crucial performance requirements. Surprisingly, assessing how the MS designs affect performance is still a challenging issue, which is generally tackled by extensive and expensive profiling. In this paper, we propose $\mu \mathbf{P}$, a novel development framework for MS applications where performance can be predicted $by$ design. $\mu \mathbf{P}$ offers an API that automatically generates a per-formance model based on Layered Queuing Networks (LQNs) without requiring any development effort beyond writing the actual system code. The model can then be queried to predict performance metrics such as response time and utilization of individual microservices. We validate $\mu \mathbf{P}$ on four benchmarks taken from the literature. The results show the effectiveness of $\mu \mathbf{P}$ in accurately predicting performance due to increasing user load, vertical and horizontal scaling. We report prediction errors for response times consistently lower than 10% across a wide range of operating conditions.},
  doi       = {10.1109/CLOUD60044.2023.00029},
  issn      = {2159-6190},
}

@InProceedings{Pinciroli2023,
  author    = {Pinciroli, Riccardo and Aleti, Aldeida and Trubiani, Catia},
  booktitle = {2023 IEEE 20th International Conference on Software Architecture (ICSA)},
  title     = {Performance Modeling and Analysis of Design Patterns for Microservice Systems},
  year      = {2023},
  month     = {March},
  pages     = {35-46},
  abstract  = {The adoption of design patterns in the microservice architecture and cloud-native development scope was recently reviewed to investigate the industry practice. Interestingly, when considering performance-related aspects, practitioners focus on specific metrics (e.g., the time taken to handle requests) to identify sources of performance hindrance. This paper investigates a subset of seven design patterns that industrial practitioners indicate as relevant for system performance. We are interested to quantify the impact of these patterns while considering heterogeneous workloads, thus supporting software architects in understanding the root causes of performance issues. We use queuing networks to build the performance models of the seven design patterns and extract quantitative insights from model-based performance analysis. Our performance models are flexible in their input parameterization and reusable in different application contexts. We find that most design patterns confirm the expectation of practitioners, and our experimental results assess the identified performance gains and pains. One design pattern (i.e., Gateway Offloading) shows the peculiar characteristic of contributing to performance pains in some cases, leading to novel insights about the impact of design patterns in microservice systems.},
  doi       = {10.1109/ICSA56044.2023.00012},
}

@InProceedings{ElMalki2022,
  author    = {El Malki, Amine and Zdun, Uwe and Pautasso, Cesare},
  booktitle = {2022 IEEE International Conference on Service-Oriented System Engineering (SOSE)},
  title     = {Impact of API Rate Limit on Reliability of Microservices-Based Architectures},
  year      = {2022},
  month     = {Aug},
  pages     = {19-28},
  abstract  = {Many API patterns and best practices have been developed around microservices-based architectures, such as Rate Limiting and Circuit Breaking, to increase quality properties such as reliability, availability, scalability, and performance. Even though estimates on such properties would be beneficial, especially during the early design of such architectures, the real impact of the patterns on these properties has not been rigorously studied yet. This paper focuses on API Rate Limit and its impact on reliability properties from the perspective of API clients. We present an analytical model that considers specific workload configurations and predefined rate limits and then accurately predicts the success and failure rates of the back-end services. The model also presents a method for adaptively fine-tuning rate limits. We performed two extensive data experiments to validate the model and measured Rate Limiting impacts, firstly on a private cloud to minimize latency and other biases, and secondly on the Google Cloud Platform to test our model in a realistic cloud environment. In both experiments, we observed a low percentage of prediction errors. Thus, we conclude that our model can provide distributed system engineers and architects with insights into an acceptable value for the rate limits to choose for a given workload. Very few works empirically studied the impact of Rate Limit or similar API-related patterns on reliability.},
  doi       = {10.1109/SOSE55356.2022.00009},
  issn      = {2642-6587},
}

@InProceedings{Li2018,
  author    = {Li, Keqin},
  booktitle = {2018 IEEE 16th International Conference on Software Engineering Research, Management and Applications (SERA)},
  title     = {Quantitative Modeling and Analytical Calculation of Elasticity in Cloud Computing},
  year      = {2018},
  month     = {June},
  pages     = {3-3},
  abstract  = {Elasticity is a fundamental feature of cloud computing and can be considered as a great advantage and a key benefit of cloud computing. Our research makes the following significant contributions. First, we present a new, quantitative, and formal definition of elasticity in cloud computing, i.e., the probability that the computing resources provided by a cloud platform match the current workload. Our definition is applicable to any cloud platform and can be easily measured and monitored. Furthermore, we develop an analytical model to study elasticity by treating a cloud platform as a queueing system, and use a continuous-time Markov chain (CTMC) model to precisely calculate the elasticity value of a cloud platform by using an analytical and numerical method based on just a few parameters, namely, the task arrival rate, the service rate, the virtual machine start-up and shut-down rates. In addition, we formally define auto-scaling schemes and point out that our model and method can be easily extended to handle arbitrarily sophisticated scaling schemes. Second, we apply our model and method to predict many other important properties of an elastic cloud computing system, such as average task response time, throughput, quality of service, average number of VMs, average number of busy VMs, utilization, cost, cost-performance ratio, productivity, and scalability. In fact, from a cloud consumer's point of view, these performance and cost metrics are even more important than the elasticity metric. Ourperformance and cost guarantee using the results developed in this talk. On the other hand, a cloud service provider can optimize its elastic scaling scheme to deliver the best cost-performance ratio. study in this talk has two significance. On one hand, a cloud service provider can predict its To the best of our knowledge, this is the first work that analytically and comprehensively studies elasticity, performance, and cost in cloud computing. Our model and method significantly contribute to the understanding of cloud elasticity and management of elastic cloud computing systems.},
  doi       = {10.1109/SERA.2018.8477218},
}

@InProceedings{Zhou2015a,
  author    = {Zhou, Ping and Wang, Zhipeng and Li, Wenjing and Jiang, Ning},
  booktitle = {2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems},
  title     = {Quality Model of Cloud Service},
  year      = {2015},
  month     = {Aug},
  pages     = {1418-1423},
  abstract  = {In recent years, services based on cloud computing have been used more and more widely. Stakeholders have paid more and more attention on the quality of cloud service. But most of them don't know how to evaluate the quality of cloud service. This paper proposes a comprehensive, structurized, and hierarchical quality model of cloud service, which concerned not only the IT features but also the service features of cloud service. The quality model was constructed by 6 characteristics, i.e., usability, security, reliability, tangibility, responsiveness, and empathy. We divided each characteristic into several subcharacteristics. In order to apply the cloud service model better, and to evaluate the service quality systematically, we provide a metrics framework for those subcharacteristics, which was made up of objective and subjective metrics. We give a brief intro to the methodology on evaluating the cloud service quality. We also illustrate the evaluation process with a case study.},
  doi       = {10.1109/HPCC-CSS-ICESS.2015.134},
}

@InProceedings{P.M.S.S2016,
  author    = {Chandu P.M.S.S and Kata, Divyasree},
  booktitle = {2016 International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET)},
  title     = {Integrating and enhancing the quality of services in cloud computing with software testing},
  year      = {2016},
  month     = {March},
  pages     = {2008-2010},
  abstract  = {Cloud computing involves to delivering the hosted services throughout the internet. Testing tools are used to test the desktop applications, web applications and the cloud based software systems that are used to address the quality of the cloud infrastructure such as tremendous extensibility and aggressive composition. In the existing paper it is not providing the quality of services in the effective manner. In this paper we focused on integrating the software metrics for getting the quality of services, in terms of speed, memory size, RAM, ROM size and we are also using the D-cloud and prefail testing tools to perform the fault tolerance and recovery testing. By using OVMP algorithm we are minimizing the cost spending for services and load prediction algorithm and it is also used to reduce the load. The aim is to extend the above framework with cross cloud testing scenario involving communications between heterogeneous cloud hosts. The results shows that the cloud environment ensures more flexible and quality of services.},
  doi       = {10.1109/WiSPNET.2016.7566494},
}

@InProceedings{Jelassi2017,
  author    = {Jelassi, Mariem and Ghazel, Cherif and Saïdane, Leila Azzouz},
  booktitle = {2017 3rd International Conference on Frontiers of Signal Processing (ICFSP)},
  title     = {A survey on quality of service in cloud computing},
  year      = {2017},
  month     = {Sep.},
  pages     = {63-67},
  abstract  = {The quality of service is one of challenges posed by the Cloud Computing. This issue plays an important role in making the Cloud services acceptable to customers, denotes the levels of performance, reliability, and availability offered by Cloud services. Literature has reported many implementations for measuring and ensuring QoS in Cloud Computing systems to achieve better results and meet the needs of producers and consumers. In this paper, we have presented a survey on QoS in Cloud Computing, the mechanisms and methods to guarantee quality of service (QoS) used to Cloud Computing services.},
  doi       = {10.1109/ICFSP.2017.8097142},
}

@InProceedings{Abdeladim2014,
  author    = {Abdeladim, Alfath and Baina, Salah and Baina, Karim},
  booktitle = {2014 Third IEEE International Colloquium in Information Science and Technology (CIST)},
  title     = {Elasticity and scalability centric quality model for the cloud},
  year      = {2014},
  month     = {Oct},
  pages     = {135-140},
  abstract  = {Cloud computing seems to be the most logical shift in terms of Information Technology after Internet, Social Networking. Despite the potential benefits that cloud computing offers, the model brings new issues, challenges, and needs in term of SLA formalization, Quality of Service (QoS) evaluation due to the heterogeneous resources and to the special features it implies, such as Elasticity and Scalability. In the scope of this paper we focus on the Elasticity and Scalability attributes to assess their impact on the QoS. The paper provides a multi-lenses overview that can help both cloud consumers and potential business application's owners to understand, analyze, and evaluate important aspects related to Scalability and Elasticity capabilities. We determine and analyze the key features of these characteristics and derive metrics that evaluate the cloud elasticity-centric capabilities. We present a specific quality model for those two characteristics derived from their sub-attributes.},
  doi       = {10.1109/CIST.2014.7016607},
  issn      = {2327-1884},
}

@InProceedings{Ravanello2014,
  author    = {Ravanello, Anderson and Desharnais, Jean-Marc and Bautista Villalpando, Luis Eduardo and April, Alain and Gherbi, Abdelouahed},
  booktitle = {2014 Joint Conference of the International Workshop on Software Measurement and the International Conference on Software Process and Product Measurement},
  title     = {Performance Measurement for Cloud Computing Applications Using ISO 25010 Standard Characteristics},
  year      = {2014},
  month     = {Oct},
  pages     = {41-49},
  abstract  = {Measuring the performance of cloud computing-based applications using ISO quality characteristics is a complex activity for various reasons, among them the complexity of the typical cloud computing infrastructure on which an application operates. To address this issue, the authors use Bautista's proposed performance measurement framework [1] on log data from an actual data centre to map and statistically analyze one of the ISO quality characteristics: time behavior. This empirical case study was conducted on an industry private cloud. The results of the study demonstrate that it is possible to use the proposed performance measurement framework in a cloud computing context. They also show that the framework holds great promise for expanding the experimentation to other ISO quality characteristics, larger volumes of data, and other statistical techniques that could be used to analyze performance.},
  doi       = {10.1109/IWSM.Mensura.2014.33},
}

@InProceedings{Althani2016,
  author    = {Althani, B. and Khaddaj, S. and Makoond, B.},
  booktitle = {2016 IEEE Intl Conference on Computational Science and Engineering (CSE) and IEEE Intl Conference on Embedded and Ubiquitous Computing (EUC) and 15th Intl Symposium on Distributed Computing and Applications for Business Engineering (DCABES)},
  title     = {A Quality Assured Framework for Cloud Adaptation and Modernization of Enterprise Applications},
  year      = {2016},
  month     = {Aug},
  pages     = {634-637},
  abstract  = {Cloud Computing has emerged as a viable alternative to in-house computing resources for many organisations. It offers an alternative solution for many enterprise applications, particularly large-scale legacy applications. In addition, it can offer a cost effective strategy for small and medium-sized enterprises (SMEs) where the high set-up and maintenance cost of computing resources can be prohibiting. Thus, in this paper a System Migration Life Cycle (SMLC) framework is proposed, which includes a step by-stepmigration strategy that is descriptive at the business analyst level and based on quality metrics modelling at the technical level, to estimate the potential computational needs, risks, and costs for an organisation. The proposed framework is generic and adaptable in order to accommodate various organisational requirements, thus covering a wide range of enterprise applications and following a number of novel software requirements and quality engineering principles.},
  doi       = {10.1109/CSE-EUC-DCABES.2016.251},
}

@InProceedings{Haupt2017a,
  author    = {Haupt, Florian and Leymann, Frank and Scherer, Anton and Vukojevic-Haupt, Karolina},
  booktitle = {2017 IEEE International Conference on Software Architecture (ICSA)},
  title     = {A Framework for the Structural Analysis of REST APIs},
  year      = {2017},
  month     = {April},
  pages     = {55-58},
  abstract  = {Today, REST APIs have established as a means for realizing distributed systems and are supposed to gain even more importance in the context of Cloud Computing, Internet of Things, and Microservices. Nevertheless, many existing REST APIs are known to be not well-designed, resulting in the absence of desirable quality attributes that truly RESTful systems entail. Although existing analysis show, that many REST APIs are not fully REST compliant, it is still an open issue how to improve this deficit and where to start. In this work, we introduce a framework for the structural analysis of REST APIs based on their description documents, as this allows for a comprehensive, well-structured analysis approach that also includes analyzing the corresponding API description languages. A first validation builds on a set of 286 real world API descriptions available as Swagger documents, and comprises their transformation into a canonical metamodel for REST APIs as well as a metrics-based analysis and discussion of their structural characteristics with respect to compliance with the REST architectural style.},
  doi       = {10.1109/ICSA.2017.40},
}

@InProceedings{Papakonstantinou2020,
  author    = {Papakonstantinou, Ioannis and Kalafatidis, Sarantis and Mamatas, Lefteris},
  booktitle = {2020 16th International Conference on Network and Service Management (CNSM)},
  title     = {A Techno-Economic Assessment of Microservices},
  year      = {2020},
  month     = {Nov},
  pages     = {1-5},
  abstract  = {The microservices design paradigm enables applications, usually based on containers, exploiting the flexibility of cloud computing and bringing unique scalability, fault-tolerance and resource-allocation benefits. A number of orchestration facilities, including Kubernetes, target the efficient deployment and operation of containers and are mainly focusing on the maintenance of server resource allocation under predefined thresholds, i.e., through scaling up or down containers to mitigate dynamic changes in the workload. In this work, we highlight the technical capabilities and cost-saving impact of microservices in contrast to traditional monolithic applications, based on a techno-economic analysis. We also investigate the service performance vs resource allocation trade-off, uncovering interesting dynamics when elasticity is driven from service quality metrics. This approach allows the Service Providers (SPs) to balance their profit margins with the customer satisfaction, i.e., reducing the infrastructure cost while keeping the service performance at an acceptable level.},
  doi       = {10.23919/CNSM50824.2020.9269114},
  issn      = {2165-963X},
}

@Article{Ala’anzy2019,
  author   = {Ala’anzy, Mohammed and Othman, Mohamed},
  journal  = {IEEE Access},
  title    = {Load Balancing and Server Consolidation in Cloud Computing Environments: A Meta-Study},
  year     = {2019},
  issn     = {2169-3536},
  pages    = {141868-141887},
  volume   = {7},
  abstract = {The data-center is considered the heart of cloud computing. Recently, the growing demand for cloud computing services has caused a growing load on data centers. In terms of system behavior and workload, patterns of cloud computing are very dynamic; and that might serve to imbalance the load among data center resources. Eventually, some data-center resources could come to be over-loaded/under-loaded, which leads to an increase in energy consumption in addition to decreased functioning and wastage of resources. Just considering energy-efficiency (that can be attained efficiently by consolidate the servers) may not be enough for real applications because it may cause problems such as unbalanced load for each Physical Machine (PM). Therefore, this paper surveys published load balancing algorithms that achieved by server consolidation via a meta-analysis. Load balancing with server consolidation enriches the exploitation of resource utilization and can enhance Quality of Service (QoS) metrics, since data-centers and their applications are increasing exponentially. This meta-study, reviews the literature on load balancing and server consolidation and presents a ready reference taxonomy on the most efficient algorithms that achieve load balancing and server consolidation. This work attempts to present a taxonomy with a new classification for load balancing and server consolidation, such as migration overhead, hardware threshold, network traffic, and reliability.},
  doi      = {10.1109/ACCESS.2019.2944420},
}

@Article{Peng2017,
  author   = {Peng, Kuan-Li and Huang, Chin-Yu},
  journal  = {IEEE Transactions on Services Computing},
  title    = {Reliability Analysis of On-Demand Service-Based Software Systems Considering Failure Dependencies},
  year     = {2017},
  issn     = {1939-1374},
  month    = {May},
  number   = {3},
  pages    = {423-435},
  volume   = {10},
  abstract = {Service-based software systems (SBSSs) are widely deployed due to the growing trend of distributed computing and cloud computing. It is important to ensure high quality of an SBSS, especially in a strongly competitive market. Existing works on SBSS reliability usually assumed independence of service failures. However, the fact that resource sharing exists in different levels of SBSS operations invalidates this assumption. Ignorance of failure dependencies have been discussed as potentially affecting system reliability predictions and lowering the benefits of design diversity, as typically seen in high-reliability systems. In this paper, we propose a reliability framework that incorporates failure dependence modeling, system reliability modeling, as well as reliability analysis for individual services and for failure sources. The framework is also capable of analyzing the internal structures of popular software fault tolerant (FT) schemes. The proposed method is applied to a travel agency system based upon a real-world practice for verifying its accuracy of reliability modeling and effectiveness of varied reliability measures. The results show that failure dependence of the services is an essential factor for analyzing any valuable SBSS system. Further, a set of reliability measures with different capabilities and complexities are available for assisting SBSS engineers with system improvements.},
  doi      = {10.1109/TSC.2015.2473843},
}

@InProceedings{Toka2021a,
  author    = {Toka, Laszlo and Dobreff, Gergely and Haja, David and Szalay, Mark},
  booktitle = {2021 IFIP/IEEE International Symposium on Integrated Network Management (IM)},
  title     = {Predicting cloud-native application failures based on monitoring data of cloud infrastructure},
  year      = {2021},
  month     = {May},
  pages     = {842-847},
  abstract  = {The quality of service provided by cloud-deployed online applications is often affected by faults in the underlying cloud platform and infrastructure. In order to discover the cause and effect at application failures, a cloud monitoring system must be in place. The sheer amount of the produced monitoring data calls for smart and automatic handling in order to find the patterns that can be used for fault management. In this paper we present an open source, cloud-native, lightweight cloud monitoring system, and a data analytics pipeline that efficiently processes the gathered data and is able to discover useful inference between infrastructure-, and application-level metrics. We apply time series clustering steps within the pipeline to compress the collected data for fast and lightweight data mining. We show the capabilities of our proposed system in a reactive and a proactive use case. The results prove that the proposed system brings precious insights for root-cause analysis and proactive fault management frameworks of cloud applications.},
  issn      = {1573-0077},
}

@InProceedings{Klinaku2021,
  author    = {Klinaku, Floriment and Hakamian, Alireza and Becker, Steffen},
  booktitle = {2021 IEEE International Conference on Autonomic Computing and Self-Organizing Systems (ACSOS)},
  title     = {Architecture-based Evaluation of Scaling Policies for Cloud Applications},
  year      = {2021},
  month     = {Sep.},
  pages     = {151-157},
  abstract  = {The cloud computing model enables organizations to employ policies for the automated provisioning of computing resources. The impact on the quality, such as performance or cost, of such policies is often unknown for complex, large, and highly distributed cloud applications. Software architects lack a feasible approach to evaluate scaling policies for their cloud application quantitatively. While approaches exist in the literature, they are costly and require a high effort. We propose an approach that utilizes modeling and terminating simulations to evaluate alternative styles and configurations for cloud scaling policies. The approach aids the architect in understanding and explaining their dynamic behavior and the existing trade-offs. Third, we conduct simulation experiments on a representative case study model to show the approach&#x0027;s feasibility. We evaluate the performance, cost, efficiency, and complexity of three scaling policies of different styles (e.g., centralized vs. decentralized) on a model. Results show that the policies improve the performance for the selected scenario. However, no significant difference among them exists in terms of performance. Other metrics highlight the present trade-offs across policies. All in all, the case shows that the approach helps architects refine the style and find an appropriate policy for their context.},
  doi       = {10.1109/ACSOS52086.2021.00035},
}

@Article{Liu2021a,
  author   = {Liu, Li and Lu, Caiwu and Xiao, Fengjun and Liu, Ruimin and Xiong, Neal Naixue},
  journal  = {IEEE Access},
  title    = {A Practical, Integrated Multi-Criteria Decision-Making Scheme for Choosing Cloud Services in Cloud Systems},
  year     = {2021},
  issn     = {2169-3536},
  pages    = {88391-88404},
  volume   = {9},
  abstract = {Currently, with the rapid development and broad application of cloud computing technology, companies tend to use cloud services to build their applications or business systems. Selecting a trustworthy cloud service is a challenging multi-criteria decision-making (MCDM) problem. Moreover, decision makers are more inclined to use linguistic descriptions to assess the quality of service (QoS) for cloud services due to the limitation of the decision makers' knowledge and the vagueness of criteria information. Therefore, we propose a practical, integrated MCDM scheme for cloud service evaluation and selection of cloud systems, allowing decision makers to compare cloud services based on QoS criteria. First, to more accurately and effectively express the uncertainty of qualitative concepts, the cloud model is used as a conversion tool for qualitative and quantitative information to quantify linguistic terms. Second, given the shortcomings of traditional differentiating measures between cloud models, a more comprehensive distance measurement algorithm using cloud droplet distribution is proposed for the cloud model. The new distance measurement algorithm is applied to the calculation of cloud model similarity and the gray correlation coefficient. The dynamic expertise weights are determined by calculating the similarity between the expert evaluation cloud model and the arithmetic mean cloud model. Then, we propose a technique for order preference by similarity to an ideal solution (TOPSIS) improved by the grey relational analysis (GRA) to calculate the relative closeness of alternatives to the positive and negative ideal solutions and establish a multi-objective optimization model that maximizes the relative closeness of all alternatives to determine the weights of the criteria. Finally, we reconstructed the QoS evaluation criteria for cloud services from both application and service perspectives, and the classical TOPSIS is applied to generate alternative rankings. The practicability and robustness of the scheme were tested through the cloud service selection problem experienced by a real mining company's scheduling platform, which can provide practical references with the theoretical basis for the selection and evaluation of cloud services.},
  doi      = {10.1109/ACCESS.2021.3089991},
}

@Article{Mahmoudi2022,
  author   = {Mahmoudi, Nima and Khazaei, Hamzeh},
  journal  = {IEEE Transactions on Cloud Computing},
  title    = {Performance Modeling of Serverless Computing Platforms},
  year     = {2022},
  issn     = {2168-7161},
  month    = {Oct},
  number   = {4},
  pages    = {2834-2847},
  volume   = {10},
  abstract = {Analytical performance models have been leveraged extensively to analyze and improve the performance and cost of various cloud computing services. However, in the case of serverless computing, which is projected to be the dominant form of cloud computing in the future, we have not seen analytical performance models to help with the analysis and optimization of such platforms. In this work, we propose an analytical performance model that captures the unique details of serverless computing platforms. The model can be leveraged to improve the quality of service and resource utilization and reduce the operational cost of serverless platforms. Also, the proposed performance model provides a framework that enables serverless platforms to become workload-aware and operate differently for different workloads to provide a better trade-off between the cost and performance depending on the user's preferences. The current serverless offerings require the user to have extensive knowledge of the internals of the platform to perform efficient deployments. Using the proposed analytical model, the provider can simplify the deployment process by calculating the performance metrics for users even before physical deployments. We validate the applicability and accuracy of the proposed model by extensive experimentation on AWS Lambda. We show that the proposed model can calculate essential performance metrics such as average response time, probability of cold start, and the average number of function instances in the steady-state. Also, we show how the performance model can be used to tune the serverless platform for each workload, which will result in better performance or lower cost without scarifying the other. The presented model assumes no non-realistic restrictions, so that it offers a high degree of fidelity while maintaining tractability at large scale.},
  doi      = {10.1109/TCC.2020.3033373},
}

 
@Article{Rajput2020,
  author    = {Rajput, Pushpendra Kumar and Sikka, Geeta},
  journal   = {Journal of Ambient Intelligence and Humanized Computing},
  title     = {Multi-agent architecture for fault recovery in self-healing systems},
  year      = {2020},
  issn      = {1868-5145},
  month     = aug,
  number    = {2},
  pages     = {2849–2866},
  volume    = {12},
  abstract  = {Self-healing, a prominent property of self-adaptiveness provides reliability, availability, maintainability, and survivability to a software system. These qualitative factors are very salient to modern distributed systems in which components and their collaboration often vary. Survivability of such systems can be best addressed from an architectural viewpoint. When it comes to maintainability and reliability, architectural level adaptation is not often supported during the design phase. Adaptation to fault tolerance into the design phase of the system development process can increase the scope of software availability and thereby attaining self-healing. In distributed systems, most of the existing architectures are often associated with communication and correspondence as primary criteria. On the other hand, a multi-agent mechanism helps in schematic control of functionality, communication by emphasizing scalability. In this paper, a novel architecture was proposed that could support agent-based distributed systems to address fault recovery aspects for achieving self-adaptiveness. Unlike traditional multi-agent architecture, task-oriented functional multi-agent communication is incorporated for various activities during design phase designated to perform self-healing criteria. An adaptation of agent communication control flow is proposed using three novel mechanism such as planning, functioning and enacting as agents’ critical responsibility. The paper also validates the proposed architecture for resource and availability based faults related to crash and resource unavailability using performance-based evaluation metrics. A case-based application with single thread connectivity is used to reflect the architecture during application design phase and is tested for success using mean response time as evaluation metric.},
  doi       = {10.1007/s12652-020-02443-8},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s12652-020-02443-8},
}

 
@Article{Haoues2016,
  author    = {Haoues, Mariem and Sellami, Asma and Ben-Abdallah, Hanêne and Cheikhi, Laila},
  journal   = {International Journal of System Assurance Engineering and Management},
  title     = {A guideline for software architecture selection based on ISO 25010 quality related characteristics},
  year      = {2016},
  issn      = {0976-4348},
  month     = nov,
  number    = {S2},
  pages     = {886–909},
  volume    = {8},
  abstract  = {As the complexity of software increases, the choice of the appropriate software architecture becomes a critical task. This paper provides a guideline for selecting the appropriate software architecture based on pertinent ISO 25010 quality characteristics. The guideline was established through an analytical survey of 113 papers published from 2010 to 2014. Through this survey, we first identified a set of commonly used software architectures in the software engineering literature. Secondly, we applied the Formal Concept Analysis technique to classify each one of these architectures according to ISO 25010 quality characteristics. Finally, we identified the relationships among ISO 25010 quality characteristics, which in turn helped us to develop a guideline on how to select the appropriate software architecture with respect to ISO 25010 quality characteristics. In order to make sure about the validation of the proposed guideline, a survey with industrial experts is in progress. Data were collected from two companies working in the software development field (ST2i and Telnet).},
  doi       = {10.1007/s13198-016-0546-8},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s13198-016-0546-8},
}

 
@InBook{Ntentos2021,
  author    = {Ntentos, Evangelos and Zdun, Uwe and Plakidas, Konstantinos and Geiger, Sebastian},
  pages     = {188–203},
  publisher = {Springer International Publishing},
  title     = {Evaluating and Improving Microservice Architecture Conformance to Architectural Design Decisions},
  year      = {2021},
  isbn      = {9783030914318},
  abstract  = {Microservices are a commonly used architectural style targeting independent development, deployment, and release of services, as well as supporting polyglot capabilities and rapid release strategies. This depends on the presence of certain software architecture qualities. A number of architecture patterns and best practices that support the required qualities have been proposed in the literature, but usually in isolation of one another. Additionally, in real-world systems, assessing conformance to these patterns and practices and detecting possible violations is a significant challenge. For small-scale systems of a few services, a manual assessment and violation detection by an expert is probably both accurate and sufficient. However, for industrial-scale systems of several hundred or more services, manual assessment and violation detection is laborious and likely leads to inaccurate results. Furthermore, manual assessment is impractical for rapidly evolving and frequently released system architectures. In this work we examine a subset of microservice-relevant patterns, and propose a method for the semi-automatic detection and resolution of conformance violations. Our aim is to assist the software architect by providing a set of possible fix options and generating models of “fixed” architectures.},
  booktitle = {Lecture Notes in Computer Science},
  doi       = {10.1007/978-3-030-91431-8_12},
  issn      = {1611-3349},
  url       = {http://dx.doi.org/10.1007/978-3-030-91431-8_12},
}

 
@Article{ReyesDelgado2021,
  author    = {Reyes-Delgado, Paola Y. and Duran-Limon, Hector A. and Mora, Manuel and Rodriguez-Martinez, Laura C.},
  journal   = {Software and Systems Modeling},
  title     = {SOCAM: a service-oriented computing architecture modeling method},
  year      = {2021},
  issn      = {1619-1374},
  month     = nov,
  number    = {4},
  pages     = {1551–1581},
  volume    = {21},
  abstract  = {Software architecture models are considered first-class artifacts in current software engineering best practices. Thus, usable and well-understood modeling methods are required for software architects. For this aim, several specific software architecture modeling methods as well as generic design methods included in software development methodologies are available. However, we believe, there is the lack of more specific guidance in current software architecture methods. One of the principal causes of such a lack of specific guidance is the general-purpose nature of these methods. Therefore, further efforts are required to define domain-specific software architecture methods. In this paper, we present SOCAM, a software architecture modeling method for Web Service-Oriented Systems. We illustrate the use of SOCAM with a customization of the well-known SOA test application case: the Sun Adventure Builder system. A comparative analysis of SOCAM with other methods reveals a number of benefits of our method over the other approaches. Also, a survey research method evaluation confirms some of these benefits such as the fact that SOCAM is perceived as more useful than certain general-purpose methods.},
  doi       = {10.1007/s10270-021-00946-2},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s10270-021-00946-2},
}

 
@Article{Kosinska2023,
  author    = {Kosińska, Joanna and Zieliński, Krzysztof},
  journal   = {Journal of Grid Computing},
  title     = {Enhancement of Cloud-native applications with Autonomic Features},
  year      = {2023},
  issn      = {1572-9184},
  month     = jul,
  number    = {3},
  volume    = {21},
  abstract  = {The Autonomic Computing paradigm reduces complexity in installing, configuring, optimizing, and maintaining heterogeneous systems. Despite first discussing it a long ago, it is still a top research challenge, especially in the context of other technologies. It is necessary to provide autonomic features to the Cloud-native execution environment to meet the rapidly changing demands without human support and continuous improvement of their capabilities. The present work attempts to answer how to explore autonomic features in Cloud-native environments. As a solution, we propose using the AMoCNA framework. It is rooted in Autonomic Computing. The success factors for the AMoCNA implementation are its execution controllers. They drive the management actions proceeding in a Cloud-native execution environment. A similar concept already exists in Kubernetes, so we compare both execution mechanisms. This research presents guidelines for including autonomic features in Cloud-native environments. The integration of Cloud-native Applications with AMoCNA leads to facilitating autonomic management. To show the potential of our concept, we evaluated it. The developed executor performs cluster autoscaling and ensures autonomic management in the infrastructure layer. The experiment also proved the importance of observations. The knowledge gained in this process is a good authority of information about past and current state of Cloud-native Applications. Combining this knowledge with defined executors provides an effective means of achieving the autonomic nature of Cloud-native applications.},
  doi       = {10.1007/s10723-023-09675-w},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s10723-023-09675-w},
}

 
@Article{ZargarAzad2023,
  author    = {ZargarAzad, Matineh and Ashtiani, Mehrdad},
  journal   = {Journal of Grid Computing},
  title     = {An Auto-Scaling Approach for Microservices in Cloud Computing Environments},
  year      = {2023},
  issn      = {1572-9184},
  month     = nov,
  number    = {4},
  volume    = {21},
  abstract  = {Recently, microservices have become a commonly-used architectural pattern for building cloud-native applications. Cloud computing provides flexibility for service providers, allowing them to remove or add resources depending on the workload of their web applications. If the resources allocated to the service are not aligned with its requirements, instances of failure or delayed response will increase, resulting in customer dissatisfaction. This problem has become a significant challenge in microservices-based applications, because thousands of microservices in the system may have complex interactions. Auto-scaling is a feature of cloud computing that enables resource scalability on demand, thus allowing service providers to deliver resources to their applications without human intervention under a dynamic workload to minimize resource cost and latency while maintaining the quality of service requirements. In this research, we aimed to establish a computational model for analyzing the workload of all microservices. To this end, the overall workload entering the system was considered, and the relationships and function calls between microservices were taken into account, because in a large-scale application with thousands of microservices, accurately monitoring all microservices and gathering precise performance metrics are usually difficult. Then, we developed a multi-criteria decision-making method to select the candidate microservices for scaling. We have tested the proposed approach with three datasets. The results of the conducted experiments show that the detection of input load toward microservices is performed with an average accuracy of about 99% which is a notable result. Furthermore, the proposed approach has demonstrated a substantial enhancement in resource utilization, achieving an average improvement of 40.74%, 20.28%, and 28.85% across three distinct datasets in comparison to existing methods. This is achieved by a notable reduction in the number of scaling operations, reducing the count by 54.40%, 55.52%, and 69.82%, respectively. Consequently, this optimization translates into a decrease in required resources, leading to cost reductions of 1.64%, 1.89%, and 1.67% respectively.},
  doi       = {10.1007/s10723-023-09713-7},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s10723-023-09713-7},
}

 
@Article{Bento2023,
  author    = {Bento, Andre and Araujo, Filipe and Barbosa, Raul},
  journal   = {Journal of Grid Computing},
  title     = {Cost-Availability Aware Scaling: Towards Optimal Scaling of Cloud Services},
  year      = {2023},
  issn      = {1572-9184},
  month     = dec,
  number    = {4},
  volume    = {21},
  abstract  = {Cloud services have become increasingly popular for developing large-scale applications due to the abundance of resources they offer. The scalability and accessibility of these resources have made it easier for organizations of all sizes to develop and implement sophisticated and demanding applications to meet demand instantly. As monetary fees are involved in the use of the cloud, one of the challenges for application developers and operators is to balance their budget constraints with crucial quality attributes, such as availability. Industry standards usually default to simplified solutions that cannot simultaneously consider competing objectives. Our research addresses this challenge by proposing a Cost-Availability Aware Scaling (CAAS) approach that uses multi-objective optimization of availability and cost. We evaluate CAAS using two open-source microservices applications, yielding improved results compared to the industry standard CPU-based Autoscaler (AS). CAAS can find optimal system configurations with higher availability, between 1 and 2 nines on average, and reduced costs, 6% on average, with the first application, and 1 nine of availability on average, and reduced costs up to 18% on average, with the second application. The gap in the results between our model and the default AS suggests that operators can significantly improve the operation of their applications.},
  doi       = {10.1007/s10723-023-09718-2},
  publisher = {Springer Science and Business Media LLC},
  url       = {http://dx.doi.org/10.1007/s10723-023-09718-2},
}

 
@InBook{Abdelfattah2023,
  author    = {Abdelfattah, Amr S. and Cerny, Tomas and Salazar, Jorge Yero and Lehman, Austin and Hunter, Joshua and Bickham, Ashley and Taibi, Davide},
  pages     = {35–51},
  publisher = {Springer Nature Switzerland},
  title     = {End-to-End Test Coverage Metrics in Microservice Systems: An Automated Approach},
  year      = {2023},
  isbn      = {9783031462351},
  abstract  = {Microservice architecture gains momentum by fueling systems with cloud-native benefits, scalability, and decentralized evolution. However, new challenges emerge for end-to-end (E2E) testing. Testers who see the decentralized system through the user interface might assume their tests are comprehensive, covering all middleware endpoints scattered across microservices. However, they do not have instruments to verify such assumptions. This paper introduces test coverage metrics for evaluating the extent of E2E test suite coverage for microservice endpoints. Next, it presents an automated approach to compute these metrics to provide feedback on the completeness of E2E test suites. Furthermore, a visual perspective is provided to highlight test coverage across the system’s microservices to guide on gaps in test suites. We implement a proof-of-concept tool and perform a case study on a well-established system benchmark showing it can generate conclusive feedback on test suite coverage over system endpoints.},
  booktitle = {Lecture Notes in Computer Science},
  doi       = {10.1007/978-3-031-46235-1_3},
  issn      = {1611-3349},
  url       = {http://dx.doi.org/10.1007/978-3-031-46235-1_3},
}

 
@InBook{Riccio2023,
  author    = {Riccio, Vincenzo and Sorrentino, Giancarlo and Camilli, Matteo and Mirandola, Raffaela and Scandurra, Patrizia},
  pages     = {227–242},
  publisher = {Springer Nature Switzerland},
  title     = {Engineering Self-adaptive Microservice Applications: An Experience Report},
  year      = {2023},
  isbn      = {9783031484216},
  abstract  = {This paper reports our experience in engineering RAMSES, a Reusable Autonomic Manager for microServicES that conforms to the well-known MAPE-K feedback control loop model to realize self-adaptive microservices. The goal of RAMSES is to enforce the satisfaction of user-defined QoS attributes (e.g., availability, performance) of a microservice application at runtime. RAMSES’s control loop components themselves are microservices. RAMSES is designed to ease its reuse across microservice applications. To illustrate RAMSES, we describe how we used it for making self-adaptive an e-food microservice application. We report the results of an experimental evaluation we conducted to validate the capability of RAMSES. Finally, we discuss our experience in facing existing challenges as well as the main lessons learned.},
  booktitle = {Lecture Notes in Computer Science},
  doi       = {10.1007/978-3-031-48421-6_16},
  issn      = {1611-3349},
  url       = {http://dx.doi.org/10.1007/978-3-031-48421-6_16},
}

@InProceedings{Chauvel2014,
  author    = {Chauvel, Franck and Song, Hui and Ferry, Nicolas and Fleurey, Franck},
  booktitle = {Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing},
  title     = {Robustness Indicators for Cloud-Based Systems Topologies},
  year      = {2014},
  address   = {USA},
  pages     = {307–316},
  publisher = {IEEE Computer Society},
  series    = {UCC '14},
  abstract  = {Various services are now available in the Cloud, ranging from turnkey databases and application servers to high-level services such as continuous integration or source version control. To stand out of this diversity, robustness of service compositions is an important selling argument, but which remains difficult to understand and estimate as it does not only depend on services but also on the underlying platform and infrastructure. Yet, choosing a specific service composition may fail to deliver the expected robustness, but reverting early choices may jeopardise the success of any Cloud project. Inspired by existing models used in Biology to quantify the robustness of ecosystems, we show how to tailor them to obtain early indicators of robustness for cloud-based deployments. This technique helps identify weakest services in the overall architecture and in turn mitigates the risk of having to revert key architectural choices. We illustrate our approach by comparing the robustness of four alternative deployments of the Sens App application, which includes a Mongo DB database, four REST services and a graphical web-front end.},
  doi       = {10.1109/UCC.2014.40},
  isbn      = {9781479978816},
  keywords  = {robustness indicators, failures sequences, extinction sequences, cloud topologies, deployment, bio-inspired},
  numpages  = {10},
  url       = {https://doi.org/10.1109/UCC.2014.40},
}

@InProceedings{Alzboon2022,
  author    = {Alzboon, Ghufran and Al-Said Ahmad, Amro},
  booktitle = {Proceedings of the 2022 6th International Conference on Cloud and Big Data Computing},
  title     = {A Performance Evaluation Approach for N-Tier Cloud-Based Software Services},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {31–36},
  publisher = {Association for Computing Machinery},
  series    = {ICCBDC '22},
  abstract  = {Cloud computing and cloud testing are vast fields that have attracted significant attention recently. In addition, the need to find an approach for measuring cloud-based applications' effectiveness has also increased. In this work, we introduced an approach to testing the performance of the cloud software services on the Amazon cloud. We used two cloud-based applications hosted in the Amazon cloud to demonstrate the approach depending on five technical performance metrics. We applied the testing methodology using a JMeter test script. The two selected applications represent two different taxonomies: 2-tier and 3-tier architectures. Following the testing process, we found that the WordPress application (i.e., 3-tier architecture) performs better than Ghost and is more stable in terms of the selected performance metrics. Practitioners would benefit from this study by a better understanding of the assessment and testing of n-tier Cloud-Based Software Services using technical arguments.},
  doi       = {10.1145/3555962.3555968},
  isbn      = {9781450396578},
  keywords  = {evaluation method, Cloud computing, n-tier, Software services, performance},
  location  = {Birmingham, United Kingdom},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3555962.3555968},
}

@Article{Burckhardt2022,
  author     = {Burckhardt, Sebastian and Chandramouli, Badrish and Gillum, Chris and Justo, David and Kallas, Konstantinos and McMahon, Connor and Meiklejohn, Christopher S. and Zhu, Xiangfeng},
  journal    = {Proc. VLDB Endow.},
  title      = {Netherite: Efficient Execution of Serverless Workflows},
  year       = {2022},
  issn       = {2150-8097},
  month      = {apr},
  number     = {8},
  pages      = {1591–1604},
  volume     = {15},
  abstract   = {Serverless is a popular choice for cloud service architects because it can provide scalability and load-based billing with minimal developer effort. Functions-as-a-service (FaaS) are originally stateless, but emerging frameworks add stateful abstractions. For instance, the widely used Durable Functions (DF) allow developers to write advanced serverless applications, including reliable workflows and actors, in a programming language of choice. DF implicitly and continuosly persists the state and progress of applications, which greatly simplifies development, but can create an IOps bottleneck.To improve efficiency, we introduce Netherite, a novel architecture for executing serverless workflows on an elastic cluster. Netherite groups the numerous application objects into a smaller number of partitions, and pipelines the state persistence of each partition. This improves latency and throughput, as it enables workflow steps to group commit, even if causally dependent. Moreover, Netherite leverages FASTER's hybrid log approach to support larger-than-memory application state, and to enable efficient partition movement between compute hosts.Our evaluation shows that (a) Netherite achieves lower latency and higher throughput than the original DF engine, by more than an order of magnitude in some cases, and (b) that Netherite has lower latency than some commonly used alternatives, like AWS Step Functions or cloud storage triggers.},
  doi        = {10.14778/3529337.3529344},
  issue_date = {April 2022},
  numpages   = {14},
  publisher  = {VLDB Endowment},
  url        = {https://doi.org/10.14778/3529337.3529344},
}

@InProceedings{Weerasinghe2021,
  author    = {Weerasinghe, L. D. S. B. and Perera, Indika},
  booktitle = {2021 International Research Conference on Smart Computing and Systems Engineering (SCSE)},
  title     = {An exploratory evaluation of replacing ESB with microservices in service-oriented architecture},
  year      = {2021},
  month     = {Sep.},
  pages     = {137-144},
  volume    = {4},
  abstract  = {With the continuous progress in technology during the past few decades, cloud computing has become a fast-growing technology in the world, making computerized systems widespread. The emergence of Cloud Computing has evolved towards microservice concepts, which are highly demanded by corporates for enterprise application level. Most enterprise applications have moved away from traditional unified models of software programs like monolithic architecture and traditional SOA architecture to microservice architecture to ensure better scalability, lesser investment in hardware, and high performance. The monolithic architecture is designed in a manner that all the components and the modules are packed together and deployed on a single binary. However, in the microservice architecture, components are developed as small services so that horizontally and vertically scaling is made easier in comparison to monolith or SOA architecture. SOA and monolithic architecture are at a disadvantage compared to Microservice architecture, as they require colossal hardware specifications to scale the software. In general terms, the system performance of these architectures can be measured considering different aspects such as system capacity, throughput, and latency. This research focuses on how scalability and performance software quality attributes behave when converting the SOA system to microservice architecture. Experimental results have shown that microservice architecture can bring more scalability with a minimum cost generation. Nevertheless, specific gaps in performance are identified in the perspective of the final user experiences due to the interservice communication in the microservice architecture in a distributed environment.},
  doi       = {10.1109/SCSE53661.2021.9568289},
  issn      = {2613-8662},
}

@Article{Sebrechts2022,
  author   = {Sebrechts, Merlijn and Volckaert, Bruno and De Turck, Filip and Yang, Kun and Al-Naday, Mays},
  journal  = {IEEE Communications Magazine},
  title    = {Fog Native Architecture: Intent-Based Workflows to Take Cloud Native toward the Edge},
  year     = {2022},
  issn     = {1558-1896},
  month    = {August},
  number   = {8},
  pages    = {44-50},
  volume   = {60},
  abstract = {The cloud native approach is rapidly transforming how applications are developed and operated, turning monolithic applications into microservice applications, allowing teams to release faster, increase reliability, and expedite operations by taking full advantage of cloud resources and their elasticity. At the same time, “fog computing” is emerging, bringing the cloud toward the edge, near the end user, in order to increase privacy, improve resource efficiency, and reduce latency. Combining these two trends, however, proves difficult because of four fundamental disconnects between the cloud native paradigm and fog computing. This article identifies these disconnects and proposes a fog native architecture along with a set of design patterns to take full advantage of the fog. Central to this approach is turning microservice applications into microservice workflows, constructed dynamically by the system using an intent-based approach taking into account a number of factors such as user requirements, request location, and available infrastructure and microservices. The architecture introduces a novel softwarized fog mesh facilitating both inter-microservice connectivity, external communication, and end-user aggregation. Our evaluation analyzes the impact of distributing microservice-based applications over a fog ecosystem, illustrating the impact of CPU and network latency and application metrics on perceived quality of service of fog native workflows compared to the cloud. The results show the fog can offer superior application performance given the right conditions.},
  doi      = {10.1109/MCOM.003.2101075},
}

@Article{Yu2022,
  author   = {Yu, Guangba and Chen, Pengfei and Zheng, Zibin},
  journal  = {IEEE Transactions on Cloud Computing},
  title    = {Microscaler: Cost-Effective Scaling for Microservice Applications in the Cloud With an Online Learning Approach},
  year     = {2022},
  issn     = {2168-7161},
  month    = {April},
  number   = {2},
  pages    = {1100-1116},
  volume   = {10},
  abstract = {Recently, the microservice becomes a popular architecture to construct cloud native systems due to its agility. In cloud native systems, autoscaling is a key enabling technique to adapt to workload changes by acquiring or releasing the right amount of computing resources. However, it becomes a challenging problem in microservice applications, since such an application usually comprises a large number of different microservices with complex interactions. When the performance decreases due to an unpredictable workload peak, it is difficult to pinpoint the scaling-needed services which need to scale out and evaluate how many resources they need. In this article, we present a novel system named Microscaler to automatically identify the scaling-needed services and scale them to meet the Service Level Agreement (SLA) with an optimal cost for microservice applications. Microscaler first collects the quality of service (QoS) metrics in the service mesh enabled microservice infrastructure. Then, it determines under-provisioning or over-provisioning service instances along the service dependency graph with a novel scaling-needed service criterion named service power. The service dependency graph could be obtained by correlating each request flow in the service mesh. By combining an online learning approach and a step-by-step heuristic approach, Microscaler can precisely reach the optimal service scale meeting the SLA requirements. The experimental evaluations in a microservice benchmark show that Microscaler achieves an average 93 percent precision in scaling-needed service determination and converges to the optimal service scale faster than several state-of-the-art methods. Moreover, Microscaler is lightweight and flexible enough to work in a large-scale microservice system.},
  doi      = {10.1109/TCC.2020.2985352},
}

@InProceedings{Filippone2023,
  author    = {Filippone, Gianluca and Qaisar Mehmood, Nadeem and Autili, Marco and Rossi, Fabrizio and Tivoli, Massimo},
  booktitle = {2023 IEEE 20th International Conference on Software Architecture (ICSA)},
  title     = {From monolithic to microservice architecture: an automated approach based on graph clustering and combinatorial optimization},
  year      = {2023},
  month     = {March},
  pages     = {47-57},
  abstract  = {Migrating from a legacy monolithic system to a microservice architecture is a complex and time-consuming process. Software engineers may strongly benefit from automated support to identify a high-cohesive and loose-coupled set of microservices with proper granularity. The automated approach proposed in this paper extracts microservices by using graph clustering and combinatorial optimization to maximize cohesion and minimize coupling. The approach performs static analysis of the code to obtain a graph representation of the monolithic system. Then, it uses graph clustering to detect high-cohesive communities of nodes using the Louvain community algorithm. In parallel, the tool clusters the domain entities (i.e., classes representing uniquely identifiable concepts in a system domain) within bounded contexts to identify the required service granularity. Finally, it uses combinatorial optimization to minimize the coupling, hence deriving the microservice architecture. The approach is fully implemented. We applied it over four different monolithic systems and found valuable results. We evaluated the identified architectures through cohesion and coupling metrics, along with a comparison with other state-of-the-art approaches based on features such as granularity level, number of produced services, and methods applied. The approach implementation and the experimental results are publicly available.},
  doi       = {10.1109/ICSA56044.2023.00013},
}

@Comment{jabref-meta: databaseType:bibtex;}
