@inproceedings{10.1145/3120895.3120916,
author = {Arndt, Oliver Jakob and Spindeldreier, Christian and Wohnrade, Kevin and Pfefferkorn, Daniel and Neuenhahn, Martin and Blume, Holger},
title = {FPGA Accelerated NoC-Simulation: A Case Study on the Intel Xeon Phi Ringbus Topology},
year = {2017},
isbn = {9781450353168},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3120895.3120916},
doi = {10.1145/3120895.3120916},
abstract = {Complex signal processing algorithms targeted on architectures with increasingly high
numbers of parallel processing units require high performance core-interconnections
(i.e., low latencies, high throughput, no pinch-offs or bottlenecks). Therefore, assisting
techniques, exploring characteristics of diverse topologies of common as well as innovative
Network-on-Chips (NoCs), are necessary for the development of chips with massive parallel
processing cores. In contrast to analytic NoC models, event driven NoC simulations
can handle even complex task graphs, but however feature long simulation times. Enabling
the simulation of even complex task graphs, in this work, we propose to use FPGA accelerated
simulation. While we extend such a simulator in order to imitate cache coherence communication-behavior,
we also present a translation of real measured profiles to task graphs for in-depth
simulation of the communication behavior of an existing NoC-based manycore. Therefore,
this approach is able to not only deal with synthetic scenarios, but analyse the communication
behavior of real world applications. Additionally, a simulation of the Histograms
of Oriented Gradients algorithm, running on the Intel Xeon Phi manycore, exhibiting
a 70-stop ring-bus, exemplifies this approach.},
booktitle = {Proceedings of the 8th International Symposium on Highly Efficient Accelerators and Reconfigurable Technologies},
articleno = {21},
numpages = {6},
location = {Bochum, Germany},
series = {HEART2017}
}

@inproceedings{10.1145/2766498.2774989,
author = {Podiyan, Pradeep and Butakov, Sergey and Zavarsky, Pavol},
title = {Study of Compliance of Android Location APIs with Geopriv},
year = {2015},
isbn = {9781450336239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2766498.2774989},
doi = {10.1145/2766498.2774989},
abstract = {This paper carefully examines the location APIs of Android OS as well as the Geopriv
standard architecture to study measures that are being taken by Android OS to protect
the location privacy of a user. Android offers various location APIs in its architecture
for the app developers to work on location based services (LBS). The results of this
evaluation will be compared with Geopriv standard architecture and its ways to enhance
location information privacy on mobile platforms. The review of functionality of location
APIs shows that Android has limited features such as Geofencing to have some extent
of location privacy for a typical user. Only few of the recommendation in distribution
segment of Geopriv with slightly different approach are similar to the protection
mechanisms offered by location APIs in Android. The paper proposes general steps that
can be taken to address location privacy issues on mobile devices.},
booktitle = {Proceedings of the 8th ACM Conference on Security &amp; Privacy in Wireless and Mobile Networks},
articleno = {30},
numpages = {2},
keywords = {Geopriv, Android, location privacy},
location = {New York, New York},
series = {WiSec '15}
}

@inproceedings{10.1145/3139531.3139537,
author = {Liu, Ling},
title = {Keynote: Privacy and Trust: Friend or Foe},
year = {2017},
isbn = {9781450353939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3139531.3139537},
doi = {10.1145/3139531.3139537},
abstract = {Internet of Things (IoT) and Big Data have fueled the development of fully distributed
computational architectures for future cyber systems from data analytics, machine
learning (ML) to artificial intelligence (AI). Trust and Privacy become two vital
and necessary measures for distributed management of IoT powered big data learning
systems and services. However, these two measures have been studied independently
in computer science, social science and law.Trust is widely considered as a critical
measure for the correctness, predictability, and resiliency (with respect to reliability
and security) of software systems, be it big data systems, IoT systems, machine learning
systems, or Artificial Intelligence systems. Privacy on the other hand is commonly
recognized as a personalization measure for imposing control on the ways of how data
is captured, accessed and analyzed, and the ways of how data analytic results from
ML models and AI systems should be released and shared.Broadly speaking, in human
society, we rely on three types of trust in our everyday work and life to achieve
a peaceful mind: (1) verifiable belief-driven trust, (2) statistical evidence based
trust, and (3) complex systemwide cognitive trust. Interestingly, privacy has been
a more controversial subject. On one hand, privacy is an important built-in dimension
of trust, which is deep rooted in human society, and a highly valued virtue in Western
civilization. Even though different human beings may have diverse levels of privacy
sensitivity, we all trust that our privacy is respected in our social and professional
environments, including at home, at work and in social commons. Thus, Privacy is a
perfect example of three-fold trust: belief-driven, statistical evident, and complex
cognitive trust. On the other hand, many view privacy (and privacy protection) as
an antagonistic measure of trust and one is often asked to show trust at the cost
of giving up on privacy.Are Privacy and Trust friend or foe? This keynote will share
my view to this question from multiple perspectives. I conjecture that the answer
to this question can fundamentally change the ways we conduct research in privacy
and trust in the next generation of big data enhanced cyber learning systems from
data mining, machine learning to artificial intelligence.},
booktitle = {Proceedings of the 2017 Workshop on Women in Cyber Security},
pages = {11},
numpages = {1},
keywords = {internet of things, deep learning, privacy, big data, trust},
location = {Dallas, Texas, USA},
series = {CyberW '17}
}

@inproceedings{10.1145/2619239.2631461,
author = {Fiadino, Pierdomenico and Schiavone, Mirko and Casas, Pedro},
title = {Vivisecting Whatsapp through Large-Scale Measurements in Mobile Networks},
year = {2014},
isbn = {9781450328364},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2619239.2631461},
doi = {10.1145/2619239.2631461},
abstract = {WhatsApp, the new giant in instant multimedia messaging in mobile networks is rapidly
increasing its popularity, taking over the traditional SMS/MMS messaging. In this
paper we present the first large-scale characterization of WhatsApp, useful among
others to ISPs willing to understand the impacts of this and similar applications
on their networks. Through the combined analysis of passive measurements at the core
of a national mobile network, worldwide geo-distributed active measurements, and traffic
analysis at end devices, we show that: (i) the WhatsApp hosting architecture is highly
centralized and exclusively located in the US; (ii) video sharing covers almost 40%
of the total WhatsApp traffic volume; (iii) flow characteristics depend on the OS
of the end device; (iv) despite the big latencies to US servers, download throughputs
are as high as 1.5 Mbps; (v) users react immediately and negatively to service outages
through social networks feedbacks.},
booktitle = {Proceedings of the 2014 ACM Conference on SIGCOMM},
pages = {133–134},
numpages = {2},
keywords = {instant multimedia messaging, service outages, whatsapp, mobile networks, large-scale measurements},
location = {Chicago, Illinois, USA},
series = {SIGCOMM '14}
}

@article{10.1145/2740070.2631461,
author = {Fiadino, Pierdomenico and Schiavone, Mirko and Casas, Pedro},
title = {Vivisecting Whatsapp through Large-Scale Measurements in Mobile Networks},
year = {2014},
issue_date = {October 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {4},
issn = {0146-4833},
url = {https://doi.org/10.1145/2740070.2631461},
doi = {10.1145/2740070.2631461},
abstract = {WhatsApp, the new giant in instant multimedia messaging in mobile networks is rapidly
increasing its popularity, taking over the traditional SMS/MMS messaging. In this
paper we present the first large-scale characterization of WhatsApp, useful among
others to ISPs willing to understand the impacts of this and similar applications
on their networks. Through the combined analysis of passive measurements at the core
of a national mobile network, worldwide geo-distributed active measurements, and traffic
analysis at end devices, we show that: (i) the WhatsApp hosting architecture is highly
centralized and exclusively located in the US; (ii) video sharing covers almost 40%
of the total WhatsApp traffic volume; (iii) flow characteristics depend on the OS
of the end device; (iv) despite the big latencies to US servers, download throughputs
are as high as 1.5 Mbps; (v) users react immediately and negatively to service outages
through social networks feedbacks.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = aug,
pages = {133–134},
numpages = {2},
keywords = {service outages, large-scale measurements, mobile networks, whatsapp, instant multimedia messaging}
}

@inproceedings{10.1145/3018981.3018986,
author = {Mell, Peter and Shook, James and Harang, Richard},
title = {Measuring and Improving the Effectiveness of Defense-in-Depth Postures},
year = {2016},
isbn = {9781450347884},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3018981.3018986},
doi = {10.1145/3018981.3018986},
abstract = {Defense-in-depth is an important security architecture principle that has significant
application to industrial control systems (ICS), cloud services, storehouses of sensitive
data, and many other areas. We claim that an ideal defense-in-depth posture is 'deep',
containing many layers of security, and 'narrow', the number of node independent attack
paths is minimized. Unfortunately, accurately calculating both depth and width is
difficult using standard graph algorithms because of a lack of independence between
multiple vulnerability instances (i.e., if an attacker can penetrate a particular
vulnerability on one host then they can likely penetrate the same vulnerability on
another host). To address this, we represent known weaknesses and vulnerabilities
as a type of colored attack graph. We measure depth and width through solving the
shortest color path and minimum color cut problems. We prove both of these to be NP-Hard
and thus for our solution we provide a suite of greedy heuristics. We then empirically
apply our approach to large randomly generated networks as well as to ICS networks
generated from a published ICS attack template. Lastly, we discuss how to use these
results to help guide improvements to defense-in-depth postures.},
booktitle = {Proceedings of the 2nd Annual Industrial Control System Security Workshop},
pages = {15–22},
numpages = {8},
keywords = {security, measurement, attack graph, defense in depth},
location = {Los Angeles, CA, USA},
series = {ICSS '16}
}

@inproceedings{10.1145/3018896.3018934,
author = {Kokkonis, George and Kontogiannis, Sotirios and Tomtsis, Dimitrios},
title = {FITRA: A Neuro-Fuzzy Computational Algorithm Approach Based on an Embedded Water Planting System},
year = {2017},
isbn = {9781450347747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3018896.3018934},
doi = {10.1145/3018896.3018934},
abstract = {This paper proposes a novel neuro-fuzzy computational algorithm for embedded irrigation
systems called FITRA. It presents a new system architecture for the process of continuously
monitoring environmental conditions and efficient irrigation of arable areas. The
system includes microcontroller equipment with multiple sensors interspersed all over
the field. Transmissions of measurements, which occur periodically, send to a central
cloud system Application Service (AS) assisted by a 3G network. The decision for irrigation
or not is made by a neuro-fuzzy algorithm. As an input for that algorithm are the
values taken from the interspersed sensors. As an output, this algorithm controls
the central solenoid water valve of the water planting system. The irrigation system
automatically adjusts to changing environmental conditions.},
booktitle = {Proceedings of the Second International Conference on Internet of Things, Data and Cloud Computing},
articleno = {39},
numpages = {8},
keywords = {neuro-fuzzy algorithms, soil sensor, agriculture, smart irrigation, smart farming, water planting systems, IoT},
location = {Cambridge, United Kingdom},
series = {ICC '17}
}

@inproceedings{10.1145/3054977.3057290,
author = {Ma, Meiyi and Preum, Sarah Masud and Stankovic, John A.},
title = {Simulating Conflict Detection in Heterogeneous Services of a Smart City: Demo Abstract},
year = {2017},
isbn = {9781450349666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3054977.3057290},
doi = {10.1145/3054977.3057290},
abstract = {Despite the increasing intelligence of smart services and sophistication of IoT platforms,
the safety issues in smart cities are not addressed adequately, especially the safety
issues arising from the integration of smart services. Therefore, in this demo abstract,
we present CityGuard, a safety-aware watchdog architecture to detect conflicts among
actions of heterogeneous services considering both safety and performance requirements.
This demo simulates parts of New York City to depict how CityGuard identifies unsafe
actions and thus helps to prevent the city from safety hazards, detects two major
types of conflicts, i.e., device and environmental conflicts, and improves the overall
city performance in terms of multiple performance metrics. This demo complements the
full paper on CityGuard that appears in this conference [2].},
booktitle = {Proceedings of the Second International Conference on Internet-of-Things Design and Implementation},
pages = {275–276},
numpages = {2},
keywords = {Smart City, City Simulation, Conflict Detection, City Safety},
location = {Pittsburgh, PA, USA},
series = {IoTDI '17}
}

@inproceedings{10.1145/3466933.3466945,
author = {Oliveira, Breno Silva and Ara\'{u}jo, \'{I}talo L. and Paiva, Joseane O. V. and Junior, Evilasio C. and Andrade, Rossana M. C.},
title = {Refactoring Decision Based on Measurements for IoHT Apps},
year = {2021},
isbn = {9781450384919},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3466933.3466945},
doi = {10.1145/3466933.3466945},
abstract = {Internet of Things (IoT) provides smart objects with the ability to connect to the
Internet, allowing the exchange of information among them to provide a certain service
and the development of innovative applications in several domains, including e-Health,
in which it is called Internet of Health Things (IoHT). This domain can be critical
specially when the application deals with the monitoring of the user health in real-time,
what demands software quality assurance, even more than in other applications. Measures
can be used to support that, for example, measures can suggest which components need
refactoring to improve the software code, thus improving the application. In this
work, we report how to do that with two existing measures that guide the refactoring
process of an IoHT application for fall detection, called WatchAlert. These measures
indicate that changes in both the architecture and the algorithms for fall detection
should occur. After the refactoring, the app accuracy was improved from 73.3% to 92.7%.
We believe that this work can contribute to other studies focusing on developing applications
on the IoHT domain using a methodology, a set of refactoring techniques, and lessons
learned that could be replicated to improve the quality of this type of application.},
booktitle = {XVII Brazilian Symposium on Information Systems},
articleno = {12},
numpages = {9},
keywords = {Refactoring, Fall detection, Measures, Internet of Things, e-Health},
location = {Uberl\^{a}ndia, Brazil},
series = {SBSI 2021}
}

@inproceedings{10.1145/3297280.3297648,
author = {Koupaee, Mahnaz},
title = {Mortality Prediction Using Medical Notes: Student Research Abstract},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297648},
doi = {10.1145/3297280.3297648},
abstract = {Mortality prediction is a critical task for assessing patients' conditions in Intensive
Care Units (ICU) of hospitals to improve decision-making and quality of care. Measurements
taken and recorded at different time points are the main source of information to
be used for tasks related to healthcare. However, the notes written by medical service
providers during patients' stay in hospital as a rich source of detailed information
is not sufficiently exploited. In this work, we propose a Convolutional Neural Network
(CNN) architecture to utilize the unstructured texts to predict the pre-discharge
and post-discharge mortality of ICU patients. Evaluations show high performance of
the proposed method in terms of precision and recall. Moreover, our method outperforms
the state of the art method by achieving a higher AUC.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {778–781},
numpages = {4},
keywords = {convolutional neural network, medical notes, MIMIC, mortality prediction},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1145/3449301.3449322,
author = {Wen, Yana and Wei, Tingyue and Cui, Kewei and Ling, Bai and Zhang, Yahao and Huang, Meng},
title = {Research on Belt and Road Big Data Visualization Based on Text Clustering Algorithm},
year = {2020},
isbn = {9781450388597},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3449301.3449322},
doi = {10.1145/3449301.3449322},
abstract = {In the era of big data, people's visual needs for data expression are increasing.
In order to achieve better big data display effects, this article introduced the use
of text clustering algorithms to achieve data crawling and Echarts technology to realize
big data visualization. This system used mvvm's architecture and vue framework development
platform, ThinkPHP was used as the background framework, and ES6 related technologies
and specifications were used for application development. This system used Echarts,
IView, GIS technology and JavaScript development methods to demonstrate economic big
data module functions on the web side; Applied CSS3, HTML5, GIS technology to implement
project achievement module and university alliance module; Applied Echarts, HTML5,
JS function library technology to achieve national information module. This system
used stored procedure, database index optimization technology to achieve rapid screening
of massive data, and dynamically update and displayed related data through two-way
data binding. This system combined real-time location technology with GIS technology
to measure the distance between the user and the destination, and automatically plan
the tour route to provide related services. This system can provide feasibility suggestions
for strategic researchers or experts in related areas of the “Belt and Road”, and
provide theoretical basis and technical support.},
booktitle = {2020 6th International Conference on Robotics and Artificial Intelligence},
pages = {121–125},
numpages = {5},
keywords = {big data visualization, Text clustering algorithm, One Belt One Road, Keywords-component},
location = {Singapore, Singapore},
series = {ICRAI 2020}
}

@inproceedings{10.1145/2815675.2815677,
author = {Gracia-Tinedo, Ra\'{u}l and Tian, Yongchao and Samp\'{e}, Josep and Harkous, Hamza and Lenton, John and Garc\'{\i}a-L\'{o}pez, Pedro and S\'{a}nchez-Artigas, Marc and Vukolic, Marko},
title = {Dissecting UbuntuOne: Autopsy of a Global-Scale Personal Cloud Back-End},
year = {2015},
isbn = {9781450338486},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2815675.2815677},
doi = {10.1145/2815675.2815677},
abstract = {Personal Cloud services, such as Dropbox or Box, have been widely adopted by users.
Unfortunately, very little is known about the internal operation and general characteristics
of Personal Clouds since they are proprietary services.In this paper, we focus on
understanding the nature of Personal Clouds by presenting the internal structure and
a measurement study of UbuntuOne (U1). We first detail the U$1$ architecture, core
components involved in the U1 metadata service hosted in the datacenter of Canonical,
as well as the interactions of U$1$ with Amazon S3 to outsource data storage. To our
knowledge, this is the first research work to describe the internals of a large-scale
Personal Cloud.Second, by means of tracing the U$1$ servers, we provide an extensive
analysis of its back-end activity for one month. Our analysis includes the study of
the storage workload, the user behavior and the performance of the U1 metadata store.
Moreover, based on our analysis, we suggest improvements to U1 that can also benefit
similar Personal Cloud systems.Finally, we contribute our dataset to the community,
which is the first to contain the back-end activity of a large-scale Personal Cloud.
We believe that our dataset provides unique opportunities for extending research in
the field.},
booktitle = {Proceedings of the 2015 Internet Measurement Conference},
pages = {155–168},
numpages = {14},
keywords = {personal cloud, performance analysis, measurement},
location = {Tokyo, Japan},
series = {IMC '15}
}

@article{10.1145/3399742,
author = {Kocher, Paul and Horn, Jann and Fogh, Anders and Genkin, Daniel and Gruss, Daniel and Haas, Werner and Hamburg, Mike and Lipp, Moritz and Mangard, Stefan and Prescher, Thomas and Schwarz, Michael and Yarom, Yuval},
title = {Spectre Attacks: Exploiting Speculative Execution},
year = {2020},
issue_date = {July 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {63},
number = {7},
issn = {0001-0782},
url = {https://doi.org/10.1145/3399742},
doi = {10.1145/3399742},
abstract = {Modern processors use branch prediction and speculative execution to maximize performance.
For example, if the destination of a branch depends on a memory value that is in the
process of being read, CPUs will try to guess the destination and attempt to execute
ahead. When the memory value finally arrives, the CPU either discards or commits the
speculative computation. Speculative logic is unfaithful in how it executes, can access
the victim's memory and registers, and can perform operations with measurable side
effects.Spectre attacks involve inducing a victim to speculatively perform operations
that would not occur during correct program execution and which leak the victim's
confidential information via a side channel to the adversary. This paper describes
practical attacks that combine methodology from side-channel attacks, fault attacks,
and return-oriented programming that can read arbitrary memory from the victim's process.
More broadly, the paper shows that speculative execution implementations violate the
security assumptions underpinning numerous software security mechanisms, such as operating
system process separation, containerization, just-in-time (JIT) compilation, and countermeasures
to cache timing and side-channel attacks. These attacks represent a serious threat
to actual systems because vulnerable speculative execution capabilities are found
in microprocessors from Intel, AMD, and ARM that are used in billions of devices.Although
makeshift processor-specific countermeasures are possible in some cases, sound solutions
will require fixes to processor designs as well as updates to instruction set architectures
(ISAs) to give hardware architects and software developers a common understanding
as to what computation state CPU implementations are (and are not) permitted to leak.},
journal = {Commun. ACM},
month = jun,
pages = {93–101},
numpages = {9}
}

@inproceedings{10.1145/2642687.2642690,
author = {Migault, Daniel and Palomares, Daniel and Hendrik, Hendrik and Laurent, Maryline},
title = {Secure IPsec Based Offload Architectures for Mobile Data},
year = {2014},
isbn = {9781450330275},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2642687.2642690},
doi = {10.1145/2642687.2642690},
abstract = {Radio Access Network (RAN) are likely to be overloaded, and some places will not be
able to provide the necessary requested bandwidth. In order to respond to the demand
of bandwidth, overloaded RAN are currently offloading their traffic on WLAN. WLAN
Access Points like (ISP provided xDSL boxes) are untrusted, unreliable and do not
handle mobility. As a result, mobility, multihoming, and security cannot be handled
by the network anymore, and must be handled by the terminal. This paper positions
offload architectures based on IPsec and shows that IPsec can provide end-to-end security,
as well as seamless connectivity across IP networks. Then, the remaining of the paper
evaluates how mobility on these IPsec based architectures impacts the Quality of Service
(QoS) for real time applications such as an audio streaming service. QoS is measured
using network interruption time and POLQA. Measurements compare TCP/HLS and UDP/RTSP
over various IPsec configurations.},
booktitle = {Proceedings of the 10th ACM Symposium on QoS and Security for Wireless and Mobile Networks},
pages = {95–104},
numpages = {10},
keywords = {wlan offload architecture, terminal mobility, quality of service, IPsec multiple interfaces, IPsec mobility},
location = {Montreal, QC, Canada},
series = {Q2SWinet '14}
}

@inproceedings{10.1145/3329391,
author = {Esposito, Christian and Pop, Florin and Choi, Chang},
title = {Session Details: Theme: Information Systems: SFECS - Sustainability of Fog/Edge Computing Systems Track},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3329391},
doi = {10.1145/3329391},
abstract = {Fog/Edge Computing paradigms are widely used in enterprises to address the emerging
challenges of big data analysis, because of their underlying scalable, flexible and
distributed data management schemes. The data centers in the Clouds are facing great
challenges on the burden of the consequent increasing the amount of data to be man-
aged and the additional requirements of location awareness and low latency at the
edge of network necessary by smart cites and factories. These are the reasons why
a centralized model cannot be an efficient solution for generated or required data
by the IoT devices in those applications and there is the progressive shift towards
fog nodes and smarted edge nodes mediating between the cloud and the IoT devices.
The Fog/Edge computing paradigm is a decentralized model that transfers a part of
low computing data analysis from the cloud to the intermediate (fog) nodes or the
edges, performing only high computing tasks in the cloud. This new approach tries
to minimize the three factors that negatively compromise the effective and efficient
application of the Cloud computing to smart cities and factories, or similar application
domains: the network bandwidth usage, decentralization of the data processing tasks
and reduced response latency for clients (IoT devices). Fog/Edge computing is a hierarchical
approach where the overall infrastructure is structured in multiple layers, each responsible
of offering a good coordination and data management to the nodes at the lower layer.
The lowest layer is usually composed of sensors and/or actuators that measure and/or
control the environment or a given business process, implemented as mobile devices
that are running a sensing/controlling application. In this case, combining Sustainable
computing with Fog and Edge computing represents a new approach for increasing quality-of-
service and efficiency of the system, creating the capability to present temporal
and geo-coded information, and increasing innovation, and co-designing sustainable
future large scale distributed systems. This new paradigm appears to offer a good
approach in handling the scale factor of the data size, reducing the network bandwidth
usage and the response latency of the system. In order to support specifically the
Fog/Edge architectures, there is a need, for instance, of location-awareness and computation
placement, replication and recovery. In many cases Edge resources would be required
for both computation and data storage to address the time and locality constraints.
There are multiple kinds of orchestration management solutions for virtualization
in this type of architecture with different characteristics and drawbacks. This results
in different restrictions for application definition, scalability, availability, load
balancing and so on. Also, virtualization may be needed at multiple levels in a Fog/Edge
architecture as it consists of the following levels of abstraction: at the sensing
level we have the IoT devices/smart things, at the Edge level there are the gateways
to a first collection and the data from the IoT devices and their preliminary processing,
at the Fog level we have an additional data management layer, and at the Cloud level
there is the compute/storage infrastructure with applications on top. Last, but not
least, the energy efficiency is particularly important at the IoT and edge level since
the devices may be equipped with a limited battery, possible difficult or impossible
to be charged. So, optimizing the energy consumption is a must. To address several
open research is- sues regarding sustainability of future Fog/Edge systems, this track
aims at solicit contributions highlighting challenges, state-of-the-art, and solutions
to a set of currently unresolved key questions including - but not limited to - performance,
modeling, optimization, energy-efficiency, reliability, security, privacy and techno-economic
aspects of Fog/Edge systems. Through addressing these concerns while understanding
their impacts and limitations, technological advancements will be channeled toward
more sustainable/efficient platforms for tomorrow's ever-connected systems.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1145/3316615.3316622,
author = {Ming, Fan Xiu and Habeeb, Riyaz Ahamed Ariyaluran and Md Nasaruddin, Fariza Hanum Binti and Gani, Abdullah Bin},
title = {Real-Time Carbon Dioxide Monitoring Based on IoT &amp; Cloud Technologies},
year = {2019},
isbn = {9781450365734},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3316615.3316622},
doi = {10.1145/3316615.3316622},
abstract = {In recent years, environment monitoring are of greater importance towards the area
of climate monitoring, analysis, agricultural productivity management, quality assurance
of water, air, alongside with other potential factors that are closely connected to
industrial development and convenience of living. This research is motivated by creating
awareness of smart home residents on indoor air quality, as well as providing insight
of carbon dioxide emissions for industries and environmental organizations.This paper
proposes an efficient solution towards environment monitoring of carbon dioxide integrated
with Internet of Things capability and cloud computing technology. Aforementioned
techniques will deliver highly accessible and real-time data visualization which would
be greatly beneficial for Smart Homes efficiency of analysis actualization and counter-measures
deployment. A monitoring architecture was developed to generate, accumulate, store
and visualize carbon dioxide concentration using MQ135 carbon dioxide sensor, ESP8266
Wi-Fi module, Firebase Cloud Storage Service and Android mobile application Carbon
Insight for data visualization. 2880 data points in the time frame of 10 days with
a 30-second interval was collected, stored and visualized with the application of
this system.},
booktitle = {Proceedings of the 2019 8th International Conference on Software and Computer Applications},
pages = {517–521},
numpages = {5},
keywords = {Internet of things, cloud, environment monitoring},
location = {Penang, Malaysia},
series = {ICSCA '19}
}

@inproceedings{10.1145/2851613.2851727,
author = {Megyesi, P\'{e}ter and Botta, Alessio and Aceto, Giuseppe and Pescap\`{e}, Antonio and Moln\'{a}r, S\'{a}ndor},
title = {Available Bandwidth Measurement in Software Defined Networks},
year = {2016},
isbn = {9781450337397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851613.2851727},
doi = {10.1145/2851613.2851727},
abstract = {Software Defined Networking (SDN) is an emerging paradigm that is expected to revolutionize
computer networks. With the decoupling of data and control plane and the introduction
of open communication interfaces between layers, SDN enables programmability over
the entire network, promising rapid innovation in this area. The SDN concept was already
proven to work successfully in cloud and data center environments thus the proper
monitoring of such networks is already in the focus of the research community. Methods
for measuring Quality of Service (QoS) parameters such as bandwidth utilization, packet
loss, and delay have been recently introduced in literature, but they lack a solution
for tackling down the question of available bandwidth. In this paper, we attempt to
fill this gap and introduce a novel mechanism for measuring available bandwidth in
SDN networks. We take advantage of the SDN architecture and build an application over
the Network Operating System (NOS). Our application can track the topology of the
network and the bandwidth utilization over the network links, and thus it is able
to calculate the available bandwidth between any two points in the network. We validate
our method using the popular Mininet network emulation environment and the widely
used NOS called Floodlight. We present results providing insights into the measurement
accuracy and showing its relationship with the delay in the control network and the
polling frequency.},
booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},
pages = {651–657},
numpages = {7},
keywords = {network operating system, floodlight, OpenFlow, software defined networks, available bandwidth, mininet},
location = {Pisa, Italy},
series = {SAC '16}
}

@inproceedings{10.1145/2699343.2699348,
author = {Achtzehn, Andreas and Riihihj\"{a}rvi, Janne and Barri\'{\i}a Castillo, Irving Antonio and Petrova, Marina and M\"{a}h\"{o}nen, Petri},
title = {<i>CrowdREM</i>: Harnessing the Power of the Mobile Crowd for Flexible Wireless Network Monitoring},
year = {2015},
isbn = {9781450333917},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2699343.2699348},
doi = {10.1145/2699343.2699348},
abstract = {High-speed mobile broadband connections have opened exciting new opportunities to
collect sensor data from thousands or even millions of distributed mobile devices
for the purpose of crowdsourced decision making. In this paper, we propose CrowdREM
(crowdsourced radio environment mapping), a framework with the specific aim of monitoring
and modelling wireless cellular networks. CrowdREM enables operator-independent and
highly efficient collection of network performance data along all layers of the communications
protocol stack. Such extensive information on network load, spectrum usage, or local
coverage can help operators to optimize their networks and service quality and enable
improved consumer decision making. In this paper, we introduce the mbox{CrowdREM}
mobile architecture and show first results from a prototype implementation on open-source
mobile phones. We demonstrate the versatility of using commodity devices for network
and spectrum monitoring, and present the challenges originating from the use of uncalibrated
and low-precision measurement equipment. We have acquired an extensive data set from
using our prototype implementation in a 21-day measurement campaign covering more
than 1,000 hours of measurement data. From this we present and discuss the potential
derivation of tangible and relevant network performance and signal quality indicators,
which could, e.g., be conducted by independent parties.},
booktitle = {Proceedings of the 16th International Workshop on Mobile Computing Systems and Applications},
pages = {63–68},
numpages = {6},
keywords = {drive testing, crowdsourcing, cellular networks, mobile},
location = {Santa Fe, New Mexico, USA},
series = {HotMobile '15}
}

@proceedings{10.1145/2656434,
title = {RIIT '14: Proceedings of the 3rd Annual Conference on Research in Information Technology},
year = {2014},
isbn = {9781450327114},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is with great pleasure that we welcome you to the 15th Annual Conference on Information
Technology Education (SIGITE 2014) and the 3rd Annual Conference on Research in Information
Technology (RIIT 2014). The theme this year is "Riding the Wave of Change in Information
Technology" and the many quality submissions we received allowed us to assemble one
of the strongest programs in the history of the conferences. As in past years, the
synergies between research and education in information technology are prevalent,
and several themes emerged from the accepted submissions. Networking, security, and
development remain popular with researchers, and interest in mobile computing, resource
measurement and management, capstone courses, and personalization has grown.The call
for participation attracted 111 submissions, 72 of which were submitted to SIGITE
and 39 to RIIT. Both numbers represent a larger pool than in recent years, demonstrating
that the conferences are of great interest in the community. Ninety-five of the submissions
were papers, with 59 papers submitted to SIGITE and 36 papers submitted to RIIT. SIGITE
has 27 papers in its program for an acceptance rate of 46% and RIIT has 14 papers
for an acceptance rate of 39%. All of the authors presenting should be congratulated
on their excellent work.A conference cannot happen without the help of its reviewers,
and this year was no exception. Fiftyfive reviewers worked diligently to ensure that
every paper had at least three independent reviews. It was a significant effort to
produce the 317 reviews that ended up in the system, and we thank the reviewers from
the bottom of our heart. New to the conferences this year was a meta review process,
in which 13 diligent meta reviewers together examined all reviews for each submission
and reconciled those reviews into a coherent message for each author. We hope the
meta review process enabled authors to have more substantive feedback on their work,
whether it appears in the final program or not.The conference runs from Thursday to
Saturday and each day offers something of interest to attendees. On Thursday our keynote
speaker is Dr. Flavio Villanustre, Vice-President of Technology Architecture &amp; Product
for LexisNexis and HPCC Systems. The day continues with a workshop on end-user development
activities and paper sessions for both SIGITE and RIIT. Thursday concludes with a
reception, which we know will be useful for networking with colleagues old and new.
Friday introduces a new presentation format, lightning talks on research in progress,
at the conferences. There are also paper sessions for SIGITE and RIIT, a poster session
in the afternoon and, of course, more opportunities for networking during lunch and
the breaks. Saturday offers a three-hour workshop on process-oriented guided inquiry
learning (POGIL) as well as a panel on mobile computing courses and some excellent
SIGITE papers. We also hope that you stay for the closing session where we will share
our plans for SIGITE/RIIT 2015 in Chicago.We hope you find the conference presentations
interesting and thought-provoking, you reconnect with colleagues you know, you find
new collaborators, and you submit the work that results to SIGITE or RIIT next year.
The excellence you see at SIGITE/RIIT 2014 depends on your energy and effort, and
we thank you for letting us be a part of it.},
location = {Atlanta, Georgia, USA}
}

@inproceedings{10.1145/3452918.3467815,
author = {Dijkstra-Soudarissanane, Sylvie and Klunder, Tessa and Brandt, Aschwin and Niamut, Omar},
title = {Towards XR Communication for Visiting Elderly at Nursing Homes},
year = {2021},
isbn = {9781450383899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452918.3467815},
doi = {10.1145/3452918.3467815},
abstract = {Due to the current pandemic, the elderly in care homes are greatly affected by the
lack of contact with their families, resulting in various mental conditions (e.g.,
depression, feelings of loneliness) and deterioration of mental health for dementia
patients. In response, residents and family members increasingly resorted to mediated
communication to maintain social contact. To facilitate high-quality mediated social
contact between residents in nursing homes and remote family members, we developed
an Augmented Reality (AR)-based communication tool. The proposed demonstrator improved
this situation by providing a working communication tool that enables the elderly
to feel being together with their family by means of AR techniques. A complete end-to-end-chain
architecture is defined, where the aspects of capture, transmission, and rendering
are thoroughly investigated to fit the purpose of the use case. Based on an extensive
user study comprising user experience (UX) and quality of service (QoS) measurements,
each module is presented with the improvements made and the resulting higher quality
AR communication platform.},
booktitle = {ACM International Conference on Interactive Media Experiences},
pages = {319–321},
numpages = {3},
keywords = {Augmented Reality, Social XR, Immersive Media, AR, Volumetric video, WebRTC, Conferencing, Communication},
location = {Virtual Event, USA},
series = {IMX '21}
}

@proceedings{10.1145/2656450,
title = {SIGITE '14: Proceedings of the 15th Annual Conference on Information Technology Education},
year = {2014},
isbn = {9781450326865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is with great pleasure that we welcome you to the 15th Annual Conference on Information
Technology Education (SIGITE 2014) and the 3rd Annual Conference on Research in Information
Technology (RIIT 2014). The theme this year is "Riding the Wave of Change in Information
Technology" and the many quality submissions we received allowed us to assemble one
of the strongest programs in the history of the conferences. As in past years, the
synergies between research and education in information technology are prevalent,
and several themes emerged from the accepted submissions. Networking, security, and
development remain popular with researchers, and interest in mobile computing, resource
measurement and management, capstone courses, and personalization has grown.The call
for participation attracted 111 submissions, 72 of which were submitted to SIGITE
and 39 to RIIT. Both numbers represent a larger pool than in recent years, demonstrating
that the conferences are of great interest in the community. Ninety-five of the submissions
were papers, with 59 papers submitted to SIGITE and 36 papers submitted to RIIT. SIGITE
has 27 papers in its program for an acceptance rate of 46% and RIIT has 14 papers
for an acceptance rate of 39%. All of the authors presenting should be congratulated
on their excellent work.A conference cannot happen without the help of its reviewers,
and this year was no exception. Fiftyfive reviewers worked diligently to ensure that
every paper had at least three independent reviews. It was a significant effort to
produce the 317 reviews that ended up in the system, and we thank the reviewers from
the bottom of our heart. New to the conferences this year was a meta review process,
in which 13 diligent meta reviewers together examined all reviews for each submission
and reconciled those reviews into a coherent message for each author. We hope the
meta review process enabled authors to have more substantive feedback on their work,
whether it appears in the final program or not.The conference runs from Thursday to
Saturday and each day offers something of interest to attendees. On Thursday our keynote
speaker is Dr. Flavio Villanustre, Vice-President of Technology Architecture &amp; Product
for LexisNexis and HPCC Systems. The day continues with a workshop on end-user development
activities and paper sessions for both SIGITE and RIIT. Thursday concludes with a
reception, which we know will be useful for networking with colleagues old and new.
Friday introduces a new presentation format, lightning talks on research in progress,
at the conferences. There are also paper sessions for SIGITE and RIIT, a poster session
in the afternoon and, of course, more opportunities for networking during lunch and
the breaks. Saturday offers a three-hour workshop on process-oriented guided inquiry
learning (POGIL) as well as a panel on mobile computing courses and some excellent
SIGITE papers. We also hope that you stay for the closing session where we will share
our plans for SIGITE/RIIT 2015 in Chicago.We hope you find the conference presentations
interesting and thought-provoking, you reconnect with colleagues you know, you find
new collaborators, and you submit the work that results to SIGITE or RIIT next year.
The excellence you see at SIGITE/RIIT 2014 depends on your energy and effort, and
we thank you for letting us be a part of it.},
location = {Atlanta, Georgia, USA}
}

@inproceedings{10.1145/3286719.3286727,
author = {Coroller, Stevan and Chabridon, Sophie and Laurent, Maryline and Conan, Denis and Leneutre, Jean},
title = {Position Paper: Towards End-to-End Privacy for Publish/Subscribe Architectures in the Internet of Things},
year = {2018},
isbn = {9781450361187},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3286719.3286727},
doi = {10.1145/3286719.3286727},
abstract = {The Internet of Things paradigm lacks end-to-end privacy solutions to consider its
full adoption in real life scenarios in the near future. The recent enactment of the
EU General Data Protection Regulation (GDPR) indeed emphasises the need for stronger
security and privacy measures for personal data processing and free movement, including
consent management and accountability by the data controller and processor. In this
paper, we suggest an architecture to enforce end-to-end data usage control in Distributed
Event-Based Systems (DEBS), from data producers to consumer services, taking into
account some of the GDPR requirements concerning consent management and data processing
transparency. Our architecture proposal is based on UCONABC usage control models,
which we overlap with a distributed hash table overlay for scalability and fault-tolerance
concerns, and across and within systems data usage control. Our proposal highlights
the benefits of combining both DEBS and end-user usage control architectures. To complete
our approach, we quickly survey existing encryption models that ensure data confidentiality
in topic-based Publish/Subscribe systems and highlight the remaining obstacles to
transpose them to content-based DEBS with an overlay of brokers.},
booktitle = {Proceedings of the 5th Workshop on Middleware and Applications for the Internet of Things},
pages = {35–40},
numpages = {6},
keywords = {IoT, Privacy, Usage Control, Content-based Distributed Event-Based Systems},
location = {Rennes, France},
series = {M4IoT'18}
}

@inproceedings{10.1145/3005745.3005762,
author = {Tilmans, Olivier and B\"{u}hler, Tobias and Vissicchio, Stefano and Vanbever, Laurent},
title = {Mille-Feuille: Putting ISP Traffic under the Scalpel},
year = {2016},
isbn = {9781450346610},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3005745.3005762},
doi = {10.1145/3005745.3005762},
abstract = {For Internet Service Provider (ISP) operators, getting an accurate picture of how
their network behaves is challenging. Given the traffic volumes that their networks
carry and the impossibility to control end-hosts, ISP operators are typically forced
to randomly sample traffic, and rely on aggregated statistics. This provides coarse-grained
visibility, at a time resolution that is far from ideal (seconds or minutes). In this
paper, we present Mille-Feuille, a novel monitoring architecture that provides fine-grained
visibility over ISP traffic. Mille-Feuille schedules activation and deactivation of
traffic-mirroring rules, that are then provisioned network-wide from a central location,
within milliseconds. By doing so, Mille-Feuille combines the scalability of sampling
with the visibility and controllability of traffic mirroring. As a result, it supports
a set of monitoring primitives, ranging from checking key performance indicators (e.g.,
one-way delay) for single destinations to estimating traffic matrices in sub-seconds.
Our preliminary measurements on existing routers confirm that Mille-Feuille is viable
in practice.},
booktitle = {Proceedings of the 15th ACM Workshop on Hot Topics in Networks},
pages = {113–119},
numpages = {7},
location = {Atlanta, GA, USA},
series = {HotNets '16}
}

@inproceedings{10.1145/3152434.3152450,
author = {Singhvi, Arjun and Banerjee, Sujata and Harchol, Yotam and Akella, Aditya and Peek, Mark and Rydin, Pontus},
title = {Granular Computing and Network Intensive Applications: Friends or Foes?},
year = {2017},
isbn = {9781450355698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3152434.3152450},
doi = {10.1145/3152434.3152450},
abstract = {Computing/infrastructure as a service continues to evolve with bare metal, virtual
machines, containers and now serverless granular computing service offerings. Granular
computing enables developers to decompose their applications into smaller logical
units or functions, and run them on small, low cost and short lived computation containers
without having to worry about setting up servers - hence the term serverless computing.
While serverless environments can be used very cost effectively for large scale parallel
processing data analytics applications, it is less clear if network intensive packet
processing applications can also benefit from these new computing services as they
do not share the same characteristics. This paper examines the architectural constraints
as well as current serverless implementations to develop a position on this topic
and influence the next generation of computing services. We support our position through
measurement and experimentation on Amazon's AWS Lambda service with a few popular
network functions.},
booktitle = {Proceedings of the 16th ACM Workshop on Hot Topics in Networks},
pages = {157–163},
numpages = {7},
location = {Palo Alto, CA, USA},
series = {HotNets-XVI}
}

@inproceedings{10.1145/2883851.2883876,
author = {Renz, Jan and Hoffmann, Daniel and Staubitz, Thomas and Meinel, Christoph},
title = {Using A/B Testing in MOOC Environments},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883876},
doi = {10.1145/2883851.2883876},
abstract = {In recent years, Massive Open Online Courses (MOOCs) have become a phenomenon offering
the possibility to teach thousands of participants simultaneously. In the same time
the platforms used to deliver these courses are still in their fledgling stages. While
course content and didactics of those massive courses are the primary key factors
for the success of courses, still a smart platform may increase or decrease the learners
experience and his learning outcome. The paper at hand proposes the usage of an A/B
testing framework that is able to be used within an micro-service architecture to
validate hypotheses about how learners use the platform and to enable data-driven
decisions about new features and settings. To evaluate this framework three new features
(Onboarding Tour, Reminder Mails and a Pinboard Digest) have been identified based
on a user survey. They have been implemented and introduced on two large MOOC platforms
and their influence on the learners behavior have been measured. Finally this paper
proposes a data driven decision workflow for the introduction of new features and
settings on e-learning platforms.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {304–313},
numpages = {10},
keywords = {MOOC, A/B testing, e-learning, controlled online tests, microservice},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@inproceedings{10.1109/UCC.2014.49,
author = {Keller, Matthias and Robbert, Christoph and Karl, Holger},
title = {Template Embedding: Using Application Architecture to Allocate Resources in Distributed Clouds},
year = {2014},
isbn = {9781479978816},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/UCC.2014.49},
doi = {10.1109/UCC.2014.49},
abstract = {In distributed cloud computing, application deployment across multiple sites can improve
quality of service. Recent research developed algorithms to find optimal locations
for virtual machines. However, those algorithms assume to have either single-tier
applications or a fixed number of virtual machines--a strong simplification of reality.
This paper investigates the placement and scaling of complex application architectures.
An application is dynamically scaled to fit both the current demand situation and
the currently available infrastructure resources. We compare two approaches: The first
one is based on virtual network embedding. The second approach is a novel method called
Template Embedding. It is based on a hierarchical 1-allocation hub flow problem and
combines application scaling and embedding in one step. Extensive experiments on 43200
network configurations showed that Template Embedding outperforms virtual network
embedding in all cases in three metrics: success rate, solution quality, and runtime.
This positive result shows that template embedding is a promising approach for distributed
cloud resource allocation.},
booktitle = {Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing},
pages = {387–395},
numpages = {9},
keywords = {Flow Problem, Distributed Cloud Computing, Application Architecture, Hub Problem, Cloud Resource Allocation},
series = {UCC '14}
}

@inproceedings{10.1145/2642668.2642673,
author = {Hatoum, Rima and Hatoum, Abbas and Ghaith, Alaa and Pujolle, Guy},
title = {Qos-Based Joint Resource Allocation with Link Adaptation for SC-FDMA Uplink in Heterogeneous Networks},
year = {2014},
isbn = {9781450330268},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2642668.2642673},
doi = {10.1145/2642668.2642673},
abstract = {The LTE-based femtocell network is a promising solution adopted today to cope with
the huge cellular traffic requirements. In particular, the Uplink communication becomes
an attractive issue especially with the emerging of the interactive services and large
uploaded data volume. Intelligent allocation of the resources and interference management
are the main challenges in such context. In this paper, we propose a linear optimization
model for the SC-FDMA Uplink transmission aiming to adaptively allocate resources
with respect to the link quality. Both power and modulation and coding schemes are
independently assigned to each user over each allocated sub-channel. The cluster architecture
is adopted as a hybrid centralized/distributed network. The user differentiation strategy
ensures the QoS guarantee with respect to a priority level of each user. Taking into
account the specifications of the uplink communication, we confirm through comparative
simulations the outperformance of our proposal considering several metrics such as
throughput satisfaction rate, transmitted power, outage probability, special spectrum
reuse and others.},
booktitle = {Proceedings of the 12th ACM International Symposium on Mobility Management and Wireless Access},
pages = {59–66},
numpages = {8},
keywords = {interference mitigation, uplink, QoS, resource allocation, link adaptation, SC-FDMA-femtocell},
location = {Montreal, QC, Canada},
series = {MobiWac '14}
}

@proceedings{10.1145/2898375,
title = {HotSos '16: Proceedings of the Symposium and Bootcamp on the Science of Security},
year = {2016},
isbn = {9781450342773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Science of Security (SoS) emphasizes the advancement of research methods as well as
the development of new research results. This dual focus is intended to improve both
the confidence we gain from scientific results and also the capacity and efficiency
through which we address increasingly challenging technical problems.The HotSoS conferences
have focused on work related to one or more of the five Hard Problems identified by
the Science of Security community:•Scalability and composability in the construction
of secure systems•Policy-governed collaboration in handling data across different
domains of authority for security and privacy protection•Predictive security metrics
to guide choice-making in security engineering and response•Resilient architectures
that can deliver service despite compromised components•Human behavior, modeling users,
operators, and adversaries to support improved design and analysisA second and equally
major focus of the conferences is on the advancement of scientific methods, including
data gathering and analysis, experimental methods, and mathematical models for modeling
and reasoning. This includes the exploration of interactions among these methods to
enhance validity.},
location = {Pittsburgh, Pennsylvania}
}

@inproceedings{10.1145/2676723.2691890,
author = {Hoffman, Mark E.},
title = {Student Board-Writing to Integrate Communication Skills and Content to Enhance Student Learning (Abstract Only)},
year = {2015},
isbn = {9781450329668},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2676723.2691890},
doi = {10.1145/2676723.2691890},
abstract = {Students frequently use a whiteboard to individually demonstrate understanding or
interactively develop understanding in groups. The practice is employed to develop
content knowledge; however, an opportunity to intentionally develop communication
skills is overlooked. On the other hand, instructors carefully integrate instructional
organization and communication to maximize student content learning. Taken together,
this presents an opportunity for students to intentionally improve their communication
skills in the service of content learning. This poster details a "work in progress"
project where students follow organizational guidelines for written homework and board-writing
to facilitate in-class, problem solution presentation. Problem solution presentations
occur during one class period each week. Students are given colored pencils for written
homework and colored markers for board-writing. Student work including written homework
and board-writing was gathered from the 2013 and 2014 iterations of a sophomore-level
computer architecture course. Preliminary analysis of student work shows that students
either adopt the guidelines from the start or learn to use them through feedback and
practice. On the semester-end survey, students report that adopting guidelines for
written homework, board-writing, and color scheme improve presentation, and board-writing
improves student learning. Future work includes gathering data from more students
including recorded student presentations, developing quantitative scores to analyze
student work, and developing measures of student learning.},
booktitle = {Proceedings of the 46th ACM Technical Symposium on Computer Science Education},
pages = {684},
numpages = {1},
keywords = {student board-writing, content learning, communication skills},
location = {Kansas City, Missouri, USA},
series = {SIGCSE '15}
}

@inproceedings{10.5555/2893711.2893715,
author = {Rauter, Tobias and H\"{o}ller, Andrea and Iber, Johannes and Kreiner, Christian},
title = {Thingtegrity: A Scalable Trusted Computing Architecture for the Internet of Things},
year = {2016},
isbn = {9780994988607},
publisher = {Junction Publishing},
address = {USA},
abstract = {Remote attestation is used to prove the integrity of one system (prover) to another
(challenger). The prover measures its configuration and transmits the result to the
challenger for verification. Common attestation methods lead to complex configuration
measurements (e.g., hash of all executables), which are updated every time one of
the software modules changes. The updated configuration has to be distributed to all
possible challengers since they need a reference to enable the verification. Recently,
an idea of reducing the complexity of the configuration measurement by taking into
account privileges of software modules has been presented. However, this approach
has not been exhaustively analyzed since, as yet, no implementation exists. Especially
in the Internet of Things (IoT) domain, where resources are constrained strictly while
devices are potentially physically exposed to adversaries, attestation methodologies
with reduced overhead are desireable. In this work we combine binary-, property- and
privilege-based remote attestation to integrate a trusted computing architecture transparently
into iotivity, an existing IoT middleware. As a first step, we aim to enable to attestation
of the integrity of complex devices with different services to constrained devices.
With the help of an illustrative simulated environment, we show that our architecture
reduces the effort of bootstrapping trusted relations, as well as updating single
modules in the whole system, even if software and devices from different vendors are
combined.},
booktitle = {Proceedings of the 2016 International Conference on Embedded Wireless Systems and Networks},
pages = {23–34},
numpages = {12},
location = {Graz, Austria},
series = {EWSN '16}
}

@article{10.1145/3372136,
author = {Lao, Laphou and Li, Zecheng and Hou, Songlin and Xiao, Bin and Guo, Songtao and Yang, Yuanyuan},
title = {A Survey of IoT Applications in Blockchain Systems: Architecture, Consensus, and Traffic Modeling},
year = {2020},
issue_date = {May 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3372136},
doi = {10.1145/3372136},
abstract = {Blockchain technology can be extensively applied in diverse services, including online
micro-payments, supply chain tracking, digital forensics, health-care record sharing,
and insurance payments. Extending the technology to the Internet of things (IoT),
we can obtain a verifiable and traceable IoT network. Emerging research in IoT applications
exploits blockchain technology to record transaction data, optimize current system
performance, or construct next-generation systems, which can provide additional security,
automatic transaction management, decentralized platforms, offline-to-online data
verification, and so on. In this article, we conduct a systematic survey of the key
components of IoT blockchain and examine a number of popular blockchain applications.In
particular, we first give an architecture overview of popular IoT-blockchain systems
by analyzing their network structures and protocols. Then, we discuss variant consensus
protocols for IoT blockchains, and make comparisons among different consensus algorithms.
Finally, we analyze the traffic model for P2P and blockchain systems and provide several
metrics. We also provide a suitable traffic model for IoT-blockchain systems to illustrate
network traffic distribution.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {18},
numpages = {32},
keywords = {Blockchain, architecture, traffic modeling, IoT, consensus}
}

@inproceedings{10.1145/2568088.2576760,
author = {Ghaith, Shadi and Wang, Miao and Perry, Philip and Murphy, Liam},
title = {Software Contention Aware Queueing Network Model of Three-Tier Web Systems},
year = {2014},
isbn = {9781450327336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2568088.2576760},
doi = {10.1145/2568088.2576760},
abstract = {Using modelling to predict the performance characteristics of software applications
typically uses Queueing Network Models representing the various system hardware resources.
Leaving out the software resources, such as the limited number of threads, in such
models leads to a reduced prediction accuracy. Accounting for Software Contention
is a challenging task as existing techniques to model software components are complex
and require deep knowledge of the software architecture. Furthermore, they also require
complex measurement processes to obtain the model's service demands. In addition,
solving the resultant model usually require simulation solvers which are often time
consuming.In this work, we aim to provide a simpler model for three-tier web software
systems which accounts for Software Contention that can be solved by time efficient
analytical solvers. We achieve this by expanding the existing "Two-Level Iterative
Queuing Modelling of Software Contention" method to handle the number of threads at
the Application Server tier and the number of Data Sources at the Database Server
tier. This is done in a generic manner to allow for extending the solution to other
software components like memory and critical sections. Initial results show that our
technique clearly outperforms existing techniques.},
booktitle = {Proceedings of the 5th ACM/SPEC International Conference on Performance Engineering},
pages = {273–276},
numpages = {4},
keywords = {performance prediction, performance models, web applications, software contention},
location = {Dublin, Ireland},
series = {ICPE '14}
}

@inproceedings{10.5555/2821327.2821330,
author = {Zimmermann, Olaf},
title = {Metrics for Architectural Synthesis and Evaluation: Requirements and Compilation by Viewpoint: An Industrial Experience Report},
year = {2015},
publisher = {IEEE Press},
abstract = {During architectural analysis and synthesis, architectural metrics are established
tacitly or explicitly. In architectural evaluation, these metrics are then consulted
to assess whether architectures are fit for purpose and in line with recommended practices
and published architectural knowledge. This experience report presents a personal
retrospective of the author's use of architectural metrics during 20 years in IT architect
roles in professional services as well as research and development. This reflection
drives the identification of use cases, critical success factors and elements of risk
for architectural metrics management. An initial catalog of architectural metrics
is compiled next, which is organized by viewpoints and domains. The report concludes
with a discussion of practical impact of architectural metrics and potential research
topics in this area.},
booktitle = {Proceedings of the Second International Workshop on Software Architecture and Metrics},
pages = {8–14},
numpages = {7},
keywords = {patterns, viewpoints, architectural metrics, architectural metrics management, enterprise information systems, architectural reviews, integration},
location = {Florence, Italy},
series = {SAM '15}
}

@inproceedings{10.1145/3437120.3437284,
author = {Psilias, Dimitrios and Milidonis, Athanasios and Voyiatzis, Ioannis},
title = {Architecture for Secure UAV Systems},
year = {2020},
isbn = {9781450388979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3437120.3437284},
doi = {10.1145/3437120.3437284},
abstract = {UAV applications are providing an extended range of services in society's needs. These
applications require high execution speed and security to all transmitted data. In
this paper an architecture is proposed for secure UAV applications. The architecture
consists of a microcontroller to execute the flight controller tasks and a FPGA for
implementing the security related tasks. The microcontroller is an Arduino which is
widely used in UAVs. Arduino communicates with all sensors and generates outputs needed
for controlling the UAV's motors. The circuit inside the FPGA encrypts/decrypts data
related to transmission. Measurements taken concerning the execution time and power
consumption, reveal the benefits of the extra hardware added for encryption/decryption
in comparison with those of a single microcontroller.},
booktitle = {24th Pan-Hellenic Conference on Informatics},
pages = {99–102},
numpages = {4},
location = {Athens, Greece},
series = {PCI 2020}
}

@inproceedings{10.1145/2973750.2973766,
author = {Yu, Der-Yeuan and Ranganathan, Aanjhan and Masti, Ramya Jayaram and Soriente, Claudio and Capkun, Srdjan},
title = {SALVE: Server Authentication with Location Verification},
year = {2016},
isbn = {9781450342261},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2973750.2973766},
doi = {10.1145/2973750.2973766},
abstract = {The Location Service (LCS) proposed by the telecommunication industry is an architecture
that allows the location of mobile devices to be accessed in various applications.
We explore the use of LCS in location-enhanced server authentication, which traditionally
relies on certificates. Given recent incidents involving certificate authorities,
various techniques to strengthen server authentication were proposed. They focus on
improving the certificate validation process, such as pinning, revocation, or multi-path
probing. In this paper, we propose using the server's geographic location as a second
factor of its authenticity. Our solution, SALVE, achieves location-based server authentication
by using secure DNS resolution and by leveraging LCS for location measurements. We
develop a TLS extension that enables the client to verify the server's location in
addition to its certificate. Successful server authentication therefore requires a
valid certificate and the server's presence at a legitimate geographic location, e.g.,
on the premises of a data center. SALVE prevents server impersonation by remote adversaries
with mis-issued certificates or stolen private keys of the legitimate server. We develop
a prototype implementation and our evaluation in real-world settings shows that it
incurs minimal impact to the average server throughput. Our solution is backward compatible
and can be integrated with existing approaches for improving server authentication
in TLS.},
booktitle = {Proceedings of the 22nd Annual International Conference on Mobile Computing and Networking},
pages = {401–414},
numpages = {14},
keywords = {location service, TLS, server authentication, location-based authentication},
location = {New York City, New York},
series = {MobiCom '16}
}

@inproceedings{10.4108/icst.pervasivehealth.2014.255331,
author = {Weiss, Patrick and Heldmann, Marcus and Gabrecht, Alexander and Schweikard, Achim and M\"{u}nte, Thomas M. and Maehle, Erik},
title = {A Low Cost Tele-Rehabilitation Device for Training of Wrist and Finger Functions after Stroke},
year = {2014},
isbn = {9781631900112},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
url = {https://doi.org/10.4108/icst.pervasivehealth.2014.255331},
doi = {10.4108/icst.pervasivehealth.2014.255331},
abstract = {There is a need for robotic rehabilitation devices that improve the outcome while
reducing the cost of therapy. This paper presents a device for training of supination/pronation,
dorsal wrist extension, and finger manipulation after stroke. The system exhibits
modularity in terms of the communication architecture and different optional components.
User interfaces (UI) can be implemented on different kinds of devices including a
Rasperry Pi single-board computer on which a Qt-based graphical UI was run in this
instance. Tele-rehabilitation functionality is included using SSL-encrypted RESTful
web services on a three-tier architecture. Expensive sensors were omitted in order
to have a cost-effective system which is a requirement for home-based rehabilitation.
The current-based torque sensing is evaluated by comparing current measurements to
force-torque sensor values. After canceling out the static friction, the low error
justified the omission of an additional sensor.},
booktitle = {Proceedings of the 8th International Conference on Pervasive Computing Technologies for Healthcare},
pages = {422–425},
numpages = {4},
keywords = {robotic rehabilitation, stroke, tele-rehabilitation, wrist and finger functions, home health care},
location = {Oldenburg, Germany},
series = {PervasiveHealth '14}
}

@inproceedings{10.1145/3357141.3357149,
author = {Seabra, Matheus and Naz\'{a}rio, Marcos Felipe and Pinto, Gustavo},
title = {REST or GraphQL? A Performance Comparative Study},
year = {2019},
isbn = {9781450376372},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357141.3357149},
doi = {10.1145/3357141.3357149},
abstract = {Given the variety of architectural models that can be used, a frequent questioning
among software development practitioners is: which architectural model to use? To
respond this question regarding performance issues, three target applications have
been studied, each written using two models web services architectures: REST and GraphQL.
Through research of performance metrics of response time and the average transfer
rate between the requests, it was possible to deduce the particularities of each architectural
model in terms of performance metrics. It was observed that migrating to GraphQL.
resulted in an increase in performance in two-thirds of the tested applications, with
respect to average number of requests per second and transfer rate of data. However,
it was noticed that services after migration for GraphQL performed below its REST
counterpart for workloads above 3000 requests, ranging from 98 to 2159 Kbytes per
second after the migration study. On the other hand, for more trivial workloads, services
on both REST and GraphQL architectures presented similar performances, where values
between REST and GraphQL services ranged from 6.34 to 7.68 requests per second for
workloads of 100 requests.},
booktitle = {Proceedings of the XIII Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {123–132},
numpages = {10},
keywords = {Modelo arquitetural, REST, Teste de desempenho, GraphQL},
location = {Salvador, Brazil},
series = {SBCARS '19}
}

@inproceedings{10.1145/2736084.2736091,
author = {Zhang, Cong and Liu, Jiangchuan},
title = {On Crowdsourced Interactive Live Streaming: A Twitch.Tv-Based Measurement Study},
year = {2015},
isbn = {9781450333528},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2736084.2736091},
doi = {10.1145/2736084.2736091},
abstract = {Empowered by today's rich tools for media generation and collaborative production,
the multimedia service paradigm is shifting from the conventional single source, to
multi-source, to many sources, and now toward crowdsource. Such crowdsourced live
streaming platforms as Twitch.tv allow general users to broadcast their content to
massive viewers, thereby greatly expanding the content and user bases. The resources
available for these non-professional broadcasters however are limited and unstable,
which potentially impair the streaming quality and viewers' experience. The diverse
live interactions among the broadcasters and viewers can further aggravate the problem.In
this paper, we present an initial investigation on the modern crowdsourced live streaming
systems. Taking Twitch as a representative, we outline their inside architecture using
both crawled data and captured traffic of local broadcasters/viewers. Closely examining
the access data collected in a two-month period, we reveal that the view patterns
are determined by both events and broadcasters' sources. Our measurements explore
the unique source- and event-driven views, showing that the current delay strategy
on the viewer's side substantially impacts the viewers' interactive experience, and
there is significant disparity between the long broadcast latency and the short live
messaging latency. On the broadcaster's side, the dynamic uploading capacity is a
critical challenge, which noticeably affects the smoothness of live streaming for
viewers.},
booktitle = {Proceedings of the 25th ACM Workshop on Network and Operating Systems Support for Digital Audio and Video},
pages = {55–60},
numpages = {6},
keywords = {view statistics, crowdsourced live streaming, interactive latency, Twitch.tv},
location = {Portland, Oregon},
series = {NOSSDAV '15}
}

@inproceedings{10.1145/2775292.2775312,
author = {Scully, Timothy and Dobo\v{s}, Jozef and Sturm, Timo and Jung, Yvonne},
title = {3drepo.Io: Building the next Generation Web3D Repository with AngularJS and X3DOM},
year = {2015},
isbn = {9781450336475},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2775292.2775312},
doi = {10.1145/2775292.2775312},
abstract = {This paper presents a novel open source web-based 3D version control system positioned
directly within the context of the recent strategic plan for digitising the construction
sector in the United Kingdom. The aim is to achieve reduction of cost and carbon emissions
in the built environment by up to 20% simply by properly managing digital information
and 3D models. Even though previous works in the field concentrated mainly on defining
novel WebGL frameworks and later on the efficiency of 3D data delivery over the Internet,
there is still the emerging need for a practical solution that would provide ubiquitous
access to 3D assets, whether it is for large international enterprises or individual
members of the general public. We have, therefore, developed a novel platform leveraging
the latest open web-based technologies such as AngularJS and X3DOM in order to define
an industrial-strength collaborative cloud hosting service 3drepo.io. Firstly, we
introduce the work and outline the high-level system architecture as well as improvements
in relation to previous work. Next, we describe database and front-end considerations
with emphasis on scalability and enhanced security. Finally, we present several performance
measurement experiments and a selection of real-life industrial use cases. We conclude
that jQuery provides performance benefits over AngularJS when manipulating large scene
graphs in web browsers.},
booktitle = {Proceedings of the 20th International Conference on 3D Web Technology},
pages = {235–243},
numpages = {9},
keywords = {version control, X3DOM, 3D repo, AngularJS, BIM},
location = {Heraklion, Crete, Greece},
series = {Web3D '15}
}

@inproceedings{10.1145/3405837.3411375,
author = {Khooi, Xin Zhe and Csikor, Levente and Kang, Min Suk and Divakaran, Dinil Mon},
title = {In-Network Defense against AR-DDoS Attacks},
year = {2020},
isbn = {9781450380485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3405837.3411375},
doi = {10.1145/3405837.3411375},
abstract = {The prevalence of the disruptive amplified reflection DDoS (AR-DDoS) attacks is one
of the biggest concerns of all network operators today. The increasing magnitude of
new attacks are rendering existing measures (e.g., scrubbing services) inefficient.
This work demonstrates DIDA, an efficient, topology independent, in-line AR-DDoS detection
and mitigation architecture that operates entirely in the data plane.},
booktitle = {Proceedings of the SIGCOMM '20 Poster and Demo Sessions},
pages = {18–20},
numpages = {3},
keywords = {detection and mitigation, programmable switches, denial-of-service attacks, amplification attacks, in-network, reflection attacks},
location = {Virtual event},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3030207.3044531,
author = {Jun, Tae Joon and Yoo, Myong Hwan and Kim, Daeyoung and Cho, Kyu Tae and Lee, Seung Young and Yeun, Kyuoke},
title = {HPC Supported Mission-Critical Cloud Architecture},
year = {2017},
isbn = {9781450344043},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030207.3044531},
doi = {10.1145/3030207.3044531},
abstract = {Tactical Operations Center (TOC) system in military field is an advanced computer
system composed of multiple servers and desktops to interlock internal/external weapon
systems processing mission-critical applications in combat situation. However, the
current TOC system has several limitations such as difficulty of integrating tactical
weapon systems including missile launch system and radar system into the single TOC
system due to the heterogeneity of HW and SW between systems, and an inefficient computing
resource management for the weapon systems.In this paper, we proposed a novel HPC
supported mission-critical Cloud architecture as TOC for Surface-to-Air-Missile (SAM)
system with OpenStack Cloud OS, Data Distribution Service (DDS), and GPU virtualization
techniques. With this approach, our system provides elastic resource management over
the weapon systems with virtual machines, integration of heterogeneous systems with
different kinds of guest OS, real-time, reliable, and high-speed communication between
the virtual machines and virtualized GPU resource over the virtual machines. Evaluation
of our TOC system includes DDS performance measurement over 10Gbps Ethernet and QDR
InfiniBand networks on the virtualized environment with OpenStack Cloud OS, and GPU
virtualization performance evaluation with two different methods, PCI pass-through
and remote-API. With the evaluation results, we conclude that our system provides
reasonable performance in the combat situation compared to the previous TOC system
while additionally supports scalable and elastic use of computing resource through
the virtual machines.},
booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering},
pages = {223–232},
numpages = {10},
keywords = {cloud computing, tactical operations center, data distribution service, gpgpu},
location = {L'Aquila, Italy},
series = {ICPE '17}
}

@article{10.1145/3442187,
author = {Al-Abbasi, Abubakr O. and Aggarwal, Vaneet},
title = {VidCloud: Joint Stall and Quality Optimization for Video Streaming over Cloud},
year = {2021},
issue_date = {March 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {4},
issn = {2376-3639},
url = {https://doi.org/10.1145/3442187},
doi = {10.1145/3442187},
abstract = {As video-streaming services have expanded and improved, cloud-based video has evolved
into a necessary feature of any successful business for reaching internal and external
audiences. In this article, video streaming over distributed storage is considered
where the video segments are encoded using an erasure code for better reliability.
We consider a representative system architecture for a realistic (typical) content
delivery network (CDN). Given multiple parallel streams/link between each server and
the edge router, we need to determine, for each client request, the subset of servers
to stream the video, as well as one of the parallel streams from each chosen server.
To have this scheduling, this article proposes a two-stage probabilistic scheduling.
The selection of video quality is also chosen with a certain probability distribution
that is optimized in our algorithm. With these parameters, the playback time of video
segments is determined by characterizing the download time of each coded chunk for
each video segment. Using the playback times, a bound on the moment generating function
of the stall duration is used to bound the mean stall duration. Based on this, we
formulate an optimization problem to jointly optimize the convex combination of mean
stall duration and average video quality for all requests, where the two-stage probabilistic
scheduling, video quality selection, bandwidth split among parallel streams, and auxiliary
bound parameters can be chosen. This non-convex problem is solved using an efficient
iterative algorithm. Based on the offline version of our proposed algorithm, an online
policy is developed where servers selection, quality, bandwidth split, and parallel
streams are selected in an online manner. Experimental results show significant improvement
in QoE metrics for cloud-based video as compared to the considered baselines.},
journal = {ACM Trans. Model. Perform. Eval. Comput. Syst.},
month = jan,
articleno = {17},
numpages = {32},
keywords = {erasure codes, Video streaming over cloud, video quality, two-stage probabilistic scheduling, mean stall duration}
}

@inproceedings{10.1145/2666620.2666630,
author = {Vidas, Timothy and Tan, Jiaqi and Nahata, Jay and Tan, Chaur Lih and Christin, Nicolas and Tague, Patrick},
title = {A5: Automated Analysis of Adversarial Android Applications},
year = {2014},
isbn = {9781450331555},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2666620.2666630},
doi = {10.1145/2666620.2666630},
abstract = {Mobile malware is growing - both in overall volume and in number of existing variants
- at a pace rapid enough that systematic manual, human analysis is becoming increasingly
difficult. As a result, there is a pressing need for techniques and tools that provide
automated analysis of mobile malware samples. We present A5, an open source automated
system to process Android malware. A5 is a hybrid system combining static and dynamic
malware analysis techniques. Android's architecture permits many different paths for
malware to react to system events, any of which may result in malicious behavior.
Key innovations in A5 consist of novel methods of interacting with mobile malware
to better coerce malicious behavior, and in combining both virtual and physical pools
of Android platforms to capture behavior that could otherwise be missed. The primary
output of A5 is a set of network threat indicators and intrusion detection system
signatures that can be used to detect and prevent malicious network activity. We detail
A5's distributed design and demonstrate applicability of our interaction techniques
using examples from real malware. Additionally, we compare A5 with other automated
systems and provide performance measurements of an implementation, using a published
dataset of 1,260 unique malware samples, showing that A5 can quickly process large
amounts of malware. We provide a public web interface to our implementation of A5
that allows third parties to use A5 as a web service.},
booktitle = {Proceedings of the 4th ACM Workshop on Security and Privacy in Smartphones &amp; Mobile Devices},
pages = {39–50},
numpages = {12},
keywords = {dynamic analysis, mobile malware, sandbox, virtualization, static analysis, malicious behavior},
location = {Scottsdale, Arizona, USA},
series = {SPSM '14}
}

@inproceedings{10.1145/3052973.3053028,
author = {Inci, Mehmet Sinan and Eisenbarth, Thomas and Sunar, Berk},
title = {Hit by the Bus: QoS Degradation Attack on Android},
year = {2017},
isbn = {9781450349444},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3052973.3053028},
doi = {10.1145/3052973.3053028},
abstract = {Mobile apps need optimal performance and responsiveness to rise amongst numerous rivals
on the market. Further, some apps like media streaming or gaming apps cannot even
function properly with a performance below a certain threshold. In this work, we present
the first performance degradation attack on Android OS that can target rival apps
using a combination of logical channel leakages and low-level architectural bottlenecks
in the underlying hardware. To show the viability of the attack, we design a proof-of-concept
app and test it on various mobile platforms. The attack runs covertly and brings the
target to the level of unresponsiveness. With less than 10% CPU time in the worst
case, it requires minimal computational effort to run as a background service, and
requires only the UsageStats permission from the user. We quantify the impact of our
attack using 11 popular benchmark apps, running 44 different tests.} The measured
QoS degradation varies across platforms and applications, reaching a maximum of 90%
in some cases. The attack combines the leakage from logical channels with low-level
architectural bottlenecks to design a malicious app that can covertly degrade Quality
of Service (QoS) of any targeted app. Furthermore, our attack code has a small footprint
and is not detected by the Android system as malicious. Finally, our app can pass
the Google Play Store malware scanner, Google Bouncer, as well as the top malware
scanners in the Play Store.},
booktitle = {Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security},
pages = {716–727},
numpages = {12},
keywords = {mobile security, mobile malware, performance degradation, QoS attack},
location = {Abu Dhabi, United Arab Emirates},
series = {ASIA CCS '17}
}

@inproceedings{10.1145/2684746.2689095,
author = {Ben Fakih, Hichem and Elhossini, Ahmed and Juurlink, Ben},
title = {An Efficient and Flexible FPGA Implementation of a Face Detection System (Abstract Only)},
year = {2015},
isbn = {9781450333153},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2684746.2689095},
doi = {10.1145/2684746.2689095},
abstract = {Robust and rapid face detection systems are constantly gaining more interest, since
they represent the first stone for many challenging tasks in the field of computer
vision. In this paper a software-hardware co-design approach is presented, that enables
the detection of frontal faces in real time. A complete hardware implementation of
all components taking part of the face detection is introduced. This work is based
on the object detection framework of Viola and Jones, which makes use of a cascade
of classifiers to reduce the computation time. The proposed architecture is flexible,
as it allows the use of multiple instances of the face detector. This makes developers
free to choose the speed range and reserved resources for this task. The current implementation
runs on the Zynq SoC and receives images over IP network, which allows exposing the
face detection task as a remote service that can be consumed from any device connected
to the network. We performed several measurements for the final detector and the software
equivalent. Using three Evaluator cores, the ZedBoard system achieves a maximal average
frame rate of 13.4 FPS when analysing an image containing 640x480 pixels. This stands
for an improvement of 5.25 times compared to the software solution and represents
acceptable results for most real-time systems. On the ZC706 system, a higher frame
rate of 16.58 FPS is achieved. The proposed hardware solution achieved 92% accuracy,
which is low compared to the software solution (97%) due to different scaling algorithm.
The proposed solution achieved higher frame rate compared to other solutions found
in the literature.},
booktitle = {Proceedings of the 2015 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
pages = {261},
numpages = {1},
keywords = {zynq, copmuter visioin, fpga, face detection, viola and jones},
location = {Monterey, California, USA},
series = {FPGA '15}
}

@inproceedings{10.1145/3131365.3131373,
author = {Chung, Taejoong and van Rijswijk-Deij, Roland and Choffnes, David and Levin, Dave and Maggs, Bruce M. and Mislove, Alan and Wilson, Christo},
title = {Understanding the Role of Registrars in DNSSEC Deployment},
year = {2017},
isbn = {9781450351188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3131365.3131373},
doi = {10.1145/3131365.3131373},
abstract = {The Domain Name System (DNS) provides a scalable, flexible name resolution service.
Unfortunately, its unauthenticated architecture has become the basis for many security
attacks. To address this, DNS Security Extensions (DNSSEC) were introduced in 1997.
DNSSEC's deployment requires support from the top-level domain (TLD) registries and
registrars, as well as participation by the organization that serves as the DNS operator.
Unfortunately, DNSSEC has seen poor deployment thus far: despite being proposed nearly
two decades ago, only 1% of .com, .net, and .org domains are properly signed.In this
paper, we investigate the underlying reasons why DNSSEC adoption has been remarkably
slow. We focus on registrars, as most TLD registries already support DNSSEC and registrars
often serve as DNS operators for their customers. Our study uses large-scale, longitudinal
DNS measurements to study DNSSEC adoption, coupled with experiences collected by trying
to deploy DNSSEC on domains we purchased from leading domain name registrars and resellers.
Overall, we find that a select few registrars are responsible for the (small) DNSSEC
deployment today, and that many leading registrars do not support DNSSEC at all, or
require customers to take cumbersome steps to deploy DNSSEC. Further frustrating deployment,
many of the mechanisms for conveying DNSSEC information to registrars are error-prone
or present security vulnerabilities. Finally, we find that using DNSSEC with third-party
DNS operators such as Cloudflare requires the domain owner to take a number of steps
that 40% of domain owners do not complete. Having identified several operational challenges
for full DNSSEC deployment, we make recommendations to improve adoption.},
booktitle = {Proceedings of the 2017 Internet Measurement Conference},
pages = {369–383},
numpages = {15},
keywords = {registrar, DNS, DNS security extension, public key infrastructure, PKI, DNS operator, DNSSEC},
location = {London, United Kingdom},
series = {IMC '17}
}

@inproceedings{10.1145/3003733.3003756,
author = {Efthymiopoulos, Nikolaos and Efthymiopoulou, Maria and Christakidis, Athanasios},
title = {Experimentation on Low Delay and Stable Congestion Control for P2P Video Streaming},
year = {2016},
isbn = {9781450347891},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3003733.3003756},
doi = {10.1145/3003733.3003756},
abstract = {In recent years, a number of research efforts have focused on using peer-to-peer (P2P)
systems in order to provide live streaming (LS) and Video-on-Demand (VoD) services.
Most of them focused on the development of distributed P2P block schedulers for content
exchange among the participating peers and on the architecture of the overlay graph
(P2P overlay) that interconnects the set of these peers. Currently, the effort has
shifted towards the combination of P2P systems with cloud infrastructures. By deploying
monitoring and control architectures they use resources from the cloud in order to
enhance the QoS, thus achieving an attractive trade-off between stability and low
cost operation. However, there is a lack of research effort on the congestion control
layer of these systems while the existing congestion control architectures in use
are not suited for P2P traffic. This paper proposes a P2P congestion control protocol
suitable for LS and VoD that: i) is capable to manage sequential traffic to multiple
network destinations, ii) efficiently exploits the available bandwidth, iii) accurately
measures the idle peers' resources, iv) it avoids network congestion, and v) is friendly
to other TCP generated traffic. Our proposed algorithms and protocol have been implemented,
tested and evaluated through a series of real experiments in the context of STEER
[20].},
booktitle = {Proceedings of the 20th Pan-Hellenic Conference on Informatics},
articleno = {48},
numpages = {6},
keywords = {video streaming, P2P, congestion control},
location = {Patras, Greece},
series = {PCI '16}
}

@inproceedings{10.1145/3375555.3384938,
author = {Zibitsker, Boris and Lupersolsky, Alex},
title = {How to Apply Modeling to Compare Options and Select the Appropriate Cloud Platform},
year = {2020},
isbn = {9781450371094},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375555.3384938},
doi = {10.1145/3375555.3384938},
abstract = {Organizations want to take advantage of the flexibility and scalability of Cloud platforms.
By migrating to the Cloud, they hope to develop and implement new applications faster
with lower cost. Amazon AWS, Microsoft Azure, Google, IBM, Oracle and others Cloud
providers support different DBMS like Snowflake, Redshift, Teradata Vantage, and others.
These platforms have different architectures, mechanisms of allocation and management
of resources, and levels of sophistication of DBMS optimizers which affect performance,
scalability and cost. As a result, the response time, CPU Service Time and the number
of I/Os for the same query, accessing the similar table in the Cloud could be significantly
different than On Prem. In order to select the appropriate Cloud platform as a first
step we perform a Workload Characterization for On Prem Data Warehouse. Each Data
Warehouse workload represents a specific line of business and includes activity of
many users generating concurrently simple and complex queries accessing data from
different tables. Each workload has different demands for resources and different
Response Time and Throughput Service Level Goals. In this presentation we will review
results of the workload characterization for an On Prem Data Warehouse environment.
During the second step we collected measurement data for standard TPC-DS benchmark
tests performed in AWS Vantage, Redshift and Snowflake Cloud platform for different
sizes of the data sets and different number of concurrent users. During the third
step we used the results of the workload characterization and measurement data collected
during the benchmark to modify BEZNext On Prem Closed Queueing model to model individual
Clouds. And finally, during the fourth step we used our Model to take into consideration
differences in concurrency, priorities and resource allocation to different workloads.
BEZNext optimization algorithms incorporating Graduate search mechanism are used to
find the AWS instance type and minimum number of instances which will be required
to meet SLGs for each of the workloads. Publicly available information about the cost
of the different AWS instances is used to predict the cost of supporting workloads
in the Cloud month by month during next 12 months.},
booktitle = {Companion of the ACM/SPEC International Conference on Performance Engineering},
pages = {16},
numpages = {1},
keywords = {seasonality determination, service level goals, workload forecasting, benchmarking, workload characterization, cloud platform, optimization., modeling},
location = {Edmonton AB, Canada},
series = {ICPE '20}
}

@inproceedings{10.1145/2959100.2959122,
author = {Celma, Oscar},
title = {The Exploit-Explore Dilemma in Music Recommendation},
year = {2016},
isbn = {9781450340359},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2959100.2959122},
doi = {10.1145/2959100.2959122},
abstract = {Were The Rolling Stones right when they said, "You can't always get what you want;
but if you try sometime you get what you need"? Recommendation systems are the crystal
ball of the Internet: predicting user intentions, making sense of big data, and delivering
what people are looking for before they even know they want it. Pandora radio is best
known for the Music Genome Project; the most unique and richly labeled music catalog
of 1.5 million+ tracks. While this content-based approach to music recommendation
is extremely effective and still used today as the foundation to the leading online
radio service, Pandora has also collected more than a decade of contextual listener
feedback in the form of more than 65 billion thumbs from 79M+ monthly active users
who have created more than 9 billion stations. This session will look at how the interdisciplinary
team at Pandora goes about making sense of these massive data sets to successfully
make large scale music recommendations to our listeners.As opposed to more traditional
recommender systems which need only to recommend a single item or set of items, Pandora's
recommenders must provide an evolving set of sequential items, which constantly keep
the experience new and exciting. In this talk I will present a dynamic ensemble learning
system that combines musicological data and machine learning models to provide a truly
personalized experience. This approach allows us to switch from a lean back experience
(exploitation) to a more exploration mode to discover new music tailored specifically
to users individual tastes. To exemplify this, I will present a recently launched
product led by the research team, Thumbprint Radio.Following this session the audience
will have an in-depth understanding of how Pandora uses science to determine the perfect
balance of familiarity, discovery, repetition and relevance for each individual listener,
measures and evaluates user satisfaction, and how our online and offline architecture
stack plays a critical role in our success.},
booktitle = {Proceedings of the 10th ACM Conference on Recommender Systems},
pages = {377},
numpages = {1},
keywords = {machine listening, ensemble learning, content-based recommendation, thumbprint radio, A/B online testing, offline evaluation, exploit-explore dilemma},
location = {Boston, Massachusetts, USA},
series = {RecSys '16}
}

@inproceedings{10.1145/3241539.3241567,
author = {Marquez, Cristina and Gramaglia, Marco and Fiore, Marco and Banchs, Albert and Costa-Perez, Xavier},
title = {How Should I Slice My Network? A Multi-Service Empirical Evaluation of Resource Sharing Efficiency},
year = {2018},
isbn = {9781450359030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3241539.3241567},
doi = {10.1145/3241539.3241567},
abstract = {By providing especially tailored instances of a virtual network,network slicing allows
for a strong specialization of the offered services on the same shared infrastructure.
Network slicing has profound implications on resource management, as it entails an
inherent trade-off between: (i) the need for fully dedicated resources to support
service customization, and (ii) the dynamic resource sharing among services to increase
resource efficiency and cost-effectiveness of the system. In this paper, we provide
a first investigation of this trade-off via an empirical study of resource management
efficiency in network slicing. Building on substantial measurement data collected
in an operational mobile network (i) we quantify the efficiency gap introduced by
non-reconfigurable allocation strategies of different kinds of resources, from radio
access to the core of the network, and (ii) we quantify the advantages of their dynamic
orchestration at different timescales. Our results provide insights on the achievable
efficiency of network slicing architectures, their dimensioning, and their interplay
with resource management algorithms.},
booktitle = {Proceedings of the 24th Annual International Conference on Mobile Computing and Networking},
pages = {191–206},
numpages = {16},
keywords = {resource management, network efficiency, network slicing},
location = {New Delhi, India},
series = {MobiCom '18}
}

@inproceedings{10.5555/2667510.2667516,
author = {Seneviratne, Janaka and Parampalli, Udaya and Kulik, Lars},
title = {An Authorised Pseudonym System for Privacy Preserving Location Proof Architectures},
year = {2014},
isbn = {9781921770326},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {An emerging class of Location Based Services (LBSs) needs verified mobile device locations
for service provision. For example, an automated car park billing system requires
verified locations of cars to confirm the place and the duration of parked cars. Location
Proof Architectures (LPAs) allow a user (or a device on behalf of its user) to obtain
a proof of its presence at a location from a trusted third party. A major concern
in LPAs is to preserve user location privacy. To achieve this a user's identity and
location data should be maintained separately with additional measures that prevent
leaking sensitive identity and location data. In this paper, we present a privacy
preserving LPA in which users appear under pseudonyms. Our main contribution is a
third party free pseudonym registering protocol based on blind signature schemes.
We show that our protocol allows to build a pseudonym system with a guaranteed degree
of privacy agreed at the time of pseudonym registration. We also demonstrate that
a pseudonym can be authenticated across different organizations in an LPA. Our system
ensures that (i) only authenticated users can register their pseudonyms, (ii) the
pseudonyms have a consistent degree of privacy at the point of registration and (iii)
a user cannot take another user's pseudonym.},
booktitle = {Proceedings of the Twelfth Australasian Information Security Conference - Volume 149},
pages = {47–56},
numpages = {10},
keywords = {pseudonym, location proof architecture, privacy},
location = {Auckland, New Zealand},
series = {AISC '14}
}

