% Encoding: UTF-8

@InProceedings{Anchuri2014,
  author    = {Anchuri, Pranay and Sumbaly, Roshan and Shah, Sam},
  booktitle = {Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management},
  title     = {Hotspot Detection in a Service-Oriented Architecture},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {1749–1758},
  publisher = {Association for Computing Machinery},
  series    = {CIKM '14},
  abstract  = {Large-scale websites are predominantly built as a service-oriented architecture. Here,
services are specialized for a certain task, run on multiple machines, and communicate
with each other to serve a user's request. Reducing latency and improving the cost
to serve is quite important, but optimizing this service call graph is particularly
challenging due to the volume of data and the graph's non-uniform and dynamic nature.In
this paper, we present a framework to detect hotspots in a service-oriented architecture.
The framework is general, in that it can handle arbitrary objective functions. We
show that finding the optimal set of hotspots for a metric, such as latency, is NP-complete
and propose a greedy algorithm by relaxing some constraints. We use a pattern mining
algorithm to rank hotspots based on the impact and consistency. Experiments on real
world service call graphs from LinkedIn, the largest online professional social network,
show that our algorithm consistently outperforms baseline methods.},
  doi       = {10.1145/2661829.2661991},
  file      = {:Anchuri2014 - Hotspot Detection in a Service Oriented Architecture.pdf:PDF},
  isbn      = {9781450325981},
  keywords  = {monitoring, call graph, service-oriented architecture, hotspots},
  location  = {Shanghai, China},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2661829.2661991},
}

@InProceedings{Oliveira2016,
  author    = {Oliveira, Joyce Aline and Junior, Jose J.L.D.},
  booktitle = {Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1},
  title     = {A Three-Dimensional View of Reuse in Service Oriented Architecture},
  year      = {2016},
  address   = {Porto Alegre, BRA},
  pages     = {409–416},
  publisher = {Brazilian Computer Society},
  series    = {SBSI 2016},
  abstract  = {The reuse in Service Oriented Architecture (SOA) has been used strategically in organizations
to reduce development costs and increase the quality of applications. This article
reports a qualitative research realized with experts in order to identify goals, barriers,
facilitators, strategies, metrics and benefits associated with reuse in SOA. The results
were summarized in three dimensions (management, architecture, operation) and represented
by a conceptual model that can serve as a preliminary roadmap to manage the reuse
in SOA.},
  isbn      = {9788576693178},
  keywords  = {qualitative research, SOA reuse, Services Oriented Architecture},
  location  = {Florianopolis, Santa Catarina, Brazil},
  numpages  = {8},
}

@InProceedings{Lehmann2017,
  author    = {Lehmann, Martin and Sandnes, Frode Eika},
  booktitle = {Proceedings of the Second International Conference on Internet of Things, Data and Cloud Computing},
  title     = {A Framework for Evaluating Continuous Microservice Delivery Strategies},
  year      = {2017},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ICC '17},
  abstract  = {The emergence of service-oriented computing, and in particular microservice architecture,
has introduced a new layer of complexity to the already challenging task of continuously
delivering changes to the end users. Cloud computing has turned scalable hardware
into a commodity, but also imposes some requirements on the software development process.
Yet, the literature mainly focuses on quantifiable metrics such as number of manual
steps and lines of code required to make a change. The industry, on the other hand,
appears to focus more on qualitative metrics such as increasing the productivity of
their developers. These are common goals, but must be measured using different approaches.
Therefore, based on interviews of industry stakeholders a framework for evaluating
and comparing approaches to continuous microservice delivery is proposed. We show
that it is possible to efficiently evaluate and compare strategies for continuously
delivering microservices.},
  articleno = {64},
  doi       = {10.1145/3018896.3018961},
  file      = {:Lehmann2017 - A Framework for Evaluating Continuous Microservice Delivery Strategies.pdf:PDF},
  isbn      = {9781450347747},
  keywords  = {microservices, microservice architectures, deployment strategy, cloud computing, evaluation framework, continuous deployment},
  location  = {Cambridge, United Kingdom},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3018896.3018961},
}

@InProceedings{Oliveira2018,
  author    = {Oliveira, Joyce Aline and Vargas, Matheus and Rodrigues, Roni},
  booktitle = {Proceedings of the XIV Brazilian Symposium on Information Systems},
  title     = {SOA Reuse: Systematic Literature Review Updating and Research Directions},
  year      = {2018},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {SBSI'18},
  abstract  = {Service Oriented Architecture (SOA) reuse has been used strategically in organizations
to reduce development costs and increase the quality of applications. This article
analyzes a systematic literature review in order to identify concepts, goals, strategies,
and metrics of SOA reuse. The results show that the main goal of SOA reuse is to decrease
development costs. The factor that most negatively influences SOA reuse is the existence
of legacy systems. The strategy used most to potentialize SOA reuse is business process
management. Metrics proposed by studies to measure SOA reuse are related to modularity
and adaptability indicators. The study is relevant because it increases the body of
knowledge of the area. Additionally, a set of gaps to be addressed by researchers
and reuse practitioners was identified.},
  articleno = {71},
  doi       = {10.1145/3229345.3229419},
  file      = {:Oliveira2018 - SOA Reuse_ Systematic Literature Review Updating and Research Directions.pdf:PDF},
  isbn      = {9781450365598},
  keywords  = {Service Oriented Architecture, systematic literature review, SOA reuse},
  location  = {Caxias do Sul, Brazil},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3229345.3229419},
}

@InProceedings{Ilin2017,
  author    = {Ilin, I. and Levina, A. and Abran, A. and Iliashenko, O.},
  booktitle = {Proceedings of the 27th International Workshop on Software Measurement and 12th International Conference on Software Process and Product Measurement},
  title     = {Measurement of Enterprise Architecture (EA) from an IT Perspective: Research Gaps and Measurement Avenues},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {232–243},
  publisher = {Association for Computing Machinery},
  series    = {IWSM Mensura '17},
  abstract  = {Reorganizational projects in general and software-related projects in particular,
are often implemented with a focus only on the reorganized components within an organizational
management system, not taking into account relationships with the other components
of an enterprise architecture (EA). This paper first looks at the current state of
EA measurement to identify weaknesses and gaps in aligning and measuring EA components,
EA structures and EA interrelationships from an IT perspective. It then identifies
from related works available innovative measurement concepts that could contribute
for aligning, measuring and monitoring software-related projects within an EA strategy.
This includes measurement avenues within a Balanced Scorecard (BSC), contributions
of functional size measurement to the BSC, and measurement of software structures
and functionality within a service-oriented architecture (SOA).},
  doi       = {10.1145/3143434.3143457},
  file      = {:Ilin2017 - Measurement of Enterprise Architecture (EA) from an IT Perspective_ Research Gaps and Measurement Avenues.pdf:PDF},
  isbn      = {9781450348539},
  keywords  = {balanced scorecard (BSC), function points (FP), enterprise architecture (EA), enterprise architecture measurement, service-oriented architecture (SOA), functional size measurement (FSM)},
  location  = {Gothenburg, Sweden},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3143434.3143457},
}

@InProceedings{Bogner2018,
  author    = {Bogner, Justus and Fritzsch, Jonas and Wagner, Stefan and Zimmermann, Alfred},
  booktitle = {Proceedings of the 2018 International Conference on Technical Debt},
  title     = {Limiting Technical Debt with Maintainability Assurance: An Industry Survey on Used Techniques and Differences with Service- and Microservice-Based Systems},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {125–133},
  publisher = {Association for Computing Machinery},
  series    = {TechDebt '18},
  abstract  = {Maintainability assurance techniques are used to control this quality attribute and
limit the accumulation of potentially unknown technical debt. Since the industry state
of practice and especially the handling of Service- and Microservice-Based Systems
in this regard are not well covered in scientific literature, we created a survey
to gather evidence for a) used processes, tools, and metrics in the industry, b) maintainability-related
treatment of systems based on service-orientation, and c) influences on developer
satisfaction w.r.t. maintainability. 60 software professionals responded to our online
questionnaire. The results indicate that using explicit and systematic techniques
has benefits for maintainability. The more sophisticated the applied methods the more
satisfied participants were with the maintainability of their software while no link
to a hindrance in productivity could be established. Other important findings were
the absence of architecture-level evolvability control mechanisms as well as a significant
neglect of service-oriented particularities for quality assurance. The results suggest
that industry has to improve its quality control in these regards to avoid problems
with long-living service-based software systems.},
  doi       = {10.1145/3194164.3194166},
  file      = {:Bogner2018 - Limiting Technical Debt with Maintainability Assurance_ an Industry Survey on Used Techniques and Differences with Service and Microservice Based Systems.pdf:PDF},
  isbn      = {9781450357135},
  keywords  = {microservice-based systems, maintainability, industry, survey, software quality control, service-based systems},
  location  = {Gothenburg, Sweden},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3194164.3194166},
}

@Article{Wu2018,
  author     = {Wu, Yumei and Fang, Yuanyuan and Liu, Bin and Zhao, Zehui},
  journal    = {Personal Ubiquitous Comput.},
  title      = {A Novel Service Deployment Approach Based on Resilience Metrics for Service-Oriented System},
  year       = {2018},
  issn       = {1617-4909},
  month      = oct,
  number     = {5–6},
  pages      = {1099–1107},
  volume     = {22},
  abstract   = {Service-Oriented Architecture (SOA) has been widely used in IT areas and is expected
to bring a lot of benefits. However, the SOA system developers have to address new
challenging issues such as computational resource failure before such benefits can
be realized. This paper develops a graph-theoretic model for the SOA system and proposes
metrics that quantify the resilience of such system under resource failures. It explores
two service deployment strategies to optimize resilience by taking not only communication
costs among services but also the computation costs of services into consideration.
Among them, two types of undirected graphs are developed to model the relationships
between services, including Service Dependence Graph (SDG) and Service Concurrence
Graph (SCG). Then, these two graphs are integrated into Service Relationship Graph
(SRG) and adopt the k-cut optimization theory to complete the service deployment.
Finally, this paper verifies the effectiveness of the above methods in improving the
resilience of the system through a series of experiments, which indicate that our
methods perform better than the previous methods in improving resilience of the SOA
system.},
  address    = {Berlin, Heidelberg},
  file       = {:Wu2018 - A Novel Service Deployment Approach Based on Resilience Metrics for Service Oriented System.pdf:PDF},
  issue_date = {October 2018},
  keywords   = {Resilience, SOA, Service relationship graph, Service deployment},
  numpages   = {9},
  publisher  = {Springer-Verlag},
}

@InProceedings{Camargo2016,
  author    = {de Camargo, Andr\'{e} and Salvadori, Ivan and Mello, Ronaldo dos Santos and Siqueira, Frank},
  booktitle = {Proceedings of the 18th International Conference on Information Integration and Web-Based Applications and Services},
  title     = {An Architecture to Automate Performance Tests on Microservices},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {422–429},
  publisher = {Association for Computing Machinery},
  series    = {iiWAS '16},
  abstract  = {The microservices architecture provides a new approach to develop applications. As
opposed to monolithic applications, in which the application comprises a single software
artifact, an application based on the microservices architecture is composed by a
set of services, each one designed to perform a single and well-defined task. These
services allow the development team to decouple several parts of the application using
different frameworks, languages and hardware for each part of the system. One of the
drawbacks for adopting the microservices architecture to develop applications is testability.
In a single application test boundaries can be more easily established and tend to
be more stable as the application evolves, while with microservices we can have a
set of hundreds of services that operate together and are prone to change more rapidly.
Each one of these services needs to be tested and updated as the service changes.
In addition, the different characteristics of these services such as languages, frameworks
or the used infrastructure have to be considered in the testing phase. Performance
tests are applied to assure that a particular software complies with a set of non-functional
requirements such as throughput and response time. These metrics are important to
ensure that business constraints are respected and to help finding performance bottlenecks.
In this paper, we present a new approach to allow the performance tests to be executed
in an automated way, with each microservice providing a test specification that is
used to perform tests. Along with the architecture, we also provide a framework that
implements some key concepts of this architecture. This framework is available as
an open source project1.},
  doi       = {10.1145/3011141.3011179},
  file      = {:Camargo2016 - An Architecture to Automate Performance Tests on Microservices.pdf:PDF},
  isbn      = {9781450348072},
  keywords  = {test automation, performance test, microservices},
  location  = {Singapore, Singapore},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3011141.3011179},
}

@InProceedings{Brito2021,
  author    = {Brito, Miguel and Cunha, J\'{a}come and Saraiva, Jo\~{a}o},
  booktitle = {Proceedings of the 36th Annual ACM Symposium on Applied Computing},
  title     = {Identification of Microservices from Monolithic Applications through Topic Modelling},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {1409–1418},
  publisher = {Association for Computing Machinery},
  series    = {SAC '21},
  abstract  = {Microservices emerged as one of the most popular architectural patterns in the recent
years given the increased need to scale, grow and flexibilize software projects accompanied
by the growth in cloud computing and DevOps. Many software applications are being
submitted to a process of migration from its monolithic architecture to a more modular,
scalable and flexible architecture of microservices. This process is slow and, depending
on the project's complexity, it may take months or even years to complete.This paper
proposes a new approach on microservice identification by resorting to topic modelling
in order to identify services according to domain terms. This approach in combination
with clustering techniques produces a set of services based on the original software.
The proposed methodology is implemented as an open-source tool for exploration of
monolithic architectures and identification of microservices. A quantitative analysis
using the state of the art metrics on independence of functionality and modularity
of services was conducted on 200 open-source projects collected from GitHub. Cohesion
at message and domain level metrics' showed medians of roughly 0.6. Interfaces per
service exhibited a median of 1.5 with a compact interquartile range. Structural and
conceptual modularity revealed medians of 0.2 and 0.4 respectively.Our first results
are positive demonstrating beneficial identification of services due to overall metrics'
results.},
  doi       = {10.1145/3412841.3442016},
  file      = {:Brito2021 - Identification of Microservices from Monolithic Applications through Topic Modelling.pdf:PDF},
  isbn      = {9781450381048},
  location  = {Virtual Event, Republic of Korea},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3412841.3442016},
}

@InProceedings{Ma2020,
  author    = {Ma, Meng and Xu, Jingmin and Wang, Yuan and Chen, Pengfei and Zhang, Zonghua and Wang, Ping},
  booktitle = {Proceedings of The Web Conference 2020},
  title     = {AutoMAP: Diagnose Your Microservice-Based Web Applications Automatically},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {246–258},
  publisher = {Association for Computing Machinery},
  series    = {WWW '20},
  abstract  = {The high complexity and dynamics of the microservice architecture make its application
diagnosis extremely challenging. Static troubleshooting approaches may fail to obtain
reliable model applies for frequently changing situations. Even if we know the calling
dependency of services, we lack a more dynamic diagnosis mechanism due to the existence
of indirect fault propagation. Besides, algorithm based on single metric usually fail
to identify the root cause of anomaly, as single type of metric is not enough to characterize
the anomalies occur in diverse services. In view of this, we design a novel tool,
named AutoMAP, which enables dynamic generation of service correlations and automated
diagnosis leveraging multiple types of metrics. In AutoMAP, we propose the concept
of anomaly behavior graph to describe the correlations between services associated
with different types of metrics. Two binary operations, as well as a similarity function
on behavior graph are defined to help AutoMAP choose appropriate diagnosis metric
in any particular scenario. Following the behavior graph, we design a heuristic investigation
algorithm by using forward, self, and backward random walk, with an objective to identify
the root cause services. To demonstrate the strengths of AutoMAP, we develop a prototype
and evaluate it in both simulated environment and real-work enterprise cloud system.
Experimental results clearly indicate that AutoMAP achieves over 90% precision, which
significantly outperforms other selected baseline methods. AutoMAP can be quickly
deployed in a variety of microservice-based systems without any system knowledge.
It also supports introduction of various expert knowledge to improve accuracy.},
  doi       = {10.1145/3366423.3380111},
  file      = {:Ma2020 - AutoMAP_ Diagnose Your Microservice Based Web Applications Automatically.pdf:PDF},
  isbn      = {9781450370233},
  keywords  = {anomaly diagnosis, web application, Microservice architecture, root cause, cloud computing},
  location  = {Taipei, Taiwan},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3366423.3380111},
}

@InProceedings{Lopez2017,
  author    = {L\'{o}pez, Manuel Ram\'{\i}rez and Spillner, Josef},
  booktitle = {Companion Proceedings of The10th International Conference on Utility and Cloud Computing},
  title     = {Towards Quantifiable Boundaries for Elastic Horizontal Scaling of Microservices},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {35–40},
  publisher = {Association for Computing Machinery},
  series    = {UCC '17 Companion},
  abstract  = {One of the most useful features of a microservices architecture is its versatility
to scale horizontally. However, not all services scale in or out uniformly. The performance
of an application composed of microservices depends largely on a suitable combination
of replica count and resource capacity. In practice, this implies limitations to the
efficiency of autoscalers which often overscale based on an isolated consideration
of single service metrics. Consequently, application providers pay more than necessary
despite zero gain in overall performance. Solving this issue requires an application-specific
determination of scaling limits due to the general infeasibility of an application-agnostic
solution. In this paper, we study microservices scalability, the auto-scaling of containers
as microservice implementations and the relation between the number of replicas and
the resulting application task performance. We contribute a replica count determination
solution with a mathematical approach. Furthermore, we offer a calibration software
tool which places scalability boundaries into declarative composition descriptions
of applications ready to be consumed by cloud platforms.},
  doi       = {10.1145/3147234.3148111},
  file      = {:Lopez2017 - Towards Quantifiable Boundaries for Elastic Horizontal Scaling of Microservices.pdf:PDF},
  isbn      = {9781450351959},
  keywords  = {scalability, replication, optimization, microservices},
  location  = {Austin, Texas, USA},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3147234.3148111},
}

@InProceedings{FreitasApolinario2020,
  author    = {de Freitas Apolin\'{a}rio, Daniel Rodrigo and de Fran\c{c}a, Breno Bernard Nicolau},
  booktitle = {Proceedings of the 14th Brazilian Symposium on Software Components, Architectures, and Reuse},
  title     = {Towards a Method for Monitoring the Coupling Evolution of Microservice-Based Architectures},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {71–80},
  publisher = {Association for Computing Machinery},
  series    = {SBCARS '20},
  abstract  = {The microservice architecture is claimed to satisfy ongoing software development demands,
such as resilience, flexibility, and velocity. However, developing applications based
on microservices also brings some drawbacks, such as the increased software operational
complexity. Recent studies have also pointed out the lack of methods to prevent problems
related to the maintainability of these solutions. Disregarding established design
principles during the software evolution may lead to the so-called architectural erosion,
which can end up in a condition of unfeasible maintenance. As microservices can be
considered a new architecture style, there are few initiatives to monitoring the evolution
of software microservice-based architectures. In this paper, we introduce the SYMBIOTE
method for monitoring the coupling evolution of microservice-based systems. More specifically,
this method collects coupling metrics during runtime (staging or production environments)
and monitors them throughout software evolution. The longitudinal analysis of the
collected measures allows detecting an upward trend in coupling metrics that could
be signs of architectural erosion. To develop the proposed method, we performed an
experimental analysis of the coupling metrics behavior using artificially-generated
data.},
  doi       = {10.1145/3425269.3425273},
  file      = {:FreitasApolinario2020 - Towards a Method for Monitoring the Coupling Evolution of Microservice Based Architectures.pdf:PDF},
  isbn      = {9781450387545},
  keywords  = {maintainability, coupling metrics, software evolution, microservices},
  location  = {Natal, Brazil},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3425269.3425273},
}

@InProceedings{Cardarelli2019,
  author    = {Cardarelli, Mario and Iovino, Ludovico and Di Francesco, Paolo and Di Salle, Amleto and Malavolta, Ivano and Lago, Patricia},
  booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
  title     = {An Extensible Data-Driven Approach for Evaluating the Quality of Microservice Architectures},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {1225–1234},
  publisher = {Association for Computing Machinery},
  series    = {SAC '19},
  abstract  = {Microservice architecture (MSA) is defined as an architectural style where the software
system is developed as a suite of small services, each running in its own process
and communicating with lightweight mechanisms. The benefits of MSA are many, ranging
from an increase in development productivity, to better business-IT alignment, agility,
scalability, and technology flexibility. The high degree of microservices distribution
and decoupling is, however, imposing a number of relevant challenges from an architectural
perspective. In this context, measuring, controlling, and keeping a satisfactory level
of quality of the system architecture is of paramount importance.In this paper we
propose an approach for the specification, aggregation, and evaluation of software
quality attributes for the architecture of microservice-based systems. The proposed
approach allows developers to (i) produce architecture models of the system, either
manually or automatically via recovering techniques, (ii) contribute to an ecosystem
of well-specified and automatically-computable software quality attributes for MSAs,
and (iii) continuously measure and evaluate the architecture of their systems by (re-)using
the software quality attributes defined in the ecosystem. The approach is implemented
by using Model-Driven Engineering techniques.The current implementation of the approach
has been validated by assessing the maintainability of a third-party, publicly available
benchmark system.},
  doi       = {10.1145/3297280.3297400},
  file      = {:Cardarelli2019 - An Extensible Data Driven Approach for Evaluating the Quality of Microservice Architectures.pdf:PDF},
  isbn      = {9781450359337},
  keywords  = {microservices, architecture recovery, software quality, model-driven},
  location  = {Limassol, Cyprus},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3297280.3297400},
}

@InProceedings{Brilhante2017,
  author    = {Brilhante, Jonathan and Costa, Rostand and Maritan, Tiago},
  booktitle = {Proceedings of the 23rd Brazillian Symposium on Multimedia and the Web},
  title     = {Asynchronous Queue Based Approach for Building Reactive Microservices},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {373–380},
  publisher = {Association for Computing Machinery},
  series    = {WebMedia '17},
  abstract  = {To achieve scalability and flexibility in larger applications a new approach arises,
named by Microservices (MS). However MS architectures are at their inception and are
even more a concept than a fully mature design pattern. One of the hardest topics
in this approach is how to properly migrate or develop a single microservice, in terms
of scope, efficiency and dependability. In this sense, this work proposes a new architectural
model based on high-level architecture pattern of reactive programming to the internal
structure of a new microservice. The new model of microservices are internally coordinated
by asynchronous queues, which allowed to preserve compatibility with most monolithic
components and provide an encapsulation process to enable its continuity. A comparative
study between the standard approach and the proposed architecture was carried out
to measure the eventual performance improvement of the new strategy.},
  doi       = {10.1145/3126858.3126873},
  file      = {:Brilhante2017 - Asynchronous Queue Based Approach for Building Reactive Microservices.pdf:PDF},
  isbn      = {9781450350969},
  keywords  = {asynchronous queues, reactive approach, micro services, refactoring},
  location  = {Gramado, RS, Brazil},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3126858.3126873},
}

@InProceedings{Khazaei2017,
  author    = {Khazaei, Hamzeh and Ravichandiran, Rajsimman and Park, Byungchul and Bannazadeh, Hadi and Tizghadam, Ali and Leon-Garcia, Alberto},
  booktitle = {Proceedings of the 27th Annual International Conference on Computer Science and Software Engineering},
  title     = {Elascale: Autoscaling and Monitoring as a Service},
  year      = {2017},
  address   = {USA},
  pages     = {234–240},
  publisher = {IBM Corp.},
  series    = {CASCON '17},
  abstract  = {Auto-scalability has become an evident feature for cloud software systems including
but not limited to big data and IoT applications. Cloud application providers now
are in full control over their applications' microservices and macroservices; virtual
machines and containers can be provisioned or deprovisioned on demand at run-time.
Elascale strives to adjust both micro/macro resources with respect to workload and
changes in the internal state of the whole application stack. Elascale leverages Elasticsearch
stack for collection, analysis and storage of performance metrics. Elascale then uses
its default scaling engine to elastically adapt the managed application. Extendibility
is guaranteed through provider, schema, plug-in and policy elements in the Elascale
by which flexible scalability algorithms, including both reactive and proactive techniques,
can be designed and implemented for various technologies, infrastructures and software
stacks. In this paper, we present the architecture and initial implementation of Elascale;
an instance will be leveraged to add auto-scalability to a generic IoT application.
Due to zero dependency to the target software system, Elascale can be leveraged to
provide auto-scalability and monitoring as-a-service for any type of cloud software
system.},
  file      = {:Khazaei2017 - Elascale_ Autoscaling and Monitoring As a Service.pdf:PDF},
  keywords  = {macroservices, elasticsearch, monitoring, microservices, auto-scalability, cloud application, scalability as a service, containers, docker},
  location  = {Markham, Ontario, Canada},
  numpages  = {7},
}

@InProceedings{Toffetti2015,
  author    = {Toffetti, Giovanni and Brunner, Sandro and Bl\"{o}chlinger, Martin and Dudouet, Florian and Edmonds, Andrew},
  booktitle = {Proceedings of the 1st International Workshop on Automated Incident Management in Cloud},
  title     = {An Architecture for Self-Managing Microservices},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {19–24},
  publisher = {Association for Computing Machinery},
  series    = {AIMC '15},
  abstract  = {Running applications in the cloud efficiently requires much more than deploying software
in virtual machines. Cloud applications have to be continuously managed: 1) to adjust
their resources to the incoming load and 2) to face transient failures replicating
and restarting components to provide resiliency on unreliable infrastructure. Continuous
management monitors application and infrastructural metrics to provide automated and
responsive reactions to failures (health management) and changing environmental conditions
(auto-scaling) minimizing human intervention.In the current practice, management functionalities
are provided as infrastructural or third party services. In both cases they are external
to the application deployment. We claim that this approach has intrinsic limits, namely
that separating management functionalities from the application prevents them from
naturally scaling with the application and requires additional management code and
human intervention. Moreover, using infrastructure provider services for management
functionalities results in vendor lock-in effectively preventing cloud applications
to adapt and run on the most effective cloud for the job.In this position paper we
propose a novel architecture that enables scalable and resilient self-management of
microservices applications on cloud.},
  doi       = {10.1145/2747470.2747474},
  file      = {:Toffetti2015 - An Architecture for Self Managing Microservices.pdf:PDF},
  isbn      = {9781450334761},
  location  = {Bordeaux, France},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2747470.2747474},
}

@Article{Brondolin2020,
  author     = {Brondolin, Rolando and Santambrogio, Marco D.},
  journal    = {ACM Trans. Archit. Code Optim.},
  title      = {A Black-Box Monitoring Approach to Measure Microservices Runtime Performance},
  year       = {2020},
  issn       = {1544-3566},
  month      = nov,
  number     = {4},
  volume     = {17},
  abstract   = {Microservices changed cloud computing by moving the applications’ complexity from
one monolithic executable to thousands of network interactions between small components.
Given the increasing deployment sizes, the architectural exploitation challenges,
and the impact on data-centers’ power consumption, we need to efficiently track this
complexity. Within this article, we propose a black-box monitoring approach to track
microservices at scale, focusing on architectural metrics, power consumption, application
performance, and network performance. The proposed approach is transparent w.r.t.
the monitored applications, generates less overhead w.r.t. black-box approaches available
in the state-of-the-art, and provides fine-grain accurate metrics.},
  address    = {New York, NY, USA},
  articleno  = {34},
  doi        = {10.1145/3418899},
  file       = {:Brondolin2020 - A Black Box Monitoring Approach to Measure Microservices Runtime Performance.pdf:PDF},
  issue_date = {December 2020},
  keywords   = {network performance monitoring, cloud computing, performance monitoring, docker, power attribution, kubernetes, Microservices},
  numpages   = {26},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3418899},
}

@InProceedings{Dudouet2015,
  author    = {Dudouet, Florian and Edmonds, Andrew and Erne, Michael},
  booktitle = {Proceedings of the 1st International Workshop on Automated Incident Management in Cloud},
  title     = {Reliable Cloud-Applications: An Implementation through Service Orchestration},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {1–6},
  publisher = {Association for Computing Machinery},
  series    = {AIMC '15},
  abstract  = {As cloud-deployed applications became more and more mainstream, continuously more
complex services started to be deployed; indeed where initially monolithic applications
were simply ported to the cloud, applications are now more and more often composed
of micro-services. This improves the flexibility of an application but also makes
it more complex due to the sheer number of services comprising it.As deployment and
runtime management becomes more complex, orchestration software are becoming necessary
to completely manage the lifecycle of cloud applications. One crucial problem remaining
is how these applications can be made reliable in the cloud, a naturally unreliable
environment.In this paper we propose concepts and architectures which were implemented
in our orchestration software to guarantee reliability. Our initial implementation
also relies on Monasca, a well-known monitoring software for Open-Stack, to gather
proper metric and execute threshold-based actions. This allows us to show how service
reliability can be ensured using orchestration and how a proper incident-management
software feeding decisions to the orchestration engine ensures high-availability of
all components of managed applications.},
  doi       = {10.1145/2747470.2747471},
  file      = {:Dudouet2015 - Reliable Cloud Applications_ an Implementation through Service Orchestration.pdf:PDF},
  isbn      = {9781450334761},
  keywords  = {incident management, orchestration, cloud computing, reliability},
  location  = {Bordeaux, France},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2747470.2747471},
}

@InProceedings{Ewing2014,
  author    = {Ewing, John M. and Menasc\'{e}, Daniel A.},
  booktitle = {Proceedings of the 5th ACM/SPEC International Conference on Performance Engineering},
  title     = {A Meta-Controller Method for Improving Run-Time Self-Architecting in SOA Systems},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {173–184},
  publisher = {Association for Computing Machinery},
  series    = {ICPE '14},
  abstract  = {This paper builds on SASSY, a system for automatically generating SOA software architectures
that optimize a given utility function of multiple QoS metrics. In SASSY, SOA software
systems are automatically re-architected when services fail or degrade. Optimizing
both architecture and service provider selection presents a pair of nested NP-hard
problems. Here we adapt hill-climbing, beam search, simulated annealing, and evolutionary
programming to both architecture optimization and service provider selection. Each
of these techniques has several parameters that influence their efficiency. We introduce
in this paper a meta-controller that automates the run-time selection of heuristic
search techniques and their parameters. We examine two different meta-controller implementations
that each use online learning. The first implementation identifies the best heuristic
search combination from various prepared combinations. The second implementation analyzes
the current self-architecting problem (e.g. changes in performance metrics, service
degradations/failures) and looks for similar, previously encountered re-architecting
problems to find an effective heuristic search combination for the current problem.
A large set of experiments demonstrates the effectiveness of the first meta-controller
implementation and indicates opportunities for improving the second meta-controller
implementation.},
  doi       = {10.1145/2568088.2568098},
  file      = {:Ewing2014 - A Meta Controller Method for Improving Run Time Self Architecting in SOA Systems.pdf:PDF},
  isbn      = {9781450327336},
  keywords  = {heuristic search, meta-controlled qos optimization, autonomic computing, soa, combinatorial search techniques, metaheuristics, automated run-time software architecting},
  location  = {Dublin, Ireland},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2568088.2568098},
}

@Article{Tiwari2014,
  author     = {Tiwari, Umesh and Kumar, Santosh},
  journal    = {SIGSOFT Softw. Eng. Notes},
  title      = {In-out Interaction Complexity Metrics for Component-Based Software},
  year       = {2014},
  issn       = {0163-5948},
  month      = sep,
  number     = {5},
  pages      = {1–4},
  volume     = {39},
  abstract   = {In the current state of software engineering, component-based software development
is one of the most alluring paradigms for developing large and complex software products.
In this software engineering methodology pre-engineered, pre-tested, context-based,
adaptable, deployable software components are assembled according to a predefined
architecture. Rather than developing a system from scratch, component-based software
development emphasizes the integration of these components according to the user's
requirements and specifications. In component-based software, the components interact
to access and provide services and functionality to each other. Currently, the emphasis
of industry and researchers is on developing impressive and efficient metrics and
measurement tools to analyze the interaction complexity among these components. To
represent the request and the response of services among components, we have used
outgoing edges and incoming edges respectively. In this paper we have defined these
interactions as In-Interactions and Out-Interactions. The metrics proposed in this
paper are solely based on the interactions among the components. In this work some
simple methods and metrics for computing the complexity of composable components are
suggested. The metrics discussed in this paper include the computation of interaction
complexities as Total-Interactions of a component, Total- Interactions of component-based
software, Interaction-Ratio of a component, Interaction-Ratio of component-based software,
Average- Interaction among components and Interaction-Percentage of components.},
  address    = {New York, NY, USA},
  doi        = {10.1145/2659118.2659135},
  file       = {:Tiwari2014 - In Out Interaction Complexity Metrics for Component Based Software.pdf:PDF},
  issue_date = {September 2014},
  keywords   = {component-based software development, adaptable, in-interactions, out-interactions, context-based, metrics, pre-engineered},
  numpages   = {4},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2659118.2659135},
}

@InProceedings{Mo2018,
  author    = {Mo, Ran and Snipes, Will and Cai, Yuanfang and Ramaswamy, Srini and Kazman, Rick and Naedele, Martin},
  booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
  title     = {Experiences Applying Automated Architecture Analysis Tool Suites},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {779–789},
  publisher = {Association for Computing Machinery},
  series    = {ASE 2018},
  abstract  = {In this paper, we report our experiences of applying three complementary automated
software architecture analysis techniques, supported by a tool suite, called DV8,
to 8 industrial projects within a large company. DV8 includes two state-of-the-art
architecture-level maintainability metrics—Decoupling Level and Propagation Cost,
an architecture flaw detection tool, and an architecture root detection tool. We collected
development process data from the project teams as input to these tools, reported
the results back to the practitioners, and followed up with telephone conferences
and interviews. Our experiences revealed that the metrics scores, quantitative debt
analysis, and architecture flaw visualization can effectively bridge the gap between
management and development, help them decide if, when, and where to refactor. In particular,
the metrics scores, compared against industrial benchmarks, faithfully reflected the
practitioners’ intuitions about the maintainability of their projects, and enabled
them to better understand the maintainability relative to other projects internal
to their company, and to other industrial products. The automatically detected architecture
flaws and roots enabled the practitioners to precisely pinpoint, visualize, and quantify
the “hotspots" within the systems that are responsible for high maintenance costs.
Except for the two smallest projects for which both architecture metrics indicated
high maintainability, all other projects are planning or have already begun refactorings
to address the problems detected by our analyses. We are working on further automating
the tool chain, and transforming the analysis suite into deployable services accessible
by all projects within the company.},
  doi       = {10.1145/3238147.3240467},
  file      = {:Mo2018 - Experiences Applying Automated Architecture Analysis Tool Suites.pdf:PDF},
  isbn      = {9781450359375},
  keywords  = {Software Quality, Software Maintenance, Software Architecture},
  location  = {Montpellier, France},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3238147.3240467},
}

@InProceedings{Abderrahim2016,
  author    = {Abderrahim, Wiem and Choukair, Zied},
  booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},
  title     = {PaaS Dependability Integration Architecture Based on Cloud Brokering},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {484–487},
  publisher = {Association for Computing Machinery},
  series    = {SAC '16},
  abstract  = {Cloud computing has revolutionized the way IT is provisioned nowadays since it exposes
computing capabilities as rental resources to consumers. The emergence of cloud computing
services hasn't though prevented outages in these environments even among high profile
ranked cloud providers. Tremendous efforts concentrated on fault management measures
have been applied for these environments. But they have been focused mainly on the
IaaS service model and have been operated on the cloud provider side alone. In this
context, this paper proposes an architecture for cloud brokering that implements dependability
properties in an end to end way involving different cloud actors and all over the
cloud service models SaaS, PaaS and IaaS.},
  doi       = {10.1145/2851613.2851874},
  file      = {:Abderrahim2016 - PaaS Dependability Integration Architecture Based on Cloud Brokering.pdf:PDF},
  isbn      = {9781450337397},
  keywords  = {fault tolerance, cloud provider, PaaS, IaaS, SaaS, fault management, cloud broker, fault forecasting, dependability},
  location  = {Pisa, Italy},
  numpages  = {4},
  url       = {https://doi.org/10.1145/2851613.2851874},
}

@Article{Hu2017,
  author     = {Hu, Han and Wen, Yonggang and Chua, Tat-Seng and Li, Xuelong},
  journal    = {ACM Trans. Intell. Syst. Technol.},
  title      = {Cost-Optimized Microblog Distribution over Geo-Distributed Data Centers: Insights from Cross-Media Analysis},
  year       = {2017},
  issn       = {2157-6904},
  month      = apr,
  number     = {3},
  volume     = {8},
  abstract   = {The unprecedent growth of microblog services poses significant challenges on network
traffic and service latency to the underlay infrastructure (i.e., geo-distributed
data centers). Furthermore, the dynamic evolution in microblog status generates a
huge workload on data consistence maintenance. In this article, motivated by insights
of cross-media analysis-based propagation patterns, we propose a novel cache strategy
for microblog service systems to reduce the inter-data center traffic and consistence
maintenance cost, while achieving low service latency. Specifically, we first present
a microblog classification method, which utilizes the external knowledge from correlated
domains, to categorize microblogs. Then we conduct a large-scale measurement on a
representative online social network system to study the category-based propagation
diversity on region and time scales. These insights illustrate social common habits
on creating and consuming microblogs and further motivate our architecture design.
Finally, we formulate the content cache problem as a constrained optimization problem.
By jointly using the Lyapunov optimization framework and simplex gradient method,
we find the optimal online control strategy. Extensive trace-driven experiments further
demonstrate that our algorithm reduces the system cost by 24.5% against traditional
approaches with the same service latency.},
  address    = {New York, NY, USA},
  articleno  = {40},
  doi        = {10.1145/3014431},
  file       = {:Hu2017 - Cost Optimized Microblog Distribution Over Geo Distributed Data Centers_ Insights from Cross Media Analysis.pdf:PDF},
  issue_date = {April 2017},
  keywords   = {cross-media analysis, performance optimization, Social media analytics, data center},
  numpages   = {18},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3014431},
}

@InProceedings{Zimmermann2015,
  author    = {Zimmermann, Olaf},
  booktitle = {Proceedings of the Second International Workshop on Software Architecture and Metrics},
  title     = {Metrics for Architectural Synthesis and Evaluation: Requirements and Compilation by Viewpoint: An Industrial Experience Report},
  year      = {2015},
  pages     = {8–14},
  publisher = {IEEE Press},
  series    = {SAM '15},
  abstract  = {During architectural analysis and synthesis, architectural metrics are established
tacitly or explicitly. In architectural evaluation, these metrics are then consulted
to assess whether architectures are fit for purpose and in line with recommended practices
and published architectural knowledge. This experience report presents a personal
retrospective of the author's use of architectural metrics during 20 years in IT architect
roles in professional services as well as research and development. This reflection
drives the identification of use cases, critical success factors and elements of risk
for architectural metrics management. An initial catalog of architectural metrics
is compiled next, which is organized by viewpoints and domains. The report concludes
with a discussion of practical impact of architectural metrics and potential research
topics in this area.},
  file      = {:Zimmermann2015 - Metrics for Architectural Synthesis and Evaluation_ Requirements and Compilation by Viewpoint_ an Industrial Experience Report.pdf:PDF},
  keywords  = {patterns, viewpoints, architectural metrics, architectural metrics management, enterprise information systems, architectural reviews, integration},
  location  = {Florence, Italy},
  numpages  = {7},
}

@InProceedings{Marquez2018,
  author    = {Marquez, Cristina and Gramaglia, Marco and Fiore, Marco and Banchs, Albert and Costa-Perez, Xavier},
  booktitle = {Proceedings of the 24th Annual International Conference on Mobile Computing and Networking},
  title     = {How Should I Slice My Network? A Multi-Service Empirical Evaluation of Resource Sharing Efficiency},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {191–206},
  publisher = {Association for Computing Machinery},
  series    = {MobiCom '18},
  abstract  = {By providing especially tailored instances of a virtual network,network slicing allows
for a strong specialization of the offered services on the same shared infrastructure.
Network slicing has profound implications on resource management, as it entails an
inherent trade-off between: (i) the need for fully dedicated resources to support
service customization, and (ii) the dynamic resource sharing among services to increase
resource efficiency and cost-effectiveness of the system. In this paper, we provide
a first investigation of this trade-off via an empirical study of resource management
efficiency in network slicing. Building on substantial measurement data collected
in an operational mobile network (i) we quantify the efficiency gap introduced by
non-reconfigurable allocation strategies of different kinds of resources, from radio
access to the core of the network, and (ii) we quantify the advantages of their dynamic
orchestration at different timescales. Our results provide insights on the achievable
efficiency of network slicing architectures, their dimensioning, and their interplay
with resource management algorithms.},
  doi       = {10.1145/3241539.3241567},
  file      = {:Marquez2018 - How Should I Slice My Network_ a Multi Service Empirical Evaluation of Resource Sharing Efficiency.pdf:PDF},
  isbn      = {9781450359030},
  keywords  = {resource management, network efficiency, network slicing},
  location  = {New Delhi, India},
  numpages  = {16},
  url       = {https://doi.org/10.1145/3241539.3241567},
}

@InProceedings{Antonescu2014,
  author    = {Antonescu, Alexandru-Florian and Braun, Torsten},
  booktitle = {Proceedings of the 2014 ACM SIGCOMM Workshop on Distributed Cloud Computing},
  title     = {Modeling and Simulation of Concurrent Workload Processing in Cloud-Distributed Enterprise Information Systems},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {11–16},
  publisher = {Association for Computing Machinery},
  series    = {DCC '14},
  abstract  = {Cloud Computing enables provisioning and distribution of highly scalable services
in a reliable, on-demand and sustainable manner. Distributed Enterprise Information
Systems (dEIS) are a class of applications with important economic value and with
strong requirements in terms of performance and reliability. In order to validate
dEIS architectures, stability, scaling and SLA compliance, large testing deployments
are necessary, adding complexity to the design and testing of such systems. To fill
this gap, we present and validate a methodology for modeling and simulating such complex
distributed systems using the CloudSim cloud computing simulator, based on measurement
data from an actual distributed system. We present an approach for creating a performance-based
model of a distributed cloud application using recorded service performance traces.
We then show how to integrate the created model into CloudSim. We validate the CloudSim
simulation model by comparing performance traces gathered during distributed concurrent
experiments with simulation results using different VM configurations. We demonstrate
the usefulness of using a cloud simulator for modeling properties of real cloud-distributed
applications.},
  doi       = {10.1145/2627566.2627575},
  file      = {:Antonescu2014 - Modeling and Simulation of Concurrent Workload Processing in Cloud Distributed Enterprise Information Systems.pdf:PDF},
  isbn      = {9781450329927},
  keywords  = {cloud computing, performance profiling, distributed applications, modelling and simulation},
  location  = {Chicago, Illinois, USA},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2627566.2627575},
}

@InProceedings{Walter2017,
  author    = {Walter, J\"{u}rgen and Stier, Christian and Koziolek, Heiko and Kounev, Samuel},
  booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion},
  title     = {An Expandable Extraction Framework for Architectural Performance Models},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {165–170},
  publisher = {Association for Computing Machinery},
  series    = {ICPE '17 Companion},
  abstract  = {Providing users with Quality of Service (QoS) guarantees and the prevention of performance
problems are challenging tasks for software systems. Architectural performance models
can be applied to explore performance properties of a software system at design time
and run time. At design time, architectural performance models support reasoning on
effects of design decisions. At run time, they enable automatic reconfigurations by
reasoning on the effects of changing user behavior. In this paper, we present a framework
for the extraction of architectural performance models based on monitoring log files
generalizing over the targeted architectural modeling language. Using the presented
framework, the creation of a performance model extraction tool for a specific modeling
formalism requires only the implementation of a key set of object creation routines
specific to the formalism. Our framework integrates them with extraction techniques
that apply to many architectural performance models, e.g., resource demand estimation
techniques. This lowers the effort to implement performance model extraction tools
tremendously through a high level of reuse. We evaluate our framework presenting builders
for the Descartes Modeling Language (DML) and the Palladio Component Model(PCM). For
the extracted models we compare simulation results with measurements receiving accurate
results.},
  doi       = {10.1145/3053600.3053634},
  file      = {:Walter2017 - An Expandable Extraction Framework for Architectural Performance Models.pdf:PDF},
  isbn      = {9781450348997},
  keywords  = {descartes modeling language, palladio component model, automated performance model extraction, builder pattern},
  location  = {L'Aquila, Italy},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3053600.3053634},
}

@InProceedings{Becker2015,
  author    = {Becker, Matthias and Lehrig, Sebastian and Becker, Steffen},
  booktitle = {Proceedings of the 6th ACM/SPEC International Conference on Performance Engineering},
  title     = {Systematically Deriving Quality Metrics for Cloud Computing Systems},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {169–174},
  publisher = {Association for Computing Machinery},
  series    = {ICPE '15},
  abstract  = {In cloud computing, software architects develop systems for virtually unlimited resources
that cloud providers account on a pay-per-use basis. Elasticity management systems
provision these resources autonomously to deal with changing workload. Such changing
workloads call for new objective metrics allowing architects to quantify quality properties
like scalability, elasticity, and efficiency, e.g., for requirements/SLO engineering
and software design analysis. In literature, initial metrics for these properties
have been proposed. However, current metrics lack a systematic derivation and assume
knowledge of implementation details like resource handling. Therefore, these metrics
are inapplicable where such knowledge is unavailable.To cope with these lacks, this
short paper derives metrics for scalability, elasticity, and efficiency properties
of cloud computing systems using the goal question metric (GQM) method. Our derivation
uses a running example that outlines characteristics of cloud computing systems. Eventually,
this example allows us to set up a systematic GQM plan and to derive an initial set
of six new metrics. We particularly show that our GQM plan allows to classify existing
metrics.},
  doi       = {10.1145/2668930.2688043},
  file      = {:Becker2015 - Systematically Deriving Quality Metrics for Cloud Computing Systems.pdf:PDF},
  isbn      = {9781450332484},
  keywords  = {metric, elasticity, cloud computing, gqm, efficiency, slo, analysis, scalability},
  location  = {Austin, Texas, USA},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2668930.2688043},
}

@InProceedings{Lehrig2015,
  author    = {Lehrig, Sebastian and Eikerling, Hendrik and Becker, Steffen},
  booktitle = {Proceedings of the 11th International ACM SIGSOFT Conference on Quality of Software Architectures},
  title     = {Scalability, Elasticity, and Efficiency in Cloud Computing: A Systematic Literature Review of Definitions and Metrics},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {83–92},
  publisher = {Association for Computing Machinery},
  series    = {QoSA '15},
  abstract  = {Context: In cloud computing, there is a multitude of definitions and metrics for scalability,
elasticity, and efficiency. However, stakeholders have little guidance for choosing
fitting definitions and metrics for these quality properties, thus leading to potential
misunderstandings. For example, cloud consumers and providers cannot negotiate reliable
and quantitative service level objectives directly understood by each stakeholder.
Objectives: Therefore, we examine existing definitions and metrics for these quality
properties from the viewpoint of cloud consumers, cloud providers, and software architects
with regard to commonly used concepts. Methods: We execute a systematic literature
review (SLR), reproducibly collecting common concepts in definitions and metrics for
scalability, elasticity, and efficiency. As quality selection criteria, we assess
whether existing literature differentiates the three properties, exemplifies metrics,
and considers typical cloud characteristics and cloud roles. Results: Our SLR yields
418 initial results from which we select 20 for in-depth evaluation based on our quality
selection criteria. In our evaluation, we recommend concepts, definitions, and metrics
for each property. Conclusions: Software architects can use our recommendations to
analyze the quality of cloud computing applications. Cloud providers and cloud consumers
can specify service level objectives based on our metric suggestions.},
  doi       = {10.1145/2737182.2737185},
  file      = {:Lehrig2015 - Scalability, Elasticity, and Efficiency in Cloud Computing_ a Systematic Literature Review of Definitions and Metrics.pdf:PDF},
  isbn      = {9781450334709},
  keywords  = {systematic literature review, cloud computing, cloud, scalability, metrics, elasticity, efficiency, definitions},
  location  = {Montr\'{e}al, QC, Canada},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2737182.2737185},
}

@InProceedings{Silva2020,
  author    = {Silva, Jorge Luiz Machado da and de Fran\c{c}a, Breno B. Nicolau and Rubira, Cec\'{\i}lia Mary Fischer},
  booktitle = {Proceedings of the 14th Brazilian Symposium on Software Components, Architectures, and Reuse},
  title     = {Generating Trustworthiness Adaptation Plans Based on Quality Models for Cloud Platforms},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {141–150},
  publisher = {Association for Computing Machinery},
  series    = {SBCARS '20},
  abstract  = {Cloud computing platforms can offer many benefits related to the provision of service
processing and storage for hosting client applications. Trustworthiness can be defined
as the trust of a customer in a cloud service and its provider; however, the assurance
of this property is not trivial. First, trustworthiness in general is not composed
by a single quality attribute, but by the combination of multiple attributes, such
as data privacy, performance, reliability, etc. Second, during runtime clients can
experience a change of the trustworthiness level required by their application due
to the degradation of the cloud service. This article presents a solution that monitors
during runtime the set of quality attributes of a specific application and generates
adaptation plans in order to certify that an adequate resource amount be provided
by the cloud in order to keep its trustworthiness level. Our solution is based on
quality models to compute the metric associated to each non-functional requirement
and their combination them into different types of trustworthiness levels. The main
contribution of the solution is to provide an approach which deals with multiple requirements
at the same time (or simultaneously) during runtime in order to adapt the cloud resources
to keep the trustworthiness level required by the application. The solution was evaluated
by an experiment considering a scenario where the application trustworthiness level
was composed by three quality attributes: data privacy, performance and reliability.
Initial results have shown that the approach is feasible in terms of the execution
of the adaptation plans during runtime to certify the trustworthiness level required
by the application.},
  doi       = {10.1145/3425269.3425272},
  file      = {:Silva2020 - Generating Trustworthiness Adaptation Plans Based on Quality Models for Cloud Platforms.pdf:PDF},
  isbn      = {9781450387545},
  keywords  = {Cloud Computing, Trustworthiness, Adaptation Planning, Self-adaptive Systems},
  location  = {Natal, Brazil},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3425269.3425272},
}

@InProceedings{Lehrig2015a,
  author    = {Lehrig, Sebastian and Becker, Steffen},
  booktitle = {Proceedings of the 6th ACM/SPEC International Conference on Performance Engineering},
  title     = {The CloudScale Method for Software Scalability, Elasticity, and Efficiency Engineering: A Tutorial},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {329–331},
  publisher = {Association for Computing Machinery},
  series    = {ICPE '15},
  abstract  = {In cloud computing, software engineers design systems for virtually unlimited resources
that cloud providers account on a pay-per-use basis. Elasticity management systems
provision these resource autonomously to deal with changing workloads. Such workloads
call for new objective metrics allowing engineers to quantify quality properties like
scalability, elasticity, and efficiency. However, software engineers currently lack
engineering methods that aid them in engineering their software regarding such properties.
Therefore, the CloudScale project developed tools for such engineering tasks. These
tools cover reverse engineering of architectural models from source code, editors
for manual design/adaption of such models, as well as tools for the analysis of modeled
and operating software regarding scalability, elasticity, and efficiency. All tools
are interconnected via ScaleDL, a common architectural language, and the CloudScale
Method that leads through the engineering process. In this tutorial, we execute our
method step-by-step such that every tool and ScaleDL are briefly introduced.},
  doi       = {10.1145/2668930.2688818},
  file      = {:Lehrig2015a - The CloudScale Method for Software Scalability, Elasticity, and Efficiency Engineering_ a Tutorial.pdf:PDF},
  isbn      = {9781450332484},
  keywords  = {engineering, cloudscale, tutorial, metrics, efficiency, scalability, elasticity, cloud computing, software analysis, method},
  location  = {Austin, Texas, USA},
  numpages  = {3},
  url       = {https://doi.org/10.1145/2668930.2688818},
}

@InProceedings{Michael2017,
  author    = {Michael, Nicolas and Ramannavar, Nitin and Shen, Yixiao and Patil, Sheetal and Sung, Jan-Lung},
  booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering},
  title     = {CloudPerf: A Performance Test Framework for Distributed and Dynamic Multi-Tenant Environments},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {189–200},
  publisher = {Association for Computing Machinery},
  series    = {ICPE '17},
  abstract  = {The evolution of cloud-computing imposes many challenges on performance testing and
requires not only a different approach and methodology of performance evaluation and
analysis, but also specialized tools and frameworks to support such work. In traditional
performance testing, typically a single workload was run against a static test configuration.
The main metrics derived from such experiments included throughput, response times,
and system utilization at steady-state. While this may have been sufficient in the
past, where in many cases a single application was run on dedicated hardware, this
approach is no longer suitable for cloud-based deployments. Whether private or public
cloud, such environments typically host a variety of applications on distributed shared
hardware resources, simultaneously accessed by a large number of tenants running heterogeneous
workloads. The number of tenants as well as their activity and resource needs dynamically
change over time, and the cloud infrastructure reacts to this by reallocating existing
or provisioning new resources. Besides metrics such as the number of tenants and overall
resource utilization, performance testing in the cloud must be able to answer many
more questions: How is the quality of service of a tenant impacted by the constantly
changing activity of other tenants? How long does it take the cloud infrastructure
to react to changes in demand, and what is the effect on tenants while it does so?
How well are service level agreements met? What is the resource consumption of individual
tenants? How can global performance metrics on application- and system-level in a
distributed system be correlated to an individual tenant's perceived performance?In
this paper we present CloudPerf, a performance test framework specifically designed
for distributed and dynamic multi-tenant environments, capable of answering all of
the above questions, and more. CloudPerf consists of a distributed harness, a protocol-independent
load generator and workload modeling framework, an extensible statistics framework
with live-monitoring and post-analysis tools, interfaces for cloud deployment operations,
and a rich set of both low-level as well as high-level workloads from different domains.},
  doi       = {10.1145/3030207.3044530},
  file      = {:Michael2017 - CloudPerf_ a Performance Test Framework for Distributed and Dynamic Multi Tenant Environments.pdf:PDF},
  isbn      = {9781450344043},
  keywords  = {cloud, multi-tenancy, statistics collection, load generation, performance testing, workload modeling},
  location  = {L'Aquila, Italy},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3030207.3044530},
}

@InProceedings{Ibrahim2016,
  author    = {Ibrahim, Abdallah Ali Zainelabden A. and Kliazovich, Dzmitry and Bouvry, Pascal},
  booktitle = {Proceedings of the 16th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
  title     = {Service Level Agreement Assurance between Cloud Services Providers and Cloud Customers},
  year      = {2016},
  pages     = {588–591},
  publisher = {IEEE Press},
  series    = {CCGRID '16},
  abstract  = {Cloud services providers deliver cloud services to cloud customers on pay-per-use
model while the quality of the provided services are defined using service level agreements
also known as SLAs. Unfortunately, there is no standard mechanism which exists to
verify and assure that delivered services satisfy the signed SLA agreement in an automatic
way. There is no guarantee in terms of quality. Those applications have many performance
metrics. In this doctoral thesis, we propose a framework for SLA assurance, which
can be used by both cloud providers and cloud users. Inside the proposed framework,
we will define the performance metrics for the different applications. We will assess
the applications performance in different testing environment to assure good services
quality as mentioned in SLA. The proposed framework will be evaluated through simulations
and using testbed experiments. After testing the applications performance by measuring
the performance metrics, we will review the time correlations between those metrics.},
  doi       = {10.1109/CCGrid.2016.56},
  file      = {:Ibrahim2016 - Service Level Agreement Assurance between Cloud Services Providers and Cloud Customers.pdf:PDF},
  isbn      = {9781509024520},
  keywords  = {simulation, data centers, performance, metrics, quality of experience, applications, quality of services, cloud computing, service level agreement},
  location  = {Cartagena, Columbia},
  numpages  = {4},
}

@InProceedings{MartinezOrtiz2019,
  author    = {Martinez-Ortiz, Andres-Leonardo and Lizcano, David and Ortega, Miguel},
  booktitle = {Proceedings of the 14th International Workshop on Automation of Software Test},
  title     = {Software Metrics Artifacts Making Web Quality Measurable: AST 2019 Invited Paper},
  year      = {2019},
  pages     = {1–6},
  publisher = {IEEE Press},
  series    = {AST '19},
  abstract  = {Mining open source repositories introduces an effective approach to put in practice
empirical software engineering in a variety of technologies. Kernel development (Linux)
first and then Internet (Chromium) and more recently cloud orchestration (Kubernetes)
and machine learning (TensorFlow) are fundamental pieces not just for open source
ecosystem but also for the industry leading software innovation. Empirical software
engineering sustains a better understanding of these projects, reducing even more
the barriers for adoption. In this work we focus on empirical quality assessment developing
software metrics artifacts to make web components quality measurable. After reviewing
the state of the art and main frameworks for software measurement, we will present
our proposal for the empirical evaluation of quality metrics for web components, data
collection, measurement and prediction, discussing main benefits and some drawback
of the selected approach, which will be aimed at future works.},
  doi       = {10.1109/AST.2019.000-2},
  file      = {:MartinezOrtiz2019 - Software Metrics Artifacts Making Web Quality Measurable_ AST 2019 Invited Paper.pdf:PDF},
  keywords  = {web technologies, open source, quality metrics, software engineering},
  location  = {Montreal, Quebec, Canada},
  numpages  = {6},
}

@InProceedings{Weber2014,
  author    = {Weber, Andreas and Herbst, Nikolas and Groenda, Henning and Kounev, Samuel},
  booktitle = {Proceedings of the 2nd International Workshop on Hot Topics in Cloud Service Scalability},
  title     = {Towards a Resource Elasticity Benchmark for Cloud Environments},
  year      = {2014},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {HotTopiCS '14},
  abstract  = {Auto-scaling features offered by today's cloud infrastructures provide increased flexibility
especially for customers that experience high variations in the load intensity over
time. However, auto-scaling features introduce new system quality attributes when
considering their accuracy, timing, and boundaries. Therefore, distinguishing between
different offerings has become a complex task, as it is not yet supported by reliable
metrics and measurement approaches. In this paper, we discuss shortcomings of existing
approaches for measuring and evaluating elastic behavior and propose a novel benchmark
methodology specifically designed for evaluating the elasticity aspects of modern
cloud platforms. The benchmark is based on open workloads with realistic load variation
profiles that are calibrated to induce identical resource demand variations independent
of the underlying hardware performance. Furthermore, we propose new metrics that capture
the accuracy of resource allocations and de-allocations, as well as the timing aspects
of an auto-scaling mechanism explicitly.},
  articleno = {5},
  doi       = {10.1145/2649563.2649571},
  file      = {:Weber2014 - Towards a Resource Elasticity Benchmark for Cloud Environments.pdf:PDF},
  isbn      = {9781450330596},
  keywords  = {Resource, Elasticity, Supply, Demand, Load Profile},
  location  = {Dublin, Ireland},
  numpages  = {8},
  url       = {https://doi.org/10.1145/2649563.2649571},
}

@InProceedings{Chhetri2016,
  author    = {Chhetri, Mohan Baruwal and Vo, Quoc Bao and Kowalczyk, Ryszard},
  booktitle = {Proceedings of the 9th International Conference on Utility and Cloud Computing},
  title     = {CL-SLAM: Cross-Layer SLA Monitoring Framework for Cloud Service-Based Applications},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {30–36},
  publisher = {Association for Computing Machinery},
  series    = {UCC '16},
  abstract  = {Modern applications are increasingly being composed from multiple components that
require and consume services at different layers of the cloud stack. The diverse,
dynamic and unpredictable nature of both cloud services and application workloads
makes quality-assured provision of such cloud service-based applications (CSBAs) a
major challenge. While elasticity and autoscaling gives CSBA providers the ability
to scale cloud resources on-demand, they require a comprehensive, system-wide view
of the application performance in order to make timely, cost-effective and performance-efficient
scaling decisions. In this paper, we propose, develop and validate CL-SLAM - a Cross-Layer
SLA Monitoring Framework for CSBAs. Its main features include (a) realtime, fine-grained
visibility into CSBA performance, (b) visual descriptive analytics to identify correlations
and inter-dependencies between cross-layer performance metrics, (c) temporal profiling
of CSBA performance, (d) proactive monitoring, detection and root-cause analysis of
SLA violation, and (e) support for both reactive and proactive adaptation in support
of quality-assured CSBA provision. We validate our approach through a prototype implementation.},
  doi       = {10.1145/2996890.2996906},
  file      = {:Chhetri2016 - CL SLAM_ Cross Layer SLA Monitoring Framework for Cloud Service Based Applications.pdf:PDF},
  isbn      = {9781450346160},
  keywords  = {cross-layer SLA monitoring, cloud service-based application},
  location  = {Shanghai, China},
  numpages  = {7},
  url       = {https://doi.org/10.1145/2996890.2996906},
}

@InProceedings{Shatnawi2018,
  author    = {Shatnawi, Anas and Orr\`{u}, Matteo and Mobilio, Marco and Riganelli, Oliviero and Mariani, Leonardo},
  booktitle = {Proceedings of the 1st International Workshop on Software Health},
  title     = {Cloudhealth: A Model-Driven Approach to Watch the Health of Cloud Services},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {40–47},
  publisher = {Association for Computing Machinery},
  series    = {SoHeal '18},
  abstract  = {Cloud systems are complex and large systems where services provided by different operators
must coexist and eventually cooperate. In such a complex environment, controlling
the health of both the whole environment and the individual services is extremely
important to timely and effectively react to misbehaviours, unexpected events, and
failures. Although there are solutions to monitor cloud systems at different granularity
levels, how to relate the many KPIs that can be collected about the health of the
system and how health information can be properly reported to operators are open questions.This
paper reports the early results we achieved in the challenge of monitoring the health
of cloud systems. In particular we present CloudHealth, a model-based health monitoring
approach that can be used by operators to watch specific quality attributes. The Cloud-Health
Monitoring Model describes how to operationalize high level monitoring goals by dividing
them into subgoals, deriving metrics for the subgoals, and using probes to collect
the metrics. We use the CloudHealth Monitoring Model to control the probes that must
be deployed on the target system, the KPIs that are dynamically collected, and the
visualization of the data in dashboards.},
  doi       = {10.1145/3194124.3194130},
  file      = {:Shatnawi2018 - Cloudhealth_ a Model Driven Approach to Watch the Health of Cloud Services.pdf:PDF},
  isbn      = {9781450357302},
  keywords  = {quality model, software health, monitoring, cloud service, monitoring model, metrics, KPI},
  location  = {Gothenburg, Sweden},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3194124.3194130},
}

@InProceedings{Herbst2015,
  author    = {Herbst, Nikolas Roman and Kounev, Samuel and Weber, Andreas and Groenda, Henning},
  booktitle = {Proceedings of the 10th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
  title     = {BUNGEE: An Elasticity Benchmark for Self-Adaptive IaaS Cloud Environments},
  year      = {2015},
  pages     = {46–56},
  publisher = {IEEE Press},
  series    = {SEAMS '15},
  abstract  = {Today's infrastructure clouds provide resource elasticity (i.e. auto-scaling) mechanisms
enabling self-adaptive resource provisioning to reflect variations in the load intensity
over time. These mechanisms impact on the application performance, however, their
effect in specific situations is hard to quantify and compare. To evaluate the quality
of elasticity mechanisms provided by different platforms and configurations, respective
metrics and benchmarks are required. Existing metrics for elasticity only consider
the time required to provision and deprovision resources or the costs impact of adaptations.
Existing benchmarks lack the capability to handle open workloads with realistic load
intensity profiles and do not explicitly distinguish between the performance exhibited
by the provisioned underlying resources, on the one hand, and the quality of the elasticity
mechanisms themselves, on the other hand.In this paper, we propose reliable metrics
for quantifying the timing aspects and accuracy of elasticity. Based on these metrics,
we propose a novel approach for benchmarking the elasticity of Infrastructure-as-a-Service
(IaaS) cloud platforms independent of the performance exhibited by the provisioned
underlying resources. We show that the proposed metrics provide consistent ranking
of elastic platforms on an ordinal scale. Finally, we present an extensive case study
of real-world complexity demonstrating that the proposed approach is applicable in
realistic scenarios and can cope with different levels of resource efficiency.},
  file      = {:Herbst2015 - BUNGEE_ an Elasticity Benchmark for Self Adaptive IaaS Cloud Environments.pdf:PDF},
  location  = {Florence, Italy},
  numpages  = {11},
}

@InProceedings{Kuhlenkamp2019,
  author    = {Kuhlenkamp, J\"{o}rn and Werner, Sebastian and Borges, Maria C. and El Tal, Karim and Tai, Stefan},
  booktitle = {Proceedings of the 12th IEEE/ACM International Conference on Utility and Cloud Computing},
  title     = {An Evaluation of FaaS Platforms as a Foundation for Serverless Big Data Processing},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {1–9},
  publisher = {Association for Computing Machinery},
  series    = {UCC'19},
  abstract  = {Function-as-a-Service (FaaS), offers a new alternative to operate cloud-based applications.
FaaS platforms enable developers to define their application only through a set of
service functions, relieving them of infrastructure management tasks, which are executed
automatically by the platform. Since its introduction, FaaS has grown to support workloads
beyond the lightweight use-cases it was originally intended for, and now serves as
a viable paradigm for big data processing. However, several questions regarding FaaS
platform quality are still unanswered. Specifically, the impact of automatic infrastructure
management on serverless big data applications remains unexplored.In this paper, we
propose a novel evaluation method (SIEM) to understand the impact of these tasks.
For this purpose, we introduce new metrics to quantify quality in different big data
application scenarios. We show an application of SIEM by evaluating the four major
FaaS providers, and contribute results and new insights for FaaS-based big data processing.},
  doi       = {10.1145/3344341.3368796},
  file      = {:Kuhlenkamp2019 - An Evaluation of FaaS Platforms As a Foundation for Serverless Big Data Processing.pdf:PDF},
  isbn      = {9781450368940},
  keywords  = {serverless, benchmarking, big data processing, cloud computing},
  location  = {Auckland, New Zealand},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3344341.3368796},
}

@InProceedings{Moreno2017,
  author    = {Moreno, Gabriel A. and Papadopoulos, Alessandro V. and Angelopoulos, Konstantinos and C\'{a}mara, Javier and Schmerl, Bradley},
  booktitle = {Proceedings of the 12th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
  title     = {Comparing Model-Based Predictive Approaches to Self-Adaptation: CobRA and PLA},
  year      = {2017},
  pages     = {42–53},
  publisher = {IEEE Press},
  series    = {SEAMS '17},
  abstract  = {Modern software-intensive systems must often guarantee certain quality requirements
under changing run-time conditions and high levels of uncertainty. Self-adaptation
has proven to be an effective way to engineer systems that can address such challenges,
but many of these approaches are purely reactive and adapt only after a failure has
taken place. To overcome some of the limitations of reactive approaches (e.g., lagging
behind environment changes and favoring short-term improvements), recent proactive
self-adaptation mechanisms apply ideas from control theory, such as model predictive
control (MPC), to improve adaptation. When selecting which MPC approach to apply,
the improvement that can be obtained with each approach is scenario-dependent, and
so guidance is needed to better understand how to choose an approach for a given situation.
In this paper, we compare CobRA and PLA, two approaches that are inspired by MPC.
CobRA is a requirements-based approach that applies control theory, whereas PLA is
architecture-based and applies stochastic analysis. We compare the two approaches
applied to RUBiS, a benchmark system for web and cloud application performance, discussing
the required expertise needed to use both approaches and comparing their run-time
performance with respect to different metrics.},
  doi       = {10.1109/SEAMS.2017.2},
  file      = {:Moreno2017 - Comparing Model Based Predictive Approaches to Self Adaptation_ CobRA and PLA.pdf:PDF},
  isbn      = {9781538615508},
  keywords  = {self-adaptation, adaptive system, model predictive control, CobRA, latency, PLA},
  location  = {Buenos Aires, Argentina},
  numpages  = {12},
}

@InProceedings{Raj2018,
  author    = {Raj, Vinay and Ravichandra, S.},
  booktitle = {2018 3rd IEEE International Conference on Recent Trends in Electronics, Information Communication Technology (RTEICT)},
  title     = {Microservices: A perfect SOA based solution for Enterprise Applications compared to Web Services},
  year      = {2018},
  month     = {May},
  pages     = {1531-1536},
  abstract  = {The Software Engineering community has defined different types of architectures to build applications. One among them is Service Oriented Architecture(SOA) which has created significant impact the way software applications are built. There are many implementations of SOA like Web Services, REST services etc. But Web Services and REST services do not fully follow all the principles of SOA. Microservices as an architectural style recently emerged from SOA by which we can develop business requirements with loosely coupled, self deploying and scalable services. Microservices have gained more popularity in application development as they are easy to understand, scale and deploy. In this paper we discuss principles of SOA, major drawbacks of web services and benefits of Microservices over SOA based web services. We have highlighted the importance of Microservices in software development. This paper gives information for architects as to why choose Microservices architecture over web services. We have also discussed metrics used for calculating Coupling between services and we evaluated by considering a smart payment application for ecommerce which is built using both the styles. We observed that Microservices architectural style has less coupling between services compared to Web Service style based on the metric values of the application.},
  doi       = {10.1109/RTEICT42901.2018.9012140},
  file      = {:Raj2018 - Microservices_ a Perfect SOA Based Solution for Enterprise Applications Compared to Web Services.pdf:PDF},
  keywords  = {Service-oriented architecture;Couplings;Measurement;Computer architecture;Business;Service Oriented Architecture(SOA);Web Services;Microservices;Coupling;Metrics},
}

@InProceedings{Rosa2020,
  author    = {Rosa, Thatiane de Oliveira and Goldman, Alfredo and Guerra, Eduardo Martins},
  booktitle = {2020 IEEE International Conference on Software Architecture Companion (ICSA-C)},
  title     = {How ‘micro’ are your services?},
  year      = {2020},
  month     = {March},
  pages     = {75-78},
  abstract  = {Microservice is an architectural style that proposes that a complex system should be developed from small and independent services that work together. There is not a welldefined boundary about when a software architecture can be considered based on microservices or not. Because of that, defining microservices context and infrastructure is challenging, especially to characterize aspects related to microservice size, data consistency, and microservices coupling. Thus, it is crucial to understand the microservices-based software characteristics, to comprehend the impact of some evolutions on architecture, and evaluate how much a particular architecture fits the microservices architectural style. Therefore, based on bibliographic research and case studies conducted in academical and industrial environments, we aim to propose a model to characterize the architecture structure based on the main guidelines of the microservice architectural style. This model introduces dimensions that measure characteristics based on modules size, coupling to data sources, and service collaboration. This study should facilitate the mapping, measurement, and monitoring of different impacts generated in the software architecture from increments and refactoring performed. This work is on the initial development stage and as a result, we expected that the model supports architectural decisions that consider different quality attributes to achieve the right balance between service independence and collaboration for a given system.},
  doi       = {10.1109/ICSA-C50368.2020.00023},
  file      = {:Rosa2020 - How ‘micro’ Are Your Services_.pdf:PDF},
  keywords  = {Measurement;Databases;Couplings;Complexity theory;Software;Computer architecture;Software architecture;software architecture;microservices;characterization model},
}

@InProceedings{Santos2020a,
  author    = {Santos, Nuno and Rito Silva, António},
  booktitle = {2020 IEEE International Conference on Software Architecture (ICSA)},
  title     = {A Complexity Metric for Microservices Architecture Migration},
  year      = {2020},
  month     = {March},
  pages     = {169-178},
  abstract  = {Monolith applications tend to be difficult to deploy, upgrade, maintain, and understand. Microservices, on the other hand, have the advantages of being independently developed, tested, deployed, scaled and, more importantly, easier to change and maintain. This paper addresses the problem of migrating a monolith to a microservices architecture. Therefore, we address two research questions: (1) Can we define the cost of decomposition in terms of the effort to redesign a functionality, which is implemented in the monolith as an ACID transaction, into several distributed transactions? (2) Considering several similarity measures between domain entities, which provide a better decomposition when they are compared using the proposed complexity metric? To answer the first research question, we propose a complexity metric, for each functionality of the monolith application, that measures the impact of relaxing the functionality consistency on the architecture redesign and implementation. Regarding the second research question, we experiment with four similarity measures, each based on a different type of information collected from monolith functionality implementation. We evaluated our approach with three monolith systems and compared our complexity metric against industry metrics of cohesion and coupling. We also evaluated the different similarity measures in terms of the complexity of the decomposition they produce. We were able to correctly correlate the complexity metric with other metrics of cohesion and coupling defined in other research and we conclude that no single combination of similarity measures outperforms the other, which is confirmed by the existing research. Additionally, we conclude that the approach can help on an incremental migration to microservices, which, actually, is the strategy proposed by the industry experts.},
  doi       = {10.1109/ICSA47634.2020.00024},
  file      = {:Santos2020a - A Complexity Metric for Microservices Architecture Migration.pdf:PDF},
  keywords  = {Measurement;Complexity theory;Business;Computer architecture;Tools;Industries;Couplings;Monolith applications, Microservices, Complexity metrics, Architecture migration, Architecture evolution},
}

@InProceedings{Avritzer2020,
  author    = {Avritzer, Alberto},
  booktitle = {2020 IEEE International Conference on Software Architecture Companion (ICSA-C)},
  title     = {Challenges and Approaches for the Assessment of Micro-Service Architecture Deployment Alternatives in DevOps : A tutorial presented at ICSA 2020},
  year      = {2020},
  month     = {March},
  pages     = {1-2},
  abstract  = {The goal of this tutorial is to provide an overview of challenges and approaches for architecture/dependability assessment in the context of DevOps and microservices. Specifically, we present approaches that employ operational data obtained from production-level application performance management (APM) tools, giving access to operational workload profiles, architectural information, failure models, and security intrusions. We use this data to automatically create and conFigure architecture assessments based on models, load tests, and resilience benchmarks. The focus of this tutorial is on approaches that employ production usage, because these approaches provide more accurate recommendations for microservice architecture dependability assessment than approaches that do not consider production usage. We present an overview of (1) the state-of-the-art approaches for obtaining operational data from production systems using APM tools, (2) the challenges of dependability for DevOps and microservices, (3) selected approaches based on operational data to assess dependability. The architecture assessment focus of this tutorial is on scalability, resilience, survivability, and security. Particularly, we present a demo of the automated approach for the evaluation of a domain-based scalability and security metric assessment that is based on the microservice architecture ability to satisfy the performance requirement under load and/or intrusions. We illustrate the approach by presenting experimental results using a benchmark microservice architecture.},
  doi       = {10.1109/ICSA-C50368.2020.00007},
  file      = {:Avritzer2020 - Challenges and Approaches for the Assessment of Micro Service Architecture Deployment Alternatives in DevOps _ a Tutorial Presented at ICSA 2020.pdf:PDF},
  keywords  = {Tutorials;Computer architecture;Scalability;Security;Tools;Data models;Production;micro-service architectures;operational profile;security intrusions},
}

@InProceedings{FernandesMiotodeOliveiradosSantos2019,
  author    = {Fernandes Mioto de Oliveira dos Santos, Eduardo and Lima Werner, Claudia Maria},
  booktitle = {2019 International Conference on Information Systems and Software Technologies (ICI2ST)},
  title     = {A Survey on Microservices Criticality Attributes on Established Architectures},
  year      = {2019},
  month     = {Nov},
  pages     = {149-155},
  abstract  = {The microservice oriented software architecture considers the delegation of responsibilities by separate components, thus creating a set of interconnected but independent services. Information about the most critical microservices is relevant to software architects and other decision-makers, thus guiding the maintenance and evolution of architecture in a more assertive and guided way. This paper aims to observe the need for a method to measure criticality in a microservice oriented architecture, motivated by this purpose, during August 2019, a survey with twenty experienced participants from the industry and academia was conducted, where the lack of a grounded method to measure the criticality on established architectures was observed.},
  doi       = {10.1109/ICI2ST.2019.00028},
  file      = {:FernandesMiotodeOliveiradosSantos2019 - A Survey on Microservices Criticality Attributes on Established Architectures.pdf:PDF},
  keywords  = {Computer architecture;ISO Standards;Atmospheric measurements;Particle measurements;Service-oriented architecture;Computational modeling;Microservices;Criticality;Attributes;Established Architectures;Survey},
}

@InProceedings{Camilli2020,
  author    = {Camilli, Matteo and Colarusso, Carmine and Russo, Barbara and Zimeo, Eugenio},
  booktitle = {2020 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)},
  title     = {Domain Metric Driven Decomposition of Data-Intensive Applications},
  year      = {2020},
  month     = {Oct},
  pages     = {189-196},
  abstract  = {The microservices architectural style is picking up more and more momentum in IT industry for the development of systems as loosely coupled, collaborating services. Companies that undergo the migration of their own applications have aspirations such as increasing maintainability and the scale of operation. Such a process is worthwhile but not easy, since it should ensure atomic improvements to the overall architecture for each migration step. Furthermore, the systematic evaluation of migration steps becomes cumbersome without sensible optimization metrics that take into account performance and scalability under expected operational conditions. Recent lines of research recognize this task as challenging, especially in data-intensive applications where known approaches based, for instance, on Domain Driven Design may not be adequate. In this paper, we introduce an approach to evaluate a migration in an iterative way and recognize whether it represents an improvement in terms of performance and scalability. The approach leverages a Domain Metric-based analysis to quantitatively evaluate alternative architectures. We exemplified the envisioned approach on a data-intensive application case study in the domain of smart mobility. Preliminary results from our controlled experiments show the effectiveness of our approach to support systematic and automated evaluation of migration processes.},
  doi       = {10.1109/ISSREW51248.2020.00071},
  file      = {:Camilli2020 - Domain Metric Driven Decomposition of Data Intensive Applications.pdf:PDF},
  keywords  = {Scalability;Testing;Measurement;Computer architecture;Roads;Business;Servers;Microservices;Decomposition;Performance Analysis;Scalability Analysis;Domain Metric},
}

@InProceedings{NikDaud2014,
  author    = {Nik Daud, Nik Marsyahariani and Wan Kadir, Wan M. N.},
  booktitle = {2014 8th. Malaysian Software Engineering Conference (MySEC)},
  title     = {Static and dynamic classifications for SOA structural attributes metrics},
  year      = {2014},
  month     = {Sep.},
  pages     = {130-135},
  abstract  = {Evaluating qualities of software based on software structural attributes such as coupling and cohesion are frequently done in practice as these attributes directly have impacts on value of higher level quality. Concerning oneself with structural attributes values early on helps developers to predict quality attributes level in the software. Service-Oriented Architecture (SOA) is an architectural concept where services are used as building blocks in developing new software. Lots of structural attributes metrics related to SOA had been proposed these recent years, which triggered an investigation to classify these metrics based on specific criteria. In this paper, we introduce classifications for SOA based structural attributes metrics, where the metrics are restricted to coupling, cohesion and complexity metrics. These metrics are classified based on software static and dynamic aspects with some brief introduction for each metric. By classifying these SOA based structural attributes metrics, it will allow user to avoid redundancy in proposing similar metrics thus increases the reusability of existing metrics.},
  doi       = {10.1109/MySec.2014.6986002},
  file      = {:NikDaud2014 - Static and Dynamic Classifications for SOA Structural Attributes Metrics.pdf:PDF},
  keywords  = {Couplings;Service-oriented architecture;Complexity theory;Software measurement;Semiconductor optical amplifiers;Structural attributes metric;Service Oriented Architecture;metrics classification},
}

@InProceedings{Nuraini2014,
  author    = {Nuraini, Aminah and Widyani, Yani},
  booktitle = {2014 International Conference on Data and Software Engineering (ICODSE)},
  title     = {Software with service oriented architecture quality assessment},
  year      = {2014},
  month     = {Nov},
  pages     = {1-6},
  abstract  = {Service Oriented Architecture (SOA) is becoming popular since its flexibility fulfill the need of rapidly changing enterprise requirement. Therefore, expectation of a good quality software with SOA is getting higher. To address this need, this paper presents a guideline to conduct quality assessment using an existing tool. The quality assessment model is designed by selecting the relevant quality factors, choosing an appropriate quality to metric mapping method, identifying the relevant metrics, and mapping each quality factor to the metrics. Using the model, the quality assessment process is prepared by identifying data and selecting the appropriate tools. The chosen tool may require some modification. The proposed quality assessment guideline can help the software quality assurance team to assess quality of their software with SOA. The proposed guideline has been used to assess the quality of an existing sofware with SOA (Bonita BPM). The result is considered as promising, although several improvement are still needed.},
  doi       = {10.1109/ICODSE.2014.7062707},
  file      = {:Nuraini2014 - Software with Service Oriented Architecture Quality Assessment.pdf:PDF},
  keywords  = {Measurement;Quality assessment;Service-oriented architecture;Q-factor;Guidelines;Semiconductor optical amplifiers;SOA;software quality assessment;quality factor;quality metrics},
}

@InProceedings{Marmsoler2018,
  author    = {Marmsoler, Diego},
  booktitle = {2018 International Symposium on Theoretical Aspects of Software Engineering (TASE)},
  title     = {On Syntactic and Semantic Dependencies in Service-Oriented Architectures},
  year      = {2018},
  month     = {Aug},
  pages     = {132-137},
  abstract  = {In service oriented architectures, components provide services on their output ports and consume services from other components on their input ports. Thereby, a component is said to depend on another component if the former consumes a service provided by the latter. This notion of dependency (which we call syntactic dependency) is used by many architecture analysis tools as a measure for system maintainability. With this paper, we introduce a weaker notion of dependency, still sufficient, however, to guarantee semantic independence between components. Thereby, we discover the concepts of weak and strong semantic dependency and prove that strong semantic dependency indeed implies syntactic dependency. Our alternative notion of dependency paves the way to more precise dependency analysis tools. Moreover, our results about the different types of dependencies can be used for the verification of semantic independence.},
  doi       = {10.1109/TASE.2018.00025},
  file      = {:Marmsoler2018 - On Syntactic and Semantic Dependencies in Service Oriented Architectures.pdf:PDF},
  keywords  = {Syntactic Dependency;Semantic Dependency;Service Oriented Architectures},
}

@Article{Zhao2017b,
  author   = {Zhao, Feng and Nian, Guodong and Jin, Hai and Yang, Laurence T. and Zhu, Yajun},
  journal  = {IEEE Systems Journal},
  title    = {A Hybrid eBusiness Software Metrics Framework for Decision Making in Cloud Computing Environment},
  year     = {2017},
  issn     = {1937-9234},
  month    = {June},
  number   = {2},
  pages    = {1049-1059},
  volume   = {11},
  abstract = {Developing high-quality software is essential for eBusiness organizations to cope with drastic market competition. With the development of cloud computing technologies, eBusiness systems and applications pay more attention to open endedness. In a cloud computing environment, eBusiness systems have the ability to provide information technology resources on demand. Traditional software metric methods in distributed systems and applications are technical and project driven, making the market demand and internal practical operation not perfectly balanced within a cloud-computing-based eBusiness corporation. To address this issue, this paper presents a hybrid framework based on the goal/question/metric paradigm to evaluate the quality and efficiency of previous software products, projects, and development organizations in a cloud computing environment. In our approach, to support decision making at the project and organization levels, three angular metrics are used, i.e., project metrics, product metrics, and organization metrics. Furthermore, an improved radial-basis-function-based model is also provided to manage existing projects and design new projects. Experimental results on a well-known eBusiness organization show that the proposed framework is effective, efficient, and operational. Moreover, using the described decision-making algorithm, the predicted data are very close to actual results on the software cost, the fault rate, the development workload, etc., which are greatly helpful in achieving high-quality software.},
  doi      = {10.1109/JSYST.2015.2443049},
  file     = {:Zhao2017b - A Hybrid EBusiness Software Metrics Framework for Decision Making in Cloud Computing Environment.pdf:PDF},
  keywords = {Computational modeling;Organizations;Software metrics;Cloud computing;Data models;Cloud computing;decision making;eBusiness;prediction;radial basis function (RBF);software metrics},
}

@Article{Li2020c,
  author   = {Li, Keqin},
  journal  = {IEEE Transactions on Cloud Computing},
  title    = {Quantitative Modeling and Analytical Calculation of Elasticity in Cloud Computing},
  year     = {2020},
  issn     = {2168-7161},
  month    = {Oct},
  number   = {4},
  pages    = {1135-1148},
  volume   = {8},
  abstract = {Elasticity is a fundamental feature of cloud computing and can be considered as a great advantage and a key benefit of cloud computing. One key challenge in cloud elasticity is lack of consensus on a quantifiable, measurable, observable, and calculable definition of elasticity and systematic approaches to modeling, quantifying, analyzing, and predicting elasticity. Another key challenge in cloud computing is lack of effective ways for prediction and optimization of performance and cost in an elastic cloud platform. The present paper makes the following significant contributions. First, we present a new, quantitative, and formal definition of elasticity in cloud computing, i.e., the probability that the computing resources provided by a cloud platform match the current workload. Our definition is applicable to any cloud platform and can be easily measured and monitored. Furthermore, we develop an analytical model to study elasticity by treating a cloud platform as a queueing system, and use a continuous-time Markov chain (CTMC) model to precisely calculate the elasticity value of a cloud platform by using an analytical and numerical method based on just a few parameters, namely, the task arrival rate, the service rate, the virtual machine start-up and shut-down rates. In addition, we formally define auto-scaling schemes and point out that our model and method can be easily extended to handle arbitrarily sophisticated scaling schemes. Second, we apply our model and method to predict many other important properties of an elastic cloud computing system, such as average task response time, throughput, quality of service, average number of VMs, average number of busy VMs, utilization, cost, cost-performance ratio, productivity, and scalability. In fact, from a cloud consumer's point of view, these performance and cost metrics are even more important than the elasticity metric. Our study in this paper has two significance. On one hand, a cloud service provider can predict its performance and cost guarantee using the results developed in this paper. On the other hand, a cloud service provider can optimize its elastic scaling scheme to deliver the best cost-performance ratio. To the best of our knowledge, this is the first paper that analytically and comprehensively studies elasticity, performance, and cost in cloud computing. Our model and method significantly contribute to the understanding of cloud elasticity and management of elastic cloud computing systems.},
  doi      = {10.1109/TCC.2017.2665549},
  file     = {:Li2020c - Quantitative Modeling and Analytical Calculation of Elasticity in Cloud Computing.pdf:PDF},
  keywords = {Cloud computing;Markov processes;Computational modeling;Analytical models;Pricing;Quality of service;Optimization;Queueing analysis;Cloud computing;continuous-time Markov chain;cost-performance ratio;elasticity;queueing model},
}

@Article{Guerron2020,
  author   = {Guerron, Ximena and Abrahão, Silvia and Insfran, Emilio and Fernández-Diego, Marta and González-Ladrón-De-Guevara, Fernando},
  journal  = {IEEE Access},
  title    = {A Taxonomy of Quality Metrics for Cloud Services},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {131461-131498},
  volume   = {8},
  abstract = {A large number of metrics with which to assess the quality of cloud services have been proposed over the last years. However, this knowledge is still dispersed, and stakeholders have little or no guidance when choosing metrics that will be suitable to evaluate their cloud services. The objective of this paper is, therefore, to systematically identify, taxonomically classify, and compare existing quality of service (QoS) metrics in the cloud computing domain. We conducted a systematic literature review of 84 studies selected from a set of 4333 studies that were published from 2006 to November 2018. We specifically identified 470 metric operationalizations that were then classified using a taxonomy, which is also introduced in this paper. The data extracted from the metrics were subsequently analyzed using thematic analysis. The findings indicated that most metrics evaluate quality attributes related to performance efficiency (64%) and that there is a need for metrics that evaluate other characteristics, such as security and compatibility. The majority of the metrics are used during the Operation phase of the cloud services and are applied to the running service. Our results also revealed that metrics for cloud services are still in the early stages of maturity - only 10% of the metrics had been empirically validated. The proposed taxonomy can be used by practitioners as a guideline when specifying service level objectives or deciding which metric is best suited to the evaluation of their cloud services, and by researchers as a comprehensive quality framework in which to evaluate their approaches.},
  doi      = {10.1109/ACCESS.2020.3009079},
  file     = {:Guerron2020 - A Taxonomy of Quality Metrics for Cloud Services.pdf:PDF},
  keywords = {Measurement;Cloud computing;Taxonomy;Quality of service;Systematics;NIST;Elasticity;Software quality;metrics;cloud services;systematic literature review},
}

@Article{Zheng2014a,
  author   = {Zheng, Xianrong and Martin, Patrick and Brohman, Kathryn and Xu, Li Da},
  journal  = {IEEE Transactions on Industrial Informatics},
  title    = {CLOUDQUAL: A Quality Model for Cloud Services},
  year     = {2014},
  issn     = {1941-0050},
  month    = {May},
  number   = {2},
  pages    = {1527-1536},
  volume   = {10},
  abstract = {Cloud computing is an important component of the backbone of the Internet of Things (IoT). Clouds will be required to support large numbers of interactions with varying quality requirements. Service quality will therefore be an important differentiator among cloud providers. In order to distinguish themselves from their competitors, cloud providers should offer superior services that meet customers' expectations. A quality model can be used to represent, measure, and compare the quality of the providers, such that a mutual understanding can be established among cloud stakeholders. In this paper, we take a service perspective and initiate a quality model named CLOUDQUAL for cloud services. It is a model with quality dimensions and metrics that targets general cloud services. CLOUDQUAL contains six quality dimensions, i.e., usability, availability, reliability, responsiveness, security, and elasticity, of which usability is subjective, whereas the others are objective. To demonstrate the effectiveness of CLOUDQUAL, we conduct empirical case studies on three storage clouds. Results show that CLOUDQUAL can evaluate their quality. To demonstrate its soundness, we validate CLOUDQUAL with standard criteria and show that it can differentiate service quality.},
  doi      = {10.1109/TII.2014.2306329},
  file     = {:Zheng2014a - CLOUDQUAL_ a Quality Model for Cloud Services.pdf:PDF},
  keywords = {Cloud computing;Security;Availability;Quality of service;Measurement;Cloud computing;Internet of Things (IoT);quality model;validity criteria},
}

@InProceedings{Cedillo2015,
  author    = {Cedillo, Priscila and Jimenez-Gomez, Javier and Abrahao, Silvia and Insfran, Emilio},
  booktitle = {2015 IEEE International Conference on Services Computing},
  title     = {Towards a Monitoring Middleware for Cloud Services},
  year      = {2015},
  month     = {June},
  pages     = {451-458},
  abstract  = {Cloud Computing represents a new trend in the development and use of software. Many organizations are currently adopting the use of services that are hosted in the cloud by employing the Software as a Service (SaaS) model. Services are typically accompanied by a Service Level Agreement (SLA), which defines the quality terms that a provider offers to its customers. Many monitoring tools have been proposed to report compliance with the SLA. However, they have some limitations when changes to monitoring requirements must be made and because of the complexity involved in capturing low-level raw data from services at runtime. In this paper, we propose the design of a platform-independent monitoring middleware for cloud services, which supports the monitoring of SLA compliance and provides a report containing SLA violations that may help stakeholders to make decisions regarding how to improve the quality of cloud services. Moreover, our middleware definition is based on the use of models@run.time, which allows the dynamic change of quality requirements and/or the dynamic selection of different metric operationalizations (i.e., Calculation formulas) with which to measure the quality of services. In order to demonstrate the feasibility of our approach, we show the instantiation of the proposed middleware that can be used to monitor services when deployed on the Microsoft Azure© platform.},
  doi       = {10.1109/SCC.2015.68},
  file      = {:Cedillo2015 - Towards a Monitoring Middleware for Cloud Services.pdf:PDF},
  keywords  = {Monitoring;Middleware;Measurement;Radiation detectors;Engines;Runtime;Software as a service;Cloud Computing;Software as a Service;Monitoring;Middleware;Quality of Service;Models@run.time},
}

@InProceedings{Brataas2017,
  author    = {Brataas, Grunnar and Herbst, Nikolas and Ivansek, Simon and Polutnik, Jure},
  booktitle = {2017 IEEE International Conference on Autonomic Computing (ICAC)},
  title     = {Scalability Analysis of Cloud Software Services},
  year      = {2017},
  month     = {July},
  pages     = {285-292},
  abstract  = {Cloud computing theoretically offers its customers unlimited cloud resources. However, the scalability of software services is often limited by their underlying architecture. In contrast to current scalability analysis approaches, we make work parameters, quality thresholds, as well as the resource space explicit in a conceptually consistent set of equations. We propose two scalability metric functions based on these equations. The resource scalability metric function describes the relation between the capacity of the multi-tier cloud software service and its use of cloud resources, whereas the cost scalability metric function replaces cloud resources with cost. We validate using the Cloud-Store application. CloudStore follows the TPC-W specification, representing an online book store. We have experimented with 21 different public Amazon Web Service configurations and two private OpenStack configurations.},
  doi       = {10.1109/ICAC.2017.34},
  file      = {:Brataas2017 - Scalability Analysis of Cloud Software Services.pdf:PDF},
  issn      = {2474-0756},
  keywords  = {Measurement;Scalability;Cloud computing;Computer architecture;Aerospace electronics;cloud;service;scalability;metric;measurement;cost},
}

@InProceedings{Zhou2015,
  author    = {Zhou, Nianjun and Mohindra, Ajay},
  booktitle = {2015 IEEE International Conference on Services Computing},
  title     = {Causality-Driven Performance Monitoring and Scaling Automation for Managed Solutions},
  year      = {2015},
  month     = {June},
  pages     = {467-474},
  abstract  = {A key feature of Cloud computing is its agility and flexibility to support the scalability needs of business solutions. Currently, the agility is only limited to the scalability of the compute, memory and storage. To improve an application's agility, we need to monitor & measure solution level metrics and associate the performance of the metrics to the business agility needs of the solution by making real-time scalability or change decisions. In this paper, we illustrate a scaling decision mechanism utilizing the monitoring data from infrastructure, middleware, and business level metrics. We use these performance metrics as input to a causality analysis model to make architecture changes or scalability decisions. Mathematically, we define the causality as a graph to link the changes in the measured metric values to the action of the solution change. The causality analysis follows scalability principles as best practices. They are a) the principle of performance scalability b) principle of contribution margin for scalability, and c) principle of the least cost of SLA compliance. We define these scalability principles as the rules to ensure that the business stakeholder of the solution can maintain or improve their business quality or profit margins as the computing capability scales up or down. To implement those principles, we need to establish the linkages of the business metrics to the decision of changes. To make such linkage, we first utilize causality analysis to identify feasible scaling actions, and then associate those actions with the system, application, and business performance metrics. With the help of causality analysis, we implement a performance monitoring and scaling automation framework for managed solutions using an Open Source Monitoring system.},
  doi       = {10.1109/SCC.2015.70},
  file      = {:Zhou2015 - Causality Driven Performance Monitoring and Scaling Automation for Managed Solutions.pdf:PDF},
  keywords  = {Scalability;Measurement;Monitoring;Business;Computer architecture;Media;Servers;Scalability;Business Monitoring;Performance Metrics;Service Level Agreements;Decision;Trade-Off},
}

@Article{Cedillo2021,
  author   = {Cedillo, Priscila and Insfran, Emilio and Abrahão, Silvia and Vanderdonckt, Jean},
  journal  = {IEEE Access},
  title    = {Empirical Evaluation of a Method for Monitoring Cloud Services Based on Models at Runtime},
  year     = {2021},
  issn     = {2169-3536},
  pages    = {55898-55919},
  volume   = {9},
  abstract = {Cloud computing is being adopted by commercial and governmental organizations driven by the need to reduce the operational cost of their information technology resources and search for a scalable and flexible way to provide and release their software services. In this computing model, the Quality of Services (QoS) is agreed between service providers and their customers through Service Level Agreements (SLA). There is thus a need for systematic approaches with which to assess the quality of cloud services and their compliance with the SLA. In previous work, we introduced a generic method for Monitoring cloud Services using models at RunTime (MoS@RT), which allows the monitoring requirements or the metric operationalizations of these requirements to be changed at runtime without the modification of the underlying infrastructure. In this paper, we present the design of a monitoring infrastructure that supports the proposed method with its instantiation to a specific platform and reports the results of an experiment carried out to evaluate the perceived efficacy of 58 undergraduate students when using the infrastructure to configure the monitoring of cloud services deployed on the Microsoft Azure platform. The results show that the participants perceived MoS@RT to be easy to use, useful, and they also expressed their intention to use the method in the future. Although further experiments must be carried out to strengthen these results, MoS@RT has proved to be a promising monitoring method for cloud services.},
  doi      = {10.1109/ACCESS.2021.3071417},
  file     = {:Cedillo2021 - Empirical Evaluation of a Method for Monitoring Cloud Services Based on Models at Runtime.pdf:PDF},
  keywords = {Monitoring;Cloud computing;Tools;Runtime;Quality of service;Measurement;Service level agreements;Cloud computing;models@runtime;quality of service (QoS);services monitoring;software as a service (SaaS)},
}

@InProceedings{AlSaidAhmad2018,
  author    = {Al-Said Ahmad, Amro and Andras, Peter},
  booktitle = {2018 Fifth International Symposium on Innovation in Information and Communication Technology (ISIICT)},
  title     = {Measuring and Testing the Scalability of Cloud-based Software Services},
  year      = {2018},
  month     = {Oct},
  pages     = {1-8},
  abstract  = {Performance and scalability testing and measurements of cloud-based software services are critically important in the context of rapid growth of cloud computing and supporting the delivery of these services. Cloud-based software services performance aspects are interrelated, both elasticity and efficiency are depending on the delivery of a sufficient level of scalability performance. In this work, we focused on testing and measuring the scalability of cloud-based software services in technical terms. This paper uses technical scalability metrics that address both volume and quality scaling, that inspired by earlier technical metrics of elasticity. We show how our technical scalability metrics can be integrated into an earlier utility oriented metric of scalability. We demonstrate the application of the metrics using a practical example and discuss the importance of them.},
  doi       = {10.1109/ISIICT.2018.8613297},
  file      = {:AlSaidAhmad2018 - Measuring and Testing the Scalability of Cloud Based Software Services.pdf:PDF},
  keywords  = {Scalability;Software;Elasticity;Software measurement;Testing;Cloud computing;Measurement;Performance;Testing;Scalability;Software-as-a-Service (SaaS);Metrics},
}

@Article{AbdelBaky2019,
  author   = {AbdelBaky, Moustafa and Parashar, Manish},
  journal  = {IEEE Transactions on Services Computing},
  title    = {A General Performance and QoS Model for Distributed Software-Defined Environments},
  year     = {2019},
  issn     = {1939-1374},
  pages    = {1-1},
  abstract = {The landscape for cloud services and cyberinfrastructure offerings has increased drastically over the past few years. Initially, users moved their applications to the cloud to take advantage of a pay-per-usage model and on-demand access. However, as more cloud providers joined the market, users shifted their goals for using cloud computing from cost reduction to resilience, agility, and optimization. These goals can be achieved by dynamically combining services from multiple providers, for example, to avoid data center or cloud zone outages or to take advantage of extensive offerings with different price points. However, to efficiently support application deployment in this dynamic environment, new models and tools that can measure the application performance and the Quality of Service (QoS) of different configurations are required. The goal of this work is to evaluate the application performance and the QoS of a distributed Software-Defined Environment as well as calculate the QoS of alternative configurations from the underlying pool of services. In particular, we present a mathematical model and a tool for evaluating the performance and QoS of batch application workflows in a distributed environment. We experimentally evaluate the proposed model using a bioinformatics workflow running on infrastructure services from multiple cloud providers.},
  doi      = {10.1109/TSC.2019.2928300},
  file     = {:AbdelBaky2019 - A General Performance and QoS Model for Distributed Software Defined Environments.pdf:PDF},
  keywords = {Cloud computing;Quality of service;Computational modeling;Data models;Optimization;Mathematical model;Tools;QoS modeling;performance modeling;multi-cloud;software-define environments},
}

@Article{Raj2021,
  author    = {Vinay Raj and Ravichandra Sadam},
  journal   = {{SN} Computer Science},
  title     = {Evaluation of {SOA}-Based Web Services and Microservices Architecture Using Complexity Metrics},
  year      = {2021},
  month     = {jul},
  number    = {5},
  volume    = {2},
  abstract  = {Distributed systems have evolved rapidly as the demand for independent design and deployment of software applications has increased. Web services and microservices are two styles of designing distributed applications based on the principles of Service-Oriented Architecture (SOA). After the evolution of microservices, software architects are in chaos, whether to adopt microservices over web services. To the best of our knowledge, there has been no empirical work done in the literature for comparing both web services and microservices architecture in terms of the coupling principle of SOA. In this paper, a service graph-based approach is proposed to analyze and evaluate the effectiveness of microservices architecture when compared with web services. Loose coupling is used as a perspective for evaluation, and we have chosen two case study applications to evaluate them in terms of coupling. From the results, it is observed that microservices has lesser coupling values than web services.},
  doi       = {10.1007/s42979-021-00767-6},
  file      = {:Raj2021 - Evaluation of SOA Based Web Services and Microservices Architecture Using Complexity Metrics.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
  url       = {https://doi.org/10.1007%2Fs42979-021-00767-6},
}

@Article{Slimani2020,
  author    = {Sarra Slimani and Tarek Hamrouni and Faouzi Ben Charrada},
  journal   = {Cluster Computing},
  title     = {Service-oriented replication strategies for improving quality-of-service in cloud computing: a survey},
  year      = {2020},
  month     = {may},
  number    = {1},
  pages     = {361--392},
  volume    = {24},
  abstract  = {The recent years have witnessed significant interest in migrating different applications into the cloud platforms. In this context, one of the main challenges for cloud applications providers is how to ensure high availability of the delivered applications while meeting users’ QoS. In this respect, replication techniques are commonly applied to efficiently handle this issue. From the literature, according to the used granularity for replication there are two major approaches to achieve replication: either through replicating the service or the underlying data. The latter one is also known as Data-oriented Replication (DoR), while the former one is referred to as Service-oriented Replication (SoR). DoR is discussed extensively in the available literature and several surveys are already published. However, SoR is still at its infancy and there is a lack of research studies. Hence, in this paper we present a comprehensive survey of SoR strategies in cloud computing. We propose a classification of existing works based on the research methods they use. Then, we carried out an in-depth study and analysis of these works. In addition, a tabular representation of all relevant features is presented to facilitate the comparison of SoR techniques and the proposal of new enhanced strategies.},
  doi       = {10.1007/s10586-020-03108-z},
  file      = {:Slimani2020 - Service Oriented Replication Strategies for Improving Quality of Service in Cloud Computing_ a Survey.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Bogner2021,
  author    = {Justus Bogner and Jonas Fritzsch and Stefan Wagner and Alfred Zimmermann},
  journal   = {Empirical Software Engineering},
  title     = {Industry practices and challenges for the evolvability assurance of microservices},
  year      = {2021},
  month     = {jul},
  number    = {5},
  volume    = {26},
  abstract  = {Context
Microservices as a lightweight and decentralized architectural style with fine-grained services promise several beneficial characteristics for sustainable long-term software evolution. Success stories from early adopters like Netflix, Amazon, or Spotify have demonstrated that it is possible to achieve a high degree of flexibility and evolvability with these systems. However, the described advantageous characteristics offer no concrete guidance and little is known about evolvability assurance processes for microservices in industry as well as challenges in this area. Insights into the current state of practice are a very important prerequisite for relevant research in this field.

Objective
We therefore wanted to explore how practitioners structure the evolvability assurance processes for microservices, what tools, metrics, and patterns they use, and what challenges they perceive for the evolvability of their systems.

Method
We first conducted 17 semi-structured interviews and discussed 14 different microservice-based systems and their assurance processes with software professionals from 10 companies. Afterwards, we performed a systematic grey literature review (GLR) and used the created interview coding system to analyze 295 practitioner online resources.

Results
The combined analysis revealed the importance of finding a sensible balance between decentralization and standardization. Guidelines like architectural principles were seen as valuable to ensure a base consistency for evolvability and specialized test automation was a prevalent theme. Source code quality was the primary target for the usage of tools and metrics for our interview participants, while testing tools and productivity metrics were the focus of our GLR resources. In both studies, practitioners did not mention architectural or service-oriented tools and metrics, even though the most crucial challenges like Service Cutting or Microservices Integration were of an architectural nature.

Conclusions
Practitioners relied on guidelines, standardization, or patterns like Event-Driven Messaging to partially address some reported evolvability challenges. However, specialized techniques, tools, and metrics are needed to support industry with the continuous evaluation of service granularity and dependencies. Future microservices research in the areas of maintenance, evolution, and technical debt should take our findings and the reported industry sentiments into account.},
  doi       = {10.1007/s10664-021-09999-9},
  file      = {:Bogner2021 - Industry Practices and Challenges for the Evolvability Assurance of Microservices.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
  url       = {https://doi.org/10.1007%2Fs10664-021-09999-9},
}

@InCollection{Engel2018,
  author    = {Thomas Engel and Melanie Langermeier and Bernhard Bauer and Alexander Hofmann},
  booktitle = {Lecture Notes in Business Information Processing},
  publisher = {Springer International Publishing},
  title     = {Evaluation of Microservice Architectures: A Metric and Tool-Based Approach},
  year      = {2018},
  pages     = {74--89},
  abstract  = {Microservices are an architectural style that decomposes the functionality of an application system into several small functional units. The services are implemented and managed independently from each other. Breaking up monolithic structures into a microservice architecture increases the number of single components massively. Thus, effective management of the dependencies between them is required. This task can be supported with the creation and evaluation of architectural models. In this work, we propose an evaluation approach for microservice architectures based on identified architecture principles from research and practice like a small size of the services, a domain-driven design or loose coupling. Based on a study showing the challenges in current microservice architectures, we derived principles and metrics for the evaluation of the architectural design. The required architecture data is captured with a reverse engineering approach from traces of communication data. The developed tool is finally evaluated within a case study.},
  doi       = {10.1007/978-3-319-92901-9_8},
  file      = {:Engel2018 - Evaluation of Microservice Architectures_ a Metric and Tool Based Approach.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-319-92901-9_8},
}

@InCollection{Chauhan2016,
  author    = {Muhammad Aufeef Chauhan and Muhammad Ali Babar and Christian W. Probst},
  booktitle = {Product-Focused Software Process Improvement},
  publisher = {Springer International Publishing},
  title     = {A Process Framework for Designing Software Reference Architectures for Providing Tools as a Service},
  year      = {2016},
  pages     = {111--126},
  abstract  = {Software Reference Architecture (SRA), which is a generic architecture solution for a specific type of software systems, provides foundation for the design of concrete architectures in terms of architecture design guidelines and architecture elements. The complexity and size of certain types of software systems need customized and systematic SRA design and evaluation methods. In this paper, we present a software Reference Architecture Design process Framework (RADeF) that can be used for analysis, design and evaluation of the SRA for provisioning of Tools as a Service as part of a cloud-enabled workSPACE (TSPACE). The framework is based on the state of the art results from literature and our experiences with designing software architectures for cloud-based systems. We have applied RADeF SRA design two types of TSPACE: software architecting TSPACE and software implementation TSPACE. The presented framework emphasizes on keeping the conceptual meta-model of the domain under investigation at the core of SRA design strategy and use it as a guiding tool for design, evaluation, implementation and evolution of the SRA. The framework also emphasizes to consider the nature of the tools to be provisioned and underlying cloud platforms to be used while designing SRA. The framework recommends adoption of the multi-faceted approach for evaluation of SRA and quantifiable measurement scheme to evaluate quality of the SRA. We foresee that RADeF can facilitate software architects and researchers during design, application and evaluation of a SRA and its instantiations into concrete software systems.},
  doi       = {10.1007/978-3-319-49094-6_8},
  file      = {:Chauhan2016 - A Process Framework for Designing Software Reference Architectures for Providing Tools As a Service.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-319-49094-6_8},
}

@InCollection{AdjeponYamoah2016,
  author    = {David Ebo Adjepon-Yamoah},
  booktitle = {Lecture Notes in Computer Science},
  publisher = {Springer International Publishing},
  title     = {cloud-{ATAM}: Method for Analysing Resilient Attributes of Cloud-Based Architectures},
  year      = {2016},
  pages     = {105--114},
  abstract  = {In this work, we argue that the existing architecture evaluation methods have limitations when assessing architectures interfacing with unpredictable environments such as the Cloud. The unpredictability of this environment is attributed to the dynamic elasticity, scale, and continuous evolution of the cloud topology. As a result, architectures interfacing such unpredictable environments are expected to encounter many uncertainties. It is however, important to focus on, and present holistic approaches combining aspects of both dynamic and static analysis of architecture resilience attributes. This paper introduces an ATAM derived methodology - cloud-ATAM - for evaluating the trade-off between multiple resilience quality attributes (i.e. availability and performance) of a cloud-based Reactive Architecture for Global Software Development.},
  doi       = {10.1007/978-3-319-45892-2_8},
  file      = {:AdjeponYamoah2016 - Cloud ATAM_ Method for Analysing Resilient Attributes of Cloud Based Architectures.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-319-45892-2_8},
}

@Article{Nogueira2016,
  author    = {Elias Nogueira and Ana Moreira and Daniel Lucr{\'{e}}dio and Vin{\'{\i}}cius Garcia and Renata Fortes},
  journal   = {Journal of Software Engineering Research and Development},
  title     = {Issues on developing interoperable cloud applications: definitions, concepts, approaches, requirements, characteristics and evaluation models},
  year      = {2016},
  month     = {dec},
  number    = {1},
  volume    = {4},
  abstract  = {Among research opportunities in software engineering for cloud computing model, interoperability stands out. We found that the dynamic nature of cloud technologies and the battle for market domination make cloud applications locked-id, i.e, proprietary, non-portable and non-interoperable. In general context of cloud computing, interoperability goes beyond communication between systems like in other fields, it goes in direction of more dynamic, heterogeneous, complex and composed applications that take advantage of best features from different providers and services simultaneously. Interoperability in cloud constitutes a great challenge that must be overcome for that, in the future, software be more dynamic and improved.

Objective: This paper aims at identifying how interoperability in cloud computing has been addressed in the existing literature, offering an up-to-date view of concepts relate to how to develop interoperable software that takes advantage of different cloud models. Thus, providing a basis for further research in the field and consolidating e better exploring existing concepts.

Method: To fulfill this objective, we surveyed literature. We defined six research questions and conducted the study according to a protocol that included planning, and execution.

Results: A first result of the review is that there is no well established definition for cloud interoperability. This study also identified cloud interoperability concepts (e.g., cloud brokers, multi-cloud and cloud federation), requirements for interoperable applications and existing cloud interoperability solutions, showing that these are either too specific for particular situations. Finally, the survey found no evaluation models for cloud interoperability solutions. We also present a discussion on the findings of this study.

Conclusion: Since the study observed that there are no well-established cloud interoperability solutions yet, we conclude that the issues raised by lack of interoperability persist. Selecting one interoperable solution or even a cloud standard can free the system from the underlying providers, but it would still be locked into the selected particular solution.},
  doi       = {10.1186/s40411-016-0033-6},
  file      = {:Nogueira2016 - Issues on Developing Interoperable Cloud Applications_ Definitions, Concepts, Approaches, Requirements, Characteristics and Evaluation Models.pdf:PDF},
  publisher = {Sociedade Brasileira de Computacao - {SB}},
  url       = {https://doi.org/10.1186%2Fs40411-016-0033-6},
}

@InCollection{Ardagna2014,
  author    = {Danilo Ardagna and Giovanni Paolo Gibilisco and Michele Ciavotta and Alexander Lavrentev},
  booktitle = {Search-Based Software Engineering},
  publisher = {Springer International Publishing},
  title     = {A Multi-model Optimization Framework for the Model Driven Design of Cloud Applications},
  year      = {2014},
  pages     = {61--76},
  abstract  = {The rise and adoption of the Cloud computing paradigm had a strong impact on the ICT world in the last few years; this technology has now reached maturity and Cloud providers offer a variety of solutions and services to their customers. However, beside the advantages, Cloud computing introduced new issues and challenges. In particular, the heterogeneity of the Cloud services offered and their relative pricing models makes the identification of a deployment solution that minimizes costs and guarantees QoS very complex. Performance assessment of Cloud based application needs for new models and tools to take into consideration the dynamism and multi-tenancy intrinsic of the Cloud environment. The aim of this work is to provide a novel mixed integer linear program (MILP) approach to find a minimum cost feasible cloud configuration for a given cloud based application. The feasibility of the solution is considered with respect to some non-functional requirements that are analyzed through multiple performance models with different levels of accuracy. The initial solution is further improved by a local search based procedure. The quality of the initial feasible solution is compared against first principle heuristics currently adopted by practitioners and Cloud providers.},
  doi       = {10.1007/978-3-319-09940-8_5},
  file      = {:Ardagna2014 - A Multi Model Optimization Framework for the Model Driven Design of Cloud Applications.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-319-09940-8_5},
}

@Article{Ciancone2013,
  author    = {Andrea Ciancone and Mauro Luigi Drago and Antonio Filieri and Vincenzo Grassi and Heiko Koziolek and Raffaela Mirandola},
  journal   = {Software {\&} Systems Modeling},
  title     = {The {KlaperSuite} framework for model-driven reliability analysis of component-based systems},
  year      = {2013},
  month     = {mar},
  number    = {4},
  pages     = {1269--1290},
  volume    = {13},
  abstract  = {Automatic prediction tools play a key role in enabling the application of non-functional requirements analysis, to simplify the selection and the assembly of components for component-based software systems, and in reducing the need for strong mathematical skills for software designers. By exploiting the paradigm of Model-Driven Engineering (MDE), it is possible to automatically transform design models into analytical models, thus enabling formal property verification. MDE is the core paradigm of the KlaperSuite framework presented in this paper, which exploits the KLAPER pivot language to fill the gap between design and analysis of component-based systems for reliability properties. KlaperSuite is a family of tools empowering designers with the ability to capture and analyze quality of service views of their systems, by building a one-click bridge towards a number of established verification instruments. In this article, we concentrate on the reliability-prediction capabilities of KlaperSuite and we evaluate them with respect to several case studies from literature and industry.},
  doi       = {10.1007/s10270-013-0334-8},
  file      = {:Ciancone2013 - The KlaperSuite Framework for Model Driven Reliability Analysis of Component Based Systems.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
  url       = {https://doi.org/10.1007%2Fs10270-013-0334-8},
}

@Article{Bento2021,
  author    = {Andre Bento and Jaime Correia and Ricardo Filipe and Filipe Araujo and Jorge Cardoso},
  journal   = {Journal of Grid Computing},
  title     = {Automated Analysis of Distributed Tracing: Challenges and Research Directions},
  year      = {2021},
  month     = {feb},
  number    = {1},
  volume    = {19},
  abstract  = {Microservice-based architectures are gaining popularity for their benefits in software development. Distributed tracing can be used to help operators maintain observability in this highly distributed context, and find problems such as latency, and analyse their context and root cause. However, exploring and working with distributed tracing data is sometimes difficult due to its complexity and application specificity, volume of information and lack of tools. The most common and general tools available for this kind of data, focus on trace-level human-readable data visualisation. Unfortunately, these tools do not provide good ways to abstract, navigate, filter and analyse tracing data. Additionally, they do not automate or aid with trace analysis, relying on administrators to do it themselves. In this paper we propose using tracing data to extract service metrics, dependency graphs and work-flows with the objective of detecting anomalous services and operation patterns. We implemented and published open source prototype tools to process tracing data, conforming to the OpenTracing standard, and developed anomaly detection methods. We validated our tools and methods against real data provided by a major cloud provider. Results show that there is an underused wealth of actionable information that can be extracted from both metric and morphological aspects derived from tracing. In particular, our tools were able to detect anomalous behaviour and situate it both in terms of involved services, work-flows and time-frame. Furthermore, we identified some limitations of the OpenTracing format—as well as the industry accepted tracing abstractions—, and provide suggestions to test trace quality and enhance the standard.},
  doi       = {10.1007/s10723-021-09551-5},
  file      = {:Bento2021 - Automated Analysis of Distributed Tracing_ Challenges and Research Directions.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Kosinska2020,
  author    = {Joanna Kosi{\'{n}}ska and Krzysztof Zieli{\'{n}}ski},
  journal   = {Journal of Grid Computing},
  title     = {Autonomic Management Framework for Cloud-Native Applications},
  year      = {2020},
  month     = {sep},
  number    = {4},
  pages     = {779--796},
  volume    = {18},
  abstract  = {In order to meet the rapidly changing requirements of the Cloud-native dynamic execution environment, without human support and without the need to continually improve one’s skills, autonomic features need to be added. Embracing automation at every layer of performance management enables us to reduce costs while improving outcomes. The main contribution of this paper is the definition of autonomic management requirements of Cloud-native applications. We propose that the automation is achieved via high-level policies. In turn autonomy features are accomplished via the rule engine support. First, the paper presents the engineering perspective of building a framework for Autonomic Management of Cloud-Native Applications, namely AMoCNA, in accordance with Model Driven Architecture (MDA) concepts. AMoCNA has many desirable features whose main goal is to reduce the complexity of managing Cloud-native applications. The presented models are, in fact, meta-models, being technology agnostic. Secondly, the paper demonstrates one possibility of implementing the aforementioned design procedures. The presented AMoCNA implementation is also evaluated to identify the potential overhead introduced by the framework.},
  doi       = {10.1007/s10723-020-09532-0},
  file      = {:Kosinska2020 - Autonomic Management Framework for Cloud Native Applications.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
  url       = {https://doi.org/10.1007%2Fs10723-020-09532-0},
}

@InCollection{Bryzgalov2021,
  author    = {Anton Bryzgalov and Sergey Stupnikov},
  booktitle = {Communications in Computer and Information Science},
  publisher = {Springer International Publishing},
  title     = {A Cloud-Native Serverless Approach for Implementation of Batch Extract-Load Processes in Data Lakes},
  year      = {2021},
  pages     = {27--42},
  abstract  = {The paper presents an approach to deal with batch extract-load processes for cloud data lakes. The approach combines multiple data ingestion techniques, provides advanced failover strategies and adopts cloud-native implementation. The suggested approach. The prototype implementation utilizes Amazon Web Services platform and is based on its serverless features. The approach can be implemented also using other cloud platforms like Google Cloud Platform or Microsoft Azure.},
  doi       = {10.1007/978-3-030-81200-3_3},
  file      = {:Bryzgalov2021 - A Cloud Native Serverless Approach for Implementation of Batch Extract Load Processes in Data Lakes.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-030-81200-3_3},
}

@Article{Kehrer2019,
  author    = {Stefan Kehrer and Wolfgang Blochinger},
  journal   = {{SICS} Software-Intensive Cyber-Physical Systems},
  title     = {Migrating parallel applications to the cloud: assessing cloud readiness based on parallel design decisions},
  year      = {2019},
  month     = {feb},
  number    = {2-3},
  pages     = {73--84},
  volume    = {34},
  abstract  = {Parallel applications are the computational backbone of major industry trends and grand challenges in science. Whereas these applications are typically constructed for dedicated High Performance Computing clusters and supercomputers, the cloud emerges as attractive execution environment, which provides on-demand resource provisioning and a pay-per-use model. However, cloud environments require specific application properties that may restrict parallel application design. As a result, design trade-offs are required to simultaneously maximize parallel performance and benefit from cloud-specific characteristics. In this paper, we present a novel approach to assess the cloud readiness of parallel applications based on the design decisions made. By discovering and understanding the implications of these parallel design decisions on an application’s cloud readiness, our approach supports the migration of parallel applications to the cloud. We introduce an assessment procedure, its underlying meta model, and a corresponding instantiation to structure this multi-dimensional design space. For evaluation purposes, we present an extensive case study comprising three parallel applications and discuss their cloud readiness based on our approach.},
  doi       = {10.1007/s00450-019-00396-8},
  file      = {:Kehrer2019 - Migrating Parallel Applications to the Cloud_ Assessing Cloud Readiness Based on Parallel Design Decisions.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
  url       = {https://doi.org/10.1007%2Fs00450-019-00396-8},
}

@Article{Wei2021,
  author    = {Hao Wei and Joaquin Salvachua Rodriguez and Octavio Nieto-Taladriz Garcia},
  journal   = {Journal of Grid Computing},
  title     = {Deployment Management and Topology Discovery of Microservice Applications in the Multicloud Environment},
  year      = {2021},
  month     = {jan},
  number    = {1},
  volume    = {19},
  abstract  = {Cloud computing enables the evolution of modern software application design. Applications based on microservice architecture are an example. Meanwhile, multiclouds are widely accepted by enterprise as an infrastructure strategy; however, challenges remain. The autonomous and distributable nature of modern applications, as well as the complexity of multicloud infrastructure, often make universal application deployment management impractical. This phenomenon may further hinder application quality and efficiency. Therefore, deployment resource control and topology discovery in the multicloud infrastructure environment is an intriguing area of cloud computing research. This paper proposes a framework to manage application deployment in the multicloud environment. The framework uses a policy-based deployment control to automatically select and provide deployment resources from the multicloud infrastructure, and it subsequently uses topology discovery to visualize and verify the actual deployment. The proposed framework design is introduced in the paper, and a proof-of-concept prototype is implemented. Experiments in empirical scenarios are conducted. The experimental results indicate that the proposed framework is effective in controlling deployment resources and presenting actual deployment across clouds.},
  doi       = {10.1007/s10723-021-09539-1},
  file      = {:Wei2021 - Deployment Management and Topology Discovery of Microservice Applications in the Multicloud Environment.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
  url       = {https://doi.org/10.1007%2Fs10723-021-09539-1},
}

@InCollection{Lin2018,
  author    = {Jinjin Lin and Pengfei Chen and Zibin Zheng},
  booktitle = {Service-Oriented Computing},
  publisher = {Springer International Publishing},
  title     = {Microscope: Pinpoint Performance Issues with Causal Graphs in Micro-service Environments},
  year      = {2018},
  pages     = {3--20},
  abstract  = {Driven by the emerging business models (e.g., digital sales) and IT technologies (e.g., DevOps and Cloud computing), the architecture of software is shifting from monolithic to microservice rapidly. Benefit from microservice, software development, and delivery processes are accelerated significantly. However, along with many micro services running in the dynamic cloud environment with complex interactions, identifying and locating the abnormal services are extraordinarily difficult. This paper presents a novel system named “Microscope” to identify and locate the abnormal services with a ranked list of possible root causes in Micro-service environments. Without instrumenting the source code of micro services, Microscope can efficiently construct a service causal graph and infer the causes of performance problems in real time. Experimental evaluations in a micro-service benchmark environment show that Microscope achieves a good diagnosis result, i.e., 88% in precision and 80% in recall, which is higher than several state-of-the-art methods. Meanwhile, it has a good scalability to adapt to large-scale micro-service systems.},
  doi       = {10.1007/978-3-030-03596-9_1},
  file      = {:Lin2018 - Microscope_ Pinpoint Performance Issues with Causal Graphs in Micro Service Environments.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-030-03596-9_1},
}

@InCollection{Jindal2021,
  author    = {Anshul Jindal and Michael Gerndt},
  booktitle = {Communications in Computer and Information Science},
  publisher = {Springer International Publishing},
  title     = {From {DevOps} to {NoOps}: Is It Worth It?},
  year      = {2021},
  pages     = {178--202},
  abstract  = {With the rise of the adoption of microservice architecture due to its agility, scalability, and resiliency for building the cloud-based applications and their deployment using containerization, DevOps were in demand for handling the development and operations together. However, nowadays serverless computing offers a new way of developing and deploying cloud-native applications. Serverless computing also called NoOps, offloads management and server configuration (operations work) from the user to the cloud provider and lets the user focus only on the product developments. Hence, there are debates regarding which deployment strategy to use.

This research provides a performance comparison of a cloud-native web application along with three different function benchmarks in terms of scalability, reliability, and latency when deployed using DevOps and NoOps deployment strategy. NoOps deployment in this work is achieved using Google Cloud Function and OpenWhisk, while DevOps is achieved using the Kubernetes engine. This research shows that neither of the deployment strategies fits all the scenarios. The experimental results demonstrate that each type of deployment strategy has its advantages under different scenarios. The DevOps deployment strategy has a huge performance advantage (almost 72% lesser 90 percentile response time) for simple web-based requests and requests accessing databases while compute-intensive applications perform better with NoOps deployment. Additionally, NoOps deployment provides better scaling-agility as compared to DevOps.},
  doi       = {10.1007/978-3-030-72369-9_8},
  file      = {:Jindal2021 - From DevOps to NoOps_ Is It Worth It_.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-030-72369-9_8},
}

@Article{Zimmermann2016,
  author    = {Olaf Zimmermann},
  journal   = {Computing},
  title     = {Architectural refactoring for the cloud: a decision-centric view on cloud migration},
  year      = {2016},
  month     = {oct},
  number    = {2},
  pages     = {129--145},
  volume    = {99},
  abstract  = {Unlike code refactoring of programs, architectural refactoring of systems is not commonly practiced yet. However, legacy systems typically have to be refactored when migrating them to the cloud; otherwise, these systems may run in the cloud, but cannot fully benefit from cloud properties such as elasticity. One reason for the lack of adoption of architectural refactoring is that many of the involved artefacts are intangible—architectural refactoring therefore is harder to grasp than code refactoring. To overcome this inhibitor, we take a task-centric view on the subject and introduce an architectural refactoring template that highlights the architectural decisions to be revisited when refactoring application architectures for the cloud; in this approach, architectural smells are derived from quality stories. We also present a number of common architectural refactorings and evaluate existing patterns regarding their cloud affinity. The final contribution of this paper is the identification of an initial catalog of architectural refactorings for cloud application design. This refactoring catalog was compiled from the cloud patterns literature as well as project experiences. Cloud knowledge and supporting templates have been validated via action research and implementation in cooperation with practitioners.},
  doi       = {10.1007/s00607-016-0520-y},
  file      = {:Zimmermann2016 - Architectural Refactoring for the Cloud_ a Decision Centric View on Cloud Migration.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Casale2019,
  author    = {G. Casale and M. Arta{\v{c}} and W.-J. van den Heuvel and A. van Hoorn and P. Jakovits and F. Leymann and M. Long and V. Papanikolaou and D. Presenza and A. Russo and S. N. Srirama and D. A. Tamburri and M. Wurster and L. Zhu},
  journal   = {{SICS} Software-Intensive Cyber-Physical Systems},
  title     = {{RADON}: rational decomposition and orchestration for serverless computing},
  year      = {2019},
  month     = {aug},
  number    = {1-2},
  pages     = {77--87},
  volume    = {35},
  abstract  = {Emerging serverless computing technologies, such as function as a service (FaaS), enable developers to virtualize the internal logic of an application, simplifying the management of cloud-native services and allowing cost savings through billing and scaling at the level of individual functions. Serverless computing is therefore rapidly shifting the attention of software vendors to the challenge of developing cloud applications deployable on FaaS platforms. In this vision paper, we present the research agenda of the RADON project (http://radon-h2020.eu), which aims to develop a model-driven DevOps framework for creating and managing applications based on serverless computing. RADON applications will consist of fine-grained and independent microservices that can efficiently and optimally exploit FaaS and container technologies. Our methodology strives to tackle complexity in designing such applications, including the solution of optimal decomposition, the reuse of serverless functions as well as the abstraction and actuation of event processing chains, while avoiding cloud vendor lock-in through models.},
  doi       = {10.1007/s00450-019-00413-w},
  file      = {:Casale2019 - RADON_ Rational Decomposition and Orchestration for Serverless Computing.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
  url       = {https://doi.org/10.1007%2Fs00450-019-00413-w},
}

@InCollection{Andreou2021,
  author    = {Andreas S. Andreou and Andreas Christoforou},
  booktitle = {Next-Gen Digital Services. A Retrospective and Roadmap for Service Computing of the Future},
  publisher = {Springer International Publishing},
  title     = {On the Migration to and Synthesis of (Micro-)services: The Use of Intelligent Techniques},
  year      = {2021},
  pages     = {48--66},
  abstract  = {This chapter investigates the use of Computational Intelligence (CI) to tackle two challenges in the area of services. The first is involved with providing efficient decision support for migrating from monolithic to service-oriented software, while the latter addresses automatic service composition, which is a special form of service migration. Migration to service-oriented architecture (SOA) is influenced by a number of different and intertwined factors. These factors are identified through literature review and expert consultation. Different CI models, such as Fuzzy Influence Diagrams and Fuzzy Cognitive Maps, are employed to organize the factors and study their behavior. Various simulations are conducted that enable decision makers to execute what-if scenarios and take informed decisions as to whether to migrate or not to SOA, as well as to study the decisive factors contributing in favor or against this migration. Service synthesis is a tedious task considering on one hand the plethora of available services and on the other their different, often conflicting characteristics. Automation of this task is therefore a critical issue which deserves attention. In this context, the challenge of automatic service synthesis is addressed through specific methods and techniques based on Evolutionary Computation to achieve such automation to the best possible extent.},
  doi       = {10.1007/978-3-030-73203-5_4},
  file      = {:Andreou2021 - On the Migration to and Synthesis of (Micro )services_ the Use of Intelligent Techniques.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-030-73203-5_4},
}

@Article{OparaMartins2016,
  author    = {Justice Opara-Martins and Reza Sahandi and Feng Tian},
  journal   = {Journal of Cloud Computing},
  title     = {Critical analysis of vendor lock-in and its impact on cloud computing migration: a business perspective},
  year      = {2016},
  month     = {apr},
  number    = {1},
  volume    = {5},
  abstract  = {Vendor lock-in is a major barrier to the adoption of cloud computing, due to the lack of standardization. Current solutions and efforts tackling the vendor lock-in problem are predominantly technology-oriented. Limited studies exist to analyse and highlight the complexity of vendor lock-in problem in the cloud environment. Consequently, most customers are unaware of proprietary standards which inhibit interoperability and portability of applications when taking services from vendors. This paper provides a critical analysis of the vendor lock-in problem, from a business perspective. A survey based on qualitative and quantitative approaches conducted in this study has identified the main risk factors that give rise to lock-in situations. The analysis of our survey of 114 participants shows that, as computing resources migrate from on-premise to the cloud, the vendor lock-in problem is exacerbated. Furthermore, the findings exemplify the importance of interoperability, portability and standards in cloud computing. A number of strategies are proposed on how to avoid and mitigate lock-in risks when migrating to cloud computing. The strategies relate to contracts, selection of vendors that support standardised formats and protocols regarding standard data structures and APIs, developing awareness of commonalities and dependencies among cloud-based solutions. We strongly believe that the implementation of these strategies has a great potential to reduce the risks of vendor lock-in.},
  doi       = {10.1186/s13677-016-0054-z},
  file      = {:OparaMartins2016 - Critical Analysis of Vendor Lock in and Its Impact on Cloud Computing Migration_ a Business Perspective.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
  url       = {https://doi.org/10.1186%2Fs13677-016-0054-z},
}

@Article{ParviziMosaed2014,
  author    = {Alireza Parvizi-Mosaed and Shahrouz Moaven and Jafar Habibi and Ghazaleh Beigi and Mahdieh Naser-Shariat},
  journal   = {Frontiers of Information Technology {\&} Electronic Engineering},
  title     = {Towards a self-adaptive service-oriented methodology based on extended {SOMA}},
  year      = {2014},
  month     = {dec},
  number    = {1},
  pages     = {43--69},
  volume    = {16},
  abstract  = {We propose a self-adaptive process (SAP) that maintains the software architecture quality using the MAPE-K standard model. The proposed process can be plugged into various software development processes and service-oriented methodologies due to its explicitly defined inputs and outputs. To this aim, the proposed SAP is integrated with the service-oriented modeling and application (SOMA) methodology in a two-layered structure to create a novel methodology, named self-adaptive service-oriented architecture methodology (SASOAM), which provides a semi-automatic self-aware method by the composition of architectural tactics. Moreover, the maintenance activity of SOMA is improved using architectural and adaptive patterns, which results in controlling the software architecture quality. The improvement in the maintainability of SOMA is demonstrated by an analytic hierarchy process (AHP) based evaluation method. Furthermore, the proposed method is applied to a case study to represent the feasibility and practicality of SASOAM.},
  doi       = {10.1631/fitee.1400040},
  file      = {:ParviziMosaed2014 - Towards a Self Adaptive Service Oriented Methodology Based on Extended SOMA.pdf:PDF},
  publisher = {Zhejiang University Press},
  url       = {https://doi.org/10.1631%2Ffitee.1400040},
}

@InCollection{Apel2019,
  author    = {Sebastian Apel and Florian Hertrampf and Steffen Späthe},
  booktitle = {Innovations for Community Services},
  publisher = {Springer International Publishing},
  title     = {Towards a Metrics-Based Software Quality Rating for a Microservice Architecture},
  year      = {2019},
  pages     = {205--220},
  abstract  = {Microservice architectures should be based on isolated, independent and resilient services. In practice, however, that means that different concepts must be taken into account when designing, developing, and operating services. The WINNER research project is developing an application, based on such a microservice architecture in the context of Smart Home, Smart Grid and electromobility in tenant households, as a measurement and processing infrastructure. About this WINNER software, system metrics are calculated and collected, and the potential for rating software quality in the sense of ISO 25010 is examined. For analysis, a microservice architecture describing model will be designed witches describes correlations and links in the service network. Its instance in the context of WINNER, as well as source code and process analyses, are used to perform the final quality considerations.},
  doi       = {10.1007/978-3-030-22482-0_15},
  file      = {:Apel2019 - Towards a Metrics Based Software Quality Rating for a Microservice Architecture.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-030-22482-0_15},
}

@InCollection{Avritzer2018,
  author    = {Alberto Avritzer and Vincenzo Ferme and Andrea Janes and Barbara Russo and Henning Schulz and Andr{\'{e}} van Hoorn},
  booktitle = {Software Architecture},
  publisher = {Springer International Publishing},
  title     = {A Quantitative Approach for the Assessment of Microservice Architecture Deployment Alternatives by Automated Performance Testing},
  year      = {2018},
  pages     = {159--174},
  abstract  = {Microservices have emerged as an architectural style for developing distributed applications. Assessing the performance of architectural deployment alternatives is challenging and must be aligned with the system usage in the production environment. In this paper, we introduce an approach for using operational profiles to generate load tests to automatically assess scalability pass/fail criteria of several microservices deployment alternatives. We have evaluated our approach with different architecture deployment alternatives using extensive lab studies in a large bare metal host environment and a virtualized environment. The data presented in this paper supports the need to carefully evaluate the impact of increasing the level of computing resources on performance. Specifically, for the case study presented in this paper, we observed that the evaluated performance metric is a non-increasing function of the number of CPU resources for one of the environments under study.},
  doi       = {10.1007/978-3-030-00761-4_11},
  file      = {:Avritzer2018 - A Quantitative Approach for the Assessment of Microservice Architecture Deployment Alternatives by Automated Performance Testing.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-030-00761-4_11},
}

@InCollection{Athanasopoulos2021,
  author    = {Dionysis Athanasopoulos and Daniel Keenan},
  booktitle = {Lecture Notes in Computer Science},
  publisher = {Springer International Publishing},
  title     = {Stability Metrics for Continuous Integration of Service-Oriented Systems},
  year      = {2021},
  pages     = {139--147},
  abstract  = {One of the key principles of the service orientation is the standardised service contract. However, the assumption that the service contract is kept unmodified during the whole life-cycle of a system is not always held. Evolution changes on the service APIs have an impact on the maintainability of their programming clients within the system making difficult the continuous integration of the services. The metrics that have currently been applied for the service maintainability assess the service coupling, cohesion, complexity, and granularity. Software stability can further contribute in assessing the maintainability of systems. However, it is challenging to measure the stability of service APIs without having evolved their programming clients, because it should be measured by considering the types of the evolution changes in APIs that have direct impact on the programming clients. To address this challenge, we define a set of mappings between evolved service APIs based on which the stability changes can be determined. We further specify a generic algorithm that recognises the evolution changes required on the programming clients of the evolved APIs. We finally define an initial version of a suite of metrics that estimate the stability of a service system without assuming the existence of the evolved programming clients.},
  doi       = {10.1007/978-3-030-74296-6_11},
  file      = {:Athanasopoulos2021 - Stability Metrics for Continuous Integration of Service Oriented Systems.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-030-74296-6_11},
}

@Article{Mohsin2018,
  author    = {Ahmad Mohsin and Naeem Khalid Janjua},
  journal   = {Service Oriented Computing and Applications},
  title     = {A review and future directions of {SOA}-based software architecture modeling approaches for System of Systems},
  year      = {2018},
  month     = {oct},
  number    = {3-4},
  pages     = {183--200},
  volume    = {12},
  abstract  = {Software architecture is a software system’s earliest set of design decisions that are critical for the quality of the system desired by the stakeholders. The architecture makes it easier to reason about and manage change during different phases of complex software life cycle. The modeling of software architecture for System of Systems (SoS) is a challenging task because of a system’s complexity arising from an integration of heterogeneous, distributed, managerially and operationally independent systems collaborating to achieve global missions. SoS is essentially dynamic and evolutionary by design requiring suitable architectural patterns to deal with runtime volatility. Service-oriented architecture offers several architectural features to these complex systems; these include, interoperability, loose coupling, abstraction and the provision of dynamic services based on standard interfaces and protocols. There is some research work available that provides critical analysis of current software architecture modeling approaches for SoS. However, none of them outlines the important characteristics of SoS or provides detailed analysis of current service-oriented architecture modeling approaches to model those characteristics. This article addresses this research gap and provides a taxonomy of software architecture modeling approaches, comparing and contrasting them using criteria critical for realization of SoS. Additionally, research gaps are identified, and future directions are outlined for building software architecture for SoS to model and reason about architecture quality in a more efficient way in service-oriented paradigm.},
  doi       = {10.1007/s11761-018-0245-1},
  file      = {:Mohsin2018 - A Review and Future Directions of SOA Based Software Architecture Modeling Approaches for System of Systems.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
  url       = {https://doi.org/10.1007%2Fs11761-018-0245-1},
}

@InCollection{Ntentos2020a,
  author    = {Evangelos Ntentos and Uwe Zdun and Konstantinos Plakidas and Sebastian Meixner and Sebastian Geiger},
  booktitle = {Software Architecture},
  publisher = {Springer International Publishing},
  title     = {Assessing Architecture Conformance to Coupling-Related Patterns and Practices in Microservices},
  year      = {2020},
  pages     = {3--20},
  abstract  = {Microservices are the go-to architectural style for building applications that are polyglot, support high scalability, independent development and deployment, and are rapidly adaptable to changes. Among the core tenets for a successful microservice architecture is high independence of the individual microservices, i.e. loose coupling. A number of patterns and best practices are well-established in the literature, but most actual microservice-based systems do not, as a whole or in part, conform to them. Assessing this conformance manually is not realistically possible for large-scale systems. This study aims to provide the foundations for an automated approach for assessing conformance to coupling-related patterns and practices specific for microservice architectures. We propose a model-based assessment based on generic, technology-independent metrics, connected to typical design decisions encountered in microservice architectures. We demonstrate and assess the validity and appropriateness of these metrics by performing an assessment of the conformance of real-world systems to patterns through statistical methods.},
  doi       = {10.1007/978-3-030-58923-3_1},
  url       = {https://doi.org/10.1007%2F978-3-030-58923-3_1},
}

@InCollection{Salgado2016,
  author    = {Carlos E. Salgado and Ricardo J. Machado and Rita S. P. Maciel},
  booktitle = {Lecture Notes in Business Information Processing},
  publisher = {Springer International Publishing},
  title     = {A Three-Dimensional Approach for a Quality-Based Alignment Between Requirements and Architecture},
  year      = {2016},
  pages     = {112--125},
  abstract  = {The relation between requirements and architecture is a crucial part of an information system, standing as one of the main challenges for its successful development, with traditional projects focused on the connection of functional requirements with architecture components having a tendency to ignore quality concerns. As the quality attributes of a system support its architecture high level structure and behavior, also being highly related to its early nonfunctional requirements, there is a pressing need to align these two realities. Following our solution for aligning business requirements with services quality characteristics by derivation of a logical architecture, we now propose the specification of a metamodel and method supporting a three-dimensional approach for handling the alignment of quality issues between requirements and architecture. Taking advantage of a cube structure and method definition within a SPEM approach, which is adaptable to model variations, our proposal contributes to an improved aligned and traceable solution.},
  doi       = {10.1007/978-3-319-32689-4_9},
  file      = {:Salgado2016 - A Three Dimensional Approach for a Quality Based Alignment between Requirements and Architecture.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-319-32689-4_9},
}

@InCollection{Bogner2020,
  author    = {Justus Bogner and Stefan Wagner and Alfred Zimmermann},
  booktitle = {Communications in Computer and Information Science},
  publisher = {Springer International Publishing},
  title     = {Collecting Service-Based Maintainability Metrics from {RESTful} {API} Descriptions: Static Analysis and Threshold Derivation},
  year      = {2020},
  pages     = {215--227},
  abstract  = {While many maintainability metrics have been explicitly designed for service-based systems, tool-supported approaches to automatically collect these metrics are lacking. Especially in the context of microservices, decentralization and technological heterogeneity may pose challenges for static analysis. We therefore propose the modular and extensible RAMA approach (RESTful API Metric Analyzer) to calculate such metrics from machine-readable interface descriptions of RESTful services. We also provide prototypical tool support, the RAMA CLI, which currently parses the formats OpenAPI, RAML, and WADL and calculates 10 structural service-based metrics proposed in scientific literature. To make RAMA measurement results more actionable, we additionally designed a repeatable benchmark for quartile-based threshold ranges (green, yellow, orange, red). In an exemplary run, we derived thresholds for all RAMA CLI metrics from the interface descriptions of 1,737 publicly available RESTful APIs. Researchers and practitioners can use RAMA to evaluate the maintainability of RESTful services or to support the empirical evaluation of new service interface metrics.},
  doi       = {10.1007/978-3-030-59155-7_16},
  file      = {:Bogner2020 - Collecting Service Based Maintainability Metrics from RESTful API Descriptions_ Static Analysis and Threshold Derivation.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-030-59155-7_16},
}

@InCollection{Wu2018a,
  author    = {Wensheng Wu and Yuanfang Cai and Rick Kazman and Ran Mo and Zhipeng Liu and Rongbiao Chen and Yingan Ge and Weicai Liu and Junhui Zhang},
  booktitle = {Software Architecture},
  publisher = {Springer International Publishing},
  title     = {Software Architecture Measurement{\textemdash}Experiences from a Multinational Company},
  year      = {2018},
  pages     = {303--319},
  abstract  = {In this paper, we present our 4-year experience of creating, evolving, and validating an automated software architecture measurement system within Huawei. This system is centered around a comprehensive scale called the Standard Architecture Index (SAI), which is composed of a number of measures, each reflecting a recurring architecture problem. Development teams use this as a guide to figure out how to achieve a better score by addressing the underlying problems. The measurement practice thus motivates desired behaviors and outcomes. In this paper, we present our experience of creating and validating SAI 1.0 and 2.0, which has been adopted as the enterprise-wide standard, and our directions towards SAI 3.0. We will describe how we got the development teams to accept and apply SAI through pilot studies, constantly adjusting the formula based on feedback, and correlating SAI scores with productivity measures. Our experience shows that it is critical to guide development teams to focus on the underlying problems behind each measure within SAI, rather than on the score itself. It is also critical to introduce state-of-the-art technologies to the development teams. In doing so they can leverage these technologies to pinpoint and quantify architecture problems so that better SAI scores can be achieved, along with better quality and productivity.},
  doi       = {10.1007/978-3-030-00761-4_20},
  file      = {:Wu2018a - Software Architecture Measurement_Experiences from a Multinational Company.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-030-00761-4_20},
}

@InCollection{BaniIsmail2018,
  author    = {Basel Bani-Ismail and Youcef Baghdadi},
  booktitle = {Communications in Computer and Information Science},
  publisher = {Springer International Publishing},
  title     = {A Survey of Existing Evaluation Frameworks for Service Identification Methods: Towards a Comprehensive Evaluation Framework},
  year      = {2018},
  pages     = {191--202},
  abstract  = {Service identification is one of the main challenges in developing services for Service-Oriented Architecture (SOA). A large number of Service Identification Methods (SIMs) have been proposed to simplify service identification. Therefore, many evaluation frameworks are available in the literature for comparing the existing SIMs. This paper aims to identify and analyze the existing evaluation frameworks for SIMs. Moreover, it aims to propose comprehensive evaluation criteria that address most aspects of the existing SIMs. A review of 23 evaluation frameworks for SIMs built the foundation for deriving a comprehensive set of 16 criteria, namely SOA lifecycle coverage, approach, input artifact, technique, types of services, service description, service quality attributes, service granularity, comprehensive, systematic, availability, tool support, adoption of existing practices, validation, configurability, and domain. The proposed criteria set can be used as a first step towards a comprehensive evaluation framework for SIMs.},
  doi       = {10.1007/978-3-319-95204-8_17},
  file      = {:BaniIsmail2018 - A Survey of Existing Evaluation Frameworks for Service Identification Methods_ Towards a Comprehensive Evaluation Framework.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-319-95204-8_17},
}

@InCollection{Ntentos2019,
  author    = {Evangelos Ntentos and Uwe Zdun and Konstantinos Plakidas and Daniel Schall and Fei Li and Sebastian Meixner},
  booktitle = {Software Architecture},
  publisher = {Springer International Publishing},
  title     = {Supporting Architectural Decision Making on Data Management in Microservice Architectures},
  year      = {2019},
  pages     = {20--36},
  abstract  = {Today many service-based systems follow the microservice architecture style. As microservices are used to build distributed systems and promote architecture properties such as independent service development, polyglot technology stacks including polyglot persistence, and loosely coupled dependencies, architecting data management is crucial in most microservice architectures. Many patterns and practices for microservice data management architectures have been proposed, but are today mainly informally discussed in the so-called “grey literature”: practitioner blogs, experience reports, and system documentations. As a result, the architectural knowledge is scattered across many knowledge sources that are usually based on personal experiences, inconsistent, and, when studied on their own, incomplete. In this paper we report on a qualitative, in-depth study of 35 practitioner descriptions of best practices and patterns on microservice data management architectures. Following a model-based qualitative research method, we derived a formal architecture decision model containing 325 elements and relations. Comparing the completeness of our model with an existing pattern catalog, we conclude that our architectural decision model substantially reduces the effort needed to sufficiently understand microservice data management decisions, as well as the uncertainty in the design process.},
  doi       = {10.1007/978-3-030-29983-5_2},
  file      = {:Ntentos2019 - Supporting Architectural Decision Making on Data Management in Microservice Architectures.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-030-29983-5_2},
}

@InCollection{Zdun2017,
  author    = {Uwe Zdun and Elena Navarro and Frank Leymann},
  booktitle = {Service-Oriented Computing},
  publisher = {Springer International Publishing},
  title     = {Ensuring and Assessing Architecture Conformance to Microservice Decomposition Patterns},
  year      = {2017},
  pages     = {411--429},
  abstract  = {Microservice-based software architecture design has been widely discussed, and best practices have been published as architecture design patterns. However, conformance to those patterns is hard to ensure and assess automatically, leading to problems such as architectural drift and erosion, especially in the context of continued software evolution or large-scale microservice systems. In addition, not much in the component and connector architecture models is specific (only) to the microservices approach, whereas other aspects really specific to that approach, such as independent deployment of microservices, are usually modeled in other views or not at all. We suggest a set of constraints to check and metrics to assess architecture conformance to microservice patterns. In comparison to expert judgment derived from the patterns, a subset of these constraints and metrics shows a good relative performance and potential for automation.},
  doi       = {10.1007/978-3-319-69035-3_29},
  file      = {:Zdun2017 - Ensuring and Assessing Architecture Conformance to Microservice Decomposition Patterns.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-319-69035-3_29},
}

@Article{Detten2013,
  author    = {Markus von Detten and Marie Christin Platenius and Steffen Becker},
  journal   = {Software {\&} Systems Modeling},
  title     = {Reengineering component-based software systems with Archimetrix},
  year      = {2013},
  month     = {apr},
  number    = {4},
  pages     = {1239--1268},
  volume    = {13},
  abstract  = {Many software development, planning, or analysis tasks require an up-to-date software architecture documentation. However, this documentation is often outdated, unavailable, or at least not available as a formal model which analysis tools could use. Reverse engineering methods try to fill this gap. However, as they process the system’s source code, they are easily misled by design deficiencies (e.g., violations of component encapsulation) which leaked into the code during the system’s evolution. Despite the high impact of design deficiencies on the quality of the resulting software architecture models, none of the surveyed related works is able to cope with them during the reverse engineering process. Therefore, we have developed the Archimetrix approach which semiautomatically recovers the system’s concrete architecture in a formal model while simultaneously detecting and removing design deficiencies. We have validated Archimetrix on a case study system and two implementation variants of the CoCoME benchmark system. Results show that the removal of relevant design deficiencies leads to an architecture model which more closely matches the system’s conceptual architecture.},
  doi       = {10.1007/s10270-013-0341-9},
  file      = {:Detten2013 - Reengineering Component Based Software Systems with Archimetrix.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
  url       = {https://doi.org/10.1007%2Fs10270-013-0341-9},
}

@InCollection{Tsoumas2020,
  author    = {Ilias Tsoumas and Chrysostomos Symvoulidis and Dimosthenis Kyriazis and Panagiotis Gouvas and Anastasios Zafeiropoulos and Javier Melian and Janez Sterle},
  booktitle = {Information Systems},
  publisher = {Springer International Publishing},
  title     = {Modelling 5G Cloud-Native Applications by Exploiting the Service Mesh Paradigm},
  year      = {2020},
  pages     = {151--162},
  abstract  = {The new-coming 5G network is considered to be one of the most significant innovations today. This is due to the opportunities that is going to provide to the vertical industries. 5G infrastructures will introduce a new way for low-delay, reliable deployment of services. In fact, such infrastructures can be used for the placement of application services in the form of application graphs. An application graph consists of several application components (i.e. micro-services) that may be hosted in the same infrastructure or in different ones. Conflicting requirements that arise when deploying in such infrastructures are now handled through network slicing, which regards a way for partitioning conventional network and computing resources into virtual elements. In this paper, we define a universal application metamodel of a 5G compatible application in order to guarantee the annotation of each application descriptor with its proper requirements for their fulfillment at the instantiation time. In terms of application architecture, we consider each application graph as a service mesh topology in order to adopt this novel service architecture as a dominant methodology that is well fitting in the promising 5G capabilities},
  doi       = {10.1007/978-3-030-44322-1_12},
  file      = {:Tsoumas2020 - Modelling 5G Cloud Native Applications by Exploiting the Service Mesh Paradigm.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-030-44322-1_12},
}

@InCollection{Kratzke2017,
  author    = {Nane Kratzke and Peter-Christian Quint},
  booktitle = {Communications in Computer and Information Science},
  publisher = {Springer International Publishing},
  title     = {Investigation of Impacts on Network Performance in the Advance of a Microservice Design},
  year      = {2017},
  pages     = {187--208},
  abstract  = {Due to REST-based protocols, microservice architectures are inherently horizontally scalable. That might be why the microservice architectural style is getting more and more attention for cloud-native application engineering. Corresponding microservice architectures often rely on a complex technology stack which includes containers, elastic platforms and software defined networks. Astonishingly, there are almost no specialized tools to figure out performance impacts (coming along with this microservice architectural style) in the upfront of a microservice design. Therefore, we propose a benchmarking solution intentionally designed for this upfront design phase. Furthermore, we evaluate our benchmark and present some performance data to reflect some often heard cloud-native application performance rules (or myths).},
  doi       = {10.1007/978-3-319-62594-2_10},
  file      = {:Kratzke2017 - Investigation of Impacts on Network Performance in the Advance of a Microservice Design.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-319-62594-2_10},
}

@InCollection{Rosati2019,
  author    = {Pierangelo Rosati and Frank Fowley and Claus Pahl and Davide Taibi and Theo Lynn},
  booktitle = {Communications in Computer and Information Science},
  publisher = {Springer International Publishing},
  title     = {Right Scaling for Right Pricing: A Case Study on Total Cost of Ownership Measurement for Cloud Migration},
  year      = {2019},
  pages     = {190--214},
  abstract  = {Cloud computing promises traditional enterprises and independent software vendors a myriad of advantages over on-premise installations including cost, operational and organizational efficiencies. The decision to migrate software configured for on-premise delivery to the cloud requires careful technical consideration and planning. In this chapter, we discuss the impact of right-scaling on the cost modelling for migration decision making and price setting of software for commercial resale. An integrated process is presented for measuring total cost of ownership, taking in to account IaaS/PaaS resource consumption based on forecast SaaS usage levels. The process is illustrated with a real world case study.},
  doi       = {10.1007/978-3-030-29193-8_10},
  file      = {:Rosati2019 - Right Scaling for Right Pricing_ a Case Study on Total Cost of Ownership Measurement for Cloud Migration.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-030-29193-8_10},
}

@InCollection{Banijamali2020,
  author    = {Ahmad Banijamali and Pasi Kuvaja and Markku Oivo and Pooyan Jamshidi},
  booktitle = {Product-Focused Software Process Improvement},
  publisher = {Springer International Publishing},
  title     = {Kuksa{\textdollar}{\textdollar}{\^{}}$\lbrace${\ast}$\rbrace${\textdollar}{\textdollar}: Self-adaptive Microservices in Automotive Systems},
  year      = {2020},
  pages     = {367--384},
  abstract  = {In pervasive dynamic environments, vehicles connect to other objects to send operational data and receive updates so that vehicular applications can provide services to users on demand. Automotive systems should be self-adaptive, thereby they can make real-time decisions based on changing operating conditions. Emerging modern solutions, such as microservices could improve self-adaptation capabilities and ensure higher levels of quality performance in many domains. We employed a real-world automotive platform called Eclipse Kuksa to propose a framework based on microservices architecture to enhance the self-adaptation capabilities of automotive systems for runtime data analysis. To evaluate the designed solution, we conducted an experiment in an automotive laboratory setting where our solution was implemented as a microservice-based adaptation engine and integrated with other Eclipse Kuksa components. The results of our study indicate the importance of design trade-offs for quality requirements’ satisfaction levels of each microservices and the whole system for the optimal performance of an adaptive system at runtime.},
  doi       = {10.1007/978-3-030-64148-1_23},
  file      = {:Banijamali2020 - Kuksa__$$_$$___ Self Adaptive Microservices in Automotive Systems.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-030-64148-1_23},
}

@InCollection{Fowley2018,
  author    = {Frank Fowley and Claus Pahl},
  booktitle = {Communications in Computer and Information Science},
  publisher = {Springer International Publishing},
  title     = {Cloud Migration Architecture and Pricing {\textendash} Mapping a Licensing Business Model for Software Vendors to a {SaaS} Business Model},
  year      = {2018},
  pages     = {91--103},
  abstract  = {Cloud migration is about moving an on-premise software system into the cloud. Many approaches exist that describe the technical migration analysis and the architectural migration. Equally, cloud cost models have been investigated. What we aim to investigate here is to link architecture and software utilisation to costing and business models. We specifically look at software vendors that use the cloud to provide their solutions to customers. They might face the challenges to migrate an in-house developed and provided product onto a cloud IaaS or PaaS platform, while also mapping a licensing model onto a cloud monetisation model. We provide here an experience report. This is based on experience with five migration case studies. We discuss the migration process under consideration of cost aspects, covering both income and expenses in the cloud in relation to the cloud delivery model chosen. We focus on one of the case studies to illustrate the concepts and observations.},
  doi       = {10.1007/978-3-319-72125-5_7},
  file      = {:Fowley2018 - Cloud Migration Architecture and Pricing _ Mapping a Licensing Business Model for Software Vendors to a SaaS Business Model.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-319-72125-5_7},
}

@InCollection{Shabelnyk2021,
  author    = {Oleksandr Shabelnyk and Pantelis A. Frangoudis and Schahram Dustdar and Christos Tsigkanos},
  booktitle = {Software Architecture},
  publisher = {Springer International Publishing},
  title     = {Updating Service-Based Software Systems in Air-Gapped Environments},
  year      = {2021},
  pages     = {147--163},
  abstract  = {Contemporary component-based systems often manifest themselves as service-based architectures, where a central activity is management of their software updates. However, stringent security constraints in mission-critical settings often impose compulsory network isolation among systems, also known as air-gap; a prevalent choice in different sectors including private, public or governmental organizations. This raises several issues involving updates, stemming from the fact that controlling the update procedure of a distributed service-based system centrally and remotely is precluded by network isolation policies. A dedicated software architecture is thus required, where key themes are dependability of the update process, interoperability with respect to the software supported and auditability regarding update actions previously performed. We adopt an architectural viewpoint and present a technical framework for updating service-based systems in air-gapped environments. We describe the particularities of the domain characterized by network isolation and provide suitable notations for service versions, whereupon satisfiability is leveraged for dependency resolution; those are situated within an overall architectural design. Finally, we evaluate the proposed framework over a realistic case study of an international organization, and assess the performance of the dependency resolution procedures for practical problem sizes.},
  doi       = {10.1007/978-3-030-86044-8_10},
  file      = {:Shabelnyk2021 - Updating Service Based Software Systems in Air Gapped Environments.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-030-86044-8_10},
}

@InCollection{Floerecke2018,
  author    = {Sebastian Floerecke},
  booktitle = {Exploring Service Science},
  publisher = {Springer International Publishing},
  title     = {Success Factors of {SaaS} Providers' Business Models {\textendash} An Exploratory Multiple-Case Study},
  year      = {2018},
  pages     = {193--207},
  abstract  = {Market studies have revealed major differences in the level of performance among providers of Software as a Service (SaaS). The literature’s understanding of the underlying success factors and thus, the reasons for this performance discrepancy is, however, still limited. The goal of this research paper is therefore to investigate the success factors of SaaS providers’ business models by conducting an exploratory multiple-case study. 21 expert interviews with representatives from 17 cloud providers serve as central method of data collection. The study’s result is a catalogue of 27 success factors. In particular, a SaaS service should be developed as a system comprising modular microservices in order to meet the desired requirements in terms of cost advantages, performance and scalability. Overall, established SaaS providers obtain a reference framework to compare, rethink and innovate their present business models. Companies that are planning to offer SaaS in future gain valuable insights which should directly feed into their business model design process.},
  doi       = {10.1007/978-3-030-00713-3_15},
  file      = {:Floerecke2018 - Success Factors of SaaS Providers' Business Models _ an Exploratory Multiple Case Study.pdf:PDF},
  url       = {https://doi.org/10.1007%2F978-3-030-00713-3_15},
}

@InProceedings{Bogner2017,
  author    = {Bogner, Justus and Wagner, Stefan and Zimmermann, Alfred},
  booktitle = {Proceedings of the 27th International Workshop on Software Measurement and 12th International Conference on Software Process and Product Measurement},
  title     = {Automatically Measuring the Maintainability of Service- and Microservice-Based Systems: A Literature Review},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {107–115},
  publisher = {Association for Computing Machinery},
  series    = {IWSM Mensura '17},
  abstract  = {In a time of digital transformation, the ability to quickly and efficiently adapt
software systems to changed business requirements becomes more important than ever.
Measuring the maintainability of software is therefore crucial for the long-term management
of such products. With Service-based Systems (SBSs) being a very important form of
enterprise software, we present a holistic overview of such metrics specifically designed
for this type of system, since traditional metrics - e.g. object-oriented ones - are
not fully applicable in this case. The selected metric candidates from the literature
review were mapped to 4 dominant design properties: size, complexity, coupling, and
cohesion. Microservice-based Systems (μSBSs) emerge as an agile and fine-grained variant
of SBSs. While the majority of identified metrics are also applicable to this specialization
(with some limitations), the large number of services in combination with technological
heterogeneity and decentralization of control significantly impacts automatic metric
collection in such a system. Our research therefore suggest that specialized tool
support is required to guarantee the practical applicability of the presented metrics
to μSBSs.},
  doi       = {10.1145/3143434.3143443},
  file      = {:Bogner2017 - Automatically Measuring the Maintainability of Service and Microservice Based Systems_ a Literature Review.pdf:PDF},
  isbn      = {9781450348539},
  keywords  = {maintainability, metrics, service-based systems, SOA, microservices},
  location  = {Gothenburg, Sweden},
  numpages  = {9},
}

@InProceedings{Ntentos2020,
  author       = {Ntentos, Evangelos and Zdun, Uwe and Plakidas, Konstantinos and Meixner, Sebastian and Geiger, Sebastian},
  booktitle    = {International Conference on Service-Oriented Computing},
  title        = {Metrics for Assessing Architecture Conformance to Microservice Architecture Patterns and Practices},
  year         = {2020},
  organization = {Springer},
  pages        = {580--596},
  doi          = {10.1007/978-3-030-65310-1_42},
  file         = {:Ntentos2020 - Metrics for Assessing Architecture Conformance to Microservice Architecture Patterns and Practices.pdf:PDF},
  url          = {https://doi.org/10.1007/978-3-030-65310-1_42},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: fileDirectory-Robin-DESKTOP-CHQQ2MR:C:\\Users\\Robin\\work\\conferences\\2022_ESOCC\\private\\papers;}
