@inproceedings{10.1145/3444757.3485108,
author = {Morais, Gabriel and Bork, Dominik and Adda, Mehdi},
title = {Towards an Ontology-Driven Approach to Model and Analyze Microservices Architectures},
year = {2021},
isbn = {9781450383141},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3444757.3485108},
doi = {10.1145/3444757.3485108},
abstract = {Microservices Architectures (MSAs) are continuously replacing monolithic systems toward achieving more flexible and maintainable service-oriented software systems. However, the shift toward an MSA also requires a technological and managerial shift for its adopters. Architecting and managing MSAs represent unique challenges, including microservices' identification, interoperability, and reuse. To handle these challenges, we propose an Ontology-driven Conceptual Modelling approach, based on the Ontology of Microservices Architecture Concepts (OMSAC), for modelling and analyzing microservices-based systems. We show, how OMSAC-based conceptual models, stocked in a Stardog triple store, support Stakeholder-specific communication, documentation, and reuse. This paper reports on the application of our approach in three open-source MSA systems with a focus on microservices' discovery based on similarity metrics. Eventually, we compare the extracted similarity metrics derived from the application of machine learning techniques to the OMSAC models with a manual analysis performed by experts.},
booktitle = {Proceedings of the 13th International Conference on Management of Digital EcoSystems},
pages = {79–86},
numpages = {8},
keywords = {Microservices, Stardog, ontology, OMSAC, machine learning},
location = {Virtual Event, Tunisia},
series = {MEDES '21}
}
@inproceedings{10.1145/3493649.3493656,
author = {Allen, Sadie and Toslali, Mert and Parthasarathy, Srinivasan and Oliveira, Fabio and Coskun, Ayse K.},
title = {Tritium: A Cross-Layer Analytics System for Enhancing Microservice Rollouts in the Cloud},
year = {2021},
isbn = {9781450391719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3493649.3493656},
doi = {10.1145/3493649.3493656},
abstract = {Microservice architectures are widely used in cloud-native applications as their modularity allows for independent development and deployment of components. With the many complex interactions occurring in between components, it is difficult to determine the effects of a particular microservice rollout. Site Reliability Engineers must be able to determine with confidence whether a new rollout is at fault for a concurrent or subsequent performance problem in the system so they can quickly mitigate the issue. We present Tritium, a cross-layer analytics system that synthesizes several types of data to suggest possible causes for Service Level Objective (SLO) violations in microservice applications. It uses event data to identify new version rollouts, tracing data to build a topology graph for the cluster and determine services potentially affected by the rollout, and causal impact analysis applied to metric time-series to determine if the rollout is at fault. Tritium works based on the principle that if a rollout is not responsible for a change in an upstream or neighboring SLO metric, then the rollout's telemetry data will do a poor job predicting the behavior of that SLO metric. In this paper, we experimentally demonstrate that Tritium can accurately attribute SLO violations to downstream rollouts and outline the steps necessary to fully realize Tritium.},
booktitle = {Proceedings of the Seventh International Workshop on Container Technologies and Container Clouds},
pages = {19–24},
numpages = {6},
keywords = {container systems, microservices, version rollouts, Fault diagnosis},
location = {Virtual Event, Canada},
series = {WoC '21}
}
@inproceedings{10.1145/3575693.3575710,
author = {Switzer, Jennifer and Marcano, Gabriel and Kastner, Ryan and Pannuto, Pat},
title = {Junkyard Computing: Repurposing Discarded Smartphones to Minimize Carbon},
year = {2023},
isbn = {9781450399166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3575693.3575710},
doi = {10.1145/3575693.3575710},
abstract = {1.5 billion smartphones are sold annually, and most are decommissioned less than two years later. Most of these unwanted smartphones are neither discarded nor recycled but languish in junk drawers and storage units. This computational stockpile represents a substantial wasted potential: modern smartphones have increasingly high-performance and energy-efficient processors, extensive networking capabilities, and a reliable built-in power supply. This project studies the ability to reuse smartphones as "junkyard computers." Junkyard computers grow global computing capacity by extending device lifetimes, which supplants the manufacture of new devices. We show that the capabilities of even decade-old smartphones are within those demanded by modern cloud microservices and discuss how to combine phones to perform increasingly complex tasks. We describe how current operation-focused metrics do not capture the actual carbon costs of compute. We propose Computational Carbon Intensity---a performance metric that balances the continued service of older devices with the superlinear runtime improvements of newer machines. We use this metric to redefine device service lifetime in terms of carbon efficiency. We develop a cloudlet of reused Pixel 3A phones. We analyze the carbon benefits of deploying large, end-to-end microservice-based applications on these smartphones. Finally, we describe system architectures and associated challenges to scale to cloudlets with hundreds and thousands of smartphones.},
booktitle = {Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
pages = {400–412},
numpages = {13},
keywords = {life cycle assessment, cloud computing, sustainability},
location = {Vancouver, BC, Canada},
series = {ASPLOS 2023}
}

@inproceedings{10.1145/3543507.3583338,
author = {Jiang, Xinrui and Pan, Yicheng and Ma, Meng and Wang, Ping},
title = {Look Deep into the Microservice System Anomaly through Very Sparse Logs},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583338},
doi = {10.1145/3543507.3583338},
abstract = {Intensive monitoring and anomaly diagnosis have become a knotty problem for modern microservice architecture due to the dynamics of service dependency. While most previous studies rely heavily on ample monitoring metrics, we raise a fundamental but always neglected issue - the diagnostic metric integrity problem. This paper solves the problem by proposing MicroCU – a novel approach to diagnose microservice systems using very sparse API logs. We design a structure named dynamic causal curves to portray time-varying service dependencies and a temporal dynamics discovery algorithm based on Granger causal intervals. Our algorithm generates a smoother space of causal curves and designs the concept of causal unimodalization to calibrate the causality infidelities brought by missing metrics. Finally, a path search algorithm on dynamic causality graphs is proposed to pinpoint the root cause. Experiments on commercial system cases show that MicroCU outperforms many state-of-the-art approaches and reflects the superiorities of causal unimodalization to raw metric imputation.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {2970–2978},
numpages = {9},
keywords = {Microservice architecture, Anomaly diagnosis, Root cause analysis, Dynamic Granger causality},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.5555/3581644.3581707,
author = {Kalinagac, Onur and Soussi, Wissem and G\"{u}r, G\"{u}rkan},
title = {Graph Based Liability Analysis for the Microservice Architecture},
year = {2023},
isbn = {9783903176515},
publisher = {International Federation for Information Processing},
address = {Laxenburg, AUT},
abstract = {In this work, we present Graph Based Liability Analysis Framework (GRALAF) for root cause analysis (RCA) of the microservices. In this Proof-of-Concept (PoC) tool, we keep track of the performance metrics of microservices, such as service response time and CPU level values, to detect anomalies. By injecting faults in the services, we construct a Causal Bayesian Network (CBN) which represents the relation between service faults and metrics. The constructed CBN is used to predict the fault probability of services under given metrics which are assigned discrete values according to their anomaly states.},
booktitle = {Proceedings of the 18th International Conference on Network and Service Management},
articleno = {51},
numpages = {3},
keywords = {causal bayesian network, microservices, root cause analysis},
location = {Thessaloniki, Greece},
series = {CNSM '22}
}

@inproceedings{10.1145/3578245.3585030,
author = {Belkhiri, Adel and Shahnejat Bushehri, Ahmad and Gohring de Magalhaes, Felipe and Nicolescu, Gabriela},
title = {Transparent Trace Annotation for Performance Debugging in Microservice-Oriented Systems (Work In Progress Paper)},
year = {2023},
isbn = {9798400700729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578245.3585030},
doi = {10.1145/3578245.3585030},
abstract = {Microservices is a cloud-native architecture in which a single application is implemented as a collection of small, independent, and loosely-coupled services. This architecture is gaining popularity in the industry as it promises to make applications more scalable and easier to develop and deploy. Nonetheless, adopting this architecture in practice has raised many concerns, particularly regarding the difficulty of diagnosing performance bugs and explaining abnormal software behaviour. Fortunately, many tools based on distributed tracing were proposed to achieve observability in microservice-oriented systems and address these concerns (e.g., Jaeger). Distributed tracing is a method for tracking user requests as they flow between services. While these tools can identify slow services and detect latency-related problems, they mostly fail to pinpoint the root causes of these issues.This paper presents a new approach for enacting cross-layer tracing of microservice-based applications. It also proposes a framework for annotating traces generated by most distributed tracing tools with relevant tracing data and metrics collected from the kernel. The information added to the traces aims at helping the practitioner get a clear insight into the operations of the application executing user requests. The framework we present is notably efficient in diagnosing the causes of long tail latencies. Unlike other solutions, our approach for annotating traces is completely transparent as it does not require the modification of the application, the tracer, or the operating system. Furthermore, our evaluation shows that this approach incurs low overhead costs.},
booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {25–32},
numpages = {8},
keywords = {microservices, performance analysis, distributed systems, software tracing},
location = {Coimbra, Portugal},
series = {ICPE '23 Companion}
}

@inproceedings{10.1145/3542929.3563477,
author = {Luo, Shutian and Xu, Huanle and Ye, Kejiang and Xu, Guoyao and Zhang, Liping and Yang, Guodong and Xu, Chengzhong},
title = {The Power of Prediction: Microservice Auto Scaling via Workload Learning},
year = {2022},
isbn = {9781450394147},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3542929.3563477},
doi = {10.1145/3542929.3563477},
abstract = {When deploying microservices in production clusters, it is critical to automatically scale containers to improve cluster utilization and ensure service level agreements (SLA). Although reactive scaling approaches work well for monolithic architectures, they are not necessarily suitable for microservice frameworks due to the long delay caused by complex microservice call chains. In contrast, existing proactive approaches leverage end-to-end performance prediction for scaling, but cannot effectively handle microservice multiplexing and dynamic microservice dependencies.In this paper, we present Madu, a proactive microservice auto-scaler that scales containers based on predictions for individual microservices. Madu learns workload uncertainty to handle the highly dynamic dependency between microservices. Additionally, Madu adopts OS-level metrics to optimize resource usage while maintaining good control over scaling overhead. Experiments on large-scale deployments of microservices in Alibaba clusters show that the overall prediction accuracy of Madu can reach as high as 92.3% on average, which is 13% higher than the state-of-the-art approaches. Furthermore, experiments running real-world microservice benchmarks in a local cluster of 20 servers show that Madu can reduce the overall resource usage by 1.7X compared to reactive solutions, while reducing end-to-end service latency by 50%.},
booktitle = {Proceedings of the 13th Symposium on Cloud Computing},
pages = {355–369},
numpages = {15},
keywords = {microservices, workload uncertainty learning, proactive auto-scaler},
location = {San Francisco, California},
series = {SoCC '22}
}

@inproceedings{10.1145/3559712.3559716,
author = {Moreira, Mateus Gabi and De Fran\c{c}a, Breno Bernard Nicolau},
title = {Analysis of Microservice Evolution Using Cohesion Metrics},
year = {2022},
isbn = {9781450397452},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3559712.3559716},
doi = {10.1145/3559712.3559716},
abstract = {The adoption of Microservices Architecture (MSA) has increased in recent years due to several claimed benefits, such as reducing deployment complexity, supporting technology diversity, and better scalability. However, MSA is not free from maintainability issues, especially the lack of cohesion, in which microservices possibly concentrate or miss responsibilities. Also, the lack of empirically-validated cohesion metrics for MSA makes the quantitative assessment even more challenging. In this paper, we empirically explore the practical applicability of service-level cohesion metrics in an open-source MSA application context. The qualitative results show the possibility of assessing MSA cohesion using these service-level metrics, the feasibility of tracking software evolution, and an indication of possible technical debts along the way.},
booktitle = {Proceedings of the 16th Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {40–49},
numpages = {10},
keywords = {Cohesion Metrics, Software evolution, Microservices, Software architecture},
location = {Uberlandia, Brazil},
series = {SBCARS '22}
}

@inproceedings{10.1145/3524481.3527233,
author = {Camilli, Matteo and Guerriero, Antonio and Janes, Andrea and Russo, Barbara and Russo, Stefano},
title = {Microservices Integrated Performance and Reliability Testing},
year = {2022},
isbn = {9781450392860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524481.3527233},
doi = {10.1145/3524481.3527233},
abstract = {Continuous quality assurance for extra-functional properties of modern software systems is today a big challenge as their complexity is constantly increasing to satisfy market demands. This is the case of microservice systems. They provide high control on the scale of operation by means of fine-grained service decomposition, but this demands careful consideration of the relations between performance of individual microservices and service failures.In this work, we propose MIPaRT, a novel methodology, and platform to automatically test microservice operations for performance and reliability in combination. The proposed platform can be integrated into a DevOps cycle to support continuous testing and monitoring by the automatic (1) generation and execution of performance-reliability ex-vivo testing sessions, (2) collection of monitoring data, (3) computation of performance and reliability metrics, and (4) integrated visualization of the results.We apply our approach by operating the platform on an open source benchmark. Results show that our integrated approach can provide additional insights into the performance and reliability behaviour of microservices as well as their mutual relationships.},
booktitle = {Proceedings of the 3rd ACM/IEEE International Conference on Automation of Software Test},
pages = {29–39},
numpages = {11},
keywords = {performance testing, reliability testing, microservices systems},
location = {Pittsburgh, Pennsylvania},
series = {AST '22}
}

@inproceedings{10.1145/3569902.3569916,
author = {Castro, Jessica and Laranjeiro, Nuno and Vieira, Marco},
title = {Detecting DoS Attacks in Microservice Applications: Approach&nbsp;and Case Study},
year = {2023},
isbn = {9781450397377},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3569902.3569916},
doi = {10.1145/3569902.3569916},
abstract = {A microservices-based architecture decreases the complexity of developing new systems, making them highly scalable and manageable. However, its distributed nature, the high granularity of services, and the large attack surface increase the need to secure those systems at runtime. This paper investigates the challenges of detecting low- and high-volume DoS attacks against microservices using application-level metrics. We conducted an exploratory study to evaluate how different services influence attack detection, the use of Machine Learning (ML) techniques to detect DoS attacks, and the application-level metrics that can be used to detect DoS attacks. The results show that, analysing the services in parallel improves the detection rate, ML models are promising in detecting DoS attacks, and the numbers of sockets and threads used by containers are valuable metrics to indicate high-volume DoS attacks.},
booktitle = {Proceedings of the 11th Latin-American Symposium on Dependable Computing},
pages = {73–78},
numpages = {6},
keywords = {machine learning, microservices, security, attack detection, denial of service, container},
location = {Fortaleza/CE, Brazil},
series = {LADC '22}
}

@inproceedings{10.1145/3540250.3558951,
author = {Peng, Xin and Zhang, Chenxi and Zhao, Zhongyuan and Isami, Akasaka and Guo, Xiaofeng and Cui, Yunna},
title = {Trace Analysis Based Microservice Architecture Measurement},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3558951},
doi = {10.1145/3540250.3558951},
abstract = {Microservice architecture design highly relies on expert experience and may often result in improper service decomposition. Moreover, a microservice architecture is likely to degrade with the continuous evolution of services. Architecture measurement is thus important for the long-term evolution of microservice architectures. Due to the independent and dynamic nature of services, source code analysis based approaches cannot well capture the interactions between services. In this paper, we propose a trace analysis based microservice architecture measurement approach. We define a trace data model for microservice architecture measurement, which enables fine-grained analysis of the execution processes of requests and the interactions between interfaces and services. Based on the data model, we define 14 architectural metrics to measure the service independence and invocation chain complexity of a microservice system. We implement the approach and conduct three case studies with a student course project, an open-source microservice benchmark system, and three industrial microservice systems. The results show that our approach can well characterize the independence and invocation chain complexity of microservice architectures and help developers to identify microservice architecture issues caused by improper service decomposition and architecture degradation.},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1589–1599},
numpages = {11},
keywords = {Dynamic analysis, Architecture, Tracing, Microservice},
location = {Singapore, Singapore},
series = {ESEC/FSE 2022}
}

@inproceedings{10.1145/3575693.3575751,
author = {Liang, Mingyu and Gan, Yu and Li, Yueying and Torres, Carlos and Dhanotia, Abhishek and Ketkar, Mahesh and Delimitrou, Christina},
title = {Ditto: End-to-End Application Cloning for Networked Cloud Services},
year = {2023},
isbn = {9781450399166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3575693.3575751},
doi = {10.1145/3575693.3575751},
abstract = {The lack of representative, publicly-available cloud services has been a recurring problem in the architecture and systems communities. While open-source benchmarks exist, they do not capture the full complexity of cloud services. Application cloning is a promising way to address this, however, prior work is limited to CPU-/cache-centric, single-node services, operating at user level. We present Ditto, an automated framework for cloning end-to-end cloud applications, both monolithic and microservices, which captures I/O and network activity, as well as kernel operations, in addition to application logic. Ditto takes a hierarchical approach to application cloning, starting with capturing the dependency graph across distributed services, to recreating each tier's control/data flow, and finally generating system calls and assembly that mimics the individual applications. Ditto does not reveal the logic of the original application, facilitating publicly sharing clones of production services with hardware vendors, cloud providers, and the research community. We show that across a diverse set of single- and multi-tier applications, Ditto accurately captures their CPU and memory characteristics as well as their high-level performance metrics, is portable across platforms, and facilitates a wide range of system studies.},
booktitle = {Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
pages = {222–236},
numpages = {15},
keywords = {software reverse engineering, cloud computing, microservices, architecture, benchmarking and emulation},
location = {Vancouver, BC, Canada},
series = {ASPLOS 2023}
}

@inproceedings{10.1145/3489525.3511675,
author = {Li, Richard and Du, Min and Wang, Zheng and Chang, Hyunseok and Mukherjee, Sarit and Eide, Eric},
title = {LongTale: Toward Automatic Performance Anomaly Explanation in Microservices},
year = {2022},
isbn = {9781450391436},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3489525.3511675},
doi = {10.1145/3489525.3511675},
abstract = {Performance troubleshooting is notoriously difficult for distributed microservices-based applications. A typical root-cause diagnosis for performance anomaly by an analyst starts by narrowing down the scope of slow services, investigates into high-level performance metrics or available logs in the slow components, and finally drills down to an actual cause. This process can be long, tedious, and sometimes aimless due to the lack of domain knowledge and the sheer number of possible culprits. This paper introduces a new machine-learning-driven performance analysis system called LongTale that automates the troubleshooting process for latency-related performance anomalies to facilitate the root cause diagnosis and explanation. LongTale builds on existing application-layer tracing in two significant aspects. First, it stitches application-layer traces with corresponding system stack traces, which enables more informative root-cause analysis. Second, it utilizes a novel machine-learning-driven analysis that feeds on the combined data to automatically uncover the most likely contributing factor(s) for given performance slowdown. We demonstrate how LongTale can be utilized in different scenarios, including abnormal long-tail latency explanation and performance interference analysis.},
booktitle = {Proceedings of the 2022 ACM/SPEC on International Conference on Performance Engineering},
pages = {5–16},
numpages = {12},
keywords = {cross-layer tracing, tail latency, performance analysis},
location = {Beijing, China},
series = {ICPE '22}
}

@inproceedings{10.1145/3543507.3583274,
author = {Chakraborty, Sarthak and Garg, Shaddy and Agarwal, Shubham and Chauhan, Ayush and Saini, Shiv Kumar},
title = {CausIL: Causal Graph for Instance Level Microservice Data},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583274},
doi = {10.1145/3543507.3583274},
abstract = {AI-based monitoring has become crucial for cloud-based services due to its scale. A common approach to AI-based monitoring is to detect causal relationships among service components and build a causal graph. Availability of domain information makes cloud systems even better suited for such causal detection approaches. In modern cloud systems, however, auto-scalers dynamically change the number of microservice instances, and a load-balancer manages the load on each instance. This poses a challenge for off-the-shelf causal structure detection techniques as they neither incorporate the system architectural domain information nor provide a way to model distributed compute across varying numbers of service instances. To address this, we develop CausIL, which detects a causal structure among service metrics by considering compute distributed across dynamic instances and incorporating domain knowledge derived from system architecture. Towards the application in cloud systems, CausIL estimates a causal graph using instance-specific variations in performance metrics, modeling multiple instances of a service as independent, conditional on system assumptions. Simulation study shows the efficacy of CausIL over baselines by improving graph estimation accuracy by ∼ 25% as measured by Structural Hamming Distance whereas the real-world dataset demonstrates CausIL’s applicability in deployment settings.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {2905–2915},
numpages = {11},
keywords = {Causal Structure Detection, Causal Graph, Microservices, System Monitoring},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3540250.3549146,
author = {Zhang, Chenxi and Peng, Xin and Zhou, Tong and Sha, Chaofeng and Yan, Zhenghui and Chen, Yiru and Yang, Hong},
title = {TraceCRL: Contrastive Representation Learning for Microservice Trace Analysis},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3549146},
doi = {10.1145/3540250.3549146},
abstract = {Due to the large amount and high complexity of trace data, microservice trace analysis tasks such as anomaly detection, fault diagnosis, and tail-based sampling widely adopt machine learning technology. These trace analysis approaches usually use a preprocessing step to map structured features of traces to vector representations in an ad-hoc way. Therefore, they may lose important information such as topological dependencies between service operations. In this paper, we propose TraceCRL, a trace representation learning approach based on contrastive learning and graph neural network, which can incorporate graph structured information in the downstream trace analysis tasks. Given a trace, TraceCRL constructs an operation invocation graph where nodes represent service operations and edges represent operation invocations together with predefined features for invocation status and related metrics. Based on the operation invocation graphs of traces TraceCRL uses a contrastive learning method to train a graph neural network-based model for trace representation. In particular, TraceCRL employs six trace data augmentation strategies to alleviate the problems of class collision and uniformity of representation in contrastive learning. Our experimental studies show that TraceCRL can significantly improve the performance of trace anomaly detection and offline trace sampling. It also confirms the effectiveness of the trace augmentation strategies and the efficiency of TraceCRL.},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1221–1232},
numpages = {12},
keywords = {Contrastive Learning, Microservice, Graph Neural Network, Deep Learning, Tracing},
location = {Singapore, Singapore},
series = {ESEC/FSE 2022}
}

@inproceedings{10.1145/3531056.3542765,
author = {Peng, Xin},
title = {Large-Scale Trace Analysis for Microservice Anomaly Detection and Root Cause Localization},
year = {2022},
isbn = {9781450396639},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531056.3542765},
doi = {10.1145/3531056.3542765},
abstract = {Distributed tracing traces requests as they flow between services. It has been widely accepted and practiced in industry as an important means to achieve observability in microservice architecture for various purposes such as anomaly detection and root cause localization. However, trace analysis in an industrial microservice system is often challenging due to the huge number of traces produced by the system and the difficulties in combining traces with other types of operation data such as logs and metrics. In this talk, I will first analyze the background and describe the industrial practice of distributed tracing and trace analysis. Then I will introduce our explorations on large-scale trace analysis for microservice anomaly detection and root cause localization.},
booktitle = {Proceedings of the Federated Africa and Middle East Conference on Software Engineering},
pages = {93–94},
numpages = {2},
keywords = {Log, Root Cause Analysis, Observability, Metrics, Anomaly Detection, Microservice Architecture, Trace},
location = {Cairo-Kampala, Egypt},
series = {FAMECSE '22}
}

@inproceedings{10.1145/3578244.3583721,
author = {Straesser, Martin and Eismann, Simon and von Kistowski, J\'{o}akim and Bauer, Andr\'{e} and Kounev, Samuel},
title = {Autoscaler Evaluation and Configuration: A Practitioner's Guideline},
year = {2023},
isbn = {9798400700682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578244.3583721},
doi = {10.1145/3578244.3583721},
abstract = {Autoscalers are indispensable parts of modern cloud deployments and determine the service quality and cost of a cloud application in dynamic workloads. The configuration of an autoscaler strongly influences its performance and is also one of the biggest challenges and showstoppers for the practical applicability of many research autoscalers. Many proposed cloud experiment methodologies can only be partially applied in practice, and many autoscaling papers use custom evaluation methods and metrics. This paper presents a practical guideline for obtaining meaningful and interpretable results on autoscaler performance with reasonable overhead. We provide step-by-step instructions for defining realistic usage behaviors and traffic patterns. We divide the analysis of autoscaler performance into a qualitative antipattern-based analysis and a quantitative analysis. To demonstrate the applicability of our guideline, we conduct several experiments with a microservice of our industry partner in a realistic test environment.},
booktitle = {Proceedings of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {31–41},
numpages = {11},
keywords = {guideline, autoscaling, methodology, evaluation, antipatterns},
location = {Coimbra, Portugal},
series = {ICPE '23}
}

@inproceedings{10.1109/ASE51524.2021.9678708,
author = {Wang, Hanzhang and Wu, Zhengkai and Jiang, Huai and Huang, Yichao and Wang, Jiamu and Kopru, Selcuk and Xie, Tao},
title = {Groot: An Event-Graph-Based Approach for Root Cause Analysis in Industrial Settings},
year = {2022},
isbn = {9781665403375},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE51524.2021.9678708},
doi = {10.1109/ASE51524.2021.9678708},
abstract = {For large-scale distributed systems, it is crucial to efficiently diagnose the root causes of incidents to maintain high system availability. The recent development of microservice architecture brings three major challenges (i.e., complexities of operation, system scale, and monitoring) to root cause analysis (RCA) in industrial settings. To tackle these challenges, in this paper, we present Groot, an event-graph-based approach for RCA. Groot constructs a real-time causality graph based on events that summarize various types of metrics, logs, and activities in the system under analysis. Moreover, to incorporate domain knowledge from site reliability engineering (SRE) engineers, Groot can be customized with user-defined events and domain-specific rules. Currently, Groot supports RCA among 5,000 real production services and is actively used by the SRE teams in eBay, a global e-commerce system serving more than 159 million active buyers per year. Over 15 months, we collect a data set containing labeled root causes of 952 real production incidents for evaluation. The evaluation results show that Groot is able to achieve 95% top-3 accuracy and 78% top-1 accuracy. To share our experience in deploying and adopting RCA in industrial settings, we conduct a survey to show that users of Groot find it helpful and easy to use. We also share the lessons learned from deploying and adopting Groot to solve RCA problems in production environments.},
booktitle = {Proceedings of the 36th IEEE/ACM International Conference on Automated Software Engineering},
pages = {419–429},
numpages = {11},
keywords = {root cause analysis, microservices, AIOps, observability},
location = {Melbourne, Australia},
series = {ASE '21}
}

