@inproceedings{10.1145/3493700.3493731,
author = {Lodha, Ishaan and Kolur, Lakshana and Krishnan, Keerthan and Dheenadayalan, Kumar and Sitaram, Dinkar and Nandi, Siddhartha},
title = {Cost-Optimized Video Transfer Using Real-Time Super Resolution Convolutional Neural Networks},
year = {2022},
isbn = {9781450385824},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3493700.3493731},
doi = {10.1145/3493700.3493731},
abstract = {The explosion of video generation and consumption, coupled with an inadequate rise in network bandwidth has led to network delays and decreased Quality of Experience, limiting the opportunities to tap into the full potential of video data. These deficiencies in network resources with a shift to cloud computing models have resulted in the need to revisit the overall mechanism for video transfer and storage of videos between edge devices and the cloud. We propose a novel multi-scale real-time super-resolution convolutional neural network to achieve the composite task of optimizing the entire cost of video transfer with minimal loss of quality that can be used for any application involving the transfer of video data. To achieve this, we develop a cost-optimized video transfer system that optimizes the metrics of video transfer to give the best quality video output, given the user budget. The model makes use of Convolution blocks for extracting features and output creation with multiple sub-pixel convolutions in a novel structure. For upscaling to full High Definition video at 30 fps, the model successfully retained the frame rate while the system achieved savings in transfer time and bandwidth usage. This model has been trained on surveillance videos (VIRAT dataset), but consistent results were obtained during testing even on feature films and sports videos which demonstrates its content invariance. The evaluation of our approach averaged over 376 videos, yielded meager quality losses of 8%, measured by a novel non-referential quality metric, also proposed in this paper. Additionally, average network bandwidth savings of 80% and average video transfer time reduction of 52% were achieved.},
booktitle = {5th Joint International Conference on Data Science & Management of Data (9th ACM IKDD CODS and 27th COMAD)},
pages = {213–221},
numpages = {9},
keywords = {CNN, deep neural networks, video transfer, cost optimization, GAN, super resolution},
location = {Bangalore, India},
series = {CODS-COMAD 2022}
}

  
@inproceedings{10.1145/3578244.3583726,
author = {Straesser, Martin and Mathiasch, Jonas and Bauer, Andr\'{e} and Kounev, Samuel},
title = {A Systematic Approach for Benchmarking of Container Orchestration Frameworks},
year = {2023},
isbn = {9798400700682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578244.3583726},
doi = {10.1145/3578244.3583726},
abstract = {Container orchestration frameworks play a critical role in modern cloud computing paradigms such as cloud-native or serverless computing. They significantly impact the quality and cost of service deployment as they manage many performance-critical tasks such as container provisioning, scheduling, scaling, and networking. Consequently, a comprehensive performance assessment of container orchestration frameworks is essential. However, until now, there is no benchmarking approach that covers the many different tasks implemented in such platforms and supports evaluating different technology stacks. In this paper, we present a systematic approach that enables benchmarking of container orchestrators. Based on a definition of container orchestration, we define the core requirements and benchmarking scope for such platforms. Each requirement is then linked to metrics and measurement methods, and a benchmark architecture is proposed. With COFFEE, we introduce a benchmarking tool supporting the definition of complex test campaigns for container orchestration frameworks. We demonstrate the potential of our approach with case studies of the frameworks Kubernetes and Nomad in a self-hosted environment and on the Google Cloud Platform. The presented case studies focus on container startup times, crash recovery, rolling updates, and more.},
booktitle = {Proceedings of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {187–198},
numpages = {12},
keywords = {nomad, kubernetes, benchmarking, performance, container orchestration},
location = {Coimbra, Portugal},
series = {ICPE '23}
}

@inproceedings{10.1145/3578245.3584728,
author = {Klinaku, Floriment and Speth, Sandro and Zilch, Markus and Becker, Steffen},
title = {Hitchhiker's Guide for Explainability in Autoscaling},
year = {2023},
isbn = {9798400700729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578245.3584728},
doi = {10.1145/3578245.3584728},
abstract = {Cloud-native applications force increasingly powerful and complex autoscalers to guarantee the applications' quality of service. For software engineers with operational tasks understanding the autoscalers' behavior and applying appropriate reconfigurations is challenging due to their internal mechanisms, inherent distribution, and decentralized decision-making. Hence, engineers seek appropriate explanations. However, engineers' expectations on feedback and explanations of autoscalers are unclear. In this paper, through a workshop with a representative sample of engineers responsible for operating an autoscaler, we elicit requirements for explainability in autoscaling. Based on the requirements, we propose an evaluation scheme for evaluating explainability as a non-functional property of the autoscaling process and guide software engineers in choosing the best-fitting autoscaler for their scenario. The evaluation scheme is based on a Goal Question Metric approach and contains three goals, nine questions to assess explainability, and metrics to answer these questions. The evaluation scheme should help engineers choose a suitable and explainable autoscaler or guide them in building their own.},
booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {277–282},
numpages = {6},
keywords = {evaluation, elasticity, explainability, requirements, cloud},
location = {Coimbra, Portugal},
series = {ICPE '23 Companion}
}

@inproceedings{10.1145/3491204.3527490,
author = {Tuli, Shreshth and Casale, Giuliano},
title = {Optimizing the Performance of Fog Computing Environments Using AI and Co-Simulation},
year = {2022},
isbn = {9781450391597},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491204.3527490},
doi = {10.1145/3491204.3527490},
abstract = {This tutorial presents a performance engineering approach for optimizing the Quality of Service (QoS) of Edge/Fog/Cloud Computing environments using AI and Coupled-Simulation being developed as part of the Co-Simulation based Container Orchestration (COSCO) framework. It introduces fundamental AI and co-simulation concepts, their importance in QoS optimization and performance engineering challenges in the context of Fog computing. It also discusses how AI models, specifically, deep neural networks (DNNs), can be used in tandem with simulated estimates to take optimal resource management decisions. Additionally, we discuss a few use cases of training DNNs as surrogates to estimate key QoS metrics and utilize such models to build policies for dynamic scheduling in a distributed fog environment. The tutorial demonstrates these concepts using the COSCO framework. Metric monitoring and simulation primitives in COSCO demonstrates the efficacy of an AI and simulation based scheduler on a fog/cloud platform. Finally, we provide AI baselines for resource management problems that arise in the area of fog management.},
booktitle = {Companion of the 2022 ACM/SPEC International Conference on Performance Engineering},
pages = {25–28},
numpages = {4},
keywords = {performance engineering, artificial intelligence, fog computing, co-simulation.},
location = {Bejing, China},
series = {ICPE '22}
}

@inproceedings{10.1145/3493700.3493731,
author = {Lodha, Ishaan and Kolur, Lakshana and Krishnan, Keerthan and Dheenadayalan, Kumar and Sitaram, Dinkar and Nandi, Siddhartha},
title = {Cost-Optimized Video Transfer Using Real-Time Super Resolution Convolutional Neural Networks},
year = {2022},
isbn = {9781450385824},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3493700.3493731},
doi = {10.1145/3493700.3493731},
abstract = {The explosion of video generation and consumption, coupled with an inadequate rise in network bandwidth has led to network delays and decreased Quality of Experience, limiting the opportunities to tap into the full potential of video data. These deficiencies in network resources with a shift to cloud computing models have resulted in the need to revisit the overall mechanism for video transfer and storage of videos between edge devices and the cloud. We propose a novel multi-scale real-time super-resolution convolutional neural network to achieve the composite task of optimizing the entire cost of video transfer with minimal loss of quality that can be used for any application involving the transfer of video data. To achieve this, we develop a cost-optimized video transfer system that optimizes the metrics of video transfer to give the best quality video output, given the user budget. The model makes use of Convolution blocks for extracting features and output creation with multiple sub-pixel convolutions in a novel structure. For upscaling to full High Definition video at 30 fps, the model successfully retained the frame rate while the system achieved savings in transfer time and bandwidth usage. This model has been trained on surveillance videos (VIRAT dataset), but consistent results were obtained during testing even on feature films and sports videos which demonstrates its content invariance. The evaluation of our approach averaged over 376 videos, yielded meager quality losses of 8%, measured by a novel non-referential quality metric, also proposed in this paper. Additionally, average network bandwidth savings of 80% and average video transfer time reduction of 52% were achieved.},
booktitle = {5th Joint International Conference on Data Science &amp; Management of Data (9th ACM IKDD CODS and 27th COMAD)},
pages = {213–221},
numpages = {9},
keywords = {GAN, super resolution, video transfer, cost optimization, CNN, deep neural networks},
location = {Bangalore, India},
series = {CODS-COMAD 2022}
}

@inproceedings{10.5555/3581644.3581660,
author = {Passos, Edenilson J\^{o}natas dos and Fiorese, Adriano},
title = {Monitoring Metrics for Load Balancing over Video Content Distribution Servers},
year = {2023},
isbn = {9783903176515},
publisher = {International Federation for Information Processing},
address = {Laxenburg, AUT},
abstract = {Cloud computing and video streaming services have been in constant expansion in recent years. Along with it, the demand for computing resources has also increased significantly. In this context, monitoring the use of these resources is crucial to maintain a satisfactory level of Quality of Service and, consequently, Quality of Experience, especially in video transmission services. This work discusses a new method of monitoring resources and quality of service metrics on content servers involving CPU utilization and server throughput, which is obtained in a distributed way. For that, a distributed collector system that is based on a modified version of the ring election algorithm is developed to retrieve the Quality of Service metrics in each server. Evaluation experiment results show that there are no performance gains on the system such as the content loading faster for the user, there are however, improvements in terms of the whole system scalability. The greater the number of servers for monitoring, the better the approach is compared to the traditional method of monitoring resources through request and response.},
booktitle = {Proceedings of the 18th International Conference on Network and Service Management},
articleno = {13},
numpages = {7},
keywords = {load balancing, SDN, monitoring},
location = {Thessaloniki, Greece},
series = {CNSM '22}
}

@article{10.1145/3512893,
author = {Ming, Zhao and Li, Xiuhua and Sun, Chuan and Fan, Qilin and Wang, Xiaofei and Leung, Victor C. M.},
title = {Sleeping Cell Detection for Resiliency Enhancements in 5G/B5G Mobile Edge-Cloud Computing Networks},
year = {2022},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {3},
issn = {1550-4859},
url = {https://doi.org/10.1145/3512893},
doi = {10.1145/3512893},
abstract = {The rapid increase of data traffic has brought great challenges to the maintenance and optimization of 5G and beyond, and some smart critical infrastructures, e.g., small base stations (SBSs) in cellular cells, are facing serious security and failure threats, causing resiliency degradation concerns. Among special smart critical infrastructure failures, the sleeping cell failure is hard to address since no alarm is generally triggered. Sleeping cells can remain undetected for a long time and can severely affect the quality of service/quality of experience to users. To enhance the resiliency of the SBSs in sleeping cells, we design a mobile edge-cloud computing system and propose a semi-supervised learning-based framework to dynamically detect the sleeping cells. Particularly, we consider two indicators, recovery proportion and recovery speed, to measure the resiliency of the SBSs. Moreover, in the proposed scheme, experts’ optimization experience and each period’s detection results can be utilized to iteratively improve the performance. Then we adopt a dataset from real-world networks for performance evaluation. Trace-driven evaluation results demonstrate that the proposed scheme outperforms existing sleeping cell detection schemes, and can also reduce the communication and runtime costs and enhance the resiliency of the SBSs.},
journal = {ACM Trans. Sen. Netw.},
month = {apr},
articleno = {42},
numpages = {30},
keywords = {5G/B5G, sleeping cell detection, semi-supervised learning, Smart critical infrastructures, resiliency enhancement, mobile edge-cloud computing}
}

@inproceedings{10.1145/3578244.3583728,
author = {Volpert, Simon and Erb, Benjamin and Eisenhart, Georg and Seybold, Daniel and Wesner, Stefan and Domaschka, J\"{o}rg},
title = {A Methodology and Framework to Determine the Isolation Capabilities of Virtualisation Technologies},
year = {2023},
isbn = {9798400700682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578244.3583728},
doi = {10.1145/3578244.3583728},
abstract = {The capability to isolate system resources is an essential characteristic of virtualisation technologies and is therefore important for research and industry alike. It allows the co-location of experiments and workloads, the partitioning of system resources and enables multi-tenant business models such as cloud computing. Poor isolation among tenants bears the risk of noisy-neighbour and contention effects which negatively impacts all of those use-cases. These effects describe the negative impact of one tenant onto another by utilising shared resources. Both industry and research provide many different concepts and technologies to realise isolation. Yet, the isolation capabilities of all these different approaches are not well understood; nor is there an established way to measure the quality of their isolation capabilities. Such an understanding, however, is of uttermost importance in practice to elaborately decide on a suited implementation. Hence, in this work, we present a novel methodology to measure the isolation capabilities of virtualisation technologies for system resources, that fulfils all requirements to benchmarking including reliability. It relies on an immutable approach, based on Experiment-as-Code. The complete process holistically includes everything from bare metal resource provisioning to the actual experiment enactment.The results determined by this methodology help in the decision for a virtualisation technology regarding its capability to isolate given resources. Such results are presented here as a closing example in order to validate the proposed methodology.},
booktitle = {Proceedings of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {149–160},
numpages = {12},
keywords = {framework, isolation, virtualisation, benchmarking},
location = {Coimbra, Portugal},
series = {ICPE '23}
}

@inproceedings{10.1145/3543712.3543715,
author = {Petrov, Valerii and Gennadinik, Anna and Avksentieva, Elena},
title = {Metrics for Machine Learning Evaluation Methods in Cloud Monitoring Systems},
year = {2022},
isbn = {9781450396226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543712.3543715},
doi = {10.1145/3543712.3543715},
abstract = {During the machine learning pipeline development, engineers need to validate the efficiency of the machine learning methods in order to assess the quality of the made forecast.Due to the wide deployment and implementation of the machine learning models and methods across monitoring systems, the actual scientific problem is the assessment of these methods in the monitoring systems. This research has concluded that the current standard metrics are not sufficient to get the accurate assessment for the used machine learning methods.This research has provided the new complex rating for anomaly detection regarding the use-cases of cloud monitoring systems. The main difference from the standard metrics is that the new approach includes better integration to the business processes, demanding resources, and a critical glance to the false-positive alerts. The new approach might be used in the model assessment in monitoring systems with the similar requirements:Cost-effective use of computing resourcesLow amount of false-positivesFast detection of anomaliesFurthermore, the current research proposes new methods of computation capacity planning for different anomaly detection methods. These methods are not even limited to anomaly detection and could be used as a basis for developing capacity planning for other machine learning techniques and approaches.· Applied computing∼Operations research∼Forecasting · Computer systems organization∼Architectures∼Distributed architectures ∼Cloud computing∼Forecasting · Computing methodologies∼Machine learning},
booktitle = {Proceedings of the 2022 8th International Conference on Computer Technology Applications},
pages = {168–175},
numpages = {8},
keywords = {machine learning metrics, capacity planning, monitoring, quality assessment},
location = {Vienna, Austria},
series = {ICCTA '22}
}

